---
sidebar: sidebar 
permalink: vmware/vmware-vsphere-datastores-nfs.html 
keywords: vSphere, datastore, NFS, vVols, NFSv3, NFSv4.1 
summary: 'Cette page décrit les bonnes pratiques d"implémentation de VMware vSphere avec les datastores ONTAP et NFS.' 
---
= NFS
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ../media/


[role="lead"]
ONTAP est, entre autres, une baie NAS scale-out de grande qualité. ONTAP permet à VMware vSphere d'accéder simultanément aux datastores connectés par NFS à partir de nombreux hôtes VMware ESXi, ce qui dépasse de loin les limites imposées aux systèmes de fichiers VMFS. L'utilisation de NFS avec vSphere offre des avantages en termes de facilité d'utilisation et d'efficacité du stockage, comme indiqué dans la link:vmware-vsphere-datastores-top.html["les datastores"] section.

Nous vous recommandons les meilleures pratiques suivantes lorsque vous utilisez ONTAP NFS avec vSphere :

* Utilisez les outils ONTAP pour VMware vSphere (meilleure pratique la plus importante) :
+
** Utilisez les outils ONTAP pour VMware vSphere pour provisionner les datastores, car ils simplifient automatiquement la gestion des règles d'exportation.
** Lors de la création de datastores pour clusters VMware avec le plug-in, sélectionnez le cluster plutôt qu'un seul serveur ESX. Ce choix permet de monter automatiquement le datastore sur tous les hôtes du cluster.
** Utilisez la fonction de montage du plug-in pour appliquer les datastores existants aux nouveaux serveurs.
** Lorsque vous n'utilisez pas les outils ONTAP pour VMware vSphere, utilisez une export policy unique pour tous les serveurs ou pour chaque cluster de serveurs où un contrôle d'accès supplémentaire est nécessaire.


* Utiliser une interface logique (LIF) unique pour chaque SVM sur chaque nœud du cluster ONTAP. Les recommandations précédentes d'une LIF par datastore ne sont plus nécessaires. L'accès direct (LIF et datastore sur le même nœud) est préférable, mais ne vous inquiétez pas pour l'accès indirect, car l'effet de performance est généralement minimal (microsecondes).
* Si vous utilisez fpolicy, veillez à exclure les fichiers .lck car ils sont utilisés par vSphere pour le verrouillage à chaque mise sous tension d'une machine virtuelle.
* Toutes les versions de VMware vSphere actuellement prises en charge peuvent utiliser NFS v3 et v4.1. Le support officiel de nconnect a été ajouté à vSphere 8.0 mise à jour 2 pour NFS v3 et mise à jour 3 pour NFS v4.1. Pour NFS v4.1, vSphere continue à prendre en charge l'agrégation de sessions, l'authentification Kerberos et l'authentification Kerberos avec intégrité. Il est important de noter que l'agrégation de session nécessite ONTAP 9.14.1 ou une version ultérieure. Vous pouvez en savoir plus sur la fonction nconnect et sur la manière dont elle améliore les performances à link:https://docs.netapp.com/us-en/netapp-solutions/virtualization/vmware-vsphere8-nfsv3-nconnect.html["Fonctionnalité NFSv3 nconnect avec NetApp et VMware"].


[TIP]
====
* La valeur maximale de nconnect dans vSphere 8 est 4 et la valeur par défaut est 1. La limite de valeur maximale dans vSphere peut être augmentée par hôte grâce à des paramètres avancés, mais elle n'est généralement pas nécessaire.
* Une valeur de 4 est recommandée pour les environnements nécessitant des performances supérieures à celles d'une seule connexion TCP.
* Sachez que ESXi a une limite de 256 connexions NFS et que chaque connexion nconnect compte pour ce total. Par exemple, deux datastores avec nconnect=4 compteraient comme huit connexions au total.
* Il est important de tester l'impact de nconnect sur les performances de votre environnement avant d'implémenter des modifications à grande échelle dans les environnements de production.


====
* Notez que NFS v3 et NFS v4.1 utilisent différents mécanismes de verrouillage. NFS v3 utilise un verrouillage côté client, tandis que NFS v4.1 utilise un verrouillage côté serveur. Bien qu'un volume ONTAP puisse être exporté via les deux protocoles, ESXi ne peut monter qu'un datastore via un protocole. Cependant, cela ne signifie pas que d'autres hôtes ESXi ne peuvent pas monter le même datastore via une version différente. Pour éviter tout problème, il est essentiel de spécifier la version du protocole à utiliser lors du montage, en veillant à ce que tous les hôtes utilisent la même version et, par conséquent, le même style de verrouillage. Il est essentiel d'éviter de mélanger les versions NFS entre les hôtes. Si possible, utilisez les profils hôtes pour vérifier la conformité.
+
** Étant donné qu'il n'existe pas de conversion automatique de datastore entre NFS v3 et NFS v4.1, créez un nouveau datastore NFSv4.1 et utilisez Storage vMotion pour migrer les machines virtuelles vers le nouveau datastore.
** Pour connaître les niveaux de correctifs ESXi requis pour la prise en charge, reportez-vous aux notes du tableau d'interopérabilité NFS v4.1 dans lelink:https://mysupport.netapp.com/matrix/["Matrice d'interopérabilité NetApp"^].


* Comme indiqué à la link:vmware/vmware-vsphere-settings.html["paramètres"], si vous n'utilisez pas vSphere CSI pour Kubernetes, vous devez définir newSyncInterval par https://knowledge.broadcom.com/external/article/386364/reducing-excessive-vsan-cnssync-warnings.html["VMware KB 386364"^]
* Les règles d'export NFS permettent de contrôler l'accès des hôtes vSphere. Vous pouvez utiliser une seule règle avec plusieurs volumes (datastores). Avec NFS, ESXi utilise le style de sécurité sys (UNIX) et requiert l'option de montage racine pour exécuter les VM. Dans ONTAP, cette option est appelée superutilisateur et, lorsque l'option superutilisateur est utilisée, il n'est pas nécessaire de spécifier l'ID utilisateur anonyme. Notez que les règles d'export-policy avec des valeurs différentes pour `-anon` et `-allow-suid` peuvent causer des problèmes de découverte de SVM avec les outils ONTAP. Les adresses IP doivent être séparées par des virgules, sans espaces dans les adresses de port vmkernel qui montés dans les datastores. Voici un exemple de règle de stratégie :
+
** Protocole d'accès : nfs (qui inclut nfs3 et nfs4)
** Liste des noms d'hôte, adresses IP, groupes réseau ou domaines correspondant au client : 192.168.42.21,192.168.42.22
** Règle d'accès RO : tous
** Règle d'accès RW : tous
** ID utilisateur auquel les utilisateurs anonymes sont mappés : 65534
** Types de sécurité superutilisateur : tous
** Honorez les bits setuid dans SETATTR : TRUE
** Autoriser la création de périphériques : vrai


* Si le plug-in NetApp NFS pour VMware VAAI est utilisé, le protocole doit être défini comme `nfs` lors de la création ou de la modification de la règle d'export policy. Le protocole NFSv4 est requis pour que le déchargement des copies VAAI fonctionne, et la spécification du protocole comme `nfs` inclut automatiquement les versions NFSv3 et NFSv4. Cette opération est requise même si le type de datastore est créé en tant que NFS v3.
* Les volumes des datastores NFS sont rassemblés dans le volume racine du SVM. Par conséquent, ESXi doit également avoir accès au volume racine pour naviguer et monter des volumes de datastores. La export policy pour le volume root, et pour tout autre volume dans lequel la jonction du volume de datastore est imbriquée, doit inclure une règle ou des règles pour les serveurs ESXi leur accordant un accès en lecture seule. Voici un exemple de règle pour le volume racine, également à l'aide du plug-in VAAI :
+
** Protocole d'accès : nfs
** Comparaison avec le client : 192.168.42.21,192.168.42.22
** Règle d'accès RO : sys
** Règle d'accès RW : jamais (meilleure sécurité pour le volume racine)
** UID anonyme
** Superutilisateur : sys (également requis pour le volume racine avec VAAI)


* Bien que ONTAP offre une structure d'espace de noms de volume flexible permettant d'organiser les volumes dans une arborescence à l'aide de jonctions, cette approche n'a aucune valeur pour vSphere. Il crée un répertoire pour chaque machine virtuelle à la racine du datastore, quelle que soit la hiérarchie de l'espace de noms du stockage. Il est donc recommandé de simplement monter le Junction path pour les volumes pour vSphere au volume root du SVM, c'est-à-dire comment les outils ONTAP pour VMware vSphere provisionne les datastores. Sans chemins de jonction imbriqués, aucun volume ne dépend d'aucun volume autre que le volume root et que mettre un volume hors ligne ou le détruire, même intentionnellement, n'affecte pas le chemin d'accès aux autres volumes.
* Une taille de bloc de 4 Ko convient parfaitement aux partitions NTFS sur les datastores NFS. La figure suivante décrit la connectivité d'un hôte vSphere vers un datastore NFS ONTAP.


image:vsphere_ontap_image3.png["Connectivité d'un hôte vSphere à un datastore ONTAP NFS"]

Le tableau suivant répertorie les versions NFS et les fonctionnalités prises en charge.

|===
| Fonctionnalités de vSphere | NFSv3 | NFSv4.1 


| VMotion et Storage vMotion | Oui. | Oui. 


| Haute disponibilité | Oui. | Oui. 


| Tolérance aux pannes | Oui. | Oui. 


| DRS | Oui. | Oui. 


| Profils hôtes | Oui. | Oui. 


| DRS de stockage | Oui. | Non 


| Contrôle des E/S du stockage | Oui. | Non 


| SRM | Oui. | Non 


| Volumes virtuels | Oui. | Non 


| Accélération matérielle (VAAI) | Oui. | Oui. 


| Authentification Kerberos | Non | Oui (optimisé avec vSphere 6.5 et versions ultérieures pour prendre en charge AES et krb5i) 


| Prise en charge des chemins d'accès | Non | Oui (ONTAP 9.14.1) 
|===