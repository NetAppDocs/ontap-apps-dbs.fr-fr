<?xml version="1.0" encoding="UTF-8"?>
<blocks>
  <block id="d41d8cd98f00b204e9800998ecf8427e" category="summary"></block>
  <block id="30d965eef5ba25c6b9998ae38270b43e" category="doc">Mentions légales</block>
  <block id="e9c44bbfd795a5d63d74c6a77afee70d" category="paragraph">Les mentions légales donnent accès aux déclarations de copyright, aux marques, aux brevets, etc.</block>
  <block id="6016a2b341113bf496b719905398ecd2" category="section-title">Droits d'auteur</block>
  <block id="52009bb7ee17227f566cd26a02caee56" category="inline-link-macro"><block ref="52009bb7ee17227f566cd26a02caee56" category="inline-link-rx"></block></block>
  <block id="a1a9afcf552a769c282769271829889a" category="paragraph"><block ref="a1a9afcf552a769c282769271829889a" category="inline-link-macro-rx"></block></block>
  <block id="126a02652da6de02962cf1b654fd6376" category="section-title">Marques déposées</block>
  <block id="c4ce4761e466527d26b3e3d5ed1006fd" category="paragraph">NetApp, le logo NETAPP et les marques mentionnées sur la page des marques commerciales NetApp sont des marques commerciales de NetApp, Inc. Les autres noms de sociétés et de produits peuvent être des marques commerciales de leurs propriétaires respectifs.</block>
  <block id="f99aa604031e5049799e73b5c3748a98" category="inline-link-macro"><block ref="f99aa604031e5049799e73b5c3748a98" category="inline-link-rx"></block></block>
  <block id="5d545fe5152641e2ebe654e336e520e5" category="paragraph"><block ref="5d545fe5152641e2ebe654e336e520e5" category="inline-link-macro-rx"></block></block>
  <block id="be89498d2f8a22ce47c02ba9795fe2af" category="section-title">Brevets</block>
  <block id="d0b19d36be2c5f16e9aef46c8a452d3d" category="paragraph">Vous trouverez une liste actuelle des brevets appartenant à NetApp à l'adresse suivante :</block>
  <block id="88e5eabd3917048b6927c42496b98f86" category="inline-link-macro"><block ref="88e5eabd3917048b6927c42496b98f86" category="inline-link-rx"></block></block>
  <block id="dd38f906b37d412de7d1c1dcf4cbf31c" category="paragraph"><block ref="dd38f906b37d412de7d1c1dcf4cbf31c" category="inline-link-macro-rx"></block></block>
  <block id="56c34c6410dd45c5cec44149ad0ce037" category="section-title">Politique de confidentialité</block>
  <block id="8acb58cbd50ef1b468a020ee0bd351d3" category="inline-link-macro"><block ref="8acb58cbd50ef1b468a020ee0bd351d3" category="inline-link-rx"></block></block>
  <block id="2352c4e1f4d0024ade0869e00e6243f4" category="paragraph"><block ref="2352c4e1f4d0024ade0869e00e6243f4" category="inline-link-macro-rx"></block></block>
  <block id="c0227cef6f07a8cd2ac72f2945b031aa" category="section-title">Source ouverte</block>
  <block id="9b73989307c1975dfa4d5e1581e4afe8" category="paragraph">Les fichiers de notification fournissent des informations sur les droits d'auteur et les licences de tiers utilisés dans le logiciel NetApp.</block>
  <block id="253b40ae359ba25b56231803430c4873" category="section-title">ONTAP</block>
  <block id="856c8958afd787f748a4a025f649154a" category="inline-link-macro">Avis pour ONTAP 9.13.1</block>
  <block id="b22b3b2970d843f99e7e6904bea05207" category="inline-link-macro">Notification relative à ONTAP 9.12.1</block>
  <block id="0358f41254df2d512849db5a04b7e3d4" category="inline-link-macro">Notification relative à ONTAP 9.12.0</block>
  <block id="28f1290102a277ef2fd452d558c74219" category="inline-link-macro">Notification relative à ONTAP 9.11.1</block>
  <block id="57b07f14c8eb4660f94a86d29d53362d" category="inline-link-macro">Notification relative à ONTAP 9.10.1</block>
  <block id="396712eb9c1644241047ac30619b2b3e" category="inline-link-macro">Avis pour ONTAP 9.10.0</block>
  <block id="1e6000d4849ef9f3e08d1d9908e9f163" category="inline-link-macro">Notification relative à ONTAP 9.9.1</block>
  <block id="6f408b9c999245c7aa32bc9cb1a020f6" category="inline-link-macro">Notification relative à ONTAP 9.8</block>
  <block id="04b0bd5b1b4d414fdde93f809162d36d" category="inline-link-macro">Avis pour ONTAP 9.7</block>
  <block id="0c1d7dffcba488555d5eb39b8991e822" category="inline-link-macro">Avis pour ONTAP 9.6</block>
  <block id="a11ac6880e72412c0f54ae19bea3d191" category="inline-link-macro">Avis pour ONTAP 9.5</block>
  <block id="e49c3c01b15761b5f011d0bd2a0661a3" category="inline-link-macro">Avis pour ONTAP 9.4</block>
  <block id="bf7dcf6467a8a03b05b2d37d31d6eccd" category="inline-link-macro">Avis pour ONTAP 9.3</block>
  <block id="0328352fdfda84af6968462d1a67d3a6" category="inline-link-macro">Avis pour ONTAP 9.2</block>
  <block id="83904100c7d6fe0102e8b2b5bd8ec4bb" category="inline-link-macro">Avis pour ONTAP 9.1</block>
  <block id="9e476387322a5c250893cf9c5c4ce78c" category="doc">Stratégies</block>
  <block id="b9e18a3460bc17eb9ea65b03f0167453" category="paragraph">Ceci est courant avec les bases de données. Les bases de données qui contiennent des blocs inactifs sont également candidates au Tiering FabricPool. Par exemple, une base de données de gestion de la chaîne logistique peut contenir des informations historiques qui doivent être disponibles si nécessaire, mais qui ne sont pas accessibles pendant les opérations normales. FabricPool peut être utilisé pour déplacer de manière sélective les blocs inactifs.</block>
  <block id="95e955bbbe5dd9520a6bf45b0d8a9d4c" category="paragraph">Par exemple, les fichiers de données s'exécutant sur un volume FabricPool avec un<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> la période de 90 jours permet de conserver les blocs auxquels le tier de performance accède au cours des 90 jours précédents. Toutefois, tout élément non utilisé pendant 90 jours est transféré vers le niveau de capacité. Dans d'autres cas, l'activité normale de l'application préserve les blocs corrects du niveau approprié. Par exemple, si une base de données est normalement utilisée pour traiter les 60 jours précédents de données sur une base régulière, c'est beaucoup moins<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> la période peut être définie car l'activité naturelle de l'application s'assure que les blocs ne sont pas déplacés prématurément.</block>
  <block id="c33af7c93d461803ceaf8531e861017d" category="paragraph">Le<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> la politique doit être utilisée avec soin pour les bases de données. De nombreuses bases de données ont des activités périodiques, comme le processus de fin de trimestre ou les opérations de réindexation. Si la période de ces opérations est supérieure à<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> des problèmes de performances peuvent se produire. Par exemple, si le traitement de fin de trimestre nécessite 1 To de données qui n'étaient pas modifiées, ces données peuvent maintenant être présentes sur le niveau de capacité. Les lectures à partir du niveau de capacité sont souvent extrêmement rapides et ne provoquent pas de problèmes de performance, mais les résultats exacts dépendent de la configuration du magasin d'objets.</block>
  <block id="03431a55183cb73a12c1bbc3e1927678" category="paragraph">Le<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> la règle doit être définie de manière suffisamment élevée pour conserver les fichiers qui peuvent être requis sur le niveau de performance. Par exemple, une base de données dans laquelle les 60 derniers jours de données peuvent être requis avec des performances optimales justifierait de définir le<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> période à 60 jours. Des résultats similaires pourraient également être obtenus en fonction des modèles d'accès aux fichiers. Par exemple, si les 90 derniers jours de données sont requis et que l'application accède à cette période de 90 jours, les données restent sur le Tier de performance. Réglage du<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> une période de 2 jours permettrait de hiérarchiser les données rapidement lorsque celles-ci deviennent moins actives.</block>
  <block id="25d9496e96e698b08c4fc713bfc9a5ca" category="paragraph">Le<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> la règle est requise pour la hiérarchisation de ces blocs, car uniquement le système<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> la règle affecte les blocs qui se trouvent dans le système de fichiers actif.</block>
  <block id="55fad400d892fb6062e67904fa9be485" category="admonition">Tout type d'accès aux données réinitialise les données de la carte thermique. Par conséquent, les analyses de la table complète des bases de données, et même les opérations de sauvegarde qui lisent les fichiers source, empêchent le Tiering, car nécessaire<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> le seuil n'est jamais atteint.</block>
  <block id="117c4b6bad0236ab23e0fe29aead8aef" category="paragraph">Bien que le redimensionnement des LUN soit une option d'augmentation de la capacité, il est généralement préférable d'utiliser un LVM, y compris Oracle ASM. L'une des principales raisons pour lesquelles les LVM existent est d'éviter la nécessité d'un redimensionnement des LUN. Avec une LVM, plusieurs LUN sont reliées entre elles dans un pool de stockage virtuel. Les volumes logiques extraits de ce pool sont gérés par le LVM et peuvent être facilement redimensionnés. Il est également possible d'éviter les points sensibles sur un disque en distribuant un volume logique donné à tous les LUN disponibles. Une migration transparente peut généralement être effectuée à l'aide du gestionnaire de volumes pour déplacer les extensions sous-jacentes d'un volume logique vers de nouvelles LUN.</block>
  <block id="4d4855a15e1f9d6fd8f8bdf1668c537e" category="doc">NVFAIL forcé manuellement</block>
  <block id="8772c1c8bed97f5c942657feeb8bfb6f" category="admonition">Cette section décrit en détail les fonctionnalités de base de ONTAP NVFAIL et aborde également les sujets spécifiques à MetroCluster.</block>
  <block id="14d74316044293d1ebd8c5a01ff90055" category="paragraph">Avec MetroCluster, une écriture n'est pas confirmée tant qu'elle n'a pas été connectée à la NVRAM et à la NVRAM locales sur au moins un autre contrôleur. Cette approche évite toute panne matérielle ou de courant qui entraîne une perte des E/S à la volée En cas de panne de la mémoire NVRAM locale ou de la connectivité aux autres nœuds, les données ne seront plus mises en miroir.</block>
  <block id="d820d86d09ea05a0de19c3aacbfb72b2" category="paragraph">Si la mémoire NVRAM locale signale une erreur, le nœud s'arrête. Cet arrêt entraîne le basculement vers un contrôleur partenaire lorsque des paires haute disponibilité sont utilisées. Avec MetroCluster, le comportement dépend de la configuration globale choisie, mais il peut entraîner un basculement automatique vers la note distante. Dans tous les cas, aucune donnée n'est perdue parce que le contrôleur qui connaît la défaillance n'a pas acquitté l'opération d'écriture.</block>
  <block id="886174de078cee4595eb8a8d07f81703" category="paragraph">Une défaillance de connectivité site à site qui bloque la réplication NVRAM sur des nœuds distants est une situation plus compliquée. Les écritures ne sont plus répliquées sur les nœuds distants, ce qui crée un risque de perte de données en cas d'erreur catastrophique sur un contrôleur. Plus important encore, une tentative de basculement vers un autre nœud dans ces conditions entraîne une perte de données.</block>
  <block id="790ec042c9b89dac2390ea81b9c29a51" category="paragraph">Le facteur de contrôle est de savoir si la NVRAM est synchronisée. Si la mémoire NVRAM est synchronisée, le basculement nœud à nœud peut se poursuivre sans risque de perte de données. Dans une configuration MetroCluster, si la mémoire NVRAM et les plexes d'agrégats sous-jacents sont synchronisés, vous pouvez effectuer le basculement sans risque de perte de données.</block>
  <block id="3d936bb059b98a2fc7c177d20eb755c9" category="paragraph">ONTAP n'autorise pas le basculement ou le basculement lorsque les données ne sont pas synchronisées, sauf si le basculement ou le basculement est forcé. Le fait de forcer une modification des conditions de cette manière reconnaît que les données peuvent être laissées pour compte dans le contrôleur d'origine et que la perte de données est acceptable.</block>
  <block id="3d37a3a8ed77bebc986238aedccecbc9" category="paragraph">Les bases de données sont particulièrement vulnérables à la corruption si un basculement ou un basculement est forcé, car les bases de données conservent des caches internes de données plus volumineux sur disque. En cas de basculement forcé ou de basculement forcé, les modifications précédemment reconnues sont effectivement supprimées. Le contenu de la baie de stockage recule dans le temps et l'état du cache de la base de données ne reflète plus l'état des données sur le disque.</block>
  <block id="7ad23b7fa394c8666b132d78a58b1987" category="paragraph">Afin de protéger les applications de cette situation, ONTAP permet de configurer les volumes pour une protection spéciale contre les défaillances de mémoire NVRAM. Lorsqu'il est déclenché, ce mécanisme de protection entraîne l'entrée d'un volume dans un état appelé NVFAIL. Cet état entraîne des erreurs d'E/S qui entraînent l'arrêt d'une application et n'utilisent donc pas de données obsolètes. Les données ne doivent pas être perdues car des écritures reconnues sont toujours présentes sur le système de stockage et, avec les bases de données, toutes les données de transaction validées doivent être présentes dans les journaux.</block>
  <block id="99259586124503e22927506a7ed3738d" category="paragraph">Les étapes suivantes habituelles sont qu'un administrateur arrête complètement les hôtes avant de remettre manuellement en ligne les LUN et les volumes. Bien que ces étapes puissent impliquer un certain travail, cette approche est le moyen le plus sûr d'assurer l'intégrité des données. Toutes les données n'ont pas besoin de cette protection. C'est pourquoi NVFAIL peut être configuré volume par volume.</block>
  <block id="13fbc5a220fe8007dcaea69217bba134" category="paragraph">Pour forcer un basculement avec un cluster d'applications (y compris VMware, Oracle RAC et autres) distribué sur plusieurs sites, il faut spécifier la méthode la plus sûre<block ref="71e644310ff0f1164d905d6e80174023" prefix=" " category="inline-code"></block> en ligne de commande. Cette option est disponible en tant que mesure d'urgence pour s'assurer que toutes les données mises en cache sont vidées. Si un hôte utilise des ressources de stockage initialement situées sur le site sinistré, il reçoit des erreurs d'E/S ou un descripteur de fichier obsolète <block ref="a3c6541ac12f1f06a81cc9b03e6bd094" prefix="(" category="inline-code"></block>) erreur. Les bases de données Oracle planent et les systèmes de fichiers passent entièrement hors ligne ou en mode lecture seule.</block>
  <block id="dc6683d37e50abd82911fa91c036fbb2" category="paragraph">Une fois le basculement terminé, le<block ref="6b0a5ec5ecf08db5d4b32d860214d098" prefix=" " category="inline-code"></block> L'indicateur doit être effacé et les LUN doivent être mis en ligne. Une fois cette activité terminée, la base de données peut être redémarrée. Ces tâches peuvent être automatisées afin de réduire le RTO.</block>
  <block id="a2626552f293b2377efe829e69d14daa" category="section-title">dr-force-nvfail</block>
  <block id="f0cc4bbe3d196251009dbe9f0ac42ffc" category="paragraph">En tant que mesure de sécurité générale, réglez le<block ref="a2626552f293b2377efe829e69d14daa" prefix=" " category="inline-code"></block> drapeau sur tous les volumes accessibles depuis un site distant pendant les opérations normales, ce qui signifie qu'il s'agit d'activités utilisées avant le basculement. Le résultat de ce paramètre est que les volumes distants sélectionnés deviennent indisponibles lorsqu'ils entrent<block ref="6b0a5ec5ecf08db5d4b32d860214d098" prefix=" " category="inline-code"></block> lors d'un basculement. Une fois le basculement terminé, le<block ref="6b0a5ec5ecf08db5d4b32d860214d098" prefix=" " category="inline-code"></block> L'indicateur doit être effacé et les LUN doivent être mis en ligne. Une fois ces activités terminées, les applications peuvent être redémarrées. Ces tâches peuvent être automatisées afin de réduire le RTO.</block>
  <block id="5f6aa76cc0fe886c07f242f921486ef7" category="paragraph">Le résultat est similaire à l'utilisation du<block ref="71e644310ff0f1164d905d6e80174023" prefix=" " category="inline-code"></block> indicateur pour commutateurs manuels. Toutefois, le nombre de volumes affectés peut être limité aux volumes qui doivent être protégés contre les applications ou les systèmes d'exploitation dotés de caches obsolètes.</block>
  <block id="4df566a29b44806612369c0c1f67521b" category="paragraph">Il existe deux exigences critiques pour un environnement qui n'utilise pas<block ref="a2626552f293b2377efe829e69d14daa" prefix=" " category="inline-code"></block> sur les volumes d'application :</block>
  <block id="aaf1cc67bd88c39a71e691d413ded49f" category="list-text">Un basculement forcé ne doit pas se produire plus de 30 secondes après la perte du site principal.</block>
  <block id="7f9cc623e2a11875714cf4bc64f148fd" category="list-text">Le basculement ne doit pas avoir lieu pendant les tâches de maintenance ou tout autre mode dans lequel les plexes SyncMirror ou la réplication NVRAM sont désynchronisés. Le premier critère peut être atteint à l'aide d'un logiciel disjoncteur d'attache configuré pour effectuer un basculement dans les 30 secondes qui suivent la défaillance d'un site. Cela ne signifie pas que le basculement doit être effectué dans les 30 secondes qui suivent la détection d'une défaillance de site. Cela signifie qu'il n'est plus sûr de forcer un basculement si 30 secondes se sont écoulées depuis qu'un site a été confirmé opérationnel.</block>
  <block id="0929cc8043c21dcf0163f06424677ede" category="paragraph">Le deuxième critère peut être partiellement respecté en désactivant toutes les fonctionnalités de basculement automatisé lorsque la configuration MetroCluster est désynchronisée. Il est préférable d'opter pour une solution disjoncteur d'attache capable de surveiller l'état de santé de la réplication NVRAM et des plexes SyncMirror. Si le cluster n'est pas entièrement synchronisé, le disjoncteur d'attache ne doit pas déclencher de basculement.</block>
  <block id="a168430c68d0310385371eabe149a118" category="paragraph">Le logiciel MCTB de NetApp ne peut pas contrôler l'état de la synchronisation. Il doit donc être désactivé lorsque MetroCluster n'est pas synchronisé pour quelque raison que ce soit. ClusterLion inclut des fonctionnalités de surveillance NVRAM et plex et peut être configuré pour ne pas déclencher le basculement à moins que le système MetroCluster ne soit entièrement synchronisé.</block>
  <block id="baba038803e218b2ac3b2688bc2fd5db" category="doc">Nombre de LUN</block>
  <block id="b0e4db975ae00108abe9f47db9be5668" category="paragraph">Une LUN est un objet virtualisé sur ONTAP qui existe sur tous les disques de l'agrégat d'hébergement. Par conséquent, les performances de la LUN ne sont pas affectées par sa taille, car la LUN exploite tout le potentiel de performance de l'agrégat, quelle que soit sa taille.</block>
  <block id="7235d4b71fadc2fe03d09d863c7cdd66" category="paragraph">À titre de commodité, les clients peuvent souhaiter utiliser un LUN de taille spécifique. Par exemple, si une base de données est construite sur un groupe de disques LVM ou Oracle ASM composé de deux LUN de 1 To chacune, ce groupe de disques doit être développé par incréments de 1 To. Il peut être préférable de créer le groupe de disques à partir de huit LUN de 500 Go chacune, de sorte que le groupe de disques puisse être augmenté par incréments plus petits.</block>
  <block id="4b1ffe65479a23391a2c7f9caf467a35" category="paragraph">Il n'est pas recommandé d'établir une taille de LUN standard universelle, car cela peut compliquer la gestion. Par exemple, une taille de LUN standard de 100 Go peut fonctionner correctement lorsqu'une base de données ou un datastore se situe entre 1 et 2 To, mais qu'une base de données ou un datastore de 20 To nécessite 200 LUN. Cela signifie que les délais de redémarrage du serveur sont plus longs, que les différents utilisateurs doivent gérer davantage d'objets et que des produits tels que SnapCenter doivent effectuer des recherches sur de nombreux objets. L'utilisation d'un nombre inférieur de LUN de plus grande taille permet d'éviter de tels problèmes.</block>
  <block id="4afa3de974c36a09c2055d30989bb405" category="list-text">Le nombre de LUN est plus important que la taille de LUN.</block>
  <block id="691c70133d96d57796a9299359666f80" category="list-text">La taille de LUN est principalement contrôlée par les exigences liées au nombre de LUN.</block>
  <block id="8af9e525c143179b948a11fc382a331e" category="list-text">Évitez de créer plus de LUN que nécessaire.</block>
  <block id="407b2218ad77513a7e3964f169d07e66" category="paragraph">Contrairement à la taille de LUN, le nombre de LUN affecte les performances. La performance des applications dépend souvent de la capacité à réaliser des E/S parallèles via la couche SCSI. Ainsi, deux LUN offrent de meilleures performances qu'une seule LUN. L'utilisation d'un LVM tel que Veritas VxVM, Linux LVM2 ou Oracle ASM est la méthode la plus simple pour augmenter le parallélisme.</block>
  <block id="39143fe6204f383e4ce3bb3b77926455" category="paragraph">Les clients NetApp n'ont généralement pas eu l'avantage d'augmenter le nombre de LUN au-delà de seize. Toutefois, le test d'environnements 100 % SSD avec des E/S aléatoires très lourdes a permis d'améliorer encore jusqu'à 64 LUN.</block>
  <block id="9875f7503e59521e91e519abd87f5c9e" category="paragraph">*NetApp recommande* ce qui suit :</block>
  <block id="57153ab478a4958250d76ac6bf4e3ac0" category="paragraph">En général, de quatre à seize LUN suffisent pour prendre en charge les besoins en E/S d'une charge de travail de base de données donnée. Moins de quatre LUN peuvent créer des limites de performances en raison de limites dans les implémentations SCSI hôte.</block>
  <block id="de932976b195d4755fcbea64295fc7cb" category="doc">Paramètres du système d'exploitation hôte</block>
  <block id="f62cb371f65c322cd9e17a5c2cecd1c8" category="paragraph">La plupart des documents des fournisseurs d'applications incluent des paramètres TCP et ethernet spécifiques destinés à garantir le fonctionnement optimal de l'application. Ces mêmes paramètres suffisent généralement pour assurer des performances de stockage IP optimales.</block>
  <block id="ae7a0bb210cbd1edb935128116a21c55" category="section-title">Contrôle de flux Ethernet</block>
  <block id="a3c15fb208efc85bdfe72c57d56c92b8" category="paragraph">Cette technologie permet à un client de demander à un expéditeur d'arrêter temporairement la transmission de données. Cela est généralement fait parce que le récepteur est incapable de traiter les données entrantes assez rapidement. À un moment donné, demander à un expéditeur de cesser la transmission était moins perturbant que d'avoir un récepteur de paquets de rejet parce que les tampons étaient pleins. Ce n'est plus le cas avec les piles TCP utilisées dans les systèmes d'exploitation d'aujourd'hui. En fait, le contrôle de flux cause plus de problèmes qu'il ne résout.</block>
  <block id="950d31923e253d170d6c994801ce7cec" category="paragraph">Les problèmes de performances causés par le contrôle de flux Ethernet ont augmenté ces dernières années. En effet, le contrôle de flux Ethernet fonctionne au niveau de la couche physique. Si une configuration réseau permet à un système d'exploitation hôte d'envoyer une demande de contrôle de flux Ethernet à un système de stockage, il en résulte une pause des E/S pour tous les clients connectés. Étant donné qu'un nombre croissant de clients sont servis par un seul contrôleur de stockage, la probabilité qu'un ou plusieurs de ces clients envoient des demandes de contrôle de flux augmente. Le problème a été fréquemment rencontré sur les sites des clients qui possèdent une virtualisation étendue du système d'exploitation.</block>
  <block id="6bfd8563627c68f73c30581843441a74" category="paragraph">Une carte réseau sur un système NetApp ne doit pas recevoir de demandes de contrôle de flux. La méthode utilisée pour obtenir ce résultat varie en fonction du fabricant du commutateur réseau. Dans la plupart des cas, le contrôle de flux sur un commutateur Ethernet peut être réglé sur<block ref="a67b5ddb674c9ca32d9c9e1ca81578ee" prefix=" " category="inline-code"></block> ou<block ref="f4eb0bfa09695eb47ff4f3bd3ca4449d" prefix=" " category="inline-code"></block>, ce qui signifie qu'une demande de contrôle de flux n'est pas transmise au contrôleur de stockage. Dans d'autres cas, la connexion réseau sur le contrôleur de stockage risque de ne pas permettre la désactivation du contrôle de flux. Dans ce cas, les clients doivent être configurés pour ne jamais envoyer de demandes de contrôle de flux, soit en changeant la configuration NIC sur le serveur hôte lui-même, soit en changeant les ports de commutateur auxquels le serveur hôte est connecté.</block>
  <block id="7496f3ff64e30d4732c2c64880faf186" category="admonition">*NetApp recommande* de s'assurer que les contrôleurs de stockage NetApp ne reçoivent pas de paquets de contrôle de flux Ethernet. Pour ce faire, il est généralement possible de définir les ports de commutateur auxquels le contrôleur est connecté, mais certains matériels de commutateur ont des limites qui peuvent nécessiter des modifications côté client.</block>
  <block id="ae6d0fc57efaf02ad7dfdacd3575e315" category="section-title">Tailles du MTU</block>
  <block id="ff13ea04765cd9c9aed7b839f15eb2b4" category="paragraph">L'utilisation de trames Jumbo a été démontrée afin d'améliorer les performances des réseaux 1 Gbit en réduisant la surcharge du processeur et du réseau, mais l'avantage n'est généralement pas significatif.</block>
  <block id="ee3f364287a30ef10dfdce2f37d94ed2" category="admonition">*NetApp recommande* d'implémenter des trames Jumbo lorsque cela est possible, à la fois pour réaliser des avantages potentiels en termes de performances et pour pérenniser la solution.</block>
  <block id="2c6ba27b7ed602a9089da6ad9f762c9a" category="paragraph">L'utilisation de trames Jumbo dans un réseau de 10 Gb est presque obligatoire. En effet, la plupart des implémentations de 10 Gbits atteignent une limite de paquets par seconde sans trames Jumbo avant d'atteindre le seuil de 10 Gbits. L'utilisation de trames jumbo améliore l'efficacité du traitement TCP/IP car elle permet au système d'exploitation, au serveur, aux cartes réseau et au système de stockage de traiter moins de paquets, mais des paquets plus volumineux. L'amélioration des performances varie d'une carte réseau à l'autre, mais elle est significative.</block>
  <block id="a44be1bbfde97e4a64b50282325165e7" category="paragraph">Dans le cas des implémentations de trames Jumbo, il est courant, mais incorrect, que tous les périphériques connectés doivent prendre en charge les trames Jumbo et que la taille MTU doit correspondre de bout en bout Au lieu de cela, les deux extrémités du réseau négocient la taille de trame la plus élevée mutuellement acceptable lors de l'établissement d'une connexion. Dans un environnement standard, un commutateur réseau est défini sur une taille MTU de 9 9216, le contrôleur NetApp est défini sur 9000 et les clients sont configurés sur une combinaison de 9000 et 1514. Les clients qui prennent en charge un MTU de 9 9000 peuvent utiliser des trames jumbo, et les clients qui ne peuvent prendre en charge que 1514 peuvent négocier une valeur inférieure.</block>
  <block id="a31484167f31e1c3f36f7cea821bc581" category="paragraph">Les problèmes avec cet arrangement sont rares dans un environnement complètement commuté. Cependant, dans un environnement routé, veillez à ce qu'aucun routeur intermédiaire ne soit forcé de fragmenter des trames jumbo.</block>
  <block id="c805e9846e6fca449dbe3233cc5dbdf5" category="paragraph">*NetApp recommande* de configurer les éléments suivants :</block>
  <block id="b4446b5ca60d915111af271495bd4c17" category="list-text">Les trames Jumbo sont souhaitables, mais non requises avec Ethernet 1 Gb (GbE).</block>
  <block id="5b1ea13ac12a9c8be0d09303f637dba4" category="list-text">Les trames Jumbo sont requises pour des performances maximales avec 10GbE et plus rapides.</block>
  <block id="08a8dce78637f5dd14ed052163feb9da" category="section-title">Paramètres TCP</block>
  <block id="1a999618685598bee637262fe589de70" category="paragraph">Trois paramètres sont souvent mal configurés : les horodatages TCP, l'acquittement sélectif (SACK) et la mise à l'échelle de la fenêtre TCP. De nombreux documents obsolètes sur Internet recommandent de désactiver un ou plusieurs de ces paramètres pour améliorer les performances. Cette recommandation a été très utile il y a de nombreuses années, lorsque les capacités du processeur étaient beaucoup plus faibles et qu'il y avait un avantage à réduire la surcharge sur le traitement TCP chaque fois que cela était possible.</block>
  <block id="6a594ec6f0bb742c1d2b0f631cf65ba1" category="paragraph">Cependant, avec les systèmes d'exploitation modernes, la désactivation de l'une de ces fonctionnalités TCP n'entraîne généralement aucun avantage détectable, tout en pouvant nuire aux performances. Dans les environnements réseau virtualisés, les performances peuvent être endommagées, car ces fonctionnalités sont nécessaires pour gérer efficacement la perte de paquets et les modifications de la qualité du réseau.</block>
  <block id="cdc44d05b1633e8a8c7835010c423dd6" category="admonition">*NetApp recommande* d'activer les horodatages TCP, le SACK et la mise à l'échelle des fenêtres TCP sur l'hôte, et ces trois paramètres doivent être activés par défaut dans tout système d'exploitation actuel.</block>
  <block id="341d84aa26cb4521474864e04ea2a63b" category="inline-image-macro">Erreur : image graphique manquante</block>
  <block id="b56265ceb6311e42003e668438136a59" category="section-title">Réplication synchrone</block>
  <block id="0cf4a786acebd750bbfdfc4416c89406" category="section-title">Matériel de stockage</block>
  <block id="ea9f3de5dd21190fbc6bca180b2040f1" category="section-title">ONTAP Médiateur</block>
  <block id="0f54fb931dbdeea735f18a8e73f9eab5" category="doc">Protection des données avec SyncMirror</block>
  <block id="d7023f86951b6c3c009891a468c3effd" category="paragraph">Au niveau le plus simple, la réplication synchrone implique que toute modification doit être apportée des deux côtés du stockage en miroir avant d'être reconnue. Par exemple, si une base de données écrit un journal ou si un invité VMware est en cours de correction, une écriture ne doit jamais être perdue. Au niveau du protocole, le système de stockage ne doit pas accuser réception de l'écriture tant qu'il n'a pas été validé sur un support non volatile des deux sites. Ce n'est qu'à cette condition qu'il est possible de continuer sans risque de perte de données.</block>
  <block id="eee4f7a4e0ed3a8646a97bcf3e118fb9" category="paragraph">L'utilisation d'une technologie de réplication synchrone est la première étape de la conception et de la gestion d'une solution de réplication synchrone. Il est important de comprendre ce qui pourrait se passer lors de divers scénarios de défaillance planifiés ou non. Les solutions de réplication synchrone offrent toutes des fonctionnalités différentes. Si vous avez besoin d'une solution avec un objectif de point de récupération de zéro, c'est-à-dire sans perte de données, tous les scénarios de défaillance doivent être pris en compte. En particulier, quel est le résultat escompté lorsque la réplication est impossible en raison d'une perte de connectivité entre les sites ?</block>
  <block id="71554672a088c43ab21c759ddd161928" category="section-title">Disponibilité des données SyncMirror</block>
  <block id="8646bb558f8f18a200cce2f70602627a" category="paragraph">Non seulement SyncMirror peut basculer en mode synchrone sans interruption si le site distant est inaccessible, mais il peut également rapidement resynchroniser vers un état RPO = 0 une fois la connectivité restaurée. La copie obsolète des données sur le site distant peut également être conservée dans un état utilisable lors de la resynchronisation, garantissant la présence à tout moment de copies locales et distantes des données.</block>
  <block id="1d12d7a206d9b5337ae6fa442f23d377" category="doc">Copies Snapshot uniquement</block>
  <block id="64c29f2f2feedeb607ff588b13d9758b" category="paragraph">Le<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block><block ref="964193481f440d73ce3474a7a09bc3ac" prefix=" " category="inline-code"></block> s'applique uniquement aux blocs qui ne sont pas partagés avec le système de fichiers actif. Elle entraîne essentiellement une hiérarchisation des sauvegardes de bases de données. Les blocs deviennent candidats au Tiering après la création d'une copie Snapshot et l'écrasement du bloc, ce qui entraîne l'affichage d'un bloc uniquement dans la copie Snapshot. Le délai avant un<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> le bloc est considéré comme froid est contrôlé par le<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> réglage du volume. La plage à partir de ONTAP 9.8 est de 2 à 183 jours.</block>
  <block id="ebd9889c847a7a3ddeccd2717ead46f2" category="paragraph">De nombreux jeux de données ont des taux de modification faibles, ce qui permet de réduire au minimum les économies réalisées grâce à cette règle. Par exemple, un taux de modification hebdomadaire d'une base de données type observée sur ONTAP est inférieur à 5 %. Les journaux d'archivage de base de données peuvent occuper un espace important, mais ils continuent généralement d'exister dans le système de fichiers actif et ne sont donc pas candidats à la hiérarchisation dans le cadre de cette règle.</block>
  <block id="06b9281e396db002010bde1de57262eb" category="section-title">Auto</block>
  <block id="ecf602bd5abbd6a605debedbb6c3d4e0" category="paragraph">Le<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> la règle de tiering étend le tiering aux blocs spécifiques de snapshot et aux blocs dans le système de fichiers actif. Le délai avant qu'un bloc soit considéré comme froid est contrôlé par le<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> réglage du volume. La plage à partir de ONTAP 9.8 est de 2 à 183 jours.</block>
  <block id="6256ce48698ff0bde6f818679cdfb382" category="paragraph">Cette approche permet d'activer des options de hiérarchisation qui ne sont pas disponibles avec le<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> politique. Par exemple, une règle de protection des données peut nécessiter la conservation de 90 jours de certains fichiers journaux. Si vous définissez une période de refroidissement de 3 jours, tous les fichiers journaux de plus de 3 jours doivent être placés hors de la couche de performances. Cela libère un espace considérable sur le Tier de performance tout en vous permettant de consulter et de gérer l'ensemble des 90 jours de données.</block>
  <block id="6adf97f83acf6453d4a6a4b1070f3754" category="section-title">Aucune</block>
  <block id="7026ff5c5d4ab3946ff2d86f0e2cca6f" category="paragraph">Le<block ref="334c4a4c42fdb79d7ebc3e73b517e6f8" prefix=" " category="inline-code"></block> la règle de tiering empêche tout bloc supplémentaire d'être hiérarchisé de la couche de stockage, mais toutes les données qui se trouvent toujours dans le tier de capacité restent dans le tier de capacité jusqu'à ce qu'elles soient lues. Si le bloc est ensuite lu, il est retiré et placé sur le Tier de performance.</block>
  <block id="d152c7b0939fb6d35fdb0433de0d6369" category="paragraph">La principale raison d'utiliser le<block ref="334c4a4c42fdb79d7ebc3e73b517e6f8" prefix=" " category="inline-code"></block> la règle de tiering consiste à empêcher les blocs d'être hiérarchisés, mais elle peut s'avérer utile pour modifier les règles au fil du temps. Par exemple, imaginons qu'un dataset spécifique soit beaucoup hiérarchisé vers la couche de capacité, mais qu'un besoin inattendu de fonctionnalités de performance complètes se produit. La règle peut être modifiée pour éviter tout Tiering supplémentaire et confirmer que tous les blocs lus en cas d'augmentation des E/S restent dans le Tier de performance.</block>
  <block id="b1c94ca2fbc3e78fc30069c8d0f01680" category="section-title">Tout</block>
  <block id="84826d7e23dfac7549819d5115fdcedd" category="paragraph">Le<block ref="a181a603769c1f98ad927e7367c7aa51" prefix=" " category="inline-code"></block> la règle de tiering remplace la<block ref="402051f4be0cc3aad33bcf3ac3d6532b" prefix=" " category="inline-code"></block> Politique à partir de ONTAP 9.6. Le<block ref="402051f4be0cc3aad33bcf3ac3d6532b" prefix=" " category="inline-code"></block> Règle appliquée uniquement aux volumes de protection des données, c'est-à-dire une destination SnapMirror ou NetApp SnapVault. Le<block ref="a181a603769c1f98ad927e7367c7aa51" prefix=" " category="inline-code"></block> les règles fonctionnent de même, mais ne se limitent pas aux volumes de protection des données.</block>
  <block id="10d8500e282e8bbacd668af6f773f412" category="paragraph">Avec cette règle, les blocs sont immédiatement considérés comme « cool » et peuvent être immédiatement hiérarchisés jusqu'à la couche de capacité.</block>
  <block id="ec583de0216b95bc673c84e4ec9356e6" category="paragraph">Cette règle est particulièrement appropriée pour les sauvegardes à long terme. Il peut également être utilisé comme une forme de gestion hiérarchique du stockage (HSM). Auparavant, HSM était couramment utilisé pour classer les blocs de données d'un fichier sur bande tout en gardant le fichier lui-même visible sur le système de fichiers. Un volume FabricPool avec<block ref="a181a603769c1f98ad927e7367c7aa51" prefix=" " category="inline-code"></block> cette stratégie vous permet de stocker des fichiers dans un espace visible et gérable, tout en ne consommant quasiment aucun espace sur le niveau de stockage local.</block>
  <block id="79768a069a539d4f130e672a660bf45f" category="doc">Segmentation</block>
  <block id="a0bdb98e8b9da585816478d24278e42f" category="paragraph">Une zone FC ne doit jamais contenir plusieurs initiateurs. Un tel arrangement peut sembler fonctionner au départ, mais la diaphonie entre les initiateurs finit par interférer avec la performance et la stabilité.</block>
  <block id="8ef958d9e25538841b306960ab117626" category="paragraph">Les zones à cibles multiples sont généralement considérées comme sûres, bien que dans de rares circonstances le comportement des ports cibles FC de fournisseurs différents ait causé des problèmes. Par exemple, évitez d'inclure les ports cibles d'une baie de stockage NetApp et non NetApp dans la même zone. En outre, le fait de placer un système de stockage NetApp et un dispositif de bande dans la même zone est encore plus susceptible de causer des problèmes.</block>
  <block id="642223473862db290604321fe2ebe763" category="doc">SVM</block>
  <block id="47ea917cf14ad91c68c407f90a7a189d" category="paragraph">Un SVM, connu sous le nom de vserver sur l'interface de ligne de commandes ONTAP, est une unité fonctionnelle de base du stockage. Il est utile de comparer un SVM à un invité sur un serveur VMware ESX.</block>
  <block id="13ce2622b2cc2118c44d3aae7df8167d" category="paragraph">À l'instar des autres aspects de l'architecture de stockage, les meilleures options pour la conception des SVM et de l'interface logique (LIF) dépendent largement des exigences d'évolutivité et des besoins de l'entreprise.</block>
  <block id="8fb41a27984f0beba2e12fb920a486aa" category="paragraph">Il n'existe aucune bonne pratique officielle de provisionnement des SVM pour ONTAP. La bonne approche dépend des exigences en matière de gestion et de sécurité.</block>
  <block id="f4d8541bb6d07f7533a6b5aa6cfb2455" category="paragraph">La plupart des clients utilisent un SVM principal pour la plupart de leurs besoins quotidiens, mais ils en créent un petit pour des besoins particuliers. Par exemple, vous pouvez créer :</block>
  <block id="259908e9e431c0fbb9d425249ceb7930" category="list-text">SVM d'une base de données stratégique gérée par une équipe de spécialistes</block>
  <block id="0e10f2715884f3538282397d69b2cd00" category="list-text">SVM pour un groupe de développement auquel un contrôle administratif complet a été attribué afin de pouvoir gérer leur propre stockage indépendamment</block>
  <block id="7624156e307247e4ea1ec8bf574136a1" category="list-text">SVM pour les données sensibles de l'entreprise, telles que les données de rapports financiers ou de ressources humaines, pour lesquelles l'équipe administrative doit être limitée</block>
  <block id="e5e09031843479ef9ef8cbbd4c2f404c" category="inline-link-macro">NetApp Hardware Universe</block>
  <block id="fb012f1e7970d8285bd5d6c5a7f7d523" category="doc">Des agrégats SSD, y compris les systèmes AFF</block>
  <block id="cb8e4651c457f71d5788f38eac01471f" category="paragraph">L'espace libre est défini comme tout espace qui n'est pas utilisé pour les données réelles et inclut l'espace non alloué sur l'agrégat lui-même et l'espace inutilisé au sein des volumes constitutifs. Le provisionnement fin doit également être envisagé. Par exemple, un volume peut contenir une LUN de 1 To, dont seulement 50 % sont utilisés par des données réelles. Dans un environnement à provisionnement fin, cet espace semble être consommé de 500 Go. Toutefois, dans un environnement entièrement provisionné, la capacité totale de 1 To semble être utilisée. Les 500 Go d'espace non alloué sont masqués. Cet espace n'est pas utilisé par les données réelles et doit donc être inclus dans le calcul de l'espace libre total.</block>
  <block id="d3487661d9a0702bd5915d49070f62dc" category="paragraph">Les recommandations de NetApp pour les systèmes de stockage utilisés pour les applications d'entreprise sont les suivantes :</block>
  <block id="678e476783bceae80094bcb4c1f32969" category="admonition">*NetApp recommande* un minimum de 10% d'espace libre. Cela inclut tout l'espace inutilisé, y compris l'espace libre au sein de l'agrégat ou d'un volume, ainsi que tout espace libre alloué en raison de l'utilisation du provisionnement complet, mais qui n'est pas utilisé par les données réelles. L'espace logique n'est pas important, la question est de savoir quelle quantité d'espace physique réellement disponible pour le stockage des données.</block>
  <block id="2171d172d184f1202a686849c85dce91" category="paragraph">La recommandation de 10 % d'espace libre est très prudente. Les agrégats SSD peuvent prendre en charge des charges de travail à des niveaux d'utilisation encore plus élevés, sans affecter les performances. Cependant, à mesure que l'utilisation de l'agrégat augmente, le risque de manquer d'espace augmente également si l'utilisation n'est pas surveillée de près. De plus, même si vous utilisez un système à 99 % de capacité, les performances risquent d'être moins élevées, mais vous devrez probablement interrompre la gestion pour l'empêcher de se remplir complètement lors de la commande de matériel supplémentaire. L'acquisition et l'installation de disques supplémentaires peuvent prendre un certain temps.</block>
  <block id="789243e17acb0b134f435d6c4c1350f2" category="section-title">Les agrégats HDD, y compris les agrégats Flash Pool</block>
  <block id="0b0a68e2dedde9c0b9a3ea4276f4b85c" category="paragraph">Le<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> la règle est la règle la plus appropriée pour les données de sauvegarde. Cela garantit une hiérarchisation rapide lorsque le seuil de refroidissement a été atteint, que les fichiers aient été supprimés ou qu'ils continuent d'exister dans le système de fichiers principal. Le stockage de tous les fichiers potentiellement requis dans un emplacement unique du système de fichiers actif simplifie également la gestion. Il n'y a aucune raison de rechercher un fichier à restaurer à l'aide de snapshots.</block>
  <block id="11a75a1257cc68a4a46bc553dabe0c0d" category="paragraph">Le<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> la stratégie peut être mise en œuvre, mais elle s'applique uniquement aux blocs qui ne sont plus dans le système de fichiers actif. Par conséquent, les fichiers d'un partage NFS ou SMB doivent d'abord être supprimés avant de pouvoir placer les données dans un Tier.</block>
  <block id="b4af96e8cea99b56592db816cab30fce" category="paragraph">Cette règle serait encore moins efficace avec une configuration de LUN, car la suppression d'un fichier d'une LUN supprime uniquement les références de fichier des métadonnées du système de fichiers. Les blocs réels des LUN restent en place jusqu'à ce qu'ils soient remplacés. Cette situation peut entraîner un délai long entre la suppression d'un fichier et l'écrasement des blocs et leur candidature à la hiérarchisation. Il est avantageux de déplacer le<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> Bloque le niveau de capacité, mais, dans l'ensemble, la gestion FabricPool des données de sauvegarde fonctionne mieux avec le<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> politique.</block>
  <block id="1c237d1ebcdeff13ae0145c741d9401d" category="admonition">Cette approche permet aux utilisateurs de gérer plus efficacement l'espace requis pour les sauvegardes, mais FabricPool lui-même n'est pas une technologie de sauvegarde. Le Tiering des fichiers de sauvegarde vers un magasin d'objets simplifie la gestion, car les fichiers restent visibles sur le système de stockage d'origine. Cependant, les blocs de données de destination du magasin d'objets dépendent du système de stockage d'origine. En cas de perte du volume source, les données du magasin d'objets ne sont plus utilisables.</block>
  <block id="a19665c8f7c0210f96ad2934ad0ee361" category="paragraph">Sur un système ONTAP, le stockage est organisé en unités de 4 Ko. Un bloc de 8 Ko de base de données ou de système de fichiers doit être mappé à exactement deux blocs de 4 Ko. Si une erreur de configuration de LUN déplace l'alignement de 1 Ko dans les deux sens, chaque bloc de 8 Ko existerait sur trois blocs de stockage de 4 Ko différents au lieu de deux. Cette configuration entraîne une augmentation de la latence et des E/S supplémentaires au sein du système de stockage.</block>
  <block id="211a9fe299057fe8665b591dddbac56d" category="paragraph">L'alignement affecte également les architectures LVM. Si un volume physique au sein d'un groupe de volumes logiques est défini sur l'unité entière (aucune partition n'est créée), le premier bloc de 4 Ko de la LUN s'aligne sur le premier bloc de 4 Ko du système de stockage. Il s'agit d'un alignement correct. Des problèmes surviennent avec les partitions car elles déplacent l'emplacement de départ où le système d'exploitation utilise le LUN. Tant que le décalage est décalé en unités entières de 4 Ko, la LUN est alignée.</block>
  <block id="e98a692d783d8d778aab49ed4c55e214" category="doc">Protection contre les défaillances de site : NVRAM et MetroCluster</block>
  <block id="186577daf29184ed8a55cf899ba2979c" category="paragraph">MetroCluster étend la protection des données NVRAM de plusieurs manières :</block>
  <block id="679f5a5873d7d3378cf4b3035fd5cb13" category="list-text">Dans une configuration à deux nœuds, les données NVRAM sont répliquées au partenaire distant à l'aide des liens ISL (Inter-Switch Links).</block>
  <block id="00bec98f52b9151dd2e0c760becd4ca8" category="list-text">Dans une configuration de paire haute disponibilité, les données NVRAM sont répliquées à la fois vers le partenaire local et vers un partenaire distant.</block>
  <block id="94deccfbf8f798c1661000b27a568b18" category="list-text">Une écriture n'est pas validée tant qu'elle n'est pas répliquée à tous les partenaires. Cette architecture protège les E/S à la volée contre les défaillances de site en répliquant les données NVRAM sur un partenaire distant. Ce processus n'est pas impliqué dans la réplication des données au niveau des disques. Le contrôleur propriétaire des agrégats est responsable de la réplication des données en écrivant dans les deux plexes de l'agrégat. Cependant, il doit toujours assurer une protection contre les pertes d'E/S à la volée en cas de perte du site. Les données NVRAM répliquées sont uniquement utilisées si un contrôleur partenaire doit prendre le relais en cas de défaillance d'un contrôleur.</block>
  <block id="996aa1ed8a906e55c7f157a1643021b7" category="section-title">Protection contre les pannes de site et de tiroir : SyncMirror et plexes</block>
  <block id="1c114a932963683e04dc7dece97c15c9" category="paragraph">SyncMirror est une technologie de mise en miroir qui améliore, mais ne remplace pas, RAID DP ou RAID-TEC. Il met en miroir le contenu de deux groupes RAID indépendants. La configuration logique est la suivante :</block>
  <block id="b4b4f1d65cb5f1370402220b00584e79" category="list-text">Les disques sont configurés en deux pools en fonction de leur emplacement. Un pool est composé de tous les disques du site A et le second est composé de tous les disques du site B.</block>
  <block id="418f0763b76bff8e324f1afdd5456b49" category="list-text">Un pool de stockage commun, appelé agrégat, est ensuite créé à partir de jeux en miroir de groupes RAID. Un nombre égal de lecteurs est tiré de chaque site. Par exemple, un agrégat SyncMirror de 20 disques se compose de 10 disques du site A et de 10 disques du site B.</block>
  <block id="51bf74357f742acfa0a7cd11ce52ed7f" category="list-text">Chaque jeu de disques d'un site donné est automatiquement configuré comme un ou plusieurs groupes RAID DP ou RAID-TEC entièrement redondants, indépendamment de l'utilisation de la mise en miroir. Cette utilisation de la mise en miroir RAID assure la protection des données même après la perte d'un site.</block>
  <block id="8a35ad1e53533c7a3a8ff427bda0deb2" category="paragraph"><block ref="8a35ad1e53533c7a3a8ff427bda0deb2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="abf64dbc3ac20af1b4a30150a016ca58" category="paragraph">La figure ci-dessus illustre un exemple de configuration SyncMirror. Un agrégat de 24 disques a été créé sur le contrôleur avec 12 disques à partir d'un tiroir alloué sur le site A et 12 disques à partir d'un tiroir alloué sur le site B. Les disques ont été regroupés en deux groupes RAID en miroir. Le groupe RAID 0 comprend un plex de 6 disques sur le site A mis en miroir sur un plex de 6 disques sur le site B. De même, le groupe RAID 1 comprend un plex de 6 disques sur le site A mis en miroir sur un plex de 6 disques sur le site B.</block>
  <block id="d9945e1dbadc87ba8e52a5e69376005c" category="paragraph">SyncMirror est généralement utilisé pour assurer la mise en miroir à distance avec les systèmes MetroCluster, avec une copie des données sur chaque site. Il a parfois été utilisé pour fournir un niveau supplémentaire de redondance dans un seul système. Il assure en particulier la redondance au niveau du tiroir. Un tiroir disque contient déjà deux blocs d'alimentation et contrôleurs. Dans l'ensemble, il ne s'agit pas d'une simple tôlerie, mais dans certains cas, une protection supplémentaire peut être garantie. Par exemple, un client NetApp a déployé SyncMirror sur une plateforme mobile d'analytique en temps réel utilisée lors des tests automobiles. Le système a été séparé en deux racks physiques fournis avec des alimentations indépendantes et des systèmes UPS indépendants.</block>
  <block id="f3495a1e6cf563a617c71164f3b11ca3" category="section-title">Échec de la redondance : NVFAIL</block>
  <block id="c7474a3ed1a224804e4741a256bdd953" category="paragraph">Comme nous l'avons vu précédemment, une écriture n'est pas validée tant qu'elle n'a pas été connectée à la NVRAM et à la NVRAM locales sur au moins un autre contrôleur. Cette approche évite toute panne matérielle ou de courant qui entraîne une perte des E/S à la volée En cas de panne de la mémoire NVRAM locale ou de la connectivité aux autres nœuds, les données ne seront plus mises en miroir.</block>
  <block id="4774101e81ea03c43fe20e0d7f2d21d1" category="paragraph">Le facteur de contrôle est de savoir si la NVRAM est synchronisée. Si la mémoire NVRAM est synchronisée, le basculement nœud à nœud peut se poursuivre sans risque de perte de données. Dans une configuration MetroCluster, si la mémoire NVRAM et les plexes d'agrégats sous-jacents sont synchronisés, vous pouvez procéder au basculement sans risque de perte de données.</block>
  <block id="03e97c023521445cd70307afabdcf0d5" category="paragraph">Les bases de données et autres applications sont particulièrement vulnérables à la corruption en cas de basculement ou de basculement forcé, car elles conservent des caches internes de données plus volumineux sur disque. En cas de basculement forcé ou de basculement forcé, les modifications précédemment reconnues sont effectivement supprimées. Le contenu de la baie de stockage recule dans le temps et l'état du cache ne reflète plus l'état des données sur le disque.</block>
  <block id="ff7a32ed70b7df57dd29a3ed75e8c787" category="paragraph">Afin d'éviter ce genre de situation, ONTAP permet de configurer les volumes pour une protection spéciale contre les défaillances de mémoire NVRAM. Lorsqu'il est déclenché, ce mécanisme de protection entraîne l'entrée d'un volume dans un état appelé NVFAIL. Cet état entraîne des erreurs d'E/S qui provoquent une panne de l'application. Cette panne provoque l'arrêt des applications, qui n'utilisent donc pas de données obsolètes. Les données ne doivent pas être perdues car des données de transaction validées doivent être présentes dans les journaux. Les étapes suivantes habituelles sont qu'un administrateur arrête complètement les hôtes avant de remettre manuellement en ligne les LUN et les volumes. Bien que ces étapes puissent impliquer un certain travail, cette approche est le moyen le plus sûr d'assurer l'intégrité des données. Toutes les données n'ont pas besoin de cette protection. C'est pourquoi NVFAIL peut être configuré volume par volume.</block>
  <block id="637d4b37868fb7825461df6edd674158" category="section-title">Paires HAUTE DISPONIBILITÉ et MetroCluster</block>
  <block id="9d8738f531e6c6a809ba66315beaa2f4" category="paragraph">MetroCluster est disponible dans deux configurations : deux nœuds et paire haute disponibilité. La configuration à deux nœuds se comporte de la même manière qu'une paire haute disponibilité par rapport à la mémoire NVRAM. En cas de défaillance soudaine, le nœud partenaire peut relire les données NVRAM pour assurer la cohérence des disques et garantir la perte d'aucune écriture reconnue.</block>
  <block id="936f4311b16ee4dc74a5564892f8976d" category="paragraph">La configuration HA-pair réplique également la mémoire NVRAM sur le nœud partenaire local. Une simple défaillance de contrôleur entraîne une relecture NVRAM sur le nœud partenaire, comme c'est le cas avec une paire haute disponibilité autonome sans MetroCluster. En cas de perte complète soudaine d'un site, le site distant dispose également de la mémoire NVRAM requise pour assurer la cohérence des disques et commencer à transmettre les données.</block>
  <block id="83b6c3c3018b913ecf1aca67e0daa35e" category="paragraph">Un aspect important de MetroCluster est que les nœuds distants ne peuvent pas accéder aux données des partenaires dans des conditions de fonctionnement normales. Chaque site fonctionne essentiellement comme un système indépendant qui peut assumer la personnalité du site opposé. Ce processus est connu sous le nom de basculement et inclut un basculement planifié dans lequel les opérations sur site sont migrées sans interruption vers le site opposé. Il comprend également les situations non planifiées où un site est perdu et un basculement manuel ou automatique est nécessaire dans le cadre de la reprise d'activité.</block>
  <block id="58504b36cfdfd10d5f2802d7b943a379" category="section-title">Basculement et rétablissement</block>
  <block id="d505751d1708fb5d57b0e23d089507a9" category="paragraph">Les termes « switchover and switchoback » font référence au processus de transition des volumes entre des contrôleurs distants dans une configuration MetroCluster. Ce processus s'applique uniquement aux nœuds distants. Lorsque MetroCluster est utilisé dans une configuration à quatre volumes, le basculement de nœud local est le même processus de basculement et de rétablissement que celui décrit précédemment.</block>
  <block id="1127608e73df5ede22b149c8f19fc860" category="section-title">Basculement et rétablissement planifiés</block>
  <block id="a6733335678588619c977608e891e54e" category="paragraph">Un basculement ou rétablissement planifié est similaire à un basculement ou un rétablissement entre les nœuds. Ce processus comporte plusieurs étapes et peut sembler prendre plusieurs minutes, mais il s'agit d'une transition progressive et progressive des ressources de stockage et de réseau. Le moment où les transferts de contrôle se produisent beaucoup plus rapidement que le temps nécessaire à l'exécution de la commande complète.</block>
  <block id="4bb5647dcff332f0b53819ecd631303c" category="paragraph">La principale différence entre le basculement/rétablissement et le basculement/rétablissement réside dans l'effet sur la connectivité FC SAN. Avec le Takeover/Giveback local, un hôte subit la perte de tous les chemins FC vers le nœud local et s'appuie sur son MPIO natif pour le basculer vers des chemins alternatifs disponibles. Les ports ne sont pas déplacés. Avec le basculement et le rétablissement, les ports cibles FC virtuels des contrôleurs passent à l'autre site. Ils cessent d'exister sur le SAN pendant un instant, puis réapparaissent sur un autre contrôleur.</block>
  <block id="0ba902ec3f6ce91c2e801715bb8b96fa" category="section-title">SyncMirror expire</block>
  <block id="9c8a1814b60b84d1aa68fa7bba69138b" category="paragraph">SyncMirror est une technologie de mise en miroir ONTAP qui offre une protection contre les défaillances de tiroirs. Lorsque les tiroirs sont séparés sur une distance, les données sont protégées à distance.</block>
  <block id="68cf36f65a7e56ff3b6c0894be3ed9e8" category="paragraph">SyncMirror ne fournit pas de mise en miroir synchrone universelle. Le résultat est une meilleure disponibilité. Certains systèmes de stockage utilisent une mise en miroir totale ou nulle constante, parfois appelée mode domino. Cette forme de mise en miroir est limitée dans l'application car toutes les activités d'écriture doivent cesser en cas de perte de la connexion au site distant. Sinon, une écriture existerait sur un site, mais pas sur l'autre. Généralement, ces environnements sont configurés pour mettre les LUN hors ligne en cas de perte de la connectivité site à site pendant plus d'une courte période (par exemple, 30 secondes).</block>
  <block id="84ad4c21def9c355e80ef250d910bfa2" category="paragraph">Ce comportement est souhaitable pour un petit sous-ensemble d'environnements. Cependant, la plupart des applications nécessitent une solution capable de garantir une réplication synchrone dans des conditions normales de fonctionnement, mais avec la possibilité de suspendre la réplication. Une perte complète de la connectivité site à site est souvent considérée comme une situation proche d'une catastrophe. Généralement, ces environnements sont maintenus en ligne et donnent accès aux données jusqu'à ce que la connectivité soit réparée ou qu'une décision officielle soit prise de fermer l'environnement pour protéger les données. Il n'est pas rare d'avoir besoin d'arrêter automatiquement l'application uniquement en raison d'une défaillance de réplication à distance.</block>
  <block id="e3bd381a7bbaee6c741aee230972acf4" category="paragraph">SyncMirror prend en charge les exigences de mise en miroir synchrone avec la flexibilité d'un délai d'expiration. Si la connectivité à la télécommande et/ou au plex est perdue, une minuterie de 30 secondes commence à s'arrêter. Lorsque le compteur atteint 0, le traitement des E/S d'écriture reprend en utilisant les données locales. La copie distante des données est utilisable, mais elle est figée à temps jusqu'à ce que la connectivité soit rétablie. La resynchronisation exploite des snapshots au niveau de l'agrégat pour rétablir le système en mode synchrone aussi rapidement que possible.</block>
  <block id="0c919cd6511df6d83b811234b0448374" category="paragraph">Notamment, dans de nombreux cas, ce type de réplication universelle en mode domino tout ou rien est mieux implémenté au niveau de la couche applicative. Par exemple, Oracle DataGuard inclut le mode de protection maximum, ce qui garantit la réplication à long terme en toutes circonstances. Si la liaison de réplication échoue pendant une période dépassant un délai configurable, les bases de données s'arrêtent.</block>
  <block id="ba92cbe464cfee8aa12c41e6aecd1071" category="section-title">Basculement automatique sans surveillance avec Fabric Attached MetroCluster</block>
  <block id="515094655d10031595da776c94b3d710" category="paragraph">Le basculement automatique sans surveillance (AUSO) est une fonctionnalité MetroCluster intégrée au fabric qui offre une forme de haute disponibilité intersite. Comme évoqué précédemment, MetroCluster est disponible en deux types : un contrôleur unique sur chaque site ou une paire haute disponibilité sur chaque site. L'avantage principal de l'option haute disponibilité est que l'arrêt planifié ou non planifié du contrôleur permet toujours une E/S locale. L'avantage de l'option à nœud unique est de réduire les coûts, la complexité et l'infrastructure.</block>
  <block id="29d4da26af76b66db3a172a39edf8367" category="paragraph">La principale valeur d'AUSO est d'améliorer les fonctionnalités haute disponibilité des systèmes MetroCluster connectés à la structure. Chaque site surveille l'état de santé du site opposé et, si aucun nœud n'est encore utilisé pour transmettre des données, l'AUSO assure un basculement rapide. Cette approche est particulièrement utile dans les configurations MetroCluster avec un seul nœud par site, car elle rapproche la configuration d'une paire haute disponibilité en termes de disponibilité.</block>
  <block id="6b3a5f7923b2d803fd3b28c255fef420" category="paragraph">AUSO ne peut pas offrir de surveillance complète au niveau d'une paire HA. Une paire haute disponibilité peut offrir une haute disponibilité, car elle inclut deux câbles physiques redondants pour une communication nœud à nœud directe. En outre, les deux nœuds d'une paire haute disponibilité ont accès au même ensemble de disques sur des boucles redondantes, ce qui permet à un nœud de suivre l'état d'un autre nœud sur une autre route.</block>
  <block id="da87dad268507a3523bc38275b1d3fbc" category="paragraph">Il existe des clusters MetroCluster sur plusieurs sites pour lesquels la communication nœud à nœud et l'accès au disque reposent sur la connectivité réseau site à site. La capacité à surveiller le pouls du reste du cluster est limitée. AUSO doit faire la distinction entre une situation où l'autre site est en fait hors service plutôt qu'indisponible en raison d'un problème de réseau.</block>
  <block id="e8e4f55c4203e7fb24d4543a7a0f65da" category="paragraph">Par conséquent, un contrôleur d'une paire haute disponibilité peut demander un basculement s'il détecte une panne de contrôleur qui s'est produite pour une raison spécifique, par exemple une situation critique du système. Elle peut également déclencher un basculement en cas de perte complète de la connectivité, parfois appelée « perte de pulsation ».</block>
  <block id="91aa4ce36cb243281f3777d66c8f89e0" category="paragraph">Un système MetroCluster ne peut effectuer un basculement automatique en toute sécurité que lorsqu'une panne spécifique est détectée sur le site d'origine. En outre, le contrôleur qui devient propriétaire du système de stockage doit être en mesure de garantir la synchronisation des données du disque et de la NVRAM. Le contrôleur ne peut pas garantir la sécurité d'un basculement simplement parce qu'il a perdu le contact avec le site source, qui pourrait toujours être opérationnel. Pour plus d'informations sur les options d'automatisation d'un basculement, reportez-vous aux informations sur la solution MetroCluster Tiebreaker (MCTB) dans la section suivante.</block>
  <block id="8e7705fe4aea384d7f6a99ab6dc0f408" category="section-title">Disjoncteur d'attache MetroCluster avec MetroCluster FAS</block>
  <block id="897b7698cb343dbc3452e845705ab0f3" category="inline-link">NetApp MetroCluster Tiebreaker</block>
  <block id="9c093f14319e8253b8c9b37290597239" category="inline-link">Site de support NetApp</block>
  <block id="6f29b1849750ceee5eb7f6f02d100e6b" category="paragraph">Le basculement automatique avec AUSO est également compatible avec le MCTB. AUSO réagit très rapidement car il est conçu pour détecter des événements de défaillance spécifiques, puis n'invoque le basculement que lorsque les plexes NVRAM et SyncMirror sont synchronisés.</block>
  <block id="6f5c7ae76595eca2ca83c5dd30cd8e9f" category="paragraph">En revanche, le disjoncteur principal est situé à distance et doit donc attendre qu'une minuterie s'écoule avant de déclarer un site mort. Le disjoncteur d'attache détecte finalement le type de défaillance de contrôleur couverte par l'AUSO, mais en général, l'AUSO a déjà commencé le basculement et éventuellement terminé le basculement avant que le disjoncteur d'attache n'agisse. La deuxième commande de basculement qui en résulte provient du Tiebreaker serait rejetée.</block>
  <block id="7110edd59c3d0f25a584723f6fea26a0" category="paragraph">En outre, le MCTB peut ne pas traiter un désastre roulant qui conduit à la séquence d'événements suivante :</block>
  <block id="93d732b784eaf1a323f191e75c10f233" category="list-text">La connectivité entre les sites est interrompue pendant plus de 30 secondes.</block>
  <block id="81d4275cc3534a9fa8cfdcdb5172eb94" category="list-text">La réplication SyncMirror est obsolète et les opérations se poursuivent sur le site principal, ce qui ne permet pas au réplica distant d'être obsolète.</block>
  <block id="44441f68631008a941ce92e985131ff9" category="list-text">Le site primaire est perdu. Le résultat est la présence de modifications non répliquées sur le site primaire. Un basculement peut alors se révéler indésirable pour plusieurs raisons, notamment :</block>
  <block id="499527dd40fad77b119b8b33c99cd614" category="list-text">Certaines données critiques peuvent être présentes sur le site primaire et peuvent être récupérées à terme. Un basculement qui a permis à l'application de continuer à fonctionner aurait pour effet de supprimer ces données stratégiques.</block>
  <block id="86de4e3737e3d871dacf8ffef353fc31" category="list-text">Des données peuvent être mises en cache pour une application sur le site survivant qui utilisait des ressources de stockage sur le site principal au moment de la perte du site. Le basculement introduit une version obsolète des données qui ne correspond pas au cache.</block>
  <block id="dbb2a01afe28c8310daf781bb80b795f" category="list-text">Des données peuvent être mises en cache sur un système d'exploitation du site survivant qui utilisait des ressources de stockage sur le site principal au moment de la perte du site. Le basculement introduit une version obsolète des données qui ne correspond pas au cache. L'option la plus sûre est de configurer le Tiebreaker pour envoyer une alerte s'il détecte une défaillance du site et demander à une personne de décider si elle doit forcer un basculement. Il peut être nécessaire d'abord d'arrêter les applications et/ou les systèmes d'exploitation pour effacer les données en cache. En outre, les paramètres NVFAIL peuvent être utilisés pour renforcer la protection et rationaliser le processus de basculement.</block>
  <block id="ec6b0ea9c511479c118aa0f028f6519d" category="section-title">Mediator ONTAP avec MetroCluster IP</block>
  <block id="991d7d7d7388ccdd87c65ca09aa804f2" category="paragraph">Un MetroCluster FAS dispose d'un accès direct aux dispositifs de stockage sur le site opposé. Cela permet à un contrôleur MetroCluster de surveiller l'intégrité des autres contrôleurs en lisant les données de pulsation à partir des disques. Cela permet à un contrôleur de reconnaître la défaillance d'un autre contrôleur et d'effectuer un basculement.</block>
  <block id="db2e932a11478bcf14c75d38e8b9a170" category="paragraph">En revanche, l'architecture IP MetroCluster achemine toutes les E/S exclusivement via la connexion contrôleur-contrôleur ; il n'y a pas d'accès direct aux dispositifs de stockage sur le site distant. Cela limite la capacité d'un contrôleur à détecter les défaillances et à effectuer un basculement. Le Mediator ONTAP est donc requis comme dispositif Tiebreaker pour détecter la perte du site et effectuer automatiquement un basculement.</block>
  <block id="8004e6d63f487a456290225b74768a6c" category="section-title">Troisième site virtuel avec ClusterLion</block>
  <block id="f1d5a7305654a402a719675fbec810e7" category="paragraph">ClusterLion est un dispositif de surveillance MetroCluster avancé qui fonctionne comme un troisième site virtuel. Cette approche permet de déployer MetroCluster en toute sécurité dans une configuration à deux sites avec une fonctionnalité de basculement entièrement automatisée. De plus, ClusterLion peut effectuer un moniteur de niveau réseau supplémentaire et exécuter des opérations de post-basculement. La documentation complète est disponible auprès de ProLion.</block>
  <block id="f8aae92ec17ec82868ef9ffc767dbd03" category="list-text">Les appliances ClusterLion contrôlent l'état des contrôleurs à l'aide de câbles série et Ethernet directement connectés.</block>
  <block id="c5f8963a91e3d8e7ac0abda2eab9f17d" category="list-text">Les deux appareils sont connectés l'un à l'autre à l'aide de connexions 3G sans fil redondantes.</block>
  <block id="24de16a13a1b584832d19117982cbfa6" category="list-text">L'alimentation vers le contrôleur ONTAP est acheminée via des relais internes. En cas de panne de site, ClusterLion, qui contient un système UPS interne, coupe les connexions d'alimentation avant d'appeler un basculement. Ce processus permet de s'assurer qu'aucune condition de split-brain ne se produit.</block>
  <block id="b2bcd3c3c555e2e4f27d453de4e0f06d" category="list-text">ClusterLion effectue un basculement dans le délai d'attente SyncMirror de 30 secondes ou pas du tout.</block>
  <block id="390fb5f827a3fbcdc7d05e6e7db03223" category="list-text">ClusterLion n'effectue pas de basculement à moins que les États des plexes NVRAM et SyncMirror ne soient synchronisés.</block>
  <block id="f322f850d55e87946f9660e4ccb1bbb6" category="list-text">Étant donné que ClusterLion effectue un basculement uniquement si MetroCluster est entièrement synchronisé, NVFAIL n'est pas nécessaire. Cette configuration permet aux environnements couvrant l'ensemble des sites, tels qu'un RAC Oracle étendu, de rester en ligne, même pendant un basculement non planifié.</block>
  <block id="5c132e05fb0e306f56955603619de359" category="list-text">Il inclut les protocoles Fabric-Attached MetroCluster et MetroCluster IP</block>
  <block id="86bcf99dbc3944da56f06b48074d09f6" category="doc">Fonctionnement normal</block>
  <block id="e48472f7daf781b63506f9e296443027" category="paragraph">En fonctionnement normal, une LUN est accessible à partir du réplica local ou distant. La ligne rouge indique le chemin optimisé annoncé par ALUA, qui doit s'assurer que les E/S sont préférablement envoyées sur ce chemin.</block>
  <block id="e139a585510a502bbf1841cf589f5086" category="section-title">Panne</block>
  <block id="7ed516552b652790c92df0bf237264b2" category="paragraph">Si la copie miroir active devient indisponible, en raison d'un basculement planifié ou non planifié, elle ne sera évidemment plus utilisable. Cependant, le système distant possède une réplique synchrone et des chemins SAN vers le site distant existent déjà. Le système distant peut traiter les E/S pour cette LUN.</block>
  <block id="7388404ef116c3ff812bfd290b094d9e" category="section-title">Basculement</block>
  <block id="997dfe060d2107e84407cfb41e692c54" category="paragraph">Le basculement entraîne la copie distante en tant que copie active. Les chemins passent de actif à actif/optimisé et les E/S continuent d'être traitées sans perte de données.</block>
  <block id="0493d27e20d11e356e53e0a730b0ad08" category="section-title">Réparation</block>
  <block id="6d80a3efb80520f47b63dc279e1bea3d" category="section-title">Du rétablissement</block>
  <block id="d47f47372b9b94d274cceb3638b28845" category="paragraph">Si vous le souhaitez, un administrateur peut effectuer un retour arrière et déplacer la copie active de la ou des LUN vers les contrôleurs d'origine.</block>
  <block id="0c99cedb6f39d8ac16d5b4c01c162c23" category="paragraph">La journalisation des opérations de reprise et des transactions de la base de données génère normalement des E/S non alignées qui peuvent entraîner des avertissements erronés concernant les LUN mal alignées sur ONTAP.</block>
  <block id="b2f7bb8e75b21ee3e883141c6ac1defe" category="paragraph">La journalisation effectue une écriture séquentielle du fichier journal avec des écritures de taille variable. Une opération d'écriture de journal qui ne s'aligne pas sur les limites de 4 Ko ne provoque généralement pas de problèmes de performances, car l'opération d'écriture de journal suivante termine le bloc. ONTAP est ainsi en mesure de traiter la quasi-totalité des écritures sous forme de blocs complets de 4 Ko, même si les données de blocs de 4 Ko ont été écrites dans deux opérations distinctes.</block>
  <block id="0e635e1f8ffad809203304cf41ed45c4" category="inline-link-macro">Vérification de l'alignement WAFL</block>
  <block id="bf837d24f10c904e697e3c0092da43b9" category="paragraph">Vérifiez l'alignement à l'aide d'utilitaires tels que<block ref="40883add63f1fbabc7fe6158f93c1246" prefix=" " category="inline-code"></block> ou<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block> Qui peuvent générer des E/S à une taille de bloc définie. Les statistiques d'alignement des E/S sur le système de stockage peuvent être affichées à l'aide du<block ref="446501053769c06c565094b26d26e8ef" prefix=" " category="inline-code"></block> commande. Voir <block ref="ebccec7997af507c87f985ec4ccec634" category="inline-link-macro-rx"></block> pour en savoir plus.</block>
  <block id="b5ffbfb0c082804ad41d0f61c87525ed" category="paragraph">De nombreux jeux de données d'applications sont organisés par date, et ces données sont généralement moins susceptibles d'être accessibles au fur et à mesure du vieillissement. Par exemple, une banque peut disposer d'un référentiel de fichiers PDF contenant cinq années de relevés clients, mais seuls les derniers mois sont actifs. FabricPool peut être utilisé pour déplacer d'anciens fichiers de données vers le Tier de capacité. Une période de refroidissement de 14 jours permettrait de conserver les fichiers PDF de 14 jours les plus récents sur le niveau de performance. En outre, les fichiers lus au moins tous les 14 jours resteraient fortement sollicités et resteraient donc sur le Tier de performance.</block>
  <block id="ed7e2cc7ff107d4b2032fe65cf4e756a" category="paragraph">Pour mettre en œuvre une approche de hiérarchisation basée sur des fichiers, vous devez avoir des fichiers écrits et non modifiés par la suite. Le<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> la règle doit être définie suffisamment haut pour que les fichiers dont vous avez besoin restent sur le tier de performance. Par exemple, un jeu de données pour lequel les 60 derniers jours de données sont requis avec des performances optimales garantit le paramétrage du<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> période jusqu'en 60. Des résultats similaires peuvent également être obtenus en fonction des modèles d'accès aux fichiers. Par exemple, si les 90 derniers jours de données sont requis et que l'application accède à cette période de 90 jours, les données restent sur le Tier de performance. En réglant le<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> sur 2, le tiering s'affiche rapidement une fois les données moins actives.</block>
  <block id="8a467b35326e4738b1bd39865c3b21a0" category="admonition">Tout type d'accès aux données réinitialise les données de la carte thermique. L'analyse antivirus, l'indexation et même l'activité de sauvegarde qui lit les fichiers source empêchent le Tiering, car les besoins sont importants<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> le seuil n'est jamais atteint.</block>
  <block id="7a1920d61156abc05a60135aefe8bc67" category="doc">Valeur par défaut</block>
  <block id="5ba46d288640832c345e169b04a7458a" category="paragraph">Tous les volumes FabricPool sont initialement définis sur<block ref="c21f969b5f03d33d43e04f8f136e7682" prefix=" " category="inline-code"></block>, ce qui signifie que le comportement est contrôlé par la `cloud-retrieval-policy. `le comportement exact dépend de la règle de hiérarchisation utilisée.</block>
  <block id="d556a0d2cad80695d1d803ebb49de9cd" category="section-title">En lecture</block>
  <block id="7c39eb141ca855e5a211b468bd67636c" category="paragraph">Réglage<block ref="d253e682212338dd6cbe577947f0511e" prefix=" " category="inline-code"></block> la lecture remplace le comportement par défaut, de sorte qu'une lecture de toutes les données hiérarchisées entraîne le renvoi de ces données vers le niveau de performance.</block>
  <block id="e07df43ea07fecb178484ef278644eb2" category="paragraph">Par exemple, un volume peut avoir été légèrement utilisé pendant une longue période sous le<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> la règle de tiering et la plupart des blocs sont désormais hiérarchisés.</block>
  <block id="98c8614a9e0467f220df33a02cf7550a" category="paragraph">Si une modification inattendue des besoins de l'entreprise nécessitait l'analyse répétée de certaines données pour préparer un rapport spécifique, il peut être souhaitable de modifier le<block ref="d253e682212338dd6cbe577947f0511e" prefix=" " category="inline-code"></block> à<block ref="0ba0dc933ac714a0bef4467360437336" prefix=" " category="inline-code"></block> pour garantir que toutes les données lues sont renvoyées au niveau de performances, y compris les données lues de manière séquentielle et aléatoire. Cela améliorerait les performances des E/S séquentielles par rapport au volume.</block>
  <block id="3ea4ba4aadef21fbda74c9b242c99efa" category="section-title">Promouvoir</block>
  <block id="cb674c0cbcbaa23bdd3c8e4f6182f865" category="paragraph">Le comportement de la règle de promotion dépend de la règle de hiérarchisation. Si la règle de hiérarchisation est<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block>, puis réglage du<block ref="723c2b1883eb9949dd821267c2d1b5c7" prefix=" " category="inline-code"></block> ramène tous les blocs du tier de capacité à l'analyse de tiering suivante.</block>
  <block id="452d85cc34fd3a4cf55ac61e732239f4" category="paragraph">Si la règle de hiérarchisation est<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block>, les seuls blocs renvoyés sont les blocs associés au système de fichiers actif. Normalement, cela n'aurait aucun effet car les seuls blocs placés sous le sont<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> la règle serait les blocs associés exclusivement aux snapshots. Il n'y aurait pas de blocs hiérarchisés dans le système de fichiers actif.</block>
  <block id="d6269fb1a970b6c261fedbc79464b3dc" category="paragraph">Toutefois, si une SnapRestore de volume ou une opération de clonage de fichiers a été effectuée pour restaurer les données d'un volume à partir d'un snapshot, le système de fichiers actif peut désormais avoir besoin de certains blocs qui ont été hiérarchisés, car ils n'étaient associés qu'à des snapshots. Il peut être souhaitable de modifier temporairement le<block ref="d253e682212338dd6cbe577947f0511e" prefix=" " category="inline-code"></block> règle à<block ref="eeefc0add5ccd6e20ac4214923d27fbc" prefix=" " category="inline-code"></block> pour récupérer rapidement tous les blocs localement requis.</block>
  <block id="6e7b34fa59e1bd229b207892956dc41c" category="section-title">Jamais</block>
  <block id="c45e30a0f86af155e2feb17dd7ba6e44" category="paragraph">Ne récupérez pas les blocs du niveau de capacité.</block>
  <block id="2d242bb36ec91b32005f9296ff03a912" category="doc">Architecture</block>
  <block id="ac30d4a74ecef302adab70e9669a4bf2" category="paragraph">FabricPool est une technologie de hiérarchisation qui classe les blocs « actifs » ou « froids » et les place dans le Tier de stockage le plus approprié. Le Tier de performance se trouve le plus souvent sur un stockage SSD et héberge les blocs de données fortement sollicités. Le Tier de capacité se trouve dans un magasin d'objets et héberge les blocs de données utiles. Elle prend en charge le stockage objet, notamment NetApp StorageGRID, ONTAP S3, Microsoft Azure Blob Storage, le service de stockage objet Alibaba Cloud, IBM Cloud Object Storage, Google Cloud Storage et Amazon AWS S3.</block>
  <block id="f9f5fe2f7456d37c955f3291744c93b6" category="paragraph">Plusieurs règles de Tiering sont disponibles pour contrôler la façon dont les blocs sont classés comme actifs ou froids. Il est également possible de définir des règles par volume et de les modifier selon les besoins. Seuls les blocs de données sont déplacés entre les tiers de performance et de capacité. Les métadonnées qui définissent la structure des LUN et du système de fichiers restent toujours sur le Tier de performance. La gestion est ainsi centralisée sous ONTAP. Les fichiers et les LUN n'apparaissent pas différents des données stockées dans une autre configuration ONTAP. Le contrôleur NetApp AFF ou FAS applique les règles définies pour déplacer les données vers le Tier approprié.</block>
  <block id="616ce0475334fe37834d13972a168ca5" category="section-title">Fournisseurs de magasins d'objets</block>
  <block id="71e79501cc067e6b35ac3d3e97c940a4" category="paragraph">Les protocoles de stockage objet utilisent de simples requêtes HTTP ou HTTPS pour stocker un grand nombre d'objets de données. L'accès au stockage objet doit être fiable, car l'accès aux données depuis ONTAP dépend du traitement rapide des demandes. Notamment Amazon S3 Standard et Infrequent Access, Microsoft Azure Hot Blob Storage, IBM Cloud et Google Cloud. Les options d'archivage telles qu'Amazon Glacier et Amazon Archive ne sont pas prises en charge, car le temps nécessaire à la récupération des données peut dépasser les tolérances des systèmes d'exploitation et des applications hôtes.</block>
  <block id="e114e830308285cd9085063fad91662c" category="paragraph">NetApp StorageGRID est également pris en charge et constitue une solution optimale. C'est un système de stockage objet haute performance, évolutif et hautement sécurisé qui assure une redondance géographique pour les données FabricPool ainsi que pour les autres applications de magasin d'objets qui font de plus en plus partie des environnements applicatifs d'entreprise.</block>
  <block id="fb318c5cd9ed18c79e1f7a298dd96665" category="paragraph">StorageGRID peut également réduire les coûts en évitant les frais de sortie imposés par de nombreux fournisseurs de cloud public pour la lecture des données de leurs services.</block>
  <block id="119d8a1213b5b7cae4bb567153b028cf" category="section-title">Données et métadonnées</block>
  <block id="b59d6123a3191bd85fe14e57b7a01e11" category="paragraph">Notez que le terme « données » s'applique ici aux blocs de données réels, et non aux métadonnées. Seuls les blocs de données sont hiérarchisés, tandis que les métadonnées restent dans le Tier de performance. En outre, l'état d'un bloc en tant que bloc chaud ou froid n'est affecté que par la lecture du bloc de données réel. La simple lecture du nom, de l'horodatage ou des métadonnées de propriété d'un fichier n'affecte pas l'emplacement des blocs de données sous-jacents.</block>
  <block id="1414cdc093d39dd56d0b0d20049e17fc" category="section-title">Sauvegardes</block>
  <block id="e0b766a7a0a7633679ecddd0f78a7390" category="paragraph">Même si FabricPool permet de réduire considérablement l'encombrement du stockage, il ne s'agit pas à lui seul d'une solution de sauvegarde. Les métadonnées NetApp WAFL restent toujours sur le Tier de performance. Si un incident catastrophique détruit le Tier de performance, il est impossible de créer un nouvel environnement à l'aide des données du Tier de capacité, car il ne contient pas de métadonnées WAFL.</block>
  <block id="7a25ce12890e524732cb71784b5915ab" category="paragraph">FabricPool peut cependant faire partie d'une stratégie de sauvegarde. Par exemple, FabricPool peut être configuré avec la technologie de réplication NetApp SnapMirror. Chaque moitié du miroir peut avoir sa propre connexion à une cible de stockage objet. Vous obtenez ainsi deux copies indépendantes des données. La copie principale se compose des blocs du niveau de performance et des blocs associés du niveau de capacité, tandis que la réplique constitue un second ensemble de blocs de performance et de capacité.</block>
  <block id="82af841589057aa8922b1ac3bb4a28a4" category="doc">Compression</block>
  <block id="e242ff0701d9ed7d8317b32fd762a100" category="paragraph">Les fonctionnalités d'optimisation de l'espace, telles que la compression, la compaction et la déduplication, sont conçues pour augmenter la quantité de données logiques correspondant à un volume de stockage physique donné. Vous réduisez ainsi vos coûts et vos frais de gestion.</block>
  <block id="13b992c3d358d786db03341886472c4f" category="paragraph">À un niveau élevé, la compression est un processus mathématique qui permet de détecter et d'encoder des modèles de données de manière à réduire les besoins en espace. En revanche, la déduplication détecte les blocs de données répétés et supprime les copies parasites. La compaction permet à plusieurs blocs logiques de données de partager le même bloc physique sur le support.</block>
  <block id="786d7cc1b18aa3d9c3e8d3e30865240e" category="paragraph">Avant la disponibilité des systèmes de stockage 100 % Flash, la compression basée sur les baies était d'une valeur limitée, car la plupart des charges de travail exigeantes en E/S nécessitaient un très grand nombre de piles pour obtenir une performance acceptable. Les systèmes de stockage contenaient invariablement beaucoup plus de capacité que nécessaire, ce qui a pour effet d'augmenter le nombre de disques. La situation a changé avec la montée du stockage Solid-State. Il n'est plus nécessaire de surprovisionner des disques uniquement pour obtenir de bonnes performances. L'espace disque d'un système de stockage peut être adapté aux besoins réels en termes de capacité.</block>
  <block id="b207c460d31fea9e1cfab71057e8152c" category="paragraph">La capacité accrue des disques SSD en termes d'IOPS permet presque toujours de réaliser des économies par rapport aux disques rotatifs. Toutefois, la compression peut réaliser davantage d'économies en augmentant la capacité effective des supports SSD.</block>
  <block id="6296c8b7406b90d37edf269f1ea6f6ee" category="section-title">Compression adaptative</block>
  <block id="1245fef302b5da2c27766d9a98ad358c" category="paragraph">La compression adaptative a été testée en profondeur avec des charges de travail exigeantes sans effet sur les performances, même dans un environnement 100 % Flash où la latence se mesure en microsecondes. Certains clients ont même signalé une augmentation des performances due à l'utilisation de la compression, car les données restent compressées dans le cache, augmentant ainsi la quantité de cache disponible dans un contrôleur.</block>
  <block id="93e0a644c8f1b7f7f378bc071d15d1e9" category="paragraph">ONTAP gère les blocs physiques dans des unités de 4 Ko. La compression adaptative utilise une taille de bloc de compression par défaut de 8 Ko, ce qui signifie que les données sont compressées dans des unités de 8 Ko. La taille de bloc de 8 Ko la plus utilisée par les bases de données relationnelles est donc identique. Les algorithmes de compression deviennent plus efficaces avec la compression d'un volume croissant de données. Une taille de bloc de compression de 32 Ko serait plus compacte qu'une unité de bloc de compression de 8 Ko. Cela signifie que la compression adaptative utilisant une taille de bloc de 8 Ko par défaut entraîne des taux d'efficacité légèrement inférieurs, mais qu'une taille de bloc de compression inférieure présente également des avantages considérables. Les charges de travail de la base de données incluent une grande quantité d'activités de remplacement. Le remplacement d'un bloc de données de 32 Ko compressé de 8 Ko nécessite la lecture de l'intégralité des 32 Ko de données logiques, leur décompression, la mise à jour de la région de 8 Ko requise, la recompression, puis l'écriture de la totalité des 32 Ko sur les disques. Cette opération est très coûteuse pour un système de stockage. En effet, certaines baies de stockage concurrentes, basées sur des blocs de compression plus volumineux, affectent également considérablement les performances des charges de travail de la base de données.</block>
  <block id="1f9367b7afff301ee24188d35050ae0a" category="section-title">Efficacité du stockage sensible à la température</block>
  <block id="02e44d620def629a6c145ccd0d9a0fd3" category="section-title">Alignement de compression</block>
  <block id="3b6e6c232a02ab9c64199eb9efae012c" category="paragraph">La compression adaptative dans un environnement de base de données nécessite un certain respect de l'alignement des blocs de compression. Cela ne préoccupe que les données soumises à des écrasements aléatoires de blocs très spécifiques. Cette approche est similaire à l'alignement global du système de fichiers, où le début d'un système de fichiers doit être aligné sur une limite de périphérique de 4 Ko et la taille de bloc d'un système de fichiers doit être un multiple de 4 Ko.</block>
  <block id="1d1a594959ec615f56516f5d0f5e8ddb" category="section-title">NFS</block>
  <block id="62a0282d39568be094470486eaf70c4f" category="section-title">SAN</block>
  <block id="14c3c56ff2a98d1a9c47b63a917f67a3" category="section-title">Compaction</block>
  <block id="0b01f66d49b9df153ee76048de44f6eb" category="paragraph">La compaction des données permet de stocker plusieurs blocs logiques dans des blocs physiques. Par exemple, une base de données avec des données fortement compressibles comme des blocs texte ou partiellement pleins peut être compressée de 8 Ko à 1 Ko. Sans compaction, 1 Ko de données occuperaient toujours un bloc complet de 4 Ko. La compaction des données à la volée permet de stocker 1 Ko de données compressées dans un espace physique de seulement 1 Ko, parallèlement à d'autres données compressées. Il ne s'agit pas d'une technologie de compression. Il s'agit simplement d'un moyen plus efficace d'allouer de l'espace sur les disques et, par conséquent, il ne doit pas créer d'effet détectable sur les performances.</block>
  <block id="83f45cad5e6f535ff10e564a526baad0" category="section-title">Déduplication</block>
  <block id="f591ef30da06841378ee7f595e63a93c" category="paragraph">La déduplication permet de supprimer les tailles de bloc dupliquées d'un dataset. Par exemple, si le même bloc de 4 Ko existe dans 10 fichiers différents, la déduplication redirige ce bloc de 4 Ko au sein des 10 fichiers vers le même bloc physique de 4 Ko. Résultat : une amélioration de l'efficacité de ces données de 10:1.</block>
  <block id="699c85c5df1985b2af588f9e6c1ad353" category="paragraph">Les données, telles que les LUN de démarrage invité VMware, se dédupliquent extrêmement bien, car elles sont constituées de plusieurs copies des mêmes fichiers du système d'exploitation. L'efficacité de 100:1 et plus ont été observées.</block>
  <block id="9653a3d4907877aae00bb7d39eeec66d" category="paragraph">Dans quelques cas, des économies d'espace allant jusqu'à 15 % ont été observées pour les bases de données de 16 Ko et les blocs volumineux. La bande de 4 Ko initiale de chaque bloc contient l'en-tête unique dans le monde, et le bloc de 4 Ko final contient la remorque presque unique. Les blocs internes sont candidats à la déduplication, bien que dans la pratique cela soit presque entièrement attribué à la déduplication des données mises à zéro.</block>
  <block id="32aeb47267cb2045610b468115f3ae0e" category="section-title">Efficacité et provisionnement fin</block>
  <block id="3381946611f34fb44ad8a38a0c44e0a8" category="paragraph">Les fonctions d'efficacité sont des formes de provisionnement fin. Par exemple, une LUN de 100 Go occupant un volume de 100 Go peut compresser à 50 Go. Aucune économie réelle n'est encore réalisée, car le volume est toujours de 100 Go. Le volume doit d'abord être réduit afin que l'espace économisé puisse être utilisé ailleurs sur le système. Si des modifications ultérieures de la LUN de 100 Go réduisent la taille des données compressibles, la LUN augmente et le volume pourrait se remplir.</block>
  <block id="38ef8b6f2fc332958c293d93c61d7756" category="paragraph">Certains clients préfèrent utiliser le provisionnement lourd, soit pour des charges de travail spécifiques, soit généralement en fonction de pratiques opérationnelles et d'approvisionnement établies.</block>
  <block id="0e7c78164adb6d4650ea685a79d8e99e" category="section-title">Meilleures pratiques en matière d'efficacité</block>
  <block id="ec499ad25fa5a765ba43ec2c87819623" category="section-title">AFF par défaut</block>
  <block id="9f7127e69d50bf7b844ff3723b86fbd1" category="section-title">Recommandations générales</block>
  <block id="2c24e4751310e03f119a4df187a3bc08" category="list-text">Si les volumes et/ou les LUN ne sont pas à provisionnement fin, vous devez désactiver tous les paramètres d'efficacité car l'utilisation de ces fonctionnalités n'offre aucune économie et la combinaison du provisionnement lourd et de l'optimisation de l'espace peut provoquer des comportements inattendus, notamment des erreurs de manque d'espace.</block>
  <block id="4922fe547c351d6a121465da036d478e" category="list-text">Si les données ne sont pas sujettes à des écrasements, par exemple avec des sauvegardes ou des journaux de transactions de base de données, vous pouvez atteindre une meilleure efficacité en activant TSSE avec une période de refroidissement faible.</block>
  <block id="e75fd383e4106eb78482b18896975daf" category="list-text">Certains fichiers peuvent contenir une quantité importante de données non compressibles, par exemple lorsque la compression est déjà activée au niveau de l'application, les fichiers sont cryptés. Si l'un de ces scénarios est vrai, envisagez de désactiver la compression pour permettre un fonctionnement plus efficace sur d'autres volumes contenant des données compressibles.</block>
  <block id="64d5def835c194cac8afe4fafded756e" category="doc">Règles - snapshots locaux</block>
  <block id="baa596d0db91317fa83739a95649752e" category="paragraph">La version initiale de FabricPool a ciblé le cas d'utilisation de la sauvegarde. Les seuls types de blocs qui ont pu être hiérarchisés sont les blocs qui n'étaient plus associés aux données dans le système de fichiers actif. Par conséquent, seuls les blocs de données des snapshots peuvent être déplacés vers le niveau de capacité. Il s'agit là de l'une des options de hiérarchisation les plus sécurisées lorsque vous devez vous assurer que les performances ne sont jamais affectées.</block>
  <block id="b21eb7f0b67c3e27e915183638bf92cf" category="paragraph">Deux options sont disponibles pour le Tiering des blocs de snapshots inactifs vers le niveau de capacité. Tout d'abord, le<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> la règle cible uniquement les blocs de snapshot. Bien que le<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> la politique inclut le<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> et tiering des blocs à partir du système de fichiers actif. Ce n'est peut-être pas souhaitable.</block>
  <block id="eeba990304f236b36a9fec2434c77470" category="paragraph">Le<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> value doit être défini sur une période qui met à disposition les données éventuellement requises lors d'une restauration sur le tier de performance. Par exemple, la plupart des scénarios de restauration d'une base de données de production stratégique incluent un point de restauration à un moment donné au cours des jours précédents. Réglage a<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> la valeur 3 garantit que toute restauration du fichier entraîne un fichier qui offre immédiatement des performances maximales. Tous les blocs des fichiers actifs sont toujours présents sur un système de stockage rapide sans avoir à les restaurer à partir du niveau de capacité.</block>
  <block id="baf531ed01ad56f5614e1a68e8a2e7aa" category="section-title">Règles - snapshots répliqués</block>
  <block id="27e5121a4c75181022e7be2b738339d0" category="paragraph">Les snapshots répliqués avec SnapMirror ou SnapVault, uniquement utilisés pour la restauration, doivent généralement utiliser FabricPool<block ref="a181a603769c1f98ad927e7367c7aa51" prefix=" " category="inline-code"></block> politique. Avec cette règle, les métadonnées sont répliquées, mais tous les blocs de données sont immédiatement envoyés au niveau de capacité pour des performances maximales. La plupart des processus de restauration impliquent des E/S séquentielles, ce qui est intrinsèquement efficace. Le délai de restauration à partir de la destination du magasin d'objets doit être évalué, mais dans une architecture bien conçue, ce processus de restauration ne doit pas nécessairement être beaucoup plus lent que la restauration à partir de données locales.</block>
  <block id="639e481de0ffe002bd83251b26a2540a" category="paragraph">Si les données répliquées sont également destinées à être utilisées pour le clonage, le<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> la politique est plus appropriée, avec un<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> valeur qui englobe les données qui doivent être utilisées régulièrement dans un environnement de clonage. Par exemple, le jeu de travail actif d'une base de données peut inclure des données lues ou écrites au cours des trois jours précédents, mais il peut également inclure 6 mois de données historiques supplémentaires. Si oui, alors le<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> La règle appliquée à la destination SnapMirror met à disposition le jeu de travail sur le Tier de performance.</block>
  <block id="ace0bd0c1be3a9e17d9736d93e7a1da2" category="doc">QoS des IOPS</block>
  <block id="786ee59e0cdaa09335e12fea3a168653" category="paragraph">Plus précisément, l'adoption croissante des systèmes de stockage 100 % Flash a permis de consolider les charges de travail. Les baies de stockage qui reposent sur des supports rotatifs ne prennent généralement en charge qu'un nombre limité de charges de travail exigeantes en E/S, car leurs capacités IOPS sont limitées par rapport aux anciens disques rotatifs. Une ou deux bases de données fortement actives saturaient les disques sous-jacents bien avant que les contrôleurs de stockage n'atteignent leurs limites. Cela a changé. Il est possible de saturer les contrôleurs de stockage les plus puissants, car le nombre de disques SSD requis est relativement faible. Cela signifie que vous pouvez exploiter pleinement les capacités des contrôleurs sans craindre un effondrement soudain des performances lors de pics de latence des supports rotatifs.</block>
  <block id="270d79669200ef485add1ecc1833cc94" category="paragraph">À titre d'exemple de référence, un simple système AFF A800 HA à deux nœuds est capable de traiter jusqu'à un million d'IOPS aléatoires avant que la latence ne dépasse la milliseconde. On pourrait s'attendre à ce que très peu de charges de travail atteignent de tels niveaux. L'utilisation optimale de cette baie AFF A800 implique l'hébergement de plusieurs workloads. Pour ce faire, la sécurité et la prévisibilité exigent des contrôles de QoS.</block>
  <block id="4dca0c3547523a2e5bd1b8d0e2ff8de5" category="paragraph">Il existe deux types de qualité de service (QoS) dans ONTAP : les IOPS et la bande passante. Les contrôles de QoS peuvent être appliqués aux SVM, volumes, LUN et fichiers.</block>
  <block id="3ea539ed2021ba46a3658039e8af419f" category="paragraph">Un contrôle de la QoS pour les IOPS est évidemment basé sur l'ensemble des IOPS d'une ressource donnée, mais il existe un certain nombre d'aspects de la QoS pour les IOPS qui peuvent ne pas être intuitifs. Au départ, quelques clients ont été surpris par l'augmentation apparente de la latence lorsqu'un seuil d'IOPS est atteint. L'augmentation de la latence est la conséquence naturelle de la limitation des IOPS. Logiquement, il fonctionne de la même manière qu'un système de jetons. Par exemple, si un volume donné contenant des fichiers de données dispose d'une limite de 10 000 IOPS, chaque E/S arrivant doit d'abord recevoir un jeton pour poursuivre le traitement. Tant que plus de 10 000 jetons n'ont pas été consommés en une seconde donnée, aucun retard n'est présent. Si les opérations d'E/S doivent attendre la réception de leur jeton, cet attente apparaît comme une latence supplémentaire. Plus une charge de travail est élevée, plus les E/S sont longues à attendre dans la file d'attente pour le traitement de son tour, ce qui apparaît comme une latence plus élevée.</block>
  <block id="34a96885dd7f4501920b13026e7f2cab" category="admonition">Soyez prudent lorsque vous appliquez des contrôles QoS aux données des transactions de base de données/journaux de reprise. Alors que les demandes de performances liées à la journalisation de reprise sont généralement très élevées, bien inférieures à celles des fichiers de données, l'activité du journal de reprise est en rafales. L'E/S se produit en de brèves impulsions et une limite de QoS qui semble appropriée pour les niveaux d'E/S de reprise moyens peut être trop basse pour les exigences réelles. Cela peut entraîner de strictes limitations de performance en cas d'engagement de la QoS avec chaque pic de journal de reprise. En général, la journalisation des opérations de reprise et d'archivage ne doit pas être limitée par la QoS.</block>
  <block id="c79dc76371299e08f4b4ebd609314ca4" category="section-title">QoS de la bande passante</block>
  <block id="b9d5c520039715de9b997c5a69f4aeaa" category="paragraph">Toutes les tailles d'E/S ne sont pas identiques. Par exemple, une base de données peut effectuer de nombreuses lectures de blocs de petite taille, ce qui entraînerait l'atteinte du seuil d'IOPS, mais il est également possible que les bases de données effectuent une analyse de table complète comprenant un très petit nombre de lectures de blocs volumineux, qui consomment une très grande quantité de bande passante, mais relativement peu d'IOPS.</block>
  <block id="4930ae83bb8dd5e539dc9f7e73c6d74c" category="paragraph">De même, un environnement VMware peut générer un nombre très élevé d'IOPS aléatoires au démarrage, mais exécuter moins d'E/S, mais plus importantes, lors d'une sauvegarde externe.</block>
  <block id="eabb5a523a77d4521c12622ee9388aa6" category="paragraph">Pour gérer efficacement les performances, les IOPS ou la bande passante doivent parfois être limitées, voire les deux.</block>
  <block id="13dac55a5f26cefab26368ea5a67e29f" category="section-title">QoS minimale/garantie</block>
  <block id="68559688130772c84bb39b2a9ca2c2af" category="paragraph">De nombreux clients recherchent une solution incluant une QoS garantie, qui semble plus difficile à atteindre qu'elle ne le paraît et qui risque d'être très gaspillée. Par exemple, pour placer 10 bases de données avec une garantie de 10 000 IOPS, il est nécessaire de dimensionner un système dans le cas où les 10 bases de données s'exécutent simultanément à 10 000 IOPS, pour un total de 100 000.</block>
  <block id="c0938f706c890ea85c86388391ffad22" category="paragraph">La meilleure utilisation pour les contrôles QoS minimaux est de protéger les charges de travail stratégiques. Prenons l'exemple d'un contrôleur ONTAP avec un maximum de 500 000 IOPS et un mélange de charges de travail de production et de développement. Vous devez appliquer des règles de QoS maximales aux workloads de développement pour empêcher toute base de données de monopoliser le contrôleur. Vous appliqueriez ensuite des règles de QoS minimales aux charges de travail de production afin de vous assurer que les IOPS requises sont toujours disponibles, le cas échéant.</block>
  <block id="acdda1c20fb3985ce840929f7525c803" category="section-title">La QoS adaptative</block>
  <block id="dd5bc58ed6ab031b170a409470d9a763" category="paragraph">La QoS adaptative fait référence à la fonctionnalité ONTAP où la limite de QoS repose sur la capacité de l'objet de stockage. Elle est rarement utilisée avec les bases de données, car il n'existe généralement aucun lien entre la taille d'une base de données et ses exigences de performances. Les grandes bases de données peuvent être quasiment inertes, tandis que les bases de données plus petites peuvent être celles qui nécessitent le plus d'IOPS.</block>
  <block id="eb595833577352045f92d14ac4315ad2" category="paragraph">La QoS adaptative peut s'avérer très utile avec les datastores de virtualisation, car les exigences en IOPS de ces jeux de données ont tendance à être corrélées à la taille totale de la base de données. Un datastore plus récent contenant 1 To de fichiers VMDK devrait avoir besoin d'environ la moitié des performances pour un datastore de 2 To. La QoS adaptative vous permet d'augmenter automatiquement les limites de qualité de service lorsque le datastore est rempli de données.</block>
  <block id="23f3d415bb4fe6f99165df604b24da0e" category="paragraph">Le Tiering d'un dataset avec FabricPool entraîne une dépendance entre la baie de stockage primaire et le Tier de magasin d'objets. De nombreuses options de stockage objet offrent différents niveaux de disponibilité. Il est important de comprendre l'impact d'une éventuelle perte de connectivité entre la baie de stockage primaire et le niveau de stockage objet.</block>
  <block id="7e856c11a853d276fd5d6274bf60fafd" category="paragraph">Si une E/S émise par ONTAP nécessite des données du niveau de capacité et que les ONTAP ne peuvent pas atteindre le niveau de capacité pour récupérer des blocs, les E/S finissent par être sorties. L'effet de ce délai dépend du protocole utilisé. Dans un environnement NFS, ONTAP répond par une réponse EJUKEBOX ou EDELAY, selon le protocole. Certains systèmes d'exploitation plus anciens peuvent interpréter cela comme une erreur, mais les systèmes d'exploitation actuels et les niveaux de correctifs actuels du client Oracle Direct NFS traitent cette erreur comme une nouvelle tentative et continuent d'attendre la fin des E/S.</block>
  <block id="207d9fe0f57910936bfa043248f3afca" category="paragraph">Un délai plus court s'applique aux environnements SAN. Si un bloc de l'environnement de magasin d'objets est requis et reste inaccessible pendant deux minutes, une erreur de lecture est renvoyée à l'hôte. Le volume ONTAP et les LUN restent en ligne, mais le système d'exploitation hôte peut signaler le système de fichiers comme étant dans un état d'erreur.</block>
  <block id="c9251835da8df507ca4f6ce02d4216be" category="paragraph">Les problèmes de connectivité du stockage objet<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> la politique est moins préoccupante, car seules les données de sauvegarde sont hiérarchisées. Les problèmes de communication ralentiraient la récupération des données, mais n'affecteraient pas les données utilisées activement. Le<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> et<block ref="a181a603769c1f98ad927e7367c7aa51" prefix=" " category="inline-code"></block> Les règles permettent le Tiering des données inactives de la LUN active, ce qui signifie qu'une erreur lors de la récupération des données du magasin d'objets peut affecter la disponibilité de la base de données. Un déploiement SAN doté de ces règles doit uniquement être utilisé avec un stockage objet de grande qualité et des connexions réseau conçues pour une haute disponibilité. NetApp StorageGRID est la meilleure option.</block>
  <block id="0f8062f9220efe4f38e7236fe8885379" category="paragraph">La plupart des bases de données relationnelles opèrent en mode d'archivage du journal de transactions pour assurer une restauration instantanée. Les modifications apportées aux bases de données sont validées en enregistrant les modifications dans les journaux de transactions et le journal de transactions est conservé sans être écrasé. Il peut donc s'avérer nécessaire de conserver un énorme volume de journaux de transactions archivés. De nombreux autres workflows applicatifs génèrent des données qui doivent être conservées, mais il est très peu probable qu'elles soient accessibles.</block>
  <block id="229384bbfb1db19c4897d87ba4b9bc2d" category="paragraph">Pour résoudre ces problèmes, FabricPool propose une solution unique avec hiérarchisation intégrée. Les fichiers sont stockés et restent accessibles à leur emplacement habituel, mais ne prennent pratiquement pas d'espace sur la baie principale.</block>
  <block id="f60aec7aaed8420e09f17a8cfd1d7d37" category="paragraph">Utiliser un<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> la règle de quelques jours permet de conserver les blocs dans les fichiers récemment créés (les fichiers les plus susceptibles d'être requis à court terme) sur le niveau de performance. Les blocs de données des anciens fichiers sont ensuite déplacés vers le niveau de capacité.</block>
  <block id="485e24df9e0ebeecf416daa6e5441bba" category="paragraph">Le<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> applique la hiérarchisation des invites lorsque le seuil de refroidissement a été atteint, que les journaux aient été supprimés ou qu'ils continuent d'exister dans le système de fichiers principal. Le stockage de tous les journaux potentiellement requis dans un seul emplacement du système de fichiers actif simplifie également la gestion. Il n'y a aucune raison de rechercher un fichier à restaurer à l'aide de snapshots.</block>
  <block id="bbe0132696bc482e0ba7a1f293d80083" category="paragraph">Certaines applications, telles que Microsoft SQL Server, tronquent les fichiers journaux de transactions pendant les opérations de sauvegarde afin que les journaux ne soient plus dans le système de fichiers actif. Il est possible d'économiser de la capacité à l'aide de<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> la règle de tiering, mais la règle<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> la règle n'est pas utile pour les données de journal car il devrait rarement y avoir des données de journal refroidies dans le système de fichiers actif.</block>
  <block id="0694b4972669f201ca85f9427a230208" category="doc">MetroCluster est disponible dans 3 configurations différentes</block>
  <block id="948676ffa8073153cbe404795950ad85" category="list-text">Paires HAUTE DISPONIBILITÉ avec connectivité IP</block>
  <block id="ef012b81fd45a95681a584a59f8df77e" category="list-text">Paires HAUTE DISPONIBILITÉ avec connectivité FC</block>
  <block id="6ffec869ba36dff4e093b5ed8bac798a" category="list-text">Contrôleur unique avec connectivité FC</block>
  <block id="4767099b22895a8101a1cba45d8cf6e9" category="section-title">IP MetroCluster</block>
  <block id="adc397d87c1a7827f2df9fdd362d5ff7" category="paragraph">La configuration IP MetroCluster à paire haute disponibilité utilise deux ou quatre nœuds par site. Cette option de configuration augmente la complexité et les coûts liés à l'option à deux nœuds, mais elle offre un avantage important : la redondance intrasite. Une simple panne de contrôleur ne nécessite pas l'accès aux données via le WAN. L'accès aux données reste local via l'autre contrôleur local.</block>
  <block id="c15560f2ae5432223c591c5f5d9db5c1" category="paragraph">La plupart des clients choisissent la connectivité IP, car les exigences d'infrastructure sont plus simples. Auparavant, la connectivité inter-sites à haut débit était généralement plus facile à provisionner avec des commutateurs FC et fibre noire. Cependant, les circuits IP à haut débit et à faible latence sont aujourd'hui plus facilement disponibles.</block>
  <block id="b28c5a429800ea9669a191a402a72b49" category="paragraph">L'architecture est également plus simple, car les contrôleurs disposent des seules connexions entre les sites. Dans les MetroCluster FC, un contrôleur écrit directement sur les disques du site opposé et requiert ainsi des connexions SAN, des commutateurs et des ponts supplémentaires. En revanche, un contrôleur dans une configuration IP écrit sur les lecteurs opposés via le contrôleur.</block>
  <block id="457b0075e8f0333975a8e2aaeaceb149" category="inline-link">Architecture et conception de la solution IP de MetroCluster</block>
  <block id="82aa44c8aa5ebe78f1496c8fc80cb954" category="paragraph">Pour plus d'informations, consultez la documentation officielle de ONTAP et<block ref="03a3c76178d2d43147a2756857a0985e" category="inline-link-rx"></block>.</block>
  <block id="0d2d438a72f6c558744351265fa49a62" category="section-title">MetroCluster FC à connexion SAN HA-pair</block>
  <block id="3e9133ff590581b29a911d9631ab1737" category="paragraph">La configuration MetroCluster FC à paire haute disponibilité utilise deux ou quatre nœuds par site. Cette option de configuration augmente la complexité et les coûts liés à l'option à deux nœuds, mais elle offre un avantage important : la redondance intrasite. Une simple panne de contrôleur ne nécessite pas l'accès aux données via le WAN. L'accès aux données reste local via l'autre contrôleur local.</block>
  <block id="4bc2926f030255369db3e4435de5c774" category="paragraph">Certaines infrastructures multisites ne sont pas conçues pour les opérations en mode actif-actif. Elles sont plutôt utilisées comme site principal et site de reprise après incident. Dans ce cas, il est généralement préférable d'utiliser une option MetroCluster à paire HA pour les raisons suivantes :</block>
  <block id="5f49f48dd22b405a813e2ef7cc02e9f8" category="list-text">Bien qu'un cluster MetroCluster à deux nœuds soit un système haute disponibilité, toute panne inattendue d'un contrôleur ou une maintenance planifiée implique que les services de données soient en ligne sur le site opposé. Si la connectivité réseau entre les sites ne prend pas en charge la bande passante requise, les performances sont affectées. La seule option serait également de basculer les différents systèmes d'exploitation hôtes et les services associés vers le site secondaire. Le cluster MetroCluster de paire haute disponibilité élimine ce problème, car la perte d'un contrôleur simplifie le basculement au sein du même site.</block>
  <block id="0ce798a4f2e77d6aa1a6e0d718fa8e98" category="list-text">Certaines topologies réseau ne sont pas conçues pour l'accès intersite, mais utilisent des sous-réseaux différents ou des SAN FC isolés. Dans ce cas, le cluster MetroCluster à deux nœuds ne fonctionne plus comme un système haute disponibilité, car le contrôleur secondaire ne peut plus transmettre de données aux serveurs sur le site opposé. L'option MetroCluster de paire haute disponibilité est nécessaire pour assurer une redondance complète.</block>
  <block id="098fa44ef37572e0f8ea717199ac72e6" category="list-text">Si une infrastructure à deux sites est considérée comme une seule infrastructure extrêmement disponible, la configuration MetroCluster à deux nœuds est adaptée. Toutefois, si le système doit fonctionner pendant une période prolongée après une panne sur le site, une paire haute disponibilité est recommandée, car la haute disponibilité continue d'être disponible sur un seul site.</block>
  <block id="ea8bb3e5a357ca97851352f6944342c9" category="section-title">MetroCluster FC à deux nœuds avec connexion SAN</block>
  <block id="b759079fef92c80eca80e7349bf84363" category="paragraph">La configuration MetroCluster à deux nœuds n'utilise qu'un nœud par site. Cette conception est plus simple que l'option de paire haute disponibilité, car le nombre de composants à configurer et à gérer est inférieur. Elle a également réduit les besoins en infrastructure en termes de câblage et de commutation FC. Enfin, il réduit les coûts.</block>
  <block id="bcf549481eb36a62594e938bca6a10bb" category="paragraph">L'impact évident de cette conception est que la défaillance du contrôleur sur un seul site signifie que les données sont disponibles depuis le site opposé. Cette restriction n'est pas nécessairement un problème. De nombreuses entreprises disposent d'opérations de data Center multisites avec des réseaux étendus, ultra-rapides et à faible latence qui fonctionnent essentiellement comme une infrastructure unique. Dans ce cas, la version à deux nœuds de MetroCluster est la configuration préférée. Plusieurs fournisseurs de services utilisent actuellement des systèmes à deux nœuds de plusieurs pétaoctets.</block>
  <block id="78558542e724655ba80fc4879399f103" category="section-title">Fonctions de résilience MetroCluster</block>
  <block id="5427d2eb91f25a425f13544e56fb12c4" category="paragraph">Une solution MetroCluster ne présente aucun point de défaillance unique :</block>
  <block id="6a988bf07e73bcbf69f62ce9724dd0f3" category="list-text">Chaque contrôleur dispose de deux chemins d'accès indépendants aux tiroirs disques sur le site local.</block>
  <block id="2c98a75e02c6e103b43724f02e99e393" category="list-text">Chaque contrôleur dispose de deux chemins d'accès indépendants aux tiroirs disques du site distant.</block>
  <block id="e18f703538cd1f5af3b9185eed57b49b" category="list-text">Chaque contrôleur dispose de deux chemins d'accès indépendants aux contrôleurs sur le site opposé.</block>
  <block id="800ec0ea85a62c2fb192ac2f79ee1d02" category="list-text">Dans la configuration HA-pair, chaque contrôleur dispose de deux chemins vers son partenaire local.</block>
  <block id="a3d7a569ad6ea771a0ad9b995619251b" category="paragraph">En résumé, n'importe quel composant de la configuration peut être supprimé sans compromettre la capacité de MetroCluster à transmettre des données. La seule différence en termes de résilience entre les deux options est que la version à paire haute disponibilité reste un système de stockage haute disponibilité global après une panne de site.</block>
  <block id="9b4c3976d453e66a3dd22e2793fc3a8e" category="doc">Gestion de l'espace</block>
  <block id="e89d3732a2fbc592923c30e54522dcdb" category="paragraph">Le provisionnement fin, de nombreuses formes, fait partie intégrante de nombreuses fonctionnalités offertes par ONTAP à l'environnement applicatif d'entreprise. Le provisionnement fin est également étroitement lié aux technologies d'efficacité pour la même raison : les fonctionnalités d'efficacité permettent de stocker davantage de données logiques que ce qui existe techniquement sur le système de stockage.</block>
  <block id="537642ed3bfef7f2bb3e580b3b266bd3" category="paragraph">La plupart des snapshots impliquent un provisionnement fin. Par exemple, une base de données classique de 10 To sur un système de stockage NetApp compte environ 30 jours de copies Snapshot. Cet arrangement donne lieu à environ 10 To de données visibles dans le système de fichiers actif et 300 To dédiés aux snapshots. La capacité totale de stockage de 310 To réside généralement dans un espace d'environ 12 To à 15 To. La base de données active consomme 10 To et les 300 To de données restantes ne nécessitent que 2 à 5 To d'espace, car seules les modifications apportées aux données d'origine sont stockées.</block>
  <block id="a19609016ad1cb6b7bae7cac796a26a4" category="paragraph">Le clonage est également un exemple de provisionnement fin. Un client NetApp majeur a créé 40 clones d'une base de données de 80 To à utiliser pour le développement. Si les 40 développeurs qui utilisent ces clones surécrivent chaque bloc dans chaque fichier de données, plus de 3,2 po de stockage seraient nécessaires. En pratique, le chiffre d'affaires est faible et l'espace collectif requis est proche de 40 To, car seules les modifications sont stockées sur les disques.</block>
  <block id="2433af6347e4871be5af0f2af0f6bd6e" category="paragraph">Le provisionnement fin d'un environnement applicatif doit être extrêmement prudent, car les taux de modification des données peuvent augmenter de manière inattendue. Par exemple, la consommation d'espace due aux snapshots peut augmenter rapidement si les tables de base de données sont réindexées ou si des correctifs à grande échelle sont appliqués aux invités VMware. Une sauvegarde mal placée peut écrire une grande quantité de données dans un délai très court. Enfin, il peut être difficile de restaurer certaines applications si un système de fichiers manque d'espace de façon inattendue.</block>
  <block id="5cf4dc4d1ce52ff655ea7f1157a72e2e" category="paragraph">Avec une configuration soigneuse de, ces risques peuvent être maîtrisés<block ref="f9e1f2ea1a2becbaf82dd54e55a12e6b" prefix=" " category="inline-code"></block> et<block ref="24d554277b3513bb6cef3f0a336725a9" prefix=" " category="inline-code"></block> règles. Comme leurs noms l'indiquent, ces options permettent de créer des règles qui effacent automatiquement l'espace consommé par les snapshots ou augmentent un volume pour prendre en charge des données supplémentaires. De nombreuses options sont disponibles et les besoins varient selon les clients.</block>
  <block id="6a28738961e6f6e4b57e4dd70c446600" category="inline-link-macro">documentation sur la gestion du stockage logique</block>
  <block id="01570cb5a3aec2324ab56e318e1de04d" category="paragraph">Voir la <block ref="e69bd75bdb49183ee90588843edb33f4" category="inline-link-macro-rx"></block> pour une discussion complète de ces fonctionnalités.</block>
  <block id="e10d46632bc86306cf4c22633ee930ab" category="paragraph">Une planification minutieuse de la configuration de LVM peut améliorer l'efficacité et réduire les besoins en provisionnement du stockage et en redimensionnement des LUN. Lorsqu'un LVM tel que Veritas VxVM ou Oracle ASM est utilisé, les LUN sous-jacentes sont divisés en extensions qui ne sont utilisées que lorsque cela est nécessaire. Par exemple, si un dataset commence à 2 To mais peut atteindre 10 To au fil du temps, ce dataset peut être placé sur 10 To de LUN à provisionnement fin organisées dans un groupe de disques LVM. Elle occupant seulement 2 To d'espace au moment de la création et réclarait uniquement de l'espace supplémentaire, dans la mesure où les extensions sont allouées pour prendre en charge la croissance du volume des données. Ce processus est sûr tant que l'espace est surveillé.</block>
  <block id="66a41fd6fc38c454973e91d92cf0e291" category="section-title">Réservations fractionnaires</block>
  <block id="e8a206fe65814e0ea465e32487544751" category="paragraph">La réserve fractionnaire fait référence au comportement d'une LUN dans un volume en ce qui concerne l'efficacité de l'espace. Lorsque l'option<block ref="c1acac5c4332e37ec1f281fcbaf0765a" prefix=" " category="inline-code"></block> est défini sur 100 %. toutes les données du volume peuvent connaître un taux de rotation de 100 % avec n'importe quel modèle de données, sans épuiser l'espace sur le volume.</block>
  <block id="a3cd28aef7d0becd57b60187fdc4a24e" category="paragraph">Par exemple, prenons l'exemple d'une base de données située sur une seule LUN de 250 Go dans un volume de 1 To. La création d'un snapshot entraînerait immédiatement la réservation d'un espace supplémentaire de 250 Go dans le volume, garantissant ainsi que l'espace disponible sur le volume ne serait pas insuffisant pour quelque raison que ce soit. L'utilisation de réserves fractionnaires est généralement inutile car il est très peu probable que chaque octet du volume de base de données ait besoin d'être écrasé. Il n'y a aucune raison de réserver de l'espace pour un événement qui ne se produit jamais. Cependant, si un client ne peut pas surveiller la consommation d'espace dans un système de stockage et doit être certain que l'espace ne sera jamais épuisé, des réservations fractionnaires de 100 % seront nécessaires pour utiliser les snapshots.</block>
  <block id="e30fbe8981929fb070a820a213381bab" category="section-title">Compression et déduplication</block>
  <block id="1b6e4e9a2be031edc6f3da1f559ef884" category="paragraph">La compression et la déduplication sont deux formes de provisionnement fin. Par exemple, une empreinte des données de 50 To peut être compressée jusqu'à 30 To, ce qui permet d'économiser 20 To. Pour que la compression offre tous les avantages, il faut utiliser quelques 20 To pour d'autres données ou acheter le système de stockage avec moins de 50 To. Il en résulte une quantité de données stockées supérieure à ce qui n'est techniquement disponible sur le système de stockage. Du point de vue des données, il y a 50 To de données, même si celles-ci ne occupent que 30 To sur les disques.</block>
  <block id="dbca4bb791f36eac2c11c32f73f2b4ec" category="paragraph">Il est toujours possible que la compressibilité d'un dataset change, ce qui entraîne une consommation accrue de l'espace réel. Cette augmentation de la consommation signifie que la compression doit être gérée comme avec les autres formes de provisionnement fin en termes de surveillance et d'utilisation<block ref="f9e1f2ea1a2becbaf82dd54e55a12e6b" prefix=" " category="inline-code"></block> et<block ref="24d554277b3513bb6cef3f0a336725a9" prefix=" " category="inline-code"></block>.</block>
  <block id="ad241666a88b5414e8c2fe6d1cc1edb0" category="paragraph">La compression et la déduplication sont présentées plus en détail dans la section link:efficiency.html</block>
  <block id="8ecfcadfebb472a089481e8554ebed87" category="section-title">Compression et réservations fractionnaires</block>
  <block id="4f8fcc146d2e8e712dcd8c56b1684fcc" category="paragraph">La compression est une forme d'allocation dynamique. Les réservations fractionnaires affectent l'utilisation de la compression, avec une remarque importante ; l'espace est réservé avant la création du snapshot. Normalement, la réserve fractionnaire n'est importante que si un instantané existe. S'il n'y a pas de snapshot, la réserve fractionnaire n'est pas importante. Ce n'est pas le cas avec la compression. Si une LUN est créée sur un volume avec compression, ONTAP conserve l'espace nécessaire pour prendre en charge un snapshot. Ce comportement peut être déroutant pendant la configuration, mais il est normal.</block>
  <block id="e26f8048b4bf60dad827c5a425271361" category="paragraph">Prenons l'exemple d'un volume de 10 Go avec une LUN de 5 Go compressée à 2,5 Go sans copie Snapshot. Prenez en compte ces deux scénarios :</block>
  <block id="ade18971a2dab7e37335e95d81da0ef1" category="list-text">La réserve fractionnaire = 100 entraîne une utilisation de 7,5 Go</block>
  <block id="1d07b8e7c92488a55301ea201328cf35" category="list-text">La réserve fractionnaire = 0 entraîne une utilisation de 2,5 Go</block>
  <block id="aa410d0e46ec94b6efcf344f0d870c1a" category="paragraph">Le premier scénario comprend 2,5 Go de consommation d'espace pour les données actuelles et 5 Go d'espace pour représenter 100 % de chiffre d'affaires de la source en prévision de l'utilisation des snapshots. Le deuxième scénario ne réserve pas d'espace supplémentaire.</block>
  <block id="e79414ad391b126cc9bd53af1624c8de" category="paragraph">Bien que cette situation puisse sembler confuse, il est peu probable qu'elle soit rencontrée dans la pratique. La compression implique un provisionnement fin et le provisionnement fin dans un environnement LUN nécessite des réservations fractionnaires. Il est toujours possible d'écraser des données compressées par un élément non compressible, ce qui signifie qu'un volume doit être à provisionnement fin pour la compression, pour réaliser des économies.</block>
  <block id="499a10b92cb9ca6b3412d4bf5a91a2b0" category="paragraph">*NetApp recommande* les configurations de réserve suivantes :</block>
  <block id="7f26e875cee50c1b3baf71a014043794" category="list-text">Réglez<block ref="c1acac5c4332e37ec1f281fcbaf0765a" prefix=" " category="inline-code"></block> à 0 lorsque la surveillance de la capacité de base est en place avec<block ref="f9e1f2ea1a2becbaf82dd54e55a12e6b" prefix=" " category="inline-code"></block> et<block ref="24d554277b3513bb6cef3f0a336725a9" prefix=" " category="inline-code"></block>.</block>
  <block id="675996bd34ec0d8c134215f5be73fb3a" category="list-text">Réglez<block ref="c1acac5c4332e37ec1f281fcbaf0765a" prefix=" " category="inline-code"></block> à 100 s'il n'y a pas de capacité de surveillance ou s'il est impossible d'évacuer l'espace en quelque circonstance que ce soit.</block>
  <block id="8ee38535add58992c14b23a6f7cf8d27" category="doc">Types de LIF</block>
  <block id="50d034374ef68094a0f6c8e8d06a77af" category="inline-link-macro">Documentation de gestion de réseau ONTAP</block>
  <block id="fc25025f3f0a2afd42465a55f35c02d0" category="paragraph">Cette section présente les principes clés de conception des LIF. Pour obtenir une documentation plus complète, reportez-vous au <block ref="a3e6361e1a52d384f542a2f2d8bc9bb1" category="inline-link-macro-rx"></block>. Comme pour les autres aspects de l'architecture de la base de données, les meilleures options pour la conception des machines virtuelles de stockage (SVM, appelé SVM au niveau de l'interface de ligne de commande) et de l'interface logique (LIF) dépendent largement des besoins en termes d'évolutivité et des besoins de l'entreprise.</block>
  <block id="be0801f7fb241be642bec73b799d45cb" category="paragraph">Tenez compte des principaux sujets suivants lors de l'élaboration d'une stratégie LIF :</block>
  <block id="362c2978dddcf6988ce266d3d60f5beb" category="list-text">*Performances.* la bande passante du réseau est-elle suffisante ?</block>
  <block id="cfc88efb72b2c7ea83a4a3d68b760d55" category="list-text">*Résilience.* y a-t-il des points de défaillance uniques dans la conception?</block>
  <block id="af02972fd4dc1e949d800731d9518812" category="list-text">*Gérabilité.* le réseau peut-il être mis à l'échelle sans interruption ?</block>
  <block id="fdcbadc80d2dd31527cc91cf81fb725d" category="paragraph">Ces rubriques s'appliquent à la solution de bout en bout, de l'hôte aux commutateurs et au système de stockage.</block>
  <block id="f45fe079103703d0b315ff2e339728fd" category="inline-link-macro">Documentation ONTAP sur les types de LIF</block>
  <block id="cc4583278db25277db9ddcd781cbf992" category="paragraph">Il existe plusieurs types de LIF. <block ref="9d27879d9d2bd4f0f081ffed63159522" category="inline-link-macro-rx"></block> Fournir des informations plus complètes à ce sujet, mais d'un point de vue fonctionnel, les LIF peuvent être divisées en plusieurs groupes :</block>
  <block id="f34a52d788c5a4cf56d7ae8ccb85f8c2" category="list-text">*LIFs de gestion de clusters et de nœuds.* utilisées pour gérer le cluster de stockage.</block>
  <block id="73ac4e00a9ff3caf31e6df13a6df2f78" category="list-text">*LIF de gestion SVM.* interfaces permettant l'accès à une SVM via l'API REST ou ONTAPI (aussi connue sous le nom de ZAPI) pour des fonctions telles que la création de snapshots ou le redimensionnement de volumes. Des produits tels que SnapManager pour Oracle (SMO) doivent avoir accès à une LIF de gestion SVM.</block>
  <block id="b7010e46f4769f638197aa230f448ba0" category="list-text">*Interfaces de données LIF.* pour FC, iSCSI, NVMe/FC, NVMe/TCP, NFS, ou SMB/CIFS.</block>
  <block id="1eb4f53fa8ee8f0954514a1b9858bf6b" category="admonition">Une LIF de données utilisée pour le trafic NFS peut également être utilisée à des fins de gestion en modifiant la politique de pare-feu de<block ref="8d777f385d3dfec8815d20f7496026dc" prefix=" " category="inline-code"></block> à<block ref="d724f231a9a7b89757c4394d6622bc47" prefix=" " category="inline-code"></block> Ou une autre règle autorisant HTTP, HTTPS ou SSH. Ce changement peut simplifier la configuration du réseau en évitant la configuration de chaque hôte pour l'accès à la fois à la LIF de données NFS et à une LIF de gestion distincte. Il n'est pas possible de configurer une interface pour l'iSCSI et le trafic de gestion, bien que les deux utilisent un protocole IP. Une LIF de gestion distincte est requise dans les environnements iSCSI.</block>
  <block id="85d465743ad38be108b50648ab283d78" category="section-title">Conception de SAN LIF</block>
  <block id="8800a54085e1b2987d83537423221cf9" category="paragraph">La conception de LIF dans un environnement SAN est relativement simple pour une raison : les chemins d'accès multiples. Toutes les implémentations SAN modernes permettent à un client d'accéder aux données sur plusieurs chemins réseau indépendants et de sélectionner le ou les chemins d'accès les plus adaptés. Par conséquent, les performances du design LIF sont plus simples à gérer, car les clients SAN équilibrent automatiquement la charge en E/S sur les meilleurs chemins disponibles.</block>
  <block id="e33c923a4d6280bf6f2b2a982ff74ee3" category="paragraph">Si un chemin devient indisponible, le client sélectionne automatiquement un autre chemin. La simplicité de conception qui en résulte rend les LIF SAN généralement plus faciles à gérer. Cela ne signifie pas pour autant qu'un environnement SAN est toujours plus facile à gérer, car de nombreux autres aspects du stockage SAN sont bien plus complexes que NFS. Cela signifie simplement que la conception de la LIF SAN est plus facile.</block>
  <block id="9446a98ad14416153cc4d45ab8b531bf" category="section-title">Performance</block>
  <block id="141614e246b14131ec01a449d61ed657" category="paragraph">La bande passante est l'élément le plus important à prendre en compte dans les performances de LIF dans un environnement SAN. Par exemple, un cluster ONTAP AFF à deux nœuds doté de deux ports FC 16 Gb par nœud permet d'obtenir jusqu'à 32 Go de bande passante vers/depuis chaque nœud.</block>
  <block id="02bc0523497de72834c4c7990e32d155" category="section-title">Résilience</block>
  <block id="01b1d8276ca14813ff4804089a9ac082" category="paragraph">Les LIF SAN ne basculent pas sur un système de stockage AFF. Si une LIF SAN échoue en raison du basculement du contrôleur, le logiciel de chemins d'accès multiples du client détecte la perte d'un chemin et redirige les E/S vers une autre LIF. Avec les systèmes de stockage ASA, les LIF basculent après un court délai, mais cela n'interrompt pas les E/S, car il existe déjà des chemins actifs sur l'autre contrôleur. Le processus de basculement a lieu afin de restaurer l'accès de l'hôte sur tous les ports définis.</block>
  <block id="b7c94ef25c0629a65f8a1f6ce7014d95" category="section-title">Gestion aisée</block>
  <block id="1325935a6fa0e88cfec45038005f18e3" category="paragraph">La migration des LIF est une tâche beaucoup plus courante dans un environnement NFS, car elle est souvent associée au déplacement des volumes au sein du cluster. Il n'est pas nécessaire de migrer une LIF dans un environnement SAN lorsque les volumes sont déplacés au sein de la paire HA. En effet, une fois le déplacement de volume terminé, ONTAP envoie une notification au SAN concernant un changement de chemins et les clients SAN se réoptimisent automatiquement. La migration de LIF avec SAN est principalement associée à des modifications matérielles physiques majeures. Par exemple, si une mise à niveau des contrôleurs sans interruption est requise, une LIF SAN est migrée vers le nouveau matériel. Si un port FC est défectueux, une LIF peut être migrée vers un port non utilisé.</block>
  <block id="dbb887b1373e51dab774976c5a556964" category="section-title">Recommandations de conception</block>
  <block id="076872b2444637e6142c3c6f0f157423" category="paragraph">NetApp fait les recommandations suivantes :</block>
  <block id="d8d6bca7c981c13479781da85883cfef" category="list-text">Ne créez pas plus de chemins que nécessaire. Un nombre excessif de chemins complique la gestion globale et peut entraîner des problèmes de basculement de chemin sur certains hôtes. De plus, certains hôtes ont des limites de chemin inattendues pour les configurations comme le démarrage SAN.</block>
  <block id="bd662d86fcca370cddf188ff5378fb1b" category="list-text">Très peu de configurations doivent nécessiter plus de quatre chemins vers une LUN. L'intérêt d'avoir plus de deux nœuds de chemins publicitaires vers les LUN est limité, car l'agrégat hébergeant une LUN est inaccessible en cas de défaillance du nœud qui détient la LUN et de son partenaire haute disponibilité. Dans ce cas, la création de chemins sur des nœuds autres que la paire haute disponibilité principale n'est pas utile.</block>
  <block id="8873f044ab7c082f16372e4b8bdc6e03" category="list-text">Même si vous pouvez gérer le nombre de chemins de LUN visibles en sélectionnant les ports inclus dans les zones FC, il est généralement plus facile d'inclure tous les points cibles potentiels dans la zone FC et de contrôler la visibilité des LUN au niveau des ONTAP.</block>
  <block id="0ebc6267761306c4daefb9871a470e4b" category="list-text">Dans ONTAP 8.3 et versions ultérieures, la fonction de mappage de LUN sélectif (SLM) est la fonction par défaut. Avec SLM, toute nouvelle LUN est automatiquement annoncée à partir du nœud qui possède l'agrégat sous-jacent et du partenaire HA du nœud. Cet arrangement évite de créer des ensembles de ports ou de configurer le zoning pour limiter l'accessibilité des ports. Chaque LUN est disponible sur le nombre minimal de nœuds requis pour des performances et une résilience optimales.
*Dans le cas où un LUN doit être migré en dehors des deux contrôleurs, les nœuds supplémentaires peuvent être ajoutés avec le<block ref="02d0bbdc14988c85bbd7994723f4dd7f" prefix=" " category="inline-code"></block> De sorte que les LUN soient annoncées sur les nouveaux nœuds. Vous créez ainsi des chemins SAN supplémentaires vers les LUN pour la migration des LUN. Toutefois, l'hôte doit effectuer une opération de découverte pour utiliser les nouveaux chemins.</block>
  <block id="cc4b24f288afae5889c6061466dda472" category="list-text">Ne vous souciez pas trop du trafic indirect. Dans un environnement très exigeant en E/S, il est préférable d'éviter le trafic indirect pour lequel chaque microseconde de latence est critique, mais l'impact visible sur la performance est négligeable pour les charges de travail classiques.</block>
  <block id="f54fccb82abaa995eb9f86264f431505" category="section-title">Conception de LIF NFS</block>
  <block id="e68dee93f11ae71aebd7a1e4c2abfc5a" category="paragraph">Contrairement aux protocoles SAN, NFS dispose d'une capacité limitée de définir plusieurs chemins d'accès aux données. Les extensions NFS parallèles (pNFS) à NFSv4 répondent à cette limitation, mais l'ajout de chemins d'accès supplémentaires devient rarement intéressant dans la mesure où les vitesses ethernet atteignent 100 Go et au-delà.</block>
  <block id="391dc675ec3d853200129b799ed5923e" category="section-title">Performances et résilience</block>
  <block id="a0bd34f908e3947aa4aba15382354836" category="paragraph">Bien que la mesure des performances d'une LIF SAN consiste principalement à calculer la bande passante totale à partir de tous les chemins principaux, la détermination des performances d'une LIF NFS nécessite d'étudier de plus près la configuration réseau exacte. Par exemple, deux ports 10 Gbit peuvent être configurés comme ports physiques bruts ou en tant que groupe d'interface LACP (Link Aggregation Control Protocol). S'ils sont configurés en tant que groupe d'interface, plusieurs stratégies d'équilibrage de charge sont disponibles et fonctionnent différemment selon que le trafic est commuté ou routé. Enfin, Oracle Direct NFS (dNFS) propose des configurations d'équilibrage de charge qui n'existent pour le moment dans aucun client OS NFS.</block>
  <block id="e500ca27c6b92454c989d80e0445c359" category="paragraph">Contrairement aux protocoles SAN, les systèmes de fichiers NFS nécessitent une résilience au niveau de la couche de protocole. Par exemple, une LUN est toujours configurée avec les chemins d'accès multiples activés, ce qui signifie que plusieurs canaux redondants sont disponibles pour le système de stockage, chacun utilisant le protocole FC. Un système de fichiers NFS, en revanche, dépend de la disponibilité d'un seul canal TCP/IP qui ne peut être protégé qu'au niveau de la couche physique. C'est pourquoi des options telles que le basculement de port et l'agrégation de ports LACP existent.</block>
  <block id="35926e2ada969ad80fd3b16c0cd7d35a" category="paragraph">Dans un environnement NFS, les performances et la résilience sont fournies au niveau de la couche du protocole réseau. En conséquence, ces deux sujets sont étroitement liés et doivent être discutés ensemble.</block>
  <block id="84f4a5dfaa9613a469cd783c353a186c" category="section-title">Lier les LIFs aux groupes de ports</block>
  <block id="44bfb87c11d83c1b91c3589f2081e7ca" category="paragraph">Pour lier une LIF à un port group, associez l'adresse IP de la LIF à un groupe de ports physiques. La méthode principale pour agréger les ports physiques est le LACP. La fonctionnalité de tolérance aux pannes de LACP est assez simple : chaque port d'un groupe LACP est surveillé et supprimé du groupe de ports en cas de dysfonctionnement. Cependant, il existe de nombreuses idées fausses sur le fonctionnement de LACP en matière de performances :</block>
  <block id="19a43026949fb6ef1017a54cf7c94f9b" category="list-text">LACP ne requiert pas que la configuration sur le switch corresponde au terminal. Par exemple, ONTAP peut être configuré avec un équilibrage de charge basé sur IP, tandis qu'un commutateur peut utiliser un équilibrage de charge basé sur MAC.</block>
  <block id="86501252b34395de5303a65f5e9943e3" category="list-text">Chaque noeud final utilisant une connexion LACP peut choisir indépendamment le port de transmission des paquets, mais il ne peut pas choisir le port utilisé pour la réception. Cela signifie que le trafic de ONTAP vers une destination particulière est lié à un port particulier, et que le trafic de retour peut arriver sur une interface différente. Cela ne cause cependant aucun problème.</block>
  <block id="298ca40b99dd3540dcd82ba5537f3f8d" category="list-text">LACP ne distribue pas uniformément le trafic en permanence. Dans un grand environnement comptant de nombreux clients NFS, le résultat est même généralement l'utilisation de tous les ports d'une agrégation LACP. Cependant, tout système de fichiers NFS dans l'environnement est limité à la bande passante d'un seul port, et non à l'agrégation complète.</block>
  <block id="d071b5ccd1569aace97a0b4d6c0a71ac" category="list-text">Bien que les politiques LACP robin-Robin soient disponibles sur ONTAP, ces règles n'abordent pas la connexion entre un switch et un hôte. Par exemple, une configuration avec une jonction LACP à quatre ports sur un hôte et une jonction LACP à quatre ports sur ONTAP ne peut toujours lire un système de fichiers qu'à l'aide d'un seul port. Bien que ONTAP puisse transmettre des données via les quatre ports, aucune technologie de commutation n'est actuellement disponible, qui envoie du commutateur à l'hôte via les quatre ports. Un seul est utilisé.</block>
  <block id="6e9e98dfaea1ca7860606f1fc05e414a" category="paragraph">L'approche la plus courante dans les grands environnements composés de nombreux hôtes de base de données est de créer un agrégat LACP comportant un nombre approprié d'interfaces 10 Gbit (ou plus rapides) en utilisant l'équilibrage de la charge IP. Cette approche permet à ONTAP d'assurer une utilisation uniforme de tous les ports, tant qu'il y a suffisamment de clients. L'équilibrage de la charge est défaillant lorsque la configuration compte moins de clients, car les ressources en ligne LACP ne redistribuent pas la charge de manière dynamique.</block>
  <block id="7815da600ab459d2b05c5792f2271c1a" category="paragraph">Lorsqu'une connexion est établie, le trafic dans une direction particulière est placé sur un seul port. Par exemple, une base de données effectuant une analyse de table complète sur un système de fichiers NFS connecté via une jonction LACP à quatre ports lit les données via une seule carte d'interface réseau (NIC). Si seulement trois serveurs de base de données se trouvent dans un tel environnement, il est possible que les trois derniers lisent à partir du même port, alors que les trois autres ports sont inactifs.</block>
  <block id="153f704ea16440133d51b1877af2a657" category="section-title">Lier les LIF à des ports physiques</block>
  <block id="70e655aa3c03f840747c5272142b3527" category="paragraph">La liaison d'une LIF à un port physique permet un contrôle plus granulaire de la configuration du réseau, car une adresse IP donnée sur un système ONTAP n'est associée qu'à un seul port réseau à la fois. La résilience s'obtient ensuite via la configuration des groupes de basculement et des règles de basculement.</block>
  <block id="218f00463f5281b8ead536582c69ac3a" category="section-title">Stratégies de basculement et groupes de basculement</block>
  <block id="0a53c26a1bc4036c84fc3b4b63542744" category="inline-link-macro">Documentation de gestion de réseau ONTAP pour les groupes et politiques de basculement</block>
  <block id="f29ae31443947c9782482ee9683dbc0e" category="paragraph">Le comportement des LIF durant une interruption du réseau est contrôlé par des règles de basculement et des groupes de basculement. Les options de configuration ont été modifiées avec les différentes versions de ONTAP. Consulter le <block ref="96c8cd47b667604fb9991ace7d2eff29" category="inline-link-macro-rx"></block> Pour plus d'informations sur la version de ONTAP déployée.</block>
  <block id="0f2f345dd1247ae428cee703c1bf1c84" category="paragraph">Les versions ONTAP 8.3 et supérieures permettent la gestion du basculement des LIF sur la base des domaines de diffusion. Par conséquent, un administrateur peut définir tous les ports ayant accès à un sous-réseau donné et autoriser ONTAP à sélectionner une LIF de basculement appropriée. Cette approche peut être utilisée par certains clients, mais elle est limitée dans un environnement de réseau de stockage haut débit en raison du manque de prévisibilité. Par exemple, un environnement peut inclure à la fois des ports 1 Gbit pour l'accès aux systèmes de fichiers de routine et des ports 10 Gbit pour les E/S des fichiers de données Si les deux types de ports existent dans le même broadcast domain, le basculement de LIF peut entraîner le déplacement des E/S des fichiers de données d'un port 10 Gb vers un port 1 Gb.</block>
  <block id="ced0729d57c08312b2b12382f2147d26" category="paragraph">En résumé, tenez compte des pratiques suivantes :</block>
  <block id="57cb6a7ba8acb7faa31cc5219bae83b3" category="list-text">Configurez un groupe de basculement comme défini par l'utilisateur.</block>
  <block id="b444855eccae552d7fb79bf3d31a4f7b" category="list-text">Remplissez le groupe de basculement avec les ports du contrôleur partenaire de basculement de stockage (SFO) de sorte que les LIF suivent les agrégats lors d'un basculement de stockage. Cela évite de créer du trafic indirect.</block>
  <block id="86c48b21d166ed8e440a07e1d4a0b15d" category="list-text">Utilisez les ports de basculement avec des caractéristiques de performance correspondantes à la LIF d'origine. Par exemple, une LIF située sur un seul port physique de 10 Go doit inclure un groupe de basculement doté d'un seul port 10 Go. Une LIF LACP à quatre ports doit basculer vers une autre LIF LACP à quatre ports. Ces ports seraient un sous-ensemble des ports définis dans le domaine de diffusion.</block>
  <block id="3e839a73f7dc1262508f23a89628ca2d" category="list-text">Définissez la politique de basculement sur partenaire SFO uniquement. Veillez donc à ce que la LIF suive l'agrégat lors du failover.</block>
  <block id="85e82ce4c9842f978fa774c4fe96b14c" category="section-title">Restauration automatique</block>
  <block id="3dc8610f78478640e47688101cecbfad" category="paragraph">Réglez le<block ref="9f1b7141f09f19c4e33409646aef43cf" prefix=" " category="inline-code"></block> paramètre selon vos besoins. La plupart des clients préfèrent définir ce paramètre sur<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> Pour que la LIF rerevienne sur son port home. Cependant, dans certains cas, les clients ont défini cette option sur `false `afin qu'un basculement inattendu puisse être recherché avant de renvoyer une LIF à son port de attache.</block>
  <block id="edf6d4c299bc2890ba63c7eb3ef8b4d2" category="section-title">Rapport LIF/volume</block>
  <block id="9c75becef8c432a0152a40c7c037a04c" category="paragraph">On croit souvent, à tort, qu'il doit y avoir une relation 1:1 entre les volumes et les LIFs NFS. Même si cette configuration est requise pour déplacer un volume n'importe où dans un cluster sans jamais créer de trafic d'interconnexion supplémentaire, elle n'est pas obligatoire de manière catégorique. Le trafic intercluster doit être envisagé, mais la simple présence du trafic intercluster ne crée pas de problèmes. Nombre des bancs d'essai publiés pour ONTAP portent sur des E/S principalement indirectes</block>
  <block id="2b4ebcd522b07b80d3fd76b301c506e8" category="paragraph">Par exemple, un projet de base de données contenant un nombre relativement limité de bases de données pour lesquelles seuls 40 volumes nécessitent des performances élevées peut justifier un rapport volume 1:1 vers une stratégie LIF, un arrangement qui nécessiterait 40 adresses IP. N'importe quel volume peut ensuite être déplacé n'importe où dans le cluster avec la LIF associée, et le trafic serait toujours direct, minimisant ainsi chaque source de latence, même à des niveaux d'une microseconde.</block>
  <block id="38bad4911bcdf1117d37eb1195566f8c" category="paragraph">Par exemple, un grand environnement hébergé peut être plus facilement géré avec une relation 1:1 entre les clients et les LIF. Au fil du temps, un volume peut avoir besoin d'être migré vers un autre nœud, ce qui provoque du trafic indirect. Cependant, l'effet sur les performances doit être indétectable à moins que les ports réseau du commutateur d'interconnexion ne soient saturés. En cas de problème, une nouvelle LIF peut être établie sur des nœuds supplémentaires et l'hôte peut être mis à jour dans la fenêtre de maintenance suivante afin de supprimer le trafic indirect de la configuration.</block>
  <block id="d75b0d8f723c3e97eaa4ca39630c7420" category="doc">MetroCluster et plusieurs agrégats</block>
  <block id="df5855269b493a27a5565dfd9f2584f0" category="list-text">Dans des conditions normales, les écritures entrantes sur un contrôleur donné sont mises en miroir de manière synchrone sur son partenaire. Dans un environnement NetApp MetroCluster, les écritures sont également mises en miroir sur un contrôleur distant. Tant qu'une écriture n'est pas stockée sur un support non volatile dans tous les emplacements, elle n'est pas validée par l'application hôte.</block>
  <block id="05b60db315aa45e1524b7a6ffa242fa8" category="list-text">Le support qui stocke les données d'écriture est appelé mémoire non volatile ou NVMEM. Elle est également parfois appelée mémoire NVRAM, et peut être considérée comme un cache d'écriture, même si elle fonctionne comme un journal. En fonctionnement normal, les données de NVMEM ne sont pas lues ; elles sont uniquement utilisées pour protéger les données en cas de défaillance logicielle ou matérielle. Lors de l'écriture des données sur les disques, les données sont transférées de la mémoire RAM du système, et non de NVMEM.</block>
  <block id="e6dd8b559da6e046f2043043a55faafc" category="list-text">Lors d'une opération de basculement, un nœud d'une paire haute disponibilité reprend les opérations de son partenaire. Un basculement est quasiment identique, mais s'applique aux configurations MetroCluster dans lesquelles un nœud distant prend le relais par rapport à un nœud local.</block>
  <block id="33c0c466972aae7427262e3075a2ed07" category="paragraph">Lors des opérations de maintenance de routine, un basculement du stockage ou un basculement doivent être transparents, sauf en cas de brève pause potentielle dans les opérations en cas de changement des chemins réseau. La mise en réseau peut toutefois être complexe et il est facile d'y faire des erreurs. NetApp recommande donc de tester minutieusement les opérations de basculement et de basculement avant de mettre en production un système de stockage. C'est la seule façon de s'assurer que tous les chemins réseau sont correctement configurés. Dans un environnement SAN, vérifiez soigneusement le résultat de la commande<block ref="41dc2c94e82e1c56ba876085acf5a974" prefix=" " category="inline-code"></block> pour vous assurer que tous les chemins principaux et secondaires attendus sont disponibles.</block>
  <block id="d33ea1ad1493de23aafd480e95fea159" category="paragraph">Il convient de faire attention lors d'un basculement forcé ou d'un basculement forcé. Forcer une modification de la configuration du stockage avec ces options signifie que l'état du contrôleur propriétaire des disques est ignoré et que le nœud alternatif prend le contrôle des disques. Une force de basculement incorrecte peut entraîner une perte ou une corruption des données. En effet, un basculement forcé ou un basculement forcé peut rejeter le contenu de la NVMEM. Une fois le basculement ou le basculement effectué, la perte de ces données signifie que les données stockées sur les disques peuvent revenir à un état plus ancien du point de vue de la base de données.</block>
  <block id="c226371d96b605ccff84ad23db0069b8" category="paragraph">Un basculement forcé avec une paire haute disponibilité normale devrait rarement être nécessaire. Dans la plupart des scénarios de défaillance, un nœud s'arrête et informe le partenaire qu'un basculement automatique a lieu. Il existe certains cas à la périphérie, par exemple une panne de déploiement où l'interconnexion entre les nœuds est perdue puis un contrôleur est perdu, dans lequel un basculement forcé est nécessaire. Dans ce cas, la mise en miroir entre les nœuds est perdue avant la panne du contrôleur, ce qui signifie que le contrôleur survivant n'aurait plus de copie des écritures en cours. Le basculement doit ensuite être forcé, ce qui signifie que des données peuvent être perdues.</block>
  <block id="418f81f529a577cb711b44adece1376f" category="paragraph">La même logique s'applique à un basculement MetroCluster. Dans des conditions normales, le basculement est presque transparent. Toutefois, un incident peut entraîner une perte de connectivité entre le site survivant et le site de reprise sur incident. Du point de vue du site survivant, le problème ne pourrait être rien de plus qu'une interruption de la connectivité entre les sites, et le site d'origine pourrait encore traiter les données. Si un nœud ne peut pas vérifier l'état du contrôleur principal, seul un basculement forcé est possible.</block>
  <block id="ae0c16d397348d8f8fd4e56b08b06c7c" category="paragraph">*NetApp recommande* de prendre les précautions suivantes :</block>
  <block id="79fd18cb18befbe5c2113757478be193" category="list-text">Veillez à ne pas forcer accidentellement un basculement ou un basculement. En règle générale, il n'est pas nécessaire de forcer et le fait de forcer la modification peut entraîner la perte de données.</block>
  <block id="26cece11254903c5ba8bfdd8d54ae779" category="list-text">Si un basculement ou un basculement forcé s'avère nécessaire, assurez-vous que les applications sont arrêtées, que tous les systèmes de fichiers sont démontés et que les groupes de volumes LVM (Logical Volume Manager) sont proposés en mode Variyoffed. Les groupes de disques ASM doivent être démontés.</block>
  <block id="0b6986eb1285d28a9987ea13adbca358" category="list-text">En cas de basculement forcé du MetroCluster, vous pouvez isoler le nœud défaillant de toutes les ressources de stockage restantes. Pour plus d'informations, consultez le Guide de gestion et de reprise sur incident de MetroCluster correspondant à la version appropriée de ONTAP.</block>
  <block id="71303adf87737046acd4381c72151278" category="paragraph">MetroCluster est une technologie de réplication synchrone qui passe en mode asynchrone en cas d'interruption de la connectivité. Cette demande est la plus courante de la part des clients, car une réplication synchrone garantie signifie que l'interruption de la connectivité du site entraîne un blocage complet des E/S de la base de données, ce qui la met hors service.</block>
  <block id="cb791a44ee361703eb7594a7932f57de" category="paragraph">Avec MetroCluster, les agrégats sont rapidement resynchronisés une fois la connectivité restaurée. Contrairement à d'autres technologies de stockage, MetroCluster ne devrait jamais nécessiter de mise en miroir complète après une panne de site. Seules les modifications delta doivent être expédiées.</block>
  <block id="c1536091d7c1ca33c9dc4dfa8c0852a2" category="paragraph">Dans les jeux de données qui couvrent les agrégats, le risque est faible de nécessiter des étapes supplémentaires de restauration des données en cas de sinistre en cas de déploiement. En particulier, si (a) la connectivité entre les sites est interrompue, (b) la connectivité est restaurée, (c) les agrégats atteignent un état dans lequel certains sont synchronisés et d'autres ne le sont pas, puis (d) le site primaire est perdu, le site survivant dans lequel les agrégats ne sont pas synchronisés. Dans ce cas, une partie du dataset est synchronisée et il est impossible d'ouvrir des applications, des bases de données ou des datastores sans restauration. Si un dataset compte plusieurs agrégats, NetApp recommande vivement d'utiliser des sauvegardes basées sur des snapshots avec l'un des nombreux outils disponibles pour vérifier la restauration rapide dans ce scénario inhabituel.</block>
  <block id="a42c87064c284490a38efac4bf0b7f7f" category="paragraph">RAID 4, RAID 5, RAID 6, RAID DP et RAID-TEC utilisent tous la parité pour s'assurer qu'une panne de disque n'entraîne pas de perte de données. Ces options RAID offrent une meilleure utilisation du stockage que la mise en miroir, mais la plupart des implémentations RAID présentent des inconvénients pour les opérations d'écriture. La réalisation d'une opération d'écriture sur d'autres implémentations RAID peut nécessiter plusieurs lectures de disque pour régénérer les données de parité, un processus communément appelé la pénalité RAID.</block>
  <block id="3cfcf9a3299db75df9aa0e024ebef965" category="paragraph">Cependant, ONTAP n'entraîne pas cette pénalité RAID. Cela est dû à l'intégration de NetApp WAFL (Write Anywhere File Layout) à la couche RAID. Les opérations d'écriture sont fusionnées dans la mémoire RAM et préparées sous la forme d'une couche RAID complète, y compris la génération de la parité. ONTAP n'a pas besoin d'effectuer de lecture pour effectuer une écriture, ce qui signifie que ONTAP et WAFL évitent la pénalité RAID. Les performances des opérations stratégiques pour la latence, telles que la journalisation de reprise, sont assurées sans aucun obstacle. Les écritures aléatoires des fichiers de données n'entraînent aucune pénalité RAID résultant de la régénération de la parité.</block>
  <block id="5ff9a871332f0f82f38d880b68a9874b" category="paragraph">En ce qui concerne la fiabilité statistique, même RAID DP offre une meilleure protection que la mise en miroir RAID. Le problème principal est la demande sur disques lors de la reconstruction RAID. Avec une configuration RAID en miroir, le risque de perte de données en cas de défaillance d'un disque pendant la reconstruction vers son partenaire dans la configuration RAID est bien plus grand que le risque de défaillance simultanée de trois disques dans une configuration RAID DP.</block>
  <block id="12c3fe87fd5a746ce8a7cbe25dc1c25b" category="paragraph">Avant l'ère des disques Flash, la répartition était utilisée pour surmonter les limites de performances des disques rotatifs. Par exemple, si un système d'exploitation doit effectuer une opération de lecture de 1 Mo, la lecture de ce 1 Mo de données à partir d'un seul disque demande beaucoup de tête de lecture lorsque le transfert des 1 Mo est lent. Si ce 1 Mo de données a été réparti sur 8 LUN, le système d'exploitation pourrait exécuter huit opérations de lecture de 128 K en parallèle et réduire le temps nécessaire au transfert de 1 Mo.</block>
  <block id="e337352c3d57672fd08af8ba709b544f" category="paragraph">Le striping avec des disques rotatifs était plus difficile, car le modèle d'E/S devait être connu à l'avance. Si la répartition n'a pas été correctement réglée pour les véritables modèles d'E/S, les configurations à bandes risquent d'endommager les performances. Avec les bases de données Oracle, et en particulier les configurations 100 % Flash, le striping est beaucoup plus facile à configurer et a fait ses preuves pour améliorer considérablement les performances.</block>
  <block id="7025652291dc6872022b0f79a2b2be21" category="paragraph">Par défaut, les gestionnaires de volumes logiques, tels que la bande Oracle ASM, ne le font pas pour le système d'exploitation natif LVM. Certaines lient plusieurs LUN ensemble en tant que périphérique concaténé. Résultat : des fichiers de données existent sur un seul périphérique LUN. Ceci provoque des points chauds. Les autres implémentations LVM prennent par défaut en charge les extensions distribuées. Cette méthode est similaire à la répartition, mais elle est plus grossière. Les LUN du groupe de volumes sont tranchées en grandes parties, appelées extensions et généralement mesurées en plusieurs mégaoctets. Ensuite, les volumes logiques sont distribués sur ces extensions. Il en résulte des E/S aléatoires sur un fichier qui doit être bien réparti entre les LUN, mais les opérations d'E/S séquentielles ne sont pas aussi efficaces qu'elles pourraient l'être.</block>
  <block id="0c2f3b2ec9d90baa0a0a0b6fb673a113" category="paragraph">Les E/S des applications exigeantes en performances sont presque toujours de (a) en unités de taille de bloc de base ou (b) d'un mégaoctet.</block>
  <block id="804d5b1f06570b4d242be0c2f0c3392c" category="paragraph">L'objectif principal d'une configuration à bandes est de s'assurer que les E/S de fichier unique peuvent être exécutées comme une seule unité, et que les E/S de plusieurs blocs, d'une taille de 1 Mo, peuvent être parallélisées de façon homogène sur toutes les LUN du volume réparti. Cela signifie que la taille de bande ne doit pas être inférieure à la taille du bloc de base de données, et que la taille de bande multipliée par le nombre de LUN doit être de 1 Mo.</block>
  <block id="0598f393baefd05d48b48076cc7df606" category="paragraph">La figure suivante présente trois options possibles pour le réglage de la taille et de la largeur des bandes. Le nombre de LUN est sélectionné pour répondre aux exigences de performances comme décrit ci-dessus, mais dans tous les cas, le total des données dans une seule bande est de 1 Mo.</block>
  <block id="0353522b39b87d54d40d3f09ec668851" category="doc">Configuration ONTAP</block>
  <block id="8e52de0d4b03d5fe87dc88da09616c7f" category="inline-link-macro">ici.</block>
  <block id="337c62c6b6eb7319bae58701105e889c" category="doc">Tiering</block>
  <block id="3493794b3ccb587f71a663f51f4484ef" category="summary">Bases de données PostgreSQL sur ONTAP</block>
  <block id="2d3298c651b356a82db5d664ce68e65e" category="doc">Protection native des données</block>
  <block id="31c6611c8e0bd237a3ee51db1728a440" category="paragraph">L'un des principaux aspects de la conception du stockage est l'activation de la protection pour les volumes PostgreSQL. Les clients peuvent protéger leurs bases de données PostgreSQL en utilisant l'approche dump ou en utilisant des sauvegardes de système de fichiers. Cette section décrit les différentes approches de sauvegarde de bases de données individuelles ou de l'ensemble du cluster.</block>
  <block id="9f3265914462c64fd02bc50ab4c9ebe9" category="paragraph">Il existe trois approches de sauvegarde des données PostgreSQL :</block>
  <block id="6b592c7950245a5a9f54d9424e851e97" category="list-text">Dump SQL Server</block>
  <block id="c8b1fc69d12d1da6589e384671c8e82c" category="list-text">Sauvegarde au niveau du système de fichiers</block>
  <block id="3c25062a0babfa1495dd604698707610" category="list-text">Archivage continu</block>
  <block id="58c132e2be12705408a7456c6183b617" category="paragraph">L'idée derrière la méthode de vidage de SQL Server est de générer un fichier avec des commandes SQL Server qui, une fois renvoyées au serveur, peuvent recréer la base de données telle qu'elle était au moment de la sauvegarde. PostgreSQL fournit les programmes utilitaires<block ref="5a5149b2817f30cbb3805307f9cadae4" prefix=" " category="inline-code"></block> et<block ref="0ead269b3d000482b5a44a1ef4e8cd54" prefix=" " category="inline-code"></block> pour la création de sauvegardes individuelles et au niveau du cluster. Ces vidages sont logiques et ne contiennent pas suffisamment d'informations pour être utilisés par la relecture WAL.</block>
  <block id="1d05b80fc6f199681263e063190e8325" category="paragraph">Une autre stratégie de sauvegarde consiste à utiliser une sauvegarde au niveau du système de fichiers, dans laquelle les administrateurs copient directement les fichiers utilisés par PostgreSQL pour stocker les données dans la base de données. Cette méthode s'effectue en mode hors ligne : la base de données ou le cluster doit être arrêté. Une autre alternative est d'utiliser<block ref="35679fc424d9eec0c30f38459fd9b322" prefix=" " category="inline-code"></block> Pour exécuter une sauvegarde de diffusion à chaud de la base de données PostgreSQL.</block>
  <block id="10907e7ac5ab6e5235a23898a2331b31" category="doc">Bases de données PostgreSQL sur ONTAP</block>
  <block id="841a21e58e7c22a71c07b89a4362d2b6" category="admonition">Cette documentation sur ONTAP et la base de données PostgreSQL remplace la base de données _TR-4770: PostgreSQL sur les meilleures pratiques ONTAP._</block>
  <block id="9147e5e61a7b9260dec09f3a6eb3e5be" category="doc">Snapshots</block>
  <block id="0b9d99167191c5d9ad23ca07bc6a9b38" category="paragraph">Les sauvegardes basées sur des copies Snapshot avec PostgreSQL requièrent la configuration de snapshots pour les fichiers de données, les fichiers WAL et les fichiers WAL archivés afin d'assurer une restauration complète ou instantanée.</block>
  <block id="8c6a53edc4449a4cc3983d47ecffa851" category="paragraph">Pour les bases de données PostgreSQL, la durée moyenne de sauvegarde avec des copies Snapshot est comprise entre quelques secondes et quelques minutes. Cette vitesse de sauvegarde est 60 à 100 fois plus rapide que<block ref="35679fc424d9eec0c30f38459fd9b322" prefix=" " category="inline-code"></block> et d'autres approches de sauvegarde basées sur le système de fichiers.</block>
  <block id="c798632224ae09152f66f60e0edc757e" category="paragraph">Les copies Snapshot situées sur un système de stockage NetApp peuvent être à la fois cohérentes après panne et cohérentes au niveau des applications. Un snapshot cohérent après panne est créé sur un système de stockage sans interrompre la base de données, tandis qu'un Snapshot cohérent avec les applications est créé lorsque la base de données est en mode de sauvegarde. NetApp garantit également que les copies Snapshot suivantes sont des sauvegardes incrémentielles à l'infini pour promouvoir les économies de stockage et l'efficacité réseau.</block>
  <block id="d0e369216eeac8de66e915909364970a" category="paragraph">Comme les snapshots sont rapides et n'affectent pas les performances du système, vous pouvez planifier plusieurs copies Snapshot chaque jour au lieu de créer une sauvegarde quotidienne comme avec les autres technologies de sauvegarde en streaming. Lorsqu'une opération de restauration et de restauration est nécessaire, le temps d'interruption du système est réduit grâce à deux fonctionnalités clés :</block>
  <block id="316eb8adba4d16a34c92eaf9db381b9e" category="list-text">Avec la technologie de restauration des données NetApp SnapRestore, la restauration s'exécute en quelques secondes.</block>
  <block id="c128c475c12703e37685edd6db8144bc" category="list-text">Les objectifs de point de restauration (RPO) agressifs signifient qu'il faut moins de journaux de base de données et que la restauration par progression est également accélérée.</block>
  <block id="9b9f26085ff7149d4dbb916b1db0f121" category="paragraph">Pour sauvegarder PostgreSQL, vous devez vous assurer que les volumes de données sont protégés simultanément avec WAL (groupe de cohérence) et les journaux archivés. Lorsque vous utilisez la technologie Snapshot pour copier des fichiers WAL, assurez-vous de les exécuter<block ref="a3b8c8ee15ba60bfb2b999195d2b4e7d" prefix=" " category="inline-code"></block> Pour vider toutes les entrées WAL qui doivent être archivées. Si vous videz les entrées WAL pendant la restauration, il vous suffit d'arrêter la base de données, de démonter ou de supprimer le répertoire de données existant et d'effectuer une opération SnapRestore sur le stockage. Une fois la restauration terminée, vous pouvez monter le système et le ramener à son état actuel. Pour la restauration instantanée, vous pouvez également restaurer les journaux WAL et d'archivage ; PostgreSQL décide alors du point le plus cohérent et le récupère automatiquement.</block>
  <block id="8e8d6187572eace409fee5bf2dbb7cf9" category="paragraph">Les groupes de cohérence sont une fonctionnalité de ONTAP recommandée lorsque plusieurs volumes sont montés sur une seule instance ou une base de données avec plusieurs tablespaces. Une copie Snapshot de groupe de cohérence garantit que tous les volumes sont regroupés et protégés. Pour gérer efficacement un groupe de cohérence, ONTAP vous pouvez même le cloner et créer une copie d'instance d'une base de données à des fins de test ou de développement.</block>
  <block id="7e7397a7b79323762c61941fc0e6b5f9" category="doc">Protection des données</block>
  <block id="16a49d0bc0249ef3dd42949589a0ed4e" category="doc">Espaces de stockage</block>
  <block id="d6d544de56c329d9f68bb176c6245e7c" category="paragraph">Deux tablespaces sont créés automatiquement lorsque le cluster de base de données est initialisé.</block>
  <block id="6df924905e21856e4e8b8f936767cdd6" category="paragraph">Le<block ref="bd676cbef0d168a62a062c8709af1824" prefix=" " category="inline-code"></block> l'espace table est utilisé pour les catalogues système partagés. Le<block ref="3224684b8e7208962a73daeb0bb24110" prefix=" " category="inline-code"></block> tablespace est l'espace table par défaut des bases de données templage1 et template0. Si la partition ou le volume sur lequel le cluster a été initialisé est à court d'espace et ne peut pas être étendu, un espace table peut être créé sur une partition différente et utilisé jusqu'à ce que le système puisse être reconfiguré.</block>
  <block id="364c9d7b9593277eee9477befaf9f66b" category="paragraph">Un index très utilisé peut être placé sur un disque rapide et hautement disponible, comme un périphérique SSD. Par ailleurs, une table qui stocke des données archivées rarement utilisées ou non critiques pour les performances peut être stockée sur un système sur disque moins onéreux et plus lent, tel que des disques SAS ou SATA.</block>
  <block id="9bfe8d8e1117bd1d4b8597220e3f166e" category="paragraph">Les tablespaces font partie du cluster de base de données et ne peuvent pas être traités comme un ensemble autonome de fichiers de données. Elles dépendent des métadonnées contenues dans le répertoire de données principal et ne peuvent donc pas être reliées à un autre cluster de base de données ou sauvegardées individuellement. De même, si vous perdez un espace de table (suite à la suppression d'un fichier, à une panne de disque, etc.), le cluster de base de données peut devenir illisible ou ne pas démarrer. Le fait de placer un tablespace sur un système de fichiers temporaire, tel qu'un disque RAM, risque de nuire à la fiabilité de l'ensemble du cluster.</block>
  <block id="7d9573b1ed3543ec6ea42c81830dc27c" category="paragraph">Une fois créé, un espace table peut être utilisé à partir de n'importe quelle base de données si l'utilisateur demandeur dispose de privilèges suffisants. PostgreSQL utilise des liens symboliques pour simplifier l'implémentation des tablespaces. PostgreSQL ajoute une ligne au<block ref="4a926dc6e7549c49a13755513af41e67" prefix=" " category="inline-code"></block> Tableau (table à l'échelle du cluster) et attribue un nouvel identifiant d'objet (OID) à cette ligne. Enfin, le serveur utilise l'OID pour créer un lien symbolique entre votre cluster et le répertoire donné. Le répertoire<block ref="8e3da386e945c59fb1e1cd1d7a47697c" prefix=" " category="inline-code"></block> contient des liens symboliques pointant vers chacun des tablespaces non intégrés définis dans le cluster.</block>
  <block id="249fd7d68098688fab42436eed51be7d" category="doc">Configuration de la base de données</block>
  <block id="8daf26b2c72dd18a89fa89a6b1aa988d" category="paragraph">Il existe plusieurs configurations de réglage PostgreSQL qui peuvent améliorer les performances.</block>
  <block id="abb3dae412afe5c801e9ab90de71675b" category="paragraph">Les paramètres les plus utilisés sont les suivants :</block>
  <block id="bfdf741f4acb3dfee6e87075b535610e" category="list-text"><block ref="39d79378db03fed7c5ba62efba38e327" prefix="" category="inline-code"></block>: Le nombre maximal de connexions de base de données à avoir en même temps. Utilisez ce paramètre pour limiter l'échange sur le disque et l'arrêt des performances. Selon les besoins de votre application, vous pouvez également régler ce paramètre pour les paramètres du pool de connexions.</block>
  <block id="9625e1a6f5d1f695fd1c72401afaa07e" category="list-text"><block ref="904d399f43708a8a5b6d10c1ee3f8356" prefix="" category="inline-code"></block>: La méthode la plus simple pour améliorer les performances de votre serveur de base de données. La valeur par défaut est faible pour la plupart des matériels modernes. Il est défini pendant le déploiement à environ 25 % de la RAM disponible sur le système. Ce paramètre varie en fonction de la façon dont il fonctionne avec des instances de base de données particulières ; vous devrez peut-être augmenter ou diminuer les valeurs par tâtonnement et erreur. Cependant, le réglage haut risque de dégrader les performances.</block>
  <block id="d1960c56572383fc401fec3f0b767cf9" category="list-text"><block ref="5edeed59821790d8bec6d32da26bca4c" prefix="" category="inline-code"></block>: Cette valeur indique à l'optimiseur de PostgreSQL la quantité de mémoire disponible pour la mise en cache des données et aide à déterminer si un index doit être utilisé. Une valeur plus élevée augmente la probabilité d'utiliser un index. Ce paramètre doit être défini sur la quantité de mémoire allouée à<block ref="e15ed0f69e5c2475450b97691d6a2cee" prefix=" " category="inline-code"></block> Plus la quantité de cache du système d'exploitation disponible. Cette valeur représente souvent plus de 50 % de la mémoire système totale.</block>
  <block id="508df54f84fc7abb00f3a92937ca3506" category="list-text"><block ref="1edef4d43b06d4deb28010505df5724d" prefix="" category="inline-code"></block>: Ce paramètre contrôle la quantité de mémoire à utiliser dans les opérations de tri et les tables de hachage. Si vous effectuez un tri important dans votre application, vous devrez peut-être augmenter la quantité de mémoire, mais soyez prudent. Ce n'est pas un paramètre à l'échelle du système, mais un paramètre par opération. Si une requête complexe comporte plusieurs opérations de tri, elle utilise plusieurs unités de mémoire Work_mem et plusieurs back end peuvent le faire simultanément. Cette requête peut souvent amener votre serveur de base de données à échanger si la valeur est trop élevée. Cette option était auparavant appelée sort_mem dans les anciennes versions de PostgreSQL.</block>
  <block id="59d9770060aecba84c7e8ed849b5653d" category="list-text"><block ref="65768448b4f275b95af20a317c7355a9" prefix="" category="inline-code"></block>: Ce paramètre détermine si toutes vos pages WAL doivent être synchronisées sur le disque à l'aide de fsync() avant qu'une transaction ne soit validée. Sa désactivation peut parfois améliorer les performances d'écriture et son activation renforce la protection contre le risque de corruption en cas de panne du système.</block>
  <block id="625a65dd6cef83bac66319bde3894899" category="list-text"><block ref="ff5a06a39dd6824f30a778a51cf7ea69" prefix="" category="inline-code"></block>: Le processus de point de contrôle vide les données validées sur le disque. Cela implique de nombreuses opérations de lecture/écriture sur le disque. La valeur est définie en secondes et les valeurs inférieures réduisent le temps de reprise après incident et l'augmentation des valeurs peut réduire la charge sur les ressources système en réduisant les appels au point de contrôle. En fonction de la criticité de l'application, de l'utilisation et de la disponibilité de la base de données, définissez la valeur de Checkpoint_timeout.</block>
  <block id="309b1036c45e7ad490448925dc4f9597" category="list-text"><block ref="6a5c0586429891e84e05d6ab15088405" prefix="" category="inline-code"></block> et<block ref="9080796d32078fea7d191100eab64f92" prefix=" " category="inline-code"></block>: Ces options sont utilisées ensemble pour aider à améliorer les performances en écrivant plusieurs transactions qui sont exécutées simultanément. Si plusieurs objets commit_frames sont actifs à l'instant où votre transaction est validée, le serveur attend les microsecondes commit_delay pour essayer de valider plusieurs transactions à la fois.</block>
  <block id="8d5137ce002c6328c2b5f4f328662e1d" category="list-text"><block ref="fa4ca2cd95c20a44171f964fb8f5fdb9" prefix="" category="inline-code"></block>: Configurer le nombre optimal de travailleurs pour les processus. Max_Parallel_workers correspond au nombre de CPU disponibles. Selon la conception de l'application, les requêtes peuvent nécessiter un nombre réduit de collaborateurs pour les opérations parallèles. Il est préférable de conserver la même valeur pour les deux paramètres, mais d'ajuster la valeur après le test.</block>
  <block id="c8736e7ca19e9096796c624f3030dae5" category="list-text"><block ref="8dda85a5feb6de66d8f5f9a4cbdb0754" prefix="" category="inline-code"></block>: Cette valeur contrôle la façon dont PostgreSQL affiche les lectures de disque non séquentielles. Une valeur plus élevée signifie que PostgreSQL est plus susceptible d'utiliser une analyse séquentielle au lieu d'une analyse d'index, indiquant que votre serveur a des disques rapides Modifier ce paramètre après avoir évalué d'autres options telles que l'optimisation basée sur un plan, l'aspiration, l'indexation pour modifier les requêtes ou le schéma.</block>
  <block id="17edf3863f12b7d9480b3336a9fca773" category="list-text"><block ref="709989c844c22473cb8406550423d39a" prefix="" category="inline-code"></block>: Ce paramètre définit le nombre d'opérations d'E/S de disque simultanées que PostgreSQL tente d'exécuter simultanément. L'augmentation de cette valeur augmente le nombre d'opérations d'E/S que toute session PostgreSQL individuelle tente d'initier en parallèle. La plage autorisée est comprise entre 1 et 1,000, ou zéro pour désactiver l'émission de demandes d'E/S asynchrones. Actuellement, ce paramètre n'affecte que les analyses de tas bitmap. Les disques SSD et les autres systèmes de stockage basés sur la mémoire (NVMe) peuvent souvent traiter un grand nombre de requêtes simultanées. Le meilleur choix peut donc se situer dans les centaines.</block>
  <block id="82b38edb10ad73f9645c5d65e73a659b" category="paragraph">Consultez la documentation PostgreSQL pour obtenir une liste complète des paramètres de configuration PostgreSQL.</block>
  <block id="402fbc243dbef50cd5c8e57ccbdd92f5" category="section-title">TOASTS</block>
  <block id="0d2b62abb26bd0b4109f5bc967250933" category="paragraph">TOAST est l'acronyme de Oversized-Attribute Storage technique. PostgreSQL utilise une taille de page fixe (généralement 8 Ko) et ne permet pas aux blocs de données de couvrir plusieurs pages. Par conséquent, il n'est pas possible de stocker directement des valeurs de champ importantes. Lorsque vous essayez de stocker une ligne qui dépasse cette taille, TOAST divise les données de grandes colonnes en « morceaux » plus petits et les stocke dans une table de TOASTS.</block>
  <block id="3f11f21bdc22c3c955c3f0fca39e9bc0" category="paragraph">Les grandes valeurs des attributs toastés sont extraites (si elles sont sélectionnées) uniquement au moment où le jeu de résultats est envoyé au client. La table elle-même est beaucoup plus petite et peut contenir plus de lignes dans le cache du tampon partagé qu'elle ne le pouvait sans stockage hors ligne (TOAST).</block>
  <block id="9a311ef6dad816cb7a15c0ab41920ad8" category="section-title">VIDE</block>
  <block id="385e23b8ebe64dfd0005f6846cc8e85e" category="paragraph">En mode PostgreSQL normal, les blocs de données supprimés ou rendus obsolètes par une mise à jour ne sont pas physiquement supprimés de leur table ; ils restent présents jusqu'à ce que LE VIDE soit exécuté. Par conséquent, vous devez faire fonctionner le VIDE régulièrement, en particulier sur les tables fréquemment mises à jour. L'espace qu'il occupe doit ensuite être récupéré pour réutilisation par de nouvelles lignes, afin d'éviter une panne d'espace disque. Cependant, il ne renvoie pas l'espace vers le système d'exploitation.</block>
  <block id="db81319c35b48ed94867775a9a1ce1d7" category="paragraph">L'espace libre dans une page n'est pas fragmenté. VIDE réécrit le bloc entier, en empaquant efficacement les lignes restantes et en laissant un seul bloc contigu d'espace libre dans une page.</block>
  <block id="8a5c17164c9920590fc057ee01f2fcb3" category="paragraph">En revanche, LE VIDE COMPLET composera activement les tables en écrivant une version complètement nouvelle du fichier table sans espace mort. Cette action réduit la taille de la table mais peut prendre un certain temps. Elle nécessite également de l'espace disque supplémentaire pour la nouvelle copie de la table jusqu'à ce que l'opération soit terminée. L'objectif du VIDE DE routine est d'éviter toute activité de VIDE COMPLET. Ce processus permet non seulement de conserver les tables à leur taille minimale, mais également de conserver une utilisation régulière de l'espace disque.</block>
  <block id="61bcd96a2c1f8026527cbf2019d6e9a4" category="doc">Initialisation</block>
  <block id="f4f9dac58f7c47e819293af5f2dd1177" category="paragraph">Vous créez un nouveau cluster de base de données à l'aide de<block ref="abc91e782cd3950bfa31202aff74ca69" prefix=" " category="inline-code"></block> programme. An<block ref="abc91e782cd3950bfa31202aff74ca69" prefix=" " category="inline-code"></block> script crée les fichiers de données, les tables système et les bases de données modèles (template0 et template1) qui définissent le cluster.</block>
  <block id="b668460552732302350bbb840d57931c" category="paragraph">La base de données de modèles représente une base de données de stock. Il contient des définitions pour les tables système, les vues standard, les fonctions et les types de données.<block ref="3865cf98fe802a965570b4a10a1d894b" prefix=" " category="inline-code"></block> sert d'argument à l'<block ref="abc91e782cd3950bfa31202aff74ca69" prefix=" " category="inline-code"></block> script qui spécifie l'emplacement du cluster de base de données.</block>
  <block id="8fcd14822a5b94d212898fe3e006526e" category="paragraph">Tous les objets de base de données dans PostgreSQL sont gérés en interne par les OID respectives. Les tables et les index sont également gérés par des OID individuelles. Les relations entre les objets de base de données et leurs OID respectives sont stockées dans les tables de catalogue système appropriées, selon le type d'objet. Par exemple, les OID des bases de données et des tables de segment de mémoire sont stockées dans<block ref="d0fcebb608269edbd5d67486884ebed7" prefix=" " category="inline-code"></block> et `pg_class, respectivement. Vous pouvez déterminer les OID en émettant des requêtes sur le client PostgreSQL.</block>
  <block id="d0e97e34fe92edd2facd0f7377b6340b" category="paragraph">Chaque base de données a ses propres tables et fichiers d'index qui sont limités à 1 Go. Chaque table a deux fichiers associés, avec le suffixe respectivement<block ref="7b9b00c45b01f7b7c6d3a3c8ba2e9275" prefix=" " category="inline-code"></block> et<block ref="a1d869a79e2f43693a6a416fcbdc2724" prefix=" " category="inline-code"></block>. Ils sont appelés carte de l'espace libre et carte de visibilité. Ces fichiers stockent les informations relatives à la capacité d'espace libre et ont une visibilité sur chaque page du fichier de table. Les index ne disposent que de cartes d'espace libre individuelles et ne disposent pas de cartes de visibilité.</block>
  <block id="048a7ed79caf84bb5c725efc5f474911" category="paragraph">Le<block ref="c28f4f32219f5ff99fb4b116980b8549" prefix=" " category="inline-code"></block> le répertoire contient les journaux d'écriture anticipée. Des journaux d'écriture anticipée sont utilisés pour améliorer la fiabilité et les performances de la base de données. Chaque fois que vous mettez à jour une ligne dans une table, PostgreSQL écrit d'abord la modification dans le journal d'écriture anticipée, puis écrit les modifications sur les pages de données réelles sur un disque. Le<block ref="f7223cfaa9416056a91e259e326ac5cf" prefix=" " category="inline-code"></block> le répertoire contient généralement plusieurs fichiers, mais initdb ne crée que le premier. Des fichiers supplémentaires sont ajoutés si nécessaire. Chaque fichier xlog fait 16 Mo de long.</block>
  <block id="789a6c7dd865d16eb1df122bcc5c9a3a" category="admonition">*NetApp recommande* d'utiliser NFSv4.1 si les fonctionnalités NFSv4 sont requises. Certaines améliorations fonctionnelles du protocole NFSv4 dans NFSv4.1 améliorent la résilience dans certains cas à la périphérie.</block>
  <block id="8e86e0aee135afb67c6a1d3d6e0f3306" category="inline-link-macro">Tailles de transfert NFS</block>
  <block id="d84b41126744795c4ee82f7b256e7234" category="inline-link-macro">SAN FC</block>
  <block id="2c8c2171fc87c96e58fb40d8714f85cf" category="doc">Architecture PostgreSQL</block>
  <block id="ee62b4420d426c21a46d892ac084872a" category="paragraph">PostgreSQL est un SGBDR basé sur l'architecture client et serveur. Une instance PostgreSQL est appelée cluster de base de données, qui est une collection de bases de données par opposition à une collection de serveurs.</block>
  <block id="89c30c326e106773af32af40255b92a8" category="inline-image-macro">Erreur : graphique introuvable</block>
  <block id="54c2dd41fd1ad3efa25e80bee0bae549" category="paragraph">Il existe trois éléments principaux dans une base de données PostgreSQL : le postmaster, le front end (client) et le back end Le client envoie des demandes au postmaster avec des informations telles que le protocole IP et la base de données à laquelle se connecter. Le postmaster authentifie la connexion et la transmet au processus d'arrière-plan pour une communication plus poussée. Le processus back-end exécute la requête et envoie les résultats directement au frontal (client).</block>
  <block id="9f96e07bbaf7c0237047d6d0f95301a8" category="paragraph">Une instance PostgreSQL est basée sur un modèle multiprocessus au lieu d'un modèle multithread. Il génère plusieurs processus pour différents travaux, et chaque processus possède sa propre fonctionnalité. Les principaux processus incluent le processus client, le processus WAL writer, le processus Background writer et le processus checkpointer :</block>
  <block id="6aebf901bd4be26a765c56e4133b3798" category="list-text">Lorsqu'un processus client (premier plan) envoie des demandes de lecture ou d'écriture à l'instance PostgreSQL, il ne lit pas ou n'écrit pas les données directement sur le disque. Il met d'abord en mémoire tampon les données dans des tampons partagés et des tampons WAL (Write-Ahead Logging).</block>
  <block id="458239ee6c634dc5fef96f9dfab275f0" category="list-text">Un processus WAL writer manipule le contenu des tampons partagés et des tampons WAL pour écrire dans les journaux WAL. Les journaux WAL sont généralement des journaux de transaction de PostgreSQL et sont écrits de manière séquentielle. Par conséquent, pour améliorer le temps de réponse de la base de données, PostgreSQL écrit d'abord dans les journaux de transactions et reconnaît le client.</block>
  <block id="9ec2999256fe568cd596b42e7da2cc39" category="list-text">Pour mettre la base de données dans un état cohérent, le processus de l'enregistreur d'arrière-plan vérifie périodiquement la présence de pages sales dans le tampon partagé. Il purge ensuite les données sur les fichiers de données stockés sur des volumes NetApp ou des LUN.</block>
  <block id="5c852dd8ba7215c01dfde8e98f6c46c6" category="list-text">Le processus CheckPointer s'exécute également périodiquement (moins fréquemment que le processus d'arrière-plan) et empêche toute modification des tampons. Il signale au processus d'écriture WAL d'écrire et de vider l'enregistrement de point de contrôle à la fin des journaux WAL stockés sur le disque NetApp. Il signale également au processus d'écriture d'arrière-plan d'écrire et de vider toutes les pages sales sur le disque.</block>
  <block id="0a7b1215fd0b9621d4d7300f88b2906c" category="doc">Logiciels de protection des données</block>
  <block id="e265011e47d11db43ee112fd2fdc9d5b" category="paragraph">Le plug-in NetApp SnapCenter pour les bases de données PostgreSQL, associé aux technologies Snapshot et NetApp FlexClone, vous offre les avantages suivants :</block>
  <block id="4dcdaba06a92b8fecfdc823643a71723" category="list-text">Sauvegarde et restauration rapides.</block>
  <block id="aee746a577a1baebdc33197fb5f3a279" category="list-text">Clones compacts.</block>
  <block id="b96bb0cd2ebc0389b6670602ac80d983" category="list-text">La possibilité de mettre en place un système de reprise d'activité rapide et efficace.</block>
  <block id="9e060ad00fced94f2616dd71fbc49f76" category="paragraph">Vous pouvez choisir les partenaires de sauvegarde premium de NetApp, tels que Veeam Software et CommVault dans les circonstances suivantes :</block>
  <block id="0ee17b3b55ea2b0af3d90985bc347775" category="list-text">Gestion des workloads dans un environnement hétérogène</block>
  <block id="88fbde7bbe0274fbe9e7ce01c563d03c" category="list-text">Stocker les sauvegardes dans le cloud ou sur bande pour les conserver à long terme</block>
  <block id="445e3e0cce7f959696dde65b3be27843" category="list-text">Prise en charge d'un large éventail de versions et de types de systèmes d'exploitation</block>
  <block id="21c5d67cc22beaf7d7c9c84c8deaabbe" category="paragraph">Le plug-in SnapCenter pour PostgreSQL est un plug-in pris en charge par la communauté et la configuration et la documentation sont disponibles sur le magasin d'automatisation NetApp. Grâce à SnapCenter, l'utilisateur peut sauvegarder la base de données, cloner et restaurer les données à distance.</block>
  <block id="7d334ca369e4a752ec91b1503183f0ed" category="summary">Pour SAP HANA et AnyDB</block>
  <block id="1ac73696f4529e3901b0d4e5430365cb" category="doc">SAP HANA et SAP avec AnyDB</block>
  <block id="2c1b27a986b5e37a810d61f72b23ee4b" category="paragraph">Les bonnes pratiques de configuration, de gestion et d'automatisation des solutions SAP sont disponibles sur la page Solutions SAP de NetApp.</block>
  <block id="6c92285fa6d3e827b198d120ea3ac674" category="inline-link-macro">ici</block>
  <block id="ee1e67308b27672a8f54eace4c615a98" category="paragraph">Veuillez cliquer sur <block ref="c95e4a3e1de9e00fefc4bf8a7ce42893" category="inline-link-macro-rx"></block> pour plus.</block>
  <block id="beb3ca55ed0a53a38a2b97540b05d6e4" category="summary">Microsoft SQL Server sur ONTAP</block>
  <block id="7636ae91f443b605f05bed59d7d57a02" category="doc">Reprise sur incident de Microsoft SQL Server</block>
  <block id="18c6a681ea46e1ed394e092461bb53ef" category="list-text">Distribuez les volumes contenant des données SQL Server sur différents nœuds du cluster pour permettre à tous les nœuds de cluster de partager l'activité de réplication SnapMirror. Cette distribution optimise l'utilisation des ressources du nœud.</block>
  <block id="0a01e6837f5c691536f0b6cbdd0232ec" category="inline-link-macro">Tr-4015 : Guide de configuration et des meilleures pratiques de SnapMirror pour ONTAP 9</block>
  <block id="1cca1a3fad8c6dd7e2dadbd2aa08bf07" category="paragraph">Pour plus d'informations sur SnapMirror, reportez-vous à la section <block ref="64b916f792bad525a069a243c092b62e" category="inline-link-macro-rx"></block>.</block>
  <block id="77641f4a3e4406855e878235cbd89b87" category="doc">Configuration du processeur</block>
  <block id="673c216e20d1cf8827f347c01dace664" category="paragraph">La mise en garde ici est que chaque version de SQL Server a ses propres limites sur la puissance de calcul qu'il peut utiliser. Pour plus d'informations, voir calcul des limites de capacité par édition de SQL Server.</block>
  <block id="cf0e2551e639758cc3c4d82df655eccd" category="inline-link-macro">SQL Server 2022 : une plateforme de données moderne</block>
  <block id="809c9e1f6ce0bc82bf42fae361c6f43e" category="paragraph">Par conséquent, pour utiliser tous les CPU, vous devez utiliser la licence par cœur de processeur. Pour plus d'informations sur les licences SQL Server, reportez-vous à la section <block ref="457abfaf1083b1cbfc49f2783069c6cd" category="inline-link-macro-rx"></block>.</block>
  <block id="cb8d56a3511d402b7355db8502a54c5a" category="section-title">Affinité CPU</block>
  <block id="74f896768ee487acfd4c42370c202bed" category="paragraph">SQL Server prend en charge l'affinité de processeur par deux options :</block>
  <block id="cb315fb2b62c836ba51357d46f2e8c3f" category="list-text">Masque d'affinité du processeur</block>
  <block id="cb00a2408ea648cf85edfd7dbb23fbe0" category="list-text">Masque d'E/S d'affinité</block>
  <block id="49e103832576f4486179df8868372d17" category="section-title">Degré maximal de parallélisme (MAXDOP)</block>
  <block id="a99f7ebb3b0f5b0ecea93ed586b2a17d" category="section-title">Nombre max. De threads de travail</block>
  <block id="aff27140f50a549b1331add8d5025f7e" category="paragraph">L'option max worker threads permet d'optimiser les performances lorsqu'un grand nombre de clients sont connectés à SQL Server.</block>
  <block id="decd79137325e1efbc7b994f946ea24f" category="paragraph">La valeur par défaut est 0, ce qui permet à SQL Server de configurer automatiquement le nombre de threads de travail au démarrage. Cela fonctionne pour la plupart des systèmes. Max worker threads est une option avancée qui ne doit pas être modifiée sans l'aide d'un administrateur de base de données expérimenté (DBA).</block>
  <block id="29d04e616d2293c4c7538dd6226feac5" category="section-title">Configuration du nombre maximal de threads de travail à l'aide de SQL Server Management Studio.</block>
  <block id="44dbc82801d84781083ed9e23b63be00" category="list-text">Pour &lt; ou = jusqu'à 8 cœurs : fichiers de données tempdb = nombre de cœurs</block>
  <block id="6203fcdbdad10bb603fd00edd2f0fcf5" category="list-text">Pour plus de 8 cœurs : 8 fichiers de données tempdb</block>
  <block id="0424163d6b24f29436021dfd7072863b" category="paragraph">À partir de SQL Server 2016, le nombre de cœurs de CPU visibles par le système d'exploitation est automatiquement détecté lors de l'installation et, en fonction de ce nombre, SQL Server calcule et configure le nombre de fichiers tempdb requis pour des performances optimales.</block>
  <block id="3b5b2ca12603a36517ce602ffe47361c" category="list-text">NetApp SnapCenter en tant que logiciel de sauvegarde, qui inclut :</block>
  <block id="36a92a010308100e1efc10d9eb98c369" category="list-text">Plug-in SnapCenter pour Microsoft Windows</block>
  <block id="ec51578d7d8f930329548bf3d00d7038" category="list-text">Plug-in SnapCenter pour SQL Server</block>
  <block id="a6d698a68f555339f6e91957f636ad69" category="list-text">Architecture et administration de Microsoft SQL Server</block>
  <block id="697ea025ecb303d4f40d1bf3a8b4bde0" category="inline-link-macro">Matrice d'interopérabilité NetApp (IMT)</block>
  <block id="fbd4c4f9516af91c6c3cb5fa35fb5720" category="doc">Considérations relatives au stockage Microsoft SQL Server</block>
  <block id="3da07c62fca4dd242f7ffcfcf72998be" category="section-title">Conception du stockage des données</block>
  <block id="9e45010900186b3cbbe04f954a6f3562" category="paragraph">Pour les bases de données SQL Server qui n'utilisent pas SnapCenter pour effectuer des sauvegardes, Microsoft recommande de placer les données et les fichiers journaux sur des disques distincts. Pour les applications qui mettent à jour et demandent simultanément des données, le fichier journal est très gourmand en écriture et le fichier de données (selon votre application) consomme beaucoup de ressources en lecture/écriture. Pour la récupération des données, le fichier journal n'est pas nécessaire. Par conséquent, les demandes de données peuvent être satisfaites à partir du fichier de données placé sur son propre disque.</block>
  <block id="df018ea4abdb71f91802ea1d4fb0fb37" category="inline-link-macro">Placez les fichiers de données et les fichiers journaux sur des lecteurs distincts</block>
  <block id="f2f25c68d67c561be1926b4b06e676b0" category="paragraph">Lorsque vous créez une nouvelle base de données, Microsoft recommande de spécifier des disques distincts pour les données et les journaux. Pour déplacer des fichiers après la création de la base de données, la base de données doit être mise hors ligne. Pour plus d'informations sur les recommandations de Microsoft, consultez la section <block ref="04fab8828edf0d2e95eff3c4f124b372" category="inline-link-macro-rx"></block>.</block>
  <block id="d5350d8759b1ec84607e47908809058e" category="section-title">64 bits</block>
  <block id="77f1d6b9cbcaf3663f6bdd19a821e773" category="list-text">Un seul grand agrégat permet d'optimiser l'utilisation de l'espace disque.</block>
  <block id="63d9962fabe500361986d05317bd65a5" category="paragraph">Pour la haute disponibilité (HA), placer la réplique synchrone secondaire SQL Server Always On Availability Group sur une machine virtuelle de stockage (SVM) distincte dans l'agrégat. Pour la reprise sur incident, placez la réplication asynchrone sur un agrégat faisant partie d'un cluster de stockage distinct dans le site de reprise sur incident, le contenu étant répliqué à l'aide de la technologie NetApp SnapMirror. Pour des performances de stockage optimales, NetApp recommande de disposer d'au moins 10 % d'espace libre dans un agrégat.</block>
  <block id="c6f01c78bfe0a0a495cb5d3ed77824a9" category="section-title">Volumes</block>
  <block id="17fce39141e6fa457c789ce2c3239b0c" category="section-title">Considérations relatives à la conception des volumes</block>
  <block id="d1c9fdbcdbb8521971decf35c6d1c0c8" category="paragraph">Avant de créer une conception de volume de base de données, il est important de comprendre comment le modèle et les caractéristiques d'E/S SQL Server varient en fonction de la charge de travail et des exigences de sauvegarde et de restauration. Consultez les recommandations NetApp suivantes pour les volumes flexibles :</block>
  <block id="674343739e297abb52c536a453ebaad0" category="list-text">Utilisez des points de montage NTFS au lieu de lettres de lecteur pour dépasser la limite de 26 lettres de lecteur dans Windows. Lorsque vous utilisez des points de montage de volume, il est généralement recommandé de donner au libellé de volume le même nom que le point de montage.</block>
  <block id="4176288dbc134524f79476ba4e57e3aa" category="list-text">Tempdb est une base de données système utilisée par SQL Server comme espace de travail temporaire, en particulier pour les opérations DBCC CHECKDB exigeantes en E/S. Par conséquent, placez cette base de données sur un volume dédié avec un jeu séparé de piles de disques. Dans les grands environnements dans lesquels le nombre de volumes est un défi, vous pouvez consolider tempdb en un nombre réduit de volumes et le stocker dans le même volume que les autres bases de données système après une planification minutieuse. La protection des données pour tempdb n'est pas une priorité élevée car cette base de données est recréée à chaque redémarrage de SQL Server.</block>
  <block id="b703a2ceaabee81dd9dfcfb3a4b738ee" category="list-text">Assurez-vous que les fichiers de base de données utilisateur et le répertoire des journaux pour stocker la sauvegarde des journaux se trouvent sur des volumes distincts afin d'empêcher la règle de conservation d'écraser les snapshots lorsqu'ils sont utilisés avec la technologie SnapVault.</block>
  <block id="ae72f885471636cbfd0dbe902ddf24e1" category="list-text">Si vous créez des LUN à l'aide de DiskManager ou d'autres outils, assurez-vous que la taille de l'unité d'allocation est définie sur 64 Ko pour les partitions lors du formatage des LUN.</block>
  <block id="ac4782a9243acaaff52164f9e47417d5" category="inline-link-macro">Microsoft Windows et MPIO natif conformément aux meilleures pratiques ONTAP pour les SAN modernes</block>
  <block id="934e206705ddafc720e4a8f25a4acded" category="list-text">Voir la <block ref="95506eaa4fca841adc20747ae4650d10" category="inline-link-macro-rx"></block> Pour appliquer la prise en charge des chemins d'accès multiples sur Windows aux périphériques iSCSI dans les propriétés MPIO.</block>
  <block id="31a8d85b6a44cffc2c7dfc6387696f31" category="section-title">Répertoire du journal</block>
  <block id="29766ed5967263787fface0a4ad3396f" category="paragraph">La taille du répertoire de journaux hôte est calculée comme suit :
Taille du répertoire des journaux hôtes = ( (taille LDF maximale de la base de données x taux de modification quotidien du journal %) x (rétention des snapshots) ÷ (1 - espace de surcharge de la LUN %)
La formule de dimensionnement du répertoire des journaux hôte suppose un espace supplémentaire de 10 % pour les LUN</block>
  <block id="31333b887781902e13c263570523ddc1" category="paragraph">Placez le répertoire des journaux sur un volume ou une LUN dédié. La quantité de données dans le répertoire du journal hôte dépend de la taille des sauvegardes et du nombre de jours pendant lesquels les sauvegardes sont conservées. SnapCenter n'autorise qu'un seul répertoire de journaux hôte par hôte SQL Server. Vous pouvez configurer les répertoires de journaux hôtes dans SnapCenter --&gt; hôte --&gt; configurer le plug-in.</block>
  <block id="e815059019027c04aa969a50787d5b34" category="paragraph">*NetApp recommande* ce qui suit pour un répertoire de journaux hôte :</block>
  <block id="07ae4edb1ccfbfe1f5da6006c95ee4a9" category="list-text">Assurez-vous que le répertoire du journal de l'hôte n'est partagé par aucun autre type de données pouvant potentiellement corrompre les données du snapshot de sauvegarde.</block>
  <block id="991bd1f492a593453f65c2a23c1f1612" category="list-text">Ne placez pas de bases de données utilisateur ou de bases de données système sur un LUN qui héberge des points de montage.</block>
  <block id="7b01578e73f5081fecdcc6dedf28aa3c" category="list-text">Utilisez les assistants SnapCenter pour migrer les bases de données vers le stockage NetApp de sorte que les bases de données soient stockées dans des emplacements valides, ce qui permet de réaliser les opérations de sauvegarde et de restauration SnapCenter. N'oubliez pas que le processus de migration est disruptif et peut mettre les bases de données hors ligne pendant la migration.</block>
  <block id="b2d0e2f60ee139155b728ef6933efe7c" category="list-text">Les conditions suivantes doivent être en place pour les instances de cluster de basculement (FCI) de SQL Server :</block>
  <block id="863fda0972208e1e15d0c4a16d6915af" category="list-text">Si vous utilisez une instance de cluster de basculement, la LUN du répertoire de journalisation de l'hôte doit être une ressource de disque de cluster dans le même groupe de cluster que l'instance SQL Server en cours de sauvegarde SnapCenter.</block>
  <block id="ddb1104e1e71caabad3e7639c7675af8" category="list-text">Si vous utilisez une instance de cluster de basculement, les bases de données utilisateur doivent être placées sur des LUN partagées qui sont des ressources de cluster de disques physiques affectées au groupe de clusters associé à l'instance SQL Server.</block>
  <block id="bca5f9a18696e080113088282fe481de" category="doc">Configuration de la mémoire Microsoft SQL Server</block>
  <block id="02578ec0e8ce2fbef37ca792fd20c289" category="section-title">Mémoire maximale du serveur</block>
  <block id="6e345f11e9b2856a7ac40d6cf283606b" category="paragraph">Sur un cluster SQL Server avec plusieurs instances SQL Server, chaque instance peut être en concurrence pour des ressources. La définition d'une limite de mémoire pour chaque instance de SQL Server peut aider à garantir les meilleures performances pour chaque instance.</block>
  <block id="318b34a3511a1be6d179a73303da2077" category="admonition">*NetApp recommande* de laisser au moins 4 Go à 6 Go de RAM pour le système d'exploitation afin d'éviter les problèmes de performances.</block>
  <block id="cd151dbdf946ad6bd27e1d55ea1cd029" category="section-title">Réglage de la mémoire minimale et maximale du serveur à l'aide de SQL Server Management Studio.</block>
  <block id="998c5e632fa0f987c20c182fc9322f67" category="section-title">Accès à la mémoire non uniforme</block>
  <block id="b3b5cd113ed637ebe6cb28eab322307a" category="section-title">Mémoire de création d'index</block>
  <block id="631c6718cc62ad33b6e3b3b48d754569" category="paragraph">Il contrôle la quantité maximale de RAM initialement allouée pour la création d'index. La valeur par défaut de cette option est 0, ce qui signifie qu'elle est gérée automatiquement par SQL Server. Cependant, si vous rencontrez des difficultés à créer des index, envisagez d'augmenter la valeur de cette option.</block>
  <block id="8c91aa3f5264c57bd2d2e66bd70f2ad1" category="section-title">Mémoire min. Par requête</block>
  <block id="181341700086c5e2f2259774b2aaa59c" category="inline-link-macro">Mise en œuvre de la compression de page</block>
  <block id="46c6aaf21d639d23d4f297a1f6922d9a" category="paragraph">La compression de ligne modifie le format de stockage des données. Par exemple, il change les entiers et les décimales au format de longueur variable au lieu de leur format natif de longueur fixe. Il remplace également les chaînes de caractères de longueur fixe par le format de longueur variable en éliminant les espaces vides. La compression de page implémente la compression de ligne et deux autres stratégies de compression (compression de préfixe et compression de dictionnaire). Vous trouverez plus de détails sur la compression de page dans <block ref="88eab602b149fe360da37498ad5cdeae" category="inline-link-macro-rx"></block>.</block>
  <block id="0d629ff07f9214182fa91977089ff029" category="paragraph">La compression des données est actuellement prise en charge dans les éditions entreprise, Développeur et évaluation de SQL Server 2008 et versions ultérieures. Bien que la compression puisse être effectuée par la base de données elle-même, elle est rarement observée dans un environnement SQL Server.</block>
  <block id="c6757fbc56df4ba20f0ef165aeb214d0" category="paragraph">Voici les recommandations pour la gestion de l'espace pour les fichiers de données SQL Server</block>
  <block id="46344e63db1ea2128cc47543b10a0f96" category="list-text">Utiliser le provisionnement fin dans les environnements SQL Server pour améliorer l'utilisation de l'espace et réduire les besoins globaux en stockage lorsque la fonctionnalité de garantie d'espace est utilisée.</block>
  <block id="924e1b131d6b3a2846efd1a81de8eac1" category="list-text">Utilisez le croissance automatique dans la plupart des configurations de déploiement courantes, car l'administrateur du stockage ne doit contrôler l'utilisation de l'espace dans l'agrégat.</block>
  <block id="752d71c042ef775879f6db705ccf6b31" category="section-title">Réclamations d'espace</block>
  <block id="89f8656e4e33094d6011ef9aaa8fa8de" category="paragraph">La récupération d'espace peut être lancée régulièrement pour restaurer l'espace inutilisé d'une LUN. Avec SnapCenter, vous pouvez utiliser la commande PowerShell suivante pour démarrer la récupération d'espace.</block>
  <block id="aa864feb1e600aa376e91ac119da387b" category="paragraph">Si vous devez exécuter la récupération d'espace, ce processus doit être exécuté pendant les périodes de faible activité car il consomme initialement des cycles sur l'hôte.</block>
  <block id="5c014f8939a89da0166a347a0237cf4f" category="section-title">SnapCenter</block>
  <block id="1567bc0803275089d7cbc1ffc468158c" category="inline-link-macro">Tr-4714 : guide des meilleures pratiques pour SQL Server avec NetApp SnapCenter</block>
  <block id="17f58c1b5cb5feb5dcaf49ca87298c00" category="paragraph">Pour plus d'informations sur le plug-in SQL Server pour SnapCenter, reportez-vous à la section <block ref="c94de7812b9bc9ed76b3c4005974958d" category="inline-link-macro-rx"></block>.</block>
  <block id="91a7baba41dc4b5f958101b261cf179b" category="section-title">Protection de la base de données à l'aide de snapshots T-SQL</block>
  <block id="02e19b2989ebddca9ad3778807bdc426" category="paragraph">Voici un exemple de flux de travail de sauvegarde :</block>
  <block id="bd03301405e4dd8f2460ff1788765ac4" category="list-text">Réalisez des instantanés de plusieurs bases de données sur les volumes de stockage simultanément avec les nouvelles commandes de GROUPE DE SAUVEGARDE et de SERVEUR DE SAUVEGARDE.</block>
  <block id="a3b19be7df3ddff7295558d9934cd9b6" category="list-text">Effectuer des sauvegardes COMPLÈTES ou des sauvegardes COMPLÈTES COPY_ONLY. Ces sauvegardes sont également enregistrées dans msdb.</block>
  <block id="e2d06152222f63515f4b83229cb5444c" category="list-text">Effectuez une restauration instantanée à l'aide de sauvegardes de journaux effectuées avec l'approche de streaming standard après la sauvegarde COMPLÈTE des snapshots. Les sauvegardes différentielles en continu sont également prises en charge si nécessaire.</block>
  <block id="a7a2496066febda8d325e0964e434481" category="inline-link-macro">Documentation Microsoft à connaître sur les snapshots T-SQL</block>
  <block id="bf06f3f95c5b653499bb4ac53ba44c95" category="paragraph">Pour en savoir plus, voir <block ref="2ba8392a398067f6d2e5f6e4167e9d00" category="inline-link-macro-rx"></block>.</block>
  <block id="450eb6d84ec721a20f17b7778b24b457" category="doc">Workloads Microsoft SQL Server</block>
  <block id="5306de2e4bff067a10c1c9b5aafe5920" category="paragraph">En théorie, SQL Server (64 bits) prend en charge 32,767 bases de données par instance et 524 272 To de taille de base de données, bien que l'installation standard comporte généralement plusieurs bases de données. Cependant, le nombre de bases de données que SQL Server peut gérer dépend de la charge et du matériel. Il n'est pas rare que des instances SQL Server hébergent des dizaines, des centaines, voire des milliers de petites bases de données.</block>
  <block id="9a3f42cec243006996ab4580d3ce5d56" category="paragraph">Chaque base de données se compose d'un ou plusieurs fichiers de données et d'un ou plusieurs fichiers journaux de transactions. Le journal de transactions stocke les informations sur les transactions de base de données et toutes les modifications de données effectuées par chaque session. Chaque fois que les données sont modifiées, SQL Server stocke suffisamment d'informations dans le journal de transactions pour annuler (revenir en arrière) ou rétablir (relire) l'action. Un journal de transactions SQL Server fait partie intégrante de la réputation de SQL Server en matière d'intégrité et de robustesse des données. Le journal de transactions est essentiel aux capacités d'atomicité, de cohérence, d'isolation et de durabilité (ACIDE) de SQL Server. SQL Server écrit dans le journal de transactions dès qu'une modification de la page de données se produit. Chaque instruction Data manipulation Language (DML) (par exemple, Select, INSERT, Update ou DELETE) est une transaction complète, et le journal de transactions s'assure que l'opération basée sur l'ensemble a lieu, en s'assurant de l'atomicité de la transaction.</block>
  <block id="cbe6958e46fbab53cdbdb9deb2d75938" category="paragraph">Chaque base de données possède un fichier de données primaire, qui, par défaut, possède l'extension .mdf. En outre, chaque base de données peut avoir des fichiers de base de données secondaires. Ces fichiers, par défaut, ont des extensions .ndf.</block>
  <block id="811b578b6dfbb4a4ca16ba0c0911e3df" category="paragraph">Tous les fichiers de base de données sont regroupés en groupes de fichiers. Un groupe de fichiers est l'unité logique, qui simplifie l'administration de la base de données. Ils permettent de séparer le placement d'objets logiques des fichiers de base de données physiques. Lorsque vous créez les tables d'objets de base de données, vous spécifiez dans quel groupe de fichiers elles doivent être placées sans vous soucier de la configuration du fichier de données sous-jacent.</block>
  <block id="3ac46c2f04dec9d215efbe44d307a020" category="admonition">*NetApp recommande* d'éviter l'utilisation du groupe de fichiers principal pour tout autre objet que les objets système. La création d'un groupe de fichiers distinct ou d'un ensemble de groupes de fichiers pour les objets utilisateur simplifie l'administration de la base de données et la reprise après incident, en particulier dans le cas de bases de données volumineuses.</block>
  <block id="e3fc56c012a5d0c9f92dff9b49bcc80d" category="paragraph">Vous pouvez spécifier la taille initiale du fichier et les paramètres de croissance automatique au moment de la création de la base de données ou de l'ajout de nouveaux fichiers à une base de données existante. SQL Server utilise un algorithme de remplissage proportionnel lors du choix du fichier de données dans lequel il doit écrire des données. Elle écrit une quantité de données proportionnellement à l'espace libre disponible dans les fichiers. Plus l'espace libre dans le fichier est important, plus il traite d'écritures.</block>
  <block id="91d249de86b62102d6324849de2360fe" category="admonition">*NetApp recommande* que tous les fichiers d'un seul groupe de fichiers aient les mêmes paramètres de taille initiale et de croissance automatique, avec la taille de croissance définie en mégaoctets plutôt qu'en pourcentages. Cela permet à l'algorithme de remplissage proportionnel d'équilibrer uniformément les activités d'écriture entre les fichiers de données.</block>
  <block id="54db492ee9e4d356cc8722d1f4126f77" category="paragraph">SQL Server met toujours à zéro le journal de transactions et ce comportement ne peut pas être modifié. Toutefois, vous pouvez contrôler si les fichiers de données sont mis à zéro en activant ou en désactivant l'initialisation instantanée des fichiers. L'activation de l'initialisation instantanée des fichiers permet d'accélérer la croissance des fichiers de données et de réduire le temps nécessaire à la création ou à la restauration de la base de données.</block>
  <block id="92208bd4d9c6fec3f7c1dedeca62e135" category="paragraph">Un petit risque de sécurité est associé à l'initialisation instantanée des fichiers. Lorsque cette option est activée, les parties non allouées du fichier de données peuvent contenir des informations provenant de fichiers OS précédemment supprimés. Les administrateurs de base de données peuvent examiner ces données.</block>
  <block id="2b222ad4000e6e966783fd7bc480180e" category="paragraph">Vous pouvez activer l'initialisation instantanée des fichiers en ajoutant l'autorisation sa_MANAGE_VOLUME_NAME, également appelée « effectuer une tâche de maintenance de volume » au compte de démarrage SQL Server. Vous pouvez le faire sous l'application de gestion des stratégies de sécurité locales (secpol.msc), comme indiqué dans la figure suivante. Ouvrez les propriétés de l'autorisation "effectuer une tâche de maintenance de volume" et ajoutez le compte de démarrage SQL Server à la liste des utilisateurs.</block>
  <block id="c622e0142ed854a10f98fcaa8b3487f8" category="paragraph">Pour vérifier si l'autorisation est activée, vous pouvez utiliser le code de l'exemple suivant. Ce code définit deux indicateurs de suivi qui forcent SQL Server à écrire des informations supplémentaires dans le journal d'erreurs, à créer une petite base de données et à lire le contenu du journal.</block>
  <block id="eba8c32bde087b29aaa1fe0d3bb32ef3" category="paragraph">Lorsque l'initialisation instantanée des fichiers n'est pas activée, le journal d'erreurs SQL Server indique que SQL Server met à zéro le fichier de données mdf en plus de mettre à zéro le fichier journal ldf, comme indiqué dans l'exemple suivant. Lorsque l'initialisation instantanée des fichiers est activée, elle affiche uniquement la remise à zéro du fichier journal.</block>
  <block id="37fbf1be337695452699ab9df948aa25" category="paragraph">La résolution des problèmes de performances peut s'avérer complexe, car vous devez déterminer quelle instance est la cause première. Cette question est comparée aux coûts des licences de systèmes d'exploitation et des licences SQL Server. Si les performances des applications sont primordiales, une instance dédiée est fortement recommandée.</block>
  <block id="c840abede1d1bcf78e7b3e30048c08b1" category="paragraph">Microsoft octroie des licences SQL Server par cœur au niveau du serveur et non par instance. C'est pourquoi les administrateurs de base de données sont tentés d'installer autant d'instances SQL Server que le serveur peut gérer pour réduire les coûts de licence, ce qui peut entraîner des problèmes de performances majeurs par la suite.</block>
  <block id="8a77155b45f0f2313c8ebf3d755463e5" category="admonition">*NetApp recommande* de choisir des instances SQL Server dédiées chaque fois que possible pour obtenir des performances optimales.</block>
  <block id="df7423789cebcf51de121abdae4181c3" category="summary">ONTAP et applications d'entreprise</block>
  <block id="eaf36c98b91893b7f79bd5184a23d377" category="doc">Solaris</block>
  <block id="fb04d97697a77a89d0c3f5c09cd9ba47" category="paragraph">Rubriques de configuration spécifiques au système d'exploitation Solaris.</block>
  <block id="eefc332f1bd0a0aa81d0ce222989294f" category="section-title">Options de montage Solaris NFS</block>
  <block id="3e484486d582145f6d93ca5f8c71e228" category="paragraph">Le tableau suivant répertorie les options de montage Solaris NFS pour une seule instance.</block>
  <block id="6622c14ce91b6b9683505626a5eebdd2" category="cell">Type de fichier</block>
  <block id="f18f8a29d3e2281d374f43c78cf8f0f1" category="cell">Options de montage</block>
  <block id="a45543a64530673135f37ff8f9e95e69" category="cell">Accueil ADR</block>
  <block id="93a02670f814a2df6c830194a7244ea9" category="cell"><block ref="623bbf58c0b2f552d891a1c276bcc3bc" prefix="" category="inline-code"></block></block>
  <block id="80d52d74fd5c383b43f91575d569b42c" category="cell">Fichiers de contrôle
Fichiers de données
Journaux de reprise</block>
  <block id="73cf9d3814b8678439c37316096219b1" category="cell"><block ref="4c899c62e1ffeb12078476828bb54351" prefix="" category="inline-code"></block></block>
  <block id="72d33cb5c8b7ff5f7fd6a894094b0697" category="cell"><block ref="e1f651debac4f720c13ae930ff3ca14a" prefix="" category="inline-code"></block></block>
  <block id="3f490427e0bf55dc5c837e7b0d4c651c" category="cell"><block ref="b9ce73264210e6d0faa4115ce7525610" prefix="" category="inline-code"></block></block>
  <block id="b00b0ab6e8494db1a230bf3da7f42fd6" category="paragraph">L'utilisation de<block ref="545e1db0caafaa47ef37ce893c8fb92c" prefix=" " category="inline-code"></block> il a été prouvé qu'il améliorait considérablement les performances dans les environnements des clients en supprimant la latence associée à l'acquisition et au déblocage du système de stockage. Utilisez cette option avec soin dans les environnements dans lesquels de nombreux serveurs sont configurés pour monter les mêmes systèmes de fichiers et où Oracle est configuré pour monter ces bases de données. Bien qu'il s'agisse d'une configuration très inhabituelle, elle est utilisée par un petit nombre de clients. Si une instance est démarrée une seconde fois par erreur, une corruption des données peut se produire, car Oracle ne peut pas détecter les fichiers de verrouillage sur le serveur étranger. Les verrous NFS n'offrent pas de protection ; comme dans la version NFS 3, ils sont réservés à des conseils.</block>
  <block id="f480015b57b289b7dad1473ee5c55216" category="paragraph">Parce que le<block ref="545e1db0caafaa47ef37ce893c8fb92c" prefix=" " category="inline-code"></block> et<block ref="6698a391ee8befa0ca4646a86a1bbd66" prefix=" " category="inline-code"></block> les paramètres s'excluent mutuellement, il est important que<block ref="b6a2b868e8bebfc19497b406a12a1071" prefix=" " category="inline-code"></block> est présent dans le<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> classez-les de sorte que<block ref="6887bae4cda2d09a283a165c5be3f2b8" prefix=" " category="inline-code"></block> est utilisé. Sans ce paramètre, la mise en cache du tampon du système d'exploitation hôte est utilisée et les performances peuvent être affectées.</block>
  <block id="5171d5dfdc21b0941b921796638c10a9" category="paragraph">Le tableau suivant répertorie les options de montage de Solaris NFS RAC.</block>
  <block id="38e4e10abf410c92cd13e9cb4d54ae35" category="cell"><block ref="41a82b9bd64cb001f8913a34614b00d1" prefix="" category="inline-code"></block></block>
  <block id="e72cc50c204d77a1e47f0dcc8ad28a56" category="cell">Fichiers de contrôle
Fichiers de données
Journaux de reprise</block>
  <block id="98ee9e91a49f27abbd9dc831afa9fae5" category="cell"><block ref="f3a0fd4a197a2eae60d2ef904e5366f1" prefix="" category="inline-code"></block></block>
  <block id="f93eecf9c582d76d4e14292dc34c79f8" category="cell">CRS/vote</block>
  <block id="42c82995de255264e2a8690c3149c16a" category="cell">Ressource dédiée<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block></block>
  <block id="b71e04a676ec52e65edb52c138f2ad98" category="cell"><block ref="ac15a7c050732bc5169b6c17ce30f859" prefix="" category="inline-code"></block></block>
  <block id="273f714e976e2a709a6abe18d34e4b61" category="cell">Partagée<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block></block>
  <block id="2052aa052eee25e077178cd737b68f47" category="cell"><block ref="18f533bce293643d1004086db883dd03" prefix="" category="inline-code"></block></block>
  <block id="e9d3beba8b6a40da6f8074236ca3ddbc" category="paragraph">La principale différence entre les options de montage à instance unique et RAC est l'ajout de<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> et<block ref="6698a391ee8befa0ca4646a86a1bbd66" prefix=" " category="inline-code"></block> aux options de montage. Cet ajout a pour effet de désactiver la mise en cache du système d'exploitation hôte, ce qui permet à toutes les instances du cluster RAC d'avoir une vue cohérente de l'état des données. En utilisant le<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> paramètre<block ref="b6a2b868e8bebfc19497b406a12a1071" prefix=" " category="inline-code"></block> a le même effet que la désactivation de la mise en cache de l'hôte, il est toujours nécessaire de l'utiliser<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> et<block ref="6698a391ee8befa0ca4646a86a1bbd66" prefix=" " category="inline-code"></block>.</block>
  <block id="983c4ff0cb78851d95be06277152653f" category="paragraph">La raison<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block> est requis pour le partage<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block> Les déploiements visent à faciliter la cohérence des fichiers tels que les fichiers de mots de passe Oracle et les fichiers spfiles. Si chaque instance d'un cluster RAC possède un dédié<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block>, ce paramètre n'est pas requis.</block>
  <block id="5a11994cffaa4d0a9c8594d2223e3e96" category="section-title">Options de montage Solaris UFS</block>
  <block id="130c5ffb786e38c2e6648fd53593681a" category="paragraph">NetApp recommande fortement d'utiliser l'option de montage de journalisation afin de préserver l'intégrité des données en cas de panne de l'hôte Solaris ou d'interruption de la connectivité FC. L'option de montage de la journalisation préserve également l'utilisation des sauvegardes Snapshot.</block>
  <block id="516f7006de2e9b1f7f871d961db4a1ca" category="section-title">ZFS Solaris</block>
  <block id="a92c2c52c7360246c6da2b1169e0fa50" category="paragraph">Solaris ZFS doit être installé et configuré avec soin pour offrir des performances optimales.</block>
  <block id="c9208a3ad95d5ce3d9e2ba1839426251" category="section-title">mvector</block>
  <block id="bc7e9b3c34345bf9ebe88467d6714f1b" category="paragraph">En cas de problème inattendu résultant de cette modification, vous pouvez facilement l'inverser en exécutant la commande suivante en tant que root :</block>
  <block id="6ff9f4444ac481652f4412b5e1623846" category="section-title">Noyau</block>
  <block id="78d06f587305b9e5481c8cf660693a61" category="paragraph">Pour des performances ZFS fiables, un noyau Solaris est nécessaire pour résoudre les problèmes d'alignement des LUN. Le correctif a été introduit avec le correctif 147440-19 dans Solaris 10 et avec SRU 10.5 pour Solaris 11. Utilisez uniquement Solaris 10 et versions ultérieures avec ZFS.</block>
  <block id="db8880d80ab20f2f01a010e5c454f7fb" category="section-title">Configuration du LUN</block>
  <block id="3b296d65c0c37979abe39ac7f6d8e1d8" category="paragraph">Pour configurer une LUN, effectuez les opérations suivantes :</block>
  <block id="3bdc2a5622b76404f8b0ce2fc774e69a" category="list-text">Créer une LUN de type<block ref="7bee0477f82303aa43de5d78f7b9cb05" prefix=" " category="inline-code"></block>.</block>
  <block id="c06f6c6685c06bb821295b3a6d5e580c" category="list-text">Installez le kit d'utilitaire hôte (HUK) approprié spécifié par le <block ref="b5b16f3cdb0eb25a282348ba54f8c677" category="inline-link-macro-rx"></block>.</block>
  <block id="33db73c9b3936cb8eaae825d3101f60c" category="inline-link-macro">documentation la plus récente</block>
  <block id="c8646086dca29c1d978ab285faa93709" category="list-text">Suivez les instructions du HUK exactement comme décrit. Les étapes de base sont décrites ci-dessous, mais reportez-vous au <block ref="33574dfffc2cb6d01be0edb6738c51bb" category="inline-link-macro-rx"></block> pour connaître la procédure adéquate.</block>
  <block id="6c06455cad171d61eac3593147bd71d6" category="list-text">Exécutez le<block ref="3062dc928daa4d85f6e34b6dea110a00" prefix=" " category="inline-code"></block> utilitaire de mise à jour du<block ref="d5416d340f5bec1fcb3addb6ae7d059e" prefix=" " category="inline-code"></block> fichier. Les disques SCSI seront ainsi en mesure de détecter correctement les LUN ONTAP.</block>
  <block id="7ec6668202fa9a677238143b0445102f" category="list-text">Suivez les instructions fournies par le<block ref="3062dc928daa4d85f6e34b6dea110a00" prefix=" " category="inline-code"></block> Utilitaire permettant d'activer les entrées/sorties multivoies (MPIO).</block>
  <block id="b53abe6c0013125abea171427b351ccc" category="list-text">Redémarrez. Cette étape est nécessaire pour que les modifications soient reconnues dans l'ensemble du système.</block>
  <block id="b88caedbe9708683eed783eb534ae5f6" category="list-text">Partitionnez les LUN et vérifiez qu'ils sont correctement alignés. Voir « Annexe B : Vérification de l'alignement WAFL » pour obtenir des instructions sur la façon de tester et de confirmer directement l'alignement.</block>
  <block id="a0c1c26e783204cf713b2e1f0823aab3" category="section-title">zpools</block>
  <block id="c81b8fe4a368c32102406e65fc41a227" category="inline-link-macro">Configuration du LUN</block>
  <block id="869dc3a8daf591c7f33e5bb32a4a63c9" category="paragraph">La valeur de<block ref="81df978a8e3da4bee74b135548f390f3" prefix=" " category="inline-code"></block> la valeur par défaut est 9, ce qui signifie 2^9, ou 512 octets. Pour des performances optimales, le<block ref="81df978a8e3da4bee74b135548f390f3" prefix=" " category="inline-code"></block> La valeur doit être 12 (2^12=4K). Cette valeur est définie au moment de la création du zpool et ne peut pas être modifiée, ce qui signifie que les données dans zpools avec<block ref="81df978a8e3da4bee74b135548f390f3" prefix=" " category="inline-code"></block> une migration autre que 12 doit être effectuée en copiant les données vers un nouveau zpool.</block>
  <block id="6a00a2262e030c2656588743cb031710" category="paragraph">Après avoir créé un zpool, vérifiez la valeur de<block ref="81df978a8e3da4bee74b135548f390f3" prefix=" " category="inline-code"></block> avant de continuer. Si la valeur n'est pas 12, les LUN n'ont pas été détectées correctement. Détruisez le zpool, vérifiez que toutes les étapes indiquées dans la documentation des utilitaires hôtes correspondante ont été effectuées correctement et recréez le zpool.</block>
  <block id="15ec722ce3f6694d12f89aeb5b621941" category="section-title">Zpools et LDOMS Solaris</block>
  <block id="8826ef54a7d108df25ed6921b5129cb6" category="paragraph">Les LDOMS Solaris créent une exigence supplémentaire pour s'assurer que l'alignement des E/S est correct. Bien qu'un LUN soit correctement découvert en tant que périphérique 4K, un périphérique virtuel vdsk sur un LDOM n'hérite pas de la configuration du domaine d'E/S. Le vdsk basé sur cette LUN revient par défaut à un bloc de 512 octets.</block>
  <block id="9a984f24f825e4f0bca1f36e11acbca9" category="paragraph">Un fichier de configuration supplémentaire est requis. Tout d'abord, les LDOM individuels doivent être corrigés pour le bogue Oracle 15824910 afin d'activer les options de configuration supplémentaires. Ce correctif a été porté dans toutes les versions actuellement utilisées de Solaris. Une fois le logiciel LDOM corrigé, il est prêt à configurer les nouveaux LUN correctement alignés comme suit :</block>
  <block id="e0f306ab540315b015db849b1ae9099e" category="list-text">Identifiez la ou les LUN à utiliser dans le nouveau zpool. Dans cet exemple, il s'agit du périphérique c2d1.</block>
  <block id="f469046d419183a7be08ed5a13d2c65e" category="list-text">Récupérez l'instance vdc des systèmes à utiliser pour un pool ZFS :</block>
  <block id="bcaa63dcd5db76bffd8b867e8720a272" category="list-text">Modifier<block ref="ebceeaa7b6ce5abf6c8de7177255fef5" prefix=" " category="inline-code"></block>:</block>
  <block id="ec960a08b4666fe258b6e005064378ab" category="paragraph">Cela signifie que l'instance de périphérique 1 se voit attribuer une taille de bloc de 4096.</block>
  <block id="3df4cdc476a0c3a5a930597e9d8da84c" category="paragraph">Par exemple, supposons que les instances vdsk 1 à 6 doivent être configurées pour une taille de bloc de 4 Ko et<block ref="74a491ed941b00d0c9909d488eee67bf" prefix=" " category="inline-code"></block> se lit comme suit :</block>
  <block id="dfed6d8974f03c5b31f20c9c5c2bbe66" category="list-text">La finale<block ref="3328fba80b08b36663ffae0684f6c578" prefix=" " category="inline-code"></block> le fichier doit contenir les éléments suivants :</block>
  <block id="764a2caff05993fc0d3eff5de7b225e9" category="cell">Avertissement</block>
  <block id="5c442834a7707cc96719e468c87b2ff6" category="cell">Le LDOM doit être redémarré après la configuration de vdc.conf et la création du vdsk. Cette étape ne peut pas être évitée. La modification de la taille de bloc n'est effective qu'après un redémarrage. Procéder à la configuration du pool de zpool et s'assurer que le module de transmission automatique est correctement réglé sur 12 comme décrit précédemment.</block>
  <block id="2138e0b461ac7e557539bb0b33bde81a" category="section-title">Journal des intentions ZFS (ZIL)</block>
  <block id="5477cebfd480a13008afdd16bea2b3f9" category="paragraph">En général, il n'y a aucune raison de localiser le ZFS Intent Log (ZIL) sur un autre périphérique. Le journal peut partager de l'espace avec le pool principal. L'utilisation principale d'une ZIL distincte est l'utilisation de disques physiques qui n'offrent pas les fonctionnalités de mise en cache des écritures dans les baies de stockage modernes.</block>
  <block id="26a004aeb043de19f767bd7daa39cf2f" category="section-title">biais logique</block>
  <block id="07fff183bc4c01bf9bbb21a48b389845" category="paragraph">Réglez le<block ref="26a004aeb043de19f767bd7daa39cf2f" prefix=" " category="inline-code"></block> Paramètre sur les systèmes de fichiers ZFS hébergeant les données Oracle.</block>
  <block id="ac01fbc5e98d6450f3b565d0617f4a55" category="paragraph">Ce paramètre réduit les niveaux d'écriture globaux. Sous les valeurs par défaut, les données écrites sont d'abord validées dans le ZIL, puis dans le pool de stockage principal. Cette approche est adaptée à une configuration utilisant une configuration de disque simple, qui inclut un périphérique ZIL SSD et un support rotatif pour le pool de stockage principal. En effet, elle permet une validation dans une seule transaction d'E/S sur le support à latence la plus faible disponible.</block>
  <block id="c6cc0f147c42f124079d7fc1a0761886" category="paragraph">Lorsque vous utilisez une baie de stockage moderne qui inclut sa propre capacité de mise en cache, cette approche n'est généralement pas nécessaire. Dans de rares cas, il peut être souhaitable d'effectuer une écriture avec une seule transaction dans le journal, par exemple une charge de travail composée d'écritures aléatoires hautement concentrées et sensibles à la latence. L'amplification d'écriture peut avoir des conséquences, car les données consignées sont finalement écrites dans le pool de stockage principal, ce qui double l'activité d'écriture.</block>
  <block id="92b9531657a4ce6a31c623d889a2c55d" category="section-title">E/S directes</block>
  <block id="387f4a4c250ed7a5003f3f6a19abfd1f" category="paragraph">De nombreuses applications, y compris les produits Oracle, peuvent contourner le cache du tampon hôte en activant des E/S directes Cette stratégie ne fonctionne pas comme prévu avec les systèmes de fichiers ZFS. Bien que le cache du tampon hôte soit contourné, ZFS lui-même continue à mettre en cache les données. Cette action peut entraîner des résultats trompeurs lors de l'utilisation d'outils tels que fio ou Sio pour effectuer des tests de performances. En effet, il est difficile de prévoir si les E/S atteignent le système de stockage ou si elles sont mises en cache localement au sein du système d'exploitation. Cette action rend également très difficile l'utilisation de tels tests synthétiques pour comparer les performances ZFS aux autres systèmes de fichiers. D'un point de vue pratique, les performances du système de fichiers varient considérablement, voire nulle, pour les charges de travail réelles des utilisateurs.</block>
  <block id="ec79b30d56e7bae54aa7efedccc47e93" category="section-title">Plusieurs zpools</block>
  <block id="f5aa5b31f0536ddcdb748ae360d91358" category="paragraph">Les sauvegardes, les restaurations, les clones et l'archivage des données ZFS basés sur des snapshots doivent être effectués au niveau du zpool et requièrent généralement plusieurs zpools. Un zpool est similaire à un groupe de disques LVM et doit être configuré à l'aide des mêmes règles. Par exemple, il est probablement préférable de définir au mieux une base de données avec les fichiers de données résidant sur<block ref="f1fb162e58045170396a0ac29d648fa5" prefix=" " category="inline-code"></block> ainsi que les journaux d'archivage, les fichiers de contrôle et les journaux de reprise qui résident sur<block ref="92073f03d18c8eaec3eb5e0908210e1a" prefix=" " category="inline-code"></block>. Cette approche permet une sauvegarde à chaud standard dans laquelle la base de données est placée en mode de sauvegarde à chaud, suivie d'un snapshot de<block ref="f1fb162e58045170396a0ac29d648fa5" prefix=" " category="inline-code"></block>. La base de données est alors supprimée du mode de sauvegarde à chaud, l'archivage des journaux est forcé et un instantané de<block ref="92073f03d18c8eaec3eb5e0908210e1a" prefix=" " category="inline-code"></block> est créé. Une opération de restauration nécessite de démonter les systèmes de fichiers zfs et de mettre hors ligne le zpool dans son intégralité, après une opération de restauration SnapRestore. Le zpool peut alors être remis en ligne et la base de données récupérée.</block>
  <block id="f1110589be196c2310808482067fce1b" category="section-title">filesytemio_options</block>
  <block id="c271ff9f255f2d215054d508448781a3" category="paragraph">Le paramètre Oracle<block ref="f1110589be196c2310808482067fce1b" prefix=" " category="inline-code"></block> Fonctionne différemment avec ZFS. Si<block ref="aef8f91b1e026cc1bb55e8b08c491d35" prefix=" " category="inline-code"></block> ou<block ref="6887bae4cda2d09a283a165c5be3f2b8" prefix=" " category="inline-code"></block> Est utilisé, les opérations d'écriture sont synchrones et contournent le cache du tampon du système d'exploitation, mais les lectures sont mises en tampon par ZFS. Cette action engendre des difficultés dans l'analyse des performances, car les E/S sont parfois interceptées et traitées par le cache ZFS, ce qui rend la latence du stockage et les E/S totales inférieures à ce qu'elles semblent être.</block>
  <block id="b1fd823d262032e04291313f72be9452" category="doc">HP-UX</block>
  <block id="8ec258cd0b6ab050fc478a415a20f2e9" category="section-title">Options de montage NFS HP-UX</block>
  <block id="7c5876d5737071c64af78562fe375386" category="paragraph">Le tableau suivant répertorie les options de montage NFS HP-UX pour une seule instance.</block>
  <block id="9c9fb3cc18a83e4e46165b5c3d4ce8ef" category="cell">Fichiers de contrôle
Fichiers de données
Journaux de reprise</block>
  <block id="55b835c747261995c0e1022d234e286d" category="cell"><block ref="fa8766c679857b7d589983df0ab5bcf4" prefix="" category="inline-code"></block></block>
  <block id="189dbd39cabd57c5d2e51714d9a5b85b" category="paragraph">Le tableau suivant répertorie les options de montage NFS HP-UX pour RAC.</block>
  <block id="fa9da3a6a7ef8986a94c7395577c322f" category="cell"><block ref="8b080dc74532d24847a6163dcc34d93f" prefix="" category="inline-code"></block></block>
  <block id="add42ff64fa5b57e5abeab49d154a9d9" category="cell"><block ref="acdef4af05a9f0c43f72b7c600f04d62" prefix="" category="inline-code"></block></block>
  <block id="c88a7b7f83f761f7fc2979815d210140" category="cell"><block ref="d29d7b7ed8c19a99fe17fd7f3d07ea7b" prefix="" category="inline-code"></block></block>
  <block id="af8831a1b8129b099114c3237a61db88" category="paragraph">La principale différence entre les options de montage à instance unique et RAC est l'ajout de<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> et<block ref="6698a391ee8befa0ca4646a86a1bbd66" prefix=" " category="inline-code"></block> aux options de montage. Cet ajout a pour effet de désactiver la mise en cache du système d'exploitation hôte, ce qui permet à toutes les instances du cluster RAC d'avoir une vue cohérente de l'état des données. En utilisant le<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> paramètre<block ref="b6a2b868e8bebfc19497b406a12a1071" prefix=" " category="inline-code"></block> a le même effet que la désactivation de la mise en cache de l'hôte, il est toujours nécessaire de l'utiliser<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> et<block ref="6698a391ee8befa0ca4646a86a1bbd66" prefix=" " category="inline-code"></block>.</block>
  <block id="b865c6aba24c3f61595471aab993d27c" category="paragraph">La raison<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> est requis pour le partage<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block> Les déploiements visent à faciliter la cohérence des fichiers tels que les fichiers de mots de passe Oracle et les fichiers spfiles. Si chaque instance d'un cluster RAC possède un dédié<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block>, ce paramètre n'est pas requis.</block>
  <block id="898311d838a2fa2fa41b4b52a63a7f1d" category="section-title">Options de montage HP-UX VxFS</block>
  <block id="85b4a3d44370909d395ab8af28ff4927" category="paragraph">Utilisez les options de montage suivantes pour les systèmes de fichiers hébergeant les binaires Oracle :</block>
  <block id="6630bbc9a901be0d038b2c39e2faf65d" category="paragraph">Utilisez les options de montage suivantes pour les systèmes de fichiers contenant des fichiers de données, des journaux de reprise, des journaux d'archivage et des fichiers de contrôle dans lesquels la version de HP-UX ne prend pas en charge les E/S simultanées :</block>
  <block id="ed37730e0f28a631768a396e7898e197" category="paragraph">Lorsque des E/S simultanées sont prises en charge (VxFS 5.0.1 et versions ultérieures, ou avec ServiceGuard Storage Management Suite), utilisez ces options de montage pour les systèmes de fichiers contenant des fichiers de données, des journaux de reprise, des journaux d'archivage et des fichiers de contrôle :</block>
  <block id="f51ddb98d92e83609db075add5fba4d8" category="admonition">Le paramètre<block ref="d3cc759510a3aba837fc8efeb2e24b91" prefix=" " category="inline-code"></block> Est particulièrement critique dans les environnements VxFS. Oracle recommande que ce paramètre ne soit pas défini dans Oracle 10g R1 et versions ultérieures, sauf indication contraire. La taille de bloc Oracle de 8 Ko par défaut est 128. Si la valeur de ce paramètre est forcée à 16 ou moins, retirer le<block ref="a6b02283cba560dcfdea44af66ec792c" prefix=" " category="inline-code"></block> Option de montage car elle peut endommager les performances des E/S séquentielles. Cette étape nuit à d'autres aspects de la performance et ne doit être prise que si la valeur de<block ref="d3cc759510a3aba837fc8efeb2e24b91" prefix=" " category="inline-code"></block> doit être modifié par rapport à la valeur par défaut.</block>
  <block id="5802d9527a43305e9e1c903bc6b5a721" category="paragraph">Rubriques de configuration spécifiques au système d'exploitation Linux utilisant AFD et ASMlib</block>
  <block id="2681013be5b0a9063a7ef0a8fe4d31da" category="section-title">Tailles de bloc ASMlib</block>
  <block id="1943673cc25055e93f0129f2baa8f499" category="paragraph">ASMlib est une bibliothèque de gestion ASM facultative et des utilitaires associés. Sa valeur principale est la capacité de tamponner un LUN ou un fichier NFS en tant que ressource ASM avec une étiquette lisible par l'utilisateur.</block>
  <block id="51713fdb873939c9c333273947776b8e" category="paragraph">Les versions récentes d'ASMlib détectent un paramètre LUN appelé blocs logiques par exposant de bloc physique (LBPPBE). Cette valeur n'a été signalée que récemment par la cible SCSI ONTAP. Elle renvoie désormais une valeur qui indique qu'une taille de bloc de 4 Ko est recommandée. Il ne s'agit pas d'une définition de la taille de bloc, mais il est un indice pour toute application utilisant LBPPBE que les E/S d'une certaine taille peuvent être gérées plus efficacement. Cependant, ASMlib interprète LBPPBE comme une taille de bloc et estampille constamment l'en-tête ASM lors de la création du périphérique ASM.</block>
  <block id="65242d5b49071240043eeef598415104" category="paragraph">Ce processus peut causer des problèmes avec les mises à niveau et les migrations de différentes manières, tous en fonction de l'incapacité à mélanger des périphériques ASMlib avec des tailles de bloc différentes dans le même groupe de disques ASM.</block>
  <block id="ea884eec0628302adc731211dc4e2cc7" category="paragraph">Par exemple, des tableaux plus anciens ont généralement signalé une valeur LBPPBE de 0 ou n'ont pas signalé cette valeur du tout. ASMlib l'interprète comme une taille de bloc de 512 octets. Pour les baies plus récentes, la taille de bloc est de 4 Ko. Il n'est pas possible de mélanger des périphériques de 512 octets et de 4 Ko dans le même groupe de disques ASM. Cela empêche un utilisateur d'augmenter la taille du groupe de disques ASM en utilisant des LUN de deux baies ou en utilisant ASM comme outil de migration. Dans d'autres cas, RMAN pourrait ne pas permettre la copie de fichiers entre un groupe de disques ASM avec une taille de bloc de 512 octets et un groupe de disques ASM avec une taille de bloc de 4 Ko.</block>
  <block id="f17ff15b23b87f35906ece98842a080f" category="paragraph">La solution préférée est de corriger ASMlib. L'ID de bug Oracle est 13999609 et le correctif est présent dans oracleasm-support-2.1.8-1 et versions ultérieures. Ce correctif permet à un utilisateur de définir le paramètre<block ref="442e2026c8afecc4611b52331b5d0d56" prefix=" " category="inline-code"></block> à<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> dans le<block ref="92a59ba9a0643a344be2d72cfd504181" prefix=" " category="inline-code"></block> fichier de configuration. Cela empêche ASMlib d'utiliser le paramètre LBPPBE, ce qui signifie que les LUN de la nouvelle baie sont maintenant reconnues comme des périphériques de bloc de 512 octets.</block>
  <block id="f140ff6b2b71e70e551e39dacb9561ef" category="admonition">L'option ne modifie pas la taille de bloc sur les LUN précédemment estampées par ASMlib. Par exemple, si un groupe de disques ASM avec des blocs de 512 octets doit être migré vers un nouveau système de stockage qui signale un bloc de 4 Ko, l'option<block ref="442e2026c8afecc4611b52331b5d0d56" prefix=" " category="inline-code"></block> Doit être défini avant que les nouvelles LUN soient estampées avec ASMlib.  Si les périphériques ont déjà été estampillés par oracleasm, ils doivent être reformatés avant d'être repoussées avec une nouvelle taille de bloc. Commencez par déconfigurer le périphérique avec<block ref="41bd8c47b8e640da7bdb5c7dc995d435" prefix=" " category="inline-code"></block>, Puis effacez le premier 1 Go du périphérique avec<block ref="85c2e94baaf4d9c084e19d290907596e" prefix=" " category="inline-code"></block>. Enfin, si le périphérique a déjà été partitionné, utilisez le<block ref="9a287d63dabd6fbcbbe1b12344bfe922" prefix=" " category="inline-code"></block> Commande permettant de supprimer les partitions obsolètes ou de simplement redémarrer le système d'exploitation.</block>
  <block id="75ad83418241561186f96dfed5229aaa" category="paragraph">Si ASMlib ne peut pas être corrigé, ASMlib peut être supprimé de la configuration. Ce changement est perturbateur et nécessite le démarquage des disques ASM et s'assurer que le<block ref="0802edf7303a95bdecde832bbbe3a89c" prefix=" " category="inline-code"></block> le paramètre est défini correctement. Toutefois, cette modification ne nécessite pas la migration des données.</block>
  <block id="ad9ac4c6d7ed2e11bdcf8c693658a482" category="section-title">Tailles de bloc d'entraînement de filtre ASM (AFD)</block>
  <block id="de59cd97a61c9f9964a35d2cd8b05c88" category="paragraph">AFD est une bibliothèque de gestion ASM facultative qui remplace ASMlib. Du point de vue du stockage, il est très similaire à ASMlib, mais il inclut des fonctionnalités supplémentaires telles que la capacité de bloquer les E/S non-Oracle afin de réduire les risques d'erreurs d'utilisateur ou d'application susceptibles de corrompre les données.</block>
  <block id="36dc27685773851e52f035f82e3deba2" category="section-title">Tailles des blocs de périphériques</block>
  <block id="1ef92cf7e561e179d6079cc937b2778a" category="paragraph">Comme ASMlib, AFD lit également le paramètre LUN blocs logiques par exposant de bloc physique (LBPPBE) et utilise par défaut la taille de bloc physique, et non la taille de bloc logique.</block>
  <block id="b95ce6c503801cb15f2f9c0773c58f00" category="paragraph">Cela peut créer un problème si l'AFD est ajouté à une configuration existante où les périphériques ASM sont déjà formatés comme des périphériques de bloc de 512 octets. Le pilote AFD reconnaîtrait le LUN comme un périphérique 4K et l'incompatibilité entre l'étiquette ASM et le périphérique physique empêcherait l'accès. De même, les migrations seraient affectées, car il n'est pas possible de combiner des périphériques de 512 octets et de 4 Ko dans le même groupe de disques ASM. Cela empêche un utilisateur d'augmenter la taille du groupe de disques ASM en utilisant des LUN de deux baies ou en utilisant ASM comme outil de migration. Dans d'autres cas, RMAN pourrait ne pas permettre la copie de fichiers entre un groupe de disques ASM avec une taille de bloc de 512 octets et un groupe de disques ASM avec une taille de bloc de 4 Ko.</block>
  <block id="7ef45d3a7c5fff234bf42bdf549b8339" category="paragraph">La solution est simple - AFD inclut un paramètre pour contrôler si elle utilise les tailles de bloc logiques ou physiques. Il s'agit d'un paramètre global affectant tous les périphériques du système. Pour forcer AFD à utiliser la taille de bloc logique, définissez<block ref="722fc896569f3d455bb5ef8f5b8c3703" prefix=" " category="inline-code"></block> dans le<block ref="dcd5fd81543c5e08e927c54e89acdd40" prefix=" " category="inline-code"></block> fichier.</block>
  <block id="47b0d7fc4c27720c4fc326722edad27c" category="section-title">Tailles de transfert multivoie</block>
  <block id="7c329811bcc7bb2f50005da5a3aff250" category="paragraph">Les modifications récentes du noyau linux appliquent des restrictions de taille d'E/S envoyées aux périphériques à chemins d'accès multiples, et AFD ne respecte pas ces restrictions. Les E/S sont ensuite rejetées, ce qui entraîne la mise hors ligne du chemin d'accès à la LUN. Il en résulte une incapacité à installer Oracle Grid, à configurer ASM ou à créer une base de données.</block>
  <block id="926e4b7a2822a39a07f61474b92e9d8c" category="paragraph">La solution consiste à spécifier manuellement la longueur de transfert maximale dans le fichier multipath.conf pour les LUN ONTAP :</block>
  <block id="3d0c741146f1e8e31bc7d07128ca6e0a" category="admonition">Même si aucun problème n'existe actuellement, ce paramètre doit être défini si l'AFD est utilisé pour garantir qu'une future mise à niveau de linux ne provoque pas de problèmes inattendus.</block>
  <block id="d99ae60d37a12f766bc2a1f1c228fb4f" category="section-title">E/S simultanées</block>
  <block id="0f3eb508f611e203aeffa91d5753648a" category="paragraph">Pour obtenir des performances optimales sur IBM AIX, il est nécessaire d'utiliser des E/S simultanées Sans E/S simultanées, les limites de performances sont probablement dues au fait qu'AIX exécute des E/S atomiques sérialisées, ce qui entraîne une surcharge importante.</block>
  <block id="ecdc41fc6a2adf7e41e7277e12eeb805" category="paragraph">À l'origine, NetApp a recommandé d'utiliser le<block ref="4482571a249db31b3abed938e4567a15" prefix=" " category="inline-code"></block> Option de montage pour forcer l'utilisation d'E/S simultanées sur le système de fichiers, mais ce processus présente des inconvénients et n'est plus nécessaire. Depuis l'introduction d'AIX 5.2 et d'Oracle 10gR1, Oracle sous AIX peut ouvrir des fichiers individuels pour des E/S simultanées, au lieu de forcer des E/S simultanées sur l'ensemble du système de fichiers.</block>
  <block id="445b433b62b675f0ca0bda7acb56d41b" category="paragraph">La meilleure méthode pour activer les E/S simultanées est de définir le<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> paramètre<block ref="f1110589be196c2310808482067fce1b" prefix=" " category="inline-code"></block> à<block ref="aef8f91b1e026cc1bb55e8b08c491d35" prefix=" " category="inline-code"></block>. Oracle peut ainsi ouvrir des fichiers spécifiques pour une utilisation avec des E/S simultanées</block>
  <block id="6206c23a0282b18352573158f9a8f9b3" category="paragraph">À l'aide de<block ref="4482571a249db31b3abed938e4567a15" prefix=" " category="inline-code"></block> En tant qu'option de montage, force l'utilisation d'E/S simultanées, ce qui peut avoir des conséquences négatives. Par exemple, forcer des E/S simultanées désactive la lecture anticipée sur les systèmes de fichiers, ce qui peut nuire aux performances des E/S se produisant en dehors du logiciel de base de données Oracle, comme la copie de fichiers et les sauvegardes sur bande. En outre, les produits tels qu'Oracle GoldenGate et SAP BR*Tools ne sont pas compatibles avec l'utilisation du<block ref="4482571a249db31b3abed938e4567a15" prefix=" " category="inline-code"></block> Option de montage avec certaines versions d'Oracle.</block>
  <block id="770cb9a1e9321ca3012ecbb9ec65c422" category="list-text">N'utilisez pas le<block ref="4482571a249db31b3abed938e4567a15" prefix=" " category="inline-code"></block> option de montage au niveau du système de fichiers. Activez plutôt les E/S simultanées via l'utilisation de<block ref="b6a2b868e8bebfc19497b406a12a1071" prefix=" " category="inline-code"></block>.</block>
  <block id="872080b7d5ec5585776f1426fb157842" category="list-text">Utilisez uniquement le<block ref="4482571a249db31b3abed938e4567a15" prefix=" " category="inline-code"></block> l'option de montage doit être définie si elle n'est pas possible<block ref="b6a2b868e8bebfc19497b406a12a1071" prefix=" " category="inline-code"></block>.</block>
  <block id="0c5d86482201f32acb30cd2f7de3048f" category="section-title">Options de montage NFS AIX</block>
  <block id="1ce07cafb2507c98c8b96ad5f35fb66a" category="paragraph">Le tableau suivant répertorie les options de montage NFS AIX pour les bases de données Oracle à instance unique.</block>
  <block id="9a8f040dae3f0f15b337fe69a85239c0" category="cell"><block ref="86d38d6e2b36f6557e583e005e23d258" prefix="" category="inline-code"></block></block>
  <block id="d45a1a2afa30c30042b28f028fe75953" category="cell"><block ref="915be14765d6133923d803e1221f1513" prefix="" category="inline-code"></block></block>
  <block id="b74f5956b4bcda2de3c82ee97e192ab6" category="paragraph">Le tableau suivant répertorie les options de montage NFS AIX pour RAC.</block>
  <block id="b547b55ba7f2a20602494777c5426eba" category="cell"><block ref="7e879bda961bd5b7d64d2ef4f5fb7869" prefix="" category="inline-code"></block></block>
  <block id="875abb256654bd3f6da7abcb1bd92f27" category="cell"><block ref="f93eecf9c582d76d4e14292dc34c79f8" prefix="" category="inline-code"></block></block>
  <block id="3ed8fb68917b28af138fb74ccde62e80" category="cell"><block ref="415e8eb8b9fc05cb48e633d31fd04944" prefix="" category="inline-code"></block></block>
  <block id="8102775fe4080f632332ab8d3312311a" category="paragraph">La principale différence entre les options de montage à instance unique et RAC est l'ajout de<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> aux options de montage. Cet ajout a pour effet de désactiver la mise en cache du système d'exploitation hôte qui permet à toutes les instances du cluster RAC d'avoir une vue cohérente de l'état des données.</block>
  <block id="1e3f10dfa324520cb7261c0da5bf6ec7" category="paragraph">En utilisant le<block ref="4482571a249db31b3abed938e4567a15" prefix=" " category="inline-code"></block> option de montage et<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> paramètre<block ref="b6a2b868e8bebfc19497b406a12a1071" prefix=" " category="inline-code"></block> a le même effet que la désactivation de la mise en cache de l'hôte, il est toujours nécessaire de l'utiliser<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block>.<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> est requis pour le partage<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block> Déploiements pour faciliter la cohérence des fichiers tels que les fichiers de mots de passe Oracle et<block ref="1737629d60b511cf45957529a8f046e2" prefix=" " category="inline-code"></block> fichiers de paramètres. Si chaque instance d'un cluster RAC possède un dédié<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block>, ce paramètre n'est pas requis.</block>
  <block id="5365dd1a92461c9e6cf65017c4a11647" category="section-title">Options de montage AIX jfs/jfs2</block>
  <block id="d7a578263480a2003f05c459a8961298" category="paragraph">Le tableau suivant répertorie les options de montage AIX jfs/jfs2.</block>
  <block id="0aabf727ab0a83c5f5d078e8b18445e0" category="cell">Valeurs par défaut</block>
  <block id="e1f651debac4f720c13ae930ff3ca14a" category="cell">ORACLE_HOME</block>
  <block id="27a7ffa293f5a4d2a5bb54354486dece" category="paragraph">Avant d'utiliser AIX<block ref="b7cc91287fc99a8937a55e79376c6f54" prefix=" " category="inline-code"></block> dans tout environnement, y compris les bases de données, vérifiez le paramètre<block ref="9d51746070ef554ad4e93a16de4aed0f" prefix=" " category="inline-code"></block>. Ce paramètre n'est pas la profondeur de la file d'attente HBA ; il se rapporte plutôt à la profondeur de la file d'attente SCSI de l'individu<block ref="66ad66c6ace8456eae4ca6807552e54b" prefix=" " category="inline-code"></block> peut être trop faible pour de bonnes performances. Les tests ont montré que la valeur optimale est de 64.</block>
  <block id="bb79f96acbff544ded541446c9c7c894" category="doc">Microsoft Windows</block>
  <block id="14ce2582c2080a7f08fe9249f6565f40" category="paragraph">Oracle prend en charge l'utilisation de Microsoft Windows avec le client NFS direct. Cette fonctionnalité offre les avantages de NFS en termes de gestion, notamment la possibilité d'afficher les fichiers dans les différents environnements, de redimensionner les volumes de façon dynamique et d'exploiter un protocole IP moins onéreux. Pour plus d'informations sur l'installation et la configuration d'une base de données sous Microsoft Windows à l'aide de dNFS, reportez-vous à la documentation officielle d'Oracle. Il n'existe pas de meilleures pratiques spéciales.</block>
  <block id="f854b764258138b512f30be71e1c7908" category="paragraph">Pour une efficacité de compression optimale, assurez-vous que le système de fichiers NTFS utilise une unité d'allocation de 8 Ko ou plus. L'utilisation d'une unité d'allocation 4K, qui est généralement la valeur par défaut, a un impact négatif sur l'efficacité de la compression.</block>
  <block id="edc9f0a5a5d57797bf68e37364743831" category="doc">Linux</block>
  <block id="dfc95ed5e895617bbd0d4b1a8bfba8ca" category="paragraph">Rubriques de configuration spécifiques au système d'exploitation Linux.</block>
  <block id="5ecd4a6f4aedfdd45cce80a18b1a7942" category="section-title">Tables de rainures</block>
  <block id="2518e65e64213437c921c39a097db167" category="section-title">Options de montage NFS Linux</block>
  <block id="29cd2e6d4fc96e749c4a0e622cad7f50" category="paragraph">Le tableau suivant répertorie les options de montage NFS Linux pour une seule instance.</block>
  <block id="9fafd031075cede0e8a5a796ec45fbff" category="paragraph">Le tableau suivant répertorie les options de montage NFS Linux pour RAC.</block>
  <block id="f16135915fe2ca5c3b0d660acc0325d3" category="cell"><block ref="4c927b3193f1cd00c7cfd3ac2e7ba8ea" prefix="" category="inline-code"></block></block>
  <block id="fc1ea13514277ff14dc705f62c31c0fc" category="cell"><block ref="4d0511346ac74044d79c9bc297d59b09" prefix="" category="inline-code"></block></block>
  <block id="13c64659680c0bc3603209997cc22225" category="cell">CRS/vote</block>
  <block id="672c5eef2603018159295408f761324b" category="cell"><block ref="26b20bdf0b0e7d3ddef3749a70c17932" prefix="" category="inline-code"></block></block>
  <block id="f7085c7dc406f5b44813ac43c18b80c0" category="paragraph">La principale différence entre les options de montage à instance unique et RAC est l'ajout de<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block> aux options de montage. Cet ajout a pour effet de désactiver la mise en cache du système d'exploitation hôte, ce qui permet à toutes les instances du cluster RAC d'avoir une vue cohérente de l'état des données. En utilisant le<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> paramètre<block ref="b6a2b868e8bebfc19497b406a12a1071" prefix=" " category="inline-code"></block> a le même effet que la désactivation de la mise en cache de l'hôte, il est toujours nécessaire de l'utiliser<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block>.</block>
  <block id="d2537738f34705bc9d100925252c0102" category="paragraph">La raison<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block> est requis pour le partage<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block> Les déploiements visent à faciliter la cohérence des fichiers tels que les fichiers de mots de passe Oracle et les fichiers spfiles. Si chaque instance d'un cluster RAC possède un dédié<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block>, ce paramètre n'est pas requis.</block>
  <block id="5084019c1051a9937b5ff77568ce579b" category="paragraph">En règle générale, les fichiers ne provenant pas de bases de données doivent être montés avec les mêmes options que celles utilisées pour les fichiers de données à instance unique. Toutefois, certaines applications peuvent avoir des exigences différentes. Évitez les options de montage<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> et<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block> si possible parce que ces options désactivent la lecture et la mise en mémoire tampon au niveau du système de fichiers. Cela peut entraîner de graves problèmes de performances pour les processus tels que l'extraction, la translation et le chargement.</block>
  <block id="243de27c01fea05cc58186d2e5ad1ce5" category="section-title">ACCESS et GETATTR</block>
  <block id="59dcf78e97c197a0f240067da57a248f" category="paragraph">Certains clients ont remarqué qu'un niveau extrêmement élevé d'autres IOPS, comme L'ACCÈS et GETATTR, peut dominer leurs charges de travail. Dans des cas extrêmes, les opérations telles que les lectures et les écritures peuvent représenter jusqu'à 10 % du total. Il s'agit d'un comportement normal avec toute base de données qui inclut l'utilisation de<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block> et/ou<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> Sous Linux car ces options font que le système d'exploitation Linux recharge en permanence les métadonnées de fichiers à partir du système de stockage. Les opérations telles que ACCESS et GETATTR sont des opérations à faible impact qui sont traitées à partir du cache ONTAP dans un environnement de base de données. Elles ne doivent pas être considérées comme des IOPS authentiques, comme les lectures et les écritures, qui génèrent une véritable demande pour les systèmes de stockage. Cependant, ces autres IOPS créent une certaine charge, en particulier dans les environnements RAC. Pour résoudre ce problème, activez dNFS, qui contourne le cache du tampon du système d'exploitation et évite ces opérations de métadonnées inutiles.</block>
  <block id="041f371e212c70407e145ae9f752a8b4" category="section-title">NFS direct Linux</block>
  <block id="dd2f3f344f14ae5daf12cb0a817a72e0" category="paragraph">Une option de montage supplémentaire, appelée<block ref="4740c034d97ca90a96b8050082816605" prefix=" " category="inline-code"></block>, Est requis lorsque (a) dNFS est activé et (b) qu'un volume source est monté plusieurs fois sur un seul serveur (c) avec un montage NFS imbriqué. Cette configuration est principalement utilisée dans les environnements prenant en charge les applications SAP. Par exemple, un seul volume sur un système NetApp peut avoir un répertoire situé sur<block ref="9f9f4ccb1fc3afcbfe0cc3f5eac4332c" prefix=" " category="inline-code"></block> et une seconde à<block ref="ac2f9bbcd397d8f6b39e6713658051ea" prefix=" " category="inline-code"></block>. Si<block ref="9f9f4ccb1fc3afcbfe0cc3f5eac4332c" prefix=" " category="inline-code"></block> est monté à<block ref="9ad16912cc0ba54a259b1a15d233c264" prefix=" " category="inline-code"></block> et<block ref="ac2f9bbcd397d8f6b39e6713658051ea" prefix=" " category="inline-code"></block> est monté à<block ref="1da707b60c3b55bd01cb7df7c171a368" prefix=" " category="inline-code"></block>, Le résultat est des montages NFS imbriqués qui proviennent de la même source.</block>
  <block id="14dd7af30f62ec838445a1e167d2aff6" category="section-title">Linux Direct NFS et Oracle RAC</block>
  <block id="c6a209e4ad702c6424efb7d63d76feca" category="paragraph">DNFS présente des avantages spéciaux en matière de performances pour Oracle RAC sur le système d'exploitation Linux. En effet, Linux ne dispose pas d'une méthode permettant de forcer les E/S directes, qui est requise avec RAC pour assurer la cohérence entre les nœuds. Pour contourner ce problème, Linux nécessite l'utilisation du<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block> Mount option, qui entraîne l'expiration immédiate des données de fichier à partir du cache du système d'exploitation. Cette option force à son tour le client Linux NFS à relire en permanence les données d'attributs, ce qui endommage la latence et augmente la charge sur le contrôleur de stockage.</block>
  <block id="3070cb366c38db327b0cf057d63792c1" category="paragraph">L'activation de dNFS contourne le client NFS hôte et évite ces dommages. Plusieurs clients ont signalé une amélioration significative des performances sur les clusters RAC et une baisse significative de la charge ONTAP (en particulier par rapport aux autres IOPS) lors de l'activation de dNFS.</block>
  <block id="e97ab7f94d503bbec4b013b5b77118c6" category="section-title">Linux Direct NFS et fichier orangfstab</block>
  <block id="f63255b70940d25581e0cf5f81dd6cd6" category="paragraph">Si vous utilisez dNFS sur Linux avec l'option de chemins d'accès multiples, vous devez utiliser plusieurs sous-réseaux. Sur d'autres systèmes d'exploitation, vous pouvez établir plusieurs canaux dNFS à l'aide du<block ref="54b4c4075463b2e02cd69f5cd139b5b2" prefix=" " category="inline-code"></block> et<block ref="bbf52a1a57a4eaa83512cab68fd52b70" prefix=" " category="inline-code"></block> Options de configuration de plusieurs canaux dNFS sur un même sous-réseau. Cependant, cela ne fonctionne pas correctement sur Linux et des problèmes de performances inattendus peuvent survenir. Sous Linux, chaque carte réseau utilisée pour le trafic dNFS doit se trouver sur un sous-réseau différent.</block>
  <block id="6c5cf31ca1af553b1f4a9b99e3cb054c" category="section-title">Planificateur d'E/S.</block>
  <block id="49bb1f5f4810e5f3d32dac84bd96005d" category="paragraph">Le noyau Linux permet un contrôle de bas niveau sur la façon dont les E/S sont planifiées pour bloquer les périphériques. Les valeurs par défaut sur les différentes distributions de Linux varient considérablement. Les tests montrent que la date limite offre habituellement les meilleurs résultats, mais il arrive que le NOOP ait été légèrement meilleur. La différence de performance est minime, mais testez les deux options s'il est nécessaire d'extraire les performances maximales d'une configuration de base de données. Dans de nombreuses configurations, le paramètre CFQ est le paramètre par défaut. Il a démontré des problèmes de performances significatifs avec les charges de travail de la base de données.</block>
  <block id="38f25b8840d56fc601af1024115764b2" category="paragraph">Pour plus d'informations sur la configuration du planificateur d'E/S, reportez-vous à la documentation du fournisseur Linux correspondant.</block>
  <block id="4150162ad42bffea7bb903b4c7a4ffd9" category="section-title">Chemins d'accès multiples</block>
  <block id="305482bf1c318f0a9a04f94987db06b2" category="paragraph">Certains clients ont rencontré des pannes durant une interruption du réseau, car le démon multivoie ne s'exécutait pas sur leur système. Sur les versions récentes de Linux, le processus d'installation du système d'exploitation et le démon de chemins d'accès multiples peuvent exposer ces systèmes d'exploitation à ce problème. Les packages sont installés correctement, mais ils ne sont pas configurés pour un démarrage automatique après un redémarrage.</block>
  <block id="6fb0bf499bef576f56e0fd6360eba0a6" category="paragraph">Par exemple, la valeur par défaut du démon multiacheminement sur RHEL5.5 peut apparaître comme suit :</block>
  <block id="31026ba0b77cbe4c9d44ed6afc859ed6" category="paragraph">Ceci peut être corrigé à l'aide des commandes suivantes :</block>
  <block id="c759a9b7e4db09da8a25fb73d256f6b7" category="section-title">Mise en miroir ASM</block>
  <block id="f2f41836b42c08199948378b4a4a6e26" category="paragraph">La mise en miroir ASM peut nécessiter des modifications des paramètres de chemins d'accès multiples Linux pour permettre à ASM de reconnaître un problème et de basculer vers un autre groupe de pannes. La plupart des configurations ASM sur ONTAP reposent sur une redondance externe. La protection des données est assurée par la baie externe et ASM ne met pas en miroir les données. Certains sites utilisent ASM avec redondance normale pour fournir une mise en miroir bidirectionnelle, généralement entre différents sites.</block>
  <block id="25f47751ccd5df99e3c25a8eb2a21fc5" category="inline-link-macro">Documentation des utilitaires hôtes NetApp</block>
  <block id="066a79b72a430b074cdc0476b67bbde3" category="paragraph">Les paramètres Linux indiqués dans le <block ref="210658f6fe0d0061c73c19a9a6b263d1" category="inline-link-macro-rx"></block> Incluez les paramètres de chemins d'accès multiples qui entraînent une mise en file d'attente illimitée des E/S. Cela signifie qu'une E/S sur un périphérique LUN sans chemin d'accès actif attend tant que les E/S sont terminées. Cette opération est généralement souhaitable, car les hôtes Linux attendent tant que nécessaire la fin des modifications du chemin SAN, le redémarrage des commutateurs FC ou le basculement d'un système de stockage.</block>
  <block id="184ea23c04f24d03fc0123bc6eb30de2" category="paragraph">Ce comportement de mise en file d'attente illimité cause un problème de mise en miroir ASM car ASM doit recevoir une erreur d'E/S pour qu'il puisse réessayer d'E/S sur une autre LUN.</block>
  <block id="5616945ee545765b51d3fe1871cff4ec" category="paragraph">Définissez les paramètres suivants dans Linux<block ref="9ac80d53ede05256c28cf9e043eb423c" prefix=" " category="inline-code"></block> Fichier pour les LUN ASM utilisés avec la mise en miroir ASM :</block>
  <block id="49af3bbe0c557480960d217b217502ff" category="paragraph">Ces paramètres créent une temporisation de 120 secondes pour les périphériques ASM. Le délai d'attente est calculé comme étant le<block ref="e2f0125c5971e1ce714f86f145386ee3" prefix=" " category="inline-code"></block> *<block ref="9434de34302b4f40887a7277cf35a8fc" prefix=" " category="inline-code"></block> en secondes. Il peut être nécessaire d'ajuster la valeur exacte dans certaines circonstances, mais un délai de 120 secondes doit être suffisant pour la plupart des utilisations. En particulier, 120 secondes doivent permettre un basculement ou un retour du contrôleur sans générer d'erreur d'E/S susceptible de mettre le groupe défaillant hors ligne.</block>
  <block id="dbff1dc161f3f1d61258259b3a0b549c" category="paragraph">Un plus bas<block ref="9434de34302b4f40887a7277cf35a8fc" prefix=" " category="inline-code"></block> La valeur peut réduire le temps nécessaire à ASM pour passer à un autre groupe de pannes, mais augmente également le risque de basculement indésirable lors des activités de maintenance, telles qu'une prise de contrôle. Le risque peut être atténué par une surveillance attentive de l'état de mise en miroir ASM. Si un basculement indésirable se produit, les miroirs peuvent être rapidement resynchronisés si la resynchronisation est effectuée relativement rapidement. Pour plus d'informations, consultez la documentation Oracle sur ASM Fast Mirror Resync pour la version du logiciel Oracle utilisé.</block>
  <block id="ec0b68df6b5a0fdd6d73ac710b9684da" category="section-title">Options de montage Linux xfs, ext3 et ext4</block>
  <block id="278230e4238d02fcb49850454e7d79e0" category="admonition">*NetApp recommande* d'utiliser les options de montage par défaut.</block>
  <block id="02a5a4d50c5112bb31ff9c94f5b47ce9" category="paragraph">De nombreux clients d'Oracle sur ONTAP utilisent ethernet, le protocole réseau de NFS, iSCSI, NVMe/TCP, en particulier le cloud.</block>
  <block id="8a1870adbe8a237106c32d72660a9c42" category="summary">Conception d'interface logique pour les bases de données Oracle</block>
  <block id="f46a94d438563c03413adfec27c6bfda" category="paragraph">Les bases de données Oracle doivent accéder au stockage. Les interfaces logiques (LIF) correspondent à la tuyauterie réseau qui connecte une machine virtuelle de stockage (SVM) au réseau et, par conséquent, à la base de données. Une conception correcte des LIF est requise pour s'assurer qu'il y a suffisamment de bande passante pour chaque charge de travail de la base de données, et le basculement ne provoque pas de perte des services de stockage.</block>
  <block id="f445528d334d486a14570735705e2223" category="summary">Configuration réseau FC pour les bases de données Oracle</block>
  <block id="92cdde4ecc529b9f9379ed2bdb6aae34" category="paragraph">La configuration de FC SAN pour les bases de données Oracle consiste principalement à suivre les meilleures pratiques quotidiennes en matière de SAN.</block>
  <block id="9eaca569c6f5ca3388f5613da3aa008c" category="doc">Bases de données Oracle sur ONTAP</block>
  <block id="528b35962f1679204260ddef6800eece" category="paragraph">ONTAP est conçu pour les bases de données Oracle. Pendant des décennies, ONTAP a été optimisé pour les demandes uniques d'E/S de bases de données relationnelles. Plusieurs fonctionnalités ONTAP ont été créées spécifiquement pour répondre aux besoins des bases de données Oracle, et même à la demande d'Oracle Inc. Elle-même.</block>
  <block id="c9f8ef2db64ce19b15d2cc98fbd3d24c" category="admonition">Cette documentation remplace les rapports techniques publiés précédemment _TR-3633 : bases de données Oracle sur ONTAP ; TR-4591 : protection des données Oracle : sauvegarde, restauration, réplication ; TR-4592 : Oracle sur MetroCluster ; et TR-4534 : migration de bases de données Oracle vers des systèmes de stockage NetApp_</block>
  <block id="b42ad0517ef7394f97178fb9e1de8d78" category="paragraph">Outre les nombreuses possibilités offertes par ONTAP pour valoriser votre environnement de base de données, les besoins des utilisateurs sont très variés, notamment en termes de taille de la base de données, de performances et de protection des données. Les déploiements de systèmes de stockage NetApp prennent des formes diverses, qu'il s'agisse d'un environnement virtualisé incluant environ 6,000 bases de données fonctionnant sous VMware ESX ou d'un data warehouse à instance unique dont la taille de 996 To ne cesse de croître. Par conséquent, il existe peu de bonnes pratiques claires pour la configuration d'une base de données Oracle sur un système de stockage NetApp.</block>
  <block id="7bf0493f27e81fe4c3740e773e137a48" category="paragraph">Les exigences relatives à l'exploitation d'une base de données Oracle sur un stockage NetApp sont traitées de deux manières. Tout d'abord, lorsqu'il existe une bonne pratique claire, elle sera appelée spécifiquement. D'une manière générale, de nombreuses considérations de conception à prendre en compte par les architectes de solutions de stockage Oracle en fonction de leurs besoins spécifiques seront expliquées.</block>
  <block id="633d94718c25247da5772ed6f2b244c9" category="summary">Introduction à la migration du stockage Oracle</block>
  <block id="08beeb11d62fd51ef2742eae3ee3719f" category="admonition">Cette documentation remplace le rapport technique _TR-4534 : migration des bases de données Oracle vers des systèmes de stockage NetApp_</block>
  <block id="5f2a4190824fd64be3c8cabeb7dc62ff" category="paragraph">Dans le cas d'un nouveau projet de base de données, cela ne pose pas de problème car les environnements de base de données et d'application sont construits en place. Cependant, la migration pose des défis particuliers en ce qui concerne les interruptions d'activité, le temps nécessaire à la réalisation de la migration, les compétences requises et la réduction des risques.</block>
  <block id="a83f1ca5ad00b39773d9e6a26b0e70b2" category="section-title">Scripts</block>
  <block id="08293bec81c296b61f4a751175d9caa7" category="paragraph">Des exemples de scripts sont fournis dans cette documentation. Ces scripts fournissent des exemples de méthodes d'automatisation de divers aspects de la migration afin de réduire le risque d'erreurs des utilisateurs. Les scripts réduisent les demandes globales de l'équipe INFORMATIQUE responsable de la migration et accélèrent le processus global. Ces scripts sont issus de projets de migration réalisés par les services professionnels de NetApp et les partenaires NetApp. Des exemples de leur utilisation sont présentés dans cette documentation.</block>
  <block id="c28b52826242c7cdffe5f3ae1e917f61" category="paragraph">Certaines perturbations lors de l'importation d'une LUN étrangère sont inévitables en raison de la nécessité de modifier la configuration du réseau FC. Cependant, l'interruption ne doit pas durer beaucoup plus longtemps que le temps nécessaire pour redémarrer l'environnement de base de données et mettre à jour la segmentation FC pour basculer la connectivité FC de l'hôte de la LUN étrangère vers ONTAP.</block>
  <block id="a2248459756ffc1877beb9b39c77668b" category="paragraph">Ce processus peut être résumé comme suit :</block>
  <block id="c9f77905e39abbada6c73a7a3d5f51f8" category="list-text">Mettez toutes les activités de LUN au repos sur les LUN étrangères.</block>
  <block id="cff6e7c6c4f8dd7e57a0286f28712c58" category="list-text">Rediriger les connexions FC de l'hôte vers le nouveau système ONTAP.</block>
  <block id="9fea842823b73e1eb32307ab325f170e" category="list-text">Déclencher le processus d'importation.</block>
  <block id="df814ea2bf92d4f18e72a648e93103a2" category="list-text">Redécouvrez les LUN.</block>
  <block id="030a5009bbe6fb141ca5863ab6c59464" category="list-text">Redémarrez la base de données.</block>
  <block id="f3bb22d18791c042e889671ad1963239" category="paragraph">Inutile d'attendre la fin du processus de migration. Dès que la migration d'une LUN donnée commence, celle-ci est disponible sur ONTAP et peut assurer le service des données pendant que le processus de copie des données se poursuit. Toutes les lectures sont transmises au LUN étranger et toutes les écritures sont écrites de manière synchrone sur les deux baies. L'opération de copie est très rapide et la surcharge liée à la redirection du trafic FC est minimale. Par conséquent, tout impact sur les performances doit être transitoire et minimal. En cas de problème, vous pouvez retarder le redémarrage de l'environnement jusqu'à ce que le processus de migration soit terminé et que les relations d'importation aient été supprimées.</block>
  <block id="b19e17ab765f91aa0bc0e7152f13779f" category="section-title">Arrêtez la base de données</block>
  <block id="2869cd69e0fec20ba28a42e74afef158" category="paragraph">Dans cet exemple, la première étape de la mise en veille de l'environnement consiste à arrêter la base de données.</block>
  <block id="e20dab0880a91f5da2ea05170177576d" category="section-title">Fermez les services de grille</block>
  <block id="89c458e5176d6caf0690f1e61ecb0620" category="paragraph">L'un des systèmes de fichiers SAN en cours de migration inclut également les services Oracle ASM. La mise en veille des LUN sous-jacentes nécessite la suspension des systèmes de fichiers, ce qui signifie l'arrêt des processus avec des fichiers ouverts sur ce système de fichiers.</block>
  <block id="49f05bf7da4eacfa4c80bb987443eb5a" category="section-title">Démonter les systèmes de fichiers</block>
  <block id="c5a09ac3ff0bb25c97951c7b7f815cd0" category="paragraph">Si tous les processus sont arrêtés, l'opération de montage a réussi. Si l'autorisation est refusée, il doit y avoir un processus avec un verrou sur le système de fichiers. Le<block ref="ace112f9725b6fa0b702e6b3970b2102" prefix=" " category="inline-code"></block> permet d'identifier ces processus.</block>
  <block id="765e13ffc3361a9fd6c6088b2603ffbf" category="section-title">Désactiver les groupes de volumes</block>
  <block id="907e5f35f70dc2f5e4b67da56381bdf4" category="paragraph">Une fois tous les systèmes de fichiers d'un groupe de volumes donné démontés, le groupe de volumes peut être désactivé.</block>
  <block id="ad80f935ccd133a802189e3c2f4421d7" category="section-title">Modifications du réseau FC</block>
  <block id="a497da6790d9ab4bb5cce3d04b0efd2e" category="paragraph">Les zones FC peuvent maintenant être mises à jour pour supprimer tout accès de l'hôte à la baie étrangère et établir l'accès à ONTAP.</block>
  <block id="3ef31115a10790468ad841ec2cdf566f" category="section-title">Démarrer le processus d'importation</block>
  <block id="5bc309ef1913ddc70534a0a7135ba938" category="paragraph">Pour démarrer les processus d'importation de LUN, exécutez<block ref="76ffc50817aa4cd6214aa0061339fdf6" prefix=" " category="inline-code"></block> commande.</block>
  <block id="0a10f1ad4a0b45d384c5771ec0906c4c" category="section-title">Surveiller la progression de l'importation</block>
  <block id="9a3a7545f4a7407ec022c4b2271e0c34" category="paragraph">L'opération d'importation peut être surveillée avec<block ref="1ab15ef2c245a4434fcea3cc3149f4f4" prefix=" " category="inline-code"></block> commande. Comme indiqué ci-dessous, l'importation des 20 LUN est en cours, ce qui signifie que les données sont désormais accessibles via ONTAP, même si la copie des données progresse.</block>
  <block id="d36f98c8a305e33483232e7b5cd90c49" category="inline-link-macro">Importation de LUN étrangères—fin</block>
  <block id="a9c97f84ee4958d39ed989b3da7ed0ba" category="paragraph">Si vous avez besoin d'une migration en ligne, redécouvrez les LUN de leur nouveau domicile et accédez aux services.</block>
  <block id="d0369936c6fe8c292874e3bc647893b8" category="section-title">Recherchez les modifications de périphérique SCSI</block>
  <block id="6d338faddede649cab4c5b498e8e4379" category="paragraph">Dans la plupart des cas, l'option la plus simple pour redécouvrir de nouvelles LUN consiste à redémarrer l'hôte. Cela supprime automatiquement les anciens périphériques obsolètes, détecte correctement toutes les nouvelles LUN et construit les périphériques associés, tels que les périphériques multivoies. L'exemple ci-dessous montre un processus entièrement en ligne à des fins de démonstration.</block>
  <block id="3b493a859f19779c1f7db7d1951785ee" category="paragraph">Attention : avant de redémarrer un hôte, assurez-vous que toutes les entrées dans<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block> Les ressources SAN migrées de cette référence sont commentées. Si ce n'est pas le cas et si des problèmes surviennent lors de l'accès aux LUN, le système d'exploitation risque de ne pas démarrer. Cette situation n'endommage pas les données. Cependant, il peut être très peu commode de démarrer en mode de secours ou un mode similaire et de corriger le<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block> Afin que le système d'exploitation puisse être démarré pour permettre le dépannage.</block>
  <block id="9d7b16568eb7edb80492b49cb02d7663" category="paragraph">Les LUN de la version de Linux utilisée dans cet exemple peuvent être renumérisées avec<block ref="b6f75508bf2af141e9de6f862662661e" prefix=" " category="inline-code"></block> commande. Si la commande réussit, chaque chemin de LUN doit apparaître dans le résultat de la commande. Le résultat de cette commande peut être difficile à interpréter, mais si la configuration de zoning et d'igroup était correcte, de nombreuses LUN doivent apparaître et inclure un<block ref="971c047750d8e3b03c71d24020b3816f" prefix=" " category="inline-code"></block> chaîne du fournisseur.</block>
  <block id="3384aa7c090758ad18028832967b143f" category="section-title">Vérifiez la présence de périphériques multivoies</block>
  <block id="07a39d42e6d8cc61e0a880e43b83e2a3" category="paragraph">Le processus de découverte des LUN déclenche également la recréation des périphériques multivoies, mais il est connu que le pilote de chemins d'accès multiples Linux présente des problèmes occasionnels. La sortie de<block ref="eeb30d005cab1d8c69785a3cd5818f55" prefix=" " category="inline-code"></block> doit être vérifié pour vérifier que la sortie semble correcte. Par exemple, le résultat ci-dessous affiche les périphériques à chemins d'accès multiples associés à un<block ref="971c047750d8e3b03c71d24020b3816f" prefix=" " category="inline-code"></block> chaîne du fournisseur. Chaque périphérique a quatre chemins, dont deux avec une priorité de 50 et deux avec une priorité de 10. Bien que le résultat exact puisse varier selon les versions de Linux, ce résultat semble normal.</block>
  <block id="efd921479c3d57448954050760c568ca" category="admonition">Reportez-vous à la documentation des utilitaires hôtes pour connaître la version de Linux que vous utilisez pour vérifier que l'<block ref="dd5ff67ba72768d33f75e645aa2b8e56" prefix=" " category="inline-code"></block> les paramètres sont corrects.</block>
  <block id="28751dc1e914a778d11ca0e69613690b" category="section-title">Réactiver le groupe de volumes LVM</block>
  <block id="a66a38e4056f28a310ef6d1fa8bbcc77" category="paragraph">Si les LUN LVM ont été correctement découvertes, le système<block ref="5239f542d8edbc4b528b1f362153c0c7" prefix=" " category="inline-code"></block> la commande doit réussir. C'est un bon exemple de la valeur d'un gestionnaire de volumes logiques. Une modification du WWN d'une LUN ou même d'un numéro de série n'est pas importante, car les métadonnées du groupe de volumes sont écrites sur la LUN elle-même.</block>
  <block id="1d374f8de5ba1b82ab4407b8c6efbd0d" category="paragraph">Le système d'exploitation a analysé les LUN et découvert une petite quantité de données écrites sur la LUN qui l'identifie comme un volume physique appartenant au système<block ref="83b7788c8e4de444d6cd4c69978eaf32" prefix=" " category="inline-code"></block>. Il a ensuite construit tous les périphériques requis. Il suffit de réactiver le groupe de volumes.</block>
  <block id="1f0285a57b2357507c3b77ce5130b548" category="section-title">Remonter les systèmes de fichiers</block>
  <block id="a9047d68dc7e99f553b71590cff301d6" category="paragraph">Une fois le groupe de volumes réactivé, les systèmes de fichiers peuvent être montés avec toutes les données d'origine intactes. Comme nous l'avons vu précédemment, les systèmes de fichiers sont pleinement opérationnels, même si la réplication des données est toujours active dans le groupe en arrière-plan.</block>
  <block id="a787d65e2525ac6bc3a6328efe383b5c" category="section-title">Rechercher à nouveau les périphériques ASM</block>
  <block id="a25bb20f07ed95a633f623678855e8dc" category="paragraph">Les périphériques ASMlib auraient dû être redécouverts lorsque les périphériques SCSI ont été renumérisés. La redécouverte peut être vérifiée en ligne en redémarrant ASMlib puis en analysant les disques.</block>
  <block id="37fb12a52b4a5371c12209e89e09b04f" category="admonition">Cette étape concerne uniquement les configurations ASM où ASMlib est utilisé.</block>
  <block id="6de48f39063d81d53fd0ff3e9938af13" category="paragraph">Attention : lorsque ASMlib n'est pas utilisé, le<block ref="9c9f766701f811ef6f170c7a3453c53f" prefix=" " category="inline-code"></block> les périphériques doivent avoir été recréés automatiquement. Cependant, les autorisations peuvent ne pas être correctes. Vous devez définir des autorisations spéciales sur les périphériques sous-jacents pour ASM en l'absence d'ASMlib. Cette opération est généralement réalisée par des entrées spéciales dans l'un ou l'autre des<block ref="dd5ff67ba72768d33f75e645aa2b8e56" prefix=" " category="inline-code"></block> ou<block ref="ab775c875d5f89d991a670444dd32ad2" prefix=" " category="inline-code"></block> ou éventuellement dans les deux jeux de règles. Ces fichiers peuvent avoir besoin d'être mis à jour pour refléter les modifications de l'environnement en termes de WWN ou de numéros de série afin de s'assurer que les périphériques ASM disposent toujours des autorisations appropriées.</block>
  <block id="08b33d6af4ec78f99dbbc3533589aafc" category="paragraph">Dans cet exemple, le redémarrage d'ASMlib et l'analyse des disques affichent les 10 mêmes LUN ASM que l'environnement d'origine.</block>
  <block id="17c4ae76000d9a79a56195071665af32" category="section-title">Redémarrez les services de grille</block>
  <block id="e8c3dc00e15826e3b77a2d41d7fde92a" category="paragraph">Maintenant que les périphériques LVM et ASM sont en ligne et disponibles, les services de grille peuvent être redémarrés.</block>
  <block id="934317e45581988a01f54761705ca58a" category="section-title">Redémarrez la base de données</block>
  <block id="41475a737e947d73c674b90e78e246a0" category="paragraph">Une fois les services de grille redémarrés, la base de données peut être ouverte. Il peut être nécessaire d'attendre quelques minutes que les services ASM soient entièrement disponibles avant d'essayer de démarrer la base de données.</block>
  <block id="b171714b39ad4102aced4daceef8c678" category="paragraph">Du point de vue de l'hôte, la migration est terminée, mais les E/S sont toujours servies depuis la baie étrangère jusqu'à ce que les relations d'importation soient supprimées.</block>
  <block id="f708d001227724fa0a8a3d57aacedb1a" category="paragraph">Avant de supprimer les relations, vous devez confirmer que le processus de migration est terminé pour toutes les LUN.</block>
  <block id="85cf20229bc9008553794abdaed507f5" category="section-title">Supprimer les relations d'importation</block>
  <block id="b23ec325eb9c6278cb36e4c45c2c3499" category="paragraph">Une fois le processus de migration terminé, supprimez la relation de migration. Une fois que vous avez terminé, les E/S sont servies exclusivement à partir des disques sur ONTAP.</block>
  <block id="40b98b0023a7eea7c432c29e3c44ba7d" category="section-title">Désenregistrer des LUN étrangères</block>
  <block id="5ccc14ae93ba94bd4183439a9f80f6c8" category="paragraph">Enfin, modifiez le disque pour retirer le<block ref="96ea0e5f46787e93e2970a086b47fdb6" prefix=" " category="inline-code"></block> désignation.</block>
  <block id="875bb561ba851d301052704e0ffb70f4" category="summary">Migration Oracle via l'envoi de journaux</block>
  <block id="e0f9c3b73fe5700df95f30eb98ca4034" category="doc">Envoi de journaux Oracle</block>
  <block id="8e42b5809657e127c7e2d24f30bc493e" category="paragraph">L'objectif d'une migration à l'aide de l'envoi de journaux est de créer une copie des fichiers de données d'origine à un nouvel emplacement, puis d'établir une méthode d'expédition des modifications dans le nouvel environnement.</block>
  <block id="599df5f564506c95624dd78b0b75eeac" category="paragraph">Une fois établie, l'envoi et la relecture des journaux peuvent être automatisés afin de maintenir la base de données de réplica largement synchronisée avec la source. Par exemple, une tâche cron peut être planifiée pour (a) copier les journaux les plus récents vers le nouvel emplacement et (b) les relire toutes les 15 minutes. L'interruption au moment de la mise en service est ainsi minimale, car la lecture des journaux d'archivage ne doit pas dépasser 15 minutes.</block>
  <block id="41bec1b4ddc17b3367c68a025c0ddfb9" category="paragraph">La procédure présentée ci-dessous est également essentiellement une opération de clonage de base de données. La logique illustrée est similaire au moteur de NetApp SnapManager pour Oracle (SMO) et du plug-in Oracle NetApp SnapCenter. Certains clients ont utilisé la procédure présentée dans des scripts ou des workflows WFA pour des opérations de clonage personnalisé. Bien que cette procédure soit plus manuelle qu'avec SMO ou SnapCenter, elle reste facilement scriptée, et les API de gestion des données de ONTAP simplifient davantage le processus.</block>
  <block id="f0616883a5ca70aa97676de436a7fb9e" category="section-title">Envoi de journaux - système de fichiers vers le système de fichiers</block>
  <block id="8f922b64f0bc64f6bba1d555a61ee3bb" category="paragraph">Cet exemple illustre la migration d'une base de données appelée WAFFLE d'un système de fichiers ordinaire vers un autre système de fichiers ordinaire situé sur un serveur différent. Il illustre également l'utilisation de SnapMirror pour effectuer une copie rapide des fichiers de données, mais cela ne fait pas partie intégrante de la procédure globale.</block>
  <block id="60100e1b826a4b972fc113c391f932e7" category="section-title">Créer une sauvegarde de base de données</block>
  <block id="80cf34e10dcfbc5e76c6b2f845f2708d" category="paragraph">La première étape consiste à créer une sauvegarde de base de données. Plus précisément, cette procédure nécessite un ensemble de fichiers de données pouvant être utilisés pour la relecture des journaux d'archivage.</block>
  <block id="0ba29c6a1afacf586b03a26162c72274" category="section-title">De production</block>
  <block id="744a73803cdac4a5067725ca5814a2cf" category="section-title">Restaurer dans un nouvel environnement</block>
  <block id="46228bb2ce31b0d397faad2b805e8a37" category="paragraph">La sauvegarde doit maintenant être restaurée dans le nouvel environnement. Cette opération peut être effectuée de plusieurs façons, notamment Oracle RMAN, la restauration à partir d'une application de sauvegarde comme NetBackup ou une simple opération de copie des fichiers de données placés en mode de sauvegarde à chaud.</block>
  <block id="1f255556546f1fdfb53692e41f35eb6c" category="list-text">Créez un volume pour recevoir les données de snapshot. Initialiser la mise en miroir à partir de<block ref="937e9fa808ccfe9a4f6b004a2a7caada" prefix=" " category="inline-code"></block> à<block ref="96f9dacb3cb1b1f6f9b4ad02992a1a0e" prefix=" " category="inline-code"></block>.</block>
  <block id="5b1944ec8c0ed933e5b2ea2e3e5fa76e" category="list-text">Une fois l'état défini par SnapMirror, indiquant que la synchronisation est terminée, mettre à jour le miroir en fonction du snapshot souhaité.</block>
  <block id="f4d90c6c29b1f76ab9c87a9996c9751e" category="list-text">La synchronisation peut être vérifiée en affichant le<block ref="31952c255e722053d4cc3f82921e95db" prefix=" " category="inline-code"></block> champ sur le volume miroir.</block>
  <block id="0934c3fcad3065c2a479125e4a80b259" category="list-text">Le miroir peut alors être cassé.</block>
  <block id="fcf1f505b94151a36eba8e1563e7176f" category="list-text">Montez le nouveau système de fichiers.avec les systèmes de fichiers en mode bloc, les procédures précises varient en fonction du LVM utilisé. Le zoning FC ou les connexions iSCSI doivent être configurés. Une fois la connectivité aux LUN établie, des commandes telles que Linux<block ref="302c49bbd5bcda5463eb5130804effc1" prefix=" " category="inline-code"></block> Il peut être nécessaire de déterminer quels groupes de volumes ou LUN doivent être configurés correctement pour être détectables par ASM.</block>
  <block id="20c4d1d4163c2463cf15ff7df6424459" category="paragraph">Dans cet exemple, un simple système de fichiers NFS est utilisé. Ce système de fichiers peut être monté directement.</block>
  <block id="b2dd88a1f03a5fb4c2e3c0d46f425161" category="section-title">Créer un modèle de création de fichier de contrôle</block>
  <block id="1c30e11140f1d0a1093bedee34eef1e4" category="paragraph">Vous devez ensuite créer un modèle de fichier de contrôle. Le<block ref="3177841b2335a6640ea3054199830f1c" prefix=" " category="inline-code"></block> commande crée des commandes texte pour recréer un fichier de contrôle. Dans certaines circonstances, cette fonction peut être utile pour restaurer une base de données à partir d'une sauvegarde, et elle est souvent utilisée avec des scripts qui effectuent des tâches telles que le clonage de base de données.</block>
  <block id="3f51d58ec72b9d36cb5e0636525130b5" category="list-text">Le résultat de la commande suivante est utilisé pour recréer les fichiers de contrôle pour la base de données migrée.</block>
  <block id="cb395c3bf18fd427287caecc9b28058a" category="list-text">Une fois les fichiers de contrôle créés, copiez-les sur le nouveau serveur.</block>
  <block id="cf5c9046a3617a19c0ccc24e4cf54a33" category="section-title">Sauvegarde du fichier de paramètres</block>
  <block id="0d1d1a7db58f3f93ec977733f4909f5d" category="paragraph">Un fichier de paramètres est également requis dans le nouvel environnement. La méthode la plus simple consiste à créer un fichier pfile à partir du fichier spfile ou pfile actuel. Dans cet exemple, la base de données source utilise un fichier spfile.</block>
  <block id="051a634cb1e9a53dbf139214e1d24001" category="section-title">Créer une entrée oratab</block>
  <block id="2dabc26c8b55d44e25a184ba2624eed0" category="paragraph">La création d'une entrée oratab est requise pour le bon fonctionnement des utilitaires tels que oraenv. Pour créer une entrée oratab, procédez comme suit.</block>
  <block id="87ef75141d237e3b44e8310aad8fcf19" category="section-title">Préparer la structure du répertoire</block>
  <block id="12f833c44c11e6bbd970cc126bce2bcb" category="paragraph">Si les répertoires requis n'étaient pas déjà présents, vous devez les créer ou la procédure de démarrage de la base de données échoue. Pour préparer la structure de répertoires, remplissez les conditions minimales suivantes.</block>
  <block id="60225c364a012796a6d886e8cf4ec486" category="section-title">Mises à jour du fichier de paramètres</block>
  <block id="e36ee2d9a95a6b672917862d714af383" category="list-text">Pour copier le fichier de paramètres sur le nouveau serveur, exécutez les commandes suivantes. L'emplacement par défaut est le<block ref="45c7302d9c2e8745b3a2bff0f992b6df" prefix=" " category="inline-code"></block> répertoire. Dans ce cas, le fichier pfile peut être placé n'importe où. Il est utilisé uniquement comme étape intermédiaire dans le processus de migration.</block>
  <block id="d437a40a59905247cfb39cf9dc9da256" category="list-text">Modifiez le fichier selon vos besoins. Par exemple, si l'emplacement du journal d'archive a changé, le fichier pfile doit être modifié pour refléter le nouvel emplacement. Dans cet exemple, seuls les fichiers de contrôle sont déplacés, en partie pour les distribuer entre les systèmes de fichiers journaux et de données.</block>
  <block id="55cc35656c3d28c1b3267c246b397521" category="list-text">Une fois les modifications terminées, créez un fichier spfile basé sur ce fichier pfile.</block>
  <block id="a833a03e6af0b969524dcccb8f296f1c" category="section-title">Recréer les fichiers de contrôle</block>
  <block id="74a636ee3a009f08cd5623dc8066dd09" category="paragraph">Dans une étape précédente, la sortie de<block ref="3177841b2335a6640ea3054199830f1c" prefix=" " category="inline-code"></block> a été copié sur le nouveau serveur. La partie spécifique de la sortie requise est le<block ref="0ca1fba455d799b9a1cc2440b9ba7043" prefix=" " category="inline-code"></block> commande. Ces informations se trouvent dans le fichier sous la section marquée<block ref="9fb76d62be749cec8bdd06f46c77bf5b" prefix=" " category="inline-code"></block>. Il commence par la ligne<block ref="13ac20c4a96b2ecfd703e831ad722907" prefix=" " category="inline-code"></block> et doit inclure le mot<block ref="c3c62948f78a7ccaabb9ef2eea80a895" prefix=" " category="inline-code"></block>. Il se termine par le caractère point-virgule (; ).</block>
  <block id="bf4b2a006646a8e77166a2a596425074" category="list-text">Dans cet exemple de procédure, le fichier se lit comme suit.</block>
  <block id="a9a27c002ec883341220e267712250a7" category="list-text">Modifiez ce script comme vous le souhaitez pour refléter le nouvel emplacement des différents fichiers. Par exemple, certains fichiers de données connus pour prendre en charge des E/S élevées peuvent être redirigés vers un système de fichiers sur un niveau de stockage hautes performances. Dans d'autres cas, les modifications peuvent être uniquement pour des raisons d'administrateur, telles que l'isolation des fichiers de données d'un PDB donné dans des volumes dédiés.</block>
  <block id="2540fb1670d4f9ee8a704a7eb8d748fe" category="list-text">Dans cet exemple, le<block ref="b86df74c6982de8dec7509d039294d7a" prefix=" " category="inline-code"></block> la strophe reste inchangée, mais les journaux de reprise sont déplacés vers un nouvel emplacement dans<block ref="96bb85ed0fe822778c4e5a821e991ad8" prefix=" " category="inline-code"></block> plutôt que de partager de l'espace avec les journaux d'archivage<block ref="0e62afc91abe157ef67895cca0a7f912" prefix=" " category="inline-code"></block>.</block>
  <block id="8d47ad079859f2976fdc7ebf742f768d" category="paragraph">Si des fichiers sont mal placés ou si des paramètres sont mal configurés, des erreurs sont générées et indiquent ce qui doit être corrigé. La base de données est montée, mais elle n'est pas encore ouverte et ne peut pas être ouverte car les fichiers de données utilisés sont toujours marqués comme étant en mode de sauvegarde à chaud. Les journaux d'archivage doivent d'abord être appliqués pour rendre la base de données cohérente.</block>
  <block id="6b7c2d588ac708b58f7ac889090608f6" category="section-title">Réplication initiale du journal</block>
  <block id="2db2d3d6001a06d1a027904fa66bc78c" category="paragraph">Au moins une opération de réponse de journal est nécessaire pour rendre les fichiers de données cohérents. De nombreuses options sont disponibles pour relire les journaux. Dans certains cas, l'emplacement du journal d'archivage d'origine sur le serveur d'origine peut être partagé via NFS et la réponse du journal peut être effectuée directement. Dans d'autres cas, les journaux d'archivage doivent être copiés.</block>
  <block id="5c394e6951584d114c6706d0768e30d7" category="paragraph">Par exemple, un simple<block ref="8a444a43bdf534c0c6338bb7809659b3" prefix=" " category="inline-code"></block> l'opération peut copier tous les journaux en cours du serveur source vers le serveur de migration :</block>
  <block id="5fdb3158ed28dd3aa90b94556476b781" category="section-title">Relecture initiale du journal</block>
  <block id="c2f93ef52583f81f0eba05a39483e2d8" category="paragraph">Une fois les fichiers à l'emplacement du journal d'archivage, ils peuvent être relus en exécutant la commande<block ref="5fea768eb2d353716ca623ae58ce382c" prefix=" " category="inline-code"></block> suivi de la réponse<block ref="e1f2d5134ed2543d38a0de9751cf75d9" prefix=" " category="inline-code"></block> pour relire automatiquement tous les journaux disponibles.</block>
  <block id="f30a45a22256018185c5d235292e4d5e" category="paragraph">La réponse finale au journal d'archivage signale une erreur, mais c'est normal. Le journal l'indique<block ref="a84f4f3da79386c29ab6dfa560af786e" prefix=" " category="inline-code"></block> a cherché un fichier journal particulier et ne l'a pas trouvé. La raison est, très probablement, que le fichier journal n'existe pas encore.</block>
  <block id="80bea8a60412cace54760b223b2d799e" category="paragraph">Si la base de données source peut être arrêtée avant de copier les journaux d'archivage, cette étape ne doit être effectuée qu'une seule fois. Les journaux d'archivage sont copiés et relus. Le processus peut ensuite se poursuivre directement vers le processus de mise en service qui réplique les journaux de reprise critiques.</block>
  <block id="1e334141582a9dcb581c9b34ef2df071" category="section-title">Réplication et relecture incrémentielles du journal</block>
  <block id="5fd2b0bf662c2b1ebdc677ea888536ce" category="paragraph">Dans la plupart des cas, la migration n'est pas effectuée immédiatement. La fin du processus de migration peut prendre plusieurs jours, voire plusieurs semaines, ce qui signifie que les journaux doivent être envoyés en continu à la base de données de réplica et relus. Par conséquent, lors de la mise en service, un nombre minimal de données doit être transféré et relu.</block>
  <block id="0c56d82ec6857bcef5475899b9f7b5cc" category="paragraph">Cela peut être scripté de plusieurs manières, mais l'une des méthodes les plus courantes est l'utilisation de rsync, un utilitaire commun de réplication de fichiers. La façon la plus sûre d'utiliser cet utilitaire est de le configurer en tant que démon. Par exemple, le<block ref="b31375af035ed8a698a803a491084f61" prefix=" " category="inline-code"></block> le fichier suivant montre comment créer une ressource appelée<block ref="260e23541ff372b9bc53b4bd3c0c38ba" prefix=" " category="inline-code"></block> Accessible avec les informations d'identification d'utilisateur Oracle et mappé sur<block ref="488a4921a81e36fca411e6f13cefbbf2" prefix=" " category="inline-code"></block>. Plus important encore, la ressource est définie en lecture seule, ce qui permet de lire les données de production sans les modifier.</block>
  <block id="eabf1b424989b2c7113ba3a538079afa" category="paragraph">La commande suivante synchronise la destination du journal d'archive du nouveau serveur avec la ressource rsync<block ref="260e23541ff372b9bc53b4bd3c0c38ba" prefix=" " category="inline-code"></block> sur le serveur d'origine. Le<block ref="e358efa489f58062f10dd7316b65649e" prefix=" " category="inline-code"></block> argument dans<block ref="293e33723231f0504effabb52b054a31" prefix=" " category="inline-code"></block> permet de comparer la liste de fichiers en fonction de l'horodatage et de copier uniquement les nouveaux fichiers. Ce processus fournit une mise à jour incrémentielle du nouveau serveur. Cette commande peut également être planifiée en cron pour s'exécuter de façon régulière.</block>
  <block id="c775c44069da13c8f7ee5c5116e76e36" category="inline-link-macro">Relire les journaux sur la base de données</block>
  <block id="c3bf9b2ef3e3ae2ae6a02f7f77cfcbc6" category="paragraph">Une fois les journaux reçus, ils doivent être relus. Les exemples précédents montrent l'utilisation de sqlplus pour une exécution manuelle<block ref="5fea768eb2d353716ca623ae58ce382c" prefix=" " category="inline-code"></block>, un processus qui peut être facilement automatisé. L'exemple illustré ici utilise le script décrit dans <block ref="3e57a2099043fa40c58f1e0d4eed995d" category="inline-link-macro-rx"></block>. Les scripts acceptent un argument qui spécifie la base de données nécessitant une opération de relecture. Cela permet d'utiliser le même script dans un effort de migration multibase de données.</block>
  <block id="4ea2a6c39b10b3e3076f976f58a861d1" category="section-title">Mise en service</block>
  <block id="5de3f1ba0bbef459baa93f04f63b9ea1" category="paragraph">Lorsque vous êtes prêt à passer au nouvel environnement, vous devez effectuer une synchronisation finale qui inclut à la fois les journaux d'archivage et les journaux de reprise. Si l'emplacement original du journal de reprise n'est pas déjà connu, il peut être identifié comme suit :</block>
  <block id="677f005cc0f8be0f891df5af72fb5688" category="list-text">Arrêtez la base de données source.</block>
  <block id="41b182875e12de118d17b3432cca93fa" category="list-text">Effectuez une synchronisation finale des journaux d'archivage sur le nouveau serveur avec la méthode souhaitée.</block>
  <block id="37d6d9420cef8230249e7691315f0e13" category="list-text">Les fichiers redo log source doivent être copiés sur le nouveau serveur. Dans cet exemple, les journaux de reprise ont été déplacés vers un nouveau répertoire à<block ref="96bb85ed0fe822778c4e5a821e991ad8" prefix=" " category="inline-code"></block>.</block>
  <block id="d0a5f1380bd67b0d0fd3bc72f22d88f2" category="list-text">À ce stade, le nouvel environnement de base de données contient tous les fichiers nécessaires pour le ramener au même état que la source. Les journaux d'archivage doivent être relus une dernière fois.</block>
  <block id="c2721157205b2d2e96c656c45ca72992" category="list-text">Une fois l'opération terminée, les journaux de reprise doivent être relus. Si le message s'affiche<block ref="975df7a5099101ffbe47981cd1d37c2c" prefix=" " category="inline-code"></block> est renvoyé, le processus a réussi et les bases de données sont synchronisées et peuvent être ouvertes.</block>
  <block id="6acab27c5f334c66f06f3f74bc62d6d8" category="section-title">Envoi de journaux - ASM vers le système de fichiers</block>
  <block id="a67ffcc8b155bb909a6f8c5d5ba2f334" category="paragraph">Cet exemple illustre l'utilisation d'Oracle RMAN pour migrer une base de données. Il est très similaire à l'exemple précédent de système de fichiers pour l'envoi de journaux de système de fichiers, mais les fichiers sur ASM ne sont pas visibles par l'hôte. Les seules options de migration des données situées sur les périphériques ASM sont soit le déplacement du LUN ASM, soit l'utilisation d'Oracle RMAN pour effectuer les opérations de copie.</block>
  <block id="1c51600a778919f7f3abb5b25175220a" category="paragraph">Bien que RMAN soit obligatoire pour la copie de fichiers à partir d'Oracle ASM, l'utilisation de RMAN ne se limite pas à ASM. RMAN peut être utilisé pour migrer de tout type de stockage vers tout autre type.</block>
  <block id="2cb6a5bfc4a76f651d496cddc685e078" category="paragraph">Cet exemple montre le déplacement d'une base de données appelée PANCAKE depuis le stockage ASM vers un système de fichiers standard situé sur un serveur différent au niveau des chemins<block ref="f006bf17b06c884c47190c4225d3215a" prefix=" " category="inline-code"></block> et<block ref="0e62afc91abe157ef67895cca0a7f912" prefix=" " category="inline-code"></block>.</block>
  <block id="d1d789c37f1c96d0a5de07798c14fcc5" category="paragraph">La première étape consiste à créer une sauvegarde de la base de données à migrer vers un autre serveur. Comme la source utilise Oracle ASM, RMAN doit être utilisé. Une simple sauvegarde RMAN peut être effectuée comme suit. Cette méthode crée une sauvegarde balisée qui peut être facilement identifiée par RMAN plus tard dans la procédure.</block>
  <block id="ed927706d8abc2bbf3a5a8bc55e1e562" category="paragraph">La première commande définit le type de destination de la sauvegarde et l'emplacement à utiliser. La seconde lance la sauvegarde des fichiers de données uniquement.</block>
  <block id="db85d05166dd65559ae5f426b51198e6" category="section-title">Fichier de contrôle de sauvegarde</block>
  <block id="a0b95d36955723a82dde7bbe40b6ccb9" category="paragraph">Un fichier de contrôle de sauvegarde est requis plus tard dans la procédure pour<block ref="08de2bfcc2d52d5bc4f3f2dcb97558ad" prefix=" " category="inline-code"></block> fonctionnement.</block>
  <block id="76ff543de72e62217293a1d0ceade0aa" category="paragraph">Un fichier de paramètres est également requis dans le nouvel environnement. La méthode la plus simple consiste à créer un fichier pfile à partir du fichier spfile ou pfile actuel. Dans cet exemple, la base de données source utilise un fichier spfile.</block>
  <block id="d28f3a5b77909b45c50e6c711bef8b60" category="section-title">Script de renommage de fichier ASM</block>
  <block id="c242730c760d895368557f78141ff8b1" category="paragraph">Plusieurs emplacements de fichiers actuellement définis dans les fichiers de contrôle changent lorsque la base de données est déplacée. Le script suivant crée un script RMAN pour faciliter le processus. Cet exemple illustre une base de données comportant un très petit nombre de fichiers de données, mais en général, les bases de données contiennent des centaines, voire des milliers de fichiers de données.</block>
  <block id="359b84bcf7447a77b212e844aeaa9d89" category="inline-link-macro">Conversion de noms de système de fichiers ASM en système de fichiers</block>
  <block id="374a1a0facd7c604ac09ed0dca6efb3e" category="paragraph">Ce script est disponible dans <block ref="288325982fd7bee6cf9eb66ad33f6f7a" category="inline-link-macro-rx"></block> et il fait deux choses.</block>
  <block id="42787fdca1cf792241ce03151ec7dbd3" category="paragraph">Tout d'abord, il crée un paramètre pour redéfinir les emplacements du journal de reprise appelés<block ref="0f2d7ef9b967c2d9fb1ad5aa5e9eb688" prefix=" " category="inline-code"></block>. Il s'agit essentiellement d'une liste de champs alternatifs. Le premier champ est l'emplacement d'un journal de reprise en cours et le second est l'emplacement sur le nouveau serveur. Le schéma est alors répété.</block>
  <block id="cf444fd96c87609516f0ad8212f41b01" category="paragraph">La deuxième fonction consiste à fournir un modèle pour renommer le fichier de données. Le script passe en boucle dans les fichiers de données, extrait les informations relatives au nom et au numéro de fichier et les formate en tant que script RMAN. Il fait ensuite la même chose avec les fichiers temporaires. Le résultat est un script rman simple qui peut être modifié comme vous le souhaitez pour vous assurer que les fichiers sont restaurés à l'emplacement souhaité.</block>
  <block id="50614366822786a4f2ee3a5065543634" category="paragraph">Capturer la sortie de cet écran. Le<block ref="0f2d7ef9b967c2d9fb1ad5aa5e9eb688" prefix=" " category="inline-code"></block> le paramètre est placé dans le fichier pfile comme décrit ci-dessous. Le script de renommage et de duplication du fichier de données RMAN doit être modifié en conséquence pour placer les fichiers de données aux emplacements souhaités. Dans cet exemple, ils sont tous placés dans<block ref="36c3572e381980ee1f1343988ae4a955" prefix=" " category="inline-code"></block>.</block>
  <block id="e60cd818b9f7ae02a73d8b3a6ea0a809" category="paragraph">Les scripts sont presque prêts à être exécutés, mais d'abord la structure de répertoire doit être en place. Si les répertoires requis ne sont pas déjà présents, ils doivent être créés ou la procédure de démarrage de la base de données échoue. L'exemple ci-dessous reflète les exigences minimales.</block>
  <block id="2f2eed2ed14ba876a017aa9ea9515724" category="paragraph">La commande suivante est requise pour que des utilitaires tels que oraenv fonctionnent correctement.</block>
  <block id="f34a9f7c077457a54f8838b55b9fc025" category="section-title">Mises à jour des paramètres</block>
  <block id="fd5c3a935e7374f8b1577e73e85ef375" category="paragraph">Le fichier pfile enregistré doit être mis à jour pour refléter toute modification de chemin sur le nouveau serveur. Les modifications du chemin d'accès au fichier de données sont modifiées par le script de duplication RMAN, et presque toutes les bases de données nécessitent des modifications<block ref="d98137bd230dac4372cf20a2e7839463" prefix=" " category="inline-code"></block> et<block ref="2d205df7ae2efff1576140524b40b93c" prefix=" " category="inline-code"></block> paramètres. Il peut également y avoir des emplacements de fichiers d'audit qui doivent être modifiés, ainsi que des paramètres tels que<block ref="40f8833ae28ec69bcc89eb0eba090fe4" prefix=" " category="inline-code"></block> Peut ne pas être pertinent en dehors d'ASM. Un administrateur de base de données expérimenté doit examiner attentivement les modifications proposées avant de poursuivre.</block>
  <block id="b581dd429e9b4c24127b8940ca8e4346" category="paragraph">Dans cet exemple, les changements de clé sont les emplacements des fichiers de contrôle, la destination de l'archive de journal et l'ajout du<block ref="0f2d7ef9b967c2d9fb1ad5aa5e9eb688" prefix=" " category="inline-code"></block> paramètre.</block>
  <block id="bbba1f65801697ba3abd94d90c83ba71" category="paragraph">Une fois les nouveaux paramètres confirmés, les paramètres doivent être mis en vigueur. Plusieurs options existent, mais la plupart des clients créent un fichier spfile basé sur le fichier pfile texte.</block>
  <block id="3a17a12678d74dabb1032aaf373166d8" category="section-title">Nom de démarrage</block>
  <block id="a9dc570a0b3161e69edc31f3545cbf22" category="paragraph">La dernière étape avant la réplication de la base de données consiste à afficher les processus de la base de données, mais pas à monter les fichiers. Dans cette étape, des problèmes avec le fichier spfile peuvent devenir évidents. Si le<block ref="357eedab214bb515c5622e275bc19cdb" prefix=" " category="inline-code"></block> la commande échoue en raison d'une erreur de paramètre, il est simple de s'arrêter, de corriger le modèle pfile, de le recharger en tant que fichier spfile et de réessayer.</block>
  <block id="0257eff4bf9bf0cb483f2544fd42f109" category="section-title">Dupliquez la base de données</block>
  <block id="4632b675c558eda129fe6da4fbbae2b2" category="paragraph">La restauration de la sauvegarde RMAN précédente vers le nouvel emplacement prend plus de temps que les autres étapes de ce processus. La base de données doit être dupliquée sans modification de l'ID de base de données (DBID) ou réinitialisation des journaux. Cela empêche l'application des journaux, ce qui est une étape nécessaire pour synchroniser complètement les copies.</block>
  <block id="06206ea0cdea741420d9f7619503db89" category="paragraph">Connectez-vous à la base de données avec RMAN en tant qu'aux et exécutez la commande duplicate database en utilisant le script créé lors d'une étape précédente.</block>
  <block id="5ae45dfed3c4aff7fe4fd6a7e3606cb0" category="paragraph">Vous devez maintenant envoyer les modifications de la base de données source vers un nouvel emplacement. Cela peut nécessiter une combinaison d'étapes. La méthode la plus simple serait que RMAN sur la base de données source écrive des journaux d'archive sur une connexion réseau partagée. Si aucun emplacement partagé n'est disponible, une autre méthode consiste à utiliser RMAN pour écrire dans un système de fichiers local, puis à utiliser rcp ou rsync pour copier les fichiers.</block>
  <block id="e355807335e5f05930a748afe1c3b23d" category="paragraph">Dans cet exemple, le<block ref="45987b06d5eae35fc3e3487749a9ba27" prefix=" " category="inline-code"></block> Directory est un partage NFS disponible pour la base de données d'origine et migrée.</block>
  <block id="49fffa356bcd041918ce24ef714f3f72" category="paragraph">L'une des questions importantes est la<block ref="6761e3b36547cd115b3966fcbc7192b2" prefix=" " category="inline-code"></block> clause. Le format de disque de la sauvegarde est<block ref="9ae0f22d9fa2eac270499e74092af364" prefix=" " category="inline-code"></block>, Ce qui signifie que vous devez utiliser le format du numéro de thread, du numéro de séquence et de l'ID d'activation de la base de données. Bien que les lettres soient différentes, cela correspond à<block ref="03e92f2c3a8cae5315f0e42bf6acf436" prefix=" " category="inline-code"></block> dans le fichier pfile. Ce paramètre spécifie également les journaux d'archivage au format de numéro de thread, de numéro de séquence et d'ID d'activation. Le résultat final est que les sauvegardes du fichier journal sur la source utilisent une convention de dénomination attendue par la base de données. Cela permet de réaliser des opérations telles que<block ref="81168dbef15af03d02c51a7447378e76" prefix=" " category="inline-code"></block> beaucoup plus simple parce que sqlplus anticipe correctement les noms des journaux d'archive à lire.</block>
  <block id="76d77393c7ffc6b0a0edd47ad09afe4d" category="paragraph">Une fois les fichiers à l'emplacement du journal d'archivage, ils peuvent être relus en exécutant la commande<block ref="5fea768eb2d353716ca623ae58ce382c" prefix=" " category="inline-code"></block> suivi de la réponse<block ref="e1f2d5134ed2543d38a0de9751cf75d9" prefix=" " category="inline-code"></block> pour relire automatiquement tous les journaux disponibles. Le fichier de paramètres dirige actuellement les journaux d'archivage vers<block ref="e421a42fc6f604fcc78707336ed222b9" prefix=" " category="inline-code"></block>, Mais cela ne correspond pas à l'emplacement où RMAN a été utilisé pour enregistrer les journaux. L'emplacement peut être redirigé temporairement comme suit avant de récupérer la base de données.</block>
  <block id="0a96a4559ad3ab8c616a12a207e8daca" category="paragraph">La réponse finale au journal d'archivage signale une erreur, mais c'est normal. L'erreur indique que sqlplus recherchait un fichier journal particulier et qu'il ne l'a pas trouvé. La raison est la plus probable que le fichier journal n'existe pas encore.</block>
  <block id="e2a234d3299b9e66f0756db00c9ee8c7" category="paragraph">Dans la plupart des cas, la migration n'est pas effectuée immédiatement. La fin du processus de migration peut prendre plusieurs jours, voire plusieurs semaines, ce qui signifie que les journaux doivent être envoyés en continu à la base de données de réplica et relus. Ainsi, le transfert et la lecture de données minimales doivent être assurés à l'arrivée de la mise en service.</block>
  <block id="247e1695519da78866726a4dcb2c5252" category="paragraph">Ce processus peut facilement être scripté. Par exemple, la commande suivante peut être planifiée sur la base de données d'origine pour s'assurer que l'emplacement utilisé pour l'envoi des journaux est mis à jour en permanence.</block>
  <block id="3ce19ecb7c874f75b9a46e29abe2012e" category="inline-link-macro">Relire les journaux sur la base de données de secours</block>
  <block id="469d3082a0f3ad08223ba8fe69bf9311" category="paragraph">Une fois les journaux reçus, ils doivent être relus. Des exemples précédents ont montré l'utilisation de sqlplus pour une exécution manuelle<block ref="5fea768eb2d353716ca623ae58ce382c" prefix=" " category="inline-code"></block>, qui peut être facilement automatisé. L'exemple illustré ici utilise le script décrit dans <block ref="7c7730292e0135c86626e1771f7f02ec" category="inline-link-macro-rx"></block>. Le script accepte un argument qui spécifie la base de données nécessitant une opération de relecture. Ce processus permet d'utiliser le même script dans un effort de migration multibase de données.</block>
  <block id="15d3442f7626bb62f4b255c7ed5c5098" category="paragraph">Lorsque vous êtes prêt à passer au nouvel environnement, vous devez effectuer une synchronisation finale. Lorsque vous travaillez avec des systèmes de fichiers réguliers, il est facile de s'assurer que la base de données migrée est synchronisée à 100 % par rapport à l'original car les journaux de reprise d'origine sont copiés et relus. Il n'y a pas de bonne façon de le faire avec ASM. Seuls les journaux d'archivage peuvent être facilement recopiés. Pour s'assurer qu'aucune donnée n'est perdue, l'arrêt final de la base de données d'origine doit être effectué avec précaution.</block>
  <block id="f9952f2469fbec5fc9dca180322ff9ee" category="list-text">Tout d'abord, la base de données doit être mise en veille, en veillant à ce qu'aucune modification ne soit apportée. Cette mise en veille peut inclure la désactivation des opérations planifiées, l'arrêt des auditeurs et/ou l'arrêt des applications.</block>
  <block id="58fd1c52efcde7151ac264a8f67b14ff" category="list-text">Une fois cette étape effectuée, la plupart des administrateurs de bases de données créent une table fictive qui sert de marqueur de l'arrêt.</block>
  <block id="442da9ab2cced82a6cbdd112be285bcf" category="list-text">Forcer l'archivage des journaux pour s'assurer que la création de la table fictive est enregistrée dans les journaux d'archivage. Pour ce faire, exécutez les commandes suivantes :</block>
  <block id="83fce8a41250d6af49205f9659468351" category="list-text">Pour copier le dernier des journaux d'archivage, exécutez les commandes suivantes. La base de données doit être disponible mais pas ouverte.</block>
  <block id="1b0e887c1394d4617c2a5243da19e44e" category="list-text">Pour copier les journaux d'archivage, exécutez les commandes suivantes :</block>
  <block id="86a7e05acb17098c514dd570b9220302" category="list-text">Enfin, rejouez les journaux d'archive restants sur le nouveau serveur.</block>
  <block id="a430882deb5403e7b4b8061dec17cc80" category="list-text">À ce stade, répliquez toutes les données. La base de données est prête à être convertie à partir d'une base de données de secours vers une base de données opérationnelle active, puis ouverte.</block>
  <block id="077c7bcbf9a94bb62aecadc85045886e" category="list-text">Confirmer la présence de la table factice, puis la déposer.</block>
  <block id="6130a27b8ec8ccf18e06bb3389b0fbbd" category="section-title">Migration des journaux de reprise sans interruption</block>
  <block id="26c294f993888218237d5f9306bfcfc4" category="paragraph">Il arrive qu'une base de données soit correctement organisée de manière globale, à l'exception des journaux de reprise. Cela peut se produire pour de nombreuses raisons, dont la plus courante est liée aux snapshots. Des produits tels que SnapManager pour Oracle, SnapCenter et la structure de gestion du stockage NetApp Snap Creator permettent une restauration quasi instantanée d'une base de données, mais uniquement si vous restaurez l'état des volumes de fichiers de données. Si les journaux de reprise partagent l'espace avec les fichiers de données, la restauration ne peut pas être effectuée en toute sécurité, car elle entraînerait la destruction des journaux de reprise, ce qui entraînerait probablement une perte des données. Les journaux de reprise doivent donc être déplacés.</block>
  <block id="2c56f5081b94b926c93c40f4c935a44a" category="paragraph">Cette procédure est simple et peut être effectuée sans interruption.</block>
  <block id="2986f9fe7ed4aab5aaa64c2ee9fe4841" category="section-title">Configuration actuelle du journal de reprise</block>
  <block id="dd786d22c88a5f1fe0c10cfec58c1b44" category="list-text">Identifiez le nombre de groupes de fichiers redo log et leurs numéros de groupe respectifs.</block>
  <block id="3cd0f7a32a4f5ee026702f8125f3dda7" category="list-text">Indiquez la taille des journaux de reprise.</block>
  <block id="7c2f6ada37d59f2be0bc1a3ead80f77c" category="section-title">Créer de nouveaux journaux</block>
  <block id="106b215e5d87fb1256e47932f2ebf9cf" category="list-text">Pour chaque journal de reprise, créez un nouveau groupe avec la taille et le nombre de membres correspondants.</block>
  <block id="0851b65f20b98420968e488fc3c0085e" category="list-text">Vérifiez la nouvelle configuration.</block>
  <block id="cbccec9e0905e0b7f5cd630a3fa12f64" category="section-title">Supprimez les anciens journaux</block>
  <block id="00f63618719701ddae7fc2ff1d406ec2" category="list-text">Supprimez les anciens journaux (groupes 1, 2 et 3).</block>
  <block id="f00c8361a8acc818247282bb6420a8c1" category="list-text">Si vous rencontrez une erreur qui vous empêche de supprimer un journal actif, forcez un commutateur au journal suivant pour libérer le verrouillage et forcer un point de contrôle global. Reportez-vous à l'exemple suivant de ce processus. La tentative de suppression du groupe de fichiers journaux 2, qui se trouvait sur l'ancien emplacement, a été refusée parce qu'il y avait encore des données actives dans ce fichier journal.</block>
  <block id="5d49a93437a42d2926c8be7eb3c7a56f" category="list-text">Un archivage de journaux suivi d'un point de contrôle vous permet de supprimer le fichier journal.</block>
  <block id="e3898c187d7edf64fc8e4d4e409fd244" category="list-text">Supprimez ensuite les journaux du système de fichiers. Vous devez effectuer ce processus avec une extrême prudence.</block>
  <block id="dacc2a633e9981c9f91e43ac6b59e889" category="paragraph">La migration des données Oracle peut se faire à l'un des trois niveaux suivants : la base de données, l'hôte ou la baie de stockage.</block>
  <block id="5153193d50d4c628312db2d5bc0132ed" category="paragraph">Les différences résident dans la capacité du composant de la solution globale à déplacer les données : la base de données, le système d'exploitation hôte ou le système de stockage.</block>
  <block id="cc3e73ae592a355b9beb405232d08fe2" category="paragraph">La figure ci-dessous présente un exemple des niveaux de migration et du flux de données. Dans le cas d'une migration au niveau de la base de données, les données sont déplacées du système de stockage d'origine vers le nouvel environnement via les couches hôte et base de données. La migration au niveau de l'hôte est similaire, mais les données ne passent pas par la couche applicative et sont écrites au nouvel emplacement à l'aide de processus hôtes. Enfin, avec la migration au niveau du stockage, une baie telle qu'un système NetApp FAS est responsable du déplacement des données.</block>
  <block id="204415652114bfb773b51cd76c8c692e" category="paragraph"><block ref="204415652114bfb773b51cd76c8c692e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b059e0e23ffaa8fbd97f681942ce0018" category="paragraph">Une migration au niveau de la base de données fait généralement référence à l'utilisation de l'envoi de journaux Oracle via une base de données de secours pour effectuer une migration au niveau de la couche Oracle. Les migrations au niveau de l'hôte s'effectuent à l'aide de la fonctionnalité native de la configuration du système d'exploitation hôte. Cette configuration inclut des opérations de copie de fichiers à l'aide de commandes telles que cp, tar et Oracle Recovery Manager (RMAN) ou à l'aide d'un gestionnaire de volumes logiques (LVM) pour déplacer les octets sous-jacents d'un système de fichiers. Oracle Automatic Storage Management (ASM) est classé comme une fonctionnalité de niveau hôte car elle s'exécute en dessous du niveau de l'application de base de données. ASM remplace le gestionnaire de volumes logiques habituel sur un hôte. Enfin, les données peuvent être migrées au niveau de la baie de stockage, ce qui signifie en dessous du niveau du système d'exploitation.</block>
  <block id="228d9e0418aa12bae73676a5743558db" category="section-title">Planification</block>
  <block id="ce7eea640cd6ee20e55cbe868f4026e9" category="paragraph">La meilleure option de migration dépend de plusieurs facteurs, notamment de l'étendue de l'environnement à migrer, de la nécessité d'éviter les temps d'indisponibilité et des efforts globaux requis pour effectuer la migration. Les bases de données volumineuses nécessitent évidemment plus de temps et d'efforts pour la migration, mais la complexité de cette migration est minimale. Les petites bases de données peuvent être migrées rapidement. Toutefois, si des milliers d'entre elles doivent être migrées, l'ampleur des efforts peut engendrer des complications. Enfin, plus la base de données est volumineuse, plus elle est susceptible d'être stratégique, ce qui entraîne la nécessité de minimiser les temps d'indisponibilité tout en préservant un chemin « back-out ».</block>
  <block id="d4b9b19593598d98059aae44d6a7bbe1" category="paragraph">Voici quelques-uns des éléments à prendre en compte lors de la planification d'une stratégie de migration.</block>
  <block id="931c6f2c99380fbd899e3eaa31e97d98" category="section-title">Taille des données</block>
  <block id="64e4d570abeebacf6bdcb19dfb73fcae" category="paragraph">La taille des bases de données à migrer a de toute évidence un impact sur la planification de la migration, bien que la taille n'ait pas nécessairement un impact sur le délai de mise en service. Lorsqu'une grande quantité de données doit être migrée, la principale considération est la bande passante. Les opérations de copie s'effectuent généralement via des E/S séquentielles efficaces En guise d'estimation prudente, on suppose une utilisation de 50 % de la bande passante réseau disponible pour les opérations de copie. Par exemple, un port FC de 8 Go peut en théorie transférer environ 800 Mbit/s. Si l'on suppose une utilisation de 50 %, une base de données peut être copiée à un taux d'environ 400 Mbit/s. Ainsi, une base de données de 10 To peut être copiée en sept heures environ à ce rythme.</block>
  <block id="84a80a048e7abc027dd6bdce55fda9d2" category="inline-link-macro">Déplacement du fichier de données en ligne</block>
  <block id="1c169b76761527b28040655a783e50a2" category="section-title">Nombre de bases de données</block>
  <block id="da3770c5d6d1215e9f2524b9d7b7c3c5" category="paragraph">Dans de nombreux cas, le problème du déplacement d'une grande quantité de données n'est pas la taille des données, mais plutôt la complexité de la configuration qui prend en charge la base de données. Savoir qu'il faut migrer 50 To de bases de données n'est pas suffisant. Il peut s'agir d'une seule base de données stratégique de 50 To, d'un ensemble de 4 000 bases de données héritées ou d'un mélange de données de production et de données hors production. Dans certains cas, une grande partie des données est constituée de clones d'une base de données source. Il n'est pas nécessaire de migrer ces clones car ils peuvent être recréés facilement, notamment lorsque la nouvelle architecture est conçue pour exploiter les volumes NetApp FlexClone.</block>
  <block id="a1739e745a7544d2432b2b990a715817" category="paragraph">Pour la planification de la migration, vous devez connaître le nombre de bases de données concernées et leur priorité. À mesure que le nombre de bases de données augmente, l'option de migration privilégiée tend à être plus faible et plus faible dans la pile. Par exemple, la copie d'une seule base de données peut s'effectuer facilement avec RMAN et en cas de courte panne. Il s'agit de la réplication au niveau de l'hôte.</block>
  <block id="284723d6a05b50ace5e5b96c761d03ac" category="paragraph">S'il existe 50 bases de données, il peut être plus facile d'éviter de configurer une nouvelle structure de système de fichiers pour recevoir une copie RMAN et de déplacer les données à la place. Ce processus peut être effectué en tirant parti de la migration LVM basée sur l'hôte pour déplacer les données des anciennes LUN vers les nouvelles LUN. L'équipe chargée de l'administration de la base de données (DBA) est alors détransférée vers l'équipe chargée du système d'exploitation pour que les données soient migrées de manière transparente par rapport à la base de données. La configuration du système de fichiers n'est pas modifiée.</block>
  <block id="8e734da04d394519001f47f723341e9d" category="paragraph">Enfin, si 500 bases de données réparties sur 200 serveurs doivent être migrées, des options basées sur le stockage, telles que la fonctionnalité ONTAP Foreign LUN Import (FLI), peuvent être utilisées pour effectuer une migration directe des LUN.</block>
  <block id="39f43935349622951e0f392c83b6e736" category="section-title">Exigences en matière d'architecture</block>
  <block id="50f1558a3f9d47464b5d57f9d9d0f9d1" category="paragraph">En général, l'organisation d'un fichier de base de données doit être modifiée pour exploiter les fonctionnalités de la nouvelle baie de stockage. Toutefois, ce n'est pas toujours le cas. Par exemple, les fonctionnalités des baies 100 % Flash EF-Series se concentrent sur les performances SAN et la fiabilité SAN. Dans la plupart des cas, les bases de données peuvent être migrées vers une baie EF-Series sans tenir compte particulière de la disposition des données. Les seules exigences sont un nombre élevé d'IOPS, une faible latence et une fiabilité robuste. Bien que certaines pratiques d'excellence soient liées à des facteurs tels que la configuration RAID ou les pools de disques dynamiques, les projets EF-Series nécessitent rarement des modifications importantes de l'architecture de stockage globale pour exploiter ces fonctionnalités.</block>
  <block id="0e2c78f7e9948e19ccb1bf2e1b7f0faf" category="paragraph">En revanche, la migration vers ONTAP nécessite généralement une plus grande considération de la disposition de la base de données pour s'assurer que la configuration finale offre une valeur maximale. À elle seule, ONTAP offre de nombreuses fonctionnalités pour un environnement de base de données, même sans effort d'architecture spécifique. Plus important encore, il permet de migrer vers un nouveau matériel sans interruption lorsque le matériel actuel arrive en fin de vie. De manière générale, une migration vers ONTAP est la dernière migration que vous auriez à effectuer. Ensuite, le matériel est mis à niveau et les données sont migrées sans interruption vers de nouveaux supports.</block>
  <block id="ad93bd21d59f2286385dc519fd7e39fb" category="paragraph">Avec une certaine planification, davantage d'avantages sont disponibles. Les considérations les plus importantes concernent l'utilisation des snapshots. Les copies Snapshot sont la base des sauvegardes, des restaurations et des opérations de clonage quasi-instantanées. Comme exemple de la puissance des snapshots, l'utilisation la plus répandue concerne une base de données unique de 996 To qui s'exécute sur environ 250 LUN sur 6 contrôleurs. Cette base de données peut être sauvegardée en 2 minutes, restaurée en 2 minutes et clonée en 15 minutes. Les autres avantages sont la capacité à déplacer les données au sein du cluster en réponse aux modifications des charges de travail et les contrôles de qualité de service (QoS) appliqués pour fournir de bonnes performances cohérentes dans un environnement à plusieurs bases de données.</block>
  <block id="6b48ce64da84423ce167ffb72f5f9a8b" category="inline-link-macro">Présentation des procédures de migration Oracle</block>
  <block id="1311d3b592e4da5950e91965dac1d593" category="paragraph">Les technologies comme les contrôles de qualité de service, la relocalisation des données, la copie Snapshot et le clonage fonctionnent dans presque toutes les configurations. Cependant, certains pensent généralement être nécessaires pour maximiser les avantages. Dans certains cas, les dispositions du stockage de la base de données peuvent nécessiter des modifications de conception afin d'optimiser l'investissement dans la nouvelle baie de stockage. De telles modifications de conception peuvent avoir un impact sur la stratégie de migration, car les migrations basées sur les hôtes ou sur le stockage répliquent la disposition des données d'origine. Des étapes supplémentaires peuvent être nécessaires pour mener à bien la migration et assurer une disposition des données optimisée pour ONTAP. Les procédures indiquées à la <block ref="d4d5600aaaced44e203002ec1910822d" category="inline-link-macro-rx"></block> vous pouvez par la suite présenter certaines méthodes qui vous permettent non seulement de migrer une base de données, mais aussi de la migrer vers la configuration finale optimale en un minimum d'efforts.</block>
  <block id="1fd9b0a8321228b5b8ad4be85e71cf64" category="section-title">Délai de mise en service</block>
  <block id="95b9194d9f06f6f70febc87c071f3050" category="paragraph">Vous devez déterminer la durée maximale autorisée de l'interruption de service pendant la mise en service. C'est une erreur courante de supposer que l'ensemble du processus de migration provoque des perturbations. De nombreuses tâches peuvent être effectuées avant le début d'une interruption de service, et de nombreuses options permettent d'effectuer la migration sans interruption ni panne. Même si une interruption est inévitable, vous devez toujours définir le temps d'interruption de service maximal autorisé, car la durée de la mise en service varie d'une procédure à l'autre.</block>
  <block id="9cfeaf56d2fc41c2695a69adf260c3f8" category="section-title">Chemin de retour arrière</block>
  <block id="f493e16f7e2caba820eba88a1c5f82d8" category="paragraph">Aucune migration n'est totalement sans risque. Même si la technologie fonctionne parfaitement, il y a toujours une possibilité d'erreur de l'utilisateur. Le risque associé au chemin de migration choisi doit être pris en compte parallèlement aux conséquences d'un échec de la migration. Par exemple, la fonctionnalité de migration transparente du stockage en ligne d'Oracle ASM est l'une de ses principales fonctionnalités, et cette méthode est l'une des plus fiables connues. Cependant, les données sont copiées de manière irréversible avec cette méthode. Dans le cas peu probable où un problème se produit avec ASM, il n'y a pas de chemin de sortie simple. La seule option consiste à restaurer l'environnement d'origine ou à utiliser ASM pour restaurer la migration vers les LUN d'origine. Le risque peut être réduit, mais pas éliminé, en effectuant une sauvegarde de type Snapshot sur le système de stockage d'origine, à condition que le système soit capable d'effectuer une telle opération.</block>
  <block id="1886f1ab01daa4511ce537d1af675427" category="section-title">Répétition</block>
  <block id="dd5dac65febd7071311b1ae3be1eca90" category="paragraph">Certaines procédures de migration doivent être entièrement vérifiées avant leur exécution. La nécessité d'une migration et d'une répétition du processus de mise en service est courante dans les bases de données stratégiques pour lesquelles la migration doit réussir et où les temps d'indisponibilité doivent être minimisés. En outre, les tests d'acceptation par l'utilisateur sont fréquemment inclus dans le travail de post-migration et le système global ne peut être remis en production qu'une fois ces tests terminés.</block>
  <block id="7d06b32cdd06d27f7c62fb110d831e60" category="paragraph">S'il est nécessaire de répéter, plusieurs fonctionnalités ONTAP peuvent faciliter le processus. En particulier, les snapshots peuvent réinitialiser un environnement de test et créer rapidement plusieurs copies compactes d'un environnement de base de données.</block>
  <block id="440a667261bd94f099ef4dde5caf024f" category="summary">Migration des fichiers de données Oracle individuels</block>
  <block id="727bb4db430517995ca651c4f57b0c9f" category="doc">Déplacement du fichier de données</block>
  <block id="fade70b277397e039e100bf0faa98d8e" category="paragraph">Vous pouvez déplacer individuellement les fichiers de données Oracle via une seule commande.</block>
  <block id="50c3d56e93d52f122bab9de1f2b35780" category="paragraph">Par exemple, la commande suivante déplace le fichier de données IOPST.dbf du système de fichiers<block ref="87941c54be03c9785752ea54ac9a2dd4" prefix=" " category="inline-code"></block> vers le système de fichiers<block ref="eff8b2f7c4da1cf002bdea257a43fd10" prefix=" " category="inline-code"></block>.</block>
  <block id="53784088a62519d581c3dac4640c41b5" category="paragraph">Le déplacement d'un fichier de données avec cette méthode peut être lent, mais il ne doit normalement pas produire suffisamment d'E/S pour interférer avec les charges de travail quotidiennes des bases de données. En revanche, la migration via le rééquilibrage d'ASM peut s'exécuter beaucoup plus rapidement, mais au détriment du ralentissement de la base de données globale pendant le déplacement des données.</block>
  <block id="f92065612dfd409585ca08d95cc7a4dc" category="paragraph">Le temps nécessaire à la migration des fichiers de données peut être mesuré en créant un fichier de données de test et en le déplaçant. Le temps écoulé pour l'opération est enregistré dans les données v$session :</block>
  <block id="78fb69ccdf01155db62828d0bc182b84" category="paragraph">Dans cet exemple, le fichier déplacé était le fichier de données 8, dont la taille était de 21 Go et dont la migration nécessitait environ 6 minutes. Le temps nécessaire dépend évidemment des capacités du système de stockage, du réseau de stockage et de l'activité globale de la base de données au moment de la migration.</block>
  <block id="593b763e01de37a327966ee1abb3f8a2" category="summary">Migration Oracle à l'aide de la pile de stockage côté hôte</block>
  <block id="3dc2d5f8d7209bb75e8d67aed68bc5ed" category="paragraph">À l'instar de la migration au niveau des bases de données, la migration au niveau de la couche hôte offre une approche indépendante du fournisseur de stockage.</block>
  <block id="1686ceaaa0d8fb4f9a8adb5e717b029c" category="paragraph">En d'autres termes, parfois "juste copier les fichiers" est la meilleure option.</block>
  <block id="d5732a4ab4c633ceb871cebdbf9ae34f" category="paragraph">Bien que cette approche peu technologique puisse sembler trop basique, elle offre des avantages significatifs, car aucun logiciel spécial n'est requis et les données d'origine ne sont pas modifiées en toute sécurité pendant le processus. La principale limitation est le fait qu'une migration de données de copie de fichier est un processus perturbateur, car la base de données doit être arrêtée avant le début de l'opération de copie. Il n'y a pas de bonne façon de synchroniser les modifications dans un fichier, de sorte que les fichiers doivent être complètement suspendus avant le début de la copie.</block>
  <block id="706e7514bb30a289d7ce786a1a5c2ca0" category="paragraph">Si l'arrêt requis par une opération de copie n'est pas souhaitable, la meilleure option basée sur l'hôte suivante consiste à exploiter un gestionnaire de volumes logiques (LVM). De nombreuses options LVM existent, y compris Oracle ASM, toutes avec des capacités similaires, mais avec certaines limitations qui doivent être prises en compte. Dans la plupart des cas, la migration peut s'effectuer sans interruption ni perturbation.</block>
  <block id="f58e97ac8406ca3e8f0bb7a019a81985" category="section-title">Copie du système de fichiers vers le système de fichiers</block>
  <block id="a08ab728e75c63a41ce7571cb781cda2" category="paragraph">L'utilité d'une simple opération de copie ne doit pas être sous-estimée. Cette opération requiert un temps d'indisponibilité lors de la copie, mais le processus est extrêmement fiable et ne requiert aucune expertise particulière en matière de systèmes d'exploitation, de bases de données ou de systèmes de stockage. De plus, elle est très sûre car elle n'affecte pas les données d'origine. Généralement, un administrateur système modifie les systèmes de fichiers source pour qu'ils soient montés en lecture seule, puis redémarre un serveur pour garantir que rien ne risque d'endommager les données actuelles. Le processus de copie peut être scripté pour s'assurer qu'il s'exécute aussi rapidement que possible sans risque d'erreur de l'utilisateur. Comme le type d'E/S est un simple transfert séquentiel de données, il est très peu gourmand en bande passante.</block>
  <block id="ba0bd93801872993ce832352dd03b56a" category="paragraph">L'exemple suivant illustre une option pour une migration sûre et rapide.</block>
  <block id="d8cb8bcd239bbe7a2a488c1d68dbe420" category="paragraph">L'environnement à migrer est le suivant :</block>
  <block id="3ffbdefc66ad1d1e707c1d6820afbdc0" category="list-text">Systèmes de fichiers actuels</block>
  <block id="bdc9e98c6b17bb14a7bce916054413ba" category="list-text">Nouveaux systèmes de fichiers</block>
  <block id="3b878279a04dc47d60932cb294d96259" category="section-title">Présentation</block>
  <block id="e76912cd513cc8cbcabc2735b524e814" category="paragraph">Il suffit à l'administrateur de bases de données de fermer la base de données et de copier les fichiers pour migrer la base de données. Toutefois, ce processus peut être facilement scripté si de nombreuses bases de données doivent être migrées ou si la réduction des temps d'indisponibilité est essentielle. L'utilisation de scripts réduit également les risques d'erreur de l'utilisateur.</block>
  <block id="d21aae9692f3b1d4e53fd73131414b93" category="paragraph">Les exemples de scripts présentés automatisent les opérations suivantes :</block>
  <block id="66909ae9d06bad444f5a059b8ee2cd41" category="list-text">Arrêt de la base de données</block>
  <block id="ae737f3f8c04ccbefa99b2bbf87dccc2" category="list-text">Conversion des systèmes de fichiers existants en état de lecture seule</block>
  <block id="1dd90b7b28cbd03687df6538c66ff494" category="list-text">Copie de toutes les données de la source vers les systèmes de fichiers cibles, ce qui préserve toutes les autorisations de fichier</block>
  <block id="741341be7809d7f5765b2352e6ab0aab" category="list-text">Démontage de l'ancien et du nouveau système de fichiers</block>
  <block id="7465bc030ca3fe236bcf3ecdf8aaebe4" category="list-text">Remontage des nouveaux systèmes de fichiers aux mêmes chemins que les systèmes de fichiers précédents</block>
  <block id="8c4271e6faf2cea4cfc8e5b7108d8ee9" category="section-title">Procédure</block>
  <block id="b273f8d4284bd1f58cfbafe8065af9fa" category="list-text">Arrêtez la base de données.</block>
  <block id="67eadd4b70772835f318e6d3027e4308" category="inline-link-macro">Convertir le système de fichiers en lecture seule</block>
  <block id="474aae6515223cc3ba71074c9d5abcae" category="list-text">Convertissez les systèmes de fichiers en lecture seule. Ceci peut être effectué plus rapidement en utilisant un script, comme indiqué dans la <block ref="2d6e37849c641071fe1cf71ac348d28c" category="inline-link-macro-rx"></block>.</block>
  <block id="4879ec77723fce4974f8ae2a7f87121a" category="list-text">Vérifiez que les systèmes de fichiers sont maintenant en lecture seule.</block>
  <block id="c91e7f5dba3c873d0978f4892bf8b3f2" category="list-text">Synchroniser le contenu du système de fichiers avec le<block ref="89a4551b0f29c1a652648b1cb8747021" prefix=" " category="inline-code"></block> commande.</block>
  <block id="91e702884985853b8a7091ed5f2beceb" category="inline-link-macro">Remplacer le système de fichiers</block>
  <block id="ea27cab9fe7b891870e0ce59aa34e853" category="list-text">Démontez les anciens systèmes de fichiers et déplacez les données copiées. Ceci peut être effectué plus rapidement en utilisant un script, comme indiqué dans la <block ref="fa3b775593af4f3de8972aced258710d" category="inline-link-macro-rx"></block>.</block>
  <block id="5fe2431acb45422c46eadf66a93851af" category="list-text">Vérifiez que les nouveaux systèmes de fichiers sont en place.</block>
  <block id="2d53403ab873059f92ad884eb271e8dc" category="list-text">Démarrez la base de données.</block>
  <block id="40351c33ab81b8b374a20fd292057481" category="section-title">Mise en service entièrement automatisée</block>
  <block id="3f70361470a11fb351c83257cd7aa63e" category="paragraph">Cet exemple de script accepte les arguments du SID de la base de données suivis de paires de systèmes de fichiers délimitées par des points communs. Pour l'exemple ci-dessus, la commande est émise comme suit :</block>
  <block id="5cddd7b314b7ae819e2cfcac85021426" category="paragraph">Lorsqu'il est exécuté, l'exemple de script tente d'exécuter la séquence suivante. Il se termine s'il rencontre une erreur dans une étape :</block>
  <block id="43d4fce7952ee09c0c8df60a17f5ea56" category="list-text">Convertissez les systèmes de fichiers actuels en mode lecture seule.</block>
  <block id="9d53d62d1e6dc69460f47c83e6c1919d" category="list-text">Utilisez chaque paire d'arguments de système de fichiers délimités par des virgules et synchronisez le premier système de fichiers avec le second.</block>
  <block id="39ff0e6dfa9915344ec96f9e78a27267" category="list-text">Démonter les systèmes de fichiers précédents.</block>
  <block id="e220fa2a2806386a64e9860f27372e43" category="list-text">Mettez à jour le<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block> classer comme suit :</block>
  <block id="232c2c4ddd45fc028ae13b58251c5f7e" category="list-text">Créez une sauvegarde à<block ref="9eb56e72a6bb8350a1453c2762d14178" prefix=" " category="inline-code"></block>.</block>
  <block id="d5082ae73767550813688202df21bc4d" category="list-text">Commenter les entrées précédentes pour les systèmes de fichiers antérieurs et nouveaux.</block>
  <block id="b8793b424d1738f1e00e545379867b0d" category="list-text">Créez une nouvelle entrée pour le nouveau système de fichiers qui utilise l'ancien point de montage.</block>
  <block id="29478980f354caa483bc0cfb827c7251" category="list-text">Montez les systèmes de fichiers.</block>
  <block id="a0ec0d8bede7d9d58172084de7d5ce53" category="paragraph">Le texte suivant fournit un exemple d'exécution pour ce script :</block>
  <block id="350265a378d2cb1183cd51d56f0e5843" category="section-title">Migration Oracle ASM spfile et passwd</block>
  <block id="f37bc722651f2fd86ba4da87f947c4db" category="paragraph">Le fichier spfile spécifique à ASM et le fichier de mots de passe constituent une difficulté pour terminer la migration impliquant ASM. Par défaut, ces fichiers de métadonnées critiques sont créés sur le premier groupe de disques ASM défini. Si un groupe de disques ASM particulier doit être évacué et supprimé, le fichier spfile et le fichier de mot de passe qui régissent cette instance ASM doivent être déplacés.</block>
  <block id="88e2a97e52f9854b59ce63e74c4b0cac" category="paragraph">Un autre cas d'utilisation où il peut être nécessaire de déplacer ces fichiers est le cas lors du déploiement d'un logiciel de gestion de base de données, tel que SnapManager pour Oracle ou le plug-in SnapCenter pour Oracle. L'une des fonctionnalités de ces produits consiste à restaurer rapidement une base de données en rétablissant l'état des LUN ASM qui hébergent les fichiers de données. Pour ce faire, vous devez mettre le groupe de disques ASM hors ligne avant d'effectuer une restauration. Ce n'est pas un problème tant que les fichiers de données d'une base de données donnée sont isolés dans un groupe de disques ASM dédié.</block>
  <block id="24de04443b6bdae76336fcab04ae946c" category="paragraph">Lorsque ce groupe de disques contient également le fichier ASM spfile/passwd, la seule façon de mettre le groupe de disques hors ligne est d'arrêter l'instance ASM entière. Il s'agit d'un processus perturbateur, ce qui signifie que le fichier spfile/passwd doit être déplacé.</block>
  <block id="a6221bf4332cc966c69066295a843480" category="list-text">SID de base de données = TOAST</block>
  <block id="0af0da2831407b8130e7f2fabdfab87d" category="list-text">Fichiers de données actuels sur<block ref="c097579d8cb34b312d396304e0b8f487" prefix=" " category="inline-code"></block></block>
  <block id="24aa2824a0b52b46b301afdb3af9336f" category="list-text">Fichiers journaux et fichiers de contrôle actuels sur<block ref="ad6062251d172504e3b3bed3a8256a5a" prefix=" " category="inline-code"></block></block>
  <block id="bb6de9ea84381f7d01fdd038f104e4ae" category="list-text">Nouveaux groupes de disques ASM définis en tant que<block ref="cb2eb5386826561ac7895f1c878e4252" prefix=" " category="inline-code"></block> et<block ref="5e20ccf28224fc0cc564f9825c208dbd" prefix=" " category="inline-code"></block></block>
  <block id="8b14bd9d310bf8b211c19645576201e3" category="section-title">Emplacements des fichiers spfile/passwd ASM</block>
  <block id="7c7d8dd5d09a73f06678562b66dcdc68" category="paragraph">La migration de ces fichiers peut s'effectuer sans interruption. Cependant, pour des raisons de sécurité, NetApp recommande de fermer l'environnement de base de données afin de vous assurer que les fichiers ont été déplacés et que la configuration est correctement mise à jour. Cette procédure doit être répétée si plusieurs instances ASM sont présentes sur un serveur.</block>
  <block id="3666b74ddcf77306328ac5d6db94fecd" category="section-title">Identifier les instances ASM</block>
  <block id="9d19a85576af8e1b3dbd78e343a2b022" category="paragraph">Identifier les instances ASM en fonction des données enregistrées dans le<block ref="9da4474b569071bcb2ece1d0bdfe7560" prefix=" " category="inline-code"></block> fichier. Les instances ASM sont signalées par un symbole +.</block>
  <block id="3fe2dd8cf6f82ac15544fd96f9b59b28" category="paragraph">Il existe une instance ASM appelée +ASM sur ce serveur.</block>
  <block id="35a557b0490d5a93931025eaaf712cac" category="section-title">Assurez-vous que toutes les bases de données sont arrêtées</block>
  <block id="e6b0819ae1eca7d408a097efc2fbf2cf" category="paragraph">Le seul processus smon visible doit être le smon de l'instance ASM utilisée. La présence d'un autre processus smon indique qu'une base de données est toujours en cours d'exécution.</block>
  <block id="97639c779a60f010af01997e2363f4eb" category="paragraph">Le seul processus smon est l'instance ASM elle-même. Cela signifie qu'aucune autre base de données n'est en cours d'exécution et que vous pouvez continuer en toute sécurité sans risque d'interruption des opérations de la base de données.</block>
  <block id="a8d157790e55d19378ddbbdfeb675ef8" category="section-title">Localisez les fichiers</block>
  <block id="12d8c982eb4072e31ac4bfe375193160" category="paragraph">Identifiez l'emplacement actuel du fichier spfile et du fichier de mots de passe ASM à l'aide du<block ref="e258dbf5114b4df07f0d9e72deb386f2" prefix=" " category="inline-code"></block> et<block ref="bb41cdf6c9bb75ee17856f938070f23d" prefix=" " category="inline-code"></block> commandes.</block>
  <block id="bebe64e9d0d4ae3d44b4dfb3583e0109" category="paragraph">Les fichiers se trouvent tous deux à la base du<block ref="c097579d8cb34b312d396304e0b8f487" prefix=" " category="inline-code"></block> groupe de disques.</block>
  <block id="558f28628ba8ab4cb8420949524832d3" category="section-title">Copier des fichiers</block>
  <block id="c0c2c850cb11c5bb52abbd55a9578e54" category="paragraph">Copiez les fichiers dans le nouveau groupe de disques ASM avec le<block ref="c0baea639672c84505e661b9e369c68a" prefix=" " category="inline-code"></block> et<block ref="c7adee97d05083a7b65e4b6953045177" prefix=" " category="inline-code"></block> commandes. Si le nouveau groupe de disques a été créé récemment et est actuellement vide, il peut être nécessaire de le monter en premier.</block>
  <block id="3ed2faf3e1299edd7d92d6c4064f1579" category="paragraph">Les fichiers ont été copiés depuis<block ref="c097579d8cb34b312d396304e0b8f487" prefix=" " category="inline-code"></block> à<block ref="cb2eb5386826561ac7895f1c878e4252" prefix=" " category="inline-code"></block>.</block>
  <block id="1dba5fc559232a8dae45d9f88ed36030" category="section-title">Mettre à jour l'instance ASM</block>
  <block id="1fe2cc6cf436a4bcc6bdc41f947a416a" category="paragraph">L'instance ASM doit maintenant être mise à jour pour refléter le changement d'emplacement. Le<block ref="c8b1affa9ec15d0c0e79347905e75d3e" prefix=" " category="inline-code"></block> et<block ref="73fb08020d8535b4123a8968c596038c" prefix=" " category="inline-code"></block> Les commandes mettent à jour les métadonnées ASM requises pour démarrer le groupe de disques ASM.</block>
  <block id="626759f91a0458b0c068cce8a05a6468" category="section-title">Activez ASM à l'aide de fichiers mis à jour</block>
  <block id="69f08287c6faa04381e5a05f4087abe1" category="paragraph">À ce stade, l'instance ASM utilise toujours les emplacements précédents de ces fichiers. L'instance doit être redémarrée pour forcer une relecture des fichiers à partir de leurs nouveaux emplacements et pour libérer les verrous sur les fichiers précédents.</block>
  <block id="5505cf0c514193b89221f1cef3004c58" category="section-title">Supprimez les anciens fichiers spfile et les anciens fichiers de mots de passe</block>
  <block id="8f2d3ac58be7a91f51d7ce9ffa04e397" category="paragraph">Si la procédure a été effectuée avec succès, les fichiers précédents ne sont plus verrouillés et peuvent maintenant être supprimés.</block>
  <block id="cfca2b2eb0d694e70904ec82f5d1c34e" category="section-title">Copie d'Oracle ASM vers ASM</block>
  <block id="12632d520b8d9518b5622ac00dc764a8" category="paragraph">Oracle ASM est essentiellement un gestionnaire de volumes combiné léger et un système de fichiers. Comme le système de fichiers n'est pas facilement visible, RMAN doit être utilisé pour effectuer des opérations de copie. Même si un processus de migration basé sur la copie est sûr et simple, il provoque certaines perturbations. Les interruptions peuvent être minimisées, mais pas totalement éliminées.</block>
  <block id="152106ebb2aaa94cc87657d353331189" category="paragraph">Si vous souhaitez effectuer une migration sans interruption d'une base de données ASM, il est préférable d'exploiter la capacité d'ASM à rééquilibrer les extensions ASM vers de nouveaux LUN lors de la suppression des anciennes LUN. Cette opération est généralement sûre et non disruptive, mais elle n'offre pas de chemin « back-out ». En cas de problèmes fonctionnels ou de performances, la seule option consiste à migrer les données vers la source.</block>
  <block id="81fe23a1ac3b2bb348e579b2c5b0f5d5" category="paragraph">Ce risque peut être évité en copiant la base de données vers le nouvel emplacement plutôt que de déplacer les données, afin que les données d'origine ne soient pas modifiées. La base de données peut être entièrement testée à son nouvel emplacement avant la mise en service, et la base de données d'origine est disponible comme option de retour en arrière si des problèmes sont détectés.</block>
  <block id="3028182db088e823770b3d02aa0eac9e" category="paragraph">Cette procédure est l'une des nombreuses options impliquant RMAN. Il est conçu pour permettre un processus en deux étapes dans lequel la sauvegarde initiale est créée, puis synchronisée par la suite via la relecture du journal. Ce processus est recommandé pour réduire les temps d'indisponibilité, car il permet à la base de données de rester opérationnelle et d'assurer l'accès aux données pendant la copie de base initiale.</block>
  <block id="634f50a6c6f112c46150a301d749dbcb" category="section-title">Copier la base de données</block>
  <block id="5f0bd85dd65afab1472713e8e034fff7" category="paragraph">Oracle RMAN crée une copie de niveau 0 (complète) de la base de données source actuellement située sur le groupe de disques ASM<block ref="c097579d8cb34b312d396304e0b8f487" prefix=" " category="inline-code"></block> vers le nouvel emplacement sur<block ref="cb2eb5386826561ac7895f1c878e4252" prefix=" " category="inline-code"></block>.</block>
  <block id="b51dc519efad4b151a05682b68f4b182" category="section-title">Forcer le changement de journal d'archivage</block>
  <block id="10793485747151dfa2eaddb0854c84b2" category="paragraph">Vous devez forcer un commutateur de journal d'archivage pour vous assurer que les journaux d'archivage contiennent toutes les données nécessaires pour que la copie soit totalement cohérente. Sans cette commande, les données clés peuvent toujours être présentes dans les journaux de reprise.</block>
  <block id="c55a88a6b8fdc5972d4e2a4924f93dbf" category="section-title">Arrêtez la base de données source</block>
  <block id="9ec82bff06c706f42a8170befdd6cf39" category="paragraph">L'interruption commence à cette étape car la base de données est arrêtée et placée en mode lecture seule à accès limité. Pour arrêter la base de données source, exécutez les commandes suivantes :</block>
  <block id="6ecf02e1343e82cf0cd95d7303346ff1" category="section-title">Sauvegarde Controlfile</block>
  <block id="e7bc82f6d1381df55ace121dc02368e6" category="paragraph">Vous devez sauvegarder le fichier de contrôle si vous devez abandonner la migration et revenir à l'emplacement de stockage d'origine. Une copie du fichier de contrôle de sauvegarde n'est pas nécessaire à 100 %, mais elle facilite le processus de réinitialisation des emplacements des fichiers de base de données vers leur emplacement d'origine.</block>
  <block id="4e7a51f2c1ee60c69cd719d415f5e87a" category="paragraph">Le fichier spfile actuel contient des références aux fichiers de contrôle sur leurs emplacements actuels dans l'ancien groupe de disques ASM. Il doit être édité, ce qui est facile à faire en éditant une version intermédiaire de pfile.</block>
  <block id="253e30479f86461bc79f2fca58ee4cb1" category="section-title">Mettre à jour le fichier pfile</block>
  <block id="35db8a54b9c7581f0f77b059233cc61b" category="paragraph">Mettez à jour tous les paramètres faisant référence aux anciens groupes de disques ASM pour refléter les nouveaux noms de groupes de disques ASM. Enregistrez ensuite le fichier pfile mis à jour. Assurez-vous que le<block ref="5fa1d01559c04dcdb3ba05775712b1ab" prefix=" " category="inline-code"></block> des paramètres sont présents.</block>
  <block id="bb607fbd46f48c3a4080ecda83288b69" category="paragraph">Dans l'exemple ci-dessous, les références à<block ref="c097579d8cb34b312d396304e0b8f487" prefix=" " category="inline-code"></block> ils ont été remplacés par<block ref="cb2eb5386826561ac7895f1c878e4252" prefix=" " category="inline-code"></block> sont surlignés en jaune. Deux paramètres clés sont le<block ref="5fa1d01559c04dcdb3ba05775712b1ab" prefix=" " category="inline-code"></block> paramètres qui créent de nouveaux fichiers à l'emplacement correct.</block>
  <block id="5275e85db4d606621d8f074e44b95748" category="section-title">Mettre à jour le fichier init.ora</block>
  <block id="17a2b5d1af48f7f8d1511d5372896f7a" category="paragraph">La plupart des bases de données ASM utilisent un<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> fichier situé dans le<block ref="45c7302d9c2e8745b3a2bff0f992b6df" prefix=" " category="inline-code"></block> Répertoire, qui est un point vers le fichier spfile sur le groupe de disques ASM. Ce fichier doit être redirigé vers un emplacement du nouveau groupe de disques ASM.</block>
  <block id="6ad274256421918b584abff3b9446b09" category="paragraph">Modifiez ce fichier comme suit :</block>
  <block id="b6638505615764c377e2cf2585993fd0" category="section-title">Récréation du fichier de paramètres</block>
  <block id="52b21c2e6103a3b8d888a4185e21a787" category="paragraph">Le fichier spfile est maintenant prêt à être rempli par les données du fichier pfile modifié.</block>
  <block id="37f4738eddd35e77d15af55a40e1ab1c" category="section-title">Démarrez la base de données pour commencer à utiliser le nouveau fichier spfile</block>
  <block id="79f8a930424fe3b21dc30a72791171d4" category="paragraph">Démarrez la base de données pour vous assurer qu'elle utilise maintenant le fichier spfile nouvellement créé et que toute autre modification des paramètres système est correctement enregistrée.</block>
  <block id="231ef0ea12d142611eeea2fdfad67114" category="section-title">Restaurer le fichier de contrôle</block>
  <block id="33cdbbeabc7f2c647f20b3f8b924307f" category="paragraph">Le fichier de contrôle de sauvegarde créé par RMAN peut également être restauré directement par RMAN à l'emplacement spécifié dans le nouveau fichier spfile.</block>
  <block id="ce656b7f351ebdc7c599aff6a99e0f2a" category="paragraph">Montez la base de données et vérifiez l'utilisation du nouveau fichier de contrôle.</block>
  <block id="fda1e79fe400519496075b7e2871092a" category="section-title">Relecture du journal</block>
  <block id="daaec4441f16b5bac11476d4582a296c" category="paragraph">La base de données utilise actuellement les fichiers de données dans l'ancien emplacement. Avant de pouvoir utiliser la copie, elles doivent être synchronisées. Le temps s'est écoulé pendant le processus de copie initial et les modifications ont été enregistrées principalement dans les journaux d'archivage. Ces modifications sont répliquées comme suit :</block>
  <block id="fca6726270a94f51cab3142509d32919" category="list-text">Effectuez une sauvegarde incrémentielle RMAN contenant les journaux d'archivage.</block>
  <block id="8b8a5667b011b5f37163ff4da1004343" category="list-text">Relire le journal.</block>
  <block id="a9a62e70841c4d06dd16306a85700d36" category="section-title">Activation</block>
  <block id="8fecb0145484a35b1d9d5926c945ca30" category="paragraph">Le fichier de contrôle restauré fait toujours référence aux fichiers de données à l'emplacement d'origine et contient également les informations de chemin des fichiers de données copiés.</block>
  <block id="f590db5fdc10f6942f7cd173c0bb578b" category="list-text">Pour modifier les fichiers de données actifs, exécutez<block ref="7705ebb59373d0b1dfc71d86ef726f93" prefix=" " category="inline-code"></block> commande.</block>
  <block id="2c5c2b5174eafe321358329636e80f5e" category="paragraph">Les fichiers de données actifs sont désormais les fichiers de données copiés, mais des modifications peuvent encore être contenues dans les journaux de reprise finaux.</block>
  <block id="fe83c5826bec1aa20e26802fa94a4a0f" category="list-text">Pour relire tous les journaux restants, exécutez le<block ref="81168dbef15af03d02c51a7447378e76" prefix=" " category="inline-code"></block> commande. Si le message s'affiche<block ref="cef3519da39a73834e89a18ca91951f1" prefix=" " category="inline-code"></block> apparaît, le processus a réussi.</block>
  <block id="15434ad90ad32205a804fe96f265b91d" category="paragraph">Ce processus a uniquement modifié l'emplacement des fichiers de données normaux. Les fichiers de données temporaires doivent être renommés, mais ils n'ont pas besoin d'être copiés car ils sont temporaires uniquement. La base de données est actuellement inactive, il n'y a donc pas de données actives dans les fichiers de données temporaires.</block>
  <block id="2a7c5560f8e4ad220c853666c46eb051" category="list-text">Pour déplacer les fichiers de données temporaires, identifiez d'abord leur emplacement.</block>
  <block id="10b2632cf9c3bf6568b36f6a37e627c2" category="list-text">Déplacez les fichiers de données temporaires à l'aide d'une commande RMAN qui définit le nouveau nom de chaque fichier de données. Avec Oracle Managed Files (OMF), le nom complet n'est pas nécessaire ; le groupe de disques ASM est suffisant. Lorsque la base de données est ouverte, OMF est lié à l'emplacement approprié sur le groupe de disques ASM. Pour déplacer des fichiers, exécutez les commandes suivantes :</block>
  <block id="2c592b1e2841899b280deafe27eeefbf" category="section-title">Migration du journal de reprise</block>
  <block id="3f53598059c3bf11ff505ad9dc0d6776" category="paragraph">Le processus de migration est presque terminé, mais les journaux de reprise se trouvent toujours sur le groupe de disques ASM d'origine. Les journaux de reprise ne peuvent pas être transférés directement. Un nouvel ensemble de journaux de reprise est créé et ajouté à la configuration, suivi d'un DROP des anciens journaux.</block>
  <block id="d54f1c98a924385411a8488657b21dad" category="list-text">Pour chaque journal de reprise, créez un groupe avec une configuration correspondante. Si vous n'utilisez pas OMF, vous devez spécifier le chemin complet. C'est également un exemple qui utilise le<block ref="c9655c773db3ebd5871fbe76c0e38a52" prefix=" " category="inline-code"></block> paramètres. Comme indiqué précédemment, ce paramètre a été défini sur +NEWLOGS. Cette configuration vous permet d'utiliser les commandes suivantes pour créer de nouveaux journaux en ligne sans avoir à spécifier un emplacement de fichier ou même un groupe de disques ASM spécifique.</block>
  <block id="3e0c7c8ee841e9919343fe45e3e04f2d" category="list-text">Ouvrez la base de données.</block>
  <block id="7e4b38db083a404d0d628bdb1ad83311" category="list-text">Supprimez les anciens journaux.</block>
  <block id="37e48dd687a01e58ed329feebebf3198" category="list-text">Si vous rencontrez une erreur qui vous empêche de supprimer un journal actif, forcez un commutateur au journal suivant pour libérer le verrouillage et forcer un point de contrôle global. Un exemple est illustré ci-dessous. La tentative de suppression du groupe de fichiers journaux 3, qui se trouvait sur l'ancien emplacement, a été refusée parce qu'il y avait encore des données actives dans ce fichier journal. Un archivage de journaux après un point de contrôle vous permet de supprimer le fichier journal.</block>
  <block id="79d08abfbe5fd73dc85c55cd20ad4974" category="list-text">Vérifiez l'environnement pour vous assurer que tous les paramètres basés sur l'emplacement sont mis à jour.</block>
  <block id="799f5ce04f1d9cad4455676b2fd908d9" category="list-text">Le script suivant explique comment simplifier ce processus :</block>
  <block id="9867dfc0eee2725f24f86d8114c356a0" category="list-text">Si les groupes de disques ASM ont été complètement évacués, ils peuvent maintenant être démontés avec<block ref="ae709dc3414219bf2c9c8abc9ff6c67a" prefix=" " category="inline-code"></block>. Cependant, dans de nombreux cas, les fichiers appartenant à d'autres bases de données ou au fichier ASM spfile/passwd peuvent toujours être présents.</block>
  <block id="49f8dc5754bd205ea0da17521cb89a1f" category="section-title">Copie d'Oracle ASM vers le système de fichiers</block>
  <block id="0f5b1767a58e43cb548226e94441dc07" category="paragraph">La procédure de copie d'Oracle ASM vers un système de fichiers est très similaire à la procédure de copie d'ASM vers ASM, avec des avantages et des restrictions similaires. La différence principale est la syntaxe des différentes commandes et paramètres de configuration lors de l'utilisation d'un système de fichiers visible par opposition à un groupe de disques ASM.</block>
  <block id="b533404c568b600f9fceddeac9253964" category="paragraph">Oracle RMAN permet de créer une copie de niveau 0 (complète) de la base de données source actuellement située sur le groupe de disques ASM<block ref="c097579d8cb34b312d396304e0b8f487" prefix=" " category="inline-code"></block> vers le nouvel emplacement sur<block ref="f006bf17b06c884c47190c4225d3215a" prefix=" " category="inline-code"></block>.</block>
  <block id="f78b0ab71e2863c28dbe331056451135" category="paragraph">Forcer le commutateur de journal d'archivage est nécessaire pour s'assurer que les journaux d'archivage contiennent toutes les données requises pour rendre la copie entièrement cohérente. Sans cette commande, les données clés peuvent toujours être présentes dans les journaux de reprise. Pour forcer un commutateur de journal d'archivage, exécutez la commande suivante :</block>
  <block id="c37c761fc28428b9ead4533aba9ee148" category="paragraph">L'interruption commence à cette étape car la base de données est arrêtée et placée en mode lecture seule à accès limité. Pour arrêter la base de données source, exécutez les commandes suivantes :</block>
  <block id="3abd8870d8a333edcaec6a1082520c67" category="paragraph">Sauvegarder les fichiers de contrôle si vous devez abandonner la migration et revenir à l'emplacement de stockage d'origine. Une copie du fichier de contrôle de sauvegarde n'est pas nécessaire à 100 %, mais elle facilite le processus de réinitialisation des emplacements des fichiers de base de données vers leur emplacement d'origine.</block>
  <block id="38825215f02e25ca63ff64387b01c1c2" category="paragraph">Tous les paramètres faisant référence aux anciens groupes de disques ASM doivent être mis à jour et, dans certains cas, supprimés lorsqu'ils ne sont plus pertinents. Mettez-les à jour pour refléter les nouveaux chemins du système de fichiers et enregistrez le fichier pfile mis à jour. Assurez-vous que le chemin cible complet est répertorié. Pour mettre à jour ces paramètres, exécutez les commandes suivantes :</block>
  <block id="9d0dce3e570fa0ec18269ca508809401" category="section-title">Désactivez le fichier init.ora d'origine</block>
  <block id="03dda6526778417460fd0bbb7716b373" category="paragraph">Ce fichier se trouve dans le<block ref="45c7302d9c2e8745b3a2bff0f992b6df" prefix=" " category="inline-code"></block> Et se trouve généralement dans un fichier pfile qui sert de pointeur vers le fichier spfile sur le groupe de disques ASM. Pour vous assurer que le fichier spfile d'origine n'est plus utilisé, renommez-le. Ne le supprimez pas, cependant, car ce fichier est nécessaire si la migration doit être abandonnée.</block>
  <block id="6087f741090627369fd114fbc794abc4" category="paragraph">Il s'agit de la dernière étape de la relocalisation de fichier spfile. Le fichier spfile d'origine n'est plus utilisé et la base de données est actuellement démarrée (mais pas montée) à l'aide du fichier intermédiaire. Le contenu de ce fichier peut être écrit dans le nouvel emplacement spfile comme suit :</block>
  <block id="3f62847435205b7b2af1bd5aaf1d3277" category="paragraph">Vous devez démarrer la base de données pour libérer les verrous sur le fichier intermédiaire et démarrer la base de données en utilisant uniquement le nouveau fichier spfile. Le démarrage de la base de données prouve également que le nouvel emplacement spfile est correct et que ses données sont valides.</block>
  <block id="ea164abfd83078cd71a2f3ba5d237900" category="paragraph">Un fichier de contrôle de sauvegarde a été créé au niveau du chemin<block ref="7a1a1280501cff0194d8ce6e351f2a2c" prefix=" " category="inline-code"></block> plus tôt dans la procédure. Le nouveau fichier spfile définit les emplacements des fichiers de contrôle comme <block ref="b4d54c88ccade13a82dcaf8f7c07cac5" prefix="/" category="inline-code"></block> et<block ref="cd300fb0386526438b368e7a6d1b8ace" prefix=" " category="inline-code"></block>. Cependant, ces fichiers n'existent pas encore.</block>
  <block id="f7ed72e578ca8d23dd45bfa2c0a61ed8" category="list-text">Cette commande restaure les données du fichier de contrôle dans les chemins définis dans le fichier spfile.</block>
  <block id="c947c89cb4c7a595782d0be73bbe8cfa" category="list-text">Exécutez la commande mount pour que les fichiers de contrôle soient correctement découverts et contiennent des données valides.</block>
  <block id="da4ae71a31a1286600968f8a340fddb2" category="paragraph">Pour valider le<block ref="d98137bd230dac4372cf20a2e7839463" prefix=" " category="inline-code"></block> paramètre, exécutez la commande suivante :</block>
  <block id="c25a81770c591c46d6909aae84bf5814" category="paragraph">La base de données utilise actuellement les fichiers de données dans l'ancien emplacement. Avant de pouvoir utiliser la copie, les fichiers de données doivent être synchronisés. Le temps s'est écoulé pendant le processus de copie initial et les modifications ont été enregistrées principalement dans les journaux d'archivage. Ces modifications sont répliquées dans les deux étapes suivantes.</block>
  <block id="95ea23a5654037c0ab2a5418478d9da2" category="list-text">Relire les journaux.</block>
  <block id="e726fdb8508ef59abc6d8ef533186382" category="list-text">Pour modifier les fichiers de données actifs, exécutez<block ref="7705ebb59373d0b1dfc71d86ef726f93" prefix=" " category="inline-code"></block> commande :</block>
  <block id="7fdba4cfea0e0d298cda23e7f46e40c4" category="list-text">Bien que les fichiers de données soient parfaitement cohérents, une dernière étape est nécessaire pour relire les modifications restantes enregistrées dans les journaux de reprise en ligne. Utilisez le<block ref="81168dbef15af03d02c51a7447378e76" prefix=" " category="inline-code"></block> pour relire ces modifications et rendre la copie identique à 100 % à l'original. Toutefois, la copie n'est pas encore ouverte.</block>
  <block id="8eb94d53286760da56ca9c892a49cd8b" category="section-title">Déplacer les fichiers de données temporaires</block>
  <block id="a1e7f15bee0eaa976661307aa884fd99" category="list-text">Identifiez l'emplacement des fichiers de données temporaires toujours en cours d'utilisation sur le groupe de disques d'origine.</block>
  <block id="89b79c94ceba42d5bc646c1b4b1acd24" category="list-text">Pour déplacer les fichiers de données, exécutez les commandes suivantes. S'il existe de nombreux fichiers tempfiles, utilisez un éditeur de texte pour créer la commande RMAN, puis coupez-la et collez-la.</block>
  <block id="81aa65cb154a5f125bbf3ede064d4b3f" category="paragraph">Le processus de migration est presque terminé, mais les journaux de reprise se trouvent toujours sur le groupe de disques ASM d'origine. Les journaux de reprise ne peuvent pas être transférés directement. Un nouvel ensemble de journaux de reprise est créé et ajouté à la configuration, suivant un DROP des anciens journaux.</block>
  <block id="6e46687c6cc5deabe53fa42932683c4d" category="list-text">Pour chaque fichier redo log, créez un groupe en utilisant la même taille que le groupe de fichiers redo log actuel à l'aide du nouvel emplacement du système de fichiers.</block>
  <block id="22fd48a866ce4d04edb57c15b2fad5da" category="list-text">Supprimez les anciens groupes de fichiers journaux qui se trouvent toujours sur le stockage précédent.</block>
  <block id="94158400e59555bf69ecd550887bd9f6" category="list-text">Si une erreur bloque la suppression d'un journal actif, forcez un commutateur au journal suivant pour libérer le verrouillage et forcer un point de contrôle global. Un exemple est illustré ci-dessous. La tentative de suppression du groupe de fichiers journaux 3, qui se trouvait sur l'ancien emplacement, a été refusée parce qu'il y avait encore des données actives dans ce fichier journal. L'archivage des journaux suivi d'un point de contrôle permet la suppression des fichiers journaux.</block>
  <block id="326770a786c5933416b6a167c854e7b8" category="list-text">Le script suivant explique comment faciliter ce processus.</block>
  <block id="ffdcdc8ee9653232a906773fa11358fd" category="list-text">Si les groupes de disques ASM ont été complètement évacués, ils peuvent maintenant être démontés avec<block ref="ae709dc3414219bf2c9c8abc9ff6c67a" prefix=" " category="inline-code"></block>. Dans de nombreux cas, les fichiers appartenant à d'autres bases de données ou au fichier ASM spfile/passwd peuvent toujours être présents.</block>
  <block id="3d8b8f4734039817e35d5fb6993c8d08" category="section-title">Procédure de nettoyage du fichier de données</block>
  <block id="637607e2203ac522fc9dbc88deb6c36f" category="inline-link-macro">Nettoyage de migration ASM</block>
  <block id="18325b8b206963bc1ae6cca25406f942" category="paragraph">Le processus de migration peut donner lieu à des fichiers de données avec une syntaxe longue ou chiffrée, selon la façon dont Oracle RMAN a été utilisé. Dans l'exemple illustré ici, la sauvegarde a été effectuée avec le format de fichier de<block ref="1da91ad80bcfeb818066022a42cde773" prefix=" " category="inline-code"></block>.<block ref="432459869b7d0085e120ec9454032267" prefix=" " category="inline-code"></block> Indique que RMAN doit créer un nom unique par défaut pour chaque fichier de données. Le résultat est similaire à ce qui est affiché dans le texte suivant. Les noms traditionnels des fichiers de données sont incorporés dans les noms. Pour ce faire, utilisez l'approche par script illustrée à la <block ref="bf0c2c579af181f7d1e4d0267c1385fe" category="inline-link-macro-rx"></block>.</block>
  <block id="5e8488a95f83d2789417a1f3298f2f31" category="section-title">Rééquilibrage d'Oracle ASM</block>
  <block id="2768938325db3a71a6713959a0f309d9" category="paragraph">Comme nous l'avons vu précédemment, un groupe de disques Oracle ASM peut être migré en toute transparence vers un nouveau système de stockage en utilisant le processus de rééquilibrage. En résumé, le processus de rééquilibrage nécessite l'ajout de LUN de taille égale au groupe existant de LUN, suivi d'une opération de DROP de la LUN précédente. Oracle ASM déplace automatiquement les données sous-jacentes vers un nouveau stockage selon une disposition optimale, puis libère les anciens LUN une fois l'opération terminée.</block>
  <block id="24a638b29b3c55f26c731aa4b9943a52" category="paragraph">Le processus de migration utilise des E/S séquentielles efficaces et ne provoque généralement aucune interruption des performances. En revanche, le taux de migration peut être ralenti lorsque cela est nécessaire.</block>
  <block id="25d06b03dd002ad791b19500c58e9f72" category="section-title">Identifiez les données à migrer</block>
  <block id="3709d4034873467e8e6ae138da54a443" category="section-title">Créer des LUN</block>
  <block id="32176bd565539329eafb96db9447e517" category="paragraph">Créez de nouvelles LUN de la même taille et définissez l'appartenance des utilisateurs et des groupes selon les besoins. Les LUN doivent s'afficher comme<block ref="bea4821516973214973a70aea8337c38" prefix=" " category="inline-code"></block> disques.</block>
  <block id="6e59535a7b8dd239c67b8d015618f5e1" category="section-title">Ajouter de nouvelles LUN</block>
  <block id="71f7e1ff1a6e075f8364d083f145b655" category="paragraph">Même si les opérations d'ajout et de suppression peuvent être effectuées ensemble, il est généralement plus facile d'ajouter de nouvelles LUN en deux étapes. Commencez par ajouter les nouvelles LUN au groupe de disques. Cette étape entraîne la migration de la moitié des extensions des LUN ASM actuelles vers les nouvelles LUN.</block>
  <block id="7989dfdf722e8bee00001dac817e4833" category="paragraph">La puissance de rééquilibrage indique la vitesse à laquelle les données sont transférées. Plus le nombre est élevé, plus le parallélisme du transfert de données est élevé. La migration s'effectue au moyen d'opérations d'E/S séquentielles efficaces, peu susceptibles d'entraîner des problèmes de performances. Toutefois, si nécessaire, le pouvoir de rééquilibrage d'une migration en cours peut être ajusté avec le<block ref="e20ea7dfbbe351f6a5275d7adc71efbd" prefix=" " category="inline-code"></block> commande. Les migrations types utilisent une valeur de 5.</block>
  <block id="2b69f08c262a142b3fb0868f4d31ab4f" category="section-title">Surveiller le fonctionnement</block>
  <block id="a5097a0967c777285f74d63bf0cc26a1" category="paragraph">Une opération de rééquilibrage peut être contrôlée et gérée de plusieurs manières. Nous avons utilisé la commande suivante dans cet exemple.</block>
  <block id="5d68829c11bdb5ae7a50b847bb126d44" category="paragraph">Une fois la migration terminée, aucune opération de rééquilibrage n'est signalée.</block>
  <block id="957310262614cddc1992368d2d0b14b3" category="section-title">Supprimez les anciennes LUN</block>
  <block id="260c16583c8eb689202ed5b4a44708b1" category="paragraph">La migration est maintenant terminée à mi-chemin. Il peut être souhaitable d'effectuer quelques tests de performances de base pour s'assurer que l'environnement est sain. Après confirmation, les données restantes peuvent être déplacées en déposant les anciennes LUN. Notez que cela ne provoque pas la publication immédiate des LUN. L'opération de DROP indique à Oracle ASM de déplacer d'abord les extensions, puis de libérer la LUN.</block>
  <block id="90423249814011b02ba06afd9fb2d617" category="paragraph">L'opération de rééquilibrage peut être contrôlée et gérée de plusieurs manières. Nous avons utilisé la commande suivante dans cet exemple :</block>
  <block id="1544b3a52519b3856f1f7d1e704cb56f" category="section-title">Supprimer les anciens LUN</block>
  <block id="983d704730b30910fc03d3ed444278f0" category="paragraph">Avant de supprimer les anciennes LUN du groupe de disques, vous devez effectuer une dernière vérification de l'état de l'en-tête. Une fois qu'une LUN est libérée d'ASM, son nom n'est plus répertorié et son état est répertorié comme<block ref="e2ffc99cf675f5f0f1a3456438551a9a" prefix=" " category="inline-code"></block>. Cela signifie que ces LUN peuvent être supprimées du système en toute sécurité.</block>
  <block id="22a67c375eff91d37f2363ea69b0c41f" category="section-title">Migration LVM</block>
  <block id="d52f83c78118c243801797ba9b795b72" category="paragraph">La procédure présentée ici présente les principes d'une migration basée sur LVM d'un groupe de volumes appelé<block ref="ec2db4422261eae02091227fb9e53c88" prefix=" " category="inline-code"></block>. Les exemples sont tirés du LVM Linux, mais les principes s'appliquent également à AIX, HP-UX et VxVM. Les commandes précises peuvent varier.</block>
  <block id="64a375907ede7a86c9e8a1b4b142f22e" category="list-text">Identifiez les LUN actuellement dans le<block ref="ec2db4422261eae02091227fb9e53c88" prefix=" " category="inline-code"></block> groupe de volumes.</block>
  <block id="0ae75856dd12545cdd98b8cad5c12ad8" category="list-text">Créez de nouvelles LUN de taille physique identique ou légèrement supérieure et définissez-les comme volumes physiques.</block>
  <block id="2426fa707e9d362c711977b79acd65bb" category="list-text">Ajoutez les nouveaux volumes au groupe de volumes.</block>
  <block id="02443ebd7f86c3a688a1e3466d3f106a" category="list-text">Émettez le<block ref="8167c9a6bd495f7ed235364201039099" prefix=" " category="inline-code"></block> Commande permettant de déplacer les extensions de chaque LUN actuelle vers la nouvelle LUN. Le<block ref="1b464374742cfda0167b82bc6f9462f1" prefix=" " category="inline-code"></block> l'argument surveille la progression de l'opération.</block>
  <block id="ce4a174d56245f6ba5b8808527919921" category="list-text">Une fois ce processus terminé, supprimez les anciennes LUN du groupe de volumes à l'aide du<block ref="3a4d1e7b0af1cf3d80e419c09d238535" prefix=" " category="inline-code"></block> commande. En cas de réussite, la LUN peut être supprimée en toute sécurité du système.</block>
  <block id="599a80136f745b38f35077e1c7eb020e" category="summary">Procédures de migration Oracle</block>
  <block id="329ffa7a9038afa62748f87628b749d5" category="paragraph">De nombreuses procédures sont disponibles pour la migration d'une base de données Oracle. Le bon dépend des besoins de votre entreprise.</block>
  <block id="48a2d08de8943e7ca4718c02e6b791b6" category="paragraph">Dans de nombreux cas, les administrateurs système et les administrateurs de bases de données utilisent leurs propres méthodes de déplacement des données de volume physique, de mise en miroir et de déréplication, ou d'utilisation d'Oracle RMAN pour la copie des données.</block>
  <block id="79d01f6e7efcfef7db530c0b3c5ea516" category="paragraph">Ces procédures sont fournies principalement à titre de conseils pour le personnel INFORMATIQUE qui connaît moins bien certaines des options disponibles. En outre, ces procédures illustrent les tâches, les exigences en termes de temps et les besoins en compétences de chaque approche de migration. Ainsi, d'autres parties, telles que NetApp et les services professionnels partenaires ou la direction INFORMATIQUE, peuvent mieux apprécier les exigences de chaque procédure.</block>
  <block id="5604c71a7d9ae37df511cc85052c1894" category="paragraph">Il n'existe pas de meilleure pratique unique pour créer une stratégie de migration. Pour créer un plan, il faut d'abord comprendre les options de disponibilité, puis sélectionner la méthode la mieux adaptée aux besoins de l'entreprise. La figure ci-dessous illustre les considérations de base et les conclusions types des clients, mais elle n'est pas universellement applicable à toutes les situations.</block>
  <block id="fa2e72668f7d48694bef3ba5474e3967" category="paragraph">Par exemple, une étape soulève le problème de la taille totale de la base de données. L'étape suivante dépend si la base de données est supérieure ou inférieure à 1 To. Les étapes recommandées sont précisément des recommandations basées sur les pratiques standard des clients. La plupart des clients n'utiliseraient pas DataGuard pour copier une petite base de données, mais d'autres pourraient le faire. La plupart des clients ne tenteraient pas de copier une base de données de 50 To en raison du temps nécessaire, mais certaines peuvent disposer d'une fenêtre de maintenance suffisamment longue pour permettre une telle opération.</block>
  <block id="e38af1623479eee6cfe1782df43819d3" category="paragraph">Oracle 12cR1 et versions supérieures incluent la possibilité de déplacer un fichier de données pendant que la base de données reste en ligne. Il fonctionne en outre entre différents types de systèmes de fichiers. Par exemple, un fichier de données peut être déplacé d'un système de fichiers xfs vers ASM. Cette méthode n'est généralement pas utilisée à grande échelle en raison du nombre d'opérations de déplacement de fichiers de données individuelles qui seraient requises. Toutefois, il est important de tenir compte de cette méthode avec des bases de données plus petites et moins de fichiers de données.</block>
  <block id="5972a038819f045814401b2baea9ee09" category="paragraph">En outre, le simple déplacement d'un fichier de données est une bonne option pour migrer des parties de bases de données existantes. Par exemple, les fichiers de données moins actifs peuvent être transférés vers un stockage plus économique, tel qu'un volume FabricPool qui peut stocker les blocs inactifs dans le magasin d'objets.</block>
  <block id="fcdd0d9eae6df775f1bdc52f950a0160" category="section-title">Migration au niveau de la base de données</block>
  <block id="2b619622b2b8505c335acc8be3a2c3fd" category="paragraph">La migration au niveau de la base de données signifie que la base de données peut déplacer des données. Plus précisément, cela signifie l'envoi de journaux. Des technologies telles que RMAN et ASM sont des produits Oracle, mais pour la migration, elles fonctionnent au niveau de l'hôte où elles copient les fichiers et gèrent les volumes.</block>
  <block id="1048000638cc5357b8b2b36ab55cbc5a" category="section-title">Envoi de journaux</block>
  <block id="36f7294e33f88b462199b92362434684" category="paragraph">La base de la migration au niveau de la base de données est le journal d'archivage Oracle, qui contient un journal des modifications apportées à la base de données. La plupart du temps, un journal d'archivage fait partie d'une stratégie de sauvegarde et de restauration. Le processus de restauration commence par la restauration d'une base de données, puis la relecture d'un ou plusieurs journaux d'archivage pour ramener la base de données à l'état souhaité. Cette même technologie de base peut être utilisée pour effectuer une migration avec une interruption des opérations nulle ou minime. Plus important encore, cette technologie permet la migration tout en conservant la base de données d'origine intacte, ce qui permet de conserver un chemin de retour.</block>
  <block id="d43de5ded302797939b76670bc488b51" category="paragraph">Le processus de migration commence par la restauration d'une sauvegarde de base de données sur un serveur secondaire. Vous pouvez le faire de différentes manières, mais la plupart des clients utilisent leur application de sauvegarde normale pour restaurer les fichiers de données. Une fois les fichiers de données restaurés, les utilisateurs établissent une méthode d'envoi des journaux. L'objectif est de créer un flux constant de journaux d'archivage générés par la base de données primaire et de les relire sur la base de données restaurée afin de les conserver dans un état similaire. Lorsque le délai de mise en service arrive, la base de données source est complètement arrêtée et les journaux d'archivage finaux, et dans certains cas les journaux de reprise, sont copiés et relus. Il est essentiel que les journaux de reprise soient également pris en compte, car ils peuvent contenir certaines des transactions finales validées.</block>
  <block id="f6fc42763ddbd981d5803ee6676dc7c3" category="paragraph">Une fois ces journaux transférés et relus, les deux bases de données sont cohérentes l'une avec l'autre. À ce stade, la plupart des clients effectuent des tests de base. Si des erreurs sont commises pendant le processus de migration, la relecture du journal doit signaler les erreurs et échouer. Il est toujours conseillé d'effectuer des tests rapides basés sur des requêtes connues ou des activités applicatives pour vérifier que la configuration est optimale. Il est également courant de créer une table de test finale avant d'arrêter la base de données d'origine pour vérifier qu'elle est présente dans la base de données migrée. Cette étape permet de s'assurer qu'aucune erreur n'a été effectuée lors de la synchronisation finale du journal.</block>
  <block id="d8e9d23b4beb4db3da15d77542782747" category="paragraph">Une simple migration d'envoi de journaux peut être configurée hors bande par rapport à la base de données d'origine, ce qui la rend particulièrement utile pour les bases de données stratégiques. Il n'est pas nécessaire de modifier la configuration de la base de données source, car la restauration et la configuration initiale de l'environnement de migration n'affectent pas les opérations de production. Une fois l'envoi de journaux configuré, il impose des demandes d'E/S sur les serveurs de production. Cependant, l'envoi de journaux se compose de simples lectures séquentielles des journaux d'archivage, qui n'ont probablement aucun impact sur les performances des bases de données de production.</block>
  <block id="2c31403002a9f424c6ef56460c6b3715" category="paragraph">L'expédition de journaux s'est avérée particulièrement utile pour les projets de migration longue distance à taux de changement élevé. Dans un cas, une seule base de données de 220 To a été migrée vers un nouvel emplacement situé à environ 500 kilomètres. Le taux de modification était extrêmement élevé et les restrictions de sécurité empêchaient l'utilisation d'une connexion réseau. L'expédition des journaux a été effectuée à l'aide de bandes et de coursiers. Une copie de la base de données source a d'abord été restaurée à l'aide des procédures décrites ci-dessous. Les journaux ont ensuite été expédiés chaque semaine par messagerie jusqu'au moment de la mise en service, lorsque le jeu final de bandes a été livré et que les journaux ont été appliqués à la base de données de réplica.</block>
  <block id="b8efa655c4deb7af8a24fc241f8b53ff" category="section-title">Oracle DataGuard</block>
  <block id="d3165c4060fc6d19c0a6364e7c4580ee" category="paragraph">Dans certains cas, un environnement DataGuard complet est garanti. Il est incorrect d'utiliser le terme DataGuard pour faire référence à toute configuration d'envoi de journaux ou de base de données de secours. Oracle DataGuard est un framework complet de gestion de la réplication de base de données, mais il ne s'agit pas d'une technologie de réplication. Le principal avantage d'un environnement DataGuard complet dans un effort de migration est le basculement transparent d'une base de données à une autre. DataGuard permet également un basculement transparent vers la base de données d'origine en cas de problème, tel qu'un problème de performances ou de connectivité réseau avec le nouvel environnement. Un environnement DataGuard entièrement configuré nécessite la configuration non seulement de la couche de base de données, mais aussi des applications pour que les applications puissent détecter un changement dans l'emplacement de la base de données primaire. En général, il n'est pas nécessaire d'utiliser DataGuard pour effectuer une migration, mais certains clients possèdent une expertise DataGuard étendue en interne et en dépendent déjà pour le travail de migration.</block>
  <block id="f17c0a1ce359c1a6665412f89234bf41" category="section-title">Architecture</block>
  <block id="ece8d784e248d63091fc0d248cdeebc3" category="paragraph">Comme évoqué précédemment, l'exploitation des fonctionnalités avancées des baies de stockage nécessite parfois de modifier l'organisation de la base de données. De plus, une modification du protocole de stockage, telle que le passage d'ASM à un système de fichiers NFS, modifie nécessairement la disposition du système de fichiers.</block>
  <block id="71843fb61639ed5fe216bfebc85af16f" category="paragraph">L'un des principaux avantages des méthodes d'envoi de journaux, y compris DataGuard, est que la destination de réplication ne doit pas correspondre à la source. Il n'y a pas de problème avec l'utilisation d'une approche d'envoi de journaux pour migrer d'ASM vers un système de fichiers standard, et inversement. La disposition précise des fichiers de données peut être modifiée à la destination pour optimiser l'utilisation de la technologie de base de données enfichable (PDB) ou pour définir des contrôles QoS de manière sélective sur certains fichiers. En d'autres termes, un processus de migration basé sur l'envoi de journaux vous permet d'optimiser facilement et en toute sécurité l'organisation du stockage de la base de données.</block>
  <block id="f00ec1b23f539163f4c748a85e49e2dd" category="section-title">Ressources du serveur</block>
  <block id="76c5d43a72d856a95b0eed94694ae696" category="paragraph">La migration au niveau de la base de données est limitée par le besoin d'un second serveur. Ce second serveur peut être utilisé de deux manières :</block>
  <block id="6cb133f8b5045ef30c17e96ab281749e" category="list-text">Vous pouvez utiliser le second serveur comme nouveau domicile permanent pour la base de données.</block>
  <block id="f5133929790fe62dbc76a73db4c88544" category="list-text">Vous pouvez utiliser le second serveur comme serveur temporaire de transfert. Une fois la migration des données vers la nouvelle baie de stockage terminée et testée, les systèmes de fichiers LUN ou NFS sont déconnectés du serveur intermédiaire et reconnectés au serveur d'origine.</block>
  <block id="48a00ba9881b62c610201cd833ee9c88" category="paragraph">La première option est la plus simple, mais son utilisation peut ne pas être possible dans les environnements très vastes nécessitant des serveurs très puissants. La deuxième option nécessite un travail supplémentaire pour replacer les systèmes de fichiers à leur emplacement d'origine. Il peut s'agir d'une opération simple dans laquelle NFS est utilisé comme protocole de stockage car les systèmes de fichiers peuvent être démontés du serveur de transfert et remontés sur le serveur d'origine.</block>
  <block id="c223252c2d577984b75caddbd1dff9dc" category="paragraph">Les systèmes de fichiers basés sur les blocs nécessitent un travail supplémentaire pour mettre à jour le zoning FC ou les initiateurs iSCSI. Avec la plupart des gestionnaires de volumes logiques (y compris ASM), les LUN sont automatiquement détectées et mises en ligne après leur mise à disposition sur le serveur d'origine. Cependant, certaines implémentations de système de fichiers et de LVM peuvent nécessiter davantage de travail pour exporter et importer les données. La procédure précise peut varier, mais il est généralement facile d'établir une procédure simple et reproductible pour terminer la migration et réexécuter les données sur le serveur d'origine.</block>
  <block id="2d22ab8be3661ce5dfd8c9910d1cc003" category="paragraph">Bien qu'il soit possible de configurer l'envoi de journaux et de répliquer une base de données dans un environnement de serveur unique, la nouvelle instance doit avoir un SID de processus différent pour pouvoir relire les journaux. Il est possible d'afficher temporairement la base de données sous un autre ensemble d'ID de processus avec un SID différent et de la modifier ultérieurement. Toutefois, cela peut entraîner de nombreuses activités de gestion complexes et mettre l'environnement de base de données en danger d'erreur de la part des utilisateurs.</block>
  <block id="2660e825d3a58f68aeec49e1c749f477" category="section-title">Migration au niveau de l'hôte</block>
  <block id="fae5bb68519bf78c1b3711566283f4ef" category="paragraph">La migration des données au niveau de l'hôte implique l'utilisation du système d'exploitation hôte et des utilitaires associés pour terminer la migration. Ce processus inclut tout utilitaire qui copie les données, y compris Oracle RMAN et Oracle ASM.</block>
  <block id="01070e0746a412afd171ccf162d3a170" category="section-title">Copie de données</block>
  <block id="180e717e34d5e4bd2991c47960d00f51" category="paragraph">La valeur d'une opération de copie simple ne doit pas être sous-estimée. Les infrastructures réseau modernes peuvent déplacer des données à un taux de gigaoctets par seconde. Les opérations de copie de fichiers reposent sur des E/S efficaces en lecture et écriture séquentielles Si une opération de copie de l'hôte est plus perturbant que l'envoi de journaux, la migration ne se limite pas au déplacement des données. Elle inclut généralement les modifications apportées au réseau, au délai de redémarrage de la base de données et aux tests de post-migration.</block>
  <block id="750e04d167938f35054d1c30fd06af58" category="paragraph">Le temps réel nécessaire à la copie des données peut ne pas être important. En outre, une opération de copie préserve un chemin de retour garanti, car les données d'origine ne sont pas modifiées. En cas de problème pendant le processus de migration, les systèmes de fichiers d'origine avec les données d'origine peuvent être réactivés.</block>
  <block id="5a3572c65171e06d99a4e055f9d35d32" category="section-title">Changement de plate-forme</block>
  <block id="d123cc133e4de7ab3a4b1a5af3bf37a7" category="paragraph">Le changement de plate-forme fait référence à un changement de type de CPU. Lorsqu'une base de données est migrée d'une plate-forme Solaris, AIX ou HP-UX traditionnelle vers Linux x86, les données doivent être reformatées en raison de modifications de l'architecture CPU. Les processeurs SPARC, IA64 et POWER sont connus sous le nom de processeurs big endian, tandis que les architectures x86 et x86_64 sont connues sous le nom de Little endian. Par conséquent, certaines données des fichiers de données Oracle sont triées différemment selon le processeur utilisé.</block>
  <block id="6a03806f9c4b1f0048478bab7863fd2c" category="paragraph">Jusqu'ici, les clients ont généralement utilisé DataPump pour répliquer des données sur plusieurs plateformes. DataPump est un utilitaire qui crée un type spécial d'exportation de données logiques qui peut être importé plus rapidement dans la base de données de destination. Comme il crée une copie logique des données, DataPump laisse derrière lui les dépendances de l'endianness du processeur. DataPump est encore utilisé par certains clients pour le changement de plateforme, mais une option plus rapide est désormais disponible avec Oracle 11g : les tablespaces interplateformes transportables. Cette avance permet de convertir un espace de table en un format endian différent. Il s'agit d'une transformation physique qui offre de meilleures performances qu'une exportation DataPump, qui doit convertir les octets physiques en données logiques, puis les convertir en octets physiques.</block>
  <block id="713bf8ff4ea4c4ece861f3345e15e3ea" category="paragraph">Une discussion complète sur DataPump et les tablespaces transportables va au-delà de la documentation NetApp portée, mais NetApp propose quelques recommandations basées sur notre expérience d'assistance aux clients lors de la migration vers une nouvelle baie de stockage dans le cadre d'une nouvelle architecture de processeur :</block>
  <block id="86b0ebca28354c7f55b4cc2fe79bee0e" category="list-text">Si DataPump est utilisé, le temps nécessaire à la migration doit être mesuré dans un environnement de test. Les clients sont parfois surpris du temps nécessaire à la réalisation de la migration. Cette interruption supplémentaire imprévue peut provoquer des interruptions.</block>
  <block id="8a592f25a72fd6f3718b1b01869ade30" category="list-text">De nombreux clients pensent à tort que les tablespaces transportables multi plates-formes ne nécessitent pas de conversion de données. Lorsqu'une CPU avec un autre endian est utilisée, un RMAN<block ref="31168275dcaac634489082b54c4c66d0" prefix=" " category="inline-code"></block> l'opération doit être effectuée au préalable sur les fichiers de données. Cette opération n'est pas instantanée. Dans certains cas, le processus de conversion peut être accéléré en ayant plusieurs threads fonctionnant sur différents fichiers de données, mais le processus de conversion ne peut pas être évité.</block>
  <block id="db7b3f86f4c9a2a6a76adac81614c03b" category="section-title">Migration basée sur le gestionnaire de volumes logiques</block>
  <block id="86586aa50b0df80a7c68bcd3e86c8606" category="paragraph">Les LVM fonctionnent en déregroupant un groupe d'une ou de plusieurs LUN en petites unités généralement appelées extensions. Le pool d'extensions est ensuite utilisé comme source pour créer des volumes logiques qui sont essentiellement virtualisés. Cette couche de virtualisation apporte de la valeur de plusieurs manières :</block>
  <block id="68d083c44669b8b20f0421b0389c6ded" category="list-text">Les volumes logiques peuvent utiliser des extensions tirées de plusieurs LUN. Lorsqu'un système de fichiers est créé sur un volume logique, il peut exploiter les performances maximales de toutes les LUN. Il favorise également le chargement homogène de toutes les LUN du groupe de volumes, pour des performances plus prévisibles.</block>
  <block id="10d1e748082641ce33e82f457cabcbe7" category="list-text">Les volumes logiques peuvent être redimensionnés en ajoutant et, dans certains cas, en supprimant des extensions. Le redimensionnement d'un système de fichiers sur un volume logique s'effectue généralement sans interruption.</block>
  <block id="5efed6e7bf2fda8321882aff35768721" category="list-text">Le déplacement des extensions sous-jacentes permet de migrer les volumes logiques sans interruption.</block>
  <block id="96371ba57b3d2f331cc9bd7b5e34708b" category="paragraph">La migration à l'aide d'un LVM fonctionne de deux manières : déplacer une extension ou mettre en miroir/démirroring une extension. La migration des LVM utilise des E/S séquentielles de blocs de grande taille efficaces et pose rarement des problèmes de performances. Si ce problème survient, il existe généralement des options pour limiter le taux d'E/S. Cela augmente le temps nécessaire à la migration, tout en réduisant la charge d'E/S sur l'hôte et les systèmes de stockage.</block>
  <block id="28084a93e6570f55c3923991e269816e" category="section-title">Miroir et démiroir</block>
  <block id="f5b05967100f74bb14ae26d5021ef4e3" category="paragraph">Certains gestionnaires de volumes, tels que AIX LVM, permettent à l'utilisateur de spécifier le nombre de copies pour chaque extension et de contrôler les périphériques qui hébergent chaque copie. La migration s'effectue par la mise en miroir d'un volume logique existant sur les extensions sous-jacentes des nouveaux volumes, l'attente de la synchronisation des copies, puis l'abandon de l'ancienne copie. Si un chemin de retour arrière est souhaité, un instantané des données d'origine peut être créé avant le point de suppression de la copie miroir. Il est également possible d'arrêter brièvement le serveur pour masquer les LUN d'origine avant de forcer la suppression des copies miroir contenues. Cela permet de conserver une copie récupérable des données à leur emplacement d'origine.</block>
  <block id="7151373ff69a9fafa4a579b40282beeb" category="section-title">Migration d'extension</block>
  <block id="682ba6adb168511d03877bdbf940a0b7" category="paragraph">La plupart des gestionnaires de volumes permettent la migration des extensions, et il arrive parfois que plusieurs options existent. Par exemple, certains gestionnaires de volumes permettent à un administrateur de déplacer les extensions individuelles d'un volume logique spécifique de l'ancien vers le nouveau stockage. Les gestionnaires de volumes tels que Linux LVM2 offrent le<block ref="8167c9a6bd495f7ed235364201039099" prefix=" " category="inline-code"></block> Qui déplace toutes les extensions du périphérique LUN spécifié vers une nouvelle LUN. Une fois l'ancien LUN évacué, il est possible de le retirer.</block>
  <block id="8c232bd157fb78062260d11e1ec3fc2c" category="admonition">Le risque principal pour les opérations est la suppression des anciennes LUN inutilisées de la configuration. Une attention toute particulière doit être portée au changement de segmentation FC et au retrait des périphériques LUN obsolètes.</block>
  <block id="41175a8b2053bedbf868e340edf92f55" category="section-title">Gestion automatique du stockage par Oracle</block>
  <block id="dce3f0c1b1c85aaee6448197054602d1" category="paragraph">Oracle ASM est un gestionnaire de volumes logiques et un système de fichiers combinés. À un niveau élevé, Oracle ASM prend un ensemble de LUN, les répartit en petites unités d'allocation et les présente comme un seul volume appelé groupe de disques ASM. ASM permet également de mettre en miroir le groupe de disques en définissant le niveau de redondance. Un volume peut être sans miroir (redondance externe), en miroir (redondance normale) ou en miroir tridirectionnel (redondance élevée). La configuration du niveau de redondance doit être effectuée avec précaution car il ne peut pas être modifié après sa création.</block>
  <block id="d0ac5c14a6207835f733f4366345089d" category="paragraph">ASM fournit également des fonctionnalités de système de fichiers. Bien que le système de fichiers ne soit pas visible directement depuis l'hôte, la base de données Oracle peut créer, déplacer et supprimer des fichiers et des répertoires sur un groupe de disques ASM. Vous pouvez également naviguer dans la structure à l'aide de l'utilitaire asmcmd.</block>
  <block id="e72c9da30cbec4daedddc9b6e6fdf03b" category="paragraph">Comme pour les autres implémentations LVM, Oracle ASM optimise les performances d'E/S en segmentant et en équilibrant les E/S de chaque fichier sur l'ensemble des LUN disponibles. Deuxièmement, les extensions sous-jacentes peuvent être déplacées pour permettre le redimensionnement du groupe de disques ASM ainsi que la migration. Oracle ASM automatise le processus tout au long de l'opération de rééquilibrage. Les nouvelles LUN sont ajoutées à un groupe de disques ASM et les anciennes LUN sont abandonnées, ce qui déclenche le déplacement d'extension et le DROP suivant de la LUN évacuée du groupe de disques. Ce processus est l'une des méthodes de migration les plus éprouvées, et la fiabilité d'ASM pour assurer une migration transparente est probablement sa fonctionnalité la plus importante.</block>
  <block id="d4ad443888b51ec4e13912c45da68f76" category="admonition">Comme le niveau de mise en miroir d'Oracle ASM est fixe, il ne peut pas être utilisé avec la méthode de migration miroir et démiroir.</block>
  <block id="048429277e643e20907317612c1f3318" category="section-title">Migration au niveau du stockage</block>
  <block id="623bb7ffbb3730716ea39b5086d26f18" category="paragraph">La migration au niveau du stockage implique d'effectuer la migration au-dessous des niveaux des applications et du système d'exploitation. Auparavant, il fallait parfois utiliser des périphériques spécialisés qui copiaient les LUN au niveau du réseau, mais ces fonctionnalités sont désormais natives dans ONTAP.</block>
  <block id="794cb725c5631ad99b5b7c000307f0df" category="section-title">SnapMirror</block>
  <block id="963ce762febea70d619f1fd5c114d85c" category="paragraph">La migration de bases de données entre des systèmes NetApp est presque effectuée de manière universelle avec le logiciel de réplication des données NetApp SnapMirror. Ce processus implique la configuration d'une relation de miroir pour les volumes à migrer, leur permettant ainsi de se synchroniser, puis d'attendre la fenêtre de mise en service. Lorsqu'elle arrive, la base de données source est arrêtée, une dernière mise à jour miroir est effectuée et le miroir est cassé. Les volumes de réplica sont alors prêts à l'emploi, soit en montant un répertoire de système de fichiers NFS contenu, soit en découvrant les LUN contenues et en démarrant la base de données.</block>
  <block id="1871452e5ea7e53152b5c874a12a890b" category="paragraph">La relocalisation des volumes dans un seul cluster ONTAP n'est pas considérée comme une migration, mais plutôt comme une routine<block ref="0fc2ecb8aa71bddc595fbc39f593496a" prefix=" " category="inline-code"></block> fonctionnement. SnapMirror est utilisé en tant que moteur de réplication des données au sein du cluster. Ce processus est entièrement automatisé. Il n'y a pas d'étape de migration supplémentaire à effectuer lorsque les attributs du volume, tels que le mappage de LUN ou les autorisations d'exportation NFS, sont déplacés avec le volume lui-même. La relocalisation ne prend pas en charge l'hôte. Dans certains cas, il convient de mettre à jour l'accès au réseau pour s'assurer que les données nouvellement déplacées sont accessibles de la manière la plus efficace possible, mais sans interruption.</block>
  <block id="19fee3ea4b7f4472b5c1853122e8f47b" category="section-title">Importation de LUN étrangères (FLI)</block>
  <block id="a73cf458eed5aeff5c15aa5d70298cce" category="paragraph">La FLI est une fonctionnalité qui permet à un système Data ONTAP exécutant la version 8.3 ou supérieure de migrer un LUN existant à partir d'une autre baie de stockage. La procédure est simple : le système ONTAP est zoné sur la baie de stockage existante comme s'il s'agissait d'un autre hôte SAN. Data ONTAP prend alors le contrôle des LUN héritées souhaitées et migre les données sous-jacentes. De plus, le processus d'importation utilise les paramètres d'efficacité du nouveau volume lors de la migration des données. Ainsi, les données peuvent être compressées et dédupliquées en ligne pendant le processus de migration.</block>
  <block id="0ee4b09881406835f151f103412a2f1e" category="paragraph">La première implémentation de FLI dans Data ONTAP 8.3 a permis uniquement la migration hors ligne. Ce transfert était extrêmement rapide, mais cela signifiait que les données de LUN étaient indisponibles jusqu'à la fin de la migration. La migration en ligne a été introduite dans Data ONTAP 8.3.1. Ce type de migration minimise les interruptions en permettant à ONTAP de transmettre des données LUN lors du processus de transfert. Il y a une brève interruption lors de la remise en place de l'hôte pour l'utilisation des LUN via ONTAP. Cependant, dès que ces modifications sont apportées, les données sont de nouveau accessibles et restent accessibles tout au long du processus de migration.</block>
  <block id="19d95ee75467fc2f9a06d150cc99d944" category="paragraph">Les E/S de lecture sont proxées via ONTAP jusqu'à la fin de l'opération de copie, tandis que les E/S d'écriture sont écrites de manière synchrone sur les LUN étrangères et ONTAP. Les deux copies LUN sont ainsi synchronisées jusqu'à ce que l'administrateur exécute une mise en service complète qui libère le LUN étranger et ne réplique plus les écritures.</block>
  <block id="5caad387757ca99ada41709ce30a31a5" category="paragraph">FLI est conçu pour fonctionner avec FC. Toutefois, si vous souhaitez passer à iSCSI, le LUN migré peut facilement être remappé en tant que LUN iSCSI une fois la migration terminée.</block>
  <block id="7fa6cfc683e0f5f9e3a79f6be14e23f4" category="paragraph">Parmi les caractéristiques de FLI figurent la détection et le réglage automatiques de l'alignement. Dans ce contexte, le terme alignement fait référence à une partition sur un périphérique LUN. Pour des performances optimales, les E/S doivent être alignées sur des blocs de 4 Ko. Si une partition est placée à un décalage qui n'est pas un multiple de 4K, les performances en pâtissent.</block>
  <block id="7b4ef266729f1ddfbc724cad17af4efc" category="paragraph">Il existe un deuxième aspect de l'alignement qui ne peut pas être corrigé en réglant un décalage de partition, c'est-à-dire la taille du bloc du système de fichiers. Par exemple, un système de fichiers ZFS prend généralement par défaut une taille de bloc interne de 512 octets. D'autres clients utilisant AIX ont parfois créé des systèmes de fichiers jfs2 avec une taille de bloc de 512 ou 1, 024 octets. Bien que le système de fichiers puisse être aligné sur une limite de 4 Ko, les fichiers créés dans ce système de fichiers ne le sont pas et les performances en pâtissent.</block>
  <block id="1d6b28ed67b1d554df806b0b5a020711" category="paragraph">FLI ne doit pas être utilisé dans ces circonstances. Bien que les données soient accessibles après la migration, vous obtenez des systèmes de fichiers avec de graves limitations de performances. En principe, tout système de fichiers prenant en charge une charge de travail de remplacement aléatoire sur ONTAP doit utiliser une taille de bloc de 4 Ko. Cela s'applique principalement aux charges de travail telles que les fichiers de données de base de données et les déploiements VDI. La taille de bloc peut être identifiée à l'aide des commandes appropriées du système d'exploitation hôte.</block>
  <block id="4941562ef813562e0d6aaef673158b99" category="paragraph">Par exemple, sous AIX, la taille de bloc peut être affichée avec<block ref="10c9a985c983a826424b496a708263ec" prefix=" " category="inline-code"></block>. Avec Linux,<block ref="ba5265473f00b27178098cc38d3aef24" prefix=" " category="inline-code"></block> et<block ref="1f8a87190704df357c64a49aee936874" prefix=" " category="inline-code"></block> peut être utilisé pour<block ref="310201b6353c5f38bc039e0e51b079d3" prefix=" " category="inline-code"></block> et<block ref="5382133ffbecb9bce9d47f2e44327b16" prefix=" " category="inline-code"></block>, respectivement. Avec<block ref="8cbc6ba7c8bba133ce2bc44780d88742" prefix=" " category="inline-code"></block>, la commande est<block ref="1615297782a0dff59b20451e2ca97ea7" prefix=" " category="inline-code"></block>.</block>
  <block id="033a4cb04b5225e2b7cf966f2ce16598" category="paragraph">Le paramètre qui contrôle la taille du bloc est<block ref="81df978a8e3da4bee74b135548f390f3" prefix=" " category="inline-code"></block> et la valeur par défaut est généralement 9, soit 2^9, ou 512 octets. Pour des performances optimales, le<block ref="81df978a8e3da4bee74b135548f390f3" prefix=" " category="inline-code"></block> La valeur doit être 12 (2^12=4K). Cette valeur est définie au moment de la création du zpool et ne peut pas être modifiée, ce qui signifie que les zpools de données avec un<block ref="81df978a8e3da4bee74b135548f390f3" prefix=" " category="inline-code"></block> une migration autre que 12 doit être effectuée en copiant les données vers un nouveau zpool.</block>
  <block id="8bd9661d8c8eb9924c62b8242191af4e" category="paragraph">Oracle ASM n'a pas de taille de bloc fondamentale. La seule exigence est que la partition sur laquelle le disque ASM est construit doit être correctement alignée.</block>
  <block id="ea7f7e1e8119ee64585b6173afe720e8" category="section-title">Outil de transition 7-mode</block>
  <block id="75df51cc2f43b8dde951695f97b838c0" category="paragraph">L'outil 7-mode transition Tool (7MTT) est un utilitaire d'automatisation utilisé pour migrer de grandes configurations 7-mode vers ONTAP. La plupart des clients de bases de données trouvent d'autres méthodes plus faciles, notamment parce qu'ils migrent généralement leurs environnements de bases de données par base de données plutôt que de déplacer l'intégralité de l'empreinte du stockage. De plus, les bases de données ne font souvent partie que d'un environnement de stockage plus important. Les bases de données sont donc souvent migrées individuellement, puis le reste de l'environnement peut être déplacé avec 7MTT.</block>
  <block id="85fd7dcbc2206c27059ae7f88712154d" category="paragraph">Les clients sont de petite taille, mais nombreux. Ils disposent de systèmes de stockage dédiés à des environnements de base de données complexes. Ces environnements peuvent contenir de nombreux volumes, snapshots et de nombreuses informations de configuration telles que les autorisations d'exportation, les groupes initiateurs de LUN, les autorisations utilisateur et la configuration du protocole d'accès aux répertoires légers. Dans de tels cas, les fonctionnalités d'automatisation de l'outil 7MTT simplifient considérablement la migration.</block>
  <block id="2c87fbdecbf0dfe299f9f89958d61085" category="paragraph">7MTT peut fonctionner dans deux modes :</block>
  <block id="dc818e71a5519d1b99c7e996cf21fd74" category="list-text">*Transition basée sur les copies (CBT).* dans le nouvel environnement, l'outil 7MTT avec CBT configure les volumes SnapMirror à partir d'un système 7- mode existant. Une fois les données synchronisées, l'outil 7MTT orchestre le processus de mise en service.</block>
  <block id="453bbc96e365e25cc2d091dced3565a6" category="list-text">*Transition sans copie.* 7MTT avec la transition sans copie repose sur la conversion des tiroirs disques 7-mode existants sans déplacement des données. Aucune donnée n'est copiée et les tiroirs disques existants peuvent être réutilisés. La protection des données et la configuration de l'efficacité du stockage existantes sont préservées.</block>
  <block id="16262236c3981cb3310b9320b5a67fd0" category="paragraph">La différence principale entre ces deux options est que la transition sans copie constitue une approche globale où tous les tiroirs disques rattachés à la paire HA 7-mode d'origine doivent être transférés vers le nouvel environnement. Il n'existe aucune option pour déplacer un sous-ensemble de tiroirs. L'approche basée sur les copies permet de déplacer des volumes sélectionnés. Par ailleurs, une fenêtre de mise en service peut être plus longue et la transition sans copie est liée à l'alignement des tiroirs disques et à la conversion des métadonnées. En fonction de son expérience sur le terrain, NetApp recommande de consacrer 1 heure au déplacement et à la réinstallation des tiroirs disques, et entre 15 minutes et 2 heures à la conversion des métadonnées.</block>
  <block id="795bbfbd054829fad905065087ba2d5a" category="paragraph">Du point de vue de la base de données et de l'hôte, aucune étape particulière n'est requise. Une fois les zones FC mises à jour et les LUN disponibles sur ONTAP, LVM doit pouvoir lire les métadonnées LVM des LUN. De plus, les groupes de volumes sont prêts à être utilisés sans étape de configuration supplémentaire. Dans de rares cas, les environnements peuvent inclure des fichiers de configuration codés en dur avec des références à la baie de stockage précédente. Par exemple, un système Linux inclus<block ref="dd5ff67ba72768d33f75e645aa2b8e56" prefix=" " category="inline-code"></block> Les règles qui référençaient un WWN d'un périphérique donné doivent être mises à jour pour refléter les modifications introduites par FLI.</block>
  <block id="9e7ddc2ddefcd6f202fb11a82a80bc7e" category="admonition">Reportez-vous à la matrice de compatibilité NetApp pour plus d'informations sur les configurations prises en charge. Si votre environnement n'est pas inclus, contactez votre représentant NetApp pour obtenir de l'aide.</block>
  <block id="0f5b3758229b3e28c8605b6c42398115" category="paragraph">Cet exemple montre la migration des LUN ASM et LVM hébergées sur un serveur Linux. FLI est pris en charge par d'autres systèmes d'exploitation. Bien que les commandes côté hôte puissent différer, les principes sont les mêmes et les procédures ONTAP sont identiques.</block>
  <block id="f1036cd97e461d07351c9df32fc5948d" category="section-title">Identifier les LUN LVM</block>
  <block id="88f7413f9621a816ee3d370703168647" category="paragraph">La première étape de la préparation consiste à identifier les LUN à migrer. Dans l'exemple illustré ici, deux systèmes de fichiers SAN sont montés sur<block ref="572f241ef88fdb17d16eba97133d861f" prefix=" " category="inline-code"></block> et<block ref="d14bc7787c7396144583e99a7df52f67" prefix=" " category="inline-code"></block>.</block>
  <block id="ecad615a52fda392a9b7c1075d2cb2c5" category="paragraph">Le nom du groupe de volumes peut être extrait du nom du périphérique, qui utilise le format (nom du groupe de volumes)-(nom du volume logique). Dans ce cas, le groupe de volumes est appelé<block ref="bb97320b8c517da828eae4ec543113db" prefix=" " category="inline-code"></block>.</block>
  <block id="b08986bb1757d5ae8de06d523c71803d" category="paragraph">Le<block ref="f1e2c495108b111c930735e3a0f9a04e" prefix=" " category="inline-code"></block> Vous pouvez utiliser la commande suivante pour identifier les LUN qui prennent en charge ce groupe de volumes. Dans ce cas, 10 LUN constituent le<block ref="bb97320b8c517da828eae4ec543113db" prefix=" " category="inline-code"></block> groupe de volumes.</block>
  <block id="8b47fac6803dfff2e8d2cdad6f297cfa" category="section-title">Identifier les LUN ASM</block>
  <block id="a23d0124954ecdbfe9d0f3aceb9e17a2" category="paragraph">Les LUN ASM doivent également être migrés. Pour obtenir le nombre de LUN et de chemins de LUN depuis sqlplus en tant qu'utilisateur sysasm, exécutez la commande suivante :</block>
  <block id="918841992da84786f00de7c4c7d83dbf" category="paragraph">L'environnement actuel contient 20 LUN à migrer. Mettez à jour le SAN actuel de sorte que ONTAP puisse accéder aux LUN actuelles. Les données n'ont pas encore été migrées, mais ONTAP doit lire les informations de configuration des LUN actuelles pour créer le nouveau home pour ces données.</block>
  <block id="5816768a5d83977f34ffa5025c14f430" category="paragraph">Au moins un port HBA sur le système AFF/FAS doit être configuré en tant que port initiateur. En outre, les zones FC doivent être mises à jour de sorte que ONTAP puisse accéder aux LUN de la baie de stockage étrangère. Certaines baies de stockage ont configuré le masquage des LUN, ce qui limite les WWN pouvant accéder à une LUN donnée. Dans ce cas, le masquage de LUN doit également être mis à jour pour autoriser l'accès aux WWN de ONTAP.</block>
  <block id="030a992b1340f67584d67ef6230e9adf" category="paragraph">Une fois cette étape terminée, ONTAP doit être en mesure d'afficher la baie de stockage étrangère avec le<block ref="d90ba20b63acab53952d68665c50ec47" prefix=" " category="inline-code"></block> commande. Le champ de clé renvoyé est le préfixe utilisé pour identifier la LUN étrangère sur le système. Dans l'exemple ci-dessous, les LUN de la baie étrangère<block ref="25103eba8d70e82b5bd837be0d2f63c4" prefix=" " category="inline-code"></block> Apparaissent dans ONTAP en utilisant le préfixe de<block ref="6b35470d99880c4630ed3ca7b4c842e7" prefix=" " category="inline-code"></block>.</block>
  <block id="c1a0f5174323df40a8b659eb65ac5155" category="section-title">Identifiez le tableau étranger</block>
  <block id="6c1b8919e2e706972b3ec48cb7f014ba" category="section-title">Identifiez les LUN étrangères</block>
  <block id="63841e312d3a8531331e35bd826268d1" category="paragraph">Vous pouvez lister les LUN en transmettant le<block ref="907702f5103a7823393b8dd296a75c26" prefix=" " category="inline-code"></block> à la<block ref="242f4ce1948273386f8bb487bdd3732f" prefix=" " category="inline-code"></block> commande. Les données renvoyées sont référencées plusieurs fois pendant la procédure de migration.</block>
  <block id="e5e94f7e2098883f0d621e064b1104f4" category="section-title">Enregistrer des LUN de baies étrangères en tant que candidats à l'importation</block>
  <block id="c968ec41c1c0c449b0263962966d8293" category="paragraph">Les LUN étrangères sont initialement classées comme tout type de LUN particulier. Avant de pouvoir importer des données, les LUN doivent être marquées comme étrangères et par conséquent comme candidates au processus d'importation. Cette étape est terminée en transmettant le numéro de série au<block ref="93c633f7fa188f1b27df574c0e5e929a" prefix=" " category="inline-code"></block> comme indiqué dans l'exemple suivant. Notez que ce processus balise uniquement la LUN comme étant étrangère dans ONTAP. Aucune donnée n'est écrite sur la LUN étrangère elle-même.</block>
  <block id="33380a523841f23815f2f83c9de1a628" category="section-title">Création de volumes pour héberger les LUN migrés</block>
  <block id="2c2ba8ca6bdd77da1da981b91a3fae4a" category="paragraph">Un volume est nécessaire pour héberger les LUN migrées. La configuration exacte du volume dépend du plan global d'exploitation des fonctionnalités ONTAP. Dans cet exemple, les LUN ASM sont placées dans un volume et les LUN LVM sont placées dans un second volume. Vous pouvez ainsi gérer les LUN en tant que groupes indépendants à des fins telles que la hiérarchisation, la création de snapshots ou la définition de contrôles de QoS.</block>
  <block id="8bc7d64e68e4be8f4908effd57293a2a" category="paragraph">Réglez le<block ref="fb983ebeedc63d8723c0d4aa558a4c02" prefix=" " category="inline-code"></block>. Le processus de migration peut inclure une grande partie du transfert des données. Par conséquent, si des snapshots sont créés par accident, la consommation d'espace peut augmenter de façon importante, car des données indésirables sont capturées dans les snapshots.</block>
  <block id="8c0675d07e44f55f1f5aa6d45abe0cdb" category="section-title">Créer des LUN ONTAP</block>
  <block id="0b799020dac78a5e12a3d1a6400fd0c8" category="paragraph">Une fois les volumes créés, les nouvelles LUN doivent être créées. Normalement, la création d'une LUN nécessite que l'utilisateur indique des informations telles que la taille de LUN, mais dans ce cas, l'argument disque étranger est transmis à la commande. Par conséquent, ONTAP réplique les données de configuration actuelle du LUN à partir du numéro de série spécifié. Il utilise également la géométrie des LUN et les données de la table de partition pour ajuster l'alignement des LUN et établir des performances optimales.</block>
  <block id="5272a1dc3854f1eddc353c8073234e03" category="paragraph">Dans cette étape, les numéros de série doivent être référencés avec le tableau étranger pour s'assurer que le LUN étranger correct est associé au nouveau LUN correct.</block>
  <block id="f6ee70ec9fce7bd34fa5a33d8969fb5e" category="section-title">Créer des relations d'importation</block>
  <block id="94700a911b95416221efe4064acbc2ba" category="paragraph">Les LUN ont été créées, mais ne sont pas configurées en tant que destination de réplication. Avant de pouvoir réaliser cette étape, les LUN doivent d'abord être mises hors ligne. Cette étape supplémentaire est conçue pour protéger les données contre les erreurs de l'utilisateur. Si ONTAP permettait l'exécution d'une migration sur une LUN en ligne, une erreur typographique risquerait d'écraser les données actives. L'étape supplémentaire consistant à forcer l'utilisateur à mettre d'abord une LUN hors ligne permet de vérifier que la LUN cible correcte est utilisée comme destination de migration.</block>
  <block id="85255e52054af9c6ffd3c4e79c723a34" category="paragraph">Une fois les LUN hors ligne, vous pouvez établir la relation d'importation en transmettant le numéro de série de la LUN étrangère à<block ref="04c2f87857699971f5aedd525e65690a" prefix=" " category="inline-code"></block> commande.</block>
  <block id="8e3c921431d2b7f66fa0cc85f3ae5c9d" category="paragraph">Une fois toutes les relations d'importation établies, les LUN peuvent être remis en ligne.</block>
  <block id="ea382cbfdb353cee0cf25eaae9bba150" category="section-title">Créer le groupe initiateur</block>
  <block id="152c4728a5fb152525a639439b9d7cb9" category="inline-link-macro">Conversion de protocoles</block>
  <block id="298a1c3c736859f2cfa3cb8eb1f3fdcc" category="paragraph">Dans cet exemple, un groupe initiateur est créé et contient deux WWN correspondant aux deux ports disponibles sur l'adaptateur HBA de l'hôte.</block>
  <block id="4f6f03762bfcdc7174cdd30240ce45b3" category="section-title">Mappez les nouvelles LUN sur l'hôte</block>
  <block id="c22fee2d07a149be91ae1ae2ada1cb57" category="paragraph">Après la création du groupe initiateur, les LUN sont ensuite mappées sur le groupe initiateur défini. Ces LUN sont uniquement disponibles pour les WWN inclus dans ce groupe initiateur. NetApp suppose, à ce stade du processus de migration, que l'hôte n'a pas été segmenté vers ONTAP. Cela est important, car si l'hôte est segmenté simultanément sur la baie étrangère et le nouveau système ONTAP, il est possible de détecter sur chaque baie des LUN portant le même numéro de série. Cette situation peut entraîner des dysfonctionnements des chemins d'accès multiples ou endommager les données.</block>
  <block id="ecca392290c36269e0489c0b1cf36f50" category="summary">Exemples de scripts pour l'automatisation des opérations de migration Oracle</block>
  <block id="fc53c036602508ed6c2afc18e2fbdf51" category="doc">Exemples de scripts</block>
  <block id="6f78af00b87bcad5d08c95c7b6066ad0" category="paragraph">Les scripts présentés sont fournis sous forme d'exemples de script de diverses tâches du système d'exploitation et de la base de données. Ils sont fournis en l'état. Si une assistance est requise pour une procédure particulière, contactez NetApp ou un revendeur NetApp.</block>
  <block id="3146889e40b3ca2b78c56a19178bff84" category="section-title">Arrêt de la base de données</block>
  <block id="5b98b9877c0c74dc3a3daf46cf943d3f" category="paragraph">Le script Perl suivant prend un seul argument du SID Oracle et arrête une base de données. Il peut être exécuté en tant qu'utilisateur Oracle ou en tant que root.</block>
  <block id="7df41a3619af59182fb5df6d1920d11a" category="section-title">Démarrage de la base de données</block>
  <block id="57249fb9cdac8ddc9ea8843636c4e088" category="section-title">Convertir le système de fichiers en lecture seule</block>
  <block id="f2977a22ba44544ca8921e2d75bce435" category="paragraph">Le script suivant prend un argument de système de fichiers et tente de le démonter et de le remonter en lecture seule. Cette opération est utile lors des processus de migration au cours desquels un système de fichiers doit être mis à disposition pour répliquer des données, tout en étant protégé contre les dommages accidentels.</block>
  <block id="4eac395595a8d266839db0b88fae31e4" category="section-title">Remplacer le système de fichiers</block>
  <block id="988d7030a130298e1641007b5b0aae20" category="paragraph">L'exemple de script suivant est utilisé pour remplacer un système de fichiers par un autre. Comme il modifie le fichier `/etc/fstab `file, il doit être exécuté en tant que root. Il accepte un seul argument délimité par des virgules pour les anciens et les nouveaux systèmes de fichiers.</block>
  <block id="149c75d086adf78a50a16bcb5e349158" category="list-text">Pour remplacer le système de fichiers, exécutez le script suivant :</block>
  <block id="67a4c588434c781febb12c165c3e860a" category="paragraph">Comme exemple d'utilisation de ce script, supposons que les données dans<block ref="f006bf17b06c884c47190c4225d3215a" prefix=" " category="inline-code"></block> est migré vers<block ref="27df80f143a5812bda1553d09c712efc" prefix=" " category="inline-code"></block> et<block ref="0e62afc91abe157ef67895cca0a7f912" prefix=" " category="inline-code"></block> est migré vers<block ref="1c988fc7a325635f00f9b55992128a08" prefix=" " category="inline-code"></block>. L'une des méthodes les plus simples pour effectuer cette tâche consiste à utiliser une simple opération de copie de fichier pour replacer le nouveau périphérique sur le point de montage d'origine.</block>
  <block id="4a3d90c30a5e921650fe8ad0decf4827" category="list-text">Supposons que l'ancien et le nouveau système de fichiers sont présents dans le<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block> classer comme suit :</block>
  <block id="4588a4e3d2f8d0f7c036f59c1be2163f" category="list-text">Lors de son exécution, ce script démonte le système de fichiers actuel et le remplace par le nouveau :</block>
  <block id="2d808cb44231d0a80164567e7220fc44" category="list-text">Le script met également à jour le<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block> classez-les en conséquence. Dans l'exemple illustré ici, il inclut les modifications suivantes :</block>
  <block id="840967a448e36b9efeaacf7673f825aa" category="section-title">Migration automatisée des bases de données</block>
  <block id="1107dd36fe8ba0c18ea8abc8734986e2" category="paragraph">Cet exemple illustre l'utilisation de scripts d'arrêt, de démarrage et de remplacement de système de fichiers pour automatiser complètement la migration.</block>
  <block id="36881541e7d9c7bced65fcac337ac327" category="section-title">Afficher les emplacements des fichiers</block>
  <block id="1e9a1acc40d4943a73e6865cdebaf560" category="paragraph">Ce script collecte un certain nombre de paramètres de base de données critiques et les imprime dans un format facile à lire. Ce script peut être utile lors de la révision des dispositions de données. En outre, le script peut être modifié pour d'autres utilisations.</block>
  <block id="6172b49b7fdf806b59af0aeef8de71e3" category="section-title">Nettoyage de la migration ASM</block>
  <block id="dd8d75d6766af495b5442e67eb27d387" category="section-title">Conversion du nom ASM en nom de système de fichiers</block>
  <block id="abc3fc91423668bb4bd49e6e837fa3e4" category="section-title">Relire les journaux sur la base de données</block>
  <block id="cc7b9a518bb2532f61662a9893248133" category="paragraph">Ce script accepte un seul argument d'un SID Oracle pour une base de données en mode montage et tente de relire tous les journaux d'archives actuellement disponibles.</block>
  <block id="2a5bd3a209a1ed33b81c5306780227ce" category="section-title">Relire les journaux sur la base de données de secours</block>
  <block id="ea7bebed0b4151a9b28acbde55fc0eb3" category="paragraph">Ce script est identique au script précédent, sauf qu'il est conçu pour une base de données de secours.</block>
  <block id="2adcfd589637337984e39e94dd14ae33" category="paragraph">La modification du protocole utilisé pour accéder à une LUN est une exigence courante.</block>
  <block id="38fe6838f11a6023172d11d806adbfcf" category="paragraph">Dans certains cas, cela fait partie d'une stratégie globale de migration des données vers le cloud. Le protocole TCP/IP est le protocole du cloud. En passant de FC à iSCSI, vous simplifiez la migration vers divers environnements cloud. Dans d'autres cas, il peut être souhaitable de tirer parti de la réduction des coûts d'un SAN IP. Il arrive qu'une migration utilise un protocole différent comme mesure temporaire. Par exemple, si une baie étrangère et des LUN ONTAP ne peuvent pas coexister sur les mêmes HBA, vous pouvez utiliser des LUN iSCSI suffisamment longues pour copier les données de l'ancienne baie. Vous pouvez ensuite reconvertir en FC après le retrait des anciennes LUN du système.</block>
  <block id="832c81bd0db3ad98a3804ff5ce996a58" category="paragraph">La procédure suivante illustre la conversion de FC en iSCSI, mais les principes généraux s'appliquent à une conversion iSCSI inverse en FC.</block>
  <block id="e21180783b17ea695cf9275fce8a0bc7" category="section-title">Installez l'initiateur iSCSI</block>
  <block id="0e1ddcc32a3ef636c9ca084a3d7706f5" category="paragraph">La plupart des systèmes d'exploitation incluent par défaut un initiateur iSCSI logiciel, mais si celui-ci n'est pas inclus, il peut être facilement installé.</block>
  <block id="289fe013df899f5f74fb362d4efcdd5d" category="section-title">Identifiez le nom de l'initiateur iSCSI</block>
  <block id="8242e97b190184a6c7b8ec96c5662886" category="paragraph">Un nom d'initiateur iSCSI unique est généré lors du processus d'installation. Sous Linux, il se trouve dans le<block ref="22565a44e8f73044eb2029acbb069639" prefix=" " category="inline-code"></block> fichier. Ce nom permet d'identifier l'hôte sur le SAN IP.</block>
  <block id="721a96eb0b922b337fa815839839b328" category="section-title">Créer un nouveau groupe initiateur</block>
  <block id="cda1311d977b7b77ad3aebe4a813b3bd" category="paragraph">Un groupe initiateur (igroup) fait partie de l'architecture de masquage des LUN ONTAP. L'accès à une LUN nouvellement créée n'est pas accessible à moins qu'un hôte ne bénéficie au préalable d'un accès. Cette étape est effectuée en créant un groupe initiateur qui répertorie les WWN FC ou les noms d'initiateurs iSCSI nécessitant un accès.</block>
  <block id="6548788f050643897f7354b6df4488db" category="paragraph">Dans cet exemple, un groupe initiateur contenant l'initiateur iSCSI de l'hôte Linux est créé.</block>
  <block id="da8490d81c1ef6b559b09c2ab94631d2" category="section-title">Arrêtez l'environnement</block>
  <block id="0bf211160ad57fedca3499176f213b11" category="paragraph">Avant de modifier le protocole LUN, les LUN doivent être complètement suspendues. Toute base de données de l'une des LUN en cours de conversion doit être arrêtée, les systèmes de fichiers doivent être démontés et les groupes de volumes doivent être désactivés. Si ASM est utilisé, assurez-vous que le groupe de disques ASM est démonté et arrêtez tous les services de grille.</block>
  <block id="2ba1c509ee5f5e31f05b24aed2d23054" category="section-title">Annulez le mappage des LUN à partir du réseau FC</block>
  <block id="2f9e42c479a76dd54d7946c181049dd4" category="paragraph">Une fois les LUN entièrement suspendues, supprimez les mappages du groupe initiateur FC d'origine.</block>
  <block id="5f889f52ef85be290c3e5c0211bbb8fa" category="section-title">Remappez les LUN sur le réseau IP</block>
  <block id="4ac84701530b31d8d33d9aa742715d25" category="paragraph">Accordez l'accès à chaque LUN au nouveau groupe initiateur iSCSI.</block>
  <block id="3d59eaa280c8b75d8e997eac2cf5b3e6" category="section-title">Découvrez les cibles iSCSI</block>
  <block id="981b782c3eacf8b87d8231b887873f03" category="paragraph">La découverte iSCSI se déroule en deux phases. Le premier consiste à découvrir les cibles, qui n'équivaut pas à détecter une LUN. Le<block ref="f88921f58beaaae5bcb9dffac54bf5ad" prefix=" " category="inline-code"></block> la commande illustrée ci-dessous sonde le groupe de portails spécifié par le<block ref="24e12535882a30ad33a21d76d76bd0ff" prefix=" " category="inline-code"></block> Et stocke une liste de toutes les adresses IP et de tous les ports qui offrent des services iSCSI. Dans ce cas, quatre adresses IP disposent de services iSCSI sur le port par défaut 3260.</block>
  <block id="0ab5dd035c7f92f4dce1026744c01604" category="admonition">Cette commande peut prendre plusieurs minutes si l'une des adresses IP cibles ne peut pas être atteinte.</block>
  <block id="1dba8f39914c5f44e3cb635e7ac7563e" category="section-title">Découverte des LUN iSCSI</block>
  <block id="68307bef4b9dc4071d875a0c2aadd321" category="paragraph">Une fois les cibles iSCSI détectées, redémarrez le service iSCSI pour découvrir les LUN iSCSI disponibles et construire les périphériques associés tels que les périphériques multivoies ou ASMlib.</block>
  <block id="25d811252f87ae85dda97f2ab9dd1f3a" category="section-title">Redémarrez l'environnement</block>
  <block id="8a9aae851d31dae8baf96171f114955e" category="paragraph">Redémarrez l'environnement en réactivant les groupes de volumes, en remontant les systèmes de fichiers, en redémarrant les services RAC, etc. Par mesure de précaution, NetApp vous recommande de redémarrer le serveur une fois le processus de conversion terminé afin de vous assurer que tous les fichiers de configuration sont corrects et que tous les périphériques obsolètes sont supprimés.</block>
  <block id="00f4c8378b0bf837cee4b0aed8886f31" category="paragraph">Attention : avant de redémarrer un hôte, assurez-vous que toutes les entrées dans<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block> Les ressources SAN migrées de cette référence sont commentées. Si cette étape n'est pas effectuée et qu'il y a des problèmes avec l'accès aux LUN, le système d'exploitation ne s'amorce pas. Ce problème n'endommage pas les données. Cependant, il peut être très peu commode de démarrer en mode de secours ou un mode similaire et correct<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block> Afin que le système d'exploitation puisse être démarré pour permettre aux efforts de dépannage de commencer.</block>
  <block id="08e3cfb3c3dfa08d34bcbbfe07fe5f28" category="paragraph">Pour gérer efficacement et en toute sécurité plusieurs bases de données Oracle, il est nécessaire de disposer d'une stratégie de qualité de service efficace. C'est pourquoi les systèmes de stockage modernes offrent des performances toujours plus élevées.</block>
  <block id="3408fe4b6e4b2ed9366356f08e3b9ab0" category="summary">Efficacité du stockage et des bases de données Oracle</block>
  <block id="151654fbc652cca26707bd7a060073d3" category="doc">Bases de données Oracle et fonctionnalités d'efficacité ONTAP</block>
  <block id="4564218d346b0ef8263512ebe659337d" category="paragraph">Les fonctionnalités ONTAP d'optimisation de l'espace sont optimisées pour les bases de données Oracle. Dans la plupart des cas, la meilleure approche consiste à conserver les valeurs par défaut avec toutes les fonctionnalités d'efficacité activées.</block>
  <block id="794c6d3bb54da92d9a4a4022bc5c4e94" category="summary">RAID et les bases de données Oracle</block>
  <block id="e959fe6bb794f67f31a0d4e6bc5d5bf4" category="paragraph">RAID désigne l'utilisation de la redondance pour protéger les données contre la perte d'un disque.</block>
  <block id="b60b0e7c75501fe2f322675f2e6da6d7" category="paragraph">Des questions se posent parfois au sujet des niveaux RAID dans la configuration du stockage NetApp utilisé pour les bases de données Oracle et d'autres applications d'entreprise. De nombreuses meilleures pratiques Oracle en matière de configuration de baie de stockage contiennent des avertissements concernant l'utilisation de la mise en miroir RAID et/ou l'évitement de certains types de RAID. Bien qu'elles soulèvent des points valides, ces sources ne s'appliquent pas au RAID 4 et aux technologies NetApp RAID DP et RAID-TEC utilisées dans ONTAP.</block>
  <block id="6de6bcceac7c1a53ecb774d42b8d5c9a" category="summary">Provisionnement fin Oracle et ONTAP</block>
  <block id="26c71bfc140fc9f2d56f83f7aedffd53" category="paragraph">Le provisionnement fin pour une base de données Oracle nécessite une planification minutieuse, car il en résulte une configuration d'espace sur un système de stockage qui n'est pas nécessairement physiquement disponible. Cela vaut vraiment le coup, car une fois correctement effectué, il en résulte des économies considérables et des améliorations en termes de gestion.</block>
  <block id="c9a6446e7a1a2aa2d3d06c76b3dd02ae" category="summary">Provisionnement SVM pour les bases de données Oracle</block>
  <block id="eaa6380760494a867d1be23523aaba3e" category="doc">Bases de données Oracle et machines virtuelles de stockage</block>
  <block id="ffa2dec61afa63c15c9906328e62e2e8" category="paragraph">La gestion du stockage des bases de données Oracle est centralisée sur un SVM (Storage Virtual machine)</block>
  <block id="ba0fd7b6bfa61ad7f7ad5326a0934d01" category="summary">Il est nécessaire de bien comprendre les fonctions de basculement et de basculement du stockage pour s'assurer que les opérations de la base de données Oracle ne sont pas interrompues par ces opérations. En outre, les arguments utilisés par les opérations de basculement et de basculement peuvent affecter l'intégrité des données en cas d'utilisation incorrecte.</block>
  <block id="999548558d2844d78a3b5f9186c231a4" category="summary">Capacité de stockage et espace libre pour les bases de données et ONTAP</block>
  <block id="360612d74cdd78953036946ec943f795" category="paragraph">La gestion d'une base de données ou d'une autre application d'entreprise avec un stockage d'entreprise prévisible, gérable et haute performance requiert de l'espace libre sur les disques pour la gestion des données et des métadonnées. La quantité d'espace libre requise dépend du type de disque utilisé et des processus métier.</block>
  <block id="d3cc759510a3aba837fc8efeb2e24b91" category="doc">db_file_multibloc_read_count</block>
  <block id="32faf0a922da10425f2be9f86a5f5e18" category="paragraph">Le<block ref="d3cc759510a3aba837fc8efeb2e24b91" prefix=" " category="inline-code"></block> Paramètre contrôle le nombre maximal de blocs de base de données Oracle lus par Oracle au cours d'une opération, pendant les E/S séquentielles</block>
  <block id="36cb03af3dc688208e0e94fda31ca7a4" category="paragraph">Toutefois, ce paramètre n'affecte pas le nombre de blocs lus par Oracle au cours des opérations de lecture, ni le nombre d'E/S aléatoires Seule la taille de bloc des E/S séquentielles est affectée.</block>
  <block id="2565c992b3732464484104f4c846d9b4" category="paragraph">Oracle recommande à l'utilisateur de ne pas définir ce paramètre. Cela permet au logiciel de base de données de définir automatiquement la valeur optimale. Cela signifie généralement que ce paramètre est défini sur une valeur qui produit une taille d'E/S de 1 Mo. Par exemple, une lecture de 1 Mo de blocs de 8 Ko nécessite la lecture de 128 blocs. La valeur par défaut de ce paramètre est donc 128.</block>
  <block id="0fd26e725a6c1a81508e013094776e2c" category="paragraph">La plupart des problèmes de performance de base de données observés par NetApp sur les sites des clients provenaient de paramètres incorrects. Des raisons valides ont été données pour modifier cette valeur avec les versions 8 et 9 d'Oracle. Par conséquent, le paramètre peut être présent sans le savoir dans<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> Fichiers car la base de données a été mise à niveau vers Oracle 10 et versions ultérieures. La configuration héritée de 8 ou 16, par rapport à la valeur par défaut 128, nuit de manière significative aux performances d'E/S séquentielles.</block>
  <block id="3f594bb922365c7a9f095f44822fa22e" category="admonition">*NetApp recommande* de régler le<block ref="d3cc759510a3aba837fc8efeb2e24b91" prefix=" " category="inline-code"></block> le paramètre ne doit pas être présent dans le<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> fichier. NetApp n'a jamais observé d'amélioration des performances suite à la modification de ce paramètre, mais le débit d'E/S séquentielles subit une importante dégradation dans de nombreux cas.</block>
  <block id="0eec903bb9d87349e379892ca99ef9ec" category="paragraph">Oracle RAC est un produit clusterware qui comporte plusieurs types de processus de pulsation internes qui contrôlent l'intégrité du cluster.</block>
  <block id="7c13d022c9fda6e792c4349a043a6c74" category="inline-link-macro">misscount</block>
  <block id="bab4ae46619fcbbb84e3375ef205e61c" category="admonition">Les informations dans le <block ref="9cd17d807316d35ef47b12cbecab4ec8" category="inline-link-macro-rx"></block> La section contient des informations essentielles pour les environnements RAC Oracle utilisant un stockage en réseau. Dans la plupart des cas, les paramètres RAC Oracle par défaut devront être modifiés pour garantir que le cluster RAC résiste aux modifications de chemin réseau et aux opérations de basculement/basculement du stockage.</block>
  <block id="0494651671c3dc7f1ccdf99a4368a2cf" category="section-title">disktimeout</block>
  <block id="1973cfff3b7c6d828ede9d420b8481b5" category="paragraph">Le paramètre RAC principal lié au stockage est<block ref="0494651671c3dc7f1ccdf99a4368a2cf" prefix=" " category="inline-code"></block>. Ce paramètre contrôle le seuil au sein duquel les E/S du fichier de vote doivent être terminées. Si le<block ref="0494651671c3dc7f1ccdf99a4368a2cf" prefix=" " category="inline-code"></block> Le paramètre est dépassé, puis le nœud RAC est supprimé du cluster. La valeur par défaut de ce paramètre est 200. Cette valeur doit être suffisante pour les procédures standard de Takeover et and Giveback du stockage.</block>
  <block id="4aa33fc988e36b9531d36da80d35ec2f" category="paragraph">NetApp recommande fortement de tester soigneusement les configurations RAC avant de les mettre en production, car de nombreux facteurs affectent un basculement ou un rétablissement. Outre le temps nécessaire au basculement du stockage, la propagation des modifications du protocole LACP (Link Aggregation Control Protocol) nécessite également du temps supplémentaire. En outre, le logiciel de chemins d'accès multiples SAN doit détecter un délai d'expiration d'E/S et réessayer sur un autre chemin. Si une base de données est extrêmement active, une grande quantité d'E/S doit être mise en file d'attente et relancée avant le traitement des E/S du disque de vote.</block>
  <block id="655a10764a0781d26dca3bfb939457b7" category="paragraph">En l'absence d'un basculement ou d'un retour de stockage réel, l'effet peut être simulé à l'aide de tests de câble Pull sur le serveur de base de données.</block>
  <block id="b2a9e8dd67b2d9a7333cb2c2495c2aa5" category="list-text">En quittant le<block ref="0494651671c3dc7f1ccdf99a4368a2cf" prefix=" " category="inline-code"></block> paramètre à la valeur par défaut de 200.</block>
  <block id="971a52f4b805c654dd133cf142457c53" category="list-text">Testez toujours soigneusement une configuration RAC.</block>
  <block id="cd7a91511dbfbe5c79de12fa7d394dc0" category="paragraph">Le<block ref="7c13d022c9fda6e792c4349a043a6c74" prefix=" " category="inline-code"></block> Le paramètre affecte normalement uniquement la pulsation réseau entre les nœuds RAC. La valeur par défaut est 30 secondes. Si les binaires de la grille se trouvent sur une matrice de stockage ou si le disque d'amorçage du système d'exploitation n'est pas local, ce paramètre peut devenir important. Cela inclut les hôtes avec des lecteurs de démarrage situés sur un SAN FC, les systèmes d'exploitation démarrés par NFS et les lecteurs de démarrage situés sur les datastores de virtualisation, tels qu'un fichier VMDK.</block>
  <block id="9c1fd24d7d8e04847dadb944a6643121" category="paragraph">Si l'accès à un disque de démarrage est interrompu par un basculement ou un rétablissement du stockage, il est possible que l'emplacement binaire de la grille ou l'ensemble du système d'exploitation soit temporairement bloqué. Le temps nécessaire à ONTAP pour terminer l'opération de stockage et au système d'exploitation pour changer les chemins et reprendre les E/S peut être supérieur à<block ref="7c13d022c9fda6e792c4349a043a6c74" prefix=" " category="inline-code"></block> seuil. Par conséquent, un nœud est immédiatement supprimé une fois la connectivité à la LUN de démarrage ou aux binaires de la grille restaurée. Dans la plupart des cas, l'exclusion et le redémarrage qui s'ensuit se produisent sans message de journalisation indiquant la raison du redémarrage. Toutes les configurations ne sont pas affectées. Testez donc tout hôte de démarrage SAN, de démarrage NFS ou basé sur un datastore dans un environnement RAC afin que RAC reste stable si la communication avec le lecteur de démarrage est interrompue.</block>
  <block id="2b875dbca82565f3d7e2fa51633bc2c9" category="paragraph">Dans le cas de lecteurs de démarrage non locaux ou d'un système de fichiers non local hébergeant<block ref="ff4a008470319a22d9cf3d14af485977" prefix=" " category="inline-code"></block> binaires, le<block ref="7c13d022c9fda6e792c4349a043a6c74" prefix=" " category="inline-code"></block> devra être modifié pour correspondre<block ref="0494651671c3dc7f1ccdf99a4368a2cf" prefix=" " category="inline-code"></block>. Si ce paramètre est modifié, effectuez des tests supplémentaires pour identifier également les effets sur le comportement du RAC, tels que le temps de basculement du nœud.</block>
  <block id="08d7a86ed9292993deaa28bee18d5ce5" category="list-text">Quittez le<block ref="7c13d022c9fda6e792c4349a043a6c74" prefix=" " category="inline-code"></block> paramètre à la valeur par défaut de 30, sauf si l'une des conditions suivantes s'applique :</block>
  <block id="5b46e861366ffd98cd94c26abf2bf550" category="list-text"><block ref="ff4a008470319a22d9cf3d14af485977" prefix="" category="inline-code"></block> Les fichiers binaires sont situés sur un disque connecté au réseau, y compris les disques basés sur NFS, iSCSI, FC et les datastores.</block>
  <block id="7ace6d79e63cb29c86093526fbddf845" category="list-text">Le système d'exploitation est démarré sur un SAN.</block>
  <block id="985511d6258bbf659d35bd76e0b0cea1" category="list-text">Dans de tels cas, évaluez l'effet des interruptions de réseau qui affectent l'accès au système d'exploitation ou<block ref="9599929f8663b5e2093f7bc5cb20b0c2" prefix=" " category="inline-code"></block> systèmes de fichiers. Dans certains cas, de telles interruptions provoquent le blocage des démons RAC Oracle, ce qui peut conduire à un<block ref="7c13d022c9fda6e792c4349a043a6c74" prefix=" " category="inline-code"></block>délai d'expiration et suppression basés sur. Le délai par défaut est de 27 secondes, soit la valeur de<block ref="7c13d022c9fda6e792c4349a043a6c74" prefix=" " category="inline-code"></block> moins<block ref="c9333b0a26b9f9e9fd808e6238d613b0" prefix=" " category="inline-code"></block>. Dans de tels cas, augmenter<block ref="7c13d022c9fda6e792c4349a043a6c74" prefix=" " category="inline-code"></block> à 200 pour correspondre<block ref="0494651671c3dc7f1ccdf99a4368a2cf" prefix=" " category="inline-code"></block>.</block>
  <block id="a3f7c31b8d967e0ac9f9dd30fc81c061" category="paragraph">Le paramètre d'initialisation Oracle<block ref="f1110589be196c2310808482067fce1b" prefix=" " category="inline-code"></block> Contrôle l'utilisation des E/S asynchrones et directes</block>
  <block id="d1fa3441fd96418a75a509ac2907d644" category="paragraph">Contrairement à une idée reçue, ces deux types d'E/S ne s'excluent pas mutuellement. NetApp a observé que ce paramètre est souvent mal configuré dans les environnements des clients. Cette configuration incorrecte est la cause directe de nombreux problèmes de performances.</block>
  <block id="0775b72ddf51e2a16e466ee2df8f75ab" category="paragraph">Les E/S asynchrones offrent la possibilité de paralléliser les opérations Oracle d'E/S. Avant la disponibilité des E/S asynchrones sur différents systèmes d'exploitation, les utilisateurs ont configuré de nombreux processus dbwriter et modifié la configuration du processus serveur. Avec les E/S asynchrones, le système d'exploitation lui-même exécute les E/S en parallèle pour le compte du logiciel de base de données. Ce processus ne présente aucun risque pour les données et les opérations critiques, telles que la journalisation de reprise Oracle, sont toujours exécutées de manière synchrone.</block>
  <block id="6b72950206966c1983e559eb6886ec69" category="paragraph">Les E/S directes contournent le cache du tampon du système d'exploitation. Sur un système UNIX, les E/S transitent normalement par le cache du tampon du système d'exploitation. Ceci est utile pour les applications qui ne maintiennent pas de cache interne, mais Oracle dispose de son propre cache de tampon dans la SGA. Dans la plupart des cas, il est préférable d'activer les E/S directes et d'allouer la RAM du serveur à la mémoire SGA plutôt que d'utiliser le cache du tampon du système d'exploitation. La SGA exploite la mémoire plus efficacement. En outre, lors de leur transit via le tampon du se, les E/S sont soumises à un traitement supplémentaire, ce qui augmente les latences. Cette augmentation est particulièrement visible lors des E/S intenses en écriture, pour lesquelles la faible latence est primordiale.</block>
  <block id="d8590a940a5bb30d8a845f4359f3c779" category="paragraph">Les options pour<block ref="f1110589be196c2310808482067fce1b" prefix=" " category="inline-code"></block> sont :</block>
  <block id="0aea10c6719256027228a859db38f291" category="list-text">*Async.* Oracle soumet des demandes d'E/S au système d'exploitation pour traitement. Ce qui lui permet d'effectuer d'autres tâches plutôt que d'attendre la fin des E/S et d'augmenter ainsi la parallélisation des E/S.</block>
  <block id="00cb0cc309682c42b3b936a19a042434" category="list-text">*Directio.* Oracle effectue des E/S directement par rapport aux fichiers physiques plutôt que de router les E/S via le cache du système d'exploitation hôte.</block>
  <block id="f9941e1b6cc84711e95db0e757efc36a" category="list-text">*None.* Oracle utilise des E/S synchrones et mises en tampon Dans cette configuration, le choix entre les processus serveur partagés et dédiés et le nombre de dbwriter est plus important.</block>
  <block id="f0939ff6231565c83c5c8c9ce1eddc9d" category="list-text">*Setall.* Oracle utilise des E/S asynchrones et directes Dans presque tous les cas, l'utilisation de<block ref="aef8f91b1e026cc1bb55e8b08c491d35" prefix=" " category="inline-code"></block> est optimale.</block>
  <block id="8647b2eaf101a9425f69e6f2e67aeb9d" category="admonition">Le<block ref="f1110589be196c2310808482067fce1b" prefix=" " category="inline-code"></block> Ce paramètre n'a aucun effet dans les environnements dNFS et ASM. Dans ces environnements, les E/S asynchrones et directes sont automatiquement utilisées</block>
  <block id="6dd5604aa0be2956f8b1b41c74fa648e" category="paragraph">Certains clients ont déjà rencontré des problèmes d'E/S asynchrones, notamment avec les versions précédentes de Red Hat Enterprise Linux 4 (RHEL4). Certains conseils obsolètes sur Internet suggèrent toujours d'éviter les E/S asynchrones en raison d'informations obsolètes. Les E/S asynchrones sont stables sur tous les systèmes d'exploitation actuels. Il n'y a aucune raison de le désactiver, en l'absence d'un bug connu avec le système d'exploitation.</block>
  <block id="1ea377466376b194b2d1bfc3ab2fa4c4" category="paragraph">Si une base de données utilise des E/S mises en tampon, un switch vers des E/S directes peut également justifier une modification de la taille de la mémoire SGA. La désactivation des E/S mises en tampon élimine le gain de performance fourni par le cache du se hôte pour la base de données. L'ajout de RAM à la SGA résout ce problème. Et devrait améliorer les performances nettes d'E/S.</block>
  <block id="787b3d8b62af05ac3efd1c9ca7a8fc7e" category="paragraph">Bien qu'il soit presque toujours préférable d'utiliser la RAM pour la SGA d'Oracle plutôt que pour le cache du tampon du système d'exploitation, il peut s'avérer impossible de déterminer ce qui est le plus avantageux. Par exemple, il est parfois préférable d'utiliser des E/S mises en tampon avec une mémoire SGA de très petite taille sur un serveur de base de données comportant de nombreuses instances Oracle actives par intermittence. Cette configuration permet à toutes les instances de base de données en cours d'exécution d'utiliser de manière flexible la RAM restante sur le système d'exploitation. Cette situation est très inhabituelle, mais elle a été observée sur certains sites clients.</block>
  <block id="d4157ab77eb31459bd406aa0f873e20c" category="admonition">*NetApp recommande* le réglage<block ref="f1110589be196c2310808482067fce1b" prefix=" " category="inline-code"></block> à<block ref="aef8f91b1e026cc1bb55e8b08c491d35" prefix=" " category="inline-code"></block>, Mais notez que dans certains cas, la perte du cache du tampon hôte peut nécessiter une augmentation de la SGA d'Oracle.</block>
  <block id="f8b42f9efd1a05ede10b0e0c11dfa8b0" category="paragraph">ONTAP utilise en interne une taille de bloc variable, ce qui signifie que les bases de données Oracle peuvent être configurées avec n'importe quelle taille de bloc. Cependant, la taille des blocs du système de fichiers peut affecter les performances et, dans certains cas, une taille de bloc de reprise supérieure peut améliorer les performances.</block>
  <block id="0944aedb4703c4a5e94fb90de9d7a22f" category="section-title">Tailles des blocs de fichiers de données</block>
  <block id="cc4662c047050e0082701ce6f052dcb7" category="paragraph">Certains systèmes d'exploitation offrent un choix de tailles de blocs de système de fichiers. Pour les systèmes de fichiers prenant en charge les fichiers de données Oracle, la taille de bloc doit être de 8 Ko lorsque la compression est utilisée. Lorsque la compression n'est pas requise, vous pouvez utiliser une taille de bloc de 8 Ko ou 4 Ko.</block>
  <block id="e1a001cf8c7e2072c7a44ee65e8fee11" category="paragraph">Si un fichier de données est placé sur un système de fichiers avec un bloc de 512 octets, des fichiers mal alignés sont possibles. Il est possible que le LUN et le système de fichiers soient correctement alignés en fonction des recommandations de NetApp, mais les E/S de fichier sont mal alignées. Un tel mauvais alignement entraînerait de graves problèmes de performances.</block>
  <block id="9514c8638f798f68108498dd218ec793" category="paragraph">Les systèmes de fichiers prenant en charge les journaux de reprise doivent utiliser une taille de bloc qui représente un multiple de la taille de bloc de reprise. Cela nécessite généralement que le système de fichiers redo log et le fichier redo log lui-même utilisent une taille de bloc de 512 octets.</block>
  <block id="cac7d87a1164763b666ca7d02109d153" category="section-title">Rétablir les tailles des blocs</block>
  <block id="fa06b9584ea36af182742c07894220f0" category="paragraph">Avec des taux de reprise très élevés, il est possible que des tailles de bloc de 4 Ko soient plus performantes, car les taux de reprise élevés permettent d'exécuter les E/S en moins d'opérations et de manière plus efficace. Si les taux de reprise sont supérieurs à 50 Mbit/s, envisagez de tester une taille de bloc de 4 Ko.</block>
  <block id="781000593b4913b5625dd5ed9eebe87e" category="paragraph">Quelques problèmes clients ont été identifiés avec les bases de données à l'aide de journaux de reprise avec une taille de bloc de 512 octets sur un système de fichiers d'une taille de bloc de 4 Ko et de nombreuses transactions très petites. La surcharge liée à l'application de plusieurs modifications de 512 octets à un seul bloc du système de fichiers de 4 Ko a entraîné des problèmes de performances qui ont été résolus en changeant le système de fichiers pour qu'il utilise une taille de bloc de 512 octets.</block>
  <block id="a02416fde36b174cf1196213fcf1bef6" category="admonition">*NetApp vous recommande* de ne pas modifier la taille du bloc de reprise, sauf si un service client ou un service professionnel vous en informe ou si le changement est basé sur la documentation officielle du produit.</block>
  <block id="65a6ece62f52a5e2ff74baaae821ae86" category="paragraph">La reprise d'activité consiste à restaurer les services de données après une catastrophe, par exemple un incendie qui détruit un système de stockage, voire un site entier.</block>
  <block id="e168b3b0b2f075f39012df52c5ea3c0a" category="admonition">Cette documentation remplace les rapports techniques _TR-4591 : Oracle Data protection_ et _TR-4592 : Oracle on MetroCluster._</block>
  <block id="a91982f09e6a0341a90dae002865ea11" category="paragraph">La reprise après incident peut être effectuée par une simple réplication des données à l'aide de SnapMirror, bien sûr, lorsque de nombreux clients mettent à jour les réplicas en miroir toutes les heures.</block>
  <block id="ad2c5e9521f13e89cd84fdd65ec96c7d" category="paragraph">MetroCluster fait référence à ONTAP dans une configuration matérielle qui inclut un stockage en miroir synchrone de faible niveau et de nombreuses fonctionnalités supplémentaires. Les solutions intégrées telles que MetroCluster simplifient les bases de données, les applications et les infrastructures de virtualisation complexes et évolutives. Elle remplace plusieurs produits et stratégies externes de protection des données par une seule baie de stockage centrale simple. Elle offre également des fonctionnalités intégrées de sauvegarde, de restauration, de reprise après incident et de haute disponibilité au sein d'un seul système de stockage en cluster.</block>
  <block id="4278792a47efb1e599476fe07109dca4" category="inline-link-macro">Oracle RAC sur MetroCluster</block>
  <block id="d12be40db836559c628e8024f5d6ff56" category="paragraph">Pour comprendre le fonctionnement des bases de données Oracle dans un environnement MetroCluster, il est nécessaire d'expliquer la conception physique d'un système MetroCluster.</block>
  <block id="5e33c0d8a2417ce5fb6e7a211ad063bb" category="admonition">Cette documentation remplace le rapport technique _TR-4592 : Oracle on MetroCluster._</block>
  <block id="37fa92fc2662529308c62c84eb1b38ea" category="paragraph">Comprendre le fonctionnement des bases de données Oracle dans un environnement MetroCluster alsop nécessite une explication de la fonctionnalité logique d'un système MetroCluster.</block>
  <block id="2623b589ddbc1cdb6184ba32aa06e83f" category="inline-link-macro">NVFAIL</block>
  <block id="a4feacea8b05d0f24e5a4612a164a055" category="paragraph">Les bonnes pratiques habituelles s'appliquent toujours. Si vos besoins requièrent uniquement une protection des données avec un objectif de point de récupération de 0, MetroCluster répond à ce besoin. Cependant, la plupart des clients utilisent MetroCluster non seulement pour la protection des données avec un objectif de point de récupération de 0, mais aussi pour améliorer l'objectif de délai de restauration en cas d'incident et fournir un basculement transparent dans le cadre des activités de maintenance du site.</block>
  <block id="3ff8bcf18c694581aa25b0a347508e0f" category="section-title">Basculement avec un système d'exploitation préconfiguré</block>
  <block id="442f34633164f1be348a442b2c62d29d" category="list-text">Forçage du basculement MetroCluster</block>
  <block id="e081e79ea1b1040c51d4a452e46de76d" category="list-text">Découverte de LUN FC (SAN uniquement)</block>
  <block id="e60946bf73021e18706a6ac33386b376" category="paragraph">La procédure d'activation réelle est simple. Les commandes telles que la découverte de LUN ne nécessitent que quelques commandes par port FC. Le montage du système de fichiers n'est rien de plus qu'un<block ref="19822b1b15d9eefc54c07ab49f87b100" prefix=" " category="inline-code"></block> Et les bases de données et ASM peuvent être démarrés et arrêtés sur l'interface de ligne de commande à l'aide d'une seule commande. Si les volumes et les systèmes de fichiers ne sont pas utilisés sur le site de reprise d'activité avant le basculement, il n'est pas nécessaire de les définir<block ref="3b93661df04b698b1340ff2da3238d16" prefix=" " category="inline-code"></block> sur les volumes.</block>
  <block id="486eed21f55b6fb544db5504294592e6" category="section-title">Basculement avec un système d'exploitation virtualisé</block>
  <block id="bf65e943f86f26b49698bfdac9b95f81" category="paragraph">Le basculement des environnements de base de données peut être étendu pour inclure le système d'exploitation lui-même. En théorie, ce basculement peut être effectué avec des LUN de démarrage, mais le plus souvent avec un système d'exploitation virtualisé. La procédure est similaire aux étapes suivantes :</block>
  <block id="7c37589384e83d2b43bba430c18a45aa" category="list-text">Montage des datastores hébergeant les machines virtuelles du serveur de base de données</block>
  <block id="3d4d04d6cdab90b7ca0deb0344f04eec" category="list-text">Démarrage des machines virtuelles</block>
  <block id="c702c387f07bcb4f18482e68d69a155a" category="paragraph">Le socle de la protection des données Oracle avec un système MetroCluster est SyncMirror, une technologie de mise en miroir synchrone scale-out aux performances maximales.</block>
  <block id="9028b52caaa7bdbfb9be779eeb1fe00e" category="summary">Oracle Extended RAC avec MetroCluster</block>
  <block id="4d4d8a609e5b2ac58e622eb1e90f9e39" category="paragraph">De nombreux clients optimisent leur RTO en étendant un cluster Oracle RAC sur plusieurs sites, offrant une configuration entièrement active/active. La conception globale devient plus complexe car elle doit inclure la gestion du quorum d'Oracle RAC. En outre, l'accès aux données se fait depuis les deux sites, ce qui signifie qu'un basculement forcé peut entraîner l'utilisation d'une copie obsolète des données.</block>
  <block id="89ffaa1a7d089080e9a1ce912bb8c2d3" category="paragraph">Bien qu'une copie des données soit présente sur les deux sites, seul le contrôleur qui possède actuellement un agrégat peut assurer le service des données. Par conséquent, avec les clusters RAC étendus, les nœuds distants doivent effectuer des E/S sur une connexion site à site. Il en résulte une latence d'E/S supplémentaire, mais cette latence n'est généralement pas problématique. Le réseau d'interconnexion RAC doit également être étendu entre les sites, ce qui signifie qu'un réseau haut débit à faible latence est requis de toute façon. Si la latence supplémentaire pose problème, le cluster peut être exploité de manière actif-passif. Les opérations exigeantes en E/S devront ensuite être dirigées vers les nœuds RAC locaux vers le contrôleur propriétaire des agrégats. Les nœuds distants effectuent alors des opérations d'E/S plus légères ou sont utilisés uniquement comme serveurs de secours.</block>
  <block id="f441d5fdc388f3419fb87e071534f3ce" category="inline-link-macro">Oracle RAC avec ONTAP</block>
  <block id="58285fb769eb7fb05ab12d9e0efb3e50" category="section-title">Configuration à deux sites</block>
  <block id="af1184f29d838fbfec8d5b5bf5225f66" category="paragraph">Une configuration RAC étendue sur deux sites peut fournir des services de base de données actif-actif qui peuvent survivre à de nombreux scénarios d'incident, mais pas à tous, sans interruption.</block>
  <block id="7544489c7854fcae445508015240a865" category="section-title">Fichiers de vote RAC</block>
  <block id="8b6e46422f88dab6ea82f2dbcadfc76b" category="paragraph">La gestion du quorum doit être prise en compte lors du déploiement du RAC étendu sur MetroCluster. Oracle RAC dispose de deux mécanismes pour gérer le quorum : le battement de cœur du disque et le battement de cœur du réseau. La pulsation du disque surveille l'accès au stockage à l'aide des fichiers de vote. Dans le cas d'une configuration RAC à site unique, une ressource de vote unique suffit tant que le système de stockage sous-jacent offre des fonctionnalités haute disponibilité.</block>
  <block id="fafd618b82d1827eeb8197e1c38722bc" category="paragraph">Dans les versions précédentes d'Oracle, les fichiers de vote étaient placés sur des périphériques de stockage physiques, mais dans les versions actuelles d'Oracle, les fichiers de vote sont stockés dans des groupes de disques ASM.</block>
  <block id="aeab2391a07321ac474989b9c9047226" category="admonition">Oracle RAC est pris en charge par NFS. Pendant le processus d'installation de la grille, un ensemble de processus ASM est créé pour présenter l'emplacement NFS utilisé pour les fichiers de grille en tant que groupe de disques ASM. Le processus est presque transparent pour l'utilisateur final et ne nécessite aucune gestion ASM continue une fois l'installation terminée.</block>
  <block id="42aca4aae768d5ec1cb0c50d41b7b8b7" category="paragraph">Dans une configuration à deux sites, il est tout d'abord nécessaire de s'assurer que chaque site peut toujours accéder à plus de la moitié des fichiers de vote, ce qui garantit un processus de reprise après incident sans interruption. Cette tâche était simple avant que les fichiers de vote ne soient stockés dans des groupes de disques ASM, mais aujourd'hui, les administrateurs doivent comprendre les principes de base de la redondance ASM.</block>
  <block id="60a723853bb2c173648452baf2199e73" category="paragraph">Les groupes de disques ASM disposent de trois options de redondance<block ref="6a21b6995a068148bbb65c8f949b3fb2" prefix=" " category="inline-code"></block>,<block ref="fea087517c26fadd409bd4b9dc642555" prefix=" " category="inline-code"></block>, et<block ref="8d966b2253a917086c8604959e152243" prefix=" " category="inline-code"></block>. En d'autres termes, sans miroir, avec miroir et miroir à 3 voies. Une option plus récente appelée<block ref="09d2bd168181f1e64c2b1651a80a8aa8" prefix=" " category="inline-code"></block> est également disponible, mais rarement utilisé. Le niveau de redondance et le placement des périphériques redondants contrôlent ce qui se passe dans les scénarios de panne. Par exemple :</block>
  <block id="32cdeb2c0245b51a0b590e6054f03c21" category="list-text">Placer les fichiers de vote sur un<block ref="d4f266c5956ee60df748738c483f3dc0" prefix=" " category="inline-code"></block> avec<block ref="6a21b6995a068148bbb65c8f949b3fb2" prefix=" " category="inline-code"></block> la redondance des ressources garantit la suppression d'un site en cas de perte de la connectivité intersite.</block>
  <block id="a549b4f1fc0c2d14bc333c70bbde73dc" category="list-text">Placer les fichiers de vote sur un<block ref="d4f266c5956ee60df748738c483f3dc0" prefix=" " category="inline-code"></block> avec<block ref="fea087517c26fadd409bd4b9dc642555" prefix=" " category="inline-code"></block> La redondance avec un seul disque ASM par site garantit la suppression des nœuds sur les deux sites en cas de perte de la connectivité intersite, car aucun des sites ne possède un quorum majoritaire.</block>
  <block id="c15f1c43a368db0ab3dde90eca52582d" category="list-text">Placer les fichiers de vote sur un<block ref="d4f266c5956ee60df748738c483f3dc0" prefix=" " category="inline-code"></block> avec<block ref="8d966b2253a917086c8604959e152243" prefix=" " category="inline-code"></block> la redondance avec deux disques sur un site et un seul disque sur l'autre site permet des opérations actif-actif lorsque les deux sites sont opérationnels et mutuellement accessibles. Toutefois, si le site à disque unique est isolé du réseau, ce site est supprimé.</block>
  <block id="478ced47a1ea1d6f0db02af749bfdaec" category="section-title">Pulsation du réseau RAC</block>
  <block id="2432333dc52d6150fb3d58051bc8b0c2" category="paragraph">Le signal de présence du réseau RAC Oracle surveille l'accessibilité des nœuds sur l'interconnexion de cluster. Pour rester dans le cluster, un nœud doit pouvoir contacter plus de la moitié des autres nœuds. Dans une architecture à deux sites, cette exigence crée les choix suivants pour le nombre de nœuds RAC :</block>
  <block id="3e36a59c8a51ee9cc2cba0e7051ed35f" category="list-text">Le placement d'un nombre égal de nœuds par site entraîne la suppression sur un site en cas de perte de la connectivité réseau.</block>
  <block id="4955aede919912b3c62fadbc1039671b" category="list-text">Le placement de N nœuds sur un site et de N+1 nœuds sur le site opposé garantit que la perte de la connectivité intersite entraîne le site avec le plus grand nombre de nœuds restants dans le quorum du réseau et le site avec moins de nœuds supprimés.</block>
  <block id="80bd651a66488201c928634689e2e5cc" category="paragraph">Avant Oracle 12cR2, il était impossible de contrôler quel côté devait être expulsé en cas de perte du site. Lorsque chaque site a un nombre égal de nœuds, l'exclusion est contrôlée par le nœud maître, qui est en général le premier nœud RAC à démarrer.</block>
  <block id="d128c05245b2e633856a5061db176b7e" category="paragraph">Oracle 12cR2 introduit la fonctionnalité de pondération des nœuds. L'administrateur peut ainsi mieux contrôler la manière dont Oracle résout les problèmes de partage du cerveau. À titre d'exemple simple, la commande suivante définit les préférences pour un nœud particulier dans un RAC :</block>
  <block id="104c5747f0d9dbb47b0d09953c709a8d" category="paragraph">Après le redémarrage d'Oracle High-Availability Services, la configuration se présente comme suit :</block>
  <block id="693cce334ab6658c73ea67674775156b" category="paragraph">Nœud<block ref="a31853cdea7badfc68b560e70cbbeb02" prefix=" " category="inline-code"></block> est maintenant désigné comme serveur critique. Si les deux nœuds RAC sont isolés,<block ref="a31853cdea7badfc68b560e70cbbeb02" prefix=" " category="inline-code"></block> survit, et<block ref="bf38e7432ba60433c4c8967fc8da0258" prefix=" " category="inline-code"></block> est supprimé.</block>
  <block id="386839b09451962d03e26b7bbfabce74" category="admonition">Pour plus d'informations, consultez le livre blanc Oracle « Oracle Clusterware 12c Release 2 Technical Overview. ”</block>
  <block id="11f65689342acc8f71c8014eeb7945ee" category="paragraph">Pour les versions d'Oracle RAC antérieures à 12cR2, le nœud maître peut être identifié en vérifiant les journaux CRS comme suit :</block>
  <block id="c8b8cd80b31dac17fb85459c341042bd" category="paragraph">Ce journal indique que le nœud maître est<block ref="c81e728d9d4c2f636f067f89cc14862c" prefix=" " category="inline-code"></block> et le nœud<block ref="a31853cdea7badfc68b560e70cbbeb02" prefix=" " category="inline-code"></block> A un ID de<block ref="c4ca4238a0b923820dcc509a6f75849b" prefix=" " category="inline-code"></block>. Ce fait signifie que<block ref="a31853cdea7badfc68b560e70cbbeb02" prefix=" " category="inline-code"></block> n'est pas le nœud maître. L'identité du nœud maître peut être confirmée avec la commande<block ref="08e7c60bbf8289a563b25cc033d431f7" prefix=" " category="inline-code"></block>.</block>
  <block id="fdf6179b59d3f4873b042609a5f09bc4" category="paragraph">Le nœud ayant l'ID de<block ref="c81e728d9d4c2f636f067f89cc14862c" prefix=" " category="inline-code"></block> est<block ref="bf38e7432ba60433c4c8967fc8da0258" prefix=" " category="inline-code"></block>, qui est le nœud maître. Dans une configuration avec un nombre égal de nœuds sur chaque site, le site avec<block ref="bf38e7432ba60433c4c8967fc8da0258" prefix=" " category="inline-code"></block> est le site qui survit si les deux ensembles perdent la connectivité réseau pour quelque raison que ce soit.</block>
  <block id="f2932b43ad604fa01d57212558608ed6" category="paragraph">Il est possible que l'entrée de journal qui identifie le nœud maître puisse sortir du système. Dans ce cas, les horodatages des sauvegardes du registre des clusters Oracle (OCR) peuvent être utilisés.</block>
  <block id="50cd29958db0c1dcb6505d470f553e54" category="paragraph">Cet exemple montre que le nœud maître est<block ref="bf38e7432ba60433c4c8967fc8da0258" prefix=" " category="inline-code"></block>. Il indique également un changement dans le nœud maître de<block ref="a31853cdea7badfc68b560e70cbbeb02" prefix=" " category="inline-code"></block> à<block ref="bf38e7432ba60433c4c8967fc8da0258" prefix=" " category="inline-code"></block> Quelque part entre 2:05 et 21:39 le 4 mai. Cette méthode d'identification du nœud maître n'est sûre que si les journaux CRS ont également été vérifiés car il est possible que le nœud maître ait changé depuis la sauvegarde OCR précédente. Si ce changement s'est produit, il doit être visible dans les journaux OCR.</block>
  <block id="df044a3c3d7f7f244db7c42b347b9a90" category="paragraph">La plupart des clients choisissent un seul groupe de disques de vote qui dessert l'ensemble de l'environnement et un nombre égal de nœuds RAC sur chaque site. Le groupe de disques doit être placé sur le site qui contient la base de données. En conséquence, une perte de connectivité entraîne la suppression du site distant. Le site distant n'aurait plus le quorum, ni l'accès aux fichiers de base de données, mais le site local continue à fonctionner normalement. Une fois la connectivité rétablie, l'instance distante peut être de nouveau mise en ligne.</block>
  <block id="84a24276bfdfbe485b9d961c1a57a830" category="paragraph">En cas d'incident, un basculement est nécessaire pour mettre en ligne les fichiers de base de données et le groupe de disques de vote sur le site survivant. Si l'incident permet à AUSO de déclencher le basculement, NVFAIL n'est pas déclenché, car le cluster est connu pour être synchronisé et les ressources de stockage sont normalement mises en ligne. L'AUSO est une opération très rapide et doit se terminer avant le<block ref="0494651671c3dc7f1ccdf99a4368a2cf" prefix=" " category="inline-code"></block> la période expire.</block>
  <block id="6244ee13e435dcc768edbc9b0b38b73e" category="paragraph">Comme il n'y a que deux sites, il n'est pas possible d'utiliser n'importe quel type de logiciel automatisé externe de rupture de tieBreaking, ce qui signifie que le basculement forcé doit être une opération manuelle.</block>
  <block id="568c8c12fdb7c74f65125732ee717ad3" category="section-title">Configurations à trois sites</block>
  <block id="2c7696fb04f52eb5687d059415066fa7" category="paragraph">Un cluster RAC étendu est beaucoup plus facile à concevoir avec trois sites. Les deux sites hébergeant chaque moitié du système MetroCluster prennent également en charge les workloads de la base de données, tandis que le troisième sert de disjoncteur pour la base de données et le système MetroCluster. La configuration Oracle Tiebreaker peut être aussi simple que le placement d'un membre du groupe de disques ASM utilisé pour le vote sur un troisième site, et peut également inclure une instance opérationnelle sur le troisième site pour s'assurer qu'il y a un nombre impair de nœuds dans le cluster RAC.</block>
  <block id="6265611ca77e9ad52249c5fdd4780da9" category="admonition">Consultez la documentation Oracle sur « quorum failure group » pour obtenir des informations importantes sur l'utilisation de NFS dans une configuration RAC étendue. En résumé, il peut être nécessaire de modifier les options de montage NFS pour inclure l'option logicielle permettant de s'assurer que la perte de connectivité au troisième site hébergeant les ressources quorum n'affecte pas les serveurs Oracle ou les processus RAC Oracle principaux.</block>
  <block id="d84d0eea463e72a6e15018c70a45af46" category="doc">Oracle, MetroCluster et NVFAIL</block>
  <block id="9dc6a9986107298da2a22e7c5a3efb00" category="summary">Instance unique Oracle sur MetroCluster</block>
  <block id="f8b28e31633ae72c2971ee8b815ed4af" category="paragraph">Comme indiqué précédemment, la présence d'un système MetroCluster n'ajoute pas nécessairement aux meilleures pratiques d'exploitation d'une base de données ou ne les modifie pas nécessairement. La majorité des bases de données qui s'exécutent actuellement sur les systèmes MetroCluster client sont à instance unique et suivent les recommandations de la documentation Oracle sur ONTAP.</block>
  <block id="f4872c843923dd8d8731ef66462b5a99" category="paragraph">SyncMirror livre une copie synchrone des données au niveau du site de reprise d'activité. La mise à disposition des données requiert un système d'exploitation et les applications associées. L'automatisation de base peut considérablement améliorer le délai de basculement de l'environnement global. Les produits Clusterware tels que Veritas Cluster Server (VCS) sont souvent utilisés pour créer un cluster sur les sites et, dans la plupart des cas, le processus de basculement peut être piloté par des scripts simples.</block>
  <block id="c50820a41eb4f23d0a3acc1eeddb391b" category="paragraph">En cas de perte des nœuds principaux, le cluster (ou les scripts) est configuré de manière à mettre les bases de données en ligne sur le site secondaire. Une option consiste à créer des serveurs de secours préconfigurés pour les ressources NFS ou SAN qui constituent la base de données. En cas de défaillance du site principal, le logiciel de mise en cluster ou l'alternative scriptée effectue une séquence d'actions similaires à celles décrites ci-dessous :</block>
  <block id="2a6f458321ddf666cb0c876ee39255f3" category="list-text">Montage de systèmes de fichiers et/ou montage de groupes de disques ASM</block>
  <block id="3dee93bd9bc9b8b50dcdd2066a86009f" category="list-text">Démarrage de la base de données</block>
  <block id="620515885465a26daea6cc6441403e34" category="paragraph">Cette approche doit avant tout se passer d'un système d'exploitation en cours d'exécution sur le site distant. Elles doivent être préconfigurées avec des binaires Oracle, ce qui signifie également que des tâches telles que l'application de correctifs Oracle doivent être effectuées sur les sites principal et de secours. Les binaires Oracle peuvent également être mis en miroir vers le site distant et montés en cas d'incident.</block>
  <block id="edb5332feef69c0aa60ea10ed5d31a9f" category="list-text">Démarrage manuel des bases de données ou configuration des machines virtuelles pour démarrer automatiquement les bases de données par exemple, un cluster ESX peut couvrir des sites. En cas d'incident, les machines virtuelles peuvent être mises en ligne sur le site de reprise après incident après le basculement. Tant que les datastores hébergeant les serveurs de base de données virtualisés ne sont pas utilisés au moment de l'incident, il n'est pas nécessaire de les définir<block ref="3b93661df04b698b1340ff2da3238d16" prefix=" " category="inline-code"></block> sur les volumes associés.</block>
  <block id="64bba30b717cb45555458da4fed880a1" category="paragraph">Presque toutes les applications nécessitent une réplication des données.</block>
  <block id="25fb1fa02f326334533a22c105ad3e69" category="paragraph">Au niveau le plus élémentaire, la réplication peut signifier une copie sur bande stockée hors site ou une réplication au niveau des applications vers un emplacement de secours. La reprise après incident fait référence à l'utilisation de ces copies de réplica pour mettre un service en ligne en cas de perte catastrophique de service.</block>
  <block id="eab6cb3a1168ef2311865e6155b8272c" category="paragraph">ONTAP propose plusieurs options de réplication pour répondre de nombreuses exigences de manière native à l'intérieur de la baie de stockage et couvrir un large éventail de besoins. Ces options peuvent inclure une simple réplication des sauvegardes vers un site distant jusqu'à une solution synchrone et entièrement automatisée qui assure à la fois la reprise après incident et la haute disponibilité sur la même plateforme.</block>
  <block id="32df0c1cabf839652741a56bdaac7def" category="paragraph">Les principales technologies de réplication ONTAP applicables aux applications sont les technologies NetApp SnapMirror et NetApp SyncMirror. Il ne s'agit pas de produits complémentaires ; ils sont plutôt entièrement intégrés à ONTAP et sont activés par l'ajout simple d'une clé de licence. La réplication au niveau du stockage n'est pas la seule option non plus. La réplication au niveau des applications, comme avec Oracle DataGuard, peut également s'intégrer à une stratégie de protection des données basée sur ONTAP.</block>
  <block id="a2259fa074bae962e46ca7fc7aa31be1" category="paragraph">Le bon choix dépend des exigences spécifiques en matière de réplication, de restauration et de conservation.</block>
  <block id="0d3b37ff5855bf299f3c4a154373c1e2" category="section-title">SnapMirror ONTAP</block>
  <block id="296e89e943f5160d338484b3b705a44e" category="paragraph">SnapMirror est la solution de réplication asynchrone NetApp. Elle est idéale pour protéger des datasets volumineux, complexes et dynamiques, tels que les bases de données et les applications associées. Ses valeurs clés sont les suivantes :</block>
  <block id="d9f36dae2818ace926c4259271530724" category="list-text">*Gérabilité.* SnapMirror est facile à configurer et à gérer car il fait partie intégrante du logiciel de stockage. Aucun produit complémentaire n'est requis. Les relations de réplication peuvent être établies en quelques minutes et gérées directement sur le système de stockage.</block>
  <block id="8f761eff026903aa0140319f597d1fb0" category="list-text">*Simplicité.* la réplication est basée sur des volumes FlexVol, qui sont des conteneurs de LUN ou de fichiers répliqués comme un seul groupe cohérent.</block>
  <block id="8b737d6a9db3de6436966db508cb51d4" category="list-text">*Efficacité.* une fois la relation de réplication initiale établie, seuls les changements sont répliqués. De plus, des fonctionnalités d'efficacité comme la déduplication et la compression sont préservées. De plus, le volume de données à transférer vers un site distant est réduit.</block>
  <block id="0783dadb67ff77ed26bbfc5d80fa0cbd" category="list-text">*Flexibilité.* les miroirs peuvent être temporairement brisés pour permettre le test des procédures de reprise après sinistre, et ensuite la mise en miroir peut être facilement rétablie sans besoin d'une remise en miroir complète. Seules les données modifiées doivent être appliquées pour que les miroirs soient synchronisés. La mise en miroir peut également être inversée pour permettre une resynchronisation rapide après la fin de l'incident et la remise en service du site d'origine. Enfin, les clones en lecture-écriture des données répliquées sont disponibles à des fins de test et de développement.</block>
  <block id="8a00f09d8937e890f2cfb4d7acf72733" category="paragraph">ONTAP propose plusieurs technologies de réplication, mais la plus flexible est SnapMirror, une option de mise en miroir asynchrone volume à volume.</block>
  <block id="80c8fae3d0b5dd100cc984d9ba3eced7" category="paragraph">Comme mentionné précédemment, un volume FlexVol est l'unité de gestion de base des sauvegardes basées sur des copies Snapshot et des restaurations basées sur SnapRestore. Un volume FlexVol est également l'unité de base de la réplication basée sur SnapMirror. La première étape consiste à établir le miroir de base du volume source vers le volume de destination. Une fois cette relation miroir initialisée, toutes les opérations suivantes sont basées uniquement sur la réplication des données modifiées.</block>
  <block id="c1020b1755f65f23643158ce6a4d22cc" category="paragraph">Les valeurs clés de SnapMirror sont les suivantes du point de vue de la restauration :</block>
  <block id="50bde20b37cd4d57fbff2b95f2f8ec97" category="list-text">Les opérations SnapMirror sont simples à comprendre et peuvent être facilement automatisées.</block>
  <block id="66162be45733f65fee4abb22e989eb78" category="list-text">Une simple mise à jour d'un réplica SnapMirror nécessite la réplication de seules les modifications de delta, ce qui réduit les besoins en bande passante et permet des mises à jour plus fréquentes.</block>
  <block id="a3b4fbe416387a4991ccaa8b325a68be" category="list-text">SnapMirror est hautement granulaire. Elle repose sur de simples relations volume à volume, ce qui permet de créer des centaines de répliques gérées de manière indépendante et d'intervalles de réplication. La réplication n'a pas besoin d'être universelle.</block>
  <block id="4e3785883ef3ccad9938d7e35e493057" category="list-text">La direction de symétrie peut être facilement inversée tout en conservant la possibilité de mettre à jour la relation en fonction des modifications seules. Il est ainsi possible de restaurer rapidement le site principal après un incident, comme une panne de courant. Seules les modifications doivent être synchronisées à nouveau vers la source.</block>
  <block id="8b8325381cf528eff12c1e678a3112f9" category="list-text">Les miroirs peuvent être facilement brisés et efficacement resynchés pour permettre la répétition des procédures de reprise après sinistre.</block>
  <block id="b1f45b7d95bfc815351fb649fa94b671" category="list-text">Si SnapMirror fonctionne en mode de réplication complète au niveau des blocs, il réplique non seulement les données d'un volume, mais aussi les copies Snapshot. Cette fonctionnalité permet à la fois de copier les données et d'effectuer un jeu complet de sauvegardes sur le site de reprise après incident.</block>
  <block id="ffafd9ae31dee51209961eb2453ac806" category="paragraph">SnapMirror s'exécutant en mode flexible de la version permet la réplication de snapshots spécifiques, permettant des durées de conservation différentes au niveau des sites principal et secondaire.</block>
  <block id="974658d7ac018cb945e78365b0a760fb" category="section-title">SnapMirror synchrone</block>
  <block id="ffbf9d0ce29a631b6eae8b22c41ec95e" category="paragraph">SnapMirror synchrone (SM-S) est une amélioration apportée à SnapMirror qui fournit une réplication synchrone RPO=0. Elle est le plus souvent utilisée dans les architectures de stockage où seule une partie du volume total de données nécessite une mise en miroir synchrone.</block>
  <block id="e8a45c4c0391895df78421904703c933" category="paragraph">SM-S peut fonctionner dans deux modes légèrement différents, Sync et StrictSync.</block>
  <block id="15a4e16195fb9d30c5df0e11df5c2166" category="paragraph">En mode synchrone, les modifications sont répliquées avant d'être acquittées. Cela garantit un RPO de zéro, tant que la réplication est opérationnelle. Si la modification ne peut pas être répliquée, SM-S peut quitter le mode synchrone et permettre aux opérations de continuer. Cela permet à RPO=0 dans des circonstances normales, mais les processus de données ne s'arrêtent pas complètement si la destination de réplication n'est pas disponible.</block>
  <block id="115455025d4664c0dd6deaaf3c1fc93c" category="paragraph">StrictSync garantit un RPO=0. Si les modifications ne sont pas répliquées, le système génère une erreur d'E/S qui provoque généralement l'arrêt d'une application.</block>
  <block id="1b1ea0d1ad6e5cfb06253a14fcdcfe71" category="inline-link">TR-4733</block>
  <block id="9ccd61d6efc86cc37743fdff385832e8" category="paragraph">Pour une explication complète de SM-S, voir<block ref="4459b84726c651a8047a6486e87e48fb" category="inline-link-rx"></block> Et la documentation officielle de ONTAP. Des fonctionnalités sont ajoutées en permanence avec les nouvelles versions de ONTAP.</block>
  <block id="6165c4352e1504dbaeef34d0cc50c187" category="section-title">Groupes de cohérence</block>
  <block id="0651e813e385dbd62a9bca9baee23c6c" category="paragraph">ONTAP permet de créer des snapshots de groupes de cohérence. Depuis la version 9.13.1, ONTAP peut répliquer des groupes de volumes (n'oubliez pas qu'un volume dans la terminologie ONTAP n'est pas une LUN, il s'agit d'un conteneur de gestion constitué d'un ou plusieurs fichiers ou LUN) en tant que groupe cohérent.</block>
  <block id="455c7758003d6ebd974e8858f5ef1d7d" category="paragraph">Vous pouvez ainsi répliquer un jeu de données multi-volumes et vous assurer que tous les volumes sont cohérents. Cela permet notamment de réaliser des opérations de reprise après incident « rompez le miroir et Go » sans avoir besoin d'étapes supplémentaires pour la restauration d'applications ou de bases de données.</block>
  <block id="c44a2da164b7b770fce6338a987670ee" category="section-title">MetroCluster et SyncMirror</block>
  <block id="b1a1cfbf3988d8abdfdedaabc1742ae9" category="paragraph">MetroCluster est également une solution de réplication synchrone conçue pour les workloads stratégiques à grande échelle. La réplication est basée sur SyncMirror. Au niveau de la couche la plus simple, SyncMirror crée deux ensembles complets de données protégées par RAID à deux emplacements différents. Elles peuvent se trouver dans des pièces adjacentes au sein d'un data Center ou bien se trouver à plusieurs kilomètres de distance.</block>
  <block id="89b8adf28db7abb0febecafdca5871ad" category="paragraph">SyncMirror est totalement intégré à ONTAP et fonctionne juste au-dessus du niveau RAID. Par conséquent, toutes les fonctionnalités ONTAP habituelles, telles que les copies Snapshot, SnapRestore et NetApp FlexClone, fonctionnent de manière transparente. Il s'agit toujours d'une technologie ONTAP, qui inclut juste une couche supplémentaire de mise en miroir synchrone des données.</block>
  <block id="75c677fa68f5d15c17efbf6fd1fe1765" category="paragraph">Un ensemble de contrôleurs ONTAP gérant les données SyncMirror est appelé configuration NetApp MetroCluster. L'objectif principal de MetroCluster est de fournir un accès haute disponibilité aux données en miroir synchrones dans de nombreux scénarios de défaillance courants et de reprise après incident.</block>
  <block id="af845652f0234e1f71bc37e241ab63dc" category="paragraph">Les valeurs clés de la protection des données avec MetroCluster et SyncMirror sont les suivantes :</block>
  <block id="9ab80c5e33e343c3415c21be433c4447" category="list-text">Dans les opérations normales, SyncMirror fournit une mise en miroir synchrone garantie entre plusieurs sites. Une opération d'écriture n'est pas validée tant qu'elle n'est pas présente sur un support non volatile des deux sites.</block>
  <block id="680ccf94624c9f922ed236c8cc0c1af2" category="list-text">En cas de défaillance de la connectivité entre les sites, SyncMirror passe automatiquement en mode asynchrone pour que le site principal assure le service de données jusqu'à ce que la connectivité soit rétablie. Une fois restaurée, elle permet une resynchronisation rapide en mettant efficacement à jour les modifications qui se sont accumulées sur le site primaire. Une réinitialisation complète n'est pas nécessaire.</block>
  <block id="c18ec55908c635b68abe8c6edbf6476e" category="paragraph">SnapMirror est également entièrement compatible avec les systèmes basés sur SyncMirror. Par exemple, une base de données primaire peut s'exécuter sur un cluster MetroCluster réparti sur deux sites géographiques. Cette base de données peut également répliquer les sauvegardes sur un troisième site en tant qu'archives à long terme ou pour créer des clones dans un environnement DevOps.</block>
  <block id="3a8111f0b903472ec78531619bf984f6" category="paragraph">Les procédures de réplication pour une base de données Oracle sont essentiellement les mêmes que pour les procédures de sauvegarde. La principale exigence est que les snapshots qui constituent une sauvegarde récupérable doivent être répliqués sur le système de stockage distant.</block>
  <block id="c62b3abab4fdbaf8f0a84e8c3559b5fd" category="paragraph">Comme indiqué précédemment dans la documentation sur la protection des données locales, une sauvegarde récupérable peut être créée à l'aide du processus de sauvegarde à chaud ou à l'aide de sauvegardes optimisées pour les snapshots.</block>
  <block id="3d8f8c6a5c90bcd85a22fbd17390a864" category="inline-link-macro">Disposition des données</block>
  <block id="f3f227cc5c07a040d61c36679053a58a" category="paragraph">Si les fichiers de données sont encapsulés dans des volumes dédiés, la question suivante est de savoir comment gérer les journaux de reprise, les journaux d'archivage et les fichiers de contrôle. La méthode la plus simple consiste à placer tous ces types de données dans un seul volume. L'avantage est que les journaux de reprise répliqués, les journaux d'archivage et les fichiers de contrôle sont parfaitement synchronisés. Il n'est pas nécessaire d'effectuer une restauration incomplète ou d'utiliser un fichier de contrôle de sauvegarde, bien qu'il soit également souhaitable de créer un script de fichiers de contrôle de sauvegarde pour d'autres scénarios de récupération potentiels.</block>
  <block id="927992cbeccc8211e382c97e81514ef9" category="section-title">Disposition à deux volumes</block>
  <block id="fe1cf96940a710dc95fd30bbb7533b52" category="paragraph">La disposition la plus simple est illustrée dans la figure suivante.</block>
  <block id="57f1db4bdf2ce49a98f375d8393f02bf" category="paragraph">C'est l'approche la plus courante. Du point de vue de l'administrateur de bases de données, il peut sembler inhabituel de colocaliser toutes les copies des journaux de reprise et d'archivage sur le même volume. Toutefois, la séparation n'offre pas une protection supplémentaire importante si les fichiers et les LUN se trouvent toujours sur le même jeu de disques sous-jacent.</block>
  <block id="bc46e4831ef5654d084e456c4c544a42" category="section-title">Disposition à trois volumes</block>
  <block id="f6e969769d9d166122489505d676769b" category="paragraph">Il peut arriver qu'une séparation des journaux de reprise soit nécessaire en raison de problèmes de protection des données ou de la nécessité de distribuer les E/S des journaux de reprise entre les contrôleurs. Si c'est le cas, la disposition à trois volumes décrite dans la figure ci-dessous est utilisée pour la réplication, tout en évitant toute nécessité d'effectuer une restauration incomplète ou de s'appuyer sur des fichiers de contrôle de sauvegarde.</block>
  <block id="4957c2feaa2cb72d80a0ab65228ad43f" category="paragraph">Cela permet d'entrelacer les journaux de reprise et les fichiers de contrôle sur des ensembles indépendants de piles de disques et de contrôleurs de la source. Toutefois, les journaux d'archivage et un ensemble de fichiers de contrôle et de fichiers de reprise peuvent toujours être répliqués dans un état synchronisé avec les journaux d'archivage.</block>
  <block id="39128da64bc55500b4b11391aa54a011" category="paragraph">Dans ce modèle, le volume Redo Log B n'est pas répliqué.</block>
  <block id="c0ce858e99375deac8274c96b7e5d0ee" category="section-title">Procédure de reprise d'activité : sauvegardes à chaud</block>
  <block id="6993729228512b7e23e3ff3ec9099f33" category="paragraph">Pour effectuer une reprise sur incident à l'aide de sauvegardes à chaud, utilisez la procédure de base suivante :</block>
  <block id="ee68e5b99222bbc29a480fcb0d1d6ee2" category="section-title">Prérequis</block>
  <block id="41bde9c586a860264c425700c48bd375" category="list-text">Les binaires Oracle sont installés sur le serveur de reprise après incident.</block>
  <block id="cebf7cec81152da2cadffd580d81937f" category="list-text">Les instances de base de données sont répertoriées dans le<block ref="2c0b0433aa1c96a2be6f40d9e71bc6af" prefix=" " category="inline-code"></block>.</block>
  <block id="17f8e5eda67237f2ca94c7dcce3e4022" category="list-text">Le<block ref="76a2173be6393254e72ffa4d6df1030a" prefix=" " category="inline-code"></block> et<block ref="6b2f852f7f63f2e5d4be597bbca97bb6" prefix=" " category="inline-code"></block> ou<block ref="1737629d60b511cf45957529a8f046e2" prefix=" " category="inline-code"></block> pour l'instance doit être dans le<block ref="45c7302d9c2e8745b3a2bff0f992b6df" prefix=" " category="inline-code"></block> répertoire. .</block>
  <block id="645a84975202e30700b572b49a5ee29d" category="section-title">Reprise après incident</block>
  <block id="25d18766964d7515e1f5acd893094f6e" category="list-text">Brisez les miroirs des fichiers de données et du volume de journaux commun.</block>
  <block id="8fc655e4752d521563db3bfa138ba62e" category="list-text">Restaurez le ou les volumes de fichiers de données sur le snapshot de sauvegarde à chaud le plus récent des fichiers de données.</block>
  <block id="68a9c75816a16f6d4f7572fe287961bf" category="list-text">Si SAN est utilisé, activez les groupes de volumes et/ou montez les systèmes de fichiers.</block>
  <block id="312007510a0f0dc7878d4ed6a7a01554" category="list-text">Réexécutez les journaux d'archivage au point souhaité.</block>
  <block id="e54b793d8bfa83bbb1bd965992c3474e" category="list-text">Relire les journaux de reprise en cours si vous souhaitez effectuer une restauration complète.</block>
  <block id="72e5734d53581f86093de5c97d8a3a24" category="paragraph">NFS simplifie considérablement la procédure. En effet, les systèmes de fichiers NFS pour les fichiers de données et les fichiers journaux peuvent à tout moment être montés sur le serveur de reprise après incident. Il devient en lecture/écriture lorsque les miroirs sont cassés.</block>
  <block id="de4735bc5bbfdcae3d690313c739ad67" category="section-title">Procédure de reprise après incident : sauvegardes optimisées pour les snapshots</block>
  <block id="6b2b8ef11e5ded8a083372ba49d488d2" category="paragraph">La restauration à partir de sauvegardes optimisées pour les snapshots est presque identique à la procédure de restauration à chaud avec les modifications suivantes :</block>
  <block id="af1e49e7bc2b25ce36bd93df09433fb4" category="list-text">Restaurez le(s) volume(s) de fichiers de données sur un snapshot créé avant le réplica actuel du volume de journaux.</block>
  <block id="5e09669c98226c5d3a748f7e0f0333ad" category="paragraph">Ces différences simplifient la procédure globale de restauration, car il n'est pas nécessaire de s'assurer qu'un snapshot a été correctement créé sur la source pendant que la base de données était en mode de sauvegarde à chaud. La procédure de reprise d'activité est basée sur l'horodatage des snapshots sur le site de reprise d'activité. L'état de la base de données au moment de la création des snapshots n'est pas important.</block>
  <block id="81d6beef7eaf28bbce692d4b59888f3e" category="section-title">Reprise d'activité avec des snapshots de sauvegarde à chaud</block>
  <block id="dc711b77f0d6a9c9ccf88b424509440a" category="paragraph">Voici un exemple de stratégie de reprise d'activité basée sur la réplication de snapshots de sauvegarde à chaud. Il sert également d'exemple de stratégie de sauvegarde locale simple et évolutive.</block>
  <block id="edaef18e1c956b9284405fd664c4ca4a" category="paragraph">La base de données exemple se trouve sur une architecture de base à deux volumes.<block ref="f006bf17b06c884c47190c4225d3215a" prefix=" " category="inline-code"></block> contient les fichiers de données et<block ref="894db1fc1592356880976f1b92c3e6a2" prefix=" " category="inline-code"></block> est utilisé pour les journaux de reprise, les journaux d'archivage et les fichiers de contrôle combinés.</block>
  <block id="fc0e7b6cd7cd15929987b1429d1c3a7e" category="paragraph">Deux calendriers sont requis : un pour les sauvegardes de fichiers de données nocturnes et un pour les sauvegardes de fichiers journaux. Ils sont appelés minuit et 15 minutes, respectivement.</block>
  <block id="44c0956347a70c78d2124c1041321049" category="paragraph">Ces planifications sont ensuite utilisées au sein des politiques de snapshots<block ref="44dc83cda2d6b3ce99cc25803e824061" prefix=" " category="inline-code"></block> et<block ref="9b055600529d69c4ae0d2a9408dc7aa3" prefix=" " category="inline-code"></block>, comme illustré ci-dessous :</block>
  <block id="180e86b8e3c5049779c98c2c1006bb15" category="paragraph">Enfin, ces politiques de snapshots sont appliquées aux volumes.</block>
  <block id="2887f2c14c7efbc97d53ac2f914c5657" category="paragraph">Ceci définit la planification de sauvegarde des volumes. Des snapshots des fichiers de données sont créés à minuit et conservés pendant 60 jours. Le volume du journal contient 72 instantanés créés toutes les 15 minutes, ce qui représente jusqu'à 18 heures de couverture.</block>
  <block id="e1e5ef0e7100311d950b4ffebe040670" category="paragraph">Ensuite, assurez-vous que la base de données est en mode de sauvegarde à chaud lors de la création d'un Snapshot de fichier de données. Ceci s'effectue avec un petit script qui accepte certains arguments de base qui démarrent et arrêtent le mode de sauvegarde sur le SID spécifié.</block>
  <block id="683cdd7abd993faf3ace355cd6870b6f" category="paragraph">Cette étape permet de s'assurer que la base de données est en mode de sauvegarde à chaud pendant une fenêtre de quatre minutes entourant le snapshot de minuit.</block>
  <block id="ccff7eb3ad0059a184886709c87f4889" category="paragraph">La réplication vers le site de reprise sur incident est configurée comme suit :</block>
  <block id="42d3752a745fb0cdae528f6cc425b569" category="paragraph">La destination du volume du journal est mise à jour toutes les 15 minutes. Le RPO est ainsi d'environ 15 minutes. L'intervalle de mise à jour précis varie légèrement en fonction du volume total de données à transférer pendant la mise à jour.</block>
  <block id="e272424001d72919ad498e0e9d3c2cc4" category="paragraph">La destination du volume de fichiers de données est mise à jour toutes les six heures. Cela n'affecte pas le RPO ni le RTO. Si une reprise sur incident est nécessaire, l'une des premières étapes consiste à restaurer le volume du fichier de données vers un Snapshot de sauvegarde à chaud. L'objectif de l'intervalle de mise à jour plus fréquent est de lisser la vitesse de transfert de ce volume. Si la mise à jour est planifiée une fois par jour, toutes les modifications accumulées au cours de la journée doivent être transférées en une seule fois. Avec des mises à jour plus fréquentes, les modifications sont répliquées plus progressivement tout au long de la journée.</block>
  <block id="ce176ff569d716c1fa73d0754aba684b" category="paragraph">En cas d'incident, la première étape consiste à briser les miroirs des deux volumes :</block>
  <block id="4b9cdb6e2096c0828aeccd2ee5eecf42" category="paragraph">Les répliques sont maintenant en lecture-écriture. L'étape suivante consiste à vérifier l'horodatage du volume du journal.</block>
  <block id="b4d461e48f5be5d08f677045d11e8200" category="paragraph">La copie la plus récente du volume de log est le 14 mars à 13:30:00.</block>
  <block id="96f75a4b63f4377efdf64d571d71caec" category="paragraph">Ensuite, identifiez le snapshot de sauvegarde à chaud créé juste avant l'état du volume de journal. Ceci est nécessaire car le processus de relecture des journaux nécessite la création de tous les journaux d'archivage en mode de sauvegarde à chaud. La réplique du volume du journal doit donc être plus ancienne que les images de sauvegarde à chaud ou ne doit pas contenir les journaux requis.</block>
  <block id="d358e4eb10a2f4e0b591e16941d7782c" category="paragraph">Le snapshot le plus récent est<block ref="c001e27abf0e66d13790bb8a7e00da54" prefix=" " category="inline-code"></block>. Il s'agit de l'image de sauvegarde à chaud la plus récente des fichiers de données. Cette image est ensuite restaurée comme suit :</block>
  <block id="d2037035a976c9be71cf6f372300c8c3" category="paragraph">À ce stade, la base de données est prête à être récupérée. S'il s'agissait d'un environnement SAN, l'étape suivante inclurait l'activation des groupes de volumes et le montage de systèmes de fichiers, un processus facilement automatisé. Dans la mesure où cet exemple utilise NFS, les systèmes de fichiers sont déjà montés et sont devenus des opérations de lecture-écriture sans avoir à monter ou activer les miroirs au moment où ils ont été rompus.</block>
  <block id="2edce22eade45b42bc6b2665057fa082" category="paragraph">La base de données peut désormais être restaurée au point dans le temps souhaité ou entièrement récupérée grâce à la copie des journaux de reprise répliqués. Cet exemple illustre la valeur du journal d'archives, du fichier de contrôle et du volume redo log combinés. Le processus de restauration est beaucoup plus simple, car il n'est pas nécessaire de se fier aux fichiers de contrôle de sauvegarde ou de réinitialiser les fichiers journaux.</block>
  <block id="51f74a82c7125b3b288755b6668091b1" category="section-title">Reprise d'activité avec sauvegardes optimisées pour les snapshots</block>
  <block id="3680a4757ddad43934237ab6a0ca955c" category="paragraph">La procédure de reprise sur incident utilisant des sauvegardes optimisées pour les snapshots est presque identique à la procédure de reprise sur incident de sauvegarde à chaud. Comme pour la procédure Snapshot de sauvegarde à chaud, il s'agit essentiellement d'une extension d'architecture de sauvegarde locale dans laquelle les sauvegardes sont répliquées pour être utilisées dans la reprise après incident. L'exemple suivant illustre la configuration détaillée et la procédure de restauration. Cet exemple met également en évidence les principales différences entre les sauvegardes à chaud et les sauvegardes optimisées pour les snapshots.</block>
  <block id="330dadae5e2585726f41ed1f90e88f9f" category="paragraph">La base de données exemple se trouve sur une architecture de base à deux volumes.<block ref="f006bf17b06c884c47190c4225d3215a" prefix=" " category="inline-code"></block> contient les fichiers de données, et<block ref="894db1fc1592356880976f1b92c3e6a2" prefix=" " category="inline-code"></block> est utilisé pour les journaux de reprise, les journaux d'archivage et les fichiers de contrôle combinés.</block>
  <block id="1669f47e046ce7e069e9d143f42e025d" category="paragraph">Deux calendriers sont requis : un pour les sauvegardes de fichiers de données nocturnes et un pour les sauvegardes de fichiers journaux. Ils sont appelés minuit et 15 minutes, respectivement.</block>
  <block id="ef4adcab3e9bd572d0670f9f2073c311" category="paragraph">Ceci contrôle le programme de sauvegarde ultime des volumes. Les snapshots sont créés à minuit et conservés pendant 60 jours. Le volume du journal contient 72 instantanés créés toutes les 15 minutes, ce qui représente jusqu'à 18 heures de couverture.</block>
  <block id="f9d5149b630a43ff5996adc26c6e1f08" category="paragraph">La destination du volume du journal est mise à jour toutes les 15 minutes. Le RPO est ainsi d'environ 15 minutes, l'intervalle de mise à jour précis variant légèrement selon le volume total de données à transférer pendant la mise à jour.</block>
  <block id="992398ebd9e9f825f0aa4415519abdba" category="paragraph">La destination du volume de fichiers de données est mise à jour toutes les 6 heures. Cela n'affecte pas le RPO ni le RTO. Si une reprise sur incident est nécessaire, vous devez d'abord restaurer le volume du fichier de données sur un snapshot de sauvegarde à chaud. L'objectif de l'intervalle de mise à jour plus fréquent est de lisser la vitesse de transfert de ce volume. Si la mise à jour a été planifiée une fois par jour, toutes les modifications accumulées au cours de la journée doivent être transférées en une seule fois. Avec des mises à jour plus fréquentes, les modifications sont répliquées plus progressivement tout au long de la journée.</block>
  <block id="9e85b8590ac2f9ff5ebc8d1def51ae82" category="paragraph">En cas d'incident, la première étape consiste à briser les miroirs de tous les volumes :</block>
  <block id="fd2834dcadb39f00eb897fdcdc07a03d" category="paragraph">La copie la plus récente du volume de log est le 14 mars à 13:30. Ensuite, identifiez le snapshot du fichier de données créé immédiatement avant l'état du volume de journaux. Ceci est nécessaire car le processus de relecture des journaux requiert tous les journaux d'archivage juste avant le snapshot et jusqu'au point de restauration souhaité.</block>
  <block id="810e47566b9cd5aa3b28e6514ec95735" category="paragraph">Le snapshot le plus récent est<block ref="c001e27abf0e66d13790bb8a7e00da54" prefix=" " category="inline-code"></block>. Restaurer cet instantané.</block>
  <block id="87d83a0406ac6622efcdf91c42784ecd" category="paragraph">La base de données est maintenant prête à être récupérée. S'il s'agissait d'un environnement SAN, vous activeriez alors des groupes de volumes et monterait des systèmes de fichiers, ce qui facilite l'automatisation. Cependant, cet exemple utilise NFS, de sorte que les systèmes de fichiers sont déjà montés et sont devenus lecture-écriture sans avoir besoin de monter ou d'activer le moment où les miroirs ont été rompus.</block>
  <block id="7a2e97f17454be76b7e522ce612ff961" category="paragraph">La base de données peut désormais être restaurée au point dans le temps souhaité ou entièrement récupérée grâce à la copie des journaux de reprise répliqués. Cet exemple illustre la valeur du journal d'archives, du fichier de contrôle et du volume redo log combinés. Le processus de restauration est beaucoup plus simple, car il n'est pas nécessaire de se fier aux fichiers de contrôle de sauvegarde ou de réinitialiser les fichiers journaux.</block>
  <block id="5eda890cc07e4b7cd409730d8af8ddc3" category="paragraph">La réplication de groupe de cohérence peut être aussi simple que la planification de la réplication d'un volume unique via SnapMirror. Notamment les fichiers de données, les fichiers de contrôle, les journaux d'archivage et les journaux de reprise. Chaque mise à jour SnapMirror produit une nouvelle copie cohérente de la base de données sur le site de destination, prête pour l'activation en brisant le miroir.</block>
  <block id="89cb1432594ce7c25dadf229401874e7" category="paragraph">Si une base de données doit couvrir plusieurs volumes, un Snapshot de groupe de cohérence (cg-snapshot) est nécessaire.</block>
  <block id="f96b125d1bacc785389957041be148e9" category="paragraph">Autre avantage de cette stratégie lorsqu'elle est utilisée avec SnapMirror en mode de réplication de niveau bloc : la réplication complète de tous les snapshots sur le système de stockage source. La gamme complète de sauvegardes est répliquée en plus de la copie de reprise après incident.</block>
  <block id="77fda44088666155052f9d4224878cbc" category="summary">Tiering des journaux d'archivage Oracle</block>
  <block id="8625af69ad0b5f76799d87df777e3c86" category="paragraph">L'utilisation la plus importante pour FabricPool est peut-être l'amélioration de l'efficacité des données inactives connues, telles que les journaux de transactions de base de données.</block>
  <block id="a98d546484d238b37b7e2584ae8d399d" category="summary">Tiering de sauvegarde Oracle</block>
  <block id="9f409a250e4be99904c9e90259cb747d" category="paragraph">Les sauvegardes d'applications traditionnelles incluent des produits tels qu'Oracle Recovery Manager, qui créent des sauvegardes basées sur des fichiers en dehors de l'emplacement de la base de données d'origine.</block>
  <block id="4627801bdbb24a1991e64f30a2d80cb1" category="paragraph">Quatre règles sont disponibles dans ONTAP, qui contrôlent la façon dont les données Oracle du niveau de performance deviennent candidates à la relocalisation vers le niveau de capacité.</block>
  <block id="2eea2725f31529888b5e57b36492819f" category="paragraph">Bien que le Tiering FabricPool fonctionne au niveau des blocs, il peut dans certains cas servir à fournir un Tiering au niveau des fichiers.</block>
  <block id="f935a501eae76f9c13d430bc3879cd0d" category="paragraph">Comme FabricPool fonctionne au niveau des blocs, les fichiers susceptibles d'être modifiés peuvent être partiellement hiérarchisés vers un stockage objet tout en restant partiellement sur le Tier de performance.</block>
  <block id="cc4e17c26faf6b70b383529b6215ba0f" category="doc">Interruptions d'accès au magasin d'objets</block>
  <block id="ec35a176f3e7c086273baee0c7f374d5" category="paragraph">Pour comprendre l'impact du Tiering FabricPool sur Oracle et d'autres bases de données, il est nécessaire de connaître l'architecture FabricPool de bas niveau.</block>
  <block id="6edf1821ddc55278229c2156f42905f0" category="paragraph">Les règles de Tiering contrôlent quels blocs de base de données Oracle sont hiérarchisés du niveau de performance au niveau de capacité. Les règles de récupération contrôlent ce qui se passe lorsqu'un bloc qui a été hiérarchisé est lu.</block>
  <block id="d01cbb2be77343ccdb1d3372c4b9891e" category="summary">Instructions relatives au dimensionnement des LUN de la base de données Oracle et au nombre de LUN</block>
  <block id="51f96d1f8b50084e3a2ddc21ceef8b2f" category="paragraph">Il est essentiel de sélectionner la taille de LUN optimale et le nombre de LUN à utiliser pour optimiser les performances et la gestion des bases de données Oracle.</block>
  <block id="3d1bd23e74923cdc48fe992d0687809f" category="summary">Bases de données Oracle et locations et verrouillages NFS</block>
  <block id="cec6f8a988408ba212798e1cc32658c7" category="paragraph">NFSv3 est sans état. Cela signifie que le serveur NFS (ONTAP) ne suit pas les systèmes de fichiers montés, par qui ou quels verrous sont réellement en place.</block>
  <block id="7c96331bd03e63c4eb3505c526b42244" category="paragraph">ONTAP dispose de certaines fonctionnalités qui enregistreront les tentatives de montage. Vous savez donc quels clients accèdent aux données et il se peut que des verrous consultatifs soient présents, mais les informations ne sont pas 100 % complètes. Elle ne peut pas être terminée, car le suivi de l'état du client NFS ne fait pas partie de la norme NFSv3.</block>
  <block id="20733ad7135aa0ede95fd8637fe05cf6" category="section-title">État NFSv4</block>
  <block id="3f7c11f662fc6e07a91179fdf2322ef5" category="paragraph">En revanche, NFSv4 est avec état. Le serveur NFSv4 suit les clients qui utilisent les systèmes de fichiers, les fichiers existants, les fichiers et/ou les régions de fichiers verrouillés, etc Cela signifie qu'une communication régulière entre un serveur NFSv4 doit être établie pour maintenir les données d'état à jour.</block>
  <block id="6f7e4a1e570f45fa3db0b8a0ed80a38f" category="paragraph">Les États les plus importants gérés par le serveur NFS sont les verrous NFSv4 et les locations NFSv4, qui sont très étroitement liés. Vous devez comprendre comment chacun fonctionne par lui-même, et comment ils se rapportent les uns aux autres.</block>
  <block id="0d55fd4062f29237d0fb3b7f666fb8eb" category="section-title">Verrous NFSv4</block>
  <block id="bf4139ff42e411ae5483e062387b3f70" category="paragraph">Avec NFSv3, les verrous sont consultatifs. Un client NFS peut toujours modifier ou supprimer un fichier « verrouillé ». Un verrou NFSv3 n'expire pas de lui-même, il doit être supprimé. Cela crée des problèmes. Par exemple, si une application en cluster crée des verrous NFSv3 et que l'un des nœuds tombe en panne, que faire ? Vous pouvez coder l'application sur les nœuds survivants pour supprimer les verrous, mais comment savoir que c'est sûr ? Le nœud « en panne » est peut-être opérationnel, mais ne communique pas avec le reste du cluster ?</block>
  <block id="11d1c33ac6b190a233c00cdbdd6a355b" category="paragraph">Avec NFSv4, les verrous ont une durée limitée. Tant que le client tenant les Locks continue à s'archiver avec le serveur NFSv4, aucun autre client n'est autorisé à acquérir ces Locks. Si un client ne parvient pas à s'archiver avec NFSv4, les verrous seront éventuellement révoqués par le serveur et d'autres clients pourront demander et obtenir des verrous.</block>
  <block id="c17985911e0182dc5e96c4d60aadf139" category="section-title">Locations NFSv4</block>
  <block id="596bcfef3aaccfe299bb45a969afcaf0" category="paragraph">Les verrous NFSv4 sont associés à un bail NFSv4. Lorsqu'un client NFSv4 établit une connexion avec un serveur NFSv4, il obtient un bail. Si le client obtient un verrou (il existe plusieurs types de verrous), le verrou est associé au bail.</block>
  <block id="b5248856b1835e14738aa32e053e30e0" category="paragraph">Ce bail a un délai défini. Par défaut, ONTAP définit la valeur de temporisation sur 30 secondes :</block>
  <block id="7e2a66190f452806ac1183721a43eaa1" category="paragraph">Cela signifie qu'un client NFSv4 doit vérifier avec le serveur NFSv4 toutes les 30 secondes pour renouveler ses baux.</block>
  <block id="809c552ae0a4d377e87f495b4e3ac62b" category="paragraph">Le bail est automatiquement renouvelé par n'importe quelle activité. Ainsi, si le client effectue des travaux, il n'est pas nécessaire d'effectuer des opérations supplémentaires. Si une application devient silencieuse et ne fait pas de véritable travail, elle devra effectuer une sorte d'opération de maintien en vie (appelée SÉQUENCE). Il s'agit essentiellement de dire « Je suis toujours là, veuillez actualiser mes contrats de location ».</block>
  <block id="70cb78bb7e91dcafab559f9b72e40bb6" category="paragraph">NFSv3 est sans état. Il ne s'attend pas à ce que les clients communiquent. NFSv4 est avec état et une fois la période de location expirée, le bail expire, et les verrous sont révoqués et les fichiers verrouillés sont mis à disposition des autres clients.</block>
  <block id="2ee5d81cfa6306ae71ce534ed9b31431" category="paragraph">Avec NFSv3, vous pouvez déplacer les câbles réseau, redémarrer les switchs réseau, modifier la configuration et être sûr qu'aucun problème ne se produirait. En général, les applications attendront patiemment le bon fonctionnement de la connexion réseau.</block>
  <block id="8900ff182e4197f8eb2acd7d2b7fd902" category="paragraph">Avec NFSv4, vous disposez de 30 secondes (sauf si vous avez augmenté la valeur de ce paramètre dans ONTAP) pour terminer votre travail. Si vous dépassez cette limite, vos contrats de location sont échus. Normalement, cela provoque des pannes d'application.</block>
  <block id="ffa8c7744b3e2d43b18c67aec0fe7743" category="paragraph">Par exemple, si vous disposez d'une base de données Oracle et que vous rencontrez une perte de connectivité réseau (parfois appelée « partition réseau ») qui dépasse le délai d'expiration du bail, vous plantez la base de données.</block>
  <block id="33b9897348039594b4b17bf1e1629c74" category="paragraph">Voici un exemple de ce qui se passe dans le journal des alertes Oracle si cela se produit :</block>
  <block id="85608585bf8e790a579c49ba9af705c6" category="paragraph">Si vous examinez les syslog, vous devriez voir plusieurs de ces erreurs :</block>
  <block id="e19b338de53dada4cf4da3837aaba76d" category="paragraph">Les messages du journal sont généralement le premier signe d'un problème, autre que le blocage de l'application. En général, vous ne voyez rien pendant la panne réseau, car les processus et le système d'exploitation lui-même sont bloqués et tentent d'accéder au système de fichiers NFS.</block>
  <block id="7a3c8c17a9dd10fa565f79e0ebb5bba7" category="paragraph">Les erreurs apparaissent une fois que le réseau est de nouveau opérationnel. Dans l'exemple ci-dessus, une fois la connectivité rétablie, le système d'exploitation a tenté de réacquérir les verrous, mais il était trop tard. Le bail avait expiré et les serrures ont été retirées. Cela entraîne une erreur qui se propage jusqu'à la couche Oracle et provoque le message dans le journal des alertes. Vous pouvez voir des variations sur ces modèles en fonction de la version et de la configuration de la base de données.</block>
  <block id="4bec5e793e34a5819aefb68e4f65db26" category="paragraph">En résumé, NFSv3 tolère l'interruption du réseau, mais NFSv4 est plus sensible et impose une période de location définie.</block>
  <block id="069de2d717910b2677190b9a9b5ed1cf" category="paragraph">Que se passe-t-il si un délai de 30 secondes n'est pas acceptable ? Que se passe-t-il si vous gérez un réseau changeant de façon dynamique où les commutateurs sont redémarrés ou les câbles sont déplacés et que le résultat est une interruption occasionnelle du réseau ? Vous pouvez choisir de prolonger la période de location, mais pour savoir si vous voulez y parvenir, vous devez expliquer les périodes de grâce NFSv4.</block>
  <block id="4b84416146795544deb5c9de89187f91" category="section-title">Périodes de grâce NFSv4</block>
  <block id="7d98e091c5f7be92cd5fb85b985d8d20" category="paragraph">Lorsqu'un serveur NFSv3 est redémarré, il est prêt à transmettre les E/S presque instantanément. Il ne maintenait aucune sorte d'état concernant les clients. Le résultat est qu'une opération de basculement ONTAP semble souvent proche de l'instantané. Dès qu'un contrôleur est prêt à commencer à transmettre des données, il envoie un ARP au réseau qui signale le changement de topologie. En règle générale, les clients le détectent presque instantanément et le flux des données reprend.</block>
  <block id="173d4fd05086441236dbee4710639d10" category="paragraph">NFSv4, cependant, fera une courte pause. Cela fait partie du fonctionnement de NFSv4.</block>
  <block id="21483115213b27583a07dc2ca994671c" category="paragraph">Les serveurs NFSv4 doivent suivre les baux, les verrous et les utilisateurs des données. Si un serveur NFS fonctionne de manière incohérente et redémarre, ou perd de l'alimentation pendant un moment, ou est redémarré pendant l'activité de maintenance, le résultat est le bail/verrouillage et d'autres informations client sont perdues. Le serveur doit déterminer quel client utilise les données avant de reprendre les opérations. C'est là que intervient le délai de grâce.</block>
  <block id="09b6f386094bd895d3c9694f28bfdf65" category="paragraph">Si vous mettez soudainement votre serveur NFSv4 hors/sous tension. Lorsqu'il est rétabli, les clients qui tentent de reprendre l'E/S reçoivent une réponse qui dit essentiellement « J'ai perdu les informations de location/verrouillage. Voulez-vous réenregistrer vos verrous ? » C'est le début de la période de grâce. La valeur par défaut est 45 secondes sur ONTAP :</block>
  <block id="e4f8aa90af36d76254e2f02e56232aed" category="paragraph">Par conséquent, après un redémarrage, un contrôleur met en pause les E/S tandis que tous les clients récupèrent leurs baux et verrous. Une fois le délai de grâce terminé, le serveur reprend les opérations d'E/S.</block>
  <block id="bb2b26fdcb4e947cda6f8e38724ecfc9" category="section-title">Délais de location par rapport aux délais de grâce</block>
  <block id="c4fb6f7d31d205bc07dbff47d0ae4bb3" category="summary">NFS direct Oracle</block>
  <block id="1bd6ec1185ba67395dc6f9cd2b458ec8" category="paragraph">Les bases de données Oracle peuvent utiliser NFS de deux manières.</block>
  <block id="96997ca5c577dd19a3ba5f7ff771f27a" category="paragraph">Tout d'abord, il peut utiliser un système de fichiers monté à l'aide du client NFS natif qui fait partie du système d'exploitation. Il s'agit parfois de kernel NFS ou KNFS. Le système de fichiers NFS est monté et utilisé par la base de données Oracle exactement comme toute autre application utiliserait un système de fichiers NFS.</block>
  <block id="95c17c63df7ceea39a175b1d96955bb7" category="paragraph">La deuxième méthode est Oracle Direct NFS (dNFS). Il s'agit d'une implémentation de la norme NFS dans le logiciel de base de données Oracle. Elle ne modifie pas la façon dont les bases de données Oracle sont configurées ou gérées par l'administrateur de base de données. Tant que les paramètres du système de stockage lui-même sont corrects, l'utilisation de dNFS doit être transparente pour l'équipe DBA et les utilisateurs finaux.</block>
  <block id="43539d2fca21e5b644484efb94614a7b" category="paragraph">Les systèmes de fichiers NFS habituels sont toujours montés sur une base de données avec la fonction dNFS activée. Une fois la base de données ouverte, la base de données Oracle ouvre un ensemble de sessions TCP/IP et effectue directement des opérations NFS.</block>
  <block id="26e7ebad3936387b4b3f7c4f5688ef27" category="section-title">NFS direct</block>
  <block id="6d431a52c8a41a7c2335f98e2ae8c454" category="paragraph">La valeur principale de Direct NFS d'Oracle est de contourner le client NFS hôte et d'effectuer des opérations de fichiers NFS directement sur un serveur NFS. Pour l'activer, il suffit de modifier la bibliothèque Oracle Disk Manager (ODM). Vous trouverez des instructions sur ce processus dans la documentation Oracle.</block>
  <block id="8401d91735209aeccbe56f33b4e2db73" category="paragraph">L'utilisation de dNFS entraîne une amélioration significative des performances d'E/S et réduit la charge sur l'hôte et le système de stockage, car les E/S sont effectuées de la manière la plus efficace possible.</block>
  <block id="b0dedecb00787180a9e0c657cfb278c9" category="paragraph">En outre, Oracle dNFS inclut une *option* pour les chemins d'accès multiples et la tolérance aux pannes de l'interface réseau. Par exemple, il est possible de lier deux interfaces de 10 Gbits pour offrir 20 Go de bande passante. En cas de défaillance d'une interface, les E/S sont relancées sur l'autre interface. L'opération globale est très similaire aux chemins d'accès multiples FC. Les chemins d'accès multiples étaient courants il y a plusieurs années, alors que l'ethernet 1 Gbit était la norme la plus courante. Une carte réseau 10 Go suffit pour la plupart des charges de travail Oracle, mais si un nombre supérieur de cartes réseau 10 Go sont requises, elles peuvent être reliées.</block>
  <block id="11e50b3c816105439151db3a3b4fdda3" category="paragraph">Lorsque dNFS est utilisé, il est essentiel que tous les correctifs décrits dans Oracle Doc 1495104.1 soient installés. Si un correctif ne peut pas être installé, l'environnement doit être évalué pour s'assurer que les bugs décrits dans ce document ne causent pas de problèmes. Dans certains cas, une incapacité à installer les correctifs requis empêche l'utilisation de dNFS.</block>
  <block id="8f98002fee392ad6151679875de1a7cc" category="paragraph">N'utilisez pas dNFS avec tout type de résolution de noms round-Robin, y compris DNS, DDNS, NIS ou toute autre méthode. Cela inclut la fonction d'équilibrage de la charge DNS disponible dans ONTAP. Lorsqu'une base de données Oracle utilisant dNFS résout un nom d'hôte en adresse IP, elle ne doit pas être modifiée lors des recherches ultérieures. Cela peut entraîner des pannes de la base de données Oracle et une corruption potentielle des données.</block>
  <block id="e80ad3efb180dc2d016b27506b7b24ce" category="section-title">Accès direct au NFS et au système de fichiers hôte</block>
  <block id="4c38a8c0a49e721bf2a378d0b4fb2010" category="paragraph">L'utilisation de dNFS peut parfois causer des problèmes pour les applications ou les activités des utilisateurs qui dépendent des systèmes de fichiers visibles montés sur l'hôte car le client dNFS accède au système de fichiers hors bande à partir du système d'exploitation hôte. Le client dNFS peut créer, supprimer et modifier des fichiers sans connaître le système d'exploitation.</block>
  <block id="c03389fdb295f2acb079603123e6d0e3" category="paragraph">Lorsque les options de montage des bases de données à instance unique sont utilisées, elles permettent la mise en cache des attributs de fichiers et de répertoires, ce qui signifie également que le contenu d'un répertoire est mis en cache. Par conséquent, dNFS peut créer un fichier, et il y a un court délai avant que le système d'exploitation ne relise le contenu du répertoire et que le fichier devienne visible pour l'utilisateur. Ce n'est généralement pas un problème, mais, dans de rares cas, des utilitaires tels que SAP BR*Tools peuvent présenter des problèmes. Si cela se produit, modifiez les options de montage pour utiliser les recommandations pour Oracle RAC. Ce changement entraîne la désactivation de l'ensemble de la mise en cache de l'hôte.</block>
  <block id="a370a203383b565c3fb746c1c2e1a64b" category="paragraph">Ne modifiez les options de montage que si (a) dNFS est utilisé et (b) un problème résulte d'un décalage dans la visibilité des fichiers. Si dNFS n'est pas utilisé, les options de montage Oracle RAC sur une base de données à instance unique entraînent une dégradation des performances.</block>
  <block id="22a7a03175addfd9aa5b1fa2c351e833" category="summary">Configuration NFS pour les bases de données Oracle</block>
  <block id="6cb2edd2369a17890dce007723d98a6f" category="paragraph">NetApp fournit un stockage NFS haute performance depuis plus de 30 ans et son utilisation se développe avec les infrastructures basées sur le cloud en raison de sa simplicité.</block>
  <block id="0f8a941fcc56687ad8e3914162c19a41" category="section-title">Versions NFS</block>
  <block id="d0972be450ccf257fb73d4878bce204e" category="paragraph">Le client NFS du système d'exploitation doit être pris en charge par NetApp.</block>
  <block id="7722a2ae10cef9bccea115dfdfe78a99" category="list-text">NFSv3 est pris en charge avec des systèmes d'exploitation conformes à la norme NFSv3.</block>
  <block id="a3550edc6962850398d217f78cc4ad0d" category="list-text">NFSv3 est pris en charge avec le client Oracle dNFS.</block>
  <block id="89c45ebba54478419aa679a7ece8593d" category="list-text">NFSv4 est pris en charge avec tous les systèmes d'exploitation conformes à la norme NFSv4.</block>
  <block id="471ff51c89daf6e35e8e2b5111039744" category="inline-link-macro">NetApp IMT</block>
  <block id="8594659e8c4292db778973052a30ab86" category="list-text">NFSv4.1 et NFSv4.2 nécessitent une prise en charge spécifique du système d'exploitation. Consulter le <block ref="d98f827de8e80b3365d5f4160c243cdc" category="inline-link-macro-rx"></block> Pour les systèmes d'exploitation pris en charge.</block>
  <block id="d1eb4c2a4d74705a5aa7945f734eff7c" category="list-text">La prise en charge d'Oracle dNFS pour NFSv4.1 requiert Oracle 12.2.0.2 ou version supérieure.</block>
  <block id="d8bacc1a7a9d6baaeb962e367920593b" category="inline-link-macro">Matrice de prise en charge de NetApp</block>
  <block id="f16dcce07ca44aa38c7ebe3016b981b2" category="admonition">Le <block ref="f1e4f72fb4419d4270270c5ed1e0d9f6" category="inline-link-macro-rx"></block> Pour NFSv3 et NFSv4 n'incluent pas de systèmes d'exploitation spécifiques. Tous les systèmes d'exploitation conformes à la RFC sont généralement pris en charge. Lors d'une recherche dans la prise en charge en ligne de IMT pour NFSv3 ou NFSv4, ne sélectionnez pas de système d'exploitation spécifique, car aucune correspondance ne sera affichée. Tous les systèmes d'exploitation sont implicitement pris en charge par la politique générale.</block>
  <block id="26ed9768d6a659a9768842d903d0025f" category="section-title">Tables d'emplacements TCP Linux NFSv3</block>
  <block id="c56ec9836fbbd9c0a426a40fc71c265c" category="paragraph">Les tables d'emplacements TCP sont l'équivalent NFSv3 de la profondeur de file d'attente de l'adaptateur de bus hôte (HBA). Ces tableaux contrôlent le nombre d'opérations NFS qui peuvent être en attente à la fois. La valeur par défaut est généralement 16, un chiffre bien trop faible pour assurer des performances optimales. Le problème inverse se produit sur les noyaux Linux plus récents : la limite de la table des emplacements TCP augmente automatiquement par envoi de demandes, jusqu'à atteindre le niveau de saturation du serveur NFS.</block>
  <block id="5270700baa50d07af667096293a27564" category="paragraph">Pour des performances optimales et pour éviter les problèmes de performances, ajustez les paramètres du noyau qui contrôlent les tables d'emplacements TCP.</block>
  <block id="5b29db1d99e19013580fa375a5f87fa5" category="paragraph">Exécutez le<block ref="1a1e44f7a3390ed4647a7d5b7e8b08ed" prefix=" " category="inline-code"></block> et observez les paramètres suivants :</block>
  <block id="8821adf56df4952370cfaa57ccaac68d" category="paragraph">Tous les systèmes Linux doivent inclure<block ref="c5f48b899461d4c2b9ddc0b24ea87744" prefix=" " category="inline-code"></block>, mais seulement certains incluent<block ref="6f72acaebcb9a0de6696aaf3508a6144" prefix=" " category="inline-code"></block>. Ils doivent tous deux être réglés sur 128.</block>
  <block id="3a954c4e5e8d5ac3af590651efc5a2cb" category="cell">Si vous ne définissez pas ces paramètres, vous risquez d'avoir des effets importants sur les performances. Dans certains cas, les performances sont limitées car le système d'exploitation linux n'émet pas suffisamment d'E/S. Dans d'autres cas, les latences d'E/S augmentent à mesure que le système d'exploitation linux tente d'émettre plus d'E/S que ce qui peut être traité.</block>
  <block id="837f157b2f309f5415420467f7643e3a" category="section-title">ADR et NFS</block>
  <block id="c0e7bb1383be0bf1268d1d70280bef6d" category="paragraph">Certains clients ont signalé des problèmes de performances liés à une quantité excessive d'E/S dans le<block ref="18ca3ed022c239421418de608ceb49c5" prefix=" " category="inline-code"></block> emplacement. Le problème ne se produit généralement pas tant qu'une grande quantité de données de performances ne s'est pas accumulée. La raison de cet excès d'E/S est inconnue, mais ce problème semble provenir des analyses répétées du répertoire cible par les processus Oracle pour détecter les modifications.</block>
  <block id="99be2ae95d50120a7c33c818afda1834" category="paragraph">Dépose du<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> et/ou<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block> Les options de montage permettent la mise en cache du système d'exploitation hôte et réduisent les niveaux d'E/S du stockage.</block>
  <block id="8950578c587f9503f949dfc6a274b611" category="admonition">*NetApp recommande* de ne pas placer<block ref="18ca3ed022c239421418de608ceb49c5" prefix=" " category="inline-code"></block> données sur un système de fichiers avec<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> ou<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block> parce que des problèmes de performances sont probables. Séparer<block ref="18ca3ed022c239421418de608ceb49c5" prefix=" " category="inline-code"></block> le cas échéant, les données vers un autre point de montage.</block>
  <block id="cdb92b4a73ae99cde4df55c06e20dd3c" category="section-title">nfs-rootonly et mount-rootonly</block>
  <block id="c1f0a21ee026237bef11139a30b07040" category="paragraph">ONTAP inclut une option NFS appelée<block ref="77743dec92afc92eca95c255fd9333d7" prefix=" " category="inline-code"></block> Cela permet de contrôler si le serveur accepte les connexions de trafic NFS à partir des ports élevés. Par mesure de sécurité, seul l'utilisateur root est autorisé à ouvrir des connexions TCP/IP à l'aide d'un port source inférieur à 1024 car ces ports sont normalement réservés à l'utilisation du système d'exploitation, et non aux processus utilisateur. Cette restriction permet de s'assurer que le trafic NFS provient d'un client NFS du système d'exploitation et non d'un processus malveillant émulant un client NFS. Le client Oracle dNFS est un pilote d'espace utilisateur, mais le processus s'exécute en tant que root, il n'est donc généralement pas nécessaire de modifier la valeur de<block ref="77743dec92afc92eca95c255fd9333d7" prefix=" " category="inline-code"></block>. Les connexions sont réalisées à partir de ports bas.</block>
  <block id="832b4524bcec11d28ca777ef9cdb4084" category="paragraph">Le<block ref="eb6c1a5ecd1e17d4cd46fa5c9d415816" prefix=" " category="inline-code"></block> Cette option s'applique uniquement à NFSv3. Il contrôle si l'appel de MONTAGE RPC est accepté à partir de ports supérieurs à 1024. Lorsque dNFS est utilisé, le client est de nouveau exécuté en tant que root, ce qui lui permet d'ouvrir des ports inférieurs à 1024. Ce paramètre n'a aucun effet.</block>
  <block id="57c47a1451485bec1ebb060afdf65cb4" category="paragraph">Les processus ouvrant des connexions avec dNFS sur les versions 4.0 et supérieures de NFS ne s'exécutent pas en tant que root et nécessitent donc des ports supérieurs à 1024. Le<block ref="77743dec92afc92eca95c255fd9333d7" prefix=" " category="inline-code"></block> Le paramètre doit être défini sur Désactivé pour dNFS pour terminer la connexion.</block>
  <block id="4dd73247734d116e5039cc04c4979f2c" category="paragraph">Si<block ref="77743dec92afc92eca95c255fd9333d7" prefix=" " category="inline-code"></block> Est activé, le résultat est un blocage lors de la phase de montage ouvrant les connexions dNFS. La sortie sqlplus ressemble à ceci :</block>
  <block id="f62d72479920ff0f8dc9a3ca6f301b5d" category="paragraph">Le paramètre peut être modifié comme suit :</block>
  <block id="47fc6c6691aed3ba0dbdc66c7896c61b" category="admonition">Dans de rares cas, vous devrez peut-être modifier nfs-rootonly et mount-rootonly sur Désactivé. Si un serveur gère un très grand nombre de connexions TCP, il est possible qu'aucun port inférieur à 1024 n'est disponible et que le système d'exploitation soit forcé d'utiliser des ports supérieurs. Ces deux paramètres ONTAP doivent être modifiés pour permettre la connexion.</block>
  <block id="10b4eb170fe7bd035f21e7d863796683" category="section-title">Règles d'exportation NFS : superutilisateur et setuid</block>
  <block id="98bfec37486e95443730cc3d462022fb" category="paragraph">Si les binaires Oracle se trouvent sur un partage NFS, les règles d'export doivent inclure des autorisations de superutilisateur et de setuid.</block>
  <block id="3c0699ba2c56cb17c145bbda5580ed67" category="paragraph">Les exportations NFS partagées utilisées pour les services de fichiers génériques tels que les répertoires personnels des utilisateurs écraseront généralement l'utilisateur root. Cela signifie qu'une demande de l'utilisateur root sur un hôte qui a monté un système de fichiers est remappée en tant qu'utilisateur différent avec des privilèges inférieurs. Cela permet de sécuriser les données en empêchant un utilisateur root d'un serveur donné d'accéder aux données du serveur partagé. Le bit setuid peut également représenter un risque de sécurité dans un environnement partagé. Le bit setuid permet d'exécuter un processus en tant qu'utilisateur différent de celui qui appelle la commande. Par exemple, un script shell qui était détenu par root avec le bit setuid s'exécute en tant que root. Si ce script shell peut être modifié par d'autres utilisateurs, tout utilisateur non root peut émettre une commande en tant que root en mettant à jour le script.</block>
  <block id="e341736b7d51c23cb7ef95615832e502" category="paragraph">Les binaires Oracle incluent les fichiers appartenant à root et utilisent le bit setuid. Si des binaires Oracle sont installés sur un partage NFS, les règles d'export doivent inclure les autorisations de superutilisateur et de setuid appropriées. Dans l'exemple ci-dessous, la règle inclut les deux<block ref="1efaeada4e3307369aca511f5da0498a" prefix=" " category="inline-code"></block> et permis<block ref="0baea2f0ae20150db78f58cddac442a9" prefix=" " category="inline-code"></block> Accès (root) pour les clients NFS via l'authentification système.</block>
  <block id="f1a0fa258c785ac546835a1a75017faf" category="section-title">Configuration NFSv4/4.1</block>
  <block id="52f9ad2e353a42e61d9bf7dd9f59d0cb" category="paragraph">Pour la plupart des applications, il y a très peu de différence entre NFSv3 et NFSv4. Les E/S applicatives sont généralement des E/S très simples et ne bénéficient pas énormément de certaines des fonctionnalités avancées de NFSv4. Les versions supérieures de NFS ne doivent pas être considérées comme une « mise à niveau » du point de vue du stockage de la base de données, mais plutôt comme des versions de NFS qui incluent des fonctionnalités supplémentaires. Par exemple, si la sécurité de bout en bout du mode de confidentialité kerberos (krb5p) est requise, NFSv4 est requis.</block>
  <block id="a1dc4350330c061ae52050f5a3400e25" category="section-title">Domaine NFSv4</block>
  <block id="c30669603c950b31f6093d8beaf8060a" category="paragraph">Une explication complète de la configuration NFSv4/4.1 dépasse le cadre de ce document, mais un problème couramment rencontré est une incohérence dans le mappage de domaine. Du point de vue de sysadmin, les systèmes de fichiers NFS semblent se comporter normalement, mais les applications signalent des erreurs concernant les autorisations et/ou le setuid sur certains fichiers. Dans certains cas, les administrateurs ont conclu à tort que les autorisations des binaires de l'application ont été endommagées et ont exécuté des commandes chown ou chmod lorsque le problème réel était le nom de domaine.</block>
  <block id="f0c6c8a632eeaa954640907ee1da277d" category="paragraph">Le nom de domaine NFSv4 est défini sur le SVM ONTAP :</block>
  <block id="97a98ebe6ac1f4a8eaf69158419dd818" category="paragraph">Le nom de domaine NFSv4 sur l'hôte est défini dans<block ref="60969252b5b8391a3378335ae420d2e8" prefix=" " category="inline-code"></block></block>
  <block id="4ade50e8135e817e75aa3086851eaaa8" category="paragraph">Les noms de domaine doivent correspondre. Si ce n'est pas le cas, des erreurs de mappage similaires à ce qui suit apparaissent dans<block ref="452905a167cf4509fd08acb964fdb20c" prefix=" " category="inline-code"></block>:</block>
  <block id="c0eb73bb35a4c58d87b330cd00f1986a" category="paragraph">Les binaires d'application, tels que les binaires de base de données Oracle, incluent les fichiers appartenant à root avec le bit setuid, ce qui signifie qu'une discordance dans les noms de domaine NFSv4 provoque des échecs avec le démarrage d'Oracle et un avertissement sur la propriété ou les autorisations d'un fichier appelé<block ref="dd440398b298ff16eb1188ba8afca6df" prefix=" " category="inline-code"></block>, qui est situé dans le<block ref="002f94d606ac06f290f33a5fcc67b264" prefix=" " category="inline-code"></block> répertoire. Elle doit apparaître comme suit :</block>
  <block id="21cc6f8790de2a7022b344914915604e" category="paragraph">Si ce fichier apparaît avec la propriété de personne, il peut y avoir un problème de mappage de domaine NFSv4.</block>
  <block id="203f1cdb2421d34e9eb7391e03ffcaf6" category="paragraph">Pour résoudre ce problème, vérifiez le<block ref="60969252b5b8391a3378335ae420d2e8" prefix=" " category="inline-code"></block> Comparez le paramètre v4-ID-domain sur ONTAP et assurez-vous qu'ils sont cohérents. Si ce n'est pas le cas, effectuez les modifications requises, exécutez<block ref="1c7ebfbcaa2681599e41320ed491ca91" prefix=" " category="inline-code"></block>, et attendez un moment pour que les modifications se propagent. La propriété du fichier doit alors être correctement reconnue en tant que racine. Si un utilisateur a tenté de s'exécuter<block ref="05f0da969f2e0e6ecf3ab445e1e665ad" prefix=" " category="inline-code"></block> Sur ce fichier avant que la configuration des domaines NFS ne soit corrigée, il peut être nécessaire de l'exécuter<block ref="05f0da969f2e0e6ecf3ab445e1e665ad" prefix=" " category="inline-code"></block> encore.</block>
  <block id="748f6387bf49161b9a69b7bfd691dcd2" category="paragraph">La présence de l'une des options de montage suivantes entraîne la désactivation de la mise en cache de l'hôte :</block>
  <block id="9f75df502ef11eaef4292c94110cb673" category="paragraph">Ces paramètres peuvent avoir un effet négatif important sur la vitesse d'installation du logiciel, de correction et des opérations de sauvegarde/restauration. Dans certains cas, en particulier avec les applications en cluster, ces options sont obligatoires car elles doivent inévitablement assurer la cohérence du cache sur tous les nœuds du cluster. Dans d'autres cas, les clients utilisent ces paramètres par erreur, ce qui entraîne des dommages inutiles aux performances.</block>
  <block id="8d23519d53d6611bc42fef8dc4a432df" category="paragraph">De nombreux clients suppriment temporairement ces options de montage lors de l'installation ou de l'application de correctifs binaires. Cette suppression peut être effectuée en toute sécurité si l'utilisateur vérifie qu'aucun autre processus n'utilise activement le répertoire cible pendant le processus d'installation ou de correction.</block>
  <block id="f73bede4039d47664f70de3c2d1f2b46" category="summary">Configuration des bandes LVM pour les bases de données Oracle</block>
  <block id="1b5681ffc153e25d2a48ae3f3f01b9f5" category="paragraph">La répartition des LVM consiste à distribuer les données entre plusieurs LUN. Les performances de nombreuses bases de données en sont ainsi considérablement améliorées.</block>
  <block id="358b9a846de3e04b423c68bac9bc6d53" category="summary">Alignement des LUN avec les bases de données Oracle</block>
  <block id="3e00e4d28b17eedd6f6c2c38233e06a8" category="paragraph">L'alignement des LUN fait référence à l'optimisation des E/S par rapport à la disposition du système de fichiers sous-jacent.</block>
  <block id="a6c7e85d51ae3b98197ceb3eafa3686a" category="inline-link-macro">Efficacité</block>
  <block id="6e2524d5663b2bdc0c7985fa3e57cc55" category="section-title">Avertissements de mauvais alignement</block>
  <block id="79e721357e358d77c4700c25c863fc37" category="inline-link">Configuration de l'hôte SAN ONTAP</block>
  <block id="268b1da3f1ff11d32e385d0223101718" category="paragraph">L'alignement dans les environnements Solaris est plus compliqué. Reportez-vous à la section<block ref="2d33e0364c07dc165b4079892340d4fe" category="inline-link-rx"></block> pour en savoir plus.</block>
  <block id="6d017248f1e4f0ec7e2cd19d967b6bee" category="cell">Dans les environnements Solaris x86, prenez davantage soin de l'alignement approprié car la plupart des configurations comportent plusieurs couches de partitions. Les tranches de partition Solaris x86 existent généralement au-dessus d'une table de partition d'enregistrement d'amorçage maître standard.</block>
  <block id="b1230060a0220caf9d68d64b9dd85e6f" category="summary">Tailles de transfert NFS avec Oracle</block>
  <block id="fabe34ed4a5e432f4d1c4f6584956d8d" category="doc">Tailles de transfert NFS avec les bases de données Oracle</block>
  <block id="1e207db9a7c8127a6c43c771b89254fb" category="paragraph">Par défaut, ONTAP limite la taille des E/S NFS à 64 Ko.</block>
  <block id="72d22e3b9af95e272859e64eb1d82df7" category="paragraph">Les E/S aléatoires utilisent la plupart des applications et bases de données une taille de bloc bien inférieure à la taille maximale de 64 Ko. Les E/S de blocs volumineux sont généralement parallélisées de sorte que le maximum de 64 Ko ne limite pas non plus l'obtention d'une bande passante maximale.</block>
  <block id="ebf61afddb34d070825eb696bea48813" category="paragraph">Dans certains cas, le maximum de 64 000 charges de travail entraîne une limitation. En particulier, les opérations à thread unique, telles que les opérations de sauvegarde ou de restauration, ou encore les analyses de table complète de base de données s'exécutent plus rapidement et plus efficacement si la base de données peut exécuter moins d'E/S, mais plus volumineuses. La taille optimale de gestion des E/S pour ONTAP est de 256 Ko.</block>
  <block id="b0a5b394f3a29e64573049cda19fbacc" category="paragraph">La taille maximale de transfert pour un SVM ONTAP donné peut être modifiée comme suit :</block>
  <block id="b070b82d66be7116d5fd6dfd8172351b" category="cell">Ne réduisez jamais la taille de transfert maximale autorisée sur ONTAP en dessous de la valeur de rsize/wsize des systèmes de fichiers NFS actuellement montés. Cela peut provoquer des blocages ou même une corruption des données avec certains systèmes d'exploitation. Par exemple, si les clients NFS sont actuellement définis sur une taille rsize/wsize de 65536, la taille maximale du transfert ONTAP peut être ajustée entre 65536 et 1048576 sans effet car les clients eux-mêmes sont limités. Réduire la taille de transfert maximale en dessous de 65536 peut endommager la disponibilité ou les données.</block>
  <block id="8eb703f2756cafd21dbac4f23c0d6416" category="paragraph">ONTAP supprime efficacement les blocs nuls écrits sur un fichier ou une LUN lorsque la compression à la volée est activée. Des utilitaires tels que l'utilitaire ASRU (Oracle ASM Reclamation Utility) sont utilisés en écrivant des zéros dans les extensions ASM inutilisées.</block>
  <block id="9de53c14f2bae0c5d4b6e19be495ee94" category="paragraph">Du point de vue de la base de données, le groupe de disques ASM contient des zéros et la lecture de ces régions des LUN entraîne un flux de zéros, mais ONTAP ne stocke pas les zéros sur les disques. Des modifications simples des métadonnées sont effectuées en interne pour marquer les régions mises à zéro de la LUN comme vides de toutes les données.</block>
  <block id="06348c6e795160187e298a91b25a37a3" category="paragraph">Pour des raisons similaires, le test de performance impliquant des données mises à zéro n'est pas valide, car les blocs de zéros ne sont pas réellement traités comme des écritures dans la baie de stockage.</block>
  <block id="cee584f1e6223f6dbb73c0d64d599228" category="admonition">Lorsque vous utilisez ASRU, assurez-vous que tous les correctifs recommandés par Oracle sont installés.</block>
  <block id="17ff263bc6eb701aecb8e79f9ef53efd" category="summary">Redimensionnement des LUN et des LVM avec les bases de données Oracle</block>
  <block id="ff15e8b125dae74c1231f09380e48886" category="paragraph">Lorsqu'un système de fichiers SAN a atteint sa limite de capacité, il existe deux options pour augmenter l'espace disponible :</block>
  <block id="4182200437c090276a01ad8ca54076b0" category="summary">Configuration de NVFAIL pour protéger les bases de données Oracle</block>
  <block id="60e002164f8988e984cf4a95b240f19d" category="doc">Oracle et NVFAIL</block>
  <block id="370bdf5dd39278264774ea595054e243" category="paragraph">NVFAIL est une fonctionnalité de ONTAP qui assure l'intégrité lors des scénarios de basculement catastrophiques.</block>
  <block id="80250c1f1d70fc693877be6f22cc134e" category="paragraph">En raison de la gestion de caches internes volumineux, les bases de données sont vulnérables à la corruption lors des événements de basculement du stockage. Si un événement catastrophique nécessite de forcer un basculement ONTAP ou de forcer le basculement MetroCluster, quel que soit l'état de santé de la configuration globale, les modifications qui ont été reconnues précédemment peuvent être supprimées. Le contenu de la matrice de stockage recule dans le temps et l'état du cache de la base de données ne reflète plus l'état des données sur le disque. Cette incohérence entraîne une corruption des données.</block>
  <block id="68114defc717054e7e3b02df438cdbe1" category="paragraph">La mise en cache peut avoir lieu au niveau des applications ou des serveurs. Par exemple, une configuration Oracle Real application Cluster (RAC) avec des serveurs actifs sur un site principal et un site distant met en cache les données dans la SGA d'Oracle. Une opération de basculement forcé entraînant des pertes de données risque de corrompre la base de données, car les blocs stockés dans la mémoire SGA peuvent ne pas correspondre aux blocs du disque.</block>
  <block id="162de6d405c04ce8f152f1d246ed9187" category="paragraph">L'utilisation de la mise en cache est moins évidente au niveau du système de fichiers du système d'exploitation. Les blocs d'un système de fichiers NFS monté peuvent être mis en cache dans le système d'exploitation. Un système de fichiers en cluster basé sur des LUN situés sur le site principal peut également être monté sur des serveurs du site distant, et une fois encore, les données peuvent être mises en cache. Une défaillance de la mémoire NVRAM, un basculement forcé ou un basculement forcé dans ces situations peuvent entraîner une corruption du système de fichiers.</block>
  <block id="04ca8d9ad570a3bdf1d76e23bc108ae5" category="paragraph">ONTAP protège les bases de données et les systèmes d'exploitation de ce scénario avec NVFAIL et ses paramètres associés.</block>
  <block id="82ef718f4ebe0c276814ee3d51e33361" category="doc">SnapRestore</block>
  <block id="863696626734d6591db8be57b41c7eec" category="paragraph">La technologie NetApp SnapRestore assure la restauration rapide des données dans ONTAP à partir d'une copie Snapshot.</block>
  <block id="9099b669f87419bc03914f11f5779c60" category="paragraph">Lorsqu'un dataset stratégique n'est pas disponible, les opérations stratégiques de l'entreprise ne sont pas disponibles. Les bandes peuvent se rompre, et même les restaurations à partir de sauvegardes sur disque peuvent être lentes à transférer sur le réseau. SnapRestore évite ces problèmes en offrant une restauration quasi instantanée des datasets. Même les bases de données de plusieurs pétaoctets peuvent être entièrement restaurées en quelques minutes à peine.</block>
  <block id="b02fb7dec22d0e276ca01cc60b9efb48" category="paragraph">Il existe deux types d'SnapRestore : basés sur les fichiers/LUN et sur les volumes.</block>
  <block id="520e4b70b10aa2755a82b77e438a510f" category="list-text">Il est possible de restaurer des fichiers individuels ou des LUN en quelques secondes, qu'il s'agisse d'un LUN de 2 To ou d'un fichier de 4 Ko.</block>
  <block id="45e8a84fe4ac58c8b30a7bdaf17c0b7f" category="list-text">Le conteneur de fichiers ou de LUN peut être restauré en quelques secondes, qu'il s'agisse de 10 Go ou 100 To de données.</block>
  <block id="4be4677be8cd434956b9b9af515b971a" category="paragraph">Un « conteneur de fichiers ou de LUN » fait généralement référence à un volume FlexVol. Par exemple, vous pouvez avoir 10 LUN qui composent un groupe de disques LVM dans un seul volume, ou un volume peut stocker les home directories NFS de 1000 utilisateurs. Au lieu d'exécuter une opération de restauration pour chaque fichier ou LUN individuel, vous pouvez restaurer le volume entier en une seule opération. Ce processus fonctionne également avec des conteneurs scale-out qui incluent plusieurs volumes, tels qu'un FlexGroup ou un groupe de cohérence ONTAP.</block>
  <block id="55abea92d64d6738f9e0ed48799696e7" category="paragraph">ONTAP permet uniquement un accès en lecture seule aux données instantanées, mais les données peuvent être réactivées avec SnapRestore. L'instantané est réactivé en tant que vue en lecture-écriture des données, renvoyant les données à leur état précédent. SnapRestore peut fonctionner au niveau du volume ou du fichier. La technologie est essentiellement la même avec quelques différences mineures de comportement.</block>
  <block id="f10f2af75e2770a8ed3c2fde594e986d" category="section-title">SnapRestore du volume</block>
  <block id="ca9846346bc3b03cdec10f9fff456866" category="paragraph">La fonction SnapRestore basée sur les volumes renvoie la totalité du volume de données à un état antérieur. Cette opération ne nécessite pas de déplacement de données. Le processus de restauration est donc pratiquement instantané, bien que le traitement des opérations via l'API ou l'interface de ligne de commande puisse prendre quelques secondes. La restauration de 1 Go de données n'est pas plus compliquée et chronophage que la restauration de 1 po de données. Cette fonctionnalité est la principale raison pour laquelle de nombreux clients grands comptes migrent vers des systèmes de stockage ONTAP. Il assure un RTO se mesure en quelques secondes, même pour les datasets les plus volumineux.</block>
  <block id="627436e77bb011a6a312ae87b12f98ea" category="paragraph">L'un des inconvénients des SnapRestore sur volume est le fait que les modifications au sein d'un volume sont cumulées dans le temps. Par conséquent, chaque snapshot et les données de fichier actives dépendent des modifications apportées jusqu'à ce point. Le rétablissement d'un volume à un état antérieur implique la suppression de toutes les modifications ultérieures apportées aux données. Ce qui est moins évident, cependant, c'est qu'il s'agit d'instantanés créés par la suite. Ce n'est pas toujours souhaitable.</block>
  <block id="5c956f2c1cfc5b9e5bac32ad1acba314" category="paragraph">Par exemple, un SLA de conservation des données peut spécifier 30 jours de sauvegardes nocturnes. La restauration d'un dataset sur un snapshot créé il y a cinq jours avec SnapRestore du volume abandonnerait tous les snapshots créés les cinq jours précédents, en violation du SLA.</block>
  <block id="8bf9e697004f47ed6133aef724a8a42c" category="paragraph">Un certain nombre d'options sont disponibles pour résoudre cette limitation :</block>
  <block id="ad3b75456e625de5fe347fb918f59a22" category="list-text">Les données peuvent être copiées à partir d'un instantané précédent, au lieu d'effectuer une SnapRestore du volume entier. Cette méthode fonctionne mieux avec les jeux de données plus petits.</block>
  <block id="90541eb74c7c56cadc2f90ec6fb6f0c0" category="list-text">Un snapshot peut être cloné plutôt que restauré. La limitation à cette approche est que le snapshot source dépend du clone. Par conséquent, elle ne peut pas être supprimée si le clone n'est pas également supprimé ou s'il est divisé en volume indépendant.</block>
  <block id="ab6045d3463c0f68ce2fa405dce9d554" category="list-text">Utilisation d'un SnapRestore basé sur des fichiers.</block>
  <block id="7f7599a8b92846b691484dc91e090164" category="section-title">Fichier SnapRestore</block>
  <block id="f03eebe4f07d362dbfe4c1d4e76c724d" category="paragraph">SnapRestore basé sur les fichiers est un processus de restauration plus granulaire basé sur des snapshots. Au lieu de rétablir l'état d'un volume entier, l'état d'un fichier ou d'une LUN individuel est rétabli. Il n'est pas nécessaire de supprimer des snapshots et cette opération ne crée aucune dépendance vis-à-vis d'un instantané précédent. Le fichier ou la LUN est immédiatement disponible dans le volume actif.</block>
  <block id="e432fdcc277fc74a1b2b94cfeec8a7d2" category="paragraph">Aucun déplacement des données n'est nécessaire lors de la restauration d'un fichier ou d'une LUN par SnapRestore. Cependant, des mises à jour internes des métadonnées sont nécessaires pour refléter le fait que les blocs sous-jacents d'un fichier ou d'une LUN existent désormais à la fois dans un snapshot et dans le volume actif. Les performances ne doivent pas être affectées, mais ce processus bloque la création de snapshots jusqu'à ce qu'elle soit terminée. Le taux de traitement est d'environ 5 Gbit/s (18 To/heure) en fonction de la taille totale des fichiers restaurés.</block>
  <block id="45c46768a1cb073f0d13245a0dc816f2" category="paragraph">Une architecture de protection des données d'entreprise adaptée dépend des exigences de l'entreprise concernant la conservation des données, la restauration et la tolérance aux perturbations à divers moments.</block>
  <block id="46e1b2893bdb002c0ede448cbfe1cb14" category="paragraph">Prenons l'exemple du nombre d'applications, de bases de données et de datasets importants pris en compte. Il est relativement simple d'élaborer une stratégie de sauvegarde pour un seul dataset afin d'assurer la conformité aux SLA standard, car la gestion ne comporte pas beaucoup d'objets. À mesure que le nombre de jeux de données augmente, la surveillance devient plus complexe et les administrateurs peuvent être obligés de consacrer de plus en plus de temps aux pannes de sauvegarde. Dès qu'un environnement évolue, il faut adopter une approche totalement différente.</block>
  <block id="b70d233428e03d072b1134a97d853ab2" category="paragraph">La taille des datasets affecte également la stratégie. Par exemple, le jeu de données étant si petit, de nombreuses options sont possibles pour la sauvegarde et la restauration avec une base de données de 100 Go. En général, la simple copie des données à partir du support de sauvegarde avec des outils classiques permet d'atteindre un RTO suffisant pour la restauration. Une base de données de 100 To a généralement besoin d'une stratégie totalement différente, sauf si le RTO autorise une panne de plusieurs jours. Dans ce cas, une procédure classique de sauvegarde et de restauration basée sur des copies peut être acceptable.</block>
  <block id="64848fee9c168231f5d0f13322ed0a87" category="paragraph">Enfin, il y a des facteurs en dehors du processus de sauvegarde et de restauration lui-même. Par exemple, existe-t-il des bases de données qui prennent en charge les activités de production stratégiques, faisant de la restauration un événement rare uniquement effectué par des administrateurs de bases de données qualifiés ? Ou bien, les bases de données font-elles partie d'un vaste environnement de développement dans lequel la restauration est fréquente et gérée par une équipe INFORMATIQUE généraliste ?</block>
  <block id="e26b57887de9a65c0316a87d49bf6c44" category="section-title">Un snapshot est-il une sauvegarde ?</block>
  <block id="c3fd105ab426caff0a0ade2e93476543" category="paragraph">L'une des objections les plus fréquentes à l'utilisation des snapshots en tant que stratégie de protection des données est le fait que les « vraies » données et les données de snapshot se trouvent sur les mêmes disques. La perte de ces disques entraînerait la perte des données primaires et de la sauvegarde.</block>
  <block id="12d1adb01d24027626b2a47660fb5b81" category="paragraph">Ce problème est valide. Les snapshots locaux sont utilisés pour les besoins quotidiens de sauvegarde et de restauration, et dans ce sens, le snapshot est une sauvegarde. Dans les environnements NetApp, près de 99 % des scénarios de restauration s'appuient sur des copies Snapshot pour répondre aux exigences de RTO les plus strictes.</block>
  <block id="fc34c9966c8ecb7307468637d9e79933" category="paragraph">Toutefois, les snapshots locaux ne doivent jamais être la seule stratégie de sauvegarde. C'est pourquoi NetApp propose des technologies telles que la réplication SnapMirror pour répliquer rapidement et efficacement des copies Snapshot sur un ensemble indépendant de disques. Dans une solution bien conçue avec des snapshots et une réplication Snapshot, l'utilisation des bandes peut être réduite au minimum, voire même à une archive trimestrielle, ou totalement éliminée.</block>
  <block id="1ea948130a9dbbc02e3a80648a99ff57" category="section-title">Sauvegardes de groupes de cohérence</block>
  <block id="9b234a126e57777ab83807827d4e7078" category="paragraph">La sauvegarde d'un groupe de cohérence implique de capturer l'état d'un jeu de données (ou de plusieurs jeux de données) à un point atomique unique dans le temps. Comme exemple de base de données, cela inclut tous les composants de la base de données, tels que les fichiers de données, les fichiers journaux et les autres fichiers directement associés à la base de données. Cela fonctionne avec presque tous les produits de base de données relationnelle, comme Oracle RDBMS, Microsoft SQL Server, SAP HANA, PostgreSQL, MySQL et MariaDB. La protection d'une configuration VMware avec une sauvegarde de groupe de cohérence serait similaire, en capturant tous les datastores et potentiellement les LUN de démarrage ESX à un seul point atomique dans le temps.</block>
  <block id="5a1f7038c74e54c08669efa6722f1091" category="paragraph">La création d'un Snapshot de groupe de cohérence de ce type simule une panne. C'est pourquoi ces sauvegardes sont souvent appelées sauvegardes cohérentes après panne. La prise en charge des scénarios de restauration pose parfois des problèmes, mais il est important de comprendre qu'aucune procédure de restauration n'est généralement nécessaire. Lorsque l'application démarre après la restauration d'une sauvegarde de groupe de cohérence, elle exécute les processus de restauration de journaux habituels, les relectures du journal du système de fichiers et d'autres tâches pour relire toute E/S en cours au point de la sauvegarde. L'application démarre alors comme d'habitude.</block>
  <block id="aebdbddec25f7eba6434244a989fb659" category="paragraph">Pour l'essentiel, toute application pouvant résister à une panne de courant ou à une panne de serveur sans corruption des données peut être protégée de cette façon. Le fait que cela fonctionne peut également être démontré par le grand nombre d'applications protégées par des produits de mise en miroir synchrone et asynchrone de nombreux fournisseurs différents. Si un incident frappe soudainement le site principal, le site de réplica contient une image cohérente de l'environnement d'origine au moment où l'incident s'est produit. Une fois de plus, aucune procédure de récupération spéciale n'est requise.</block>
  <block id="e085ffefd89f8fb66260a9720e3fb6f8" category="paragraph">Le RPO de cette approche est généralement limité au point de sauvegarde. En règle générale, le RPO minimal pour les copies Snapshot à un seul volume est d'une heure. Par exemple, 48 snapshots par heure et 30 autres snapshots par nuit sont raisonnables et ne nécessitent pas la conservation d'un nombre excessif de snapshots. Il devient plus difficile d'atteindre un objectif de point de récupération inférieur à une heure. Il n'est donc pas recommandé de consulter au préalable les services professionnels NetApp pour comprendre les exigences en matière d'environnement, d'évolutivité et de protection des données.</block>
  <block id="1fe119a790b393b7dd7e79b63f15f52b" category="paragraph">Le RTO se mesure généralement en secondes. A une application est arrêtée, les volumes sont restaurés et l'application redémarrée.</block>
  <block id="444cd304758b7607c8f7a3f627a5bc1f" category="paragraph">La méthode la plus simple consiste à placer tous les fichiers ou LUN dans un groupe de cohérence de volume unique. Ainsi, la création de Snapshot peut être planifiée directement dans ONTAP. Lorsqu'un dataset doit couvrir des volumes, un Snapshot de groupe de cohérence (cg-snapshot) est nécessaire. Vous pouvez les configurer à l'aide de System Manager ou d'appels d'API RESTful. De plus, SnapCenter est capable de créer un snapshot de groupe de cohérence simple sur une liste définie de volumes.</block>
  <block id="689b0155b42a554594a44cddc736eb67" category="section-title">Architecture de réplication et de reprise après incident</block>
  <block id="1749d12df3df2319d3eee218a277ff83" category="inline-link-macro">MetroCluster</block>
  <block id="f443592081a2b3ddc55b94abe49ba128" category="paragraph">Le RPO de reprise sur incident est limité par la bande passante réseau disponible et la taille totale des données protégées. Une fois le transfert de base initial créé, les mises à jour sont uniquement basées sur les données modifiées, ce qui représente généralement un faible pourcentage de l'empreinte totale des données, même si des exceptions existent.</block>
  <block id="89e87a831dae60244ba34496d70fd45d" category="paragraph">Par exemple, une base de données de 10 To avec un taux de modification hebdomadaire de 10 % représente en moyenne 6 Go de modifications totales par heure. Avec une connectivité de 10 Gb, ce transfert de base de données prend environ 6 minutes. Le taux de modification varie en fonction des fluctuations du taux de modification de la base de données, mais dans l'ensemble, un intervalle de mise à jour de 15 minutes et un objectif de point de récupération de 15 minutes doivent être atteints. S'il existe 100 bases de données de ce type, 600 minutes sont nécessaires pour transférer les données. Par conséquent, un objectif RPO d'une heure n'est pas possible. De même, une réplique d'une seule base de données de 100 To avec un taux de modification hebdomadaire de 10 % ne peut pas être mise à jour de manière fiable en une heure.</block>
  <block id="3c886a803aef21f5ac9f7bcea7408cbb" category="paragraph">D'autres facteurs peuvent avoir une incidence sur la réplication, comme la surcharge liée à la réplication et la limitation du nombre d'opérations de réplication simultanées. Cependant, la planification globale d'une stratégie de réplication à volume unique peut reposer sur la bande passante disponible et un RPO de réplication d'une heure est généralement réalisable. Un RPO inférieur à une heure devient plus difficile à atteindre et ne doit être réalisé qu'après consultation des services professionnels de NetApp. Dans certains cas, 15 minutes sont possibles avec une très bonne connectivité réseau site à site. Cependant, dans l'ensemble, lorsqu'un objectif RPO inférieur à une heure est requis, l'architecture de relecture des journaux multivolumes produit de meilleurs résultats.</block>
  <block id="5e2cbdd214e7a73bca1af8ed5cc04626" category="paragraph">Dans un scénario de reprise d'activité, le RTO avec réplication de groupe de cohérence est excellent, généralement mesuré en secondes du point de vue du stockage. L'approche la plus simple est de mettre simplement en miroir et la base de données est prête à être démarrée. Le temps de démarrage de la base de données est généralement d'environ 10 secondes, mais les bases de données très volumineuses qui génèrent un grand nombre de transactions consignées peuvent prendre quelques minutes.</block>
  <block id="1c18c939e73ddb1ceee34e8a33079d1a" category="paragraph">Le facteur le plus important pour déterminer l'objectif de durée de restauration n'est pas le système de stockage, mais l'application et le système d'exploitation hôte sur lesquels il s'exécute. Par exemple, les données répliquées peuvent être disponibles en une ou deux secondes, mais elles ne représentent que les données. Il doit également y avoir un système d'exploitation correctement configuré avec des binaires d'application disponibles pour utiliser les données.</block>
  <block id="6fab898feea25b9d7fd4477911b90b31" category="paragraph">Dans certains cas, les clients ont préparé des instances de reprise après incident à l'avance, avec le stockage prédécouvert sur les systèmes d'exploitation. Dans ce cas, l'activation du scénario de reprise d'activité ne peut nécessiter que la rupture d'un miroir et le démarrage de l'application. Dans d'autres cas, le système d'exploitation et les applications associées peuvent être mis en miroir avec la base de données en tant que disque de machine virtuelle ESX (VMDK). Dans ce cas, le RPO est déterminé par la quantité investie par un client dans l'automatisation pour démarrer rapidement le VMDK afin de pouvoir démarrer les applications.</block>
  <block id="c7d5d755b896edf43189fbb020202913" category="paragraph">Le temps de rétention est contrôlé en partie par la limite de snapshot. Par exemple, les volumes dans ONTAP ont une limite de 1024 snapshots. Dans certains cas, les clients disposent d'une réplication multiplexée pour augmenter la limite. Par exemple, si 2000 jours de sauvegardes sont requis, une source peut être répliquée sur deux volumes avec des mises à jour effectuées sur d'autres jours. L'espace initial nécessaire doit être augmenté, mais l'approche reste bien plus efficace qu'un système de sauvegarde traditionnel qui implique plusieurs sauvegardes complètes.</block>
  <block id="7ec0f114b69016879106b5018cdf10b9" category="section-title">Groupe de cohérence à volume unique</block>
  <block id="cd70f3e596e275fe80fbbe5d7858ce1a" category="paragraph">La méthode la plus simple consiste à placer tous les fichiers ou LUN dans un groupe de cohérence de volume unique. Ainsi, les mises à jour SnapMirror et SnapVault peuvent être planifiées directement sur le système de stockage. Aucun logiciel externe n'est requis.</block>
  <block id="909e8df57072d0b3c6d7d64b11acb571" category="section-title">Groupe de cohérence multivolume</block>
  <block id="c7371eded617935ace6c71a33cfbf3fd" category="paragraph">Lorsqu'une base de données doit couvrir plusieurs volumes, un Snapshot de groupe de cohérence (cg-snapshot) est nécessaire. Comme mentionné précédemment, cette configuration peut être effectuée à l'aide de System Manager ou d'appels d'API RESTful. De plus, SnapCenter est capable de créer un snapshot de groupe de cohérence simple sur une liste définie de volumes.</block>
  <block id="9c991b38c054d7bec0632efd6667540c" category="paragraph">Il est également nécessaire de prendre en compte un autre facteur concernant l'utilisation de copies Snapshot cohérentes à plusieurs volumes à des fins de reprise après incident. Lors de la mise à jour de plusieurs volumes, il est possible qu'un incident se produise pendant le transfert. Il en résulte un ensemble de volumes qui ne sont pas cohérents les uns avec les autres. Si c'est le cas, certains volumes doivent être restaurés à un état de snapshot antérieur pour fournir une image de base de données cohérente après panne et prête à être utilisée.</block>
  <block id="fad8a5f46ebd89f74383b461e32dd6b9" category="section-title">Reprise après incident : activation</block>
  <block id="5ac319591298468b0af89c2c469201f8" category="paragraph">Le processus d'activation de la copie de reprise sur incident dépend du type de stockage. Avec NFS, les systèmes de fichiers peuvent être prémontés sur le serveur de reprise après incident. Ils sont en lecture seule et deviennent en lecture-écriture lorsque le miroir est cassé. Le RPO est ainsi extrêmement faible, et le processus global de reprise sur incident est plus fiable, car la gestion comporte moins de pièces.</block>
  <block id="b829fc11ff11b57af8d4632d38d7d7e8" category="paragraph">L'activation des configurations SAN en cas de reprise après incident devient plus complexe. L'option la plus simple consiste généralement à interrompre temporairement les miroirs et à monter les ressources SAN, notamment à découvrir la configuration LVM (y compris les fonctionnalités spécifiques à l'application telles qu'Oracle Automatic Storage Management [ASM]) et à ajouter des entrées à /etc/fstab.</block>
  <block id="335a5796fb106a877544d121062534be" category="paragraph">Le résultat est que les chemins du périphérique LUN, les noms des groupes de volumes et les autres chemins de périphériques sont connus du serveur cible. Ces ressources peuvent ensuite être désactivées, puis les miroirs peuvent être restaurés. Le résultat est un serveur qui est dans un état qui peut rapidement mettre l'application en ligne. Les étapes permettant d'activer des groupes de volumes, de monter des systèmes de fichiers ou de démarrer des bases de données et des applications sont facilement automatisables.</block>
  <block id="b1a175c5f42da29f6c27f4ea29684b63" category="paragraph">Il faut veiller à ce que l'environnement de reprise d'activité soit à jour. Par exemple, de nouvelles LUN sont susceptibles d'être ajoutées au serveur source, ce qui signifie que les nouvelles LUN doivent être prédécouvertes sur la destination pour s'assurer que le plan de reprise sur incident fonctionne comme prévu.</block>
  <block id="90426ba53f908049843b3ea392578d04" category="doc">Reprise sur incident Oracle</block>
  <block id="2a4fa9d9434561574119e3086112023f" category="paragraph">La protection des fichiers de données, des journaux d'archivage, des journaux de reprise et des fichiers de contrôle avec un seul snapshot constitue une méthode valide de sauvegarde, de restauration et de réplication.  Toutefois, le RPO est limité au point de la sauvegarde elle-même. Il convient pour un RPO d'une heure ou plus. Si une base de données s'étend sur plusieurs volumes, vous devez créer des snapshots de groupe de cohérence à l'aide de l'un des outils évoqués précédemment.</block>
  <block id="93310f4cebc752304c164f00d67e0bca" category="paragraph">Par exemple, l'ensemble de la base de données peut se trouver dans un seul volume avec la planification de snapshots suivante :</block>
  <block id="a33821be4b3522d65daed1ec317299f6" category="list-text">72 snapshots par heure</block>
  <block id="0eea0679ac7bf43c19d603cd78e81de9" category="list-text">30 snapshots de nuit</block>
  <block id="c4546c401776d279c5577011584577fa" category="list-text">12 snapshots mensuels</block>
  <block id="b63db1b650d128c342617b377baf928a" category="paragraph">Vous bénéficiez ainsi d'un RPO d'une heure sur la période de roulement des 72 heures précédentes, ainsi que de sauvegardes supplémentaires nocturnes et mensuelles. Il est également possible d'inclure plusieurs bases de données ou fichiers d'application dans le volume unique ou l'ensemble de copies Snapshot de groupe de cohérence afin d'assurer des sauvegardes cohérentes dans un environnement plus vaste.</block>
  <block id="686540783626106489734a1990d4930d" category="paragraph">ONTAP est conçu pour offrir une disponibilité maximale des bases de données Oracle. Ce document ne contient pas de description complète des fonctionnalités de haute disponibilité de ONTAP. Cependant, comme pour la protection des données, il est important de bien comprendre cette fonctionnalité lors de la conception d'une infrastructure de base de données.</block>
  <block id="b049fcbe8198301adc6bf87634a02845" category="section-title">Paires HA</block>
  <block id="1a7c11d1e2d03d3d1b57cff284ebd761" category="paragraph">L'unité de base de la haute disponibilité est la paire haute disponibilité. Chaque paire contient des liens redondants pour prendre en charge la réplication des données vers la mémoire NVRAM. La NVRAM n'est pas un cache d'écriture. La RAM à l'intérieur du contrôleur sert de cache d'écriture. L'objectif de la mémoire NVRAM est de journaliser temporairement les données afin de prévenir toute panne système inattendue. À cet égard, il est similaire à un fichier redo log de base de données.</block>
  <block id="cd2e54027dfcfeddd07ddd580db527c0" category="paragraph">La mémoire NVRAM et le journal de reprise de base de données sont utilisés pour stocker des données rapidement, ce qui permet d'y apporter les modifications le plus rapidement possible. La mise à jour des données persistantes sur les disques (ou fichiers de données) n'a lieu qu'une fois plus tard lors d'un processus appelé point de contrôle sur ONTAP et la plupart des plateformes de bases de données. Les données NVRAM et les redo logs de base de données ne sont pas lus pendant les opérations normales.</block>
  <block id="4e044ec0c36e513506c77c0a97d53539" category="paragraph">Si un contrôleur tombe en panne brusquement, des modifications sont susceptibles d'être en attente de stockage dans la mémoire NVRAM qui n'ont pas encore été écrites sur les disques. Le contrôleur partenaire détecte la panne, prend le contrôle des disques et applique les modifications requises qui ont été stockées dans la mémoire NVRAM.</block>
  <block id="310e46747ebab6a43d5a15998f6e2b33" category="section-title">Takeover et Giveback</block>
  <block id="1d739263e44469ad28f77fe7329fa78d" category="paragraph">Le basculement et le rétablissement font référence au processus de transfert de la responsabilité des ressources de stockage entre les nœuds d'une paire HA. Le basculement et le rétablissement sont deux aspects :</block>
  <block id="f2d43d90397aa8140414437eda14febb" category="list-text">Gestion de la connectivité réseau permettant l'accès aux lecteurs</block>
  <block id="6e1c794c81468e3286a23138460bb3fb" category="list-text">Gestion des disques eux-mêmes</block>
  <block id="89d3f6c60c53a11e16a6756bde03ca00" category="paragraph">Les interfaces réseau prenant en charge le trafic CIFS et NFS sont configurées avec un emplacement de home et de basculement. Il inclut le déplacement des interfaces réseau vers leur domicile temporaire sur une interface physique située sur le(s) même(s) sous-réseau que l'emplacement d'origine. Le rétablissement inclut le déplacement des interfaces réseau vers leurs emplacements d'origine. Le comportement exact peut être réglé selon les besoins.</block>
  <block id="108018656caf59cc565f1172047dab38" category="paragraph">Les interfaces réseau prenant en charge les protocoles de bloc SAN, tels que iSCSI et FC, ne sont pas déplacées pendant le basculement et le rétablissement. Les LUN doivent plutôt être provisionnées avec des chemins qui incluent une paire HA complète entraînant un chemin principal et un chemin secondaire.</block>
  <block id="80795d5dd590e432b4f5945aba47caf4" category="admonition">Des chemins d'accès supplémentaires vers des contrôleurs supplémentaires peuvent également être configurés pour prendre en charge le déplacement des données entre les nœuds d'un cluster plus grand, mais cela ne fait pas partie du processus de haute disponibilité.</block>
  <block id="aae63904d16fd1c522dc5ff53eb695b5" category="paragraph">Le deuxième aspect du Takeover et Giveback est le transfert de la propriété de disque. Le processus exact dépend de plusieurs facteurs, notamment la raison du Takeover/Giveback et les options de ligne de commande émises. L'objectif est de réaliser l'opération aussi efficacement que possible. Bien que le processus global puisse sembler durer plusieurs minutes, le moment réel où la propriété du disque est transférée d'un nœud à un autre peut généralement se mesurer en secondes.</block>
  <block id="61775b9e8f759f26eafd6b03448d1f30" category="section-title">Temps de reprise</block>
  <block id="3224b51e62790c4ce988d8c1876fb36e" category="paragraph">Les E/S de l'hôte font l'objet d'une courte pause au niveau des E/S lors des opérations de basculement et de rétablissement. Cependant, la configuration de l'environnement ne doit pas provoquer d'interruption des applications. Le processus de transition réel dans lequel les E/S sont retardées se mesure généralement en secondes, mais l'hôte peut avoir besoin de plus de temps pour reconnaître la modification des chemins de données et renvoyer les opérations d'E/S.</block>
  <block id="40f291752a9848bfecb7264cfd9aa8ee" category="paragraph">La nature de la perturbation dépend du protocole :</block>
  <block id="cb44db7841f8fb68230a260c4c68bfe0" category="list-text">Une interface réseau prenant en charge le trafic NFS et CIFS émet une requête ARP (Address Resolution Protocol) vers le réseau après la transition vers un nouvel emplacement physique. Les commutateurs réseau mettent ainsi à jour leurs tables d'adresses MAC (Media Access Control) et reprennent le traitement des E/S. L'interruption dans le cas d'un basculement et d'un rétablissement planifiés se mesure généralement en secondes et, dans la plupart des cas, elle n'est pas détectable. Certains réseaux peuvent être plus lents à reconnaître pleinement le changement de chemin réseau et certains systèmes d'exploitation peuvent mettre en file d'attente beaucoup d'E/S dans un délai très court qui doit être réessayé. Cela peut prolonger le temps nécessaire pour reprendre les E/S.</block>
  <block id="6a410522094e0b0f874dab5784e81ab8" category="list-text">Une interface réseau prenant en charge les protocoles SAN ne peut pas être mise à niveau vers un nouvel emplacement. Un système d'exploitation hôte doit modifier le ou les chemins utilisés. La pause des E/S observée par l'hôte dépend de plusieurs facteurs. Du point de vue du système de stockage, la période pendant laquelle les E/S ne peuvent pas être servies ne prend que quelques secondes. Cependant, des systèmes d'exploitation hôtes différents peuvent nécessiter plus de temps pour permettre à une E/S de se déconnecter avant de réessayer. Les systèmes d'exploitation les plus récents sont mieux à même de reconnaître un changement de chemin beaucoup plus rapidement, mais les systèmes d'exploitation plus anciens nécessitent généralement jusqu'à 30 secondes pour reconnaître un changement.</block>
  <block id="cabc4f9cda7d4bfb99181166c863a374" category="paragraph">Les délais de basculement attendus lors desquels le système de stockage ne peut pas transmettre de données à un environnement applicatif sont indiqués dans le tableau ci-dessous. Aucun environnement applicatif ne doit contenir d'erreurs ; le basculement doit alors apparaître sous forme de courte pause dans le traitement des E/S.</block>
  <block id="c8984126713ed072b9cb0a44a162be4d" category="cell">AFF</block>
  <block id="b7b46ce5d1a547db89c0bc615ff272a5" category="cell">ASA</block>
  <block id="ed3467fac861f6a32cd66093ac415805" category="cell">Basculement planifié</block>
  <block id="57a915dfa0e8469b25c1b8b947f7ee2c" category="cell">15 s</block>
  <block id="cd5dce62294e9a79e9c2165ee0903f5f" category="cell">6-10 s</block>
  <block id="cbfdbb11fd5eab0d9fdd078ae66a1c69" category="cell">2-3 s</block>
  <block id="1a066f0304c1d3a279466c70359c5103" category="cell">Basculement non planifié</block>
  <block id="0f4a6e109a34d3483995e427b6581130" category="cell">30 s</block>
  <block id="dbfb054670bc82c6e08a7e101c0f0ef4" category="paragraph">La protection logique des données dans ONTAP comprend trois exigences clés :</block>
  <block id="b6cc6762545d78ab663e39c37d172bd2" category="list-text">Les données doivent être protégées contre la corruption.</block>
  <block id="e7c7e14f4b6ca1b3ae32b2279243dba6" category="list-text">Les données doivent être protégées contre les pannes disques.</block>
  <block id="1168469b387027a850496f6cac9f3529" category="list-text">Les modifications de données doivent être protégées contre la perte.</block>
  <block id="864a6ca5da4b36656beba11c90f4c4e5" category="paragraph">Ces trois besoins sont abordés dans les sections suivantes.</block>
  <block id="a05b54004946aa523bfe7c1e92a52f52" category="section-title">Corruption du réseau : checksums</block>
  <block id="ed95581a613a4f19be367c10cd063cc2" category="paragraph">Le niveau de protection de données le plus élémentaire est la somme de contrôle, qui est un code spécial de détection d'erreur stocké avec les données. La corruption des données lors de la transmission du réseau est détectée grâce à l'utilisation d'un checksum et, dans certains cas, de multiples checksums.</block>
  <block id="c1343e51090396cf011509389bc0adab" category="paragraph">Par exemple, une trame FC inclut une forme de somme de contrôle appelée contrôle de redondance cyclique (CRC) pour s'assurer que la charge utile n'est pas corrompue en transit. L'émetteur envoie les données et le CRC des données. Le récepteur d'une trame FC recalcule le CRC des données reçues pour s'assurer qu'il correspond au CRC transmis. Si le nouveau CRC calculé ne correspond pas au CRC joint à la trame, les données sont corrompues et la trame FC est supprimée ou rejetée. Une opération d'E/S iSCSI comprend des checksums au niveau des couches TCP/IP et Ethernet. Pour une protection supplémentaire, elle peut également inclure la protection CRC facultative au niveau de la couche SCSI. Toute corruption de bit sur le fil est détectée par la couche TCP ou la couche IP, ce qui entraîne la retransmission du paquet. Comme avec FC, les erreurs dans le CRC SCSI entraînent une suppression ou un rejet de l'opération.</block>
  <block id="1f08639c540e47068c16c3ac48ea7bbe" category="section-title">Corruption de disque : checksums</block>
  <block id="c5d50bc8d916a4b26166bbda091cd6d4" category="paragraph">Des checksums sont également utilisés pour vérifier l'intégrité des données stockées sur les disques. Les blocs de données écrits sur les disques sont stockés avec une fonction de checksum qui génère un nombre imprévisible lié aux données d'origine. Lorsque les données sont lues à partir du lecteur, la somme de contrôle est recalculée et comparée à la somme de contrôle stockée. Si elle ne correspond pas, les données sont corrompues et doivent être restaurées par la couche RAID.</block>
  <block id="8edc44db01815f20f6508db8b5630cfe" category="section-title">Corruption des données : écritures perdues</block>
  <block id="972eab86b2aecd693914feabc5a3b65c" category="paragraph">L'un des types de corruption les plus difficiles à détecter est une écriture perdue ou mal placée. Lorsqu'une écriture est reconnue, elle doit être écrite sur le support à l'emplacement correct. La corruption des données sur place est relativement facile à détecter à l'aide d'une simple somme de contrôle stockée avec les données. Cependant, si l'écriture est simplement perdue, alors la version précédente des données peut toujours exister et le total de contrôle serait correct. Si l'écriture est placée au mauvais emplacement physique, la somme de contrôle associée sera à nouveau valide pour les données stockées, même si l'écriture a détruit d'autres données.</block>
  <block id="53830741c46fbc560962b086f582e79a" category="paragraph">La solution à ce défi est la suivante :</block>
  <block id="656d064400822ca2ffb25f52c9fc95db" category="list-text">Une opération d'écriture doit inclure des métadonnées indiquant l'emplacement où l'écriture est attendue.</block>
  <block id="37a60b1c7392a26270880a361f85db55" category="list-text">Une opération d'écriture doit inclure une sorte d'identifiant de version.</block>
  <block id="4275b2e68761baa23b112833facf4ca1" category="paragraph">Lorsque ONTAP écrit un bloc, il inclut les données à l'emplacement où ce bloc appartient. Si une lecture ultérieure identifie un bloc, mais que les métadonnées indiquent qu'il appartient à l'emplacement 123 lorsqu'il a été trouvé à l'emplacement 456, l'écriture a été déplacée.</block>
  <block id="009b13bf07c7db21c1e4769526e60694" category="paragraph">Il est plus difficile de détecter une écriture entièrement perdue. L'explication est très complexe, mais ONTAP stocke les métadonnées de façon à ce qu'une opération d'écriture entraîne des mises à jour vers deux emplacements différents sur les disques. En cas de perte d'une écriture, une lecture ultérieure des données et des métadonnées associées affiche deux identités de version différentes. Cela indique que l'écriture n'a pas été effectuée par le lecteur.</block>
  <block id="3b04a99c209a31ad69e7865ea94e5c94" category="paragraph">La corruption des écritures perdues ou déplacées est extrêmement rare. Cependant, avec la croissance continue des disques et l'expansion des jeux de données en exaoctets, le risque augmente. La détection des pertes en écriture doit être incluse dans tout système de stockage prenant en charge les charges de travail de la base de données.</block>
  <block id="e978ccc010ec4d37148d52e2fbf439dd" category="section-title">Panne de disque : RAID, RAID DP et RAID-TEC</block>
  <block id="a9fffaaf2b1b518afb56ef273736c0c2" category="paragraph">Si un bloc de données sur un disque est détecté comme étant corrompu, ou si l'ensemble du disque tombe en panne et est totalement indisponible, les données doivent être reconstituées. Cette opération est réalisée dans ONTAP à l'aide de disques de parité. Les données sont réparties sur plusieurs disques, puis des données de parité sont générées. Ces données sont stockées séparément des données d'origine.</block>
  <block id="54abdf00b7122c16619266482eb09f43" category="paragraph">ONTAP utilisait à l'origine RAID 4, qui utilise un seul lecteur de parité pour chaque groupe de lecteurs de données. Le résultat a été qu'un disque du groupe pouvait tomber en panne sans entraîner de perte de données. En cas de panne du disque de parité, aucune donnée n'a été endommagée et un nouveau disque de parité a pu être construit. En cas de panne d'un seul lecteur de données, les lecteurs restants peuvent être utilisés avec le lecteur de parité pour régénérer les données manquantes.</block>
  <block id="6d1ccb512ce2b25e53d90e6d8d459e18" category="paragraph">Lorsque les disques étaient petits, le risque statistique de défaillance simultanée de deux disques était négligeable. Avec l'augmentation des capacités des disques, la reconstruction des données suite à une panne disque s'est également accompagnée d'un temps considérable. Cela a augmenté la fenêtre au cours de laquelle une panne de second disque entraînerait la perte de données. De plus, le processus de reconstruction crée une grande quantité d'E/S supplémentaires sur les disques survivants. Au fur et à mesure du vieillissement des disques, le risque d'une charge supplémentaire entraînant une panne de second disque augmente également. Enfin, même si le risque de perte de données n'augmente pas avec l'utilisation continue de RAID 4, les conséquences de la perte de données deviendront plus graves. Plus la perte de données en cas de panne d'un groupe RAID est importante, plus la restauration des données est longue, ce qui entraîne une interruption de l'activité prolongée.</block>
  <block id="caef9e75bcd55d5a9a4ec855b5a6385c" category="paragraph">Ces problèmes ont conduit NetApp à développer la technologie NetApp RAID DP, une variante de RAID 6. Cette solution comprend deux disques de parité, ce qui signifie que deux disques d'un groupe RAID peuvent tomber en panne sans générer de perte de données. Les disques ont continué de croître en taille, ce qui a conduit NetApp à développer la technologie NetApp RAID-TEC, qui introduit un troisième disque de parité.</block>
  <block id="704c2697ee323569003b7b7ea203ae0f" category="paragraph">Certaines meilleures pratiques en matière de bases de données historiques recommandent l'utilisation de RAID-10, également appelée mise en miroir par bandes. Cela offre une protection des données inférieure à celle de RAID DP, car il existe plusieurs scénarios de défaillance de deux disques, alors que dans RAID DP, il n'en existe aucune.</block>
  <block id="3d0147402d7506d1d3a5227fe447427a" category="paragraph">Par ailleurs, certaines bonnes pratiques en matière d'historique de bases de données indiquent que RAID-10 est préféré aux options RAID-4/5/6 en raison de problèmes de performances. Ces recommandations font parfois référence à une pénalité RAID. Bien que ces recommandations soient généralement correctes, elles ne s'appliquent pas aux implémentations de RAID dans ONTAP. Le problème de performances est lié à la régénération de parité. Dans les implémentations RAID traditionnelles, le traitement des écritures aléatoires de routine effectuées par une base de données nécessite plusieurs lectures de disque pour régénérer les données de parité et terminer l'écriture. La pénalité est définie comme les IOPS de lecture supplémentaires requises pour exécuter les opérations d'écriture.</block>
  <block id="84ff015d2df40fc0ebb34485173f39e4" category="paragraph">ONTAP n'engendre pas de pénalité RAID, car les écritures sont placées dans la mémoire où la parité est générée, puis écrites sur le disque sous la forme d'une seule bande RAID. Aucune lecture n'est requise pour terminer l'opération d'écriture.</block>
  <block id="b7fe11ecbd8b434a231195335b4894ac" category="paragraph">En résumé, par rapport à RAID 10, les systèmes RAID DP et RAID-TEC fournissent une capacité utilisable nettement plus importante, une meilleure protection contre les pannes disque et sans sacrifier les performances.</block>
  <block id="e5e0dc0629a299f8e56ebe7de38f49f9" category="section-title">Protection contre les pannes matérielles : NVRAM</block>
  <block id="1db5fde40e489d805029f9d5be6375e7" category="paragraph">Toute baie de stockage servant de charge de travail de base de données doit traiter les opérations d'écriture le plus rapidement possible. En outre, une opération d'écriture doit être protégée contre la perte d'un événement inattendu tel qu'une coupure de courant. Cela signifie que toute opération d'écriture doit être stockée en toute sécurité dans au moins deux emplacements.</block>
  <block id="ff540b857af868ec85f8f53ddc1f1bd1" category="paragraph">Les systèmes AFF et FAS utilisent la mémoire NVRAM pour répondre à ces exigences. Le processus d'écriture fonctionne comme suit :</block>
  <block id="049f2df0de743a6be8d3ec69864f234a" category="list-text">Les données d'écriture entrantes sont stockées dans la mémoire RAM.</block>
  <block id="976be2293c2f4499d079224003644acf" category="list-text">Les modifications à apporter aux données du disque sont journalisées dans la mémoire NVRAM sur le nœud local et le nœud partenaire. La mémoire NVRAM n'est pas un cache d'écriture. Il s'agit plutôt d'un journal similaire à un redo log de base de données. Dans des conditions normales, il n'est pas lu. Il est utilisé uniquement pour la restauration, par exemple après une coupure de courant pendant le traitement des E/S.</block>
  <block id="8ae87ed4a421bec56e020cd0e83bd748" category="list-text">L'écriture est alors validée par l'hôte.</block>
  <block id="3a7682bcbb490353074b5ee69e18f01c" category="paragraph">À ce stade, le processus d'écriture est complet du point de vue de l'application. Les données sont protégées contre les pertes, car elles sont stockées dans deux emplacements différents. Finalement, les modifications sont écrites sur le disque, mais ce processus est hors bande du point de vue de l'application, car il se produit après l'acquittement de l'écriture et n'affecte donc pas la latence. Ce processus est une fois de plus similaire à la journalisation de la base de données. Une modification de la base de données est enregistrée dans les journaux de reprise aussi rapidement que possible, et la modification est alors reconnue comme validée. Les mises à jour des fichiers de données sont effectuées beaucoup plus tard et n'affectent pas directement la vitesse de traitement.</block>
  <block id="c17f09622da5f1e0064f7b6a65cb8b01" category="paragraph">En cas de panne de contrôleur, le contrôleur partenaire prend possession des disques requis et lit à nouveau les données consignées dans la mémoire NVRAM pour récupérer toutes les opérations d'E/S en cours de fonctionnement au moment de la défaillance.</block>
  <block id="24e6592d53b3bd56ed8827d2f51bb1ab" category="section-title">Protection contre les défaillances matérielles : NVFAIL</block>
  <block id="7965eb54acae120d25d0c77b012b8f90" category="paragraph">Comme nous l'avons vu précédemment, une écriture n'est pas validée tant qu'elle n'a pas été connectée à la NVRAM et à la NVRAM locales sur au moins un autre contrôleur. Cette approche évite toute panne matérielle ou de courant qui entraîne une perte des E/S à la volée En cas de panne de la mémoire NVRAM locale ou de la connectivité au partenaire de haute disponibilité, ces données à la volée ne seront plus mises en miroir.</block>
  <block id="307b6d3e63c12ada7fbcf75cdda0b574" category="paragraph">Si la mémoire NVRAM locale signale une erreur, le nœud s'arrête. Cet arrêt entraîne le basculement vers un contrôleur partenaire de haute disponibilité. Aucune donnée n'est perdue parce que le contrôleur qui connaît la défaillance n'a pas acquitté l'opération d'écriture.</block>
  <block id="6e0c6c8fe69a50581a4ac18acb2c04dd" category="paragraph">ONTAP n'autorise pas le basculement lorsque les données sont désynchronisées, sauf si le basculement est forcé. Le fait de forcer une modification des conditions de cette manière reconnaît que les données peuvent être laissées pour compte dans le contrôleur d'origine et que la perte de données est acceptable.</block>
  <block id="a3961862ed464a06ef6fa4e23935fef2" category="paragraph">Les bases de données sont particulièrement vulnérables à la corruption en cas de basculement forcé, car elles conservent de grands caches internes de données sur disque. En cas de basculement forcé, les modifications précédemment reconnues sont effectivement supprimées. Le contenu de la baie de stockage recule dans le temps et l'état du cache de la base de données ne reflète plus l'état des données sur le disque.</block>
  <block id="b46ce3019d702ee3ece327e5df990be0" category="paragraph">Afin de protéger les données de cette situation, ONTAP permet de configurer les volumes pour une protection spéciale contre les défaillances de mémoire NVRAM. Lorsqu'il est déclenché, ce mécanisme de protection entraîne l'entrée d'un volume dans un état appelé NVFAIL. Cet état entraîne des erreurs d'E/S qui entraînent l'arrêt d'une application et n'utilisent donc pas de données obsolètes. Les données ne doivent pas être perdues car une écriture reconnue doit être présente sur la matrice de stockage.</block>
  <block id="322e1f85910dfc206274f8bd58a54a9d" category="list-text">Chaque jeu de disques d'un site donné est automatiquement configuré comme un ou plusieurs groupes RAID-DP ou RAID-TEC entièrement redondants, indépendamment de l'utilisation de la mise en miroir. Les données sont ainsi protégées en permanence, même après la perte d'un site.</block>
  <block id="dee2dfce5ab0c47301b3c12970a57aa6" category="paragraph">La figure ci-dessus illustre un exemple de configuration SyncMirror. Un agrégat de 24 disques a été créé sur le contrôleur avec 12 disques à partir d'un tiroir alloué sur le site A et 12 disques à partir d'un tiroir alloué sur le site B. Les disques ont été regroupés en deux groupes RAID en miroir. Le groupe RAID 0 comprend un plex de 6 disques sur le site A mis en miroir sur un plex de 6 disques sur le site B. De même, RAID Group 1 inclut un plex de 6 disques sur le site A mis en miroir sur un plex de 6 disques sur le site B.</block>
  <block id="4fbc0abe91c0c1381d0a742f58b4e537" category="paragraph">SyncMirror est généralement utilisé pour assurer la mise en miroir à distance avec les systèmes MetroCluster, avec une copie des données sur chaque site. Il a parfois été utilisé pour fournir un niveau supplémentaire de redondance dans un seul système. Il assure en particulier la redondance au niveau du tiroir. Un tiroir disque contient déjà deux blocs d'alimentation et contrôleurs. Dans l'ensemble, il ne s'agit pas d'une simple tôlerie, mais dans certains cas, une protection supplémentaire peut être garantie. Par exemple, un client NetApp a déployé SyncMirror sur une plateforme mobile d'analytique en temps réel utilisée lors des tests automobiles. Le système a été séparé en deux racks physiques alimentés par des alimentations indépendantes provenant de systèmes UPS indépendants.</block>
  <block id="0cac56685de94a3ef0e1fd2bfca0c112" category="paragraph">Le thème des checksums est particulièrement intéressant pour les administrateurs de bases de données habitués à l'utilisation de sauvegardes en continu Oracle RMAN qui migrent vers des sauvegardes basées sur des snapshots. RMAN permet notamment de procéder à des contrôles d'intégrité lors des opérations de sauvegarde. Bien que cette fonctionnalité présente un certain intérêt, son principal avantage est une base de données qui n'est pas utilisée sur une baie de stockage moderne. Lorsque des disques physiques sont utilisés pour une base de données Oracle, il est presque certain que la corruption finit par se produire lorsque les disques vieillissent, un problème qui est résolu par les checksums basés sur les baies dans les baies de stockage réelles.</block>
  <block id="8b7b33533c2b36c157a0a482bdd52a8e" category="paragraph">L'architecture des fichiers de données et des redo log Oracle est également conçue pour offrir le plus haut niveau possible d'intégrité des données, même dans des circonstances extrêmes. Au niveau le plus élémentaire, les blocs Oracle incluent un checksum et des contrôles logiques de base avec presque toutes les E/S. Si Oracle ne s'est pas écrasé ou n'a pas mis un tablespace hors ligne, les données sont intactes. Le degré de vérification de l'intégrité des données est réglable et Oracle peut également être configuré pour confirmer les écritures. Par conséquent, la quasi-totalité des scénarios de panne et de panne peuvent être restaurés, et dans le cas extrêmement rare d'une situation irrécupérable, la corruption est rapidement détectée.</block>
  <block id="4066c36b811913c85aa86346e30cee4d" category="paragraph">La plupart des clients NetApp qui utilisent des bases de données Oracle cessent d'utiliser RMAN et d'autres produits de sauvegarde après la migration vers des sauvegardes snapshot. Il existe encore des options permettant d'utiliser RMAN pour effectuer une restauration au niveau des blocs avec SnapCenter. Toutefois, au quotidien, RMAN, NetBackup et d'autres produits ne sont utilisés qu'occasionnellement pour créer des copies d'archivage mensuelles ou trimestrielles.</block>
  <block id="d0cf0e689669c61d564607d2ef7deb79" category="paragraph">Certains clients choisissent d'exécuter<block ref="d308cbfce7e270e5b41a84d84385645f" prefix=" " category="inline-code"></block> périodiquement pour effectuer des contrôles d'intégrité sur leurs bases de données existantes. NetApp déconseille cette pratique, car elle entraîne une charge d'E/S inutile. Comme indiqué ci-dessus, si la base de données ne rencontrait pas de problèmes auparavant, le risque de<block ref="d308cbfce7e270e5b41a84d84385645f" prefix=" " category="inline-code"></block> La détection d'un problème est proche de zéro et cet utilitaire entraîne une charge d'E/S séquentielles très élevée sur le réseau et le système de stockage. À moins qu'il n'y ait de raison de croire qu'il existe une corruption, comme l'exposition à un bogue connu d'Oracle, il n'y a aucune raison de s'exécuter<block ref="d308cbfce7e270e5b41a84d84385645f" prefix=" " category="inline-code"></block>.</block>
  <block id="431bbcf828b8d3513280cb1207824991" category="doc">Sauvegardes optimisées pour Oracle Storage Snapshot</block>
  <block id="c9447fe684870cf68e9cb4f23f44db43" category="paragraph">Les administrateurs de bases de données maîtrisent mieux la procédure de restauration à partir d'une sauvegarde à chaud, mais il est depuis longtemps possible d'utiliser des snapshots qui n'ont pas été créés pendant que la base de données était en mode de sauvegarde à chaud. Pour assurer la cohérence de la base de données, des étapes manuelles supplémentaires ont été nécessaires avec Oracle 10g et 11g. Avec Oracle 12c,<block ref="a84f4f3da79386c29ab6dfa560af786e" prefix=" " category="inline-code"></block> et<block ref="075b7d3bd3bbe7767f7ef62f430bc22b" prefix=" " category="inline-code"></block> contiennent la logique supplémentaire permettant de relire les journaux d'archivage sur des sauvegardes de fichiers de données qui n'étaient pas en mode de sauvegarde à chaud.</block>
  <block id="5c7dba68615d3fa5c4c90a36dab57bcb" category="paragraph">Comme nous l'avons vu précédemment, la restauration d'une sauvegarde à chaud basée sur des snapshots nécessite deux jeux de données :</block>
  <block id="50a7086972cada154c8164dc1c6b3539" category="list-text">Un Snapshot des fichiers de données créés en mode de sauvegarde</block>
  <block id="c72d009669a638aab75c21a28a2101de" category="list-text">Les journaux d'archivage générés pendant que les fichiers de données étaient en mode de sauvegarde à chaud</block>
  <block id="b8de4b1201e5595bc3de878f2bf59d9b" category="paragraph">Lors de la restauration, la base de données lit les métadonnées à partir des fichiers de données pour sélectionner les journaux d'archivage requis à des fins de restauration.</block>
  <block id="66ee0a6fd90f3cfab8320e1de1341cbd" category="paragraph">La restauration optimisée pour les snapshots de stockage nécessite des jeux de données légèrement différents pour obtenir les mêmes résultats :</block>
  <block id="6030a1d9761fca3806ef0a0329438071" category="list-text">Un Snapshot des fichiers de données et une méthode d'identification de l'heure de création du Snapshot</block>
  <block id="4e822d4c19600b654f176d335c158829" category="list-text">Archiver les journaux à partir de l'heure du point de contrôle du fichier de données le plus récent jusqu'à l'heure exacte du snapshot</block>
  <block id="604432b50055c69f34df17a8ed5befb5" category="paragraph">Lors de la restauration, la base de données lit les métadonnées à partir des fichiers de données pour identifier le premier journal d'archivage requis. Il est possible d'effectuer une restauration complète ou instantanée. Lors de l'exécution d'une restauration à un point dans le temps, il est essentiel d'connaître l'heure du Snapshot des fichiers de données. Le point de restauration spécifié doit être après l'heure de création des snapshots. NetApp recommande d'ajouter au moins quelques minutes à l'heure du snapshot pour tenir compte des variations d'horloge.</block>
  <block id="08bfe39c49a2dc07b08bd2ccd77d8281" category="paragraph">Pour plus de détails, consultez la documentation d'Oracle sur la rubrique « Restauration à l'aide de l'optimisation des snapshots de stockage » disponible dans les différentes versions de la documentation d'Oracle 12c. Consultez également le document Oracle document ID Doc ID 604683.1 concernant la prise en charge des snapshots tiers par Oracle.</block>
  <block id="d22a890163762fcf7a4cb7605c29b7e6" category="section-title">Disposition des données</block>
  <block id="6a7fc1f74262f6973420f4fc849ba7f7" category="paragraph">La disposition la plus simple consiste à isoler les fichiers de données dans un ou plusieurs volumes dédiés. Ils doivent être non contaminés par tout autre type de fichier. Cela permet de s'assurer que les volumes de fichiers de données peuvent être rapidement restaurés lors d'une opération SnapRestore sans détruire un journal de reprise, un fichier de contrôle ou un journal d'archivage important.</block>
  <block id="ff6fb5d2136ab516e182f4b23f45886d" category="paragraph">LE SYSTÈME SAN présente des exigences similaires en matière d'isolation des fichiers de données dans des volumes dédiés. Avec un système d'exploitation tel que Microsoft Windows, un seul volume peut contenir plusieurs LUN de fichiers de données, chacune avec un système de fichiers NTFS. Avec d'autres systèmes d'exploitation, il existe généralement un gestionnaire de volumes logiques. Par exemple, avec Oracle ASM, l'option la plus simple consiste à limiter les groupes de disques à un volume unique pouvant être sauvegardé et restauré comme une unité. Si des volumes supplémentaires sont nécessaires pour des raisons de performance ou de gestion de la capacité, la création d'un groupe de disques supplémentaire sur le nouveau volume simplifie la gestion.</block>
  <block id="a06956ba6de69aec2dc2b015074e5821" category="paragraph">Si ces instructions sont respectées, les snapshots peuvent être planifiés directement sur ONTAP sans avoir à créer de snapshot de groupe de cohérence. En effet, les sauvegardes optimisées pour les snapshots ne nécessitent pas la sauvegarde simultanée de fichiers de données.</block>
  <block id="9e422c12420f1bd8c73e3c0f63da55e9" category="paragraph">Une complication se produit dans des situations telles qu'un groupe de disques ASM distribué sur des volumes. Dans ce cas, un snapshot de groupe de cohérence doit être réalisé pour s'assurer que les métadonnées ASM sont cohérentes sur tous les volumes constitutifs.</block>
  <block id="7a7969d6a47ed242c25f6a38f2da0e36" category="paragraph">[Remarque]Vérifiez que les fichiers spfile et passwd ASM ne se trouvent pas dans le groupe de disques hébergeant les fichiers de données. Cela interfère avec la capacité à restaurer de manière sélective les fichiers de données et uniquement les fichiers de données.</block>
  <block id="12eb3ceede91a01c74368e0fab03dbe4" category="section-title">Procédure de restauration locale : NFS</block>
  <block id="e1a03fcc478ae212f07b5044b11ff369" category="paragraph">Cette procédure peut être conduite manuellement ou via une application telle que SnapCenter. La procédure de base est la suivante :</block>
  <block id="abb0083d6ab87bbe9d906632fea121ae" category="list-text">Restaurez le ou les volumes de fichiers de données sur l'instantané immédiatement avant le point de restauration souhaité.</block>
  <block id="3450fe1e1eea00fa55cfb5cb835a3d80" category="paragraph">Cette procédure suppose que les journaux d'archive souhaités sont toujours présents dans le système de fichiers actif. Si ce n'est pas le cas, les journaux d'archive doivent être restaurés, ou<block ref="075b7d3bd3bbe7767f7ef62f430bc22b" prefix=" " category="inline-code"></block> ou<block ref="a84f4f3da79386c29ab6dfa560af786e" prefix=" " category="inline-code"></block> peut être dirigé vers les données dans le<block ref="a15da8cecb1f1192c4d913b8ba676121" prefix=" " category="inline-code"></block> répertoire.</block>
  <block id="e43e33171833b26f6b024d28cb8b1afd" category="paragraph">En outre, dans le cas de bases de données plus petites, l'utilisateur peut restaurer les fichiers de données directement à partir du système<block ref="a15da8cecb1f1192c4d913b8ba676121" prefix=" " category="inline-code"></block> Répertoire n'ayant pas besoin des outils d'automatisation ou d'un administrateur du stockage pour exécuter une commande SnapRestore.</block>
  <block id="097230f6ad5345abbe261eabbf533a68" category="section-title">Procédure de restauration locale—SAN</block>
  <block id="4e3110543ebf2a771c16b3b2101f1f88" category="list-text">Arrêter le ou les groupes de disques hébergeant les fichiers de données. La procédure varie en fonction du gestionnaire de volumes logiques choisi. Avec ASM, le processus nécessite de démonter le groupe de disques. Sous Linux, les systèmes de fichiers doivent être démontés et les volumes logiques et les groupes de volumes désactivés. L'objectif est d'arrêter toutes les mises à jour du groupe de volumes cible à restaurer.</block>
  <block id="1d0ecd206531f96737f8e8002be4a047" category="list-text">Restaurez les groupes de disques de fichiers de données sur l'instantané immédiatement avant le point de restauration souhaité.</block>
  <block id="946fe41f610ab658e270a1844c992bcc" category="list-text">Réactivez les groupes de disques récemment restaurés.</block>
  <block id="c21d8f41541fc2a0259e7ea5e51edac3" category="paragraph">Cette procédure suppose que les journaux d'archive souhaités sont toujours présents dans le système de fichiers actif. Si ce n'est pas le cas, les journaux d'archivage doivent être restaurés en mettant les LUN du journal d'archivage hors ligne et en effectuant une restauration. Il s'agit également d'un exemple dans lequel il est utile de diviser les journaux d'archivage en volumes dédiés. Si les journaux d'archivage partagent un groupe de volumes avec les journaux de reprise, les journaux de reprise doivent être copiés ailleurs avant la restauration de l'ensemble global de LUN afin d'éviter de perdre les transactions enregistrées finales.</block>
  <block id="3fd5b2a08b3d7c4db29da8590ef6013f" category="section-title">Exemple de récupération complète</block>
  <block id="31679daa394b7091acfd728d940b7322" category="paragraph">Supposons que les fichiers de données ont été corrompus ou détruits et qu'une restauration complète est requise. La procédure à suivre est la suivante :</block>
  <block id="aa09ca247daac25fc18c2633124ca9b6" category="section-title">Exemple de restauration instantanée</block>
  <block id="935ff627038d1f5001220c8df7f0e1b9" category="paragraph">Toute la procédure de restauration est une commande unique :<block ref="3df448f0a5ec82cac76d91ba14c0fa1d" prefix=" " category="inline-code"></block>.</block>
  <block id="dcd27cf8b8ceae2cd84c898d3c1b9fdb" category="paragraph">Si une restauration à un point dans le temps est requise, l'horodatage des snapshots doit être connu et peut être identifié comme suit :</block>
  <block id="17108ef3ad2e1e613b844beb5f2c6d29" category="paragraph">L'heure de création de l'instantané est répertoriée comme 9 mars et 10:10:06. Pour être sûr, une minute est ajoutée à l'heure du snapshot :</block>
  <block id="904b0a17b003c70e398ea85996f0f9ba" category="paragraph">La restauration est maintenant lancée. Il a spécifié une heure d'instantané de 10:11:00, une minute après l'heure enregistrée pour tenir compte de la variation d'horloge possible, et un temps de récupération cible de 10:44. Ensuite, sqlplus demande les journaux d'archivage requis pour atteindre le délai de restauration souhaité de 10:44.</block>
  <block id="91f99c5ad04365fb4d00e509963e2a0c" category="admonition">Restauration complète d'une base de données à l'aide de snapshots à l'aide de<block ref="3df448f0a5ec82cac76d91ba14c0fa1d" prefix=" " category="inline-code"></block> la commande ne nécessite pas de licence spécifique, mais une restauration à un point dans le temps via<block ref="72104026d9850e8c478c23b2e2e4e8e9" prefix=" " category="inline-code"></block> Requiert la licence Oracle Advanced compression.</block>
  <block id="9173402b63dc5f55506a692258f185e8" category="doc">SnapCenter et autres outils</block>
  <block id="5459c1727c923baa303ff472498dbe97" category="paragraph">Dans certains cas, une configuration simple de ces fonctionnalités principales directement sur ONTAP répond aux exigences, mais les besoins plus complexes requièrent une couche d'orchestration.</block>
  <block id="aeeb3212c35c26d321183e81d4926e57" category="paragraph">SnapCenter est le produit phare de la protection des données NetApp. À un niveau très bas, il est similaire aux produits SnapManager en termes d'exécution des sauvegardes de base de données, mais il a été conçu dès le départ pour proposer une gestion de la protection des données centralisée sur les systèmes de stockage NetApp.</block>
  <block id="50780f47f6839d47d60bc4555ee00c3f" category="section-title">REPOS</block>
  <block id="a0bac638f30c704da8e03aba136da86d" category="paragraph">ONTAP contient également un jeu d'API RESTful riche. Les fournisseurs tiers peuvent ainsi créer une application de protection des données et de gestion grâce à une intégration étroite avec ONTAP. De plus, l'API RESTful est facile à utiliser par les clients qui souhaitent créer leurs propres workflows et utilitaires d'automatisation.</block>
  <block id="a3b43ae3d4028e3c7ccac3d5720e9fb0" category="paragraph">Deux datasets sont nécessaires pour protéger et restaurer une base de données Oracle en mode de sauvegarde. Notez qu'il ne s'agit pas de la seule option de sauvegarde Oracle, mais qu'elle est la plus courante.</block>
  <block id="8e523970ff7c41dba74e723511d14717" category="list-text">Un Snapshot des fichiers de données en mode de sauvegarde</block>
  <block id="deeddf207b1a29c63ae7c1943f90f3d9" category="list-text">Les journaux d'archivage créés pendant que les fichiers de données étaient en mode de sauvegarde</block>
  <block id="fa1229103a2e02a4ed8790098c98f71f" category="paragraph">Si une récupération complète incluant toutes les transactions validées est requise, un troisième élément est requis :</block>
  <block id="7c11b244c2549a2cc477c134ec4c5635" category="list-text">Les journaux de reprise en cours</block>
  <block id="8522faf14bc9d4ab497945bb48adc870" category="paragraph">Il existe plusieurs façons de restaurer une sauvegarde en ligne. De nombreux clients restaurent les snapshots à l'aide de l'interface de ligne de commande ONTAP, puis à l'aide d'Oracle RMAN ou de sqlplus pour terminer la restauration. Cette approche est particulièrement fréquente dans les environnements de production de grande taille. En effet, la probabilité et la fréquence des restaurations de bases de données sont extrêmement faibles et les restaurations sont gérées par un administrateur de bases de données qualifié. Pour une automatisation totale, des solutions telles que NetApp SnapCenter intègrent un plug-in Oracle avec une ligne de commande et des interfaces graphiques.</block>
  <block id="f88f41d4801183a5d53a4b71f383d144" category="paragraph">Certains grands clients ont adopté une approche plus simple en configurant des scripts de base sur les hôtes afin de placer les bases de données en mode de sauvegarde à un moment spécifique en préparation d'un snapshot planifié. Par exemple, planifiez la commande<block ref="56f72994c4cc84b13a4c20dab49fea35" prefix=" " category="inline-code"></block> à 23:58,<block ref="84c8391d82cbfe300a9615844e0a167f" prefix=" " category="inline-code"></block> à 00:02, puis planifiez les snapshots directement sur le système de stockage à minuit. Résultat : une stratégie de sauvegarde simple et hautement évolutive ne nécessite aucun logiciel ni licence externe.</block>
  <block id="719fbeb74939b8c065321f175de3d222" category="paragraph">La disposition la plus simple consiste à isoler les fichiers de données dans un ou plusieurs volumes dédiés. Ils doivent être non contaminés par tout autre type de fichier. Cela permet de s'assurer que les volumes de fichiers de données peuvent être rapidement restaurés via une opération SnapRestore sans détruire un journal de reprise, un fichier de contrôle ou un journal d'archivage important.</block>
  <block id="19156bdcbf322e8e3189909bbb7a69e8" category="paragraph">LE SYSTÈME SAN présente des exigences similaires en matière d'isolation des fichiers de données dans des volumes dédiés. Avec un système d'exploitation tel que Microsoft Windows, un seul volume peut contenir plusieurs LUN de fichiers de données, chacune avec un système de fichiers NTFS. Avec d'autres systèmes d'exploitation, il existe généralement un gestionnaire de volumes logiques. Par exemple, avec Oracle ASM, l'option la plus simple consiste à limiter les LUN d'un groupe de disques ASM à un seul volume pouvant être sauvegardé et restauré en tant qu'unité. Si des volumes supplémentaires sont nécessaires pour des raisons de performance ou de gestion de la capacité, la création d'un groupe de disques supplémentaire sur le nouveau volume simplifie la gestion.</block>
  <block id="993afa8643b7200c5c9e527c24c1d8b2" category="paragraph">Si ces instructions sont respectées, les snapshots peuvent être planifiés directement sur le système de stockage sans avoir à créer de snapshot de groupe de cohérence. En effet, les sauvegardes Oracle ne nécessitent pas la sauvegarde simultanée de fichiers de données. La procédure de sauvegarde en ligne a été conçue pour assurer la mise à jour des fichiers de données, qui seront ensuite transmis progressivement sur bande en quelques heures.</block>
  <block id="a2ea5ea024e4a68e4d7f4abeca3441a1" category="paragraph">Une complication se produit dans des situations telles que l'utilisation d'un groupe de disques ASM distribué sur des volumes. Dans ce cas, un snapshot de groupe de cohérence doit être réalisé pour s'assurer que les métadonnées ASM sont cohérentes sur tous les volumes constitutifs.</block>
  <block id="0a3ecb97c1b7c97e5075bae0daaa45aa" category="paragraph">*Attention :* Vérifiez que l'ASM<block ref="1737629d60b511cf45957529a8f046e2" prefix=" " category="inline-code"></block> et<block ref="76a2173be6393254e72ffa4d6df1030a" prefix=" " category="inline-code"></block> les fichiers ne se trouvent pas dans le groupe de disques hébergeant les fichiers de données. Cela interfère avec la capacité à restaurer de manière sélective les fichiers de données et uniquement les fichiers de données.</block>
  <block id="2f8a5e254c86a42ebcc8b7d3c84cd22e" category="paragraph">Cette procédure suppose que les journaux d'archive souhaités sont toujours présents dans le système de fichiers actif. Si ce n'est pas le cas, les journaux d'archivage doivent être restaurés ou rman/sqlplus peut être dirigé vers les données du répertoire d'instantanés.</block>
  <block id="a67a69f712a877950e94edd27310b40e" category="paragraph">En outre, dans le cas de bases de données plus petites, l'utilisateur peut restaurer les fichiers de données directement à partir du système<block ref="a15da8cecb1f1192c4d913b8ba676121" prefix=" " category="inline-code"></block> répertoire n'ayant pas besoin des outils d'automatisation ou des administrateurs de stockage pour exécuter une<block ref="a4c0ce4da6fb04943b499690fb3afd6e" prefix=" " category="inline-code"></block> commande.</block>
  <block id="6da8ebf3245e4fbe4654e7f92f0330d7" category="list-text">Arrêter le ou les groupes de disques hébergeant les fichiers de données. La procédure varie en fonction du gestionnaire de volumes logiques choisi. Avec ASM, le processus nécessite de démonter le groupe de disques. Sous Linux, les systèmes de fichiers doivent être démontés et les volumes logiques et les groupes de volumes doivent être désactivés. L'objectif est d'arrêter toutes les mises à jour du groupe de volumes cible à restaurer.</block>
  <block id="931ab211ac6773d20c03a998f9f921ce" category="list-text">Relire tous les journaux de reprise si vous souhaitez procéder à une restauration complète.</block>
  <block id="b6575c3fca5eaaa56eeb8e9ce8867f05" category="paragraph">Cette procédure suppose que les journaux d'archive souhaités sont toujours présents dans le système de fichiers actif. Si ce n'est pas le cas, les journaux d'archivage doivent être restaurés en mettant les LUN du journal d'archivage hors ligne et en effectuant une restauration. Il s'agit également d'un exemple dans lequel il est utile de diviser les journaux d'archivage en volumes dédiés. Si les journaux d'archivage partagent un groupe de volumes avec les journaux de reprise, les journaux de reprise doivent être copiés ailleurs avant la restauration de l'ensemble global des LUN. Cette étape empêche la perte de ces transactions finales enregistrées.</block>
  <block id="65fd6f7f97414140b4d6060b743dc645" category="paragraph">Ces exigences comprennent des facteurs tels que la vitesse de restauration, la perte de données maximale autorisée et les besoins de conservation des sauvegardes. Le plan de protection des données doit également tenir compte de diverses exigences réglementaires en matière de conservation et de restauration des données. Enfin, différents scénarios de restauration des données doivent être pris en compte, allant de la restauration classique et prévisible résultant d'erreurs d'utilisateurs ou d'applications à des scénarios de reprise sur incident incluant la perte complète d'un site.</block>
  <block id="2bd1d35ff88de136066c33905c0fd677" category="paragraph">Les modifications mineures apportées aux règles de protection et de restauration des données peuvent avoir un impact significatif sur l'architecture globale du stockage, de la sauvegarde et de la restauration. Il est essentiel de définir et de documenter des normes avant de commencer le travail de conception afin d'éviter de compliquer une architecture de protection des données. Des fonctions ou des niveaux de protection inutiles entraînent des coûts et des frais de gestion inutiles. Par ailleurs, une exigence initialement négligée peut conduire un projet dans la mauvaise direction ou nécessiter des modifications de conception de dernière minute.</block>
  <block id="a60e6b87ede45aef49d8d095435db22b" category="section-title">Objectif de délai de restauration</block>
  <block id="3d3b341e14c584d1edcea9fe13619ee1" category="paragraph">L'objectif de délai de restauration (RTO) définit le temps maximal autorisé pour la restauration d'un service. Par exemple, une base de données de ressources humaines peut atteindre un objectif de délai de restauration de 24 heures. En effet, même s'il ne serait pas très pratique de perdre l'accès à ces données pendant les jours de travail, l'entreprise peut tout de même fonctionner. En revanche, une base de données prenant en charge le grand livre d'une banque aurait un RTO mesuré en minutes, voire en secondes. Un objectif RTO de zéro n'est pas possible, car il doit y avoir un moyen de faire la différence entre une panne de service réelle et un événement de routine tel qu'un paquet réseau perdu. Toutefois, un objectif RTO quasi nul est généralement requis.</block>
  <block id="5a27873285a0397cc06f9f47280c9426" category="section-title">Objectif de point de récupération</block>
  <block id="f3ae061e139f47d793058ee596a5243f" category="paragraph">L'objectif de point de récupération (RPO) définit la perte de données maximale tolérable. Dans de nombreux cas, l'objectif de point de récupération est uniquement déterminé par la fréquence des copies Snapshot ou des mises à jour snapmirror.</block>
  <block id="2d68fbd3cefeb34bfd64c8f89caba64d" category="paragraph">Dans certains cas, le RPO peut être rendu plus agressif, car il permet de protéger certaines données de manière sélective plus fréquemment. Dans un contexte de base de données, le RPO correspond généralement à la quantité de données perdues dans un journal spécifique. Dans un scénario de restauration typique dans lequel une base de données est endommagée en raison d'un bogue de produit ou d'une erreur utilisateur, le RPO doit être égal à zéro, ce qui signifie qu'il ne doit pas y avoir de perte de données. La procédure de restauration implique la restauration d'une copie antérieure des fichiers de base de données, puis la relecture des fichiers journaux pour ramener l'état de la base de données au point dans le temps souhaité. Les fichiers journaux requis pour cette opération doivent déjà être en place à l'emplacement d'origine.</block>
  <block id="57df8b025934bcd0f7e96bae19cf0688" category="paragraph">Dans des scénarios inhabituels, les données des journaux peuvent être perdues. Par exemple, un accident ou un acte malveillant<block ref="4609acba202877f99742342f4195d95e" prefix=" " category="inline-code"></block> des fichiers de base de données peuvent entraîner la suppression de toutes les données. La seule option serait de restaurer des données à partir de sauvegardes, y compris des fichiers journaux, et certaines seraient inévitablement perdues. Dans un environnement de sauvegarde classique, la seule option permettant d'améliorer le RPO consiste à effectuer des sauvegardes répétées des données du journal. Cela a toutefois ses limites en raison du déplacement constant des données et de la difficulté à maintenir un système de sauvegarde en tant que service en continu. L'un des avantages des systèmes de stockage avancés est la capacité à protéger les données contre les dommages accidentels ou malveillants aux fichiers et à fournir ainsi un meilleur RPO sans déplacement des données.</block>
  <block id="3d08c71e26ac92e34925e02570c4bd22" category="paragraph">La reprise après incident comprend l'architecture INFORMATIQUE, les règles et les procédures requises pour restaurer un service en cas d'incident physique. Cela peut inclure les inondations, les incendies ou les personnes agissant avec une intention malveillante ou négligente.</block>
  <block id="78f4e749ec0c6bb2627abbbc00bce296" category="paragraph">La reprise sur incident est bien plus qu'un ensemble de procédures de restauration. Il s'agit du processus complet d'identification des différents risques, de définition des exigences en matière de restauration des données et de continuité des services, et de mise à disposition de l'architecture appropriée avec les procédures associées.</block>
  <block id="75bcd60b234aba82b5827cd7a5171563" category="paragraph">Lors de l'établissement des exigences de protection des données, il est essentiel de faire la différence entre les objectifs RPO et RTO types et les exigences RPO et RTO requises pour la reprise après incident. Pour les situations de perte de données, allant d'une erreur utilisateur relativement normale à un incendie qui détruit un data Center, certains environnements applicatifs nécessitent un RPO nul et un RTO quasi nul. Cependant, il y a des conséquences administratives et des coûts pour ces niveaux élevés de protection.</block>
  <block id="756651fea87d05811d7a42451d074b60" category="paragraph">En général, les exigences de restauration des données non liées aux incidents doivent être strictes pour deux raisons. Tout d'abord, les bogues d'application et les erreurs d'utilisateur qui endommagent les données sont prévisibles au point qu'ils sont presque inévitables. Deuxièmement, il n'est pas difficile de concevoir une stratégie de sauvegarde capable de fournir un RPO nul et un RTO faible tant que le système de stockage n'est pas détruit. Il n'y a aucune raison de ne pas traiter un risque important facilement résolu. C'est pourquoi les objectifs RPO et RTO pour la reprise locale doivent être agressifs.</block>
  <block id="cb6faee28dd34d25f06bd0b33abe1c2f" category="paragraph">Les exigences en termes de RTO et de RPO pour la reprise d'activité varient plus largement en fonction du risque d'incident et des conséquences de la perte de données ou de l'interruption pour une entreprise. Les exigences en matière de RPO et de RTO doivent être basées sur les besoins réels de l'entreprise et non sur des principes généraux. Ils doivent prendre en compte plusieurs scénarios de catastrophe physique et logique.</block>
  <block id="68f31611fc8a5e6a20793905280a7001" category="section-title">Incidents logiques</block>
  <block id="07f5727077caaf8dedf895542181d26b" category="paragraph">Les incidents logiques incluent la corruption des données provoquée par les utilisateurs, les bogues des applications ou du système d'exploitation et les dysfonctionnements logiciels. Les incidents logiques peuvent également inclure des attaques malveillantes de tiers contenant des virus ou des vers, ou encore en exploitant les vulnérabilités des applications. Dans ces cas, l'infrastructure physique n'est pas endommagée, mais les données sous-jacentes ne sont plus valides.</block>
  <block id="3cb5ee5f24e42f56ba6dac48b7b046d2" category="paragraph">Les ransomwares sont un type de catastrophe logique de plus en plus courant qui sert à chiffrer les données à l'aide d'un vecteur d'attaque. Le chiffrement n'endommage pas les données, mais il les rend indisponibles jusqu'à ce que le paiement soit effectué à un tiers. De plus en plus d'entreprises sont spécifiquement la cible de piratage. Face à cette menace, NetApp propose des snapshots inviolables où même l'administrateur du stockage ne peut pas modifier les données protégées avant la date d'expiration configurée.</block>
  <block id="91c87f53ce0a1f416308a67ce119c623" category="section-title">Incidents physiques</block>
  <block id="79055ca11f54a97d22617a656eab8b9b" category="paragraph">Les incidents physiques incluent la défaillance de composants d'une infrastructure qui dépasse ses capacités de redondance et entraînent une perte de données ou une perte de service prolongée. Par exemple, la protection RAID assure la redondance des disques durs et l'utilisation de HBA assure la redondance des ports FC et des câbles FC. Les pannes matérielles de ces composants sont prévisibles et n'ont pas d'incidence sur la disponibilité.</block>
  <block id="3f7c55fe5f35f94cd2c4bd73b9cbb11b" category="paragraph">Dans un environnement d'entreprise, il est généralement possible de protéger l'infrastructure d'un site entier avec des composants redondants au point où le seul scénario de catastrophe physique prévisible est la perte complète du site. La planification de la reprise d'activité dépend alors de la réplication de site à site.</block>
  <block id="7f3dd7bdd41f7af6853732a383bbd7e2" category="section-title">Protection des données synchrone et asynchrone</block>
  <block id="c5ac17d5693914368f39b40a07af23d4" category="paragraph">Dans l'idéal, toutes les données seraient répliquées de manière synchrone sur des sites dispersés géographiquement. Une telle réplication n'est pas toujours possible, voire possible pour plusieurs raisons :</block>
  <block id="28c59a675d03e1f62a48958bb53ae523" category="list-text">La réplication synchrone entraîne inévitablement une augmentation de la latence d'écriture, car toutes les modifications doivent être répliquées vers les deux emplacements avant que l'application/la base de données ne puisse poursuivre le traitement. L'effet de performance qui en résulte est parfois inacceptable, excluant l'utilisation de la mise en miroir synchrone.</block>
  <block id="50a05ceeb998c4dac7e8b5d706fe2029" category="list-text">En raison de l'adoption accrue de 100 % de stockage SSD, il est plus probable que l'on remarque une latence d'écriture supplémentaire, car les attentes en termes de performances comprennent des centaines de milliers d'IOPS et une latence inférieure à la milliseconde. Pour tirer pleinement parti de l'utilisation de 100 % des SSD, il peut être nécessaire de revoir la stratégie de reprise sur incident.</block>
  <block id="04d90fe6288ce6cceba54a2b71e55727" category="list-text">La croissance des datasets en octets continue, ce qui engendre des défis en garantissant une bande passante suffisante pour soutenir la réplication synchrone.</block>
  <block id="d3aaae220bd5b3d68dd4ccec3bf78197" category="list-text">La croissance des datasets s'accompagne également de défis liés à la gestion de la réplication synchrone à grande échelle.</block>
  <block id="c3a841e0bfc640f91b0a00c4af8c6f5c" category="list-text">Les stratégies basées sur le cloud impliquent souvent des distances de réplication et une latence plus importantes, ce qui exclut davantage l'utilisation de la mise en miroir synchrone.</block>
  <block id="7df1515e247dfa2063c433b9339c2d4a" category="paragraph">NetApp propose des solutions qui incluent à la fois la réplication synchrone pour satisfaire les besoins les plus exigeants en matière de restauration des données et des solutions asynchrones qui assurent des performances et une flexibilité accrues. De plus, la technologie NetApp s'intègre en toute transparence à de nombreuses solutions de réplication tierces, telles qu'Oracle DataGuard</block>
  <block id="4d2c802af835583121763e1a6acc3f9b" category="section-title">Durée de conservation</block>
  <block id="123dbb4c09a5c8fb993a856cf65c9d25" category="paragraph">Le dernier aspect d'une stratégie de protection des données est la durée de conservation des données, qui peut varier considérablement.</block>
  <block id="d3a424909a8559a2d076e5d9a28d834f" category="list-text">Il est généralement nécessaire d'effectuer 14 jours de sauvegardes nocturnes sur le site principal et 90 jours de sauvegardes sur un site secondaire.</block>
  <block id="1d7c2d97c3bfd5ca9489e0ffeb06b150" category="list-text">De nombreux clients créent des archives trimestrielles autonomes stockées sur différents supports.</block>
  <block id="61ae175e4a0c88c4624184a0cb9b04d2" category="list-text">Une base de données constamment mise à jour n'a peut-être pas besoin de données historiques, et les sauvegardes ne doivent être conservées que pendant quelques jours.</block>
  <block id="8bb85c2149e1e808032e7025b0a27b80" category="list-text">Pour des raisons réglementaires, une capacité de restauration peut être nécessaire au point de toute transaction arbitraire dans une fenêtre de 365 jours.</block>
  <block id="05280349760feacdd6227fb8012e39d7" category="doc">Sauvegardes basées sur des snapshots</block>
  <block id="a4c2aeedbfeeda21f232cbf45be91693" category="paragraph">Les valeurs clés sont les suivantes :</block>
  <block id="d06c89cff665ecdde6eded3c9d44cd2b" category="list-text">*Simplicité.* Un instantané est une copie en lecture seule du contenu d'un conteneur de données à un moment donné.</block>
  <block id="175888ba89c31a851f719bdd271cae9c" category="list-text">*Efficacité.* les instantanés ne nécessitent pas d'espace au moment de la création. L'espace n'est consommé que lorsque des données sont modifiées.</block>
  <block id="d853e9e275a6e58b3a9a56fa641cbb9f" category="list-text">*Gérabilité.* Une stratégie de sauvegarde basée sur les snapshots est facile à configurer et à gérer car les snapshots font partie intégrante du système d'exploitation du stockage. Si le système de stockage est sous tension, il est prêt à créer des sauvegardes.</block>
  <block id="b564e5fbab71af776ed54a19d09b268c" category="list-text">*Évolutivité.* vous pouvez conserver jusqu'à 1024 sauvegardes d'un seul conteneur de fichiers et de LUN. Dans le cas de jeux de données complexes, plusieurs conteneurs de données peuvent être protégés par un ensemble unique et cohérent de snapshots.</block>
  <block id="7159872a568b97a971b9ea182fb23b7c" category="list-text">Les performances ne sont pas affectées, qu'un volume contienne ou non 1024 snapshots.</block>
  <block id="1a54f7e14e6e652bb32b12df22faf387" category="paragraph">Bien que de nombreux fournisseurs de stockage proposent la technologie Snapshot, la technologie Snapshot de ONTAP est unique et offre des avantages significatifs pour les environnements applicatifs et de bases de données d'entreprise :</block>
  <block id="d77b23e355dc2f65b90fb52ed9a90f9c" category="list-text">Les copies Snapshot font partie de la WAFL (Write-Anywhere File Layout) sous-jacente. Il ne s'agit pas d'une technologie complémentaire ou externe. La gestion est donc simplifiée, car le système de stockage est le système de sauvegarde.</block>
  <block id="8b888e6a2d883c0111428c101532294a" category="list-text">Les copies Snapshot n'affectent pas les performances, sauf dans certains cas en périphérie, par exemple lorsque le volume de données est stocké dans des snapshots que le système de stockage sous-jacent se remplit.</block>
  <block id="2283ea50a243a5d1ad551f7d21f39895" category="list-text">Le terme « groupe de cohérence » fait souvent référence à un regroupement d'objets de stockage gérés comme un ensemble cohérent de données. La copie Snapshot d'un volume ONTAP donné constitue une sauvegarde de groupe de cohérence.</block>
  <block id="ac72c83a8204d600d567261b41c5488c" category="paragraph">Les copies Snapshot ONTAP ont également une meilleure évolutivité que la technologie concurrente. Les clients peuvent stocker 5, 50 ou 500 copies Snapshot sans affecter les performances. Le nombre maximal de snapshots actuellement autorisés dans un volume est de 1024. Si une conservation supplémentaire des snapshots est nécessaire, il existe des options pour les transmettre en cascade à des volumes supplémentaires.</block>
  <block id="3b7ff39ba50f1bc3f56d38c41ba51855" category="paragraph">Par conséquent, la protection d'un dataset hébergé sur ONTAP est simple et hautement évolutive. Les sauvegardes ne nécessitent pas de déplacement de données. Par conséquent, une stratégie de sauvegarde peut être adaptée aux besoins de l'entreprise plutôt qu'aux limites des taux de transfert réseau, du grand nombre de lecteurs de bande ou des zones de transfert de disque.</block>
  <block id="55c5bbb3aad88266600eaa1a526406d4" category="paragraph">La question couramment posée sur l'utilisation des snapshots en tant que stratégie de protection des données est le fait que les données « réelles » et les données de snapshot se trouvent sur les mêmes disques. La perte de ces disques entraînerait la perte des données primaires et de la sauvegarde.</block>
  <block id="68870deb35eeb53373325a314030bd11" category="paragraph">Toutefois, les snapshots locaux ne doivent jamais être la seule stratégie de sauvegarde. C'est pourquoi NetApp propose des technologies telles que la réplication SnapMirror et SnapVault pour répliquer rapidement et efficacement des copies Snapshot sur un ensemble indépendant de disques. Dans une solution bien conçue avec des snapshots et une réplication Snapshot, l'utilisation des bandes peut être réduite au minimum, voire même à une archive trimestrielle, ou totalement éliminée.</block>
  <block id="73d3fd255835ca3dc926f59d50223f91" category="paragraph">Vous pouvez utiliser les copies Snapshot ONTAP pour protéger vos données, et les copies Snapshot sont la base de nombreuses autres fonctionnalités ONTAP, notamment la réplication, la reprise d'activité et le clonage. Une description complète de la technologie Snapshot ne fait pas partie du présent document, mais les sections suivantes offrent un aperçu général.</block>
  <block id="7441577327d1d49b71cc2f6403e17e7b" category="paragraph">Il existe deux approches principales pour créer un snapshot d'un dataset :</block>
  <block id="b38ba43128207852ef5149e6c578ba89" category="list-text">Sauvegardes cohérentes après panne</block>
  <block id="dc64a2f6075820724476e435a1ebd7fa" category="list-text">Sauvegardes cohérentes au niveau des applications</block>
  <block id="32561979f55bc68c4f028fd26a9975f6" category="paragraph">Les sauvegardes cohérentes après panne sont principalement utilisées lorsque la restauration au point de sauvegarde est suffisante. Lorsqu'une restauration plus granulaire est nécessaire, des sauvegardes cohérentes au niveau des applications sont généralement nécessaires.</block>
  <block id="367735591e5e6e04c17b7930acb29b7d" category="paragraph">Le mot "cohérent" dans "application-cohérente" est souvent un mal nommer. Par exemple, le placement d'une base de données Oracle en mode de sauvegarde est appelé sauvegarde cohérente au niveau des applications, mais les données ne sont en aucun cas rendues cohérentes ou suspendues. Les données continuent de changer tout au long de la sauvegarde. En revanche, la plupart des sauvegardes MySQL et Microsoft SQL Server ont effectivement mis les données au repos avant d'exécuter la sauvegarde. VMware peut rendre certains fichiers cohérents ou non.</block>
  <block id="ebf90723e7659cb5381545104b618612" category="paragraph">Le terme « groupe de cohérence » fait référence à la capacité d'une baie de stockage à gérer plusieurs ressources de stockage comme une seule image. Par exemple, une base de données peut comprendre 10 LUN. La baie doit pouvoir sauvegarder, restaurer et répliquer ces 10 LUN de manière cohérente. La restauration n'est pas possible si les images des LUN n'étaient pas cohérentes au point de sauvegarde. La réplication de ces 10 LUN nécessite que tous les réplicas soient parfaitement synchronisés.</block>
  <block id="3f8a43f1defaa984435092f616876545" category="paragraph">Le terme « groupe de cohérence » n'est pas souvent utilisé lors des discussions sur ONTAP, car la cohérence a toujours été une fonction de base de l'architecture de volumes et d'agrégats au sein de ONTAP. De nombreuses autres baies de stockage gèrent des LUN ou des systèmes de fichiers en tant qu'unités individuelles. Ils peuvent ensuite être configurés en tant que « groupe de cohérence » pour la protection des données, mais cette étape supplémentaire est nécessaire dans la configuration.</block>
  <block id="74e816c3c784f5c30c79dca4590d7f59" category="paragraph">ONTAP a toujours pu capturer des images locales et répliquées cohérentes de données. Bien que les différents volumes d'un système ONTAP ne soient généralement pas officiellement décrits comme des groupes de cohérence, c'est ce qu'ils sont. Une copie Snapshot de ce volume est une image de groupe de cohérence. La restauration de ce Snapshot correspond à une restauration de groupe de cohérence. SnapMirror et SnapVault proposent tous deux une réplication de groupe de cohérence.</block>
  <block id="15cc4389a08c3f4748e98622e630ad3e" category="section-title">Snapshots de groupes de cohérence</block>
  <block id="d286b747757ef3d8d3abac27bfae65f9" category="paragraph">Les copies Snapshot de groupe de cohérence (cg-snapshots) sont une extension de la technologie Snapshot ONTAP de base. Une opération de snapshot standard crée une image cohérente de toutes les données d'un même volume, mais il est parfois nécessaire de créer un ensemble cohérent de snapshots sur plusieurs volumes et même sur plusieurs systèmes de stockage. Il en résulte un ensemble de snapshots qui peuvent être utilisés de la même manière qu'un snapshot d'un seul volume individuel. Elles peuvent être utilisées pour la restauration des données locales, répliquées à des fins de reprise après incident ou clonées sous la forme d'une unité cohérente unique.</block>
  <block id="7c199465bc6344e648e2f73c88131605" category="paragraph">L'utilisation la plus connue des cg-snapshots concerne un environnement de base de données d'environ 1 po de capacité couvrant 12 contrôleurs. Les snapshots de groupe de cohérence créés sur ce système ont été utilisés pour la sauvegarde, la restauration et le clonage.</block>
  <block id="e5c199b4a97409f33d5caae984957744" category="paragraph">La plupart du temps, lorsqu'un dataset s'étend sur des volumes et que l'ordre d'écriture doit être préservé, le logiciel de gestion choisi utilise automatiquement un snapshot de groupe de cohérence. Dans ce cas, il n'est pas nécessaire de comprendre les détails techniques des cg-snapshots. Toutefois, les exigences complexes en matière de protection des données nécessitent un contrôle détaillé du processus de protection et de réplication des données. Certains workflows d'automatisation ou scripts personnalisés permettent d'appeler les API cg-Snapshot. Pour comprendre la meilleure option et le rôle de cg-snapshot, vous devez fournir une explication plus détaillée de la technologie.</block>
  <block id="cf3c30ea5c240a8aef02d240f42cdff7" category="paragraph">La création d'un ensemble de snapshots des groupes de cohérence s'effectue en deux étapes :</block>
  <block id="f30455406a91bd776afbc88e60b9697e" category="list-text">Établir une clôture d'écriture sur tous les volumes cibles.</block>
  <block id="c7afe45d94f2fd172a01e851d7f92a2f" category="list-text">Créez des instantanés de ces volumes à l'état clôturé.</block>
  <block id="c464d4671e489eaad9a8cbf0a8086ea9" category="paragraph">L'escrime d'écriture est établi en série. Cela signifie que lorsque le processus de recel est configuré sur plusieurs volumes, les E/S d'écriture sont bloquées sur le premier volume de la séquence au fur et à mesure qu'elles continuent d'être validées sur les volumes qui apparaissent plus tard. Cela peut sembler initialement contraire à l'exigence de préservation de l'ordre d'écriture, mais cela s'applique uniquement aux E/S émises de manière asynchrone sur l'hôte et ne dépend pas d'autres écritures.</block>
  <block id="688656b1f8644ee299edf7be87a8fc75" category="paragraph">Par exemple, une base de données peut émettre de nombreuses mises à jour asynchrones des fichiers de données et permettre au système d'exploitation de réorganiser les E/S et de les compléter selon sa propre configuration de planificateur. L'ordre de ce type d'E/S ne peut pas être garanti car l'application et le système d'exploitation ont déjà libéré l'obligation de conserver l'ordre d'écriture.</block>
  <block id="599ce07d1bae0fa6169959e2bdb97ada" category="paragraph">Par exemple, la plupart des activités de journalisation de la base de données sont synchrones. La base de données ne procède pas à d'autres écritures de journal tant que les E/S n'ont pas été acquittées et que l'ordre de ces écritures doit être conservé. Si une E/S de journal arrive sur un volume clôturé, elle n'est pas validée et l'application se bloque lors d'écritures ultérieures. De même, les E/S des métadonnées du système de fichiers sont généralement synchrones. Par exemple, une opération de suppression de fichier ne doit pas être perdue. Si un système d'exploitation doté d'un système de fichiers xfs supprime un fichier et que les E/S qui ont mis à jour les métadonnées du système de fichiers xfs pour supprimer la référence à ce fichier ont été reçues sur un volume isolé, l'activité du système de fichiers est alors interrompue. Cela garantit l'intégrité du système de fichiers pendant les opérations cg-Snapshot.</block>
  <block id="0f0c0f05310f9cf257d65bfd936f15c5" category="paragraph">Une fois l'isolation d'écriture configurée sur les volumes cibles, ils sont prêts pour la création d'instantanés. Les snapshots n'ont pas besoin d'être créés précisément en même temps, car l'état des volumes est figé du point de vue de l'écriture dépendant. Pour éviter toute faille dans l'application qui crée les instantanés cg, l'escrime d'écriture initiale inclut un délai configurable dans lequel ONTAP libère automatiquement l'escrime et reprend le traitement d'écriture après un nombre défini de secondes. Si tous les snapshots sont créés avant l'expiration du délai, le jeu de snapshots résultant est un groupe de cohérence valide.</block>
  <block id="df4925d1c6c3f3258e80ff35ce62b17d" category="section-title">Ordre d'écriture dépendant</block>
  <block id="6c78ee478b93fbb573157b85fb1114db" category="paragraph">Du point de vue technique, la préservation de l'ordre d'écriture et, plus particulièrement, de l'ordre d'écriture dépendant constitue la clé d'un groupe de cohérence. Par exemple, une base de données qui écrit 10 LUN écrit simultanément sur toutes ces LUN. De nombreuses écritures sont émises de manière asynchrone, ce qui signifie que l'ordre dans lequel elles sont effectuées n'est pas important et que l'ordre dans lequel elles sont effectuées varie en fonction du système d'exploitation et du comportement du réseau.</block>
  <block id="69d87c00869001f3f06ad4a1494eac21" category="paragraph">Certaines opérations d'écriture doivent être présentes sur le disque avant que la base de données puisse procéder à des écritures supplémentaires. Ces opérations d'écriture critiques sont appelées écritures dépendantes. Les E/S d'écriture suivantes dépendent de la présence de ces écritures sur le disque. Tout snapshot, restauration ou réplication de ces 10 LUN doit garantir l'ordre d'écriture dépendant. Les mises à jour du système de fichiers sont un autre exemple d'écritures dépendantes de l'ordre d'écriture. L'ordre dans lequel les modifications du système de fichiers sont effectuées doit être conservé, sinon l'ensemble du système de fichiers pourrait être corrompu.</block>
  <block id="74fbae5d0b3c16e1774c5f4dce2c1c36" category="section-title">Stratégies</block>
  <block id="53e858edb9bd9ff3f9ead52cebf5731d" category="paragraph">Il existe deux approches principales des sauvegardes basées sur des snapshots :</block>
  <block id="f87f61f625a005bd32c53f808d235eea" category="list-text">Sauvegardes à chaud protégées pour les snapshots</block>
  <block id="c32eba270db95747b471fd53e203a47b" category="paragraph">Les sauvegardes Snapshot cohérentes après panne sont principalement utilisées lorsque la restauration au point de sauvegarde est suffisante. Les journaux d'archivage peuvent être appliqués dans certains cas, mais lorsqu'une restauration granulaire à un point dans le temps est nécessaire, il est préférable d'effectuer une sauvegarde en ligne.</block>
  <block id="82cc23cd5dc667cc9fb78ff6e76ac15b" category="paragraph">La procédure de base pour une sauvegarde en ligne basée sur un snapshot est la suivante :</block>
  <block id="dbaf4855045e45fbcf678fa4cd1ab2db" category="list-text">Placez la base de données dans<block ref="402051f4be0cc3aad33bcf3ac3d6532b" prefix=" " category="inline-code"></block> mode.</block>
  <block id="c3e07fb8aef84ef3d94e3f9d5376c091" category="list-text">Créez un Snapshot de tous les volumes qui hébergent les fichiers de données.</block>
  <block id="2d0e58ff1a25bd9fd8a85ad8ce6f2665" category="list-text">Quitter<block ref="402051f4be0cc3aad33bcf3ac3d6532b" prefix=" " category="inline-code"></block> mode.</block>
  <block id="4196c5674aaa9e4317b2b4c54f94a905" category="list-text">Lancer la commande<block ref="9d2840394bc37850da4e360dbf60c0dc" prefix=" " category="inline-code"></block> pour forcer l'archivage des journaux.</block>
  <block id="f2736e795871e2fc2d36addb9436f337" category="list-text">Créer des instantanés de tous les volumes hébergeant les journaux d'archivage.</block>
  <block id="f24880a3fe8b242fdd1aba5a2d11196f" category="paragraph">Cette procédure permet d'obtenir un ensemble de snapshots contenant les fichiers de données en mode de sauvegarde et les journaux d'archivage critiques générés en mode de sauvegarde. Il s'agit des deux conditions requises pour restaurer une base de données. Il est également conseillé de protéger les fichiers tels que les fichiers de contrôle, mais la seule condition absolue est la protection des fichiers de données et des journaux d'archivage.</block>
  <block id="0c32649da44277db19fcfa3fe4dac28f" category="paragraph">Même si différents clients peuvent avoir des stratégies très différentes, la quasi-totalité de ces stratégies s'appuient sur les mêmes principes que ceux décrits ci-dessous.</block>
  <block id="88f451afed04f47352987f617f805826" category="section-title">Restauration basée sur des snapshots</block>
  <block id="c092a9763068c8382be82f9c77bb9658" category="paragraph">Lors de la conception d'infrastructures de volumes pour les bases de données Oracle, la première décision est d'utiliser ou non la technologie VBSR (Volume-Based NetApp SnapRestore).</block>
  <block id="15a0b8dc4d1b340d403bf6515f7e61b8" category="paragraph">La fonction SnapRestore basée sur les volumes permet de rétablir quasi instantanément un volume à un point antérieur. Toutes les données du volume étant rétablies, VBSR peut ne pas convenir à toutes les utilisations. Par exemple, si l'intégralité d'une base de données, y compris les fichiers de données, les journaux de reprise et les journaux d'archivage, est stockée sur un seul volume restauré avec VBSR, les données sont perdues, car les nouveaux journaux d'archivage et les données de reprise sont supprimés.</block>
  <block id="e63c0ca12b07a654ccadd92527a95c47" category="paragraph">La technologie VBSR n'est pas requise pour la restauration. De nombreuses bases de données peuvent être restaurées avec SFSR (Single File SnapRestore) ou en copiant simplement les fichiers du snapshot vers le système de fichiers actif.</block>
  <block id="b38bd603a952c93872eae2ea858cb15f" category="paragraph">Cette méthode d'isolement des fichiers de données permet de rétablir leur état antérieur sans endommager d'autres systèmes de fichiers.</block>
  <block id="5755a6275c3ecd99e8159efc58a8ff6c" category="section-title">Réserve Snapshot</block>
  <block id="957abb72f2db3a20e0b570a5fa3a1dcc" category="paragraph">Pour chaque volume contenant des données Oracle dans un environnement SAN, le<block ref="9ca25b30dcc119f9115aad6d85fd12ce" prefix=" " category="inline-code"></block> Doit être défini sur zéro car il n'est pas utile de réserver de l'espace pour un snapshot dans un environnement LUN. Si la réserve fractionnaire est définie sur 100, un snapshot d'un volume avec des LUN nécessite suffisamment d'espace libre dans le volume, à l'exception de la réserve Snapshot, pour absorber 100 % de CA de toutes les données. Si la réserve fractionnaire est définie sur une valeur inférieure, une quantité d'espace libre correspondante est nécessaire, mais elle exclut toujours la réserve snapshot. Cela signifie que l'espace de réserve du snapshot dans un environnement de LUN est gaspillé.</block>
  <block id="d5a06adf11e69f265f3ee3277212764e" category="paragraph">Dans un environnement NFS, deux options sont possibles :</block>
  <block id="7631336a8e2e03f6ac500c145445b2d7" category="list-text">Réglez le<block ref="9ca25b30dcc119f9115aad6d85fd12ce" prefix=" " category="inline-code"></block> basé sur la consommation d'espace prévue du snapshot.</block>
  <block id="acc4c5d06fc4a9ac93880c9c2d0a6e76" category="list-text">Réglez le<block ref="9ca25b30dcc119f9115aad6d85fd12ce" prefix=" " category="inline-code"></block> pour zéro et gérer collectivement l'espace utilisé actif et snapshot.</block>
  <block id="44806986c5abfcd6261803f4f75a7b56" category="paragraph">Avec la première option,<block ref="9ca25b30dcc119f9115aad6d85fd12ce" prefix=" " category="inline-code"></block> est défini sur une valeur différente de zéro, généralement autour de 20 %. Cet espace est alors masqué par l'utilisateur. Toutefois, cette valeur ne crée pas de limite d'utilisation. Si une base de données avec une réservation de 20 % connaît un chiffre d'affaires de 30 %, l'espace snapshot peut dépasser les limites de la réserve de 20 % et occuper un espace non réservé.</block>
  <block id="c8910acb0bfa30f82b423ff09a9710ca" category="paragraph">Le principal avantage de la définition d'une réserve sur une valeur telle que 20 % est de vérifier qu'un peu d'espace est toujours disponible pour les snapshots. Par exemple, un volume de 1 To avec une réserve de 20 % permettrait uniquement à un administrateur de base de données (DBA) de stocker 800 Go de données. Cette configuration garantit au moins 200 Go d'espace pour la consommation de snapshots.</block>
  <block id="be233226a8cb890c0a8bbf041c06ac6b" category="paragraph">Quand<block ref="9ca25b30dcc119f9115aad6d85fd12ce" prefix=" " category="inline-code"></block> est défini sur zéro, tout l'espace du volume est disponible pour l'utilisateur final, ce qui offre une meilleure visibilité. L'administrateur de base de données doit comprendre que, s'il constate qu'un volume de 1 To exploite les snapshots, cet espace de 1 To est partagé entre les données actives et le renouvellement du Snapshot.</block>
  <block id="b10efee713968b90d211d08ec8345d20" category="paragraph">Il n'existe pas de préférence claire entre l'option 1 et l'option 2 parmi les utilisateurs finaux.</block>
  <block id="8112d08173571f2d01372cadea3ea76d" category="section-title">ONTAP et snapshots tiers</block>
  <block id="0cc082f7cc7618a904f6cde556295cbd" category="paragraph">Oracle Doc ID 604683.1 décrit les conditions requises pour la prise en charge des snapshots tiers et les nombreuses options disponibles pour les opérations de sauvegarde et de restauration.</block>
  <block id="130a02f8381e6c54b2ea07d2bdaf6f0b" category="paragraph">Les fournisseurs tiers doivent garantir la conformité de leurs snapshots à plusieurs exigences :</block>
  <block id="97eb59a0f249226523b31dd52d557e00" category="list-text">Les snapshots doivent intégrer les opérations de restauration et de reprise recommandées par Oracle.</block>
  <block id="083e9332dc2b6bf064139ac2e670eee9" category="list-text">Les snapshots doivent être cohérents après panne de la base de données au point du Snapshot.</block>
  <block id="9dae8634b638a6949dab0f7eaf7988bd" category="list-text">L'ordre d'écriture est conservé pour chaque fichier d'un snapshot.</block>
  <block id="7bc868657652757ca8505ddcd297456f" category="paragraph">Les produits de gestion Oracle de ONTAP et NetApp sont conformes à ces exigences.</block>
  <block id="9e19caeb431a5e29a1a63e3cee4b36c9" category="doc">Protection des données Oracle avec ONTAP</block>
  <block id="848aab87f65bfade12f80d4e864ec046" category="paragraph">Une entreprise ne peut pas fonctionner sans accéder à ses données, et parfois l'activité repose sur les données. Ces données doivent être protégées, mais la protection ne se limite pas à garantir une sauvegarde utilisable. Elle consiste également à effectuer des sauvegardes rapidement et de manière fiable en plus de les stocker en toute sécurité.</block>
  <block id="28a0304f97f876b27cf541f4ad9a30d7" category="paragraph">L'autre côté de la protection des données est la restauration des données. Lorsque les données ne sont pas accessibles, l'entreprise est affectée et peut ne pas fonctionner tant qu'elle n'est pas restaurée. Ce processus doit être rapide et fiable. Enfin, la plupart des bases de données doivent être protégées contre les incidents, ce qui signifie maintenir une réplique de la base de données. La réplique doit être suffisamment à jour. Il doit également être rapide et simple de faire de la réplique une base de données entièrement opérationnelle.</block>
  <block id="3d601b26d05eac41fc6a7eba92fdc8b9" category="admonition">Cette documentation remplace le rapport technique _TR-4591 : protection des données Oracle : sauvegarde, restauration et réplication._</block>
  <block id="21d28aa03f67eb242b1c95a6a0594ff5" category="section-title">Planification</block>
  <block id="355ba59494fea8b20be391a73cc755eb" category="paragraph">Il est extrêmement compliqué de tester précisément les performances du stockage des bases de données. Il faut comprendre les problèmes suivants :</block>
  <block id="b57041cc3b57577b5c21eff44739e3f9" category="list-text">IOPS et débit</block>
  <block id="236e7fd957ada95e8094e302623980d3" category="list-text">Différence entre les opérations d'E/S au premier plan et en arrière-plan</block>
  <block id="902f90cc4ab59808cac5606f767f61c4" category="list-text">Effet de la latence sur la base de données</block>
  <block id="196198dbaa1d1ea17cfc478fbb2f419f" category="list-text">Nombreux paramètres du système d'exploitation et du réseau qui affectent également les performances du stockage</block>
  <block id="5ff18eadb2ef3fc20e13bed3e5b61d79" category="paragraph">En outre, il faut tenir compte des tâches qui ne relèvent pas du domaine du stockage dans les bases de données. L'optimisation de la performance du stockage ne présente plus d'avantages, car la performance du stockage n'est plus un facteur limitant.</block>
  <block id="32a993d3f497a6dd4392d3348b05ebc3" category="list-text">La bande passante réseau est une source de plus en plus courante de limites de performances. Par exemple, les solutions sur disque mécanique constituent souvent des goulots d'étranglement pour les performances des bases de données, car la latence d'E/S est très élevée. Lorsque les limites de latence sont éliminées par un système 100 % Flash, le obstacle est fréquemment basculer vers le réseau. Ceci est particulièrement notable dans les environnements virtualisés et les systèmes lames où la véritable connectivité réseau est difficile à visualiser. Les tests de performances peuvent ainsi être plus complexes si le système de stockage lui-même ne peut pas être pleinement utilisé en raison des limitations de bande passante.</block>
  <block id="8caa382fb0f5f7a8279424d306dd003d" category="list-text">Il est généralement impossible de comparer les performances d'une baie 100 % Flash à celles d'une baie contenant des disques rotatifs en raison de la latence considérablement améliorée des baies 100 % Flash. Les résultats des tests ne sont généralement pas significatifs.</block>
  <block id="bc2b8b37bdda467f2ce639ab28bf4646" category="list-text">Généralement, comparer les pics de performance d'IOPS avec un système 100 % Flash n'est pas utile, car les bases de données ne sont pas limitées par les E/S de stockage Supposons par exemple qu'une baie peut supporter 500 000 IOPS aléatoires, tandis qu'une autre peut supporter 300 000. La différence n'est pas pertinente en situation réelle si une base de données consacre 99 % de son temps au traitement du processeur. Ces charges de travail n'exploitent jamais toutes les capacités de la baie de stockage. À l'inverse, les pics d'activité d'E/S par seconde peuvent s'avérer critiques pour une plateforme de consolidation sur laquelle la baie de stockage doit être chargée au maximum de ses capacités.</block>
  <block id="0c2cbb26e6baa58b7d3a3309f95a2786" category="list-text">Lors de tout test de stockage, la latence et les IOPS sont systématiquement prises en compte. De nombreuses baies de stockage sur le marché revendiquant des niveaux extrêmes d'IOPS, mais avec la latence, ces IOPS deviennent inutiles à de tels niveaux. La cible type avec des baies 100 % Flash est le millième de seconde, Une meilleure approche lors de ces tests n'est pas de mesurer les IOPS maximales mais de déterminer le nombre d'IOPS qu'une baie de stockage peut supporter avant que la latence moyenne ne soit supérieure à 1 ms.</block>
  <block id="e6d8362588e550c19912b0f3f0e1a129" category="section-title">Référentiel automatique de workloads Oracle et banc d'essai</block>
  <block id="d035df494751722dd56d4cf4a8d1f795" category="paragraph">Pour les comparaisons de performances Oracle, il est référence dans le rapport Oracle Automatic Workload Repository (AWR).</block>
  <block id="95f7e55383674168e90b01b708bc88db" category="paragraph">Il existe plusieurs types de rapports AWR. Du point de vue du stockage, un rapport généré par l'exécution de<block ref="5053a9940effa118d38161a53f3b80f8" prefix=" " category="inline-code"></block> La commande est la plus complète et la plus utile, car elle cible une instance de base de données spécifique et inclut des histogrammes détaillés qui décomposent les événements d'E/S de stockage en fonction de la latence.</block>
  <block id="7b79802e5668e6e5b990081db481505d" category="paragraph">Dans l'idéal, comparer deux baies de performances implique d'exécuter la même charge de travail sur chaque baie et de produire un rapport AWR qui cible précisément la charge de travail. Dans le cas d'une charge de travail très longue, il est possible d'utiliser un seul rapport AWR avec un temps écoulé couvrant le temps de début et de fin, mais il est préférable de séparer les données AWR sous forme de plusieurs rapports. Par exemple, si une tâche par lots s'est exécutée de minuit à 6 h, créez une série de rapports AWR d'une heure de minuit à 1 h, de 1 h à 2 h, etc.</block>
  <block id="e39ecb86ad7d25413ba8ad2976fd3e4a" category="paragraph">Dans d'autres cas, une requête très courte doit être optimisée. La meilleure option est un rapport AWR basé sur un instantané AWR créé au début de la requête et un deuxième instantané AWR créé à la fin de la requête. Le serveur de base de données doit être silencieux pour réduire au minimum l'activité en arrière-plan qui pourrait masquer l'activité de la requête en cours d'analyse.</block>
  <block id="2fe7152c186ec1b5b0451e13ec8b968b" category="admonition">Lorsque les rapports AWR ne sont pas disponibles, les rapports Oracle statspack constituent une bonne alternative. Ils contiennent la plupart des mêmes statistiques d'E/S qu'un rapport AWR.</block>
  <block id="8b8c73ac7e509a897688356d1d283d75" category="section-title">Oracle AWR et dépannage</block>
  <block id="42a92c79ee82f4343e7d65f2f1cf2dd2" category="paragraph">Un rapport AWR est également l'outil le plus important pour analyser un problème de performances.</block>
  <block id="ad5387afbab7c506c781c8b12b0a4b24" category="paragraph">Comme pour les bancs d'essai, la résolution des problèmes de performances nécessite que vous mesuriez précisément une charge de travail particulière. Dans la mesure du possible, fournissez des données AWR lorsque vous signalez un problème de performance au centre de support NetApp ou lorsque vous travaillez avec une équipe NetApp ou un partenaire responsable de compte concernant une nouvelle solution.</block>
  <block id="6471146c0e33e2a8ec8a5c6635c837bc" category="paragraph">Lorsque vous fournissez des données AWR, tenez compte des exigences suivantes :</block>
  <block id="5c3ba265890805919f93c246b3f8d2d6" category="list-text">Exécutez le<block ref="5053a9940effa118d38161a53f3b80f8" prefix=" " category="inline-code"></block> pour générer le rapport. La sortie peut être texte ou HTML.</block>
  <block id="25db65f9a36910f3e488a8b7407130de" category="list-text">Si Oracle Real application clusters (RAC) est utilisé, générez des rapports AWR pour chaque instance du cluster.</block>
  <block id="96d55341f8208c60720e68b3155f3aa1" category="list-text">Cibler l'heure précise à laquelle le problème a existé. La durée maximale acceptable d'un rapport AWR est généralement d'une heure. Si un problème persiste pendant plusieurs heures ou implique une opération sur plusieurs heures, par exemple un traitement par lots, fournissez plusieurs rapports AWR d'une heure qui couvrent l'ensemble de la période à analyser.</block>
  <block id="4533b15b837909c68a0171d2638494d2" category="list-text">Si possible, réglez l'intervalle d'instantané AWR sur 15 minutes. Ce paramètre permet d'effectuer une analyse plus détaillée. Cela nécessite également des exécutions supplémentaires de<block ref="5053a9940effa118d38161a53f3b80f8" prefix=" " category="inline-code"></block> fournir un rapport pour chaque intervalle de 15 minutes.</block>
  <block id="97eb6d04cc93934c1be4ab95054cd0b0" category="list-text">Si le problème est une requête en cours très courte, fournissez un rapport AWR basé sur un instantané AWR créé au début de l'opération et un second instantané AWR créé à la fin de l'opération. Le serveur de base de données doit être silencieux pour minimiser l'activité en arrière-plan qui pourrait masquer l'activité de l'opération en cours d'analyse.</block>
  <block id="5186f459ce7d75e587a083bcb7c5927a" category="list-text">Si un problème de performance est signalé à certains moments mais pas à d'autres, fournissez des données AWR supplémentaires qui démontrent de bonnes performances pour la comparaison.</block>
  <block id="108a72dad388aa310cc52ee3bac7d1cc" category="section-title">etalonnez_io</block>
  <block id="f1c07dfccef6a6c47a5ccef938e10e3d" category="paragraph">Le<block ref="108a72dad388aa310cc52ee3bac7d1cc" prefix=" " category="inline-code"></block> command ne doit jamais être utilisé pour tester, comparer ou tester les systèmes de stockage. Comme indiqué dans la documentation Oracle, cette procédure permet d'étalonner les capacités d'E/S du stockage.</block>
  <block id="872892cce56a2665ad7ceecc44b38166" category="paragraph">L'étalonnage n'est pas le même que l'étalonnage. L'objectif de cette commande est d'émettre des E/S pour aider à étalonner les opérations de la base de données et améliorer leur efficacité en optimisant le niveau d'E/S émis pour l'hôte. Car le type d'E/S effectué par le<block ref="108a72dad388aa310cc52ee3bac7d1cc" prefix=" " category="inline-code"></block> Le fonctionnement ne représente pas les E/S réelles de l'utilisateur de la base de données, les résultats ne sont pas prévisibles et ne sont souvent même pas reproductibles.</block>
  <block id="e66807fad19acd41db50eedff918a4dd" category="section-title">SLOB2</block>
  <block id="0a6192ff5412539c31db2c7a98f408b3" category="inline-link-macro"><block ref="0a6192ff5412539c31db2c7a98f408b3" category="inline-link-rx"></block></block>
  <block id="d1f6fb23f52090ffd944dc54549735b8" category="paragraph">SLOB2, le très petit banc d'essai Oracle, est devenu l'outil privilégié pour évaluer les performances des bases de données. Il a été développé par Kevin Closson et est disponible à l'adresse <block ref="3ccce0719b1965cd915da75778e4e706" category="inline-link-macro-rx"></block>. L'installation et la configuration ne prennent que quelques minutes et une base de données Oracle génère des modèles d'E/S sur un espace de table définissable par l'utilisateur. Il s'agit de l'une des rares options de test disponibles permettant de saturer une baie 100 % Flash par E/S. Il est également utile de générer des niveaux d'E/S beaucoup plus bas pour simuler des charges de travail de stockage qui font partie des IOPS faibles, mais qui sont sensibles à la latence.</block>
  <block id="baffd8ac40ca7b966340e7b257b4c7b4" category="section-title">Swingbench</block>
  <block id="905a59d6f73f4e2aea1dc232a3bcd195" category="paragraph">Swingbench peut être utile pour tester les performances des bases de données, mais il est extrêmement difficile d'utiliser Swingbench sous un contrainte de stockage. NetApp n'a constaté aucun test de Swingbench ayant produit suffisamment d'E/S pour être une charge significative sur n'importe quelle baie AFF. Dans certains cas limités, le test OET (Order Entry Test) peut être utilisé pour évaluer le stockage du point de vue de la latence. Cela peut s'avérer utile lorsqu'une base de données a une dépendance connue en termes de latence pour des requêtes particulières. Assurez-vous que l'hôte et le réseau sont correctement configurés pour atteindre les potentiels de latence d'une baie 100 % Flash.</block>
  <block id="e3cf940afa524b20b15c43b20405be77" category="section-title">HammerDB</block>
  <block id="5c9408da71d2ff7554b9fd11add795cf" category="paragraph">HammerDB est un outil de test de base de données qui simule les bancs d'essai TPC-C et TPC-H, entre autres. La construction d'un jeu de données suffisamment volumineux pour exécuter correctement un test peut prendre beaucoup de temps, mais elle peut constituer un outil efficace pour évaluer les performances des applications OLTP et d'entrepôt de données.</block>
  <block id="7e1ad070b7fff621d9d64a71cec87684" category="section-title">Orion</block>
  <block id="56fedcbec2842fb62a743c5f84311597" category="paragraph">L'outil Oracle Orion a été couramment utilisé avec Oracle 9, mais il n'a pas été maintenu pour assurer la compatibilité avec les modifications apportées aux différents systèmes d'exploitation hôtes. Il est rarement utilisé avec Oracle 10 ou Oracle 11 en raison d'incompatibilités avec le système d'exploitation et la configuration du stockage.</block>
  <block id="38622bf572fa7bec2dc7f3915ebd345f" category="paragraph">Oracle a réécrit l'outil, qui est installé par défaut dans Oracle 12c. Bien que ce produit ait été amélioré et utilise la plupart des appels qu'une véritable base de données Oracle utilise, il n'utilise pas exactement le même chemin de code ou le même comportement d'E/S que celui utilisé par Oracle. Par exemple, la plupart des E/S Oracle sont exécutées de manière synchrone, ce qui signifie que la base de données s'arrête jusqu'à ce que les E/S soient terminées lorsque l'opération d'E/S se termine au premier plan. Le simple fait d'inonder un système de stockage d'E/S aléatoires n'est pas une reproduction de véritables E/S Oracle et n'offre pas de méthode directe pour comparer les baies de stockage ou mesurer l'impact des modifications de configuration.</block>
  <block id="bb68dfada5ca20e256bbd3ffbbfab9e6" category="paragraph">Cela étant, Orion est souvent associé à des cas d'usage, comme l'évaluation générale des performances maximales d'une configuration de stockage hôte-réseau ou encore l'évaluation de l'état d'un système de stockage. Grâce à des tests rigoureux, nous pouvons concevoir des tests Orion exploitables afin de comparer les baies de stockage ou d'évaluer l'effet d'une modification de la configuration, dans la mesure où les paramètres tiennent compte des IOPS, du débit et de la latence, et tenter de répliquer fidèlement une charge de travail réaliste.</block>
  <block id="6b64090d226d30776368e89b08c7c71b" category="summary">Alignement WAFL pour bases de données Oracle</block>
  <block id="03a35ba2b6191f8cfbd1cca378eefc91" category="doc">Vérification de l'alignement WAFL pour les bases de données Oracle</block>
  <block id="219900dcd21cee2f958254a708ad36f6" category="paragraph">Un alignement WAFL correct est essentiel pour de bonnes performances. Même si ONTAP gère des blocs dans des unités de 4 Ko, ONTAP ne réalise pas forcément toutes les opérations dans des unités de 4 Ko. ONTAP prend en charge les opérations en mode bloc de différentes tailles, mais la comptabilité sous-jacente est gérée par WAFL en unités de 4 Ko.</block>
  <block id="5d3a5c290e14d74acf49b20d15120886" category="paragraph">Le terme « alignement » fait référence à la manière dont les E/S Oracle correspondent à ces unités de 4 Ko. Pour optimiser les performances, un bloc Oracle de 8 Ko doit résider sur deux blocs physiques WAFL de 4 Ko sur un disque. Si un bloc est décalé de 2 Ko, ce bloc réside dans la moitié d'un bloc de 4 Ko, dans un bloc séparé complet de 4 Ko, puis dans la moitié d'un troisième bloc de 4 Ko. Cette configuration entraîne une dégradation des performances.</block>
  <block id="0073ce99d632b066d5ac09a4ad0cf7fc" category="paragraph">L'alignement n'est pas un problème avec les systèmes de fichiers NAS. Les fichiers de données Oracle sont alignés sur le début du fichier en fonction de la taille du bloc Oracle. Par conséquent, les tailles de bloc de 8 Ko, 16 Ko et 32 Ko sont toujours alignées. Toutes les opérations de bloc sont décalées par rapport au début du fichier en unités de 4 kilo-octets.</block>
  <block id="d7f7edd61ab216efc34578584a7d0e7c" category="paragraph">Les LUN, en revanche, contiennent généralement au départ un type d'en-tête de pilote ou de métadonnées de système de fichiers qui crée un décalage. L'alignement est rarement un problème dans les systèmes d'exploitation modernes, car ces systèmes d'exploitation sont conçus pour des disques physiques pouvant utiliser un secteur natif de 4 Ko. De plus, ils requièrent l'alignement des E/S sur les limites de 4 Ko pour des performances optimales.</block>
  <block id="38b3d1cd67903560954ad297a92e3de1" category="paragraph">Il y a toutefois quelques exceptions. Une base de données a peut-être été migrée à partir d'un système d'exploitation plus ancien qui n'a pas été optimisé pour les E/S de 4 Ko, ou une erreur de l'utilisateur lors de la création de la partition a pu entraîner un décalage qui ne se situe pas dans des unités de 4 Ko.</block>
  <block id="612eeadd26ceeace7b043d37f8e24b1f" category="paragraph">Les exemples suivants sont spécifiques à Linux, mais la procédure peut être adaptée à n'importe quel système d'exploitation.</block>
  <block id="1d5b772bea21e5e949413e09eedf17de" category="section-title">Aligné</block>
  <block id="594b0fc1af44897ff4b26f2e6b866685" category="paragraph">L'exemple suivant montre une vérification d'alignement sur une seule LUN avec une seule partition.</block>
  <block id="dc2c18402c86861702fc1d94a6495ac3" category="paragraph">Tout d'abord, créez la partition qui utilise toutes les partitions disponibles sur le lecteur.</block>
  <block id="adff8cc6319e96d2685fd082a5aa043c" category="paragraph">L'alignement peut être vérifié mathématiquement à l'aide de la commande suivante :</block>
  <block id="4bc7aba328a710bb7d0935cf830634aa" category="paragraph">Le résultat indique que les unités sont de 512 octets et que le début de la partition est de 32 unités. Il s'agit d'un total de 32 x 512 = 16,834 octets, soit un ensemble de blocs WAFL de 4 Ko. Cette partition est correctement alignée.</block>
  <block id="dd343941469b5360af52eb1b94fe5de6" category="paragraph">Pour vérifier que l'alignement est correct, procédez comme suit :</block>
  <block id="7d84e72acd05d0c93d99e414f5b092b5" category="list-text">Identifier l'UUID (identifiant universel unique) de la LUN</block>
  <block id="92af2a93f00a6297c490ba0be5fd7a8a" category="list-text">Entrez le shell du nœud sur le contrôleur ONTAP.</block>
  <block id="5274579d5eff6fe6d1e8ecbf54e84993" category="list-text">Démarrer les collections statistiques sur l'UUID cible identifié dans la première étape.</block>
  <block id="52df0a2ea976123bf02330300b2392e3" category="list-text">Certaines E/S. Il est important d'utiliser le<block ref="3c908d68ba53922b92c5595b72fa011c" prefix=" " category="inline-code"></block> Argument permettant de s'assurer que les E/S sont synchrones et non mises en tampon.</block>
  <block id="fac8a5b490ea29eca93ec213d79e6ff2" category="admonition">Faites très attention avec cette commande. Inversion du<block ref="39c8942e1038872a822c0dc75eedbde3" prefix=" " category="inline-code"></block> et<block ref="8bf8854bebe108183caeb845c7676ae4" prefix=" " category="inline-code"></block> les arguments détruisent les données.</block>
  <block id="4f7dce34a21e3de727f3e3ad05e6e7d8" category="list-text">Arrêtez les statistiques et affichez l'histogramme d'alignement. Toutes les E/S doivent se trouver dans le<block ref="c6bd178b372b0ddd17fff48819badc6a" prefix=" " category="inline-code"></block> Bucket, qui indique les E/S alignées sur les limites d'un bloc de 4 Ko.</block>
  <block id="5df81374c01d1b7c20fe8cb3883117eb" category="section-title">Mauvais alignement</block>
  <block id="5ff266dadf965b3c304513f516a13c12" category="paragraph">L'exemple suivant illustre un mauvais alignement des E/S :</block>
  <block id="25be03b87e6a5d8170ce85b16ea506ab" category="list-text">Créez une partition qui ne s'aligne pas sur une limite de 4 Ko. Il ne s'agit pas d'un comportement par défaut sur les systèmes d'exploitation modernes.</block>
  <block id="4adda0e871000c2b13a4faef6ce4e21b" category="paragraph">Le mauvais alignement est clair. Les E/S tombent principalement dans le* <block ref="66c8d76cad709856ccec680cab8ab35a" prefix="*" category="inline-code"></block> godet, qui correspond au décalage attendu. Lorsque la partition a été créée, elle a été déplacée de 512 octets plus loin dans le périphérique que la valeur par défaut optimisée, ce qui signifie que l'histogramme est décalé de 512 octets.</block>
  <block id="b53cb977228ac351c16dfacc3c427a99" category="paragraph">De plus, le<block ref="20e637b3ddd562732de038fba736c7ee" prefix=" " category="inline-code"></block> Ces statistiques ne sont pas égales à zéro, ce qui signifie que des E/S n'ont pas rempli un bloc de 4 Ko entier.</block>
  <block id="d3d92f87c5235ad11c8bc69e85fb2fd0" category="section-title">Fichiers de reprise</block>
  <block id="162b54d51a30629d78e153f8da201780" category="paragraph">Les procédures décrites ici s'appliquent aux fichiers de données. Les journaux de reprise et d'archivage Oracle ont différents modèles d'E/S. Par exemple, la journalisation de reprise est un remplacement circulaire d'un seul fichier. Si la taille de bloc par défaut de 512 octets est utilisée, les statistiques d'écriture se ressemblent à ceci :</block>
  <block id="d36dbaa617441d3308f5a9b50cb6f5ca" category="paragraph">Les E/S sont réparties dans tous les compartiments de l'histogramme, mais cela n'est pas un problème de performances. Toutefois, des taux de journalisation de reprise extrêmement élevés peuvent bénéficier d'une taille de bloc de 4 Ko. Dans ce cas, il est conseillé de vérifier que les LUN de journalisation de reprise sont correctement alignées. Cependant, cette condition n'est pas aussi importante pour de bonnes performances que l'alignement des fichiers de données.</block>
  <block id="3f9e1e3abd12ad7445baea4b681b9ceb" category="paragraph">Si un serveur de base de données Oracle tombe en panne, des verrous NFS obsolètes peuvent se présenter au redémarrage. Ce problème peut être évité en portant une attention particulière à la configuration de la résolution de nom sur le serveur.</block>
  <block id="288ebefc25180862eb0448b786b1b9fc" category="paragraph">Ce problème survient parce que la création d'un verrou et l'effacement d'un verrou utilisent deux méthodes légèrement différentes de résolution de nom. Deux processus sont impliqués, Network Lock Manager (NLM) et le client NFS. Le NLM utilise<block ref="e5caaf154dfeed411b9eec65b903a22a" prefix=" " category="inline-code"></block> pour déterminer le nom d'hôte, pendant que le système<block ref="d49331f31f40041ebcee19fca74fd9d4" prefix=" " category="inline-code"></block> utilisations des processus<block ref="330c4316ae6124616389eb1ca9912f7a" prefix=" " category="inline-code"></block>. Ces noms d'hôte doivent correspondre pour que le système d'exploitation efface correctement les verrous obsolètes. Par exemple, l'hôte peut rechercher des verrous appartenant à<block ref="c7169a6dd344d0f0a38071a1262e4973" prefix=" " category="inline-code"></block>, mais les verrous ont été enregistrés par l'hôte comme<block ref="0c32c65f5ac66d0bdb4e63bd5fde7f75" prefix=" " category="inline-code"></block>. Si<block ref="330c4316ae6124616389eb1ca9912f7a" prefix=" " category="inline-code"></block> ne renvoie pas la même valeur que<block ref="5c020b5bb8d1ce1ace51c2a2f4c06fc2" prefix=" " category="inline-code"></block>, le processus de déverrouillage n'a pas réussi.</block>
  <block id="19b9a1f540971d74c69042125bab2abc" category="paragraph">L'exemple de script suivant vérifie si la résolution des noms est parfaitement cohérente :</block>
  <block id="ee04b3fa3b28391874763596275e09c9" category="paragraph">Si<block ref="b64c6f211add16fd66ac17ef14c2a2b4" prefix=" " category="inline-code"></block> ne correspond pas<block ref="4040592cec1880aa70936989f05e7c31" prefix=" " category="inline-code"></block>, des verrous obsolètes sont probables. Par exemple, ce résultat indique un problème potentiel :</block>
  <block id="2b500e5914ea5a219ade17dea0808f51" category="paragraph">La solution est généralement trouvée en modifiant l'ordre dans lequel les hôtes apparaissent dans<block ref="ad942c725cd0cae65ca4c63717ec464c" prefix=" " category="inline-code"></block>. Par exemple, supposons que le fichier hosts inclut l'entrée suivante :</block>
  <block id="22b58ec1cec48707dfc018e6e216e966" category="paragraph">Pour résoudre ce problème, modifiez l'ordre dans lequel le nom de domaine complet et le nom d'hôte court apparaissent :</block>
  <block id="e357ccd0745db58f22ea5c0947b613ee" category="paragraph"><block ref="330c4316ae6124616389eb1ca9912f7a" prefix="" category="inline-code"></block> renvoie maintenant le court<block ref="c7169a6dd344d0f0a38071a1262e4973" prefix=" " category="inline-code"></block> nom d'hôte, qui correspond à la sortie de<block ref="4040592cec1880aa70936989f05e7c31" prefix=" " category="inline-code"></block>. Les verrous sont donc effacés automatiquement après une panne de serveur.</block>
  <block id="ea4c55be196897a16d86999f5c16d582" category="doc">Virtualisation</block>
  <block id="9e28dbd7a4f5940eeaf6d3893c5c4b1f" category="section-title">Présentation du stockage</block>
  <block id="151ae53a4100e0a6e83bde4d78083f81" category="list-text">LUN iSCSI gérées par l'initiateur iSCSI sur la machine virtuelle, pas par l'hyperviseur</block>
  <block id="36f9cea3dc0f65698a9fbe15460591c1" category="list-text">*Portabilité.* lorsqu'une machine virtuelle possède ses systèmes de fichiers, le processus de déplacement d'un environnement Oracle devient beaucoup plus simple. Les systèmes de fichiers peuvent facilement être déplacés entre des invités virtualisés et non virtualisés.</block>
  <block id="f114856edc6cd8d6a9add5ec3f67656f" category="section-title">Pilotes paravirtualisés</block>
  <block id="beeb10ceee6c9aabe178fb51edea7d22" category="paragraph">Pour des performances optimales, l'utilisation de pilotes de réseau paravirtualisés est essentielle. Lorsqu'un datastore est utilisé, un pilote SCSI paravirtualisé est requis. Un pilote de périphérique paravirtualisé permet à un invité de s'intégrer plus profondément dans l'hyperviseur, au lieu d'un pilote émulé dans lequel l'hyperviseur passe plus de temps CPU à imiter le comportement du matériel physique.</block>
  <block id="7c5996fc15a24ce96b30160b60ac2b96" category="section-title">Saturation de la mémoire RAM</block>
  <block id="5bccdd812c4af1cb5b9e36ddce656b60" category="paragraph">La saturation de la mémoire RAM implique la configuration d'une quantité de mémoire RAM virtualisée supérieure à celle qui existe sur le matériel physique sur différents hôtes. Cela peut entraîner des problèmes de performances inattendus. Lors de la virtualisation d'une base de données, les blocs sous-jacents de la SGA d'Oracle ne doivent pas être remplacés par l'hyperviseur vers le stockage. Cela entraîne des résultats de performances très instables.</block>
  <block id="be493f1fc0b02ae45602c7c13f7b5dc7" category="summary">Le rapport technique TR-4792 fournit des recommandations sur l'utilisation du NetApp HCI 615C pour les workloads de graphiques 3D dans un environnement VMware Horizon optimisé par les processeurs graphiques (GPU) et le logiciel de virtualisation NVIDIA.</block>
  <block id="ff1d278a485c443dc5d8fc9f10f1a702" category="doc">NetApp HCI pour l'infrastructure de postes de travail virtuels avec VMware Horizon 7 : offrez aux utilisateurs intensifs des graphiques 3D</block>
  <block id="e3162938e0d7b1bbc74111cc5b5871c5" category="paragraph">Le rapport technique TR-4792 fournit des conseils sur l'utilisation du nœud de calcul NetApp H615C pour les workloads de graphiques 3D dans un environnement VMware Horizon optimisé par les processeurs graphiques (GPU) et le logiciel de virtualisation NVIDIA. Il fournit également les résultats des tests préliminaires de SPECviewperf 13 pour le H615C.</block>
  <block id="1de37c09602b46db5de57a946efe2768" category="paragraph"><block ref="1de37c09602b46db5de57a946efe2768" category="inline-link-macro-rx"></block></block>
  <block id="93b94e62ad8cb02a1d1a7b0944a5445d" category="summary">Ce document présente les fonctions de sécurité des produits des outils ONTAP pour VMware vSphere.</block>
  <block id="57a033c33a8be6110be46b2914cc4989" category="doc">Utilisation de vVols avec ONTAP</block>
  <block id="21247c4392dc3c243f693dbf5b762553" category="section-title">Produits et documentation</block>
  <block id="94ef809dc16e728151bda996f8b4f8aa" category="inline-image-macro">Architecture VASA Provider des outils ONTAP,240</block>
  <block id="d78de3410d86d345a548abdf67aff375" category="paragraph"><block ref="d78de3410d86d345a548abdf67aff375" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5e5421e75636200787a4449a2cdaa1f1" category="section-title">Installation du produit</block>
  <block id="72333dadacbc964761fb14f718f6d411" category="section-title">Documentation produit</block>
  <block id="e0644c46fdc2ced2c094f7db15e15a8a" category="paragraph">La documentation suivante est disponible pour vous aider à déployer les outils ONTAP.</block>
  <block id="be11c74c1dd7f307bb80183a90dc2067" category="section-title">Commencez</block>
  <block id="7d0ee6fed10d3d4e5c9ee496729ab519" category="inline-link">Notes de mise à jour</block>
  <block id="3d7fe3e43f9f24fffe5ed0d546d12f13" category="inline-link">Déployez les outils ONTAP</block>
  <block id="a2fa58344be7fbd9a2be0320a8df0f77" category="inline-link">Mettez à niveau les outils ONTAP</block>
  <block id="21e2a89d708329706ec6ed3fc989a1f6" category="section-title">Utilisez les outils ONTAP</block>
  <block id="317bbf73ff27c5f981628c8fb83ebf22" category="inline-link">Configurez le contrôle d'accès basé sur des rôles</block>
  <block id="641e9457539249e880725760f91d5ee2" category="inline-link">Configurez la haute disponibilité</block>
  <block id="04edeb5424c826c14a69edb777edf395" category="section-title">Protéger et gérer les datastores</block>
  <block id="dd5138e8a4207a5b2fde43b411a4b5e1" category="section-title">Tableau de bord VASA Provider</block>
  <block id="cd47dd01745339787e4c7300389401f2" category="section-title">Et des meilleures pratiques</block>
  <block id="9ae938622297e9d4b14dd0006a8f0bf4" category="paragraph">*Limites*</block>
  <block id="b4f52a4fd0b07c9d904b95fc98a1cd45" category="inline-link">Configuration maximale</block>
  <block id="130b78bfd6c9b050a912fec77e285e3f" category="cell">Capacité/fonctionnalité</block>
  <block id="72e0ee397942f7233122887584f94b8b" category="paragraph">L'utilisation des vVols de ONTAP avec vSphere est simple et suit les méthodes vSphere publiées (consultez la documentation utilisation des volumes virtuels sous vSphere Storage in VMware pour votre version d'ESXi). Voici quelques autres pratiques à prendre en compte avec ONTAP.</block>
  <block id="83583580d98b69cb8317f9b285f3c8df" category="cell">*Utilisez les outils ONTAP pour les extensions d'interface utilisateur ou les API REST de VMware vSphere pour provisionner les datastores vVols* *et les terminaux de protocole.*</block>
  <block id="e8d5f9dc0bff953a9e59755813c7e8bf" category="cell">*Ne stockez jamais l'appliance ONTAP Tools ou l'appliance vCenter Server (VCSA) sur un datastore vVols qu'ils gèrent.*</block>
  <block id="c6ac0465bff03857ee851d98f6bd782b" category="cell">Cela peut entraîner une « situation de poulet et d'œuf » si vous devez redémarrer les appareils parce qu'ils ne pourront pas réassocier leurs propres vVols pendant qu'ils redémarrent. Vous pouvez les stocker sur un datastore vVols géré par un autre outil ONTAP et un déploiement vCenter.</block>
  <block id="ab8d352870fb5334773c7177d3d5dcd1" category="cell">*Évitez les opérations vVols sur différentes versions de ONTAP.*</block>
  <block id="8b2bcef781b7e1f6d64739147d50aae7" category="cell">Les fonctionnalités de stockage prises en charge telles que la QoS, le personnalité et bien d'autres encore ont changé dans plusieurs versions du fournisseur VASA, et certaines dépendent de la version de ONTAP. L'utilisation de différentes versions dans un cluster ONTAP ou le déplacement de vVols entre clusters avec différentes versions peut entraîner un comportement inattendu ou des alarmes de conformité.</block>
  <block id="cd7bf0e1e61341c1aa3fa23401af8a27" category="inline-image-macro">Segmentation à un seul initiateur avec quatre nœuds,400</block>
  <block id="51591d05b7e084ba8e5ae7f63172177e" category="inline-link">_TR-4080 meilleures pratiques pour le SAN moderne ONTAP 9_</block>
  <block id="c1723e6a0e1d3dd28232b33e0cb6e61d" category="inline-link">_TR-4684 implémentation et configuration de SAN modernes avec NVMe-of_</block>
  <block id="9a36c8f0464a7ffce114044f1859c7ff" category="cell">*Planifier vos volumes FlexVol de soutien en fonction de vos besoins.*</block>
  <block id="ee3cbda1c3c4a14ae024478c7ada6d11" category="cell">*Suivre toutes les meilleures pratiques du protocole.*</block>
  <block id="6a2c1ac1da51eca0c1a65afffab8dfab" category="inline-image-macro">Configuration réseau utilisant vVols sur NFS v3.500</block>
  <block id="918febfed3d070cf1250909e5cdcf31d" category="paragraph">Ce document présente les fonctionnalités de ONTAP pour les volumes virtuels VMware vSphere (vVols), notamment les dernières informations sur les produits et les cas d'utilisation, ainsi que les bonnes pratiques et d'autres informations permettant de rationaliser le déploiement et de réduire les erreurs.</block>
  <block id="d30f04665be7a6d9663004b1b5e61a9a" category="paragraph">Les meilleures pratiques complètent d'autres documents, tels que des guides et des listes de compatibilité. Ils sont développés en fonction de tests effectués en laboratoire et d'une vaste expérience sur le terrain par les ingénieurs et les clients NetApp. Ce ne sont peut-être pas les seules pratiques qui fonctionnent ou sont prises en charge, mais sont généralement les solutions les plus simples qui répondent aux besoins de la plupart des clients.</block>
  <block id="cc713c330b9c4e00d3ed7233bc54a889" category="section-title">Présentation des volumes virtuels (vVols)</block>
  <block id="cbf0aa9daeb855e4eace1a3bdc474ce2" category="paragraph">Plusieurs composants doivent être pris en compte :</block>
  <block id="919601826e1d58bccaaab76d787871d2" category="cell">Il s'agit du composant logiciel qui gère la communication entre VMware vSphere et le système de stockage. Pour ONTAP, le fournisseur VASA s'exécute dans une appliance connue sous le nom d'outils ONTAP pour VMware vSphere (outils ONTAP pour, par exemple). Les outils ONTAP incluent également un plug-in vCenter, un adaptateur de réplication du stockage (SRA) pour VMware site Recovery Manager et un serveur d'API REST pour vous permettre de créer votre propre automatisation. Une fois les outils ONTAP configurés et enregistrés dans vCenter, il est désormais peu nécessaire d'interagir directement avec le système ONTAP, puisque la quasi-totalité de vos besoins en stockage peut être gérée directement depuis l'interface utilisateur vCenter ou via l'automatisation de l'API REST.</block>
  <block id="3b2cd9018385f55c53c9a8b756df8bb5" category="cell">Le terminal de protocole est un proxy pour les E/S entre les hôtes ESXi et le datastore vVols. Le fournisseur ONTAP VASA les crée automatiquement, soit une LUN de terminal de protocole (4 Mo) par volume FlexVol du datastore vVols, soit un point de montage NFS par interface NFS (LIF) sur le nœud de stockage hébergeant un volume FlexVol dans le datastore. L'hôte ESXi monte ces terminaux de protocole directement plutôt que des LUN vVol individuelles et des fichiers de disque virtuel. Il n'est pas nécessaire de gérer les terminaux PE lorsqu'ils sont créés, montés, démontés et supprimés automatiquement par le fournisseur VASA, avec les groupes d'interfaces ou les règles d'exportation nécessaires.</block>
  <block id="71afca0aa1a505ea2ac3ce5a1a681549" category="paragraph">Nouveauté de vSphere 8, lorsque NVMe over Fabrics (NVMe-of) avec vVols, le concept de terminal de protocole n'est plus pertinent dans ONTAP. Au lieu de cela, un PE virtuel est instancié automatiquement par l'hôte ESXi pour chaque groupe ANA dès que la première machine virtuelle est sous tension. ONTAP crée automatiquement des groupes ANA pour chaque volume FlexVol utilisé par le datastore.</block>
  <block id="8202498953d2ebcf9968c37a7e47f4f6" category="paragraph">Autre avantage de NVMe-of pour les vVols : aucune demande de liaison n'est requise du fournisseur VASA. À la place, l'hôte ESXi gère en interne la fonctionnalité de liaison vVol basée sur le VPE. Cela réduit les risques d'impact d'une tempête de liaison vVol sur le service.</block>
  <block id="70532c0374111d897ef1176b34b6396c" category="inline-link">NVMe et les volumes virtuels</block>
  <block id="50ec55042a7f4e8c2c66219ac096cfb3" category="inline-link">vmware.com</block>
  <block id="113c9d4e642d1ba4cc469267fb7fd0de" category="paragraph">Pour plus d'informations, voir<block ref="f8d477cd77073d731aafe4f52026608a" category="inline-link-rx"></block> marche<block ref="1f1565cca975c4a703345d21e7f273b8" category="inline-link-rx"></block></block>
  <block id="937251054fa0c1a7b946f8928cc857b9" category="section-title">Gestion stratégique</block>
  <block id="2ce0d6ec59cca7e0b6e0bdc389301e63" category="section-title">Déployer une machine virtuelle à l'aide de la stratégie de stockage</block>
  <block id="e0795f8b847058e171dec5a519757ece" category="image-alt">Déploiement d'une machine virtuelle à l'aide d'une stratégie de stockage</block>
  <block id="941431bc1cecb0ec5e89e78e9a5a96fc" category="section-title">Conformité à la règle de stockage VM</block>
  <block id="bfd6dec22a6a1724ff1b67f1f289cdfc" category="image-alt">Conformité aux règles de stockage des machines virtuelles</block>
  <block id="9fe1fd556b933358881222d5c3da127c" category="paragraph">Au moment de la publication, les environnements hyperscale sont limités aux datastores NFS v3 classiques. Par conséquent, les vVols ne sont disponibles que pour les systèmes ONTAP sur site ou les systèmes connectés au cloud qui offrent l'ensemble des fonctionnalités d'un système sur site, tels que ceux hébergés par les partenaires et fournisseurs de services NetApp à travers le monde.</block>
  <block id="274bc582ca884fc158ea9ac9f79f9067" category="inline-link">Documentation des produits ONTAP</block>
  <block id="5ca60fe92dec435059ba5acefa4ce2c9" category="paragraph">_Pour plus d'informations sur ONTAP, voir<block ref="8a9b15dc18a16e0b1acfa438e27f6aa6" category="inline-link-rx"></block>_</block>
  <block id="3dffa984dadf9ff0006ee9cebd3b04b9" category="inline-link">TR-4597</block>
  <block id="d3fb76da5fbbcd6fa32e40910b5b9a47" category="section-title">Avantages de l'utilisation de vVols avec ONTAP</block>
  <block id="d0f004282063136e91d76d1d43d7c95f" category="paragraph">Lorsque VMware a introduit la prise en charge de vVols avec VASA 2.0 en 2015, ils l'ont décrite comme « une structure d'intégration et de gestion fournissant un nouveau modèle opérationnel pour le stockage externe (SAN/NAS) ». Ce modèle opérationnel présente plusieurs avantages avec le stockage ONTAP.</block>
  <block id="6a74f7c0a9021e009a9c030e54084978" category="paragraph">Comme décrit à la section 1.2, la gestion basée sur des règles permet de provisionner les machines virtuelles et de les gérer par la suite à l'aide de règles prédéfinies. Les opérations INFORMATIQUES peuvent ainsi être réalisées de plusieurs manières :</block>
  <block id="e0eb51b6d319e14c2fbfc1f628021a26" category="list-text">*Augmentez la vitesse.* les outils ONTAP éliminent la nécessité pour l'administrateur vCenter d'ouvrir des tickets avec l'équipe chargée du stockage pour les activités de provisionnement du stockage. Cependant, les rôles RBAC des outils ONTAP dans vCenter et sur le système ONTAP permettent toujours l'accès à des équipes indépendantes (telles que les équipes chargées du stockage) ou à des activités indépendantes par la même équipe en limitant l'accès à des fonctions spécifiques si nécessaire.</block>
  <block id="3f4dbd6687bd0d55bf69fe5fdd0137c4" category="list-text">*Provisionnement plus intelligent.* les fonctionnalités du système de stockage peuvent être exposées via les API VASA, ce qui permet aux flux de travail de provisionnement de tirer parti de fonctionnalités avancées sans que l'administrateur des machines virtuelles ait besoin de comprendre comment gérer le système de stockage.</block>
  <block id="a13fcc9220d042cae454e9ac073636ca" category="list-text">*Provisionnement plus rapide.* différentes capacités de stockage peuvent être prises en charge dans un seul datastore et sélectionnées automatiquement comme approprié pour une machine virtuelle en fonction de la stratégie de la machine virtuelle.</block>
  <block id="eb4c052226108afebf26e670208b9a55" category="list-text">*Évitez les erreurs.* les stratégies de stockage et de machines virtuelles sont développées à l'avance et appliquées selon les besoins sans avoir à personnaliser le stockage à chaque fois qu'une machine virtuelle est provisionnée. Les alarmes de conformité sont déclenchées lorsque les fonctionnalités de stockage sont différentes des règles définies. Comme mentionné précédemment, les plateformes SCP rendent le provisionnement initial prévisible et reproductible, tandis que la base des règles de stockage des serveurs virtuels sur les plateformes SCP garantit un placement précis.</block>
  <block id="f9878e32fdf258284c007eaae38773cd" category="section-title">Gestion granulaire des machines virtuelles dans le SAN moderne</block>
  <block id="7e673a7c12cc256f29bcd7b2028d9d5a" category="paragraph">Les systèmes DE stockage SAN utilisant Fibre Channel et iSCSI ont été les premiers à être pris en charge par VMware pour ESX, mais ils n'ont pas été en mesure de gérer les disques et les fichiers individuels des machines virtuelles à partir du système de stockage. Au lieu de cela, les LUN sont provisionnées et VMFS gère les fichiers individuels. Il est donc difficile pour le système de stockage de gérer directement les performances, le clonage et la protection du stockage des machines virtuelles individuelles. Les vVols apportent la granularité du stockage dont les clients utilisent déjà le stockage NFS, et les fonctionnalités SAN robustes et hautes performances de ONTAP.</block>
  <block id="25a46370807e0eab0dfe3853abfb9b6e" category="paragraph">Désormais, avec vSphere 8 et les outils ONTAP pour VMware vSphere 9.12 et versions ultérieures, les mêmes contrôles granulaires utilisés par les vVols pour les anciens protocoles SCSI sont désormais disponibles dans le SAN Fibre Channel moderne utilisant NVMe over Fabrics pour des performances encore plus élevées à grande échelle. Avec vSphere 8.0 mise à jour 1, il est désormais possible de déployer une solution NVMe de bout en bout complète à l'aide de vVols sans déplacement d'E/S dans la pile de stockage de l'hyperviseur.</block>
  <block id="f61f57f748f5f0b52c7f11f1f1bd43f0" category="section-title">Meilleures fonctionnalités de déchargement du stockage</block>
  <block id="911fa02c34dda38cd69be06e524ed9d0" category="inline-link">Garantie d'efficacité</block>
  <block id="3170031d77f241bc872afcb490c0a806" category="paragraph">Tandis que VAAI offre de nombreuses opérations qui sont déchargées vers le stockage, certaines lacunes sont traitées par le fournisseur VASA. SAN VAAI ne peut pas décharger les snapshots gérés par VMware vers le système de stockage. NFS VAAI peut décharger les snapshots gérés par les machines virtuelles, mais il existe des limites placées pour les machines virtuelles avec des snapshots natifs de stockage. Étant donné que les vVols utilisent des LUN, des espaces de noms ou des fichiers individuels pour des disques de machines virtuelles, ONTAP peut rapidement et efficacement cloner les fichiers ou les LUN pour créer des snapshots granulaires de machines virtuelles qui ne nécessitent plus de fichiers delta. NFS VAAI ne prend pas non plus en charge les opérations de déchargement des clones pour les migrations Storage vMotion à chaud (basées sur). La machine virtuelle doit être mise hors tension pour permettre la décharge de la migration lors de l'utilisation de VAAI avec des datastores NFS classiques. Le fournisseur VASA des outils ONTAP permet des clones quasi instantanés et efficaces du stockage pour les migrations à chaud et à froid, et prend également en charge les copies quasi instantanées pour les migrations de volumes croisés de vVols. En raison de ces avantages considérables en matière d'efficacité du stockage, vous pouvez tirer pleinement parti des workloads vVols sous le<block ref="9d1af7a9d4f98887e53c1a9bedbce044" category="inline-link-rx"></block> programme. De même, si les clones multi-volumes à l'aide de VAAI ne répondent pas à vos besoins, vous serez probablement en mesure de relever vos défis business grâce aux améliorations apportées à l'expérience de copie des vVols.</block>
  <block id="a8567b4dc683947384ef2e1dd0fc6ac1" category="section-title">Cas d'utilisation courants des vVols</block>
  <block id="48e535b80538b088fd868fde9372715c" category="paragraph">Outre ces avantages, plusieurs cas d'utilisation courants sont également mentionnés ci-dessous pour le stockage vVol :</block>
  <block id="441f01ec38e91fad1b235a0e7422a178" category="list-text">*Provisionnement à la demande des machines virtuelles*</block>
  <block id="bd652a918164d8fa5176b5f9b92c2e61" category="list-text">Cloud privé ou IaaS d'un Service Provider.</block>
  <block id="fddccd9595370687015a5ab02bcff60f" category="list-text">Exploitez l'automatisation et l'orchestration via la suite Aria (anciennement vRealize), OpenStack, etc</block>
  <block id="4fbc1141a40f5259e3ab1545de52b1ea" category="list-text">*Disques de première classe (FCDS)*</block>
  <block id="e83f2e4e8676ee8faac4d6af599fd7e7" category="list-text">Volumes persistants VMware Tanzu Kubernetes Grid [TKG].</block>
  <block id="b2b81490f2245d3d566e0ccc6a29cfc2" category="list-text">Proposez des services Amazon EBS avec une gestion indépendante du cycle de vie VMDK.</block>
  <block id="2511e4e8cbb72027ae20f24008d4b939" category="list-text">*Approvisionnement à la demande des machines virtuelles temporaires*</block>
  <block id="eeb1044cc319a5d53503e45dbf762291" category="list-text">Laboratoires de test et de développement</block>
  <block id="858d314810762abccaa7baf230e3dc18" category="list-text">Environnements de formation</block>
  <block id="ab7bbc294bf0f0354980a3014e8f4219" category="section-title">Bénéfices communs avec les vVols</block>
  <block id="ccd6ea8c57e93a5401d07aab9c60f371" category="paragraph">Lorsqu'ils sont utilisés à leur plein avantage, comme dans les cas d'utilisation ci-dessus, les vVols apportent les améliorations spécifiques suivantes :</block>
  <block id="1c21847cdc5616af138ba0c03aad7adb" category="list-text">Les vVols sont la technologie de stockage idéale lors de l'utilisation de TKG avec vSphere CSI, fournissant des classes et des capacités de stockage distinctes gérées par l'administrateur vCenter.</block>
  <block id="d5f068caef73978a5483badd927a7e98" category="list-text">Les services de type Amazon EBS peuvent être fournis via les disques FCD, car un VMDK FCD, comme son nom l'indique, est citoyen de premier ordre dans vSphere et possède un cycle de vie qui peut être géré de manière indépendante, indépendamment des machines virtuelles auxquelles il peut être rattaché.</block>
  <block id="7e7040600922b2a78715f856613a3c08" category="doc">Protection des vVols</block>
  <block id="de92c927f248723e4668aec459709995" category="section-title">Haute disponibilité VASA Provider</block>
  <block id="f4d4cb8868f07cad16bd7de7e36c5201" category="paragraph">Le fournisseur NetApp VASA s'exécute en tant que composant de l'appliance virtuelle, avec le plug-in vCenter et le serveur d'API REST (anciennement Virtual Storage Console [VSC]) et Storage Replication adapter. Si le fournisseur VASA n'est pas disponible, les machines virtuelles utilisant des vVols continueront à s'exécuter. Toutefois, il n'est pas possible de créer de nouveaux datastores vVols et ne peut pas être créé ni lié par vSphere. Cela signifie que les machines virtuelles utilisant des vVols ne peuvent pas être activées car vCenter ne pourra pas demander la création du vVol de swap. De plus, les machines virtuelles en cours d'exécution ne peuvent pas utiliser vMotion pour la migration vers un autre hôte, car les vVols ne peuvent pas être liés au nouvel hôte.</block>
  <block id="3958bf41787d7fcc6a9f8dd9348c947f" category="paragraph">Vasa Provider 7.1 et les versions ultérieures prennent en charge de nouvelles fonctionnalités pour s'assurer que les services sont disponibles dès que nécessaire. Elle comprend de nouveaux processus de surveillance qui surveillent VASA Provider et des services de base de données intégrés. S'il détecte une défaillance, il met à jour les fichiers journaux, puis redémarre automatiquement les services.</block>
  <block id="1acc458c695b0d3dfbf588309801fda2" category="paragraph">L'administrateur vSphere doit configurer une protection supplémentaire en utilisant les mêmes fonctionnalités de disponibilité que celles utilisées pour protéger les autres ordinateurs virtuels stratégiques contre les défaillances logicielles, matérielles hôtes et réseau. Aucune configuration supplémentaire n'est requise sur l'appliance virtuelle pour utiliser ces fonctionnalités ; il vous suffit de les configurer à l'aide des approches vSphere standard. Ils ont été testés et sont pris en charge par NetApp.</block>
  <block id="ff43afff832597ff45e5abeab2826ccf" category="inline-link">Documentation relative aux outils ONTAP pour VMware vSphere (configuration de la haute disponibilité des outils ONTAP)</block>
  <block id="d516ca4c9c18446a82d9fc9ee85bd955" category="paragraph">VSphere High Availability est facilement configuré pour redémarrer une machine virtuelle sur un autre hôte du cluster hôte en cas de panne. VSphere Fault Tolerance offre une plus grande disponibilité en créant une machine virtuelle secondaire répliquée en continu et capable de prendre le relais à tout moment. Des informations supplémentaires sur ces fonctions sont disponibles dans le<block ref="b6d78cbf1d5afb52929c529b32a350ad" category="inline-link-rx"></block>, Ainsi que la documentation VMware vSphere (recherchez vSphere Availability sous ESXi et vCenter Server).</block>
  <block id="97ba24d475ff6fdc7743099992cc301f" category="paragraph">Le fournisseur VASA des outils ONTAP sauvegarde automatiquement la configuration vVols en temps réel vers des systèmes ONTAP gérés où les informations vVols sont stockées dans les métadonnées de volume FlexVol. Si l'appliance ONTAP Tools devient indisponible, quelle qu'en soit la raison, vous pouvez facilement et rapidement en déployer une nouvelle et importer la configuration. Pour plus d'informations sur les étapes de restauration d'un fournisseur VASA, consultez cet article de la base de connaissances :</block>
  <block id="6799b6ec743f9159edf3b43790210a11" category="inline-link">Guide de résolution des incidents VASA Provider</block>
  <block id="9462790a7557a7eb2fe9daad4b875817" category="paragraph"><block ref="9462790a7557a7eb2fe9daad4b875817" category="inline-link-rx"></block></block>
  <block id="029a7740ecd792264454f9dbe194e980" category="section-title">Réplication vVols</block>
  <block id="c7b26217fd0c9041b6f779a0f669de5c" category="paragraph">De nombreux clients ONTAP répliquent leurs datastores classiques sur des systèmes de stockage secondaires à l'aide de NetApp SnapMirror, puis utilisent le système secondaire pour restaurer des machines virtuelles individuelles ou la totalité d'un site en cas d'incident. Dans la plupart des cas, les clients utilisent un outil logiciel pour gérer ceci, tel qu'un logiciel de sauvegarde tel que le plug-in NetApp SnapCenter pour VMware vSphere ou une solution de reprise après incident telle que site Recovery Manager de VMware (avec l'adaptateur de réplication du stockage dans les outils ONTAP).</block>
  <block id="bc6303e4538280b1b01d45a5f7d20039" category="paragraph">Cette exigence relative à un outil logiciel est encore plus importante pour la gestion de la réplication des vVols. Les fonctionnalités natives permettent de gérer certains aspects (par exemple, les copies Snapshot des vVols gérées par VMware sont déchargées vers ONTAP, qui utilise des clones de fichiers ou de LUN rapides et efficaces). Toutefois, l'orchestration générale est nécessaire pour gérer la réplication et la restauration. Les métadonnées concernant les vVols sont protégées par ONTAP et par le fournisseur VASA, mais des traitements supplémentaires sont nécessaires pour les utiliser sur un site secondaire.</block>
  <block id="c6a26835eb364bad22b16cb127b74135" category="paragraph">Les outils ONTAP 9.7.1 associés à VMware site Recovery Manager (SRM) 8.3 ont également pris en charge la reprise après incident et l'orchestration des flux de travail de migration en tirant parti de la technologie NetApp SnapMirror.</block>
  <block id="2803a799fd66056eff404a17ba640c2b" category="paragraph">Dans la version initiale de la prise en charge de SRM avec les outils ONTAP 9.7.1, il était nécessaire de pré-créer les volumes FlexVol et d'activer la protection SnapMirror avant de les utiliser comme volumes de sauvegarde pour un datastore vVols. À partir des outils ONTAP 9.10, ce processus n'est plus nécessaire. Vous pouvez désormais ajouter la protection SnapMirror aux volumes de sauvegarde existants et mettre à jour les règles de stockage de vos machines virtuelles afin de bénéficier d'une gestion basée sur des règles avec reprise après incident, orchestration de la migration et automatisation intégrées à SRM.</block>
  <block id="8142fcf496d02a58ce02a17558db863e" category="paragraph">Actuellement, VMware SRM est la seule solution d'automatisation de la migration et de la reprise après incident pour les vVols pris en charge par NetApp. Les outils ONTAP vérifient l'existence d'un serveur SRM 8.3 ou version ultérieure enregistré dans votre vCenter avant de vous permettre d'activer la réplication vVols, Vous pouvez exploiter les API REST d'outils ONTAP pour créer vos propres services.</block>
  <block id="7d8e8eced8d8b1a50f20640ffb5d363a" category="section-title">Réplication de vVols avec SRM</block>
  <block id="c95aede1de7a41511c9d962deba49054" category="section-title">Support MetroCluster</block>
  <block id="3f15bb720adb42bd521a2ce1cb3a2974" category="paragraph">Bien que les outils ONTAP ne soient pas capables de déclencher un basculement MetroCluster, ils prennent en charge les systèmes NetApp MetroCluster pour les vVols soutenant les volumes dans une configuration vMSC (vSphere Metro Storage Cluster) uniforme. Le basculement d'un système MetroCluster est géré de la manière habituelle.</block>
  <block id="cde16c5ee89c209c821e120caf65bb81" category="paragraph">Même si NetApp SnapMirror Business Continuity (SM-BC) peut également servir de base pour une configuration vMSC, il n'est pas pris en charge avec les vVols.</block>
  <block id="c859f5cd725cb2d1b163e4b066bede9a" category="paragraph">Pour plus d'informations sur NetApp MetroCluster, consultez ces guides :</block>
  <block id="e5e0fb3ae5564674a6548ade7c601578" category="inline-link">_TR-4689 Architecture et conception de la solution MetroCluster IP_</block>
  <block id="e64de4e49a37e62ff7f8c37e859bbeb9" category="paragraph"><block ref="e64de4e49a37e62ff7f8c37e859bbeb9" category="inline-link-rx"></block></block>
  <block id="0229efec9dc9b9a7fdf144b025157176" category="inline-link">_TR-4705 Architecture et conception de la solution NetApp MetroCluster_</block>
  <block id="6aee4b78ffdfaf193918978472d660a7" category="paragraph"><block ref="6aee4b78ffdfaf193918978472d660a7" category="inline-link-rx"></block></block>
  <block id="876341bac548f230eb390348e8b075ad" category="inline-link">_VMware KB 2031038 prise en charge de VMware vSphere avec NetApp MetroCluster_</block>
  <block id="5e68486fffeebad2ed145408dc250367" category="paragraph"><block ref="5e68486fffeebad2ed145408dc250367" category="inline-link-rx"></block></block>
  <block id="50c323f7050912164118ba47eab75888" category="section-title">Présentation de la sauvegarde vVols</block>
  <block id="6751e706567f4773c4f3138b4de51a0f" category="paragraph">Il existe plusieurs approches pour protéger les machines virtuelles, telles que l'utilisation d'agents de sauvegarde invités, la connexion de fichiers de données VM à un proxy de sauvegarde ou l'utilisation d'API définies telles que VMware VADP. Les vVols peuvent être protégées à l'aide des mêmes mécanismes et de nombreux partenaires NetApp prennent en charge les sauvegardes de machines virtuelles, y compris les vVols.</block>
  <block id="416d27c872769e934ac8a49ec98ccb53" category="paragraph">Comme mentionné précédemment, les snapshots gérés par VMware vCenter sont déchargés dans des clones de fichiers/LUN ONTAP rapides et compacts. Elles peuvent être utilisées pour des sauvegardes rapides et manuelles, mais vCenter limite le nombre de snapshots à 32. Vous pouvez utiliser vCenter pour créer des snapshots et restaurer les données selon vos besoins.</block>
  <block id="8f3d5ae5bd7d8922841975ccd84b8526" category="paragraph">À partir du plug-in SnapCenter pour VMware vSphere (SCV) 4.6 utilisé conjointement avec les outils ONTAP 9.10 et versions ultérieures, ajoute la prise en charge de la sauvegarde et de la restauration cohérentes après panne des machines virtuelles basées sur vVols exploitant les snapshots de volume ONTAP FlexVol avec prise en charge de la réplication SnapMirror et SnapVault. Jusqu'à 1023 copies Snapshot sont prises en charge par volume. SCV peut également stocker davantage de copies Snapshot avec une conservation plus longue sur des volumes secondaires à l'aide de SnapMirror avec une règle de copie miroir.</block>
  <block id="1429a9379faa8e82f8b198e93eebdf61" category="paragraph">La prise en charge de vSphere 8.0 a été introduite avec SCV 4.7, qui utilisait une architecture de plug-ins locaux isolée. La prise en charge de vSphere 8.0U1 a été ajoutée à SCV 4.8, qui a entièrement migré vers la nouvelle architecture de plug-ins distants.</block>
  <block id="de1d77d00dae616276b6ceb6296a18f2" category="section-title">VVols Backup avec le plug-in SnapCenter pour VMware vSphere</block>
  <block id="02f41838319aab980999b60967d7fd53" category="paragraph">Avec NetApp SnapCenter, vous pouvez désormais créer des groupes de ressources pour les vVols à partir de balises et/ou de dossiers afin de tirer automatiquement parti des snapshots FlexVol d'ONTAP pour les machines virtuelles basées sur vVols. Cela vous permet de définir des services de sauvegarde et de restauration qui protègent automatiquement les machines virtuelles lorsqu'elles sont provisionnées dynamiquement au sein de votre environnement.</block>
  <block id="4549a2943666c4815098331d30a872da" category="paragraph">Le plug-in SnapCenter pour VMware vSphere est déployé en tant qu'appliance autonome enregistrée en tant qu'extension vCenter, gérée via l'interface utilisateur vCenter ou via les API REST pour l'automatisation des services de sauvegarde et de restauration.</block>
  <block id="26e2418d177df1dddb008e455ce28752" category="section-title">Architecture SnapCenter</block>
  <block id="c32197281aa44f57ae568a9a42c7b3b6" category="paragraph">Comme les autres plug-ins SnapCenter ne prennent pas encore en charge les vVols au moment de la rédaction de ce document, nous nous concentrerons sur le modèle de déploiement autonome présenté dans ce document.</block>
  <block id="6750052f2c0fb06d80a8efd7cb871190" category="paragraph">Étant donné que SnapCenter utilise les copies Snapshot ONTAP FlexVol, il n'y a pas de surcharge placée sur vSphere, ni de réduction des performances comme on peut le voir avec les machines virtuelles traditionnelles utilisant les snapshots gérés par vCenter. De plus, comme la fonctionnalité de SCV est exposée via les API REST, il est facile de créer des workflows automatisés à l'aide d'outils tels que VMware Aria Automation, Ansible, Terraform et pratiquement tous les autres outils d'automatisation capables d'utiliser des API REST standard.</block>
  <block id="0c889d77d71512ceb7241bd0f6d6ca23" category="inline-link">Présentation des API REST</block>
  <block id="35eab4195b135718da016e20979f9031" category="paragraph">Pour plus d'informations sur les API REST de SnapCenter, reportez-vous à la section<block ref="33852d6f529e96c0b816da3945bcb1e5" category="inline-link-rx"></block></block>
  <block id="4ee2d383554981f4ea8eff4f35db6832" category="inline-link">Plug-in SnapCenter pour les API REST VMware vSphere</block>
  <block id="63ae61e98eec102c39264a819a3c522e" category="paragraph">Pour plus d'informations sur le plug-in SnapCenter pour les API REST VMware vSphere, consultez la section<block ref="40a6c7462de67e21480b7a31e406f8f9" category="inline-link-rx"></block></block>
  <block id="bdf03d5c2a7086b6c916dc96d06a0a6c" category="paragraph">Les bonnes pratiques suivantes peuvent vous aider à tirer le meilleur parti de votre déploiement SnapCenter.</block>
  <block id="60af6a4208b610da54a63a7e3658d5a5" category="list-text">SCV prend en charge les rôles RBAC vCenter Server et ONTAP RBAC et inclut des rôles vCenter prédéfinis qui sont automatiquement créés pour vous lorsque le plug-in est enregistré. Vous pouvez en savoir plus sur les types de RBAC pris en charge<block ref="a8ef9d6a500bd8288101245a3828ddb1" category="inline-link-rx"></block></block>
  <block id="0ed0835259b5b8c4b0f0910e7bfe2b17" category="list-text">Utilisez l'interface utilisateur de vCenter pour attribuer l'accès au compte le moins privilégié à l'aide des rôles prédéfinis décrits<block ref="17b3487f3493b9c198e03f92348bfca0" category="inline-link-rx"></block>.</block>
  <block id="d53326766687d6bc7fa2e28ee177e809" category="list-text">Si vous utilisez SCV avec le serveur SnapCenter, vous devez attribuer le rôle _SnapCenter_Admin_.</block>
  <block id="61ba6cb0b6021c205d41ed7f6fc1eb71" category="list-text">ONTAP RBAC fait référence au compte utilisateur utilisé pour ajouter et gérer les systèmes de stockage utilisés par SCV. ONTAP RBAC ne s'applique pas aux sauvegardes basées sur vVols. En savoir plus sur ONTAP RBAC et SCV<block ref="e4e865178d3962f87ac5cef3d6d68942" category="inline-link-rx"></block>.</block>
  <block id="1c89ba258526186ea0ec98325b61371b" category="list-text">Répliquez vos jeux de données de sauvegarde sur un second système à l'aide de SnapMirror pour créer des répliques complètes des volumes source. Comme mentionné précédemment, vous pouvez également utiliser des règles de copie miroir pour la conservation à long terme des données de sauvegarde, indépendamment des paramètres de conservation des snapshots du volume source. Les deux mécanismes sont pris en charge avec vVols.</block>
  <block id="9792eeb3b91469abf77746b005d82d77" category="list-text">Étant donné que SCV requiert également les outils ONTAP pour la fonctionnalité VMware vSphere for vVols, vérifiez toujours la compatibilité des versions avec l'outil IMT (Interoperability Matrix Tool) de NetApp</block>
  <block id="71c989bd68059e2ddfa4200c60b736c7" category="list-text">Si vous utilisez la réplication vVols avec VMware SRM, tenez compte de vos objectifs RPO et de votre planification de sauvegarde</block>
  <block id="604eb779cbb9af378f7bda71633b5b31" category="list-text">Concevez vos règles de sauvegarde avec des paramètres de conservation qui répondent aux objectifs de point de restauration (RPO) définis par votre entreprise.</block>
  <block id="067ff91a08d3ff453b59d81993b96182" category="list-text">Configurez les paramètres de notification de vos groupes de ressources pour qu'ils soient informés de l'état lors de l'exécution des sauvegardes (voir la figure 10 ci-dessous).</block>
  <block id="c3add00693172bbbb4dd864bf0ad9116" category="section-title">Options de notification de groupe de ressources</block>
  <block id="6eae9510711f8df8f55a15e1761875d9" category="section-title">Commencer à utiliser SCV à l'aide de ces documents</block>
  <block id="235a656535515ab3518937c09836e60d" category="inline-link">En savoir plus sur le plug-in SnapCenter pour VMware vSphere</block>
  <block id="79eb02d2a96cc634df87bec5bd511bbe" category="paragraph"><block ref="79eb02d2a96cc634df87bec5bd511bbe" category="inline-link-rx"></block></block>
  <block id="04e7bb0411c1c8f56ca4fc8000c62ad8" category="inline-link">Déployez le plug-in SnapCenter pour VMware vSphere</block>
  <block id="d4ba0aa084ae1145248006481c881d29" category="paragraph"><block ref="d4ba0aa084ae1145248006481c881d29" category="inline-link-rx"></block></block>
  <block id="231cf4c70d866b616c21baddaeed0696" category="doc">Dépannage</block>
  <block id="9d2169c1c2855b78a7aeaa4f42d27dc7" category="section-title">Site de support NetApp</block>
  <block id="ed9018b2e8611a3d2c03bb6a205b9715" category="inline-link">Les outils ONTAP pour VMware vSphere</block>
  <block id="890eb741924c425abbb11e4618560181" category="paragraph">Outre plusieurs articles de la base de connaissances sur les produits de virtualisation NetApp, le site de support NetApp offre également une page d'accueil pratique pour le<block ref="6e90053136fd326e5d581844ca21966d" category="inline-link-rx"></block> produit. Ce portail propose des liens vers des articles, des téléchargements, des rapports techniques et des discussions sur les solutions VMware sur la communauté NetApp. Il est disponible à l'adresse suivante :</block>
  <block id="fff460b039580a1bd42725a397b4c8be" category="inline-link">_Site de support NetApp_</block>
  <block id="897515b5a8a03f8d5cbed44fd47ef9f3" category="paragraph"><block ref="897515b5a8a03f8d5cbed44fd47ef9f3" category="inline-link-rx"></block></block>
  <block id="4020fd07f5ee2361dd23956e6a334ffd" category="paragraph">Vous trouverez une documentation supplémentaire sur les solutions ici :</block>
  <block id="baf17f6d2396be5fd3676baf863a331f" category="section-title">Dépannage du produit</block>
  <block id="9d6d7fa1a5253698556ac2b0cda2207d" category="paragraph">Les différents composants des outils ONTAP, tels que le plug-in vCenter, VASA Provider et Storage Replication adapter sont tous documentés dans le référentiel de documents NetApp. Cependant, chacun d'entre eux dispose d'une sous-section distincte de la base de connaissances et peut avoir des procédures de dépannage spécifiques. Ils répondent aux problèmes les plus courants rencontrés avec le fournisseur VASA.</block>
  <block id="ae2a93a809929192ecc7b468f234af84" category="section-title">Problèmes liés à l'interface utilisateur de VASA Provider</block>
  <block id="92a2b5cb9c6906035c2864fa225e1940" category="inline-link">article</block>
  <block id="69aecee18a55993c779487758eb051cc" category="paragraph">Il arrive que le client Web vCenter vSphere rencontre des problèmes avec les composants Serenity, ce qui empêche l'affichage des éléments de menu VASA Provider for ONTAP. Consultez la section résolution des problèmes d'enregistrement de VASA Provider dans le Guide de déploiement ou cette base de connaissances<block ref="c8979f1604396ce5570d07774ba255f0" category="inline-link-rx"></block>.</block>
  <block id="03cc611b90575ea37b55959adaa1c754" category="section-title">Échec du provisionnement du datastore vVols</block>
  <block id="281b890be0e8280eea1aebb82de90961" category="paragraph">Il arrive parfois que les services vCenter prennent du temps lors de la création du datastore vVols. Pour le corriger, redémarrez le service vmware-sps et remontez le datastore vVols à l'aide des menus vCenter (stockage &gt; Nouveau datastore). Ceci est couvert par les échecs de provisionnement du datastore vVols avec vCenter Server 6.5 dans le Guide d'administration.</block>
  <block id="3152add163cd8aaf116a259d85ebf8fb" category="section-title">La mise à niveau d'Unified Appliance ne parvient pas à monter l'ISO</block>
  <block id="ffaa56a3f5a1157f2eb3955773bb41da" category="paragraph">En raison d'un bogue dans vCenter, le montage de l'ISO utilisé pour mettre à niveau l'appliance unifiée d'une version à l'autre peut échouer. Si l'ISO peut être attaché à l'appliance dans vCenter, suivez la procédure de cette base de connaissances<block ref="9839383ed04f777c0132b57ad0cb14ac" category="inline-link-rx"></block> à résoudre.</block>
  <block id="cacba1b456347ce8f32c7f5ed0d81e64" category="doc">Déploiement du stockage vVols</block>
  <block id="3db9849d9f30bfc6e05c4e0b36d28848" category="section-title">Migration des machines virtuelles des datastores classiques vers des vVols</block>
  <block id="58f2a764a13ec89d3c5ead5343e75637" category="section-title">Gestion des machines virtuelles avec des règles</block>
  <block id="a4332a81dbc3a9888be608dea640cd3d" category="section-title">Création de stratégies de stockage de machine virtuelle</block>
  <block id="e65bde48b0a84fcc60d957de90c3a128" category="list-text">La modification des capacités de performance telles que les IOPS min et max requiert une certaine attention particulière à la configuration spécifique.</block>
  <block id="7de504873f20af5c8ce6dadd2f79b29a" category="list-text">Les outils ONTAP créent des règles de QoS individuelles non partagées avec les versions de ONTAP actuellement prises en charge. Par conséquent, chaque VMDK individuel recevra sa propre allocation d'IOPS.</block>
  <block id="63a33ddbd2c3ccd2daac06020248049f" category="section-title">Réapplication de la stratégie de stockage VM</block>
  <block id="50b6e1c7f2e81842d993d8ce88acc979" category="summary">ONTAP prend en charge tous les principaux protocoles de stockage utilisés pour la virtualisation, comme iSCSI, Fibre Channel (FC), Fibre Channel over Ethernet (FCoE) ou NVMe/FC (non-volatile Memory Express over Fibre Channel) pour les environnements SAN, ainsi que NFS (v3 et v4.1) et SMB ou S3 pour les connexions invités. Les clients sont libres de choisir ce qui fonctionne le mieux pour leur environnement et de combiner des protocoles en fonction des besoins sur un système unique.</block>
  <block id="ee8cc65cae83009c275cd4748f4c58ae" category="doc">Outils de virtualisation pour ONTAP</block>
  <block id="0894f8dfb7dd501a78dc2416b7b90c2a" category="paragraph">NetApp propose plusieurs outils logiciels autonomes pouvant être utilisés avec ONTAP et vSphere pour gérer votre environnement virtualisé.</block>
  <block id="236e1a1bf6abf86968baf738af47b78c" category="paragraph">Les outils suivants sont inclus avec la licence ONTAP sans frais supplémentaires. Voir la Figure 1 pour une description du fonctionnement de ces outils dans votre environnement vSphere.</block>
  <block id="0b266371a133b176a2ee883ccf72b46c" category="list-text">*Extensions de l'interface utilisateur vCenter.* les extensions de l'interface utilisateur des outils ONTAP simplifient le travail des équipes opérationnelles et des administrateurs vCenter en intégrant des menus contextuels faciles à utiliser pour gérer les hôtes et le stockage, les portlets d'information et les fonctionnalités d'alerte natives directement dans l'interface utilisateur vCenter pour optimiser les flux de travail.</block>
  <block id="e08c666b5127e745f8aacbacfce37dcf" category="list-text">*VASA Provider pour ONTAP.* le fournisseur VASA pour ONTAP prend en charge l'infrastructure VMware vStorage APIs for Storage Awareness (VASA). Il est fourni en tant qu'appliance virtuelle unique, avec les outils ONTAP pour VMware vSphere pour une facilité de déploiement. Vasa Provider connecte vCenter Server avec ONTAP pour faciliter le provisionnement et la surveillance du stockage des machines virtuelles. Il assure la prise en charge de VMware Virtual volumes (vvols), la gestion des profils de capacité de stockage et les performances individuelles de VM vvols, ainsi que des alarmes pour le contrôle de la capacité et de la conformité avec les profils.</block>
  <block id="1c7bb8764fc089dda8481678ad1ea0b5" category="list-text">*Storage Replication adapter.* l'adaptateur SRA est utilisé avec VMware site Recovery Manager (SRM) pour gérer la réplication des données entre les sites de production et de reprise après incident et tester les répliques de reprise après incident sans interruption. Il permet d'automatiser les tâches de détection, de restauration et de reprotection. Elle inclut une appliance serveur SRA et des adaptateurs SRA pour le serveur Windows SRM et l'appliance SRM.</block>
  <block id="a1c13ec555198266776a3a7b904810dd" category="paragraph">La figure suivante représente les outils ONTAP pour vSphere.</block>
  <block id="dd55e255500b9ec15305dc69dfa0e15b" category="section-title">Plug-in NFS pour VMware VAAI</block>
  <block id="4fbfd4c228f22ff3f2841908e853d895" category="paragraph">Le plug-in NetApp NFS pour VMware VAAI est un plug-in pour les hôtes ESXi qui leur permet d'utiliser des fonctionnalités VAAI avec les datastores NFS sur ONTAP. Il prend en charge le déchargement des copies pour les opérations de clonage, la réservation d'espace pour les fichiers de disque virtuel épais et le déchargement des snapshots. Le transfert des opérations de copie vers le stockage n'est pas forcément plus rapide. Toutefois, il réduit les besoins en bande passante réseau et réduit la charge des ressources hôte telles que les cycles de CPU, les tampons et les files d'attente. Vous pouvez utiliser les outils ONTAP pour VMware vSphere pour installer le plug-in sur des hôtes ESXi ou, le cas échéant, vSphere Lifecycle Manager (vLCM).</block>
  <block id="00cdd3f66e02711548cf72d579ec0df8" category="summary">SnapCenter vous permet de créer des règles de sauvegarde qui peuvent être appliquées à plusieurs tâches. Ces règles peuvent définir des fonctionnalités de planification, de conservation, de réplication et autres. Ils continuent d'autoriser la sélection facultative de snapshots cohérents avec les machines virtuelles, ce qui exploite la capacité de l'hyperviseur à suspendre les E/S avant de prendre un snapshot VMware.</block>
  <block id="f1d1eddd608fe98b6fa2bc3436ce81d0" category="doc">Gestion basée sur des règles de stockage et vVols</block>
  <block id="2bdce8d6813e7a3d93783119529cf146" category="paragraph">Les API VMware vSphere pour Storage Awareness (VASA) permettent à un administrateur du stockage de configurer des datastores avec des fonctionnalités bien définies et de permettre à l'administrateur des VM de les utiliser chaque fois que nécessaire pour provisionner des machines virtuelles sans avoir à interagir les unes avec les autres.</block>
  <block id="871db14a81b3510676400538c6f07073" category="paragraph">Il est intéressant d'étudier cette approche pour savoir comment rationaliser vos opérations de stockage de virtualisation et éviter un travail insignifiant.</block>
  <block id="ad0bd815b4fb6f01acc94f160af3dca7" category="paragraph">Avant de procéder à VASA, les administrateurs des VM pouvaient définir des règles de stockage des VM, mais ils devaient travailler avec l'administrateur du stockage pour identifier les datastores appropriés, souvent à l'aide de la documentation ou des conventions de nom. Grâce à VASA, l'administrateur du stockage peut définir un éventail de fonctionnalités de stockage, notamment la performance, le Tiering, le chiffrement et la réplication. Un ensemble de capacités pour un volume ou un ensemble de volumes est appelé « profil de capacité de stockage » (SCP).</block>
  <block id="44d75bdf4feecabe2de10427870ae623" category="paragraph">Le SCP prend en charge la QoS minimale et/ou maximale pour les vVols de données d'une machine virtuelle. La QoS minimale est prise en charge uniquement sur les systèmes AFF. Les outils ONTAP pour VMware vSphere comprennent un tableau de bord affichant des performances granulaires de machine virtuelle et une capacité logique pour vVvols sur les systèmes ONTAP.</block>
  <block id="4240fa68f6d9919e6d039c4038175025" category="paragraph">La figure suivante représente le tableau de bord des outils ONTAP pour VMware vSphere 9.8 vvols.</block>
  <block id="50e0e66922b3b12510a128829d1fdc70" category="paragraph">Une fois le profil de capacité de stockage défini, il peut être utilisé pour provisionner les machines virtuelles à l'aide de la règle de stockage qui identifie ses exigences. Le mappage entre la stratégie de stockage de la machine virtuelle et le profil de capacité de stockage du datastore permet à vCenter d'afficher la liste des datastores compatibles à sélectionner. Cette approche est appelée gestion basée sur des règles de stockage.</block>
  <block id="794b6e2fc393d40a552fc58975920cb0" category="paragraph">Vasa fournit la technologie permettant d'interroger le stockage et de renvoyer un ensemble de fonctionnalités de stockage vers vCenter. Les fournisseurs de VASA fournissent la traduction entre les API et les constructions du système de stockage et les API VMware que vCenter comprend. Le fournisseur VASA de NetApp pour ONTAP est proposé dans le cadre des outils ONTAP pour la machine virtuelle de l'appliance VMware vSphere. Le plug-in vCenter fournit l'interface de provisionnement et de gestion des datastores vVol, ainsi que la possibilité de définir des profils SCP (Storage Capability Profiles).</block>
  <block id="dad160104969c39365dd2cd4c98dd300" category="inline-link">TR-4400</block>
  <block id="bd490c925219bcb312338a370589bf70" category="list-text">Un datastore vvol peut être constitué de plusieurs volumes FlexVol sur plusieurs nœuds de cluster. L'approche la plus simple est un datastore unique, même si les volumes ont des capacités différentes. Grâce à la gestion du stockage basée sur des règles, un volume compatible est utilisé pour la machine virtuelle. Cependant, ces volumes doivent tous faire partie d'un seul SVM ONTAP et être accessibles via un seul protocole. Une LIF par nœud suffit pour chaque protocole. Évitez d'utiliser plusieurs versions de ONTAP dans un datastore vvol unique car les capacités de stockage peuvent varier d'une version à l'autre.</block>
  <block id="0cc956d6da91fefae9dad9b2c8c9519b" category="list-text">Utilisez les outils ONTAP pour le plug-in VMware vSphere pour créer et gérer des datastores vvol. En plus de gérer le datastore et son profil, il crée automatiquement un terminal de protocole permettant d'accéder aux vvols si nécessaire. Si les LUN sont utilisées, notez que les terminaux PE sont mappés à l'aide des ID de LUN 300 et supérieurs. Vérifiez que le paramètre système avancé de l'hôte ESXi est défini<block ref="ce913b4e625461a33f54f9e4ac38c2d7" prefix=" " category="inline-code"></block> Autorise un ID de LUN supérieur à 300 (la valeur par défaut est 1,024). Pour ce faire, sélectionnez l'hôte ESXi dans vCenter, puis l'onglet configurer et Rechercher<block ref="ce913b4e625461a33f54f9e4ac38c2d7" prefix=" " category="inline-code"></block> Dans la liste des paramètres système avancés.</block>
  <block id="fac85f355a1eb47127ef1b94e7603924" category="list-text">N'installez pas ni ne migrez de VASA Provider, vCenter Server (appliance ou base Windows), ou les outils ONTAP pour VMware vSphere lui-même vers un datastore vvols, car ils sont ensuite interdépendants et limitent votre capacité à les gérer en cas de panne de courant ou d'autre perturbation du data Center.</block>
  <block id="dd76252ea7a50def2a98f218cb1505b4" category="inline-link">Article de la base de connaissances</block>
  <block id="15ef75dd3d20b8278c16cd01a708e13e" category="list-text">Sauvegarder régulièrement la machine virtuelle de VASA Provider. Créez au moins des copies Snapshot toutes les heures du datastore classique contenant VASA Provider. Pour en savoir plus sur la protection et la restauration de VASA Provider, consultez cette section<block ref="9d642870dca1748c69f7aa0b6fb95a89" category="inline-link-rx"></block>.</block>
  <block id="2d2d2e356f9ab117b7d2a58d42cc5988" category="paragraph">La figure suivante montre les composants de vvols.</block>
  <block id="d3ba101543fc97ba1dd9272c87bf65da" category="doc">Volumes virtuels (vvols) et gestion basée sur des règles de stockage (SPBM)</block>
  <block id="fda9c21a4aefd4a1f42ad0b195e6ef0a" category="inline-link">Tr-4400 : volumes virtuels VMware vSphere avec ONTAP</block>
  <block id="61823c0f572643e0ce2e4edcb74cae51" category="paragraph">Utilisez les snapshots pour créer des copies rapides de votre machine virtuelle ou de votre datastore sans affecter les performances, puis envoyez-les à un système secondaire à l'aide de SnapMirror pour une protection des données hors site à plus long terme. Cette approche réduit l'espace de stockage et la bande passante réseau en stockant uniquement les informations modifiées.</block>
  <block id="1556ba0bf6ea4783cda0ff40e96f0265" category="paragraph">La figure suivante représente un exemple de déploiement SnapCenter.</block>
  <block id="6c1bef29e8dc34a00e17b06c221d5efe" category="paragraph">Pour des fonctionnalités améliorées de reprise sur incident, utilisez l'outil NetApp SRA pour ONTAP avec VMware site Recovery Manager. Outre la prise en charge de la réplication de datastores sur un site de reprise après incident, il permet également d'effectuer des tests sans interruption dans l'environnement de reprise après incident en clonant les datastores répliqués. L'automatisation intégrée à SRA simplifie également la reprise après incident et la reprotection de la production après panne.</block>
  <block id="650062685b0df8284f1b87f62fa3f9f3" category="inline-link">TR-4128</block>
  <block id="92515b597b8c0784d6000b89ee47c5fd" category="doc">Stockage unifié</block>
  <block id="d6154a0901f9ca6bb5d8fb15c113581e" category="paragraph"><block ref="d6154a0901f9ca6bb5d8fb15c113581e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e9e0f5f2c513c7138ea70b4c929d6fef" category="inline-link">Virtualisation du stockage</block>
  <block id="400cc516a4a40acd605aef2cfd4ba4c0" category="doc">Planificateur de ressources distribué de stockage VMware</block>
  <block id="6e210af5c49ef2b81c06b57f989ed5c6" category="paragraph">VMware Storage Distributed Resource Scheduler (SDRS) est une fonctionnalité vSphere qui place les machines virtuelles sur un stockage en fonction de la latence d'E/S actuelle et de l'utilisation de l'espace.</block>
  <block id="e7649bfbacc438bf8e20ba3564db4bdd" category="paragraph">Il déplace ensuite la machine virtuelle ou les VMDK sans interruption entre les datastores d'un cluster de datastores (également appelé pod), en sélectionnant le meilleur datastore pour placer la machine virtuelle ou les VMDK dans le cluster de datastore. Un cluster de data stores est un ensemble de datastores similaires agrégés dans une unité de consommation unique du point de vue de l'administrateur vSphere.</block>
  <block id="b028cce2007c32457c41f20d2954c0c2" category="paragraph">Les autres meilleures pratiques ONTAP en matière DE SDRS sont les suivantes :</block>
  <block id="d11eff5be5178b7ba95b06270611ffc8" category="list-text">Tous les datastores du cluster doivent utiliser le même type de stockage (SAS, SATA ou SSD, par exemple), être tous des datastores VMFS ou NFS et disposer des mêmes paramètres de réplication et de protection.</block>
  <block id="76db7ce67615bbc16da685df79ed0aa9" category="list-text">Envisagez d'utiliser DES DTS en mode par défaut (manuel). Cette approche vous permet d'examiner les recommandations et de décider s'il faut les appliquer ou non. Notez les effets suivants des migrations VMDK :</block>
  <block id="97f4ed95cb52bb29629002a25cb5039f" category="list-text">Lorsque DES DTS déplacent des VMDK entre les datastores, les économies d'espace éventuelles obtenues grâce au clonage ou à la déduplication ONTAP sont perdues. Vous pouvez réexécuter la déduplication pour récupérer ces économies.</block>
  <block id="38f492286c3edf236c76e993ce0f0bf2" category="list-text">Une fois que les DTS ont déplacé les VMDK, NetApp recommande de recréer les snapshots au niveau du datastore source car l'espace est autrement verrouillé par la machine virtuelle déplacée.</block>
  <block id="09a99cbc4fb85d10c7af970e79032a05" category="list-text">Le déplacement des VMDK entre les datastores du même agrégat n'a que peu d'avantages et LES DTS n'ont pas de visibilité sur d'autres charges de travail qui pourraient partager l'agrégat.</block>
  <block id="09b616c445ab7efa8240062532e526e4" category="doc">VMware vSphere avec ONTAP</block>
  <block id="48e29772cebbf1133d022577e278d5c1" category="admonition">Cette documentation remplace les rapports techniques _TR-4597 : VMware vSphere pour ONTAP_</block>
  <block id="bfa7e7fc7c6bf4cc4e4c5c74b09763eb" category="paragraph">Les meilleures pratiques complètent d'autres documents, tels que des guides et des listes de compatibilité. Ils sont développés en fonction de tests effectués en laboratoire et d'une vaste expérience sur le terrain par les ingénieurs et les clients NetApp. Non seulement elles sont les seules pratiques prises en charge dans chaque environnement, mais elles constituent généralement les solutions les plus simples qui répondent aux besoins de la plupart des clients.</block>
  <block id="9ed4a475dd3705157a9fed8811f63ce2" category="inline-link">Matrice d'interopérabilité NetApp</block>
  <block id="e08175c6fa64cba68719dea85ebd9d34" category="inline-link">Guide de compatibilité VMware</block>
  <block id="c7e9d53e7f1a53451fa25cb6340fbf6f" category="paragraph">Ce document est axé sur les fonctionnalités des dernières versions d'ONTAP (9.x) exécutées sur vSphere 7.0 ou version ultérieure. Voir la<block ref="37aa2814221d042697a27bc81e148f64" category="inline-link-rx"></block> et<block ref="e1593898142109fc8cd8025356d3f312" category="inline-link-rx"></block> pour obtenir des détails sur des versions spécifiques.</block>
  <block id="74587fa4ad90f8713c0446529a3670e0" category="section-title">Pourquoi choisir ONTAP pour vSphere ?</block>
  <block id="a110ecc6d4ce7014019c560e5fedf572" category="paragraph">De nombreuses raisons ont poussé des dizaines de milliers de clients à choisir ONTAP comme solution de stockage pour vSphere, par exemple un système de stockage unifié prenant en charge les protocoles SAN et NAS, des fonctionnalités robustes de protection des données à l'aide de copies Snapshot compactes et une multitude d'outils pour vous aider à gérer les données applicatives. En utilisant un système de stockage distinct de l'hyperviseur, vous pouvez décharger de nombreuses fonctions et optimiser votre investissement dans les systèmes hôtes vSphere. En plus de s'assurer que les ressources de vos hôtes sont concentrées sur les charges de travail applicatives, vous évitez également l'impact aléatoire sur les performances des applications en provenance des opérations de stockage.</block>
  <block id="0f50acddbdbb9aa9712a471f2276e655" category="paragraph">L'association de ONTAP et de vSphere permet de réduire les dépenses liées au matériel hôte et aux logiciels VMware. Vous pouvez également protéger vos données à moindre coût grâce à des performances élevées et prévisibles. Les charges de travail virtualisées étant mobiles, vous pouvez explorer différentes approches à l'aide de Storage vMotion afin de déplacer des ordinateurs virtuels entre des datastores VMFS, NFS ou vvols, le tout sur un même système de stockage.</block>
  <block id="90977175b761542615a11f2b96cc4cbd" category="paragraph">Voici les principaux facteurs dont la valeur aujourd'hui est :</block>
  <block id="0ce37df1cd9b66a2abde8244f17fc051" category="list-text">*Volumes virtuels et gestion basée sur des règles de stockage.* NetApp a été l'un des premiers partenaires de conception avec VMware dans le développement des volumes virtuels vSphere (vVols). Il a fourni des données architecturales et une prise en charge précoce des vVols et des API VMware vSphere pour la sensibilisation au stockage (VASA). Non seulement cette approche intègre la gestion granulaire du stockage des machines virtuelles à VMFS, mais elle a également pris en charge l'automatisation du provisionnement du stockage via la gestion basée sur des règles de stockage. Cette approche permet aux architectes du stockage de concevoir des pools de stockage dont les capacités sont facilement utilisable par les administrateurs de machines virtuelles. ONTAP est leader du secteur du stockage en matière d'évolutivité vvol, en gérant des centaines de milliers de vvols dans un seul cluster, alors que les fournisseurs de baies d'entreprise et de baies Flash de plus petite taille prennent en charge à peine plusieurs milliers de vvols par baie. NetApp pilotant également l'évolution de la gestion granulaire des ordinateurs virtuels avec des fonctionnalités à venir en matière de prise en charge de vvols 3.0.</block>
  <block id="9eeea06a6a7f860f801343c04af5d7d2" category="list-text">*Efficacité du stockage.* bien que NetApp ait été le premier à fournir la déduplication pour les charges de travail de production, cette innovation n'a pas été la première ou la dernière dans ce domaine. Il a commencé par les copies Snapshot, un mécanisme de protection des données peu encombrant et sans impact sur les performances, ainsi que la technologie FlexClone, qui permet de réaliser instantanément des copies en lecture/écriture des machines virtuelles pour la production et la sauvegarde. NetApp a continué à proposer des fonctionnalités en ligne, notamment la déduplication, la compression et la déduplication des blocs « zéro », afin d'exploiter tout le stockage provenant de disques SSD très coûteux. Plus récemment, ONTAP a ajouté la possibilité de stocker des opérations d'E/S et des fichiers de petite taille dans un bloc de disque à l'aide de la compaction. L'association de ces fonctionnalités a permis à des clients d'obtenir des économies allant jusqu'à 5:1 pour VSI et jusqu'à 30:1 pour VDI.</block>
  <block id="bb73602f3344c326a7b63c94db24362a" category="list-text">*Cloud hybride.* qu'il soit utilisé pour le cloud privé sur site, une infrastructure de cloud public ou un cloud hybride qui associe le meilleur des deux types de clouds, les solutions ONTAP vous aident à créer votre Data Fabric pour rationaliser et optimiser la gestion des données. Commencez par des systèmes 100 % Flash haute performance, puis coupler les avec des systèmes de stockage sur disque ou cloud pour la protection des données et le cloud computing. Vous pouvez choisir entre des clouds Azure, AWS, IBM ou Google pour optimiser les coûts et éviter l'enfermement propriétaire. Bénéficiez de la prise en charge avancée des technologies OpenStack et de conteneur, selon vos besoins. NetApp propose également des solutions de sauvegarde cloud (SnapMirror Cloud, Cloud Backup Service et Cloud Sync), ainsi que des outils de Tiering du stockage et d'archivage (FabricPool) pour ONTAP afin de réduire les dépenses d'exploitation et d'exploiter la portée du cloud.</block>
  <block id="7a61ec7965eebc0b5486cb78f096c770" category="list-text">*Et plus.* tirez parti des performances extrêmes des baies NetApp AFF A-Series pour accélérer votre infrastructure virtualisée tout en gérant les coûts. Assurez la continuité totale de l'activité, qu'il s'agisse de la maintenance ou des mises à niveau, ou du remplacement complet de votre système de stockage à l'aide de clusters ONTAP scale-out. Protégez vos données au repos avec les fonctionnalités de chiffrement NetApp, sans frais supplémentaires. Assurez-vous que les performances respectent les niveaux de service grâce à des fonctionnalités de qualité de service très avancées. Elles font toutes partie du vaste éventail de fonctionnalités fournies par ONTAP, le logiciel de gestion des données d'entreprise leader du secteur.</block>
  <block id="6104c8ef7be4222a76596ab6a22bb422" category="doc">Hôte ESXi recommandé et autres paramètres ONTAP recommandés</block>
  <block id="678582eb0cbbe0e063e618d230b63223" category="cell">*Paramètres hôte*</block>
  <block id="dfe49b73bd7e747701b49f9ed21ea2d6" category="cell">*Valeur recommandée par NetApp*</block>
  <block id="edceae57d92287f4f6200f94d3259cd0" category="cell">*Redémarrer requis*</block>
  <block id="dc3a6955a23583876d020db0f6b80d4d" category="cell">*Configuration avancée ESXi*</block>
  <block id="73663d0d00956f0632e4ae75d811d53f" category="cell">VMFS3.HardwareAccélérationde la localisation</block>
  <block id="59b1aceaef0203fdc32e11df232b16e6" category="cell">Conserver la valeur par défaut (1)</block>
  <block id="bafd7322c6e97d25b6299b5d6fe8920b" category="cell">Non</block>
  <block id="1b50110aedae4d8d2043a4eb9beb20af" category="cell">VMFS3.EnableBlockDelete</block>
  <block id="316084648bbafe451240702bd19c6ee9" category="cell">VMFS3.EnableVMFS6Unmap</block>
  <block id="befd90cd01403237f6fdf296822efbee" category="inline-link-macro">API VMware vSphere : intégration des baies (VAAI)</block>
  <block id="571cc1d48c6d1ff3cf7e3a54cb035753" category="cell">*Paramètres NFS*</block>
  <block id="c3b49a515dd0046685e06092642aa139" category="cell">Net.TcpipeHeapSize</block>
  <block id="875f6b98e20edfecb56f9013d00987f6" category="cell">VSphere 6.0 ou version ultérieure, défini sur 32.
Toutes les autres configurations NFS, définies sur 30</block>
  <block id="93cba07454f06a4a960172bbd6e2a435" category="cell">Oui.</block>
  <block id="504e96cc79e7efe30a8271cea152d9d1" category="cell">Net.TcpipeHeapMax</block>
  <block id="5f1e7b6431061565550e292d05c73588" category="cell">NFS.MaxVolumes</block>
  <block id="3058676a1cf088aa4a73312ac36f2a58" category="cell">NFS41.Maxvolumes</block>
  <block id="62c07f94c64184ee5d530e4c0917093f" category="cell">VSphere 6.0 ou version ultérieure, défini sur 256.</block>
  <block id="e18600af98c17fae10fdba0dc89979ed" category="cell">NFS.MaxQueueDepth^1^</block>
  <block id="be7707fa525d0124489c9fe3072f78de" category="cell">VSphere 6.0 ou version ultérieure, défini sur 128</block>
  <block id="18e1fb6924459470760771b20ab0c379" category="cell">NFS.HeartbeatMaxFailures</block>
  <block id="138989cbe5dd3a4997662e0f65c17878" category="cell">Définissez sur 10 pour l'ensemble des configurations NFS</block>
  <block id="1aa26eb281359ba3b9a9a4b83a09ed46" category="cell">NFS.HeartbeatFrequency</block>
  <block id="7ea6e8664542e3beb1aea10425efb4db" category="cell">Définissez la valeur 12 pour toutes les configurations NFS</block>
  <block id="eb4182715f8cde98563dc59ea36461d3" category="cell">NFS.HeartbeatTimeout</block>
  <block id="45aa5481fa55802a29a96aefd2f5dab1" category="cell">Définissez sur 5 pour l'ensemble des configurations NFS.</block>
  <block id="54a08b15243d9078d3b5a47f8242da6f" category="cell">Sunrpc.MaxConnPerIP</block>
  <block id="9a9ccbecb3f315797ff8e709d85a0e18" category="cell">VSphere 7.0 ou version ultérieure, défini sur 128.</block>
  <block id="c0b3fd5512c2093847f753f398290f30" category="cell">*Paramètres FC/FCoE*</block>
  <block id="2e556ad678160413b32dcca55c7d1f5f" category="cell">Stratégie de sélection de chemin</block>
  <block id="fb62337a3ef32f4701b639339a4ceb33" category="cell">Définissez-le sur RR (Round Robin) lorsque des chemins FC avec ALUA sont utilisés. Défini sur FIXE pour toutes les autres configurations.
La définition de cette valeur sur RR permet d'équilibrer la charge sur l'ensemble des chemins actifs/optimisés.
La valeur FIXÉE est pour les anciennes configurations non ALUA et contribue à empêcher les E/S proxy En d'autres termes, il contribue à empêcher les E/S de se diriger vers l'autre nœud d'une paire haute disponibilité dans un environnement doté de Data ONTAP 7-mode</block>
  <block id="117704664d6cada78ac3107380f63d23" category="cell">Disk.QFullSampleSize</block>
  <block id="0e82e1f81de2159b0e9bee0b7be00dc9" category="cell">Définissez sur 32 pour toutes les configurations.
La définition de cette valeur permet d'éviter les erreurs d'E/S.</block>
  <block id="f66a3c183f0e736240b77f8b755c880e" category="cell">Disk.QFullThreshold</block>
  <block id="bdd8c1d08eabb5e1923ed8f0c4b10ba4" category="cell">Réglez à 8 pour toutes les configurations.
La définition de cette valeur permet d'éviter les erreurs d'E/S.</block>
  <block id="19c08de7404551288e1274186e039ef4" category="cell">Délais d'expiration de la carte HBA FC Emulex</block>
  <block id="b4dbfc2d52627e923cbb563a31ff756d" category="cell">Utilisez la valeur par défaut.</block>
  <block id="d46cddda4da7ec11f17472d11df95b68" category="cell">Délais de connexion HBA FC QLogic</block>
  <block id="19b5aaf3e2cb86809996ca63a2a416b0" category="cell">*Paramètres iSCSI*</block>
  <block id="2aa077454308383f1e82025427cd7362" category="cell">Définissez à RR (Round Robin) pour tous les chemins iSCSI.
La définition de cette valeur sur RR permet d'équilibrer la charge sur l'ensemble des chemins actifs/optimisés.</block>
  <block id="0340eb1bcbfc6cd3c62b8a878d8d643b" category="cell">Définissez sur 32 pour toutes les configurations.
La définition de cette valeur permet d'éviter les erreurs d'E/S.</block>
  <block id="891c10448731ad57490b9a932dabfff8" category="inline-link-macro">VMware KB 86331</block>
  <block id="2c572e3c397fe100b075a09359c9cc23" category="admonition">1 : l'option de configuration avancée NFS MaxQueueDepth peut ne pas fonctionner comme prévu avec VMware vSphere ESXi 7.0.1 et VMware vSphere ESXi 7.0.2. Veuillez vous reporter à <block ref="861055760f3cd527823fd34a49459992" category="inline-link-macro-rx"></block> pour en savoir plus.</block>
  <block id="fb55ee99c04280ac638757869929785d" category="paragraph">Lors de la création de volumes et de LUN ONTAP FlexVol, les outils ONTAP permettent également de spécifier certains paramètres par défaut :</block>
  <block id="3f7502a5f109d7a73706aba1c0741a4b" category="cell">*Outil ONTAP*</block>
  <block id="485577e97e8efcd504fc8e8b13e613f1" category="cell">*Paramètre par défaut*</block>
  <block id="5938fe448c8661febcef3f4e779e3adb" category="cell">Réserve Snapshot (-percent-snapshot-space)</block>
  <block id="cfcd208495d565ef66e7dff9f98764da" category="cell">0</block>
  <block id="7218aec62575561a6de1cae8d5658390" category="cell">Réserve fractionnaire (-réserve fractionnaire)</block>
  <block id="3a7e09ff0fa38663ffe6d91324ea75d9" category="cell">Mise à jour de l'heure d'accès (-atime-update)</block>
  <block id="f8320b26d30ab433c5a54546d21f414c" category="cell">Faux</block>
  <block id="e93200d5b0d16915bf04236790544b2f" category="cell">Lecture minimum (-min-lecture anticipée)</block>
  <block id="c877d89702fdd14e51b02028a20c7d07" category="cell">Snapshots planifiés</block>
  <block id="fd18465573ec21a6218982055981f6b1" category="cell">Efficacité du stockage</block>
  <block id="00d23a76e43b46dae9ec7aa9dcbebb32" category="cell">Activé</block>
  <block id="f65fd63b63c9e9f25bf6bc141e83de34" category="cell">Garantie de volume</block>
  <block id="c2410aebdf425dabcc65e546e506b03e" category="cell">Aucune (provisionnement fin)</block>
  <block id="f97c03bf3e9580446d70d479f5aad1e0" category="cell">Taille automatique du volume</block>
  <block id="d89f4f8b1d7c18847b88b46142f61535" category="cell">augmenter_réduire</block>
  <block id="ace72ec54e17777d27eb8bdb9d57e782" category="cell">Réservation d'espace par LUN</block>
  <block id="b9f5c797ebbf55adccdd8539a65a0241" category="cell">Désactivé</block>
  <block id="514aa7792a71ab4ab677eb2385131aae" category="cell">Allocation d'espace de la LUN</block>
  <block id="dbe1e98b00264bd496095ed5c95f9350" category="section-title">Paramètres de chemins d'accès multiples pour les performances</block>
  <block id="de9f44b08eec22d6b405acff2c925d56" category="paragraph">Bien qu'il ne soit pas actuellement configuré par les outils ONTAP disponibles, NetApp suggère les options de configuration suivantes :</block>
  <block id="01d954fb2edbf283d121f0651b04de83" category="section-title">Documentation complémentaire</block>
  <block id="40db5019ed68654f4eb2cf21ec5021db" category="inline-link">Utilisez VMware vSphere 7.x avec ONTAP</block>
  <block id="30d85838b9488ee908d075559c8978cd" category="inline-link">Utilisez VMware vSphere 8.x avec ONTAP</block>
  <block id="000c9205416c1ea85f6841a7ca379c17" category="inline-link">Pour plus de détails sur NVMe-of, consultez la page Configuration d'hôte NVMe-of pour ESXi 7.x avec ONTAP</block>
  <block id="5a27e6dbe6279e323aec51d205b2b455" category="inline-link">Pour plus de détails sur NVMe-of, consultez la page Configuration d'hôte NVMe-of pour ESXi 8.x avec ONTAP</block>
  <block id="99a66df20e19a8e18fae37a7f714750a" category="doc">Clonage des VM et des datastores</block>
  <block id="fe12a277656562082ad50b980c227a84" category="paragraph">Dans vSphere, vous pouvez cloner une machine virtuelle, un disque virtuel, un volume virtuel ou un datastore. Une fois cloné, l'objet peut être davantage personnalisé, souvent par le biais d'un processus automatisé. VSphere prend en charge les clones de copie complète ainsi que les clones liés, pour assurer le suivi séparé des modifications apportées à l'objet d'origine.</block>
  <block id="883a97a36ab0c59ec785b03161a1cc32" category="paragraph">Les clones liés permettent un gain d'espace considérable, mais ils augmentent la quantité d'E/S que vSphere gère pour la machine virtuelle, ce qui affecte les performances de cette machine virtuelle, et peut-être de l'hôte dans son ensemble. C'est pourquoi les clients NetApp utilisent souvent des clones basés sur des systèmes de stockage pour profiter d'un double avantage : une utilisation efficace du stockage et des performances supérieures.</block>
  <block id="17e1a153b5d05c5a642c93ba9ce3c6de" category="paragraph">La figure suivante représente le clonage ONTAP.</block>
  <block id="d957242cd67db8ffccec78d93c14449d" category="list-text">Vvols avec le fournisseur NetApp vSphere APIs for Storage Awareness (VASA).  Les clones ONTAP sont utilisés pour prendre en charge les snapshots vVol gérés par vCenter. Ces snapshots sont peu encombrants avec un impact E/S minimal en termes de création et de suppression.  Les machines virtuelles peuvent également être clonées via vCenter, qui sont également déchargées vers ONTAP, que ce soit dans un datastore/volume unique ou entre les datastores/volumes.</block>
  <block id="059e5a6b7f963e9876ba0129dc1b667d" category="list-text">Clonage et migration de vSphere à l'aide des API vSphere – intégration de baies (VAAI). Les opérations de clonage de VM peuvent être déchargées sur ONTAP dans les environnements SAN et NAS (NetApp fournit un plug-in ESXi pour que VAAI for NFS).  VSphere ne décharge les opérations sur les machines virtuelles inactives (désactivées) dans un datastore NAS, tandis que les opérations sur les machines virtuelles fortement sollicitées (clonage et stockage vMotion) sont également déchargées pour le système SAN. ONTAP utilise l'approche la plus efficace selon la source, la destination et les licences des produits installés. Cette fonctionnalité est également utilisée par VMware Horizon View.</block>
  <block id="a603c207c7b5801942ff108502676c12" category="list-text">SRA (utilisé avec VMware site Recovery Manager). Ici, des clones sont utilisés pour tester la restauration de la réplique de reprise après incident sans interruption.</block>
  <block id="bb300d356d258c084dbe5da2ca367e08" category="list-text">Sauvegarde et restauration à l'aide d'outils NetApp tels que SnapCenter. Les clones de machine virtuelle sont utilisés pour vérifier les opérations de sauvegarde ainsi que pour monter une sauvegarde de machine virtuelle, de sorte que les fichiers individuels puissent être copiés.</block>
  <block id="524b5b8bc03312baeafbea86df667c4b" category="paragraph">Le clonage ONTAP Offloaded peut être appelé par les outils VMware, NetApp et tiers. Les clones déchargés sur ONTAP présentent plusieurs avantages. Elles sont peu gourmandes en espace dans la plupart des cas, et n'ont besoin que de systèmes de stockage pour modifier les objets. Cela n'a aucun impact supplémentaire sur les performances en lecture et en écriture. Dans certains cas, le partage des blocs dans des caches haute vitesse améliore les performances. Ils délester également le serveur ESXi de la charge des cycles CPU et des E/S réseau. Il est possible de décharger des copies dans un data store traditionnel grâce à un volume FlexVol, de manière rapide et efficace avec une licence FlexClone, mais les copies entre volumes FlexVol peuvent être plus lentes. Si vous maintenez les modèles de machine virtuelle comme source de clones, envisagez de les placer dans le volume du datastore (utilisez les dossiers ou les bibliothèques de contenu pour les organiser) afin de créer des clones rapides et compacts.</block>
  <block id="f3968368501d882b3969da59138db6e2" category="paragraph">Vous pouvez également cloner un volume ou une LUN directement au sein de ONTAP afin de cloner un datastore. Grâce aux datastores NFS, la technologie FlexClone peut cloner un volume entier. Le clone peut être exporté depuis ONTAP et monté par ESXi en tant qu'autre datastore. Pour les datastores VMFS, ONTAP peut cloner une LUN au sein d'un volume ou d'un volume complet, y compris une ou plusieurs LUN au sein de celle-ci. Une LUN contenant un VMFS doit être mappée sur un groupe d'initiateurs ESXi, puis une nouvelle signature définie par ESXi doit être montée et utilisée comme datastore standard. Pour certains cas d'utilisation temporaire, un VMFS cloné peut être monté sans nouvelle signature. Une fois le datastore cloné, les ordinateurs virtuels internes peuvent être enregistrés, reconfigurés et personnalisés comme s'ils étaient individuellement clonés.</block>
  <block id="2d506b6088a383ccf08479b0f80c0ff4" category="paragraph">Dans certains cas, des fonctionnalités supplémentaires sous licence peuvent être utilisées pour améliorer le clonage, telles que SnapRestore pour la sauvegarde ou FlexClone. Ces licences sont souvent incluses dans les packs de licence sans frais supplémentaires. Une licence FlexClone est requise pour les opérations de clonage vVol, ainsi que pour la prise en charge des snapshots gérés d'un VVol (qui sont déchargés de l'hyperviseur vers ONTAP). Une licence FlexClone peut également améliorer certains clones VAAI lorsqu'ils sont utilisés dans un datastore/volume (création de copies instantanées et compactes à la place de copies de bloc).  Elle est également utilisée par SRA pour tester la restauration d'une réplique de reprise après incident et SnapCenter pour les opérations de clonage, et pour parcourir les copies de sauvegarde afin de restaurer des fichiers individuels.</block>
  <block id="5dd57c2a315d3af44c2eb40eefc47111" category="doc">Configuration du réseau</block>
  <block id="66507f357c74ee12194270cfe053b98d" category="paragraph">Voici quelques points à prendre en compte :</block>
  <block id="7c4904daaa282388097ad83bf382e1a5" category="list-text">Les trames Jumbo peuvent être utilisées si vous le souhaitez et prises en charge par votre réseau, en particulier lors de l'utilisation d'iSCSI. Si elles sont utilisées, assurez-vous qu'elles sont configurées de manière identique sur tous les périphériques réseau, VLAN, etc. Dans le chemin entre le stockage et l'hôte ESXi. Vous pourriez voir des problèmes de performances ou de connexion. La MTU doit également être définie de manière identique sur le switch virtuel ESXi, le port VMkernel et également sur les ports physiques ou les groupes d'interface de chaque nœud ONTAP.</block>
  <block id="8b6e7f43d1d697e8f99164f0aa2ab1b6" category="inline-link">TR-4182</block>
  <block id="730a8287f758961d602b1b050bbe2751" category="list-text">Lorsque les baies de stockage ESXi et ONTAP sont connectées aux réseaux de stockage Ethernet, NetApp recommande de configurer les ports Ethernet auxquels ces systèmes se connectent en tant que ports de périphérie RSTP (Rapid Spanning Tree Protocol) ou en utilisant la fonctionnalité Cisco PortFast. NetApp recommande d'activer la fonction de jonction Spanning-Tree PortFast dans les environnements qui utilisent la fonction Cisco PortFast et dont le agrégation VLAN 802.1Q est activée soit au serveur ESXi, soit aux baies de stockage ONTAP.</block>
  <block id="ac4976538e1fc8726f77afc202561afc" category="list-text">NetApp recommande les meilleures pratiques suivantes pour l'agrégation de liens :</block>
  <block id="19d137845c7f6687c99b386dfad0aa97" category="list-text">Désactiver LACP pour les ports de switch connectés à ESXi, sauf si vous utilisez dvswitches 5.1 ou version ultérieure avec LACP configuré.</block>
  <block id="30254a2bb3e4b3b958b06d08c724e7db" category="list-text">Utilisez LACP pour créer des agrégats de liens pour les systèmes de stockage ONTAP avec des groupes d'interface multimode dynamiques avec un hachage IP.</block>
  <block id="d608421cceb8e4c584a2a32d9127879e" category="list-text">Utilisez une stratégie de regroupement de hachage IP sur ESXi.</block>
  <block id="2432030fc6183a1a6c52cf5e93f3e9ae" category="paragraph">Le tableau suivant fournit un récapitulatif des éléments de configuration réseau et indique l'emplacement d'application des paramètres.</block>
  <block id="7d74f3b92b19da5e606d737d339a9679" category="cell">Élément</block>
  <block id="1aa66ef3a8e34a7a538960a80d2e1e31" category="cell">VMware ESXi</block>
  <block id="bbc155fb2b111bf61c4f5ff892915e6b" category="cell">Commutateur</block>
  <block id="6c3a6944a808a7c0bbb6788dbec54a9f" category="cell">Nœud</block>
  <block id="0b7e67b6cdcf0432b624d53588d520fb" category="cell">SVM</block>
  <block id="75ba8d70e3692ba200f0e0df37b4d2ae" category="cell">Adresse IP</block>
  <block id="ee6c0f25c2881cc69947a2ef23be5b8c" category="cell">VMkernel</block>
  <block id="e11f298a5bd5344d2d975b5157c27b69" category="cell">Non**</block>
  <block id="d6f0876f76c273b8962b749c36153157" category="cell">Agrégation de liens</block>
  <block id="fabd320b3b2249377e53e93099e27657" category="cell">Commutateur virtuel</block>
  <block id="b1b40427c8eb8d0a083ddb16e250325b" category="cell">Non*</block>
  <block id="9881f82f0dd89588831f9d1682bd5492" category="cell">VLAN</block>
  <block id="5fc0d231160fa9650ea5c877f146bbe6" category="cell">Groupes de ports VMKernel et VM</block>
  <block id="39a3e05f380e583ae2887c79c7443f11" category="cell">Contrôle de flux</block>
  <block id="220071ab44b426f80ef21f1c552c363c" category="cell">NIC</block>
  <block id="6f2c08412f489e52a17a30217f50b3c1" category="cell">Spanning Tree</block>
  <block id="4b1c0df98ba3f3d1681c3c3dbdc97746" category="cell">MTU (pour les trames jumbo)</block>
  <block id="7d6feaf896df4a937157d4ee5b91f4e1" category="cell">Commutateur virtuel et port VMkernel (9000)</block>
  <block id="0110e50bd8629573701e73a4ba8b056f" category="cell">Oui (défini sur max)</block>
  <block id="061ff5255adf00e4ae68469f43a7bf55" category="cell">Oui (9000)</block>
  <block id="bcc0e5a3e08cd34e80692195d056b06d" category="cell">Groupes de basculement</block>
  <block id="a4d1a66a448e327c12d3e287098a31d5" category="cell">Oui (créer)</block>
  <block id="465d5674eb6808b997037470f4dace73" category="cell">Oui (sélectionner)</block>
  <block id="ba78d695573c8d4f1205452c675fa539" category="paragraph">*Les LIF SVM se connectent aux ports, aux groupes d'interface ou aux interfaces VLAN dotés de VLAN, MTU et d'autres paramètres. Cependant, les paramètres ne sont pas gérés au niveau de la SVM.</block>
  <block id="50ecdab93bf5a2f1bfb4cd8f81b9bd3d" category="paragraph">**Ces périphériques ont leur propre adresse IP pour la gestion, mais ces adresses ne sont pas utilisées dans le contexte du réseau de stockage VMware ESXi.</block>
  <block id="efd0bde36323238fec688b9cdf0c75a3" category="section-title">SAN (FC, FCoE, NVMe/FC, iSCSI), RDM</block>
  <block id="29cdd488736a6111699f7348320bbed7" category="paragraph">Dans vSphere, il existe trois façons d'utiliser les LUN de stockage bloc :</block>
  <block id="8982d243303f9d1a8c2470b7d55278e6" category="list-text">Avec les datastores VMFS</block>
  <block id="9a0098c8c1be287e8d1da1aaf3bd2e59" category="list-text">Avec mappage de périphériques bruts (RDM)</block>
  <block id="43f67f108e50dab0978a343603cbfec9" category="paragraph">VSphere inclut la prise en charge intégrée de plusieurs chemins d'accès aux périphériques de stockage, appelés chemins d'accès multiples natifs (NMP). NMP peut détecter le type de stockage pour les systèmes de stockage pris en charge et configure automatiquement la pile NMP afin de prendre en charge les capacités du système de stockage utilisé.</block>
  <block id="8466b1e5abb4751e931c5feb1af4e469" category="inline-link">TR-4080</block>
  <block id="4157f0c23fc104508f492dc846f187f3" category="list-text">SLM est activé par défaut. Sauf si vous utilisez des ensembles de ports, aucune configuration supplémentaire n'est requise.</block>
  <block id="597f1433ad810b3b86c7ae0f8f95afa8" category="list-text">Pour les LUN créées avant Data ONTAP 8.3, appliquez manuellement SLM en exécutant le<block ref="886fd385b633a0746a8a08f8f00c67cd" prefix=" " category="inline-code"></block> Commande permettant de supprimer les nœuds présentant les rapports LUN et de limiter l'accès des LUN au nœud propriétaire de la LUN et à son partenaire haute disponibilité.</block>
  <block id="43919b4d4d6d446ed498e26bff62db84" category="paragraph">Des protocoles de bloc (iSCSI, FC et FCoE) accèdent aux LUN à l'aide d'identifiants de LUN, de numéros de série et de noms uniques. Les protocoles FC et FCoE utilisent des noms mondiaux (WWN et WWPN) et iSCSI utilise les noms qualifiés iSCSI (IQN). Le chemin vers les LUN à l'intérieur du stockage n'a aucun sens avec les protocoles de bloc et n'est pas présenté au niveau du protocole. Par conséquent, un volume contenant uniquement des LUN n'a pas besoin d'être monté en interne et un chemin de jonction n'est pas nécessaire pour les volumes contenant les LUN utilisées dans les datastores. Le sous-système NVMe dans ONTAP fonctionne de la même manière.</block>
  <block id="ed0e76ed86e852bd7317a09d856ec4e8" category="paragraph">D'autres meilleures pratiques à prendre en compte :</block>
  <block id="93586ad57931e0f16fff61cdba9d77df" category="list-text">Vérifier qu'une interface logique (LIF) est créée pour chaque SVM sur chaque nœud du cluster ONTAP pour optimiser la disponibilité et la mobilité. La meilleure pratique du SAN de ONTAP est d'utiliser deux ports physiques et LIF par nœud, un pour chaque structure. ALUA sert à analyser les chemins et à identifier les chemins (directs) optimisés actifs/actifs au lieu de chemins non optimisés actifs. ALUA est utilisé pour FC, FCoE et iSCSI.</block>
  <block id="b3cebb7381bddbabb1e950a46d264190" category="list-text">Pour les réseaux iSCSI, utilisez plusieurs interfaces réseau VMkernel sur différents sous-réseaux du réseau avec le regroupement de cartes réseau lorsque plusieurs commutateurs virtuels sont présents. Vous pouvez également utiliser plusieurs cartes réseau physiques connectées à plusieurs commutateurs physiques pour fournir la haute disponibilité et un débit accru. La figure suivante fournit un exemple de connectivité multivoie. Dans ONTAP, configurez soit un groupe d'interface en mode unique pour basculement avec deux liaisons ou plus connectées à deux ou plusieurs switchs, soit au moyen de LACP ou d'une autre technologie d'agrégation de liens avec des groupes d'interfaces multimode afin d'assurer la haute disponibilité et les avantages de l'agrégation de liens.</block>
  <block id="2968b9f3c141bf23bc73d0e6e15a174a" category="list-text">Si le protocole CHAP (Challenge-Handshake Authentication Protocol) est utilisé dans ESXi pour l'authentification de la cible, il doit également être configuré dans ONTAP à l'aide de l'interface de ligne de commande <block ref="199c9b970eacf1c35d84a383b7ceb210" prefix="(" category="inline-code"></block>) Ou avec System Manager (modifier la sécurité de l'initiateur sous Storage &gt; SVM &gt; SVM Settings &gt; protocoles &gt; iSCSI).</block>
  <block id="d31f2e075df4ca75ca0874fa08f74b12" category="list-text">Utilisez les outils ONTAP pour VMware vSphere pour créer et gérer des LUN et des igroups. Le plug-in détermine automatiquement les WWPN des serveurs et crée les igroups appropriés. Il configure également les LUN en fonction des meilleures pratiques et les mappe avec les groupes initiateurs appropriés.</block>
  <block id="de78559e8aed2cd62fbf852f73dc58c2" category="inline-link">mode de compatibilité physique et virtuelle</block>
  <block id="905221150fdd103b5241870a0a1f2c42" category="list-text">Utilisez les RDM avec soin car ils peuvent être plus difficiles à gérer et ils utilisent également des chemins, qui sont limités comme décrit précédemment. Les LUN ONTAP prennent en charge les deux<block ref="27e1f8e5a88cfbb2836b083145b004c9" category="inline-link-rx"></block> RDM.</block>
  <block id="636da39a2033c6179a718983c5ce1222" category="inline-link">Guide de configuration d'hôte NVMe/FC de ONTAP</block>
  <block id="81ef6507a13da5635951bc5b533deb59" category="inline-link">TR-4684</block>
  <block id="15483b0826bb9a4b11d1c89af2029c5c" category="list-text">Pour en savoir plus sur l'utilisation de NVMe/FC avec vSphere 7.0, consultez cette<block ref="6b4ed262d14e47ef641cd57b65c32c38" category="inline-link-rx"></block> et<block ref="7a29b2f31035a451d5b068728d2b79a7" category="inline-link-rx"></block>La figure suivante décrit la connectivité multivoie d'un hôte vSphere vers un LUN ONTAP.</block>
  <block id="743fa5a7bc7d4ba215b096e34779d298" category="paragraph">Nous vous recommandons les meilleures pratiques suivantes lorsque vous utilisez ONTAP NFS avec vSphere :</block>
  <block id="ae4c5baa79e370d8f601cc7082f8123e" category="list-text">Étant donné qu'il n'existe pas de conversion automatique de datastore entre NFS v3 et NFS v4.1, créez un nouveau datastore NFSv4.1 et utilisez Storage vMotion pour migrer les machines virtuelles vers le nouveau datastore.</block>
  <block id="8065bff4940ae8d7161f926b0df47ac4" category="inline-link">Matrice d'interopérabilité NetApp</block>
  <block id="bd6cc42f9cd65cca72cbd56d2f4bf43d" category="list-text">Règle d'accès RO : sys</block>
  <block id="0bbc71e6a4ea49af70dd616d3807e524" category="list-text">UID anonyme</block>
  <block id="6670a317619282ec228a9ef492af0a76" category="list-text">Les volumes des datastores NFS sont rassemblés dans le volume racine du SVM. Par conséquent, ESXi doit également avoir accès au volume racine pour naviguer et monter des volumes de datastores. La export policy pour le volume root, et pour tout autre volume dans lequel la jonction du volume de datastore est imbriquée, doit inclure une règle ou des règles pour les serveurs ESXi leur accordant un accès en lecture seule. Voici un exemple de règle pour le volume racine, également à l'aide du plug-in VAAI :</block>
  <block id="8c93fb3ff528165613797962f5a0ed9c" category="list-text">Protocole d'accès : nfs (qui inclut nfs3 et nfs4)</block>
  <block id="80e6a4f964e826c69c1c62bd5ea67590" category="list-text">Règle d'accès RW : jamais (meilleure sécurité pour le volume racine)</block>
  <block id="f96625174b4a06d13267f9b0a5a96d59" category="list-text">Superutilisateur : sys (également requis pour le volume racine avec VAAI)</block>
  <block id="4c571520a8128d1692fc709ffbfb2b1e" category="list-text">Utilisez les outils ONTAP pour VMware vSphere (meilleure pratique la plus importante) :</block>
  <block id="23aa7b9aeed3fba2a1ec43e630313af7" category="list-text">Lors de la création de datastores pour clusters VMware avec le plug-in, sélectionnez le cluster plutôt qu'un seul serveur ESX. Ce choix permet de monter automatiquement le datastore sur tous les hôtes du cluster.</block>
  <block id="928562eb576ed6ae31cb1a149d3e751a" category="list-text">Lorsque vous n'utilisez pas les outils ONTAP pour VMware vSphere, utilisez une export policy unique pour tous les serveurs ou pour chaque cluster de serveurs où un contrôle d'accès supplémentaire est nécessaire.</block>
  <block id="7bccab0fa4c0864835c645c9fde7ebf6" category="list-text">Bien que ONTAP offre une structure d'espace de noms de volume flexible permettant d'organiser les volumes dans une arborescence à l'aide de jonctions, cette approche n'a aucune valeur pour vSphere. Il crée un répertoire pour chaque machine virtuelle à la racine du datastore, quelle que soit la hiérarchie de l'espace de noms du stockage. Il est donc recommandé de simplement monter le Junction path pour les volumes pour vSphere au volume root du SVM, c'est-à-dire comment les outils ONTAP pour VMware vSphere provisionne les datastores. Sans chemins de jonction imbriqués, aucun volume ne dépend d'aucun volume autre que le volume root et que mettre un volume hors ligne ou le détruire, même intentionnellement, n'affecte pas le chemin d'accès aux autres volumes.</block>
  <block id="ea6fc1288f1d3b21238d29ff28cb867a" category="list-text">Une taille de bloc de 4 Ko convient parfaitement aux partitions NTFS sur les datastores NFS. La figure suivante décrit la connectivité d'un hôte vSphere vers un datastore NFS ONTAP.</block>
  <block id="e54433644e830ed1503561b778e9ded4" category="paragraph">Le tableau suivant répertorie les versions NFS et les fonctionnalités prises en charge.</block>
  <block id="9fb9dac7513c7ef8452aade8a52ad40d" category="cell">Fonctionnalités de vSphere</block>
  <block id="5b12ee0369243579651edca43ff65c85" category="cell">NFSv3</block>
  <block id="de841868c2911da76b8ae2da9fa3166d" category="cell">NFSv4.1</block>
  <block id="64e3cc476958b05086721cd6070004cf" category="cell">VMotion et Storage vMotion</block>
  <block id="05807e454c19f244770adae059b3c330" category="cell">Haute disponibilité</block>
  <block id="45a75e44a713fdf94dbf1dbaa0749188" category="cell">Tolérance aux pannes</block>
  <block id="f1e3446c69e4d87279ff7863482f9dcb" category="cell">DRS</block>
  <block id="6ca09f98e8925b2cb78bbf24eccc0186" category="cell">Profils hôtes</block>
  <block id="ec8420797e3b089812499cce4047ded8" category="cell">DRS de stockage</block>
  <block id="7c19bf1cbe62a87a42857ef0b4fe22ae" category="cell">Contrôle des E/S du stockage</block>
  <block id="56d43ad1a280ada5e16fd2960ae44b32" category="cell">SRM</block>
  <block id="d595c8f30866b71ea121ced5cde66b1d" category="cell">Volumes virtuels</block>
  <block id="6ad5114acf73f68a85c72f11646920cb" category="cell">Accélération matérielle (VAAI)</block>
  <block id="ad37ded9046268d8e5ea7cb253bb5dda" category="cell">Authentification Kerberos</block>
  <block id="45701e6ef9bc09dca07f8f4abe661dc6" category="cell">Oui (optimisé avec vSphere 6.5 et versions ultérieures pour prendre en charge AES et krb5i)</block>
  <block id="76969a36155d2f41fc6cc3bd3faff244" category="cell">Prise en charge des chemins d'accès</block>
  <block id="be0ec3d9251292dd856ea0924ecc6873" category="doc">La qualité de service (QoS)</block>
  <block id="534ecd446aac2f9c809eef9064f44aab" category="paragraph">Le débit maximal de QoS sur un objet peut être défini en Mbit/s et/ou IOPS. Si les deux sont utilisés, la première limite atteinte est appliquée par ONTAP. Une charge de travail peut contenir plusieurs objets et une règle de QoS peut être appliquée à un ou plusieurs workloads. Lorsqu'une règle est appliquée à plusieurs workloads, celle-ci partage la limite totale de la règle. Les objets imbriqués ne sont pas pris en charge (par exemple, les fichiers d'un volume ne peuvent pas chacun avoir leur propre stratégie). La valeur minimale de qualité de service ne peut être définie que dans les IOPS.</block>
  <block id="040f184b126879657b253b6d258661d9" category="paragraph">Les outils suivants sont actuellement disponibles pour la gestion des règles de QoS de ONTAP et leur application aux objets :</block>
  <block id="de134183bea5df515a6756a539ce6f18" category="list-text">INTERFACE DE LIGNE DE COMMANDES DE ONTAP</block>
  <block id="6ad5e0a20f49ad6a370454bb3afc9a9e" category="list-text">ONTAP System Manager</block>
  <block id="8e23e05fc0865e950d6a3581e0dd8ce9" category="list-text">OnCommand Workflow Automation</block>
  <block id="5ecb6b24c169667ff1a176768115659e" category="list-text">Active IQ Unified Manager</block>
  <block id="8cc4e713850f67a131e9dbf8b997f61e" category="list-text">Kit d'outils NetApp PowerShell pour ONTAP</block>
  <block id="fcdb48d0d22627e4910a8352c80bd87a" category="list-text">Outils ONTAP pour VMware vSphere VASA Provider</block>
  <block id="e6defd03e0f49585b6d47614713e97f7" category="paragraph">Pour affecter une politique de QoS à un VMDK sur NFS, suivez les consignes suivantes :</block>
  <block id="2175e0e29bc4b213fa8b9c7afd591b6b" category="list-text">N'appliquez pas de règles aux autres fichiers VM tels que les fichiers d'échange virtuels <block ref="aa33c3c1850a3f99cec7426e2c411d08" prefix="(" category="inline-code"></block>).</block>
  <block id="8230e9b5c1e9862fedb2c69f7cc5d3d1" category="list-text">Lors de l'utilisation du client Web vSphere pour trouver des chemins de fichiers (datastore &gt; fichiers), notez qu'il combine les informations de l'<block ref="f149d7424e10a266ec998ca5b32b81bb" prefix=" " category="inline-code"></block> et<block ref="4a78be158c13cd6b2dc2100a80bb7070" prefix=" " category="inline-code"></block> et montre simplement un fichier avec le nom du<block ref="4a78be158c13cd6b2dc2100a80bb7070" prefix=" " category="inline-code"></block> mais la taille du<block ref="f149d7424e10a266ec998ca5b32b81bb" prefix=" " category="inline-code"></block>. Autres<block ref="4fc4e556dbb9dcede037ccd80fabd784" prefix=" " category="inline-code"></block> dans le nom du fichier pour obtenir le chemin correct.</block>
  <block id="1d4614aca13104c98d5d8cc2d415b941" category="paragraph">Pour affecter une QoS à une LUN, y compris VMFS et RDM, le SVM ONTAP (affiché comme vServer), le chemin LUN et le numéro de série peuvent être obtenus du menu systèmes de stockage de la page d'accueil des outils ONTAP pour VMware vSphere. Sélectionner le système de stockage (SVM), puis objets associés &gt; SAN.  Utilisez cette approche lors de la spécification de QoS à l'aide de l'un des outils ONTAP.</block>
  <block id="77bb2ba950959bd3f1c55da523ace0be" category="section-title">QoS ONTAP et SIOC VMware</block>
  <block id="5ad234cb2cde4266195252a23ca7d84e" category="cell">Propriété</block>
  <block id="b8b8d1ba8fa345f03438a90f29af5784" category="cell">QoS de ONTAP</block>
  <block id="c2a4cb962db2a4a6782b69864f0e411c" category="cell">SIOC VMware</block>
  <block id="aa628d5a66888444926b4dc042458200" category="cell">Lorsqu'il est actif</block>
  <block id="688b10fcfff927dee65634e3b3636064" category="cell">La règle est toujours active</block>
  <block id="a981c4aa67c29ff2d36fc614d8b28808" category="cell">Actif en cas de conflit (latence du datastore supérieure au seuil)</block>
  <block id="f46e64a82c96db56f3d6657d4fb53f00" category="cell">Type d'unités</block>
  <block id="878b4223bb85b95d8caf0429d9406cd5" category="cell">IOPS, Mo/sec</block>
  <block id="3e189a34f422a141311dad231f9ad5b5" category="cell">IOPS, partages</block>
  <block id="7367a0ec46339213625cbc77d56a9572" category="cell">Étendue vCenter ou des applications</block>
  <block id="1faff19290bb64ce8ff6bc1220496881" category="cell">Plusieurs environnements vCenter, d'autres hyperviseurs et applications</block>
  <block id="1e664a3cc0ab109fcabcc81b488cebb1" category="cell">Un seul serveur vCenter</block>
  <block id="ebccc9f5c939841d86e5382988dfcc47" category="cell">Définir la qualité de service sur la machine virtuelle ?</block>
  <block id="cddd0980ce99890d2ea90288f6b03117" category="cell">VMDK sur NFS uniquement</block>
  <block id="928629d8a2a889f5274cad9940a06da0" category="cell">VMDK sur NFS ou VMFS</block>
  <block id="305e85b992089534091855224f60cf75" category="cell">Définir la qualité de service sur la LUN (RDM) ?</block>
  <block id="e798014243cf5682e7fb3aaf4ee7cecf" category="cell">Définir la QoS sur LUN (VMFS) ?</block>
  <block id="9cd021ea9d3c88de723fe9a2e50a2380" category="cell">Définir la qualité de service sur le volume (datastore NFS) ?</block>
  <block id="c352b53c32380efcf4436926da6d0414" category="cell">Qualité de service définie sur un SVM (locataire) ?</block>
  <block id="5dad340ee8f9e8fa9b65bf86a9fd5341" category="cell">Approche basée sur des règles ?</block>
  <block id="b31c76176f26196c6379a9bcce212d99" category="cell">Oui. Elles peuvent être partagées par toutes les charges de travail dans la règle ou appliquées en totalité à chaque charge de travail dans la règle.</block>
  <block id="1ff33557bad923d68973872cacf2e43a" category="cell">Oui, avec vSphere 6.5 et versions ultérieures.</block>
  <block id="d5f1465492190ee9d30a09b36f64f4b7" category="cell">Licence requise</block>
  <block id="4cec76d82991abd453484c23f7e3788a" category="cell">Inclus avec ONTAP</block>
  <block id="6bb36803f4670824ff9ebdf665654829" category="cell">Enterprise plus</block>
  <block id="d4d4b5b65bebf236590d70c702a6ba6b" category="paragraph">VMware Storage Distributed Resource Scheduler (SDRS) est une fonctionnalité vSphere qui place les machines virtuelles sur un stockage en fonction de la latence d'E/S actuelle et de l'utilisation de l'espace. Il déplace ensuite la machine virtuelle ou les VMDK sans interruption entre les datastores d'un cluster de datastores (également appelé pod), en sélectionnant le meilleur datastore pour placer la machine virtuelle ou les VMDK dans le cluster de datastore. Un cluster de data stores est un ensemble de datastores similaires agrégés dans une unité de consommation unique du point de vue de l'administrateur vSphere.</block>
  <block id="01e838e1c124042f75adb374a81f72a6" category="paragraph">Les API VMware vSphere pour Storage Awareness (VASA) permettent à un administrateur du stockage de configurer des datastores avec des fonctionnalités bien définies et de permettre à l'administrateur des VM de les utiliser chaque fois que nécessaire pour provisionner des machines virtuelles sans avoir à interagir les unes avec les autres. Il est intéressant d'étudier cette approche pour savoir comment rationaliser vos opérations de stockage de virtualisation et éviter un travail insignifiant.</block>
  <block id="0ce8b0e3e0d7dc7f39c62fb74a28b3bf" category="section-title">Migration et sauvegarde dans le cloud</block>
  <block id="4fe11b4a91ff38ec9933009a15dd5b0b" category="paragraph">ONTAP permet également la prise en charge étendue du cloud hybride en fusionnant les systèmes de votre cloud privé sur site avec des capacités de cloud public. Voici quelques solutions clouds NetApp qui peuvent être utilisées en association avec vSphere :</block>
  <block id="99c6c4d349151c1f4a6694e424aef741" category="inline-link">Stockez davantage de snapshots de vos machines virtuelles</block>
  <block id="01fa297dbdab5aceb83a45a98161efe0" category="list-text">*FabricPool.* FabricPool offre un Tiering simple et rapide pour les données ONTAP. Les blocs inactifs peuvent être migrés vers un magasin d'objets dans des clouds publics ou un magasin d'objets StorageGRID privé. Ils sont automatiquement rappelés lorsque vous accédez de nouveau aux données ONTAP. Vous pouvez également utiliser le Tier objet comme troisième niveau de protection pour les données déjà gérées par SnapVault. Cette approche peut vous permettre de<block ref="60d027dbb3c3f076cbb70c6b246eb433" category="inline-link-rx"></block> Sur les systèmes de stockage ONTAP primaires et/ou secondaires.</block>
  <block id="1a7072854c9dd945a98f4314b3f77408" category="list-text">*ONTAP Select.* utilisez le stockage Software-defined NetApp pour étendre votre cloud privé sur Internet aux sites et bureaux distants, où vous pouvez utiliser ONTAP Select pour prendre en charge les services de blocs et de fichiers ainsi que les mêmes fonctionnalités de gestion de données vSphere que votre data Center d'entreprise.</block>
  <block id="79aec220098057ef8c0e46281a45d6c2" category="paragraph">Lors de la conception de vos applications basées sur une VM, pensez à la mobilité future du cloud. Par exemple, plutôt que de placer les fichiers d'application et de données en même temps que les fichiers de données, utilisez une exportation LUN ou NFS distincte. Cela vous permet de migrer la machine virtuelle et les données séparément vers des services cloud.</block>
  <block id="af63597853dc0983258c8f86a12aae0b" category="section-title">Chiffrement pour les données vSphere</block>
  <block id="63a07ab9352c9297cea3894d6cd41c3f" category="paragraph">Aujourd'hui, les exigences croissantes en matière de protection des données au repos sont liées au chiffrement. Bien que la priorité initiale ait été donnée aux informations financières et de santé, il est de plus en plus intéressant de protéger toutes les informations, qu'elles soient stockées dans des fichiers, des bases de données ou tout autre type de données.</block>
  <block id="937a352e0f824ff55e4cd50c8e3b051e" category="paragraph">Il existe plusieurs approches de protection des données des applications virtualisées qui s'exécutent sur VMware vSphere. L'une d'elles consiste à protéger les données avec les logiciels internes à la machine virtuelle au niveau du système d'exploitation invité. Les nouveaux hyperviseurs, tels que vSphere 6.5, prennent désormais en charge le cryptage au niveau des machines virtuelles. Cependant, le chiffrement logiciel NetApp est simple et facile :</block>
  <block id="6eda79cc710edc32583cf567b00e7672" category="list-text">*Aucun effet sur la CPU du serveur virtuel.* certains environnements de serveurs virtuels nécessitent chaque cycle CPU disponible pour leurs applications, mais les tests ont montré que jusqu'à 5x ressources CPU sont nécessaires avec le cryptage au niveau de l'hyperviseur. Même si le logiciel de chiffrement prend en charge l'ensemble d'instructions AES-ni d'Intel pour décharger la charge de travail de chiffrement (comme le fait le chiffrement du logiciel NetApp), cette approche peut ne pas être possible en raison de l'exigence de nouveaux processeurs non compatibles avec les anciens serveurs.</block>
  <block id="6abee98aea26f85e6f0fe8d4db70f998" category="list-text">*Gestionnaire de clés intégré inclus.* le chiffrement logiciel NetApp inclut un gestionnaire de clés intégré sans frais supplémentaires, ce qui simplifie les prises en main sans serveurs de gestion des clés haute disponibilité complexes à acheter et à utiliser.</block>
  <block id="c216121021de8554d33503ef6616b256" category="list-text">*Aucun effet sur l'efficacité du stockage.* les techniques d'efficacité du stockage comme la déduplication et la compression sont largement utilisées aujourd'hui et sont essentielles pour exploiter les supports disque Flash de façon rentable. Toutefois, les données cryptées ne sont en général pas dédupliquées ou compressées. Le cryptage du stockage et du matériel NetApp fonctionne à un niveau inférieur et permet l'utilisation totale des fonctionnalités d'efficacité du stockage NetApp, contrairement aux autres approches.</block>
  <block id="5f9aa8333f218d1c21e67c8608a48672" category="list-text">*Chiffrement granulaire simple des datastores.* avec NetApp Volume Encryption, chaque volume bénéficie de sa propre clé AES 256 bits. Si vous devez le modifier, utilisez une seule commande. Cette approche est idéale si vous disposez de plusieurs locataires ou si vous devez prouver votre chiffrement indépendant pour différents services ou applications. Ce chiffrement est géré au niveau du datastore, ce qui est bien plus simple que de gérer des machines virtuelles individuelles.</block>
  <block id="de2b3baa1cd4980c36e8bbf7c827ae0c" category="paragraph">La prise en main du chiffrement logiciel est très simple. Une fois la licence installée, il vous suffit de configurer le gestionnaire de clés intégré en spécifiant une phrase secrète, puis de créer un volume ou de déplacer un volume côté stockage pour activer le chiffrement. NetApp travaille à ajouter une prise en charge plus intégrée des fonctionnalités de cryptage dans les prochaines versions de ses outils VMware.</block>
  <block id="c95fa5b56a01e5c1a80c540c1ab1a750" category="paragraph">Active IQ Unified Manager permet d'avoir une grande visibilité sur les machines virtuelles de votre infrastructure virtuelle et assure la surveillance et le dépannage des problèmes de stockage et de performances dans votre environnement virtuel.</block>
  <block id="be75250c2f30870dc1e359b4ade2a767" category="paragraph">Un déploiement d'infrastructure virtuelle standard sur ONTAP comporte divers composants répartis sur les couches de calcul, de réseau et de stockage. Tout ralentissement des performances dans une application VM peut survenir en raison de la combinaison de latences rencontrées par les différents composants au niveau des couches respectives.</block>
  <block id="d1734f6f2e65a1488896f74695db5254" category="paragraph">La capture d'écran suivante présente la vue des machines virtuelles Active IQ Unified Manager.</block>
  <block id="2118336fa447fcc0f213cb8c40c516af" category="paragraph">Unified Manager présente le sous-système sous-jacent d'un environnement virtuel dans une vue topologique afin de déterminer si un problème de latence a eu lieu dans le nœud de calcul, le réseau ou le stockage. La vue indique également l'objet spécifique qui provoque le décalage des performances lors de la réalisation des étapes correctives et de la résolution du problème sous-jacent.</block>
  <block id="d8a78b994fcd4e04901203a2e7bc6414" category="paragraph">La capture d'écran suivante montre la topologie étendue AIQUM.</block>
  <block id="f02207fb26160d7e47cf5ea35d07df03" category="doc">Datastores et protocoles</block>
  <block id="a7c815fafe60ae637d38216fa6300395" category="list-text">FCP</block>
  <block id="26bcb9f1cb6f391f4b2c18e676bb458d" category="list-text">NVMe/FC</block>
  <block id="8b7c42123642e2e4ea7dd426aeb2de58" category="list-text">NVMe/TCP</block>
  <block id="e4e1c13bb0b14f6cb7608cbecea948ef" category="list-text">ISCSI</block>
  <block id="f7d773fd2896401c143676940bc001fc" category="list-text">NFS v3</block>
  <block id="0b99b245267ef194ca3b9f6e694b0983" category="list-text">NFS v4.1</block>
  <block id="9da73946f1bc3be4a41898d06c9d2e8b" category="cell">Capacités/fonctionnalités</block>
  <block id="6151632541dcd80356c6c76b34d69d0c" category="cell">NVMe-of</block>
  <block id="520d0db389f362bf79ef56ca0af3dcab" category="cell">Format</block>
  <block id="99a3142584ca8ad0a3afadeaa6f2ef69" category="cell">Mappage de périphériques VMFS ou bruts (RDM)</block>
  <block id="26aae26f61844ac20ab7b04ba6f5c515" category="cell">VMFS ou RDM</block>
  <block id="18263a30df8afc60a733e59c60676ac0" category="cell">VMFS</block>
  <block id="382b0f5185773fa0f67a8ed8056c7759" category="cell">S/O</block>
  <block id="8dc6d0c66219ddb809322c0d248e55e6" category="cell">Nombre maximal de datastores ou de LUN</block>
  <block id="aa23f9914ce1939ea7a4d479edfdc915" category="cell">1024 LUN par hôte</block>
  <block id="1af3b27207afc48a363629a315d76b59" category="cell">1024 LUN par serveur</block>
  <block id="0705fd627c25b5fba17cd9a022ed7d72" category="cell">256 Namespeces par serveur</block>
  <block id="2774ddb6f193789c5d9a480b9e53a38d" category="cell">256 supports
NFS par défaut. MaxVolumes est 8. Utilisez les outils ONTAP pour VMware vSphere et augmentez jusqu'à 256.</block>
  <block id="51c0dc217976e27de06e262947947a62" category="cell">Taille maximale des datastores</block>
  <block id="856c997f909830b8249756c07dc9452b" category="cell">64 TO</block>
  <block id="8e5d3a4b085389c59a1a7af7c4067a9b" category="cell">Volume FlexVol de 100 To ou supérieur avec FlexGroup volume</block>
  <block id="b4fb1d41fedaec79072964cbb4d16e3d" category="cell">Taille maximale des fichiers du datastore</block>
  <block id="d10549beb2f7bd1e91e5ef8965edd84a" category="cell">62TO</block>
  <block id="18301e675ce7d51c23071d7b135edbdc" category="cell">62 To avec ONTAP 9.12.1P2 et versions ultérieures</block>
  <block id="9aa56a79640231adaec83bc53e59c929" category="cell">Profondeur de file d'attente optimale par LUN ou par système de fichiers</block>
  <block id="c7dfde106afbb4e1d55096403af252e0" category="cell">64-256</block>
  <block id="ca6e77250a239af7b4aed9a1ac058825" category="cell">Négociation automatique</block>
  <block id="edc5121cb9b42a76b718b8ece9d67437" category="paragraph">Le tableau suivant répertorie les fonctionnalités de stockage VMware prises en charge.</block>
  <block id="6c1a84b789b54fd42511ce582be94d21" category="cell">VMotion</block>
  <block id="e95b58d02782c970bb339c6cc587ff39" category="cell">Stockage vMotion</block>
  <block id="0486e0e3dc3e86859f43b6d8e32b8071" category="cell">Haute disponibilité VMware</block>
  <block id="8be6bd7f20474cbefdd496cb9fd495ca" category="cell">Storage Distributed Resource Scheduler (SDRS)</block>
  <block id="28c2f8ab9cdbf296aa4261bc3c58ba0d" category="cell">Microsoft Cluster Service (MSCS) ou mise en cluster de basculement au sein d'une machine virtuelle</block>
  <block id="aa7f77e663b832d5b0e544c5511e680c" category="cell">Non pris en charge</block>
  <block id="aa18abedec09bd4f85e612c307e2eaa6" category="cell">Tolérance aux pannes</block>
  <block id="bfd52522de4ac6efd6f680e0e754eeb5" category="cell">Gestionnaire de reprise de site</block>
  <block id="17d495427086fa21259b9df40b27e00a" category="cell">Machines virtuelles à provisionnement fin (disques virtuels)</block>
  <block id="4ee7af004efef335d6a14c60ee758f5e" category="cell">Oui.
Ce paramètre est le paramètre par défaut pour toutes les machines virtuelles sur NFS lorsqu'elles n'utilisent pas VAAI.</block>
  <block id="13bc264ff420559de4156ec40980a4b9" category="cell">Chemins d'accès multiples natifs VMware</block>
  <block id="50ed43e1a7a22335069a344bc706b600" category="cell">Oui, en utilisant le nouveau plug-in haute performance (HPP)</block>
  <block id="a06819d91a165d0491c5816c54b41234" category="paragraph">Le tableau suivant répertorie les fonctionnalités de gestion du stockage ONTAP prises en charge.</block>
  <block id="f8d61013f1a3bbf1342f4ced3279c7cf" category="cell">Déduplication des données</block>
  <block id="72167540968147afed9deb59f0e9fe00" category="cell">D'économies sur la baie</block>
  <block id="9a5473a6abaea16b736f096913a749be" category="cell">Économies au niveau du datastore</block>
  <block id="6cd880eabbec3488232c6cba3fbcf998" category="cell">Provisionnement fin</block>
  <block id="5caeb11c4ed379b808d7f7cdca7cfbf0" category="cell">Datastore ou RDM</block>
  <block id="8a5227cc82d14862956938caffc1acf2" category="cell">Datastore</block>
  <block id="b71ba22dcd42deceac87150206f7bd12" category="cell">Redimensionnement datastore</block>
  <block id="c6b792bfd7aac8067d36337e67d11545" category="cell">Évoluer uniquement</block>
  <block id="29e23534878bb63341e0b689426b7fb0" category="cell">Croissance, croissance automatique et réduction des volumes</block>
  <block id="76021405cc62a4b8c542e7f65e3d24ed" category="cell">Plug-ins SnapCenter pour applications Windows, Linux (invités)</block>
  <block id="c0b3c629432c82a9e8500242abb35eaf" category="cell">Contrôle et configuration de l'hôte à l'aide des outils ONTAP pour VMware vSphere</block>
  <block id="5a915a8215e9a66bcff0f034e8adff18" category="cell">Provisionnement avec les outils ONTAP pour VMware vSphere</block>
  <block id="6495c7cda42bf1b80bc1c2af6166ef58" category="paragraph">Le tableau suivant répertorie les fonctionnalités de sauvegarde prises en charge.</block>
  <block id="ad336d1fccea3e918d07055edac855a3" category="cell">Snapshots ONTAP</block>
  <block id="bf22a1b5bc2b72a75825094826a942de" category="cell">SRM pris en charge par les sauvegardes répliquées</block>
  <block id="60d3f7d9f265eb34e826da352cb545be" category="cell">SnapMirror volume</block>
  <block id="fabf31a57c142c986c5d88cb089b3d7b" category="cell">Accès image VMDK</block>
  <block id="40b655e79545b3922b8095be28d59428" category="cell">Logiciel de sauvegarde VADP</block>
  <block id="8215e73d220182794dfbd75ad494c727" category="cell">Logiciel de sauvegarde VADP, vSphere client et le navigateur du datastore du client Web vSphere</block>
  <block id="d7605580ecad0fcb4528789d74cdcad5" category="cell">Accès niveau fichier VMDK</block>
  <block id="906ece32da286d6c4b323bc0d6443b7c" category="cell">Logiciel de sauvegarde VADP, Windows uniquement</block>
  <block id="d17e2fa63a62622f88bf170612132383" category="cell">Logiciels de sauvegarde VADP et applications tierces</block>
  <block id="4e3d259d82a536e12c5c9c948b62e26a" category="cell">Granularité NDMP</block>
  <block id="90d45e02e50c81603c36a4e4ad3649d9" category="cell">Datastore ou VM</block>
  <block id="8339c514e73f5cced3b83d504d60441b" category="inline-link">Configuration de Windows Server Failover Clustering</block>
  <block id="54b3e11ce37eaaa9884f4086e72dd2be" category="section-title">Sélection d'un protocole de stockage</block>
  <block id="0212b4e8bc965dcd8a7ff771dd96bf21" category="paragraph">Les facteurs suivants peuvent être utiles lors de l'examen d'un choix de protocole :</block>
  <block id="0425ddb6dbbe7f13280e19e1f925b0a8" category="list-text">*Environnement client actuel.* même si les équipes INFORMATIQUES sont généralement compétentes en matière de gestion de l'infrastructure IP Ethernet, elles ne sont pas toutes qualifiées pour la gestion d'une structure SAN FC. Cependant, l'utilisation d'un réseau IP générique non conçu pour le trafic de stockage risque de ne pas fonctionner correctement. Considérez l'infrastructure de réseau que vous avez en place, toutes les améliorations planifiées, ainsi que les compétences et la disponibilité du personnel pour les gérer.</block>
  <block id="774f1348caf3e145710073eb634c4fa1" category="list-text">*Simplicité d'installation.* au-delà de la configuration initiale de la structure FC (commutateurs et câblage supplémentaires, segmentation et vérification de l'interopérabilité des HBA et des micrologiciels), les protocoles de bloc exigent également la création et le mappage de LUN, ainsi que la découverte et le formatage par le système d'exploitation invité. Une fois les volumes NFS créés et exportés, ils sont montés par l'hôte ESXi et prêts à être utilisés. Avec NFS, il n'a pas de qualification de matériel ni de firmware à gérer.</block>
  <block id="bf5169ce5bb544313eaf17435f756da2" category="list-text">* Facilité de gestion.* avec les protocoles SAN, si plus d'espace est nécessaire, plusieurs étapes sont nécessaires, y compris l'expansion d'un LUN, de recanning pour découvrir la nouvelle taille, puis de développer le système de fichiers). Bien que la croissance d'une LUN soit possible, la réduction de la taille d'une LUN n'est pas possible et la restauration de l'espace inutilisé peut nécessiter un effort supplémentaire. NFS facilite le dimensionnement et le redimensionnement peut être automatisé par le système de stockage. LE SYSTÈME SAN permet de réclamer de l'espace via les commandes TRIM/UNMAP du système d'exploitation invité. L'espace des fichiers supprimés est ainsi renvoyé à la baie. Ce type de récupération d'espace est plus difficile avec les datastores NFS.</block>
  <block id="530c759326761c6ac026b313985b255f" category="list-text">*Transparence de l'espace de stockage.* l'utilisation du stockage est généralement plus facile à voir dans les environnements NFS parce que le provisionnement fin renvoie immédiatement des économies. De même, les économies de déduplication et de clonage sont immédiatement disponibles pour les autres VM dans le même datastore ou pour les autres volumes du système de stockage. La densité des machines virtuelles est également meilleure généralement dans un datastore NFS, ce qui permet d'améliorer les économies de déduplication et de réduire les coûts de gestion en utilisant moins de datastores à gérer.</block>
  <block id="16ee928b12bc598bf52b0f312879ec95" category="section-title">Disposition des datastores</block>
  <block id="b8c499c7b537f5bd4e51b0a6d6a1e9d0" category="list-text">Le déploiement de vSphere avec des datastores NFS ONTAP offre une implémentation très performante et facile à gérer qui fournit des ratios VM/datastore qui ne peuvent pas être obtenus avec des protocoles de stockage de niveau bloc. Cette architecture peut entraîner une multiplication par dix de la densité des datastores avec une corrélation réduction du nombre de datastores. Bien qu'un datastore plus volumineux puisse améliorer l'efficacité du stockage et offrir des avantages opérationnels, envisagez d'utiliser au moins quatre datastores (volumes FlexVol) pour stocker vos machines virtuelles sur un seul contrôleur ONTAP afin d'optimiser les performances des ressources matérielles. Cette approche vous permet également de créer des datastores avec différentes règles de restauration. Certaines peuvent être sauvegardées ou répliquées plus fréquemment que d'autres, en fonction des besoins de l'entreprise. Les volumes FlexGroup n'ont pas besoin de plusieurs datastores pour améliorer les performances, car ils évoluent indépendamment de la conception.</block>
  <block id="dc4d78be836807b32c7ef7f42028b1ef" category="list-text">La taille correcte des datastores de volumes FlexVol est d'environ 4 To à 8 To. Cette taille constitue un bon équilibre pour les performances, la facilité de gestion et la protection des données. Démarrer petit (4 To, par exemple) et étendre le datastore en fonction des besoins (jusqu'à 100 To maximum). Les datastores plus petits peuvent être plus rapides à restaurer depuis la sauvegarde ou après un incident, et déplacés rapidement dans l'ensemble du cluster. Envisagez d'utiliser la fonction de dimensionnement automatique de ONTAP pour augmenter et réduire automatiquement le volume en fonction des modifications de l'espace utilisé. Les outils ONTAP de l'assistant de provisionnement des datastores VMware vSphere utilisent la taille automatique par défaut pour les nouveaux datastores. Vous pouvez également personnaliser davantage les seuils d'extension et de réduction ainsi que la taille maximale et minimale, avec System Manager ou la ligne de commandes.</block>
  <block id="8c761039ef4dd69451490b849ace1f82" category="list-text">Évitez d'utiliser des utilitaires de défragmentation au sein du système d'exploitation invité, car cela n'améliore pas les performances et affecte l'efficacité du stockage et l'utilisation de l'espace Snapshot. Envisagez également de désactiver l'indexation des recherches sur le système d'exploitation invité pour les postes de travail virtuels.</block>
  <block id="14abb814748566a24367c4459a54840b" category="list-text">ONTAP s'est leader du marché en proposant des fonctionnalités innovantes d'efficacité du stockage qui vous permettent d'exploiter au maximum votre espace disque utilisable. Les systèmes AFF renforcent cette efficacité avec la compression et la déduplication à la volée par défaut. Les données sont dédupliquées sur tous les volumes d'un agrégat. Ainsi, vous n'avez plus besoin de regrouper des systèmes d'exploitation similaires et des applications similaires au sein d'un même datastore pour optimiser les économies.</block>
  <block id="446548f2b1301893641e29657fc7fe53" category="inline-link-macro">Les bases de données Oracle sur ONTAP</block>
  <block id="6cda576d2fd323c1a728b7ac67d6034f" category="list-text">Les disques de première classe (ou des disques virtuels améliorés) permettent de gérer des disques gérés par vCenter indépendamment d'une machine virtuelle dotée de vSphere 6.5 et versions ultérieures. Lorsqu'elles sont principalement gérées par API, elles peuvent être utiles avec vvols, en particulier lorsqu'elles sont gérées par les outils OpenStack ou Kubernetes. Ils sont pris en charge par ONTAP ainsi que par les outils ONTAP pour VMware vSphere.</block>
  <block id="71318121439b39fdf872bb0bd57494f2" category="section-title">Migration des datastores et des machines virtuelles</block>
  <block id="e8824ce2062c6d1fc536163f7b8940bd" category="paragraph">Lorsque vous migrez des machines virtuelles depuis un datastore existant sur un autre système de stockage vers ONTAP, voici quelques principes à prendre en compte :</block>
  <block id="73b729fbc964c7d78dd90b64aaaeb785" category="list-text">Utilisez Storage vMotion pour déplacer la masse de vos machines virtuelles vers ONTAP. Cette approche n'assure pas seulement une exécution sans interruption des machines virtuelles. Elle permet également d'exploiter des fonctionnalités d'efficacité du stockage de ONTAP, comme la déduplication et la compression à la volée, pour traiter les données lors de leur migration. Envisagez d'utiliser les fonctionnalités de vCenter pour sélectionner plusieurs machines virtuelles dans la liste d'inventaire, puis planifiez la migration (utilisez la touche Ctrl tout en cliquant sur actions) à un moment opportun.</block>
  <block id="e512c890754c686d8deccac97d84a290" category="list-text">Bien que vous puissiez planifier avec soin une migration vers des datastores de destination appropriés, il est souvent plus simple de les migrer en bloc, puis de les organiser ultérieurement, si nécessaire. Utilisez cette approche pour orienter la migration vers différents datastores si vous avez besoin de protection des données spécifique, par exemple des calendriers Snapshot différents.</block>
  <block id="616b2180a0659911fed5aa758dba722c" category="list-text">La plupart des machines virtuelles et leur stockage peuvent être migrées lors de l'exécution (à chaud), mais pour migrer le stockage attaché (hors datastore) tel qu'un ISO (ISO), une LUN ou des volumes NFS à partir d'un autre système de stockage, il peut exiger une migration à froid.</block>
  <block id="9fb2cc2ced88ce872ef16c37d8284360" category="paragraph">Le plug-in permet également d'utiliser d'autres outils ONTAP dans les environnements vSphere. Il vous permet d'installer le plug-in NFS pour VMware VAAI, ce qui permet d'alléger la copie vers ONTAP pour les opérations de clonage de machines virtuelles, de réserver de l'espace pour les fichiers de disques virtuels lourds et de décharger les snapshots ONTAP.</block>
  <block id="6161d374e9022f89382fd63b4be15aa1" category="section-title">Réseau général</block>
  <block id="c7949782ad094d3ffc126bee722642a3" category="list-text">Utilisez des commutateurs qui prennent en charge l'agrégation de liens des ports sur deux châssis de commutateurs distincts grâce à une approche de groupe d'agrégation de liens multichâssis, telle que Virtual PortChannel (VPC) de Cisco.</block>
  <block id="9dc1904e0c3ace141704b477cd9b345d" category="inline-link">Gestion de réseau</block>
  <block id="68ecdb0d7a96e68318a53d12e9fab5b5" category="list-text">Utilisez LACP pour créer des agrégats de liens pour les systèmes de stockage ONTAP avec des groupes d'interfaces multimode dynamiques avec un hachage de port ou d'IP. Reportez-vous à la section<block ref="b87480ad0ff34784c4be1445a72a3aaf" category="inline-link-rx"></block> pour obtenir des conseils supplémentaires.</block>
  <block id="3b407fe7c9654197902b1dd26af6dc81" category="list-text">Utilisez une stratégie de regroupement de hachage IP sur ESXi lors de l'agrégation de liens statiques (EtherChannel, par exemple) et des vSwitch standard ou de l'agrégation de liens basée sur LACP avec des commutateurs distribués vSphere. Si l'agrégation de liens n'est pas utilisée, utilisez plutôt « route basée sur l'ID de port virtuel d'origine ».</block>
  <block id="ee1ef6cf0f3971b44eb2abcac958fb8d" category="section-title">Volumes FlexGroup</block>
  <block id="dd9bd4a686bdeb1c7f11dc3cd0cda75f" category="paragraph">Prenons le scénario suivant :</block>
  <block id="6b277580cb59b13790b36344e827e22f" category="list-text">Vous avez créé un nouveau FlexGroup avec 8 composants</block>
  <block id="32efd8b10cc3b73c344f4c7e6c4b741e" category="list-text">Le délai d'expiration du cache pour le nouveau FlexGroup est défini sur 160 minutes</block>
  <block id="879f959734466d50681eae9b95e7e591" category="paragraph">Dans ce scénario, les 8 premiers clones à terminer seront des copies complètes, et non des clones de fichiers locaux. Tout clonage supplémentaire de cette machine virtuelle avant l'expiration du délai de 160 secondes utilisera le moteur de clonage de fichiers à l'intérieur de chaque composant de manière circulaire pour créer des copies quasi immédiates réparties uniformément sur les volumes constitutifs.</block>
  <block id="0f98175ace2dd0d56e47961b22b2544b" category="paragraph">Dans les environnements où vous ne pouvez pas tirer pleinement parti du cache FlexGroup, mais où vous avez toujours besoin d'un clonage rapide entre plusieurs volumes, envisagez d'utiliser les vVols. Le clonage entre volumes avec vVols est beaucoup plus rapide qu'avec les datastores traditionnels et ne repose pas sur un cache.</block>
  <block id="189aae773e13462525f07e99fcd9e90f" category="inline-link">VAAI : comment la mise en cache fonctionne-t-elle avec les volumes FlexGroup ?</block>
  <block id="718103d957da7fb9e8210a49a85aedab" category="paragraph">Pour plus d'informations sur l'utilisation de FlexGroups avec VAAI, consultez l'article de la base de connaissances suivant :<block ref="23db52497ce446299e31ecc0b7572649" category="inline-link-rx"></block></block>
  <block id="ce4df831657d2621e80bbef9271c33cd" category="summary">Avec la transition de l'appliance virtuelle existante, les outils ONTAP apportent une richesse de nouvelles fonctionnalités, de limites plus élevées, et de la prise en charge de nouveaux vvols.</block>
  <block id="45b1565c472fff4046d0f7ddbe1342f2" category="doc">Nouvelles fonctionnalités de SRM et des outils ONTAP</block>
  <block id="116d20fc387d73c8e4a86e7998913947" category="section-title">Dernières versions de vSphere et de site Recovery Manager</block>
  <block id="57359b8d2b77ce83f2e854fdd323377f" category="paragraph">Avec la version 8.7 et ultérieure de SRM et les versions 9.12 et ultérieures des outils ONTAP, vous pouvez désormais protéger les machines virtuelles qui s'exécutent sur VMware vSphere 8 mise à jour 1.</block>
  <block id="96ca6fcc2ffdab3c06d0875be8d4fe29" category="paragraph">NetApp a partagé un partenariat étroit avec VMware depuis près de deux décennies, et s'efforce de fournir une assistance pour les dernières versions dès que possible. Consultez toujours la matrice d'interopérabilité NetApp (IMT) pour connaître les dernières combinaisons logicielles qualifiées.</block>
  <block id="4ada3eb5b908caaedb757052562dfcf5" category="inline-link-macro"><block ref="4ada3eb5b908caaedb757052562dfcf5" category="inline-link-rx"></block></block>
  <block id="0a0a2a299629bed81a283fcd3b7833e9" category="paragraph">Le NetApp IMT est disponible à l'adresse <block ref="83e08b5e992bc41d59feec38bb24f26d" category="inline-link-macro-rx"></block>.</block>
  <block id="9d6e1631f68d52fd0f82222bf276cdc4" category="section-title">La prise en charge des vVols (et la raison pour laquelle la gestion basée sur des règles de stockage (SPBM) compte, même avec SRM)</block>
  <block id="b0b7bc3c901f340c708b7560d1f2b7e1" category="paragraph">À partir de la version 8.3, SRM prend désormais en charge la gestion basée sur les règles de stockage (SPBM) de la réplication exploitant les vVols et la réplication basée sur les baies pour les datastores utilisant iSCSI, FCP et NFS v3. Pour ce faire, le serveur SRM a été mis à jour pour inclure un nouveau service de fournisseur SRM vVols, qui communique avec le service SMS du serveur vCenter pour les tâches liées à VASA.</block>
  <block id="4567f5576b4577c63b126cac3f6aa5fa" category="paragraph">L'un des avantages de cette architecture est que SRA n'est plus nécessaire, car tout est géré à l'aide de VASA.</block>
  <block id="e04031e1cecdb6732f91d44b204dbcf3" category="paragraph">SPBM est un outil puissant dans la boîte à outils vSphere. Il permet de proposer des services de stockage cohérents, prévisibles et cohérents en fonction de la consommation dans les frameworks d'automatisation dans les environnements de cloud privé et hybride. Fondamentalement, grâce à la gestion des règles, vous pouvez définir des classes de service qui répondent aux besoins de votre base client diversifiée. SRM vous permet maintenant d'exposer des fonctionnalités de réplication à vos clients pour des charges de travail stratégiques qui nécessitent une orchestration et une automatisation fiables et standard de la reprise après incident.</block>
  <block id="1b6204fa76bd422416757c4e2d6187bd" category="paragraph">Exemple d'architecture vVols avec FCP ou iSCSI :</block>
  <block id="6f1ad7cac2af0e3b92a3936efc393a0e" category="paragraph"><block ref="6f1ad7cac2af0e3b92a3936efc393a0e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9abbd7aed7e9791d9c52e8e17f34a756" category="section-title">Prise en charge des serveurs SRM basés sur les dispositifs</block>
  <block id="925c477f139cce0692e13946a7f75eac" category="paragraph">Les serveurs SRM basés sur le système d'exploitation de photons sont désormais pris en charge, en plus des plates-formes Windows existantes.</block>
  <block id="62c2c4203aebe081ddbc6cdd489f8ad7" category="paragraph">Vous pouvez maintenant installer des cartes SRA quel que soit votre type de serveur SRM préféré.</block>
  <block id="7cb1700928c008eb817bc79250cc9002" category="section-title">Prise en charge d'IPv6</block>
  <block id="ea9aacd1495949730de8eeab11e66459" category="paragraph">IPv6 est désormais pris en charge avec les limites suivantes :</block>
  <block id="d6d7f3d43de975c07655ebba1936867a" category="list-text">VCenter 6.7 ou version ultérieure</block>
  <block id="eb26ee1a20fe3dbde98204ec8b3ab838" category="list-text">Non pris en charge avec SRM 8.2 (8.1, 8.3 et 8). 4 sont pris en charge)</block>
  <block id="918d32b75f0ab883abba3a8dc0c3ae8d" category="inline-link">Matrice d'interopérabilité</block>
  <block id="02e7e71042609d3158020ab7befe45c6" category="list-text">Vérifier le<block ref="218f4ad7153f69cdc5467065434cd2f0" category="inline-link-rx"></block> pour les dernières versions qualifiées.</block>
  <block id="e887aed8f9c3dbecd37e8896d96b6637" category="section-title">Meilleures performances</block>
  <block id="2a71574e89a69c8218fbac3f604b5728" category="paragraph">La performance opérationnelle est une exigence clé pour l'exécution des tâches SRM. Afin de respecter les exigences de RTO et RPO modernes, la SRA, associée aux outils ONTAP, a été améliorée.</block>
  <block id="bd403c539a0c414afacd7477bf3d311f" category="list-text">*Prise en charge des opérations de reprotection simultanées.* première introduction dans SRA 9.7.1, cette fonctionnalité vous permet d'exécuter la reprotection sur deux plans de reprise ou plus simultanément, ce qui réduit le temps nécessaire pour reprotéger les datastores après un basculement ou une migration et reste dans vos paramètres RTO et RPO.</block>
  <block id="f63b947f655a5aee2cf69d4f30d7f96b" category="list-text">*ONTAP Tools 9.8 ajoute un nouveau mode optimisé pour le NAS uniquement.* lorsque vous utilisez des comptes SVM et des connexions aux clusters ONTAP avec uniquement des datastores basés sur NFS, vous pouvez activer le mode optimisé pour NAS uniquement pour des performances optimales dans les environnements pris en charge.</block>
  <block id="c82379d922d9cdc55fa21affe9f9b8bf" category="list-text">*ONTAP Tools 9.12 a ajouté la prise en charge de la fonctionnalité de resynchronisation rapide SnapMirror d'ONTAP.* cette fonctionnalité permet la resynchronisation rapide des miroirs en vue de recalculer les économies réalisées après le processus. Cette fonctionnalité n'est pas utilisée par défaut, mais elle peut être activée dans les environnements à grande échelle où la resynchronisation classique prend trop de temps ou s'arrête.</block>
  <block id="4a4842d7448ef71eb69b013e560b18bb" category="section-title">Évolutivité accrue</block>
  <block id="26738e8d40ae8035805f13bdbf185c30" category="paragraph">L'outil ONTAP SRA peut désormais prendre en charge jusqu'à 500 groupes de protection (PPG) lorsqu'il est utilisé avec SRM 8.3 et versions ultérieures.</block>
  <block id="96cb4d41ca97bd9d3d446984d3170a57" category="paragraph">Une nouvelle fonctionnalité très attendue et très attendue est la version SnapMirror synchrone (SM-S) avec ONTAP 9.5 et versions ultérieures, qui offre une solution de réplication des données avec un RPO nul et granulaire pour vos applications stratégiques. SM-S requiert ONTAP Tools 9.8 ou version ultérieure.</block>
  <block id="b9832b10a87d0c3793ed3b413ee1d839" category="section-title">Prise en charge des API REST</block>
  <block id="0065ce57adc813187a8e9c640ba6223a" category="paragraph">La configuration du serveur SRA peut désormais être gérée par les API REST. Une interface utilisateur swagger a été ajoutée pour vous aider à créer vos flux de travail d'automatisation. Elle est disponible sur votre appliance ONTAP Tools à l'adresse<block ref="579ce3ee0a7c1521f3dce6a507ea64a0" prefix=" " category="inline-code"></block>.</block>
  <block id="5bdb12cbb14efa98a61e7c5e3b4de108" category="admonition">Cette documentation remplace le rapport technique _TR-4900 : VMware site Recovery Manager with ONTAP_</block>
  <block id="e3445c3aa798f5ad98665e33d34dd952" category="paragraph">Les meilleures pratiques complètent d'autres documents, tels que des guides et des outils de compatibilité. Ils sont développés en fonction de tests effectués en laboratoire et d'une vaste expérience sur le terrain par les ingénieurs et les clients NetApp. Dans certains cas, les meilleures pratiques recommandées peuvent ne pas être adaptées à votre environnement. Cependant, ce sont généralement les solutions les plus simples qui répondent aux besoins des plus clients.</block>
  <block id="10b8f80c23f8a44dfa6b10ae56d7dbe9" category="paragraph">Ce document est axé sur les fonctionnalités des dernières versions de ONTAP 9 utilisées conjointement avec les outils ONTAP pour VMware vSphere 9.12 (notamment NetApp Storage Replication adapter [SRA] et VASA Provider [VP]), ainsi que VMware site Recovery Manager 8.7.</block>
  <block id="c40f8c2af56356193284f6b46865d954" category="section-title">Pourquoi utiliser ONTAP avec SRM ?</block>
  <block id="2242b80f4627736a48c4c9a36b7428f6" category="paragraph">Lorsque vous utilisez SnapMirror pour la réplication basée sur les baies, vous tirez parti de l'une des technologies ONTAP les plus éprouvées et les plus matures. SnapMirror vous permet de transférer les données de manière sécurisée et efficace en copiant uniquement les blocs du système de fichiers modifiés, et non les machines virtuelles entières ou les datastores. Même ces blocs tirent parti des économies d'espace, telles que la déduplication, la compression et la compaction. Les systèmes ONTAP modernes utilisent désormais SnapMirror, indépendant de la version, pour vous permettre de sélectionner plus de flexibilité vos clusters source et cible. SnapMirror est véritablement devenu l'un des outils les plus puissants disponibles pour la reprise après incident.</block>
  <block id="36b04390d6103d8075862e4b825a485e" category="paragraph">Que vous utilisiez des datastores NFS, iSCSI ou Fibre Channel classiques (désormais avec prise en charge des datastores vvols), SRM constitue une offre commerciale performante qui tire parti des fonctionnalités ONTAP pour la reprise après incident ou la planification et l'orchestration de la migration de data Center.</block>
  <block id="5d111e8a6885460b43ecf1f7abb6377e" category="section-title">Comment SRM exploite ONTAP 9</block>
  <block id="16d4ec242c9f020f3a1fade311c776ed" category="paragraph">SRM exploite les technologies avancées de gestion des données des systèmes ONTAP en l'intégrant aux outils ONTAP pour VMware vSphere, une appliance virtuelle qui englobe trois composants principaux :</block>
  <block id="a106bb15d6dc2b11535ed4fefc81fbf4" category="list-text">Le fournisseur VASA pour ONTAP prend en charge la structure VMware vStorage APIs for Storage Awareness (VASA). Vasa Provider connecte vCenter Server avec ONTAP pour faciliter le provisionnement et la surveillance du stockage des machines virtuelles. Il assure la prise en charge de VMware Virtual volumes (vvols) et la gestion des profils de capacité de stockage (y compris les fonctionnalités de réplication vvols) ainsi que les performances individuelles de VM vvols. Il fournit également des alarmes pour la surveillance de la capacité et la conformité avec les profils. Utilisé conjointement avec SRM, le fournisseur VASA pour ONTAP permet la prise en charge des machines virtuelles basées sur vvols sans avoir à installer un adaptateur SRA sur le serveur SRM.</block>
  <block id="f2007951062862f5f0d593acbb23bcb4" category="list-text">SRA est utilisée en association avec SRM pour gérer la réplication des données des machines virtuelles entre les sites de production et de reprise après incident pour les datastores VMFS et NFS traditionnels, et pour les tests non disruptives des répliques de DR. Il permet d'automatiser les tâches de détection, de restauration et de reprotection. Elle inclut une appliance serveur SRA et des adaptateurs SRA pour le serveur Windows SRM et l'appliance SRM.</block>
  <block id="8ccaa60ee78ecc93c4870b3b2ad15284" category="paragraph">Après avoir installé et configuré les adaptateurs SRA sur le serveur SRM pour la protection des datastores non-vvols et/ou la réplication vvols activée dans les paramètres de VASA Provider, vous pouvez commencer la tâche de configuration de votre environnement vSphere pour la reprise après incident.</block>
  <block id="0a1e25166326359cd5f50d0ab83e6a37" category="paragraph">Les fournisseurs SRA et VASA proposent une interface de commande et de contrôle pour le serveur SRM afin de gérer les volumes FlexVol ONTAP contenant vos machines virtuelles VMware, ainsi que la réplication SnapMirror les protégeant.</block>
  <block id="38db855935949f86c5db7bfe7d49873e" category="paragraph">À partir de SRM 8.3, un nouveau chemin de contrôle SRM vvols Provider a été introduit dans le serveur SRM, ce qui lui a permis de communiquer avec le serveur vCenter et, par le biais de celui-ci, au VASA Provider sans avoir besoin d'une SRA. Ainsi, le serveur SRM a pu mieux contrôler le cluster ONTAP qu'auparavant. En effet, VASA fournit une API complète pour une intégration étroitement couplée.</block>
  <block id="1c27364cc3705aff403c6ef131c347ff" category="paragraph">SRM peut tester votre plan de reprise après incident sans interruption grâce à la technologie FlexClone propriétaire de NetApp pour créer des clones quasi instantanés de vos datastores protégés sur votre site de reprise après incident. SRM crée un sandbox afin de tester en toute sécurité afin que votre entreprise et vos clients soient protégés en cas d'incident, vous assurant ainsi la confiance de votre entreprise dans la capacité à exécuter un basculement lors d'un incident.</block>
  <block id="04a8f82007ed4bec45053912a49b6f85" category="paragraph">En cas d'incident véritable ou même de migration planifiée, SRM vous permet d'envoyer les modifications de dernière minute au jeu de données via une mise à jour SnapMirror finale (si vous le souhaitez). Il interrompt ensuite le miroir et monte le datastore sur vos hôtes de reprise après incident. À ce stade, vos machines virtuelles peuvent être automatiquement alimentées dans l'ordre de votre stratégie prédéfinie.</block>
  <block id="b2560426a08ae6ceb167dad2bfb5e8ae" category="section-title">SRM avec ONTAP et autres cas d'utilisation : cloud hybride et migration</block>
  <block id="ed4c730bd8636c27d3eaa876c63b3d45" category="inline-link">NetApp Private Storage dans Equinix</block>
  <block id="b422e05bc5c6f52208b66ff51d718b9d" category="paragraph">En intégrant votre déploiement de SRM aux fonctionnalités avancées de gestion des données de ONTAP, vous pouvez améliorer l'évolutivité et les performances par rapport aux options de stockage local. Elle apporte cependant la flexibilité du cloud hybride. Grâce au cloud hybride, vous pouvez réaliser des économies en transférant les blocs de données non utilisés de votre baie haute performance vers votre hyperscaler préférée, via FabricPool, qui peut être un magasin S3 sur site tel que NetApp StorageGRID. Vous pouvez également utiliser SnapMirror pour les systèmes basés en périphérie avec ONTAP Select l'infrastructure de reprise après incident Software-defined ou basée dans le cloud à l'aide de Cloud Volumes ONTAP (CVO) ou<block ref="37a666d3a37f1c4a8c4c8dba379664a4" category="inline-link-rx"></block> Pour créer une pile de services de stockage, de réseau et de calcul entièrement intégrée dans le cloud, Amazon Web Services (AWS), Microsoft Azure et Google Cloud Platform (GCP)</block>
  <block id="87a7b114355b836acefe833c497611bb" category="paragraph">Vous pouvez ensuite effectuer un basculement de test dans le data Center d'un fournisseur de services clouds avec une empreinte de stockage proche de zéro grâce à FlexClone. La protection de votre entreprise peut à présent être plus économique que jamais.</block>
  <block id="12d0cbcf61df7df30bf9b020f6fbb051" category="paragraph">SRM peut également être utilisé pour exécuter des migrations planifiées en utilisant SnapMirror pour transférer efficacement vos machines virtuelles d'un data Center à un autre ou même au sein d'un même data Center, que vous le soyez propriétaire ou via plusieurs fournisseurs de services partenaires NetApp.</block>
  <block id="89fafdb11a7e8cd8abebb1d4df053dad" category="doc">Topologies de réplication</block>
  <block id="be01acd2f018d38f9446f06b99ee4a2a" category="paragraph">Dans ONTAP 9, les composants physiques d'un cluster sont visibles pour les administrateurs du cluster, mais ils ne sont pas directement visibles pour les applications et les hôtes qui utilisent le cluster. Les composants physiques offrent un pool de ressources partagées à partir duquel les ressources logiques du cluster sont créées. Les applications et les hôtes accèdent aux données uniquement au moyen de SVM qui contiennent des volumes et des LIF.</block>
  <block id="7758fc02779ee5917b0a09ee22b52221" category="paragraph">Chaque SVM NetApp est traité comme une baie dans VMware vCenter site Recovery Manager. SRM prend en charge certaines dispositions de réplication baie à baie (ou SVM à SVM).</block>
  <block id="58c0b55a67f4331cc49b073a7183e06c" category="paragraph">Une seule machine virtuelle ne peut pas héberger de données (Virtual machine Disk (VMDK) ou RDM) sur plusieurs baies SRM pour les raisons suivantes :</block>
  <block id="880aeda0b58c0b30120b6319ae5f3beb" category="list-text">SRM ne voit que la SVM, pas un contrôleur physique individuel.</block>
  <block id="6f55124e085dbeb640e4cb8ad2c97905" category="list-text">Un SVM peut contrôler les LUN et les volumes répartis sur plusieurs nœuds dans un cluster.</block>
  <block id="39d9903201320a83d45d3b36d512f051" category="cell">Meilleure pratique</block>
  <block id="d86019fe4ba86b184ac71cf24a22f0c6" category="cell">Pour déterminer la prise en charge, conservez cette règle à l'esprit : pour protéger une machine virtuelle via SRM et NetApp SRA, tous les composants de la machine virtuelle doivent exister sur un seul SVM. Cette règle s'applique aussi bien au site protégé que au site de reprise.</block>
  <block id="2e4472d35f80aa8b7eca52ae3dd43dc6" category="section-title">Dispositions SnapMirror prises en charge</block>
  <block id="d070ad9d8397892aa7f317cbb9046661" category="paragraph">Les figures suivantes présentent les scénarios de disposition des relations SnapMirror pris en charge par SRM et SRA. Chaque machine virtuelle des volumes répliqués est propriétaire de données sur une seule baie SRM (SVM) sur chaque site.</block>
  <block id="86cf5bd2bdb1b1d67f8f907f41099509" category="section-title">Mises en page de Array Manager prises en charge</block>
  <block id="aacc8f18d659f75715d91a983e872233" category="paragraph">Lorsque vous utilisez la réplication basée sur la baie (ABR) dans SRM, les groupes de protection sont isolés vers une seule paire de baies, comme l'illustre la capture d'écran suivante. Dans ce scénario,<block ref="129864522ed0e4ac80f306ecfa130ef7" prefix=" " category="inline-code"></block> et<block ref="ec87aa7f4c8e70a139fd988f87b6549f" prefix=" " category="inline-code"></block> sont associés à<block ref="387d04b65848414d4697f145a3782f90" prefix=" " category="inline-code"></block> et<block ref="58bdbfcb72c2dd3d883a7ca754443a4c" prefix=" " category="inline-code"></block> sur le site de reprise. Cependant, vous ne pouvez sélectionner qu'une des deux paires de matrices lorsque vous créez un groupe de protection.</block>
  <block id="1ceb46f3e1c6c7995de4ec5f05601227" category="section-title">Présentations non prises en charge</block>
  <block id="611b9b35ac984f20e6594baec9181dbf" category="paragraph">Les configurations non prises en charge possèdent des données (VMDK ou RDM) sur plusieurs SVM appartenant à une machine virtuelle individuelle. Dans les exemples présentés dans les figures suivantes,<block ref="df777c4d2477e55571925353ce589f7e" prefix=" " category="inline-code"></block> Ne peut pas être configuré pour la protection avec SRM car<block ref="df777c4d2477e55571925353ce589f7e" prefix=" " category="inline-code"></block> Possède des données sur deux SVM.</block>
  <block id="69851ac8c2fa81b32799efc8522798d5" category="paragraph">Toute relation de réplication dans laquelle un volume NetApp individuel est répliqué depuis un SVM source vers plusieurs destinations dans un même SVM ou dans différents SVM, est appelée « Fan-Out » de SnapMirror. La réplication « Fan-Out » n'est pas prise en charge par SRM. Dans l'exemple illustré dans la figure suivante,<block ref="df777c4d2477e55571925353ce589f7e" prefix=" " category="inline-code"></block> Ne peut pas être configuré pour la protection dans SRM car elle est répliquée avec SnapMirror dans deux emplacements différents.</block>
  <block id="3f88384b0d5cdcdc25895c644126c1b0" category="section-title">SnapMirror en cascade</block>
  <block id="7ebde774ad43c45667d5544308a6d688" category="paragraph">SRM ne prend pas en charge le cascade des relations SnapMirror, dans lesquelles un volume source est répliqué sur un volume de destination, et ce volume de destination est également répliqué avec SnapMirror vers un autre volume de destination. Dans le scénario illustré dans la figure suivante, SRM ne peut pas être utilisé pour le basculement entre des sites.</block>
  <block id="8bd15e818d377a0a5cf6ebc429555f79" category="section-title">SnapMirror et SnapVault</block>
  <block id="d440734d1f5d9c6e59aa97f7cbbcd525" category="paragraph">Le logiciel NetApp SnapVault permet de sauvegarder les données d'entreprise sur disque entre les systèmes de stockage NetApp. SnapVault et SnapMirror peuvent coexister dans un même environnement, mais SRM prend en charge le basculement de uniquement les relations SnapMirror.</block>
  <block id="7878dfbf4b6ad3bc60d095cf89d79202" category="admonition">L'adaptateur NetApp SRA prend en charge le<block ref="e7d3e049f94ce3ff8a47f209f012173d" prefix=" " category="inline-code"></block> type de règle.</block>
  <block id="883e69a285ae2d5fd23c80cd29285804" category="paragraph">SnapVault a été entièrement reconstruit pour ONTAP 8.2. Bien que les anciens utilisateurs de Data ONTAP 7-mode trouvent des similarités, des améliorations majeures ont été apportées dans cette version d'SnapVault. Une avancée majeure est la capacité à préserver l'efficacité du stockage sur les données primaires au cours des transferts SnapVault.</block>
  <block id="9bc21373e0e299579a7ac86dcd4f513d" category="paragraph">L'architecture SnapVault de ONTAP 9 réplique au niveau du volume et non au niveau du qtree, comme c'est le cas avec 7-mode SnapVault. Dans ce cas, la source d'une relation SnapVault doit être un volume, et ce volume doit être répliqué sur son propre volume sur le système secondaire SnapVault.</block>
  <block id="d447048519c85a2fb3bea0790cd109fb" category="paragraph">Dans un environnement dans lequel SnapVault est utilisé, des snapshots nommés spécifiques sont créés sur le système de stockage principal. Selon la configuration implémentée, les snapshots nommés peuvent être créés sur le système principal par une planification SnapVault ou par une application telle que NetApp Active IQ Unified Manager. Les snapshots nommés créés sur le système primaire sont ensuite répliqués sur la destination SnapMirror, puis stockés sur la destination SnapVault.</block>
  <block id="5dd37b7cd36f7d38ba2e6a63c603be4c" category="paragraph">Un volume source peut être créé dans une configuration en cascade, dans laquelle un volume est répliqué vers une destination SnapMirror dans le site de reprise après incident, et depuis ce volume est copié vers une destination SnapVault. Un volume source peut également être créé au sein d'une relation « fan-out » où une destination est une destination SnapMirror et l'autre destination est une destination SnapVault. Toutefois, SRA ne reconfigurez pas automatiquement la relation SnapVault pour utiliser le volume de destination SnapMirror comme source du coffre-fort en cas de basculement ou d'inversion de réplication SRM.</block>
  <block id="5bc66b9c84b3f7cc0b375e729376b68d" category="inline-link">Tr-4015 Guide des meilleures pratiques en matière de configuration de SnapMirror pour ONTAP 9.</block>
  <block id="0d510e96259254d285c6aaeb8458f45d" category="paragraph">Pour connaître les dernières informations concernant SnapMirror et SnapVault pour ONTAP 9, consultez<block ref="32e7c991f675bf983c547a2a174c2caf" category="inline-link-rx"></block></block>
  <block id="75f8a2d99eea9f336120aec69d8c1010" category="cell">Si SnapVault et SRM sont utilisés dans le même environnement, NetApp recommande d'utiliser une configuration SnapMirror vers SnapVault en cascade dans laquelle les sauvegardes SnapVault sont normalement exécutées à partir de la destination SnapMirror sur le site de reprise après incident. En cas d'incident, cette configuration rend le site principal inaccessible. Le fait de conserver la destination SnapVault sur le site de reprise permet de reconfigurer les sauvegardes SnapVault après le basculement, de sorte que les sauvegardes SnapVault puissent continuer sur le site de reprise.</block>
  <block id="e082a67e3ddd7f4f92096536440cbb34" category="paragraph">Dans un environnement VMware, chaque datastore dispose d'un identifiant unique universel (UUID) et chaque machine virtuelle possède un ID d'objet géré unique (MOID). Ces identifiants ne sont pas gérés par SRM lors du basculement ou de la restauration. Étant donné que les UID et les MOID de machine virtuelle ne sont pas maintenus lors du basculement par SRM, toutes les applications qui dépendent de ces ID doivent être reconfigurées après le basculement SRM. NetApp Active IQ Unified Manager, qui coordonne la réplication SnapVault avec l'environnement vSphere, est un exemple d'application.</block>
  <block id="657a41cce55646ab17754ac1427970af" category="paragraph">La figure suivante décrit une configuration SnapMirror vers SnapVault en cascade. Si la destination SnapVault se trouve sur le site de reprise après incident ou sur un site tertiaire non affecté par une panne sur le site primaire, l'environnement peut être reconfiguré afin de permettre la continuité des sauvegardes après le basculement.</block>
  <block id="e068178460f103498576eac8ddb7fb82" category="paragraph">La figure suivante décrit la configuration après l'utilisation de SRM pour renvoyer la réplication SnapMirror vers le site primaire. L'environnement a également été reconfiguré de façon à ce que les sauvegardes SnapVault s'effectuent à partir d'une source SnapMirror. Cette configuration est « Fan-Out » de SnapMirror SnapVault.</block>
  <block id="b4607a4ee7e1830ab6ba0007df206956" category="paragraph">Une fois que SRM a effectué une restauration et une seconde inversion des relations SnapMirror, les données de production sont de nouveau sur le site principal. Ces données sont désormais protégées de la même manière qu'avant le basculement vers le site de reprise après incident, via les sauvegardes SnapMirror et SnapVault.</block>
  <block id="63fd1f18d5d53fa97fd05a7fd96090b4" category="section-title">Utilisation de qtrees dans les environnements site Recovery Manager</block>
  <block id="2d88570ceb2de0d8699a068b0140454b" category="paragraph">Les qtrees sont des répertoires spéciaux qui permettent l'application de quotas de système de fichiers pour NAS. ONTAP 9 permet la création de qtrees et peut exister dans les volumes répliqués avec SnapMirror. Toutefois, SnapMirror ne permet pas la réplication de qtrees individuels ni de réplication au niveau qtree. Toute la réplication SnapMirror se fait au niveau du volume uniquement. C'est pour cette raison que NetApp ne recommande pas l'utilisation de qtrees avec SRM.</block>
  <block id="345cb3f040f9f7f3f1a4261ed260aa79" category="section-title">Environnements FC et iSCSI mixtes</block>
  <block id="a60b166c2b69b4fdfbb733dc2193668a" category="paragraph">Grâce à la prise en charge des protocoles SAN (FC, FCoE et iSCSI), ONTAP 9 propose des services LUN, à savoir la création de LUN et leur mappage vers les hôtes associés. Dans la mesure où le cluster compte plusieurs contrôleurs, il existe plusieurs chemins logiques gérés par les E/S multivoies vers une LUN individuelle. L'accès ALUA (Asymmetric Logical Unit Access) est utilisé sur les hôtes pour que le chemin optimisé vers un LUN soit sélectionné et activé pour le transfert de données. Si ce chemin change (par exemple, en raison du déplacement du volume qui y est associé), ONTAP 9 reconnaît automatiquement cette modification et s'ajuste de façon non disruptive. S'il devient indisponible, ONTAP peut également basculer sans interruption sur un autre chemin.</block>
  <block id="b9921ac732e72656bc2836f83bb09522" category="paragraph">VMware SRM et NetApp SRA prennent en charge l'utilisation du protocole FC sur un site et le protocole iSCSI sur l'autre site. Il ne prend pas en charge la combinaison de datastores FC et de datastores iSCSI dans le même hôte ESXi ou d'hôtes différents dans le même cluster. Cette configuration n'est pas prise en charge avec SRM car, pendant le basculement SRM ou le basculement de test, SRM inclut tous les initiateurs FC et iSCSI des hôtes ESXi dans la demande.</block>
  <block id="fccd44a96243e459128798803dca70aa" category="cell">SRM et SRA prennent en charge les protocoles FC et iSCSI mixtes entre les sites protégés et de reprise. Cependant, chaque site ne doit pas être configuré avec un seul protocole, FC ou iSCSI, et non avec les deux protocoles sur le même site. Si il est nécessaire de configurer les protocoles FC et iSCSI sur le même site, NetApp recommande que certains hôtes utilisent iSCSI et d'autres hôtes utilisent FC. Dans ce cas, NetApp recommande également de configurer les mappages de ressources SRM de sorte que les VM soient configurés pour basculer vers un groupe d'hôtes ou un autre.</block>
  <block id="56687c1a324f03f5d1429500efea710e" category="doc">Dépannage de SRM lors de l'utilisation de la réplication de vvols</block>
  <block id="14acf40cbe69d8682b4c844ac7fbf7f6" category="paragraph">Le flux de travail de SRM est significativement différent lors de l'utilisation de la réplication vvols à partir de ce qui est utilisé avec SRA et les datastores traditionnels. Par exemple, il n'existe pas de concept de gestionnaire de baie. Comme c'est le cas,<block ref="0ec64480a9620a1430c0ae1b6603ea01" prefix=" " category="inline-code"></block> et<block ref="ba6c59072f543cb828e47d5bac560371" prefix=" " category="inline-code"></block> les commandes ne sont jamais vues.</block>
  <block id="ef74d715544e3b067a6bec3218ac5044" category="paragraph">Lors du dépannage, il est utile de comprendre les nouveaux flux de travail répertoriés ci-dessous :</block>
  <block id="47f0942d341ee10381b2eff35089d75d" category="list-text">QueryReplicationPeer : détecte les accords de réplication entre deux domaines de défaillance.</block>
  <block id="136a299aae29998a147852cb0cba5b4a" category="list-text">QueryFaultDomain : détecte la hiérarchie du domaine de pannes.</block>
  <block id="c071098c5df923c31f6245e4db2f3861" category="list-text">QueryReplicationGroup : détecte les groupes de réplication présents dans les domaines source ou cible.</block>
  <block id="792cfe9ad3a3dc8528080a262e92989a" category="list-text">SyncReplicationGroup : synchronise les données entre la source et la cible.</block>
  <block id="39afb1e1e3b180a6230e07bb8571667e" category="list-text">QueryPointInTimeReplica : détecte le point dans le temps des répliques sur une cible.</block>
  <block id="9fb25fe2ff084dc9ccfb99eaccba7212" category="list-text">TestFailoverReplicationGroupStart : démarre le basculement de test.</block>
  <block id="bd4e1dacaca4c37a53b5286b6ae0239d" category="list-text">TestFailoverReplicationGroupStop : met fin au basculement de test.</block>
  <block id="887f376a43cf9de1d6e14a8d69e588f6" category="list-text">PromoteReplicationGroup : promeut un groupe actuellement en cours de test à la production.</block>
  <block id="17ab16c5c0786ff381e6a085318bad9b" category="list-text">PreparFailoverReplicationTM : prépare une reprise après sinistre.</block>
  <block id="665dd64ebcc4016bda94e0e8020d8c8e" category="list-text">FailoverReplicationGroup : exécute la reprise après incident.</block>
  <block id="6936cf00e30b7cd4421225113a023c3e" category="list-text">ReverseReplicateGroup : lance la réplication inverse.</block>
  <block id="61ac8950a043e6998b458d4f8171154c" category="list-text">QueryMatchingContainer : recherche les conteneurs (ainsi que les hôtes ou les groupes de réplication) susceptibles de satisfaire une demande de provisionnement avec une règle donnée.</block>
  <block id="05c9efdc056d2af4640bc441ab61b53a" category="list-text">QueryResourceMetadata : recherche les métadonnées de toutes les ressources du fournisseur VASA, l'utilisation des ressources peut être renvoyée comme réponse à la fonction queryMatchingContainer.</block>
  <block id="01fa56986f885c588b1be8c206623de8" category="paragraph">L'erreur la plus courante lors de la configuration de la réplication vvols est une incapacité à découvrir les relations SnapMirror. En effet, les volumes et les relations SnapMirror sont créés en dehors de la purView des outils ONTAP. Il est donc recommandé de toujours s'assurer que votre relation SnapMirror est totalement initialisée et que vous avez exécuté une redécouverte dans les outils ONTAP sur les deux sites avant de tenter de créer un datastore vvols répliqué.</block>
  <block id="3e4627f6667f830baceaaf35890b575a" category="summary">Pour en savoir plus sur les informations données dans ce livre blanc, consultez ces documents et/ou sites web.</block>
  <block id="092bf78f9c97ba171b8232ddff585392" category="doc">Informations supplémentaires</block>
  <block id="7d5b957cd473f6eaf5ad335a9c63c4ff" category="paragraph">Pour en savoir plus sur les informations données dans ce livre blanc, consultez ces documents et/ou sites web :</block>
  <block id="cbe2f6eb2a73f4a2c871a06264f10dc7" category="inline-link"><block ref="cbe2f6eb2a73f4a2c871a06264f10dc7" category="inline-link-rx"></block></block>
  <block id="c88037eb28ae3cceb0e32c2cd3c322d7" category="inline-link"><block ref="c88037eb28ae3cceb0e32c2cd3c322d7" category="inline-link-rx"></block></block>
  <block id="9aa6e8f8fac5c131e5924ee033660d29" category="inline-link"><block ref="9aa6e8f8fac5c131e5924ee033660d29" category="inline-link-rx"></block></block>
  <block id="c9dd6bad4c7d561872f2e2d498a990bf" category="inline-link">Matrice d'interopérabilité (IMT)</block>
  <block id="1f82b18dcba5f32a085bc502cdd0c6b7" category="summary">Avec ONTAP, le concept de machine virtuelle de stockage (SVM) offre une segmentation stricte dans les environnements mutualisés sécurisés.</block>
  <block id="7520e12a140ccf3de279fe2fd48889e4" category="doc">Bonnes pratiques de déploiement</block>
  <block id="1b4574c516231b685bb37b013b789b06" category="section-title">Disposition des SVM et segmentation pour la colocation sécurisée</block>
  <block id="446e04546ec0567eeeeef8e07368ab40" category="paragraph">Avec ONTAP, le concept de machine virtuelle de stockage (SVM) offre une segmentation stricte dans les environnements mutualisés sécurisés. Les utilisateurs des SVM situés sur un SVM ne peuvent ni accéder aux ressources d'un autre ni les gérer. De cette façon, vous pouvez exploiter la technologie ONTAP en créant des SVM distincts pour différentes unités commerciales qui gèrent leurs propres flux de travail SRM sur le même cluster, pour une efficacité globale supérieure du stockage.</block>
  <block id="f98c1d223f34b2fdaf90eab1a3bc6a25" category="paragraph">Envisagez de gérer ONTAP avec des comptes SVM-scoped et des LIF de management SVM pour non seulement améliorer les contrôles de sécurité, mais aussi améliorer les performances. Les performances sont supérieures par nature lorsque des connexions SVM-scoped sont utilisées, car SRA n'est pas nécessaire pour traiter toutes les ressources d'un cluster entier, y compris les ressources physiques. Il ne doit plutôt comprendre que les ressources logiques qui sont extraites vers la SVM particulière.</block>
  <block id="849d4d5e8a5d5b2747d8375d2ec03b29" category="paragraph">Si vous utilisez uniquement des protocoles NAS (pas d'accès SAN), vous pouvez même exploiter le nouveau mode optimisé NAS en définissant le paramètre suivant (notez que le nom est tel, car SRA et VASA utilisent les mêmes services back-end de l'appliance) :</block>
  <block id="05f551a655f40911851a53ba0c721997" category="list-text">Connectez-vous au panneau de commande à<block ref="501a3478972ee5e3d6f109bdc0514bdc" prefix=" " category="inline-code"></block> Et cliquez sur interface de ligne de commande Web.</block>
  <block id="b0cc185c73ca964d1429a601551c68f5" category="list-text">Lancer la commande<block ref="4f35e9b3adeccfaf0287d002b134221c" prefix=" " category="inline-code"></block>.</block>
  <block id="5f7e35f90689bef91afe9f01257c61ac" category="list-text">Lancer la commande<block ref="aa610e3ab4e5162f432950793f30a387" prefix=" " category="inline-code"></block>.</block>
  <block id="ba2a1e4d95dc56709260e82cca20a789" category="list-text">Lancer la commande<block ref="6d83e9fce5e947159c3c34b9f499e80e" prefix=" " category="inline-code"></block>.</block>
  <block id="2d14ca751c8ce5a724606e4f75f02c50" category="section-title">Déployez des outils ONTAP et des considérations pour vvols</block>
  <block id="fa3a193f1892cf0f45f4a95a35aa3c4b" category="paragraph">Si vous prévoyez d'utiliser SRM avec vvols, vous devez gérer le stockage à l'aide d'identifiants cluster-scoped et d'une LIF de cluster management. En effet, le fournisseur VASA doit comprendre l'architecture physique sous-jacente pour satisfaire aux exigences des règles de stockage des VM. Par exemple, si vous disposez d'une règle exigeant un stockage 100 % Flash, le fournisseur VASA doit pouvoir identifier les systèmes 100 % Flash.</block>
  <block id="31d279d1cc3bc5a4281567ba697f678d" category="paragraph">Une autre meilleure pratique de déploiement est de ne jamais stocker votre appliance ONTAP Tools sur un datastore vvols qu'il gère. Cela peut entraîner une situation dans laquelle vous ne pouvez pas mettre le fournisseur VASA sous tension, car vous ne pouvez pas créer le vVol swap pour l'appliance, car l'appliance est hors ligne.</block>
  <block id="97399fb37deca0d463aa5c7dc8d064a6" category="section-title">Meilleures pratiques pour la gestion des systèmes ONTAP 9</block>
  <block id="18f8b81b7fb7ea92f333e127583df17c" category="paragraph">Comme mentionné précédemment, il est possible de gérer des clusters ONTAP avec des identifiants cluster ou SVM évalués et des LIF de gestion. Pour des performances optimales, il peut être intéressant d'utiliser des identifiants SVM- scoped lorsque vous n'utilisez pas les vVols. Cependant, ce faisant, vous devriez être conscient de certaines exigences, et que vous perdez certaines fonctionnalités.</block>
  <block id="fec05e53ca7d96aaf3e4c1a1b2502bea" category="list-text">Le compte SVM vsadmin par défaut ne dispose pas du niveau d'accès requis pour effectuer les tâches des outils ONTAP Il faut donc créer un nouveau compte SVM.</block>
  <block id="d508cbe8ee8a3aa0f975b96403baf33c" category="list-text">Si vous utilisez ONTAP 9.8 ou une version ultérieure, NetApp recommande de créer un compte utilisateur RBAC avec le moins de privilèges à l'aide du menu utilisateurs de ONTAP System Manager ainsi que le fichier JSON disponible sur votre appliance ONTAP Tools à l'adresse<block ref="137f8d4bb89dcc34c3bfe48f2a61c95e" prefix=" " category="inline-code"></block>. Utilisez votre mot de passe d'administrateur pour télécharger le fichier JSON. Il peut être utilisé pour les comptes évalués au niveau du SVM ou du cluster.</block>
  <block id="a7a83b5e4f375c0585588b9c7ff92219" category="inline-link">Outils du site de support NetApp</block>
  <block id="fdfe9ba9104df6a32fff0f859291ea3c" category="paragraph">Si vous utilisez ONTAP 9.6 ou une version antérieure, vous devez utiliser l'outil Créateur d'utilisateurs RBAC (RUC) disponible dans le<block ref="bdbf96c18cf8ac76d01fba7057b81b87" category="inline-link-rx"></block>.</block>
  <block id="ea7a3d08d55dc3e8ecf89d2a5d5e302d" category="list-text">Le plug-in de l'interface utilisateur vCenter, VASA Provider et SRA Server étant tous des services entièrement intégrés, vous devez ajouter du stockage à l'adaptateur SRA dans SRM de la même manière que vous ajoutez du stockage dans l'interface utilisateur vCenter pour les outils ONTAP. Sinon, le serveur SRA pourrait ne pas reconnaître les requêtes envoyées depuis SRM via l'adaptateur SRA.</block>
  <block id="b473de4177eeaa79a66448798a446db3" category="list-text">La vérification du chemin NFS n'est pas effectuée avec les identifiants évalués par SVM. Car l'emplacement physique est logiquement extrait du SVM. Cela ne pose pas de problème, car les systèmes ONTAP modernes ne subissent plus de déclin perceptible des performances lors de l'utilisation de chemins indirects.</block>
  <block id="6e62430b92a7c5a0b8512436b163a10d" category="list-text">Il est possible que les économies d'espace réalisées grâce à l'efficacité du stockage ne soient pas signalées.</block>
  <block id="93d86aa51e0909549d1b1210f887aef3" category="list-text">Lorsqu'ils sont pris en charge, les miroirs de partage de charge ne peuvent pas être mis à jour.</block>
  <block id="647d380b52e259fe7ed2e2582bc54b27" category="list-text">Il est possible que la connexion EMS ne soit pas effectuée sur des systèmes ONTAP gérés avec des identifiants évalués par SVM.</block>
  <block id="c5cd657df037c277c37216b73efb0b08" category="summary">Si possible, utilisez toujours les outils ONTAP pour provisionner les datastores et les volumes. Cela vérifie que les volumes, les chemins de jonction, les LUN, les igroups, les règles d'exportation, et d'autres paramètres sont configurés de manière compatible.</block>
  <block id="d3b26e9021e83573a3d2a9050400a33a" category="doc">Meilleures pratiques opérationnelles</block>
  <block id="4d15db58f26b374b36c283df6b5a5fc1" category="paragraph">SRM prend en charge iSCSI, Fibre Channel et NFS version 3 avec ONTAP 9 lors de l'utilisation d'une réplication basée sur les baies via SRA. SRM ne prend pas en charge la réplication basée sur la baie pour NFS version 4.1 avec des datastores traditionnels ou vvols.</block>
  <block id="61f54ceeb0338787a2ee2d801cbc62cd" category="paragraph">Pour confirmer la connectivité, vérifiez toujours que vous pouvez monter et démonter un nouveau datastore test sur le site de reprise sur incident à partir du cluster ONTAP de destination. Testez chaque protocole que vous envisagez d'utiliser pour la connectivité du datastore. L'une des meilleures pratiques est d'utiliser les outils ONTAP pour créer votre datastore de test, car elle effectue toutes les automatisations du datastore telles que dirigées par SRM.</block>
  <block id="0ac3e8abbf45a28af68d22b0f59a973e" category="paragraph">Les protocoles SAN doivent être homogènes pour chaque site. Vous pouvez combiner les protocoles NFS et SAN, mais les protocoles SAN ne doivent pas être combinés dans un même site. Par exemple, vous pouvez utiliser FCP sur le site A et iSCSI sur le site B. Vous ne devez pas utiliser FCP et iSCSI sur le site A. La raison en est que SRA ne crée pas de groupes initiateurs mixtes sur le site de reprise et SRM ne filtre pas la liste des initiateurs donnée à SRA.</block>
  <block id="63b6c8d5e17ef7185a34c4ddd86f9d19" category="inline-link-macro">configuration des volumes pour l'extension ou la réduction automatique</block>
  <block id="a1874a28c8389c5c687d10167e80dc1f" category="paragraph">La taille automatique du volume doit être définie sur<block ref="4d200fce73a8e1cc965cfc2c43343824" prefix=" " category="inline-code"></block> Pour les volumes contenant les datastores SAN et<block ref="d89f4f8b1d7c18847b88b46142f61535" prefix=" " category="inline-code"></block> Pour les datastores NFS. En savoir plus sur <block ref="ebd664f1c7cf128a3758282775d35e72" category="inline-link-macro-rx"></block>.</block>
  <block id="e401bd7c98141814eaf5528ddb318da6" category="section-title">Gestion basée sur des règles de stockage (SPBM) et vVols</block>
  <block id="be41c3baf700984021c43e2e6b661b0a" category="paragraph">La capture d'écran suivante fournit un exemple de planifications SnapMirror affichées dans l'assistant de création de règles de stockage de machine virtuelle.</block>
  <block id="f6292d9eb6ea467a3c3560a65b7f63b5" category="paragraph">Le fournisseur ONTAP VASA prend en charge le basculement vers des systèmes de stockage différents. Par exemple, le système peut basculer d'un système ONTAP Select à un emplacement de périphérie vers un système AFF dans le data Center central. Indépendamment de la similarité de stockage, vous devez toujours configurer les mappages des règles de stockage et les mappages inversés des règles de stockage de machines virtuelles grâce à la réplication, afin de garantir que les services fournis sur le site de reprise répondent aux attentes et aux exigences de votre entreprise. La capture d'écran suivante met en évidence un exemple de mappage de règles.</block>
  <block id="1eb90dc8f7adfd00c74af3b815e2ac15" category="section-title">Créez des volumes répliqués pour les datastores vvols</block>
  <block id="550d51e15336d4a33bcbb0f26a6810f7" category="paragraph">Il faut faire preuve de prudence lorsqu'il s'agit de vVvols et SRM. Ne mélangez jamais des machines virtuelles protégées et non protégées dans le même datastore vVvols. Cela s'explique par le fait que, lorsque vous utilisez SRM pour basculer vers votre site de reprise sur incident, seules les machines virtuelles qui font partie du groupe de protection sont mises en ligne sur le site de reprise sur incident. Par conséquent, lorsque vous reprotégez (repassez de SnapMirror de la reprise sur incident à la production), vous pouvez remplacer les machines virtuelles qui n'étaient pas basculées et qui pouvaient contenir des données précieuses.</block>
  <block id="6d717f70d89096b731dfc63d7a1379e1" category="section-title">À propos des paires de baies</block>
  <block id="2219228418c053eb593ce0a1f318da47" category="paragraph">Lors de la configuration des paires de baies dans SRM, vous devez toujours les ajouter à SRM de la même manière que vous les avez ajoutés à ONTAP Tools : autrement dit, ils doivent utiliser le même nom d'utilisateur, mot de passe et LIF de gestion. Cette exigence garantit que SRA communique correctement avec la baie. La copie d'écran suivante montre comment un cluster peut s'afficher dans les outils ONTAP et comment il peut être ajouté à un gestionnaire de baies.</block>
  <block id="3b34135c8c4d2b14ceb7ebf595f00193" category="section-title">À propos des groupes de réplication</block>
  <block id="6be59afd3c8bb91501f55a7e77ebe794" category="paragraph">Les groupes de réplication contiennent des ensembles logiques de machines virtuelles qui sont restaurées ensemble. Le fournisseur VASA, un outil de ONTAP, crée automatiquement des groupes de réplication pour vous. Étant donné que la réplication SnapMirror de ONTAP se produit au niveau du volume, toutes les machines virtuelles d'un volume se trouvent dans le même groupe de réplication.</block>
  <block id="c727c1020d3128dd7495a6e3e6f23736" category="paragraph">Dernier point à prendre en compte pour les groupes de réplication : chacun d'entre eux est, par nature, un groupe de cohérence logique (à ne pas confondre avec les groupes de cohérence SRM). En effet, toutes les machines virtuelles du volume sont transférées ensemble à l'aide du même snapshot. Ainsi, si vous disposez de machines virtuelles qui doivent être cohérentes les unes avec les autres, envisagez de les stocker dans le même FlexVol.</block>
  <block id="9f8a350a2113ea4be6b4e5e5112514a3" category="section-title">À propos des groupes de protection</block>
  <block id="df77671ab2743af7f1d1457c200eb12c" category="paragraph">Les groupes de protection définissent les VM et les datastores dans des groupes restaurés à partir du site protégé. Le site protégé est là où existent les VM configurées dans un groupe de protection pendant les opérations stables. Il est important de noter que même si SRM peut afficher plusieurs gestionnaires de baies pour un groupe de protection, un groupe de protection ne peut pas s'étendre sur plusieurs gestionnaires de baies. Pour cette raison, vous ne devez pas couvrir les fichiers de machine virtuelle sur plusieurs datastores sur différents SVM.</block>
  <block id="b148467d645c3613c1c7a2607764c515" category="section-title">À propos des plans de reprise</block>
  <block id="fd28cd9834ad3aa213c4fec2881064b5" category="paragraph">Les plans de reprise définissent les groupes de protection qui sont restaurés au cours du même processus. Plusieurs groupes de protection peuvent être configurés dans le même plan de reprise. Par ailleurs, pour activer davantage d'options pour l'exécution des plans de reprise, un seul groupe de protection peut être inclus dans plusieurs plans de restauration.</block>
  <block id="77aa84394124509e5e4006dcfd18789f" category="paragraph">Les plans de restauration permettent aux administrateurs SRM de définir les flux de travail de restauration en affectant des VM à un groupe de priorité compris entre 1 (le plus élevé) et 5 (le plus faible), dont la valeur par défaut est 3 (moyen). Au sein d'un groupe de priorités, les VM peuvent être configurés pour les dépendances.</block>
  <block id="030d749269f8866de516a551b0286001" category="paragraph">NetApp recommande fortement de travailler avec vos équipes en charge des applications pour comprendre l'ordre des opérations requises dans un scénario de basculement et pour élaborer vos plans de reprise en conséquence.</block>
  <block id="cebb1167d3e78885137c837f0abf8026" category="section-title">Tester le basculement</block>
  <block id="6ae8acfc86f5df3426d525fb95767506" category="paragraph">NetApp recommande également de confirmer occasionnellement les fonctionnalités des applications chez l'invité, en particulier après la reconfiguration du stockage des machines virtuelles.</block>
  <block id="bd47371bcd8b3d08d6b4b15481b08d93" category="paragraph">Lors de l'exécution d'une opération de restauration test, un réseau de bulles de test privé est créé sur l'hôte ESXi pour les machines virtuelles. Cependant, ce réseau n'est pas automatiquement connecté à aucune carte réseau physique et ne fournit donc pas de connectivité entre les hôtes ESXi. Pour permettre la communication entre les machines virtuelles s'exécutant sur différents hôtes ESXi lors du test de reprise après incident, un réseau privé physique est créé entre les hôtes ESXi du site de reprise après incident. Pour vérifier que le réseau de test est privé, le réseau de bulles de test peut être séparé physiquement ou à l'aide de VLAN ou de balisage VLAN. Ce réseau doit être isolé du réseau de production car les machines virtuelles sont restaurées. En effet, ils ne peuvent pas être placés sur le réseau de production avec des adresses IP qui pourraient entrer en conflit avec les systèmes de production réels. Lors de la création d'un plan de reprise d'activité dans SRM, le réseau test créé peut être sélectionné comme réseau privé afin de connecter les VM à pendant le test.</block>
  <block id="2be58fc410ddf2ba9c350135a617944a" category="paragraph">Une fois le test validé et n'est plus nécessaire, effectuez une opération de nettoyage. Le nettoyage en cours d'exécution renvoie l'état initial des machines virtuelles protégées à leur état initial et réinitialise le plan de restauration en mode prêt.</block>
  <block id="6f07b53963ee80903f0f13654de2cc3a" category="section-title">Considérations relatives au basculement</block>
  <block id="9d33d94019b4a595a1ea232926a4da1b" category="paragraph">Il y a plusieurs autres considérations lorsqu'il s'agit de basculer sur un site en plus de l'ordre des opérations mentionné dans ce guide.</block>
  <block id="74abdd5cb502cd65bcf1d7ca484ab0c2" category="paragraph">Vous devrez peut-être résoudre ce problème en tenant compte des différences de réseau entre les sites. Certains environnements peuvent utiliser les mêmes adresses IP réseau à la fois sur le site primaire et sur le site de reprise après incident. Cette fonctionnalité est appelée VLAN (Virtual LAN) étendu ou configuration réseau étendu. Dans d'autres environnements, il est parfois nécessaire d'utiliser différentes adresses IP réseau (par exemple, sur différents VLAN) sur le site primaire par rapport au site de reprise.</block>
  <block id="9b8890fe5b1ab29543118b12a7bd0a07" category="inline-link-macro">Options NSX-T avec SRM</block>
  <block id="25154023650451d6cc971fc54bff8898" category="paragraph">VMware offre plusieurs moyens de résoudre ce problème. Pour la première, des technologies de virtualisation de réseau comme VMware NSX-T Data Center extraient la pile réseau des couches 2 à 7 de l'environnement d'exploitation, afin d'offrir des solutions plus portables. En savoir plus sur <block ref="3e6a2bd8e1acf69d423b7944c6543271" category="inline-link-macro-rx"></block>.</block>
  <block id="b56336aa967325217297d8725b64eb0b" category="inline-link-macro">Documentation de VMware</block>
  <block id="d32598436410006707b2ad1d79395f02" category="paragraph">Pour configurer SRM de façon à appliquer différents paramètres réseau à plusieurs machines virtuelles sans devoir modifier les propriétés de chacune d'entre elles dans le plan de reprise, VMware fournit un outil appelé dr-ip-customizer. Pour savoir comment utiliser cet utilitaire, reportez-vous à la section <block ref="837c7339284b78d4fd5550c5d0fb1a68" category="inline-link-macro-rx"></block>.</block>
  <block id="3c8c527afa8ce5009c8f707f7fd4fabf" category="section-title">Reprotéger</block>
  <block id="3b496038cb575fc404f8b0783e570f7a" category="paragraph">Après une restauration, le site de reprise devient le nouveau site de production. Comme l'opération de reprise a rompue la réplication SnapMirror, le nouveau site de production n'est pas protégé contre un futur incident. Il est recommandé de protéger le nouveau site de production sur un autre site immédiatement après une restauration. Si le site de production d'origine est opérationnel, l'administrateur VMware peut utiliser le site de production d'origine comme nouveau site de reprise pour protéger le nouveau site de production, ce qui inversera efficacement la direction de la protection. La reprotection est disponible uniquement en cas de défaillance majeure. Par conséquent, les serveurs vCenter d'origine, les serveurs ESXi, les serveurs SRM et les bases de données correspondantes doivent être récupérables. S'ils ne sont pas disponibles, un nouveau groupe de protection et un nouveau plan de récupération doivent être créés.</block>
  <block id="2bf236f8aceaaff2b305848df524c42e" category="paragraph">Une opération de retour arrière est fondamentalement un basculement dans une direction différente de celle précédente. Il est recommandé de vérifier que le site d'origine fonctionne à un niveau de fonctionnalité acceptable avant de tenter un retour arrière ou, en d'autres termes, un basculement vers le site d'origine. Si le site d'origine est toujours compromis, vous devez reporter la restauration jusqu'à ce que la défaillance soit suffisamment remédiée.</block>
  <block id="cb03753531bad31391d7156433b98ae6" category="paragraph">Une autre meilleure pratique de restauration consiste à toujours effectuer un basculement de test après avoir terminé la reprotection et avant de procéder à la restauration finale. Cela vérifie que les systèmes en place sur le site initial peuvent mener à bien l'opération.</block>
  <block id="900a3b65ea54b6dcff72ed0d6ac66fdf" category="section-title">Reprotéger le site d'origine</block>
  <block id="12d059a2c7519f2e3497b30a71121503" category="paragraph">La reprotection après le retour arrière reprend l'état où il était au début, avec la réplication SnapMirror à nouveau en cours d'exécution depuis le site de production vers le site de reprise.</block>
  <block id="39e5fc9eb192f011ab14dae6c2974c4e" category="list-text">*Modélisation des menaces.* le but de la modélisation des menaces est de découvrir des défauts de sécurité dans une fonction, un composant ou un produit au début du cycle de vie du développement logiciel. Un modèle de menace est une représentation structurée de toutes les informations qui affectent la sécurité d'une application. En substance, c'est une vision de l'application et de son environnement par le biais du principe de sécurité.</block>
  <block id="9f16ab3a50bca32d19c4729319035c8d" category="list-text">*Dynamic application Security Testing (DAST).* cette technologie est conçue pour détecter les conditions vulnérables sur les applications dans leur état d'exécution. DAST teste les interfaces HTTP et HTML exposées des applications Web-enable.</block>
  <block id="267bed0525e4dab477e4c24ca5a1794e" category="list-text">*Devise de code tierce.* dans le cadre du développement de logiciels avec des logiciels open-source (OSS), vous devez corriger les vulnérabilités de sécurité qui pourraient être associées à tout OSS intégré à votre produit. Il s'agit d'un effort continu car une nouvelle version OSS peut avoir une nouvelle vulnérabilité découverte signalée à tout moment.</block>
  <block id="db7bc87c89c1ee76d313865a32fc0e06" category="list-text">*Analyse des vulnérabilités* l'analyse des vulnérabilités a pour but de détecter les vulnérabilités de sécurité courantes et connues dans les produits NetApp avant leur publication auprès des clients.</block>
  <block id="1a4c104571630526efc77b84e82380fe" category="list-text">* Tests de pénétration.* le test de pénétration est le processus d'évaluation d'un système, d'une application Web ou d'un réseau pour trouver des vulnérabilités de sécurité qui pourraient être exploitées par un attaquant. Les tests d'intrusion chez NetApp sont réalisés par un groupe d'entreprises tierces de confiance et approuvées. Leur domaine de test comprend le lancement d'attaques contre une application ou un logiciel similaire à des intrus hostiles ou des pirates informatiques à l'aide de méthodes ou d'outils d'exploitation sophistiqués.</block>
  <block id="7e98fc3ea1ec077cfd1727a58e9c9020" category="section-title">Fonctionnalités de sécurité du produit</block>
  <block id="dff88c2ef0b49b09246ffd6f9ec55195" category="list-text">*Bannière de connexion.* SSH est désactivé par défaut et n'autorise que les connexions à une seule fois si elles sont activées à partir de la console VM. La bannière de connexion suivante s'affiche une fois que l'utilisateur a saisi un nom d'utilisateur dans l'invite de connexion :</block>
  <block id="399875025e8e96cc13102a4dd72f2434" category="paragraph">*AVERTISSEMENT:* l'accès non autorisé à ce système est interdit et sera poursuivi par la loi. En accédant à ce système, vous convenez que vos actions peuvent être surveillées si vous soupçonnez une utilisation non autorisée.</block>
  <block id="2d8330ed99c80a842ffbd1362e038e5e" category="paragraph">Une fois la connexion établie par l'utilisateur via le canal SSH, le texte suivant s'affiche :</block>
  <block id="677528ad13d460c058ac50e8a62092cf" category="list-text">*Contrôle d'accès basé sur les rôles (RBAC).* deux types de contrôles RBAC sont associés aux outils ONTAP :</block>
  <block id="ac38773d017495a97d5b88f242578cb8" category="list-text">Privilèges de serveur vCenter natif</block>
  <block id="c2e2fce3a995f59900d7afbbe58683f5" category="inline-link">ce lien</block>
  <block id="31cedac82fef311cb790a12f96897223" category="list-text">Privilèges spécifiques au plug-in vCenter. Pour plus de détails, voir<block ref="e5f6920797dbff91ef59367270a82669" category="inline-link-rx"></block>.</block>
  <block id="5d32469f8a65b884a8f70abf95fe485a" category="list-text">*Canaux de communication cryptés.* toutes les communications externes se produisent sur HTTPS en utilisant la version 1.2 de TLS.</block>
  <block id="600d4f98483fae8e58054f976d7e0c0e" category="list-text">*Exposition minimale au port.* seuls les ports nécessaires sont ouverts sur le pare-feu.</block>
  <block id="0406f8902379502d1eba01f043c232b7" category="paragraph">Le tableau suivant décrit les détails du port ouvert.</block>
  <block id="69fc9fe9cbb7709e97a433352aecf77d" category="cell">N° de port TCP v4/v6</block>
  <block id="02674a4ef33e11c879283629996c8ff8" category="cell">Direction</block>
  <block id="86408593c34af77fdd90df932f8b5261" category="cell">Fonction</block>
  <block id="0c95054981de037de06e544a52eb3613" category="cell">8143</block>
  <block id="a8e6fe5b9e68f30a146cefebaa7edcc3" category="cell">entrant</block>
  <block id="d16c4afdc5f340936b747baf91efc843" category="cell">Connexions HTTPS pour l'API REST</block>
  <block id="5bd529d5b07b647a8863cf71e98d651a" category="cell">8043</block>
  <block id="1f4deeb2f64336d4ff65ea3d2b4ffe2f" category="cell">Connexions HTTPS</block>
  <block id="cb4b69eb9bd10da82c15dca2f86a1385" category="cell">9060</block>
  <block id="5852f8019b572f4cdef5bab783fa799f" category="cell">Connexions HTTPS
Utilisé pour les connexions SOAP sur https
Ce port doit être ouvert pour permettre à un client de se connecter au serveur d'API des outils ONTAP.</block>
  <block id="b6d767d2f8ed5d21a44b0e5886680cb9" category="cell">22</block>
  <block id="f4e339608b243f9b57b78ffaf061b498" category="cell">SSH (désactivé par défaut)</block>
  <block id="d82d678e9583c1f5f283ec56fbf1abb7" category="cell">9080</block>
  <block id="ef34781e03f49b5db5dd8fa267c4c41b" category="cell">Connexions HTTPS - VP et SRA - connexions internes à partir du bouclage uniquement</block>
  <block id="a44ba9086b2b83ccf2baf7c678723449" category="cell">9083</block>
  <block id="fe01ac95967cd8cb5f5b5669b685277a" category="cell">Connexions HTTPS - VP et SRA
Utilisé pour les connexions SOAP sur https</block>
  <block id="abea47ba24142ed16b7d8fbf2c740e0d" category="cell">1162</block>
  <block id="4a0724da5c6f4e4817663ae822550800" category="cell">Paquets de déroutement SNMP VP</block>
  <block id="5cce8dede893813f879b873962fb669f" category="cell">1527</block>
  <block id="91c15b8eb529bf2100c10383d1010a1e" category="cell">diffusion interne uniquement</block>
  <block id="60135f95267c6e0711bf5a2858dfff2f" category="cell">Port de base de données Derby, uniquement entre cet ordinateur et lui-même, connexions externes non acceptées -- connexions internes uniquement</block>
  <block id="13f3cf8c531952d72e5847c4183e6910" category="cell">443</block>
  <block id="1ef2b5426b0824e93e33753fa87ddbf5" category="cell">bidirectionnel</block>
  <block id="e4b8a8d8761aab7733e317b585d5d606" category="cell">Utilisé pour les connexions aux clusters ONTAP</block>
  <block id="bf6184406d1e18fffc86ecf770fbb391" category="inline-link">article de la base de connaissances</block>
  <block id="fedac49792829de4ff38fcf7a3846faa" category="list-text">*Prise en charge des certificats signés de l'autorité de certification (CA).* les outils ONTAP pour VMware vSphere prennent en charge les certificats signés de l'autorité de certification. Voir ceci<block ref="0903a062b2072644a9b744a7fece4216" category="inline-link-rx"></block> pour en savoir plus.</block>
  <block id="9fca19988370da2a459b24505e9d23d5" category="list-text">*Audit Logging.* les offres de support peuvent être téléchargées et sont extrêmement détaillées. Les outils ONTAP consigne toutes les activités de connexion et de déconnexion de l'utilisateur dans un fichier journal distinct. Les appels d'API VASA sont connectés à un journal d'audit VASA dédié (local cxf.log).</block>
  <block id="7d60a2806aedd934b75cce55d6693689" category="list-text">*Stratégies de mot de passe.* les stratégies de mot de passe suivantes sont respectées :</block>
  <block id="f82f7513742f08b9d2784923213bdc75" category="list-text">Les mots de passe ne sont pas enregistrés dans des fichiers journaux.</block>
  <block id="83040c348e071499488a8128db207545" category="list-text">Les mots de passe ne sont pas communiqués en texte brut.</block>
  <block id="bc319862df3312f423a50fece7730db9" category="list-text">Les mots de passe sont configurés lors du processus d'installation lui-même.</block>
  <block id="853c2ea85b86882d0ea73b606a9800a4" category="list-text">L'historique des mots de passe est un paramètre configurable.</block>
  <block id="b3d3877bc96752ae50a409c72597d47a" category="list-text">L'âge minimum du mot de passe est défini sur 24 heures.</block>
  <block id="fb0bdec50022a37424a405b53da7c9c8" category="list-text">La saisie automatique des champs de mot de passe est désactivée.</block>
  <block id="3a04f054be8ad983ea82fd5079519810" category="list-text">Les outils ONTAP crypte toutes les informations d'identification stockées à l'aide de la fonction de hachage SHA256.</block>
  <block id="46e61d6e7c848d43ddcede8efd36c3d8" category="doc">Plug-in SnapCenter VMware vSphere</block>
  <block id="ae9e79ac4b60eba67cf1c7508417b42c" category="paragraph">Le plug-in NetApp SnapCenter pour l'ingénierie logicielle VMware vSphere exploite les activités de développement sécurisées suivantes :</block>
  <block id="b25a1098aff7d0c5ee590f1e1a114bb9" category="list-text">*Test dynamique de sécurité des applications (DAST).* technologies conçues pour détecter les conditions vulnérables des applications dans leur état d'exécution. DAST teste les interfaces HTTP et HTML exposées des applications Web-enable.</block>
  <block id="6cc1fee6b4fc48755d78e93170bbed93" category="list-text">*Devise de code tierce.* dans le cadre du développement de logiciels et de l'utilisation de logiciels open-source (OSS), il est important de traiter les vulnérabilités de sécurité qui pourraient être associées à OSS qui a été intégré à votre produit. Il s'agit d'un effort continu car la version du composant OSS peut avoir une vulnérabilité nouvellement découverte signalée à tout moment.</block>
  <block id="87bd0fb9b4198f33535e0e1888a809f5" category="list-text">* Tests de pénétration.* le test de pénétration est le processus d'évaluation d'un système, d'une application Web ou d'un réseau pour trouver des vulnérabilités de sécurité qui pourraient être exploitées par un attaquant. Les tests d'intrusion chez NetApp sont réalisés par un groupe d'entreprises tierces de confiance et approuvées. Leur domaine de test comprend le lancement d'attaques contre une application ou un logiciel comme des intrus hostiles ou des pirates informatiques à l'aide de méthodes ou d'outils d'exploitation sophistiqués.</block>
  <block id="e91db3b3278f7bd95cc704d74c5c9597" category="paragraph">Le plug-in NetApp SnapCenter pour VMware vSphere inclut les fonctionnalités de sécurité suivantes dans chaque version :</block>
  <block id="4abd7d1d5d223683d3346671efb7e89c" category="list-text">*Accès limité au shell.* SSH est désactivé par défaut, et les connexions à une seule fois ne sont autorisées que si elles sont activées à partir de la console VM.</block>
  <block id="8c264fa5ca2c588d960d98bd30cbc897" category="list-text">*Avertissement d'accès dans la bannière de connexion.* la bannière de connexion suivante s'affiche après que l'utilisateur ait entré un nom d'utilisateur dans l'invite de connexion :</block>
  <block id="0d6633ada3a9803e206b2359d859e892" category="paragraph">Une fois que l'utilisateur a terminé sa connexion via le canal SSH, les valeurs de sortie suivantes s'affichent :</block>
  <block id="b883bf79639dfce77e395b8458ee69e4" category="list-text">Privilèges de serveur vCenter natif.</block>
  <block id="721796b1cb3468f0daf819180184d460" category="inline-link">Contrôle d'accès basé sur des rôles (RBAC)</block>
  <block id="1d08c46b7567a29be0690a92b9722a58" category="list-text">Privilèges spécifiques au plug-in VMware vCenter. Pour plus d'informations, voir<block ref="f351263ad3706bd0a472039400dece78" category="inline-link-rx"></block>.</block>
  <block id="acab4c655c4a7b4db67fc07e22b86222" category="list-text">*Canaux de communication cryptés.* toutes les communications externes sont effectuées via HTTPS en utilisant TLS.</block>
  <block id="47a37e2d5fc8b7c936ad9b2b7a569a08" category="paragraph">Le tableau suivant fournit les détails du port ouvert.</block>
  <block id="10bd16a816f831080065e807daa36a9a" category="cell">Numéro de port TCP v4/v6</block>
  <block id="edf0320adc8658b25ca26be5351b6c4a" category="cell">8144</block>
  <block id="d4a973e303ec37692cc8923e3148eef7" category="cell">8080</block>
  <block id="2c25c3d66f80eeaa8d6e5a144c6f942e" category="cell">Connexions HTTPS pour interface graphique OVA</block>
  <block id="14b3e670eec63cc0cc456fd904bbfbd9" category="cell">SSH (désactivé par défaut)</block>
  <block id="16fc18d787294ad5171100e33d05d4e2" category="cell">3306</block>
  <block id="4cbf9c234f6b34c242a110cb993252bd" category="cell">MySQL (connexions internes uniquement, connexions externes désactivées par défaut)</block>
  <block id="29ab4efbdb7c727c81ee1382593bc5e2" category="cell">Nginx (services de protection des données)</block>
  <block id="89f152cad33314315b4995ed1ca71535" category="inline-link">Comment créer et/ou importer un certificat SSL dans le plug-in SnapCenter pour VMware vSphere (SCV)</block>
  <block id="450adc59e39f23172756ac9369494a2d" category="list-text">*Prise en charge des certificats signés par l'autorité de certification (CA).* le plug-in SnapCenter pour VMware vSphere prend en charge la fonctionnalité des certificats signés par l'autorité de certification. Voir<block ref="9f83d87d5d9f604d96288df21d450fac" category="inline-link-rx"></block>.</block>
  <block id="05a1aa8021df4579874c4eeb8788e5c9" category="list-text">*Stratégies de mot de passe.* les stratégies de mot de passe suivantes sont en vigueur :</block>
  <block id="2c87609dbbc3630573c64e271de8207d" category="list-text">Toutes les informations d'identification sont stockées à l'aide d'un hachage SHA256.</block>
  <block id="0f1a6fa0a65f9d5c3c4a16b070104d7a" category="list-text">*Image du système d'exploitation de base.* le produit est fourni avec le système d'exploitation de base Debian pour OVA avec accès restreint et accès au shell désactivé. Cela réduit l'empreinte d'attaque. Chaque système d'exploitation de base SnapCenter est mis à jour avec les derniers correctifs de sécurité disponibles pour une protection maximale.</block>
  <block id="83cd5867ba912e517fa1100299fd1cf3" category="paragraph">NetApp développe des fonctionnalités logicielles et des correctifs de sécurité en ce qui concerne le plug-in SnapCenter pour l'appliance VMware vSphere, puis les publie auprès de ses clients sous la forme d'un pack logiciel. Étant donné que ces dispositifs intègrent des dépendances spécifiques au système d'exploitation Linux et à notre logiciel propriétaire, NetApp vous recommande de ne pas modifier le système sous-exploitation, car il présente un potentiel important d'affecter l'appliance NetApp. Cela pourrait affecter la capacité de NetApp à prendre en charge l'appliance. NetApp recommande de tester et de déployer la dernière version de code pour les appliances, car elles sont publiées pour corriger les problèmes de sécurité.</block>
  <block id="1bc6cee680286aae1b12889369b7f18a" category="summary">MySQL sur ONTAP</block>
  <block id="dac8ea4fbfd87a535663c227b91f50e3" category="doc">Planificateurs d'E/S.</block>
  <block id="215dca219378b291ae287eb076489fdd" category="paragraph">Le noyau Linux permet un contrôle de bas niveau sur la façon dont les E/S sont planifiées pour bloquer les périphériques.</block>
  <block id="dc36d23ef487690f1698c69d9e49cee2" category="paragraph">Les valeurs par défaut sur les différentes distributions de Linux varient considérablement. MySQL vous recommande d'utiliser<block ref="722d122e81cbbe543bd5520bb8678c0e" prefix=" " category="inline-code"></block> ou un<block ref="30e482a8ab57cfc19075dece53b0a56b" prefix=" " category="inline-code"></block> Planificateur d'E/S avec E/S asynchrones natives (AIO) sous Linux. De manière générale, les clients NetApp et les tests internes montrent de meilleurs résultats avec NoOps.</block>
  <block id="6def78482bd1915cb81f0f5c19ee8fe6" category="paragraph">Le moteur de stockage InnoDB de MySQL utilise le sous-système d'E/S asynchrone (AIO natif) sur Linux pour effectuer des demandes de lecture et d'écriture pour les pages de fichiers de données. Ce comportement est contrôlé par le<block ref="2c03186a22d036ce7dad84be5de2f2ce" prefix=" " category="inline-code"></block> option de configuration, activée par défaut. Avec le tout-en-un natif, le type de planificateur d'E/S a une plus grande influence sur les performances E/S. Menez des bancs d'essai pour déterminer quel planificateur d'E/S offre les meilleurs résultats pour votre charge de travail et votre environnement.</block>
  <block id="e7b09beaf26efc7d8bee91786cf794b5" category="paragraph">Consultez la documentation Linux et MySQL appropriée pour obtenir des instructions sur la configuration du planificateur d'E/S.</block>
  <block id="6e8775bd755a8835ce86806d669677ea" category="doc">Configuration de stockage sous-jacente</block>
  <block id="2f09ac000b4a1808cb795b7bdbb20ecc" category="doc">taille_fichier_log_innodb</block>
  <block id="b8674b2897b288ca55b74328df4780b3" category="paragraph">Il est important de sélectionner la bonne taille pour le fichier journal InnoDB pour les opérations d'écriture et pour avoir un temps de récupération décent après une panne du serveur.</block>
  <block id="b61bad6f7bf48bf9abda0c86c9beed79" category="paragraph">Étant donné que tant de transactions sont connectées au fichier, la taille du fichier journal est importante pour les opérations d'écriture. Lorsque les enregistrements sont modifiés, la modification n'est pas immédiatement réécrite dans l'espace de table. Au lieu de cela, la modification est enregistrée à la fin du fichier journal et la page est marquée comme sale. InnoDB utilise son journal pour convertir les E/S aléatoires en E/S séquentielles</block>
  <block id="e87d83a3c0af4df83efb4784b5182f8f" category="paragraph">Lorsque le journal est plein, la page sale est écrite dans l'espace table en séquence pour libérer de l'espace dans le fichier journal. Par exemple, supposons qu'un serveur se bloque au milieu d'une transaction et que les opérations d'écriture ne sont enregistrées que dans le fichier journal. Avant que le serveur puisse de nouveau être mis en service, il doit passer par une phase de récupération dans laquelle les modifications enregistrées dans le fichier journal sont relus. Plus le nombre d'entrées dans le fichier journal est important, plus la restauration du serveur prend de temps.</block>
  <block id="8321756b7fedf72543a1b0917bf92613" category="paragraph">Dans cet exemple, la taille du fichier journal affecte à la fois le temps de restauration et les performances d'écriture. Lorsque vous choisissez le bon nombre pour la taille du fichier journal, équilibrez le délai de restauration par rapport aux performances d'écriture. En général, tout ce qui se trouve entre 128M et 512M est d'une bonne valeur.</block>
  <block id="598132a821e8cc696fbbae934047d991" category="paragraph">MySQL et ses variantes, y compris MariaDB et Percona MySQL, est la base de données la plus populaire au monde.</block>
  <block id="35701e1bcd40c8e1a520fc33d0e14842" category="doc">innodb_flush_method</block>
  <block id="138738e11d5fda5c496edaa92e32e158" category="paragraph">Le paramètre innodb_flush_method indique comment InnoDB ouvre et vide les fichiers journaux et de données.</block>
  <block id="c262c8cd82b96f69fbbc058d7a35683b" category="section-title">Optimisations</block>
  <block id="d1e67ebe6122765789852eb430c42c75" category="paragraph">Dans l'optimisation InnoDB, la définition de ce paramètre permet de régler les performances de la base de données, le cas échéant.</block>
  <block id="51ca63a7fb332d4d18e7139ea5787c50" category="paragraph">Les options suivantes permettent de vider les fichiers via InnoDB :</block>
  <block id="a9b8d4c72b58a9554274cba7904d47e2" category="list-text"><block ref="e590322920bebc1156ab585bd6597d76" prefix="" category="inline-code"></block>. InnoDB utilise le<block ref="4d0b2ade287f8f35e993511729bc75a1" prefix=" " category="inline-code"></block> appel système pour vider les fichiers de données et les fichiers journaux. Cette option est le paramètre par défaut.</block>
  <block id="8198b1fd4bf2fafa4f4e8ffb4a8ac900" category="list-text"><block ref="a48be70a21bca2cf4b3e481efed66ae4" prefix="" category="inline-code"></block>. InnoDB utilise le<block ref="a48be70a21bca2cf4b3e481efed66ae4" prefix=" " category="inline-code"></block> option permettant d'ouvrir et de vider les fichiers journaux et fsync() pour vider les fichiers de données. InnoDB n'utilise pas<block ref="a48be70a21bca2cf4b3e481efed66ae4" prefix=" " category="inline-code"></block> Directement, parce qu'il y a eu des problèmes avec elle sur de nombreuses variétés d'UNIX.</block>
  <block id="f89f9147df5dde99a7944d2028b59e7e" category="list-text"><block ref="6a334fd488ef92b18584207148410cc4" prefix="" category="inline-code"></block>. InnoDB utilise le<block ref="6a334fd488ef92b18584207148410cc4" prefix=" " category="inline-code"></block> option (ou<block ref="42d27f470f62deaad644fef8618b59bb" prefix=" " category="inline-code"></block> Sous Solaris) pour ouvrir les fichiers de données et les utilise<block ref="4d0b2ade287f8f35e993511729bc75a1" prefix=" " category="inline-code"></block> pour vider les fichiers de données et les fichiers journaux. Cette option est disponible sur certaines versions de GNU/Linux, FreeBSD et Solaris.</block>
  <block id="5e90100e134d805a66f8cda2e73f5298" category="list-text"><block ref="d66655d6d13113f23421f282ed1eaeb7" prefix="" category="inline-code"></block>. InnoDB utilise le<block ref="6a334fd488ef92b18584207148410cc4" prefix=" " category="inline-code"></block> Option pendant le vidage des E/S ; cependant, il ignore le<block ref="4d0b2ade287f8f35e993511729bc75a1" prefix=" " category="inline-code"></block> appel système par la suite. Cette option n'est pas adaptée à certains types de systèmes de fichiers (par exemple, XFS). Si vous n'êtes pas sûr que votre système de fichiers nécessite un<block ref="4d0b2ade287f8f35e993511729bc75a1" prefix=" " category="inline-code"></block> l'appel système, par exemple pour conserver toutes les métadonnées de fichier, utilise le<block ref="6a334fd488ef92b18584207148410cc4" prefix=" " category="inline-code"></block> à la place.</block>
  <block id="c680d437163cc6bab4f9bdb35c3073d0" category="section-title">Observation</block>
  <block id="907dee0040812e8e7d1fd00b870b5063" category="paragraph">Dans les tests de laboratoire NetApp, le<block ref="e590322920bebc1156ab585bd6597d76" prefix=" " category="inline-code"></block> L'option par défaut a été utilisée sur NFS et SAN, et il s'agissait d'un outil d'amélioration des performances par rapport à<block ref="6a334fd488ef92b18584207148410cc4" prefix=" " category="inline-code"></block>. Lors de l'utilisation de la méthode de rinçage comme<block ref="6a334fd488ef92b18584207148410cc4" prefix=" " category="inline-code"></block> Avec ONTAP, nous avons observé que le client écrit beaucoup d'écritures sur un seul octet à la frontière du bloc 4096 en série. Ces écritures ont augmenté la latence sur le réseau et dégradé les performances.</block>
  <block id="2f0b9319cf6d59e07ea4b1ef65a12be1" category="doc">open_file_limits</block>
  <block id="11e52b21a9795b7dcf947027b0ec5d01" category="paragraph">Le<block ref="2f0b9319cf6d59e07ea4b1ef65a12be1" prefix=" " category="inline-code"></block> paramètre détermine le nombre de fichiers que le système d'exploitation autorise à ouvrir mysqld.</block>
  <block id="e0732f22b2900006e8fcb6367fd162f7" category="paragraph">La valeur de ce paramètre au moment de l'exécution est la valeur réelle autorisée par le système et peut être différente de la valeur spécifiée au démarrage du serveur. La valeur est 0 sur les systèmes où MySQL ne peut pas modifier le nombre de fichiers ouverts. L'efficace<block ref="3d39e9c5aa2f78830dd6993cec18e93e" prefix=" " category="inline-code"></block> la valeur est basée sur la valeur spécifiée au démarrage du système (le cas échéant) et sur les valeurs de<block ref="0bc91339c0d774f560a9a38fc9dfac30" prefix=" " category="inline-code"></block> et<block ref="023a3b50ddf424c9a1d51984190a0c92" prefix=" " category="inline-code"></block> en utilisant ces formules :</block>
  <block id="6b840ff0a7667f4642a0844269657fc4" category="list-text">10 +<block ref="0bc91339c0d774f560a9a38fc9dfac30" prefix=" " category="inline-code"></block> + <block ref="023a3b50ddf424c9a1d51984190a0c92" prefix="(" category="inline-code"></block> x 2)</block>
  <block id="d3de183489c20b8efa2947eeff3028d7" category="list-text"><block ref="0bc91339c0d774f560a9a38fc9dfac30" prefix="" category="inline-code"></block> x 5</block>
  <block id="2c08922fbaba089e7c2982df43fd352a" category="list-text">Limite du système d'exploitation si positif</block>
  <block id="8ca153937fcbdf56497ad779a91f31d1" category="list-text">Si la limite du système d'exploitation est infinie :<block ref="3d39e9c5aa2f78830dd6993cec18e93e" prefix=" " category="inline-code"></block> la valeur est spécifiée au démarrage ; 5,000 si aucune</block>
  <block id="98038bb4026a70f5ee4041522c6eebe4" category="paragraph">Le serveur tente d'obtenir le nombre de descripteurs de fichier en utilisant le maximum de ces quatre valeurs. Si ce nombre de descripteurs ne peut pas être obtenu, le serveur tente d'obtenir autant que le système le permet.</block>
  <block id="3ee58d04a0dc9b2551698643e0421005" category="doc">innodb_lru_scan_depth</block>
  <block id="29d0f4f8b383d39e73abd11ac73ca28a" category="paragraph">Le<block ref="3ee58d04a0dc9b2551698643e0421005" prefix=" " category="inline-code"></block> Le paramètre influence les algorithmes et les heuristiques de l'opération de vidage pour le pool de mémoire tampon InnoDB.</block>
  <block id="eeb16232629bd788f0d29c104105bba2" category="paragraph">Ce paramètre intéresse principalement les experts en performances qui s'intéressent au réglage des charges de travail exigeantes en E/S. Pour chaque instance de pool de mémoire tampon, ce paramètre indique la distance vers le bas dans la liste de pages LRU (least recently used) que le thread de nettoyage de page doit poursuivre la numérisation, en recherchant les pages sales à vider. Cette opération d'arrière-plan est effectuée une fois par seconde.</block>
  <block id="39359bf2914e4e1cf84a9dea580fd20a" category="paragraph">Vous pouvez régler la valeur vers le haut ou vers le bas pour réduire le nombre de pages libres. Ne définissez pas la valeur beaucoup plus haut que nécessaire, car les analyses peuvent avoir un coût de performance important. Pensez également à ajuster ce paramètre lors de la modification du nombre d'instances de pool de mémoire tampon, car<block ref="f2c8312d381c16c6c95a727c3f61a4c7" prefix=" " category="inline-code"></block> définit la quantité de travail effectuée par le thread de nettoyage de page chaque seconde.</block>
  <block id="513a275422fae2456617321a2f3fc0af" category="paragraph">Un paramètre inférieur à celui par défaut convient à la plupart des workloads. Envisagez d'augmenter la valeur uniquement si vous disposez d'une capacité d'E/S disponible pour une charge de travail classique. Inversement, si une charge de travail exigeante en écriture sature votre capacité d'E/S, diminuez la valeur, en particulier si vous disposez d'un pool de mémoire tampon important.</block>
  <block id="62812b938ba1113b81bd7f612ad0e6f8" category="doc">innodb_buffer_pool_size</block>
  <block id="d7a8b502d05f5e477158eb80c1fb8dae" category="paragraph">Le pool de mémoire tampon InnoDB est la partie la plus importante de toute activité de réglage.</block>
  <block id="5cb6c45d18482180f34ae727b53379fb" category="paragraph">InnoDB s'appuie fortement sur le pool de mémoire tampon pour mettre en cache les index et ramer les données, l'index de hachage adaptatif, le tampon d'insertion et de nombreuses autres structures de données utilisées en interne. Le pool de mémoire tampon met également en mémoire tampon les modifications apportées aux données afin que les opérations d'écriture n'aient pas à être exécutées immédiatement sur le stockage, ce qui améliore les performances. Le pool de mémoire tampon fait partie intégrante d'InnoDB et sa taille doit être ajustée en conséquence. Tenez compte des facteurs suivants lors de la définition de la taille du pool de mémoire tampon :</block>
  <block id="03f07291794c3b9cb00d04cb9f30be81" category="list-text">Pour une machine dédiée uniquement InnoDB, définissez la taille du pool de mémoire tampon sur 80 % ou plus de la mémoire RAM disponible.</block>
  <block id="7b0119b7fa59f87d23d5c65da456b226" category="list-text">S'il ne s'agit pas d'un serveur dédié MySQL, définissez la taille sur 50 % de RAM.</block>
  <block id="a6a9695e1464f5554c0006c55facfadf" category="doc">Descripteurs de fichier</block>
  <block id="8e222c68dd214db9f8a1b5b572ee6267" category="paragraph">Il les utilise pour ouvrir de nouvelles connexions, stocker des tables dans le cache, créer des tables temporaires pour résoudre des requêtes complexes et accéder à des requêtes persistantes. Si mysqld n'est pas en mesure d'ouvrir de nouveaux fichiers lorsque cela est nécessaire, il peut arrêter de fonctionner correctement. Un symptôme courant de ce problème est l'erreur 24, "trop de fichiers ouverts". Le nombre de descripteurs de fichier que mysqld peut ouvrir simultanément est défini par le<block ref="3d39e9c5aa2f78830dd6993cec18e93e" prefix=" " category="inline-code"></block> option définie dans le fichier de configuration <block ref="86d0d007043d911697753b35e2c18f35" prefix="(" category="inline-code"></block>). Mais<block ref="3d39e9c5aa2f78830dd6993cec18e93e" prefix=" " category="inline-code"></block> dépend également des limites du système d'exploitation. Cette dépendance complique la définition de la variable.</block>
  <block id="07561a91f81dfe3c8e4364aac8bdbea4" category="paragraph">MySQL ne peut pas définir son<block ref="3d39e9c5aa2f78830dd6993cec18e93e" prefix=" " category="inline-code"></block> option supérieure à celle spécifiée sous<block ref="dd1c6d8164dfd1cee0afa39b177e843b" prefix=" " category="inline-code"></block>. Par conséquent, vous devez définir explicitement ces limites au niveau du système d'exploitation pour permettre à MySQL d'ouvrir des fichiers si nécessaire. Il existe deux façons de vérifier la limite de fichiers sous Linux :</block>
  <block id="84e705ac120a887df441f4161dc29409" category="list-text">Le<block ref="2eabb4efed7dffb32ea1170eab71b798" prefix=" " category="inline-code"></block> commande vous donne rapidement une description détaillée des paramètres autorisés ou verrouillés. Les modifications apportées par l'exécution de cette commande ne sont pas permanentes et seront effacées après un redémarrage du système.</block>
  <block id="a4c404dc92855948bc4c007a86091dbe" category="list-text">Modifications apportées au<block ref="b803f460349bd101b1de260021ef0e60" prefix=" " category="inline-code"></block> les fichiers sont permanents et ne sont pas affectés par un redémarrage du système.</block>
  <block id="cbcab8220d4ffddbdc44f9936125d83d" category="paragraph">Assurez-vous de modifier les limites matérielles et logicielles de l'utilisateur mysql. Les extraits suivants sont issus de la configuration :</block>
  <block id="97dc47f90c600a96fac6642560ffaceb" category="paragraph">En parallèle, mettez à jour la même configuration dans<block ref="90f16be5b82ca0aa94088c89fe00b3dd" prefix=" " category="inline-code"></block> pour utiliser pleinement les limites de fichiers ouverts.</block>
  <block id="395ec860c9530814e94538b7121a8319" category="doc">innodb_flush_log_at_trx_commit</block>
  <block id="2f2c7742844f13de59d435b9099c78cc" category="paragraph">En cas de modification des données, celles-ci ne sont pas immédiatement écrites sur le support de stockage.</block>
  <block id="0b36b8f791a48c7b4692e7df069dabc8" category="paragraph">À la place, les données sont enregistrées dans une mémoire tampon, qui est une partie de la mémoire allouée par InnoDB aux modifications de mémoire tampon enregistrées dans le fichier journal. InnoDB vide le tampon dans le fichier journal lorsqu'une transaction est validée, lorsque le tampon est plein ou une fois par seconde, quel que soit l'événement qui se produit en premier. La variable de configuration qui contrôle ce processus est innodb_flush_log_at_trx_commit. Les options de valeur comprennent :</block>
  <block id="280a38864b81c14ba3db52801e087ed0" category="list-text">Lorsque vous réglez<block ref="cab9a35054c49f0ba619a6e6943f461b" prefix=" " category="inline-code"></block>, InnoDB écrit les données modifiées (dans le pool de mémoire tampon InnoDB) dans le fichier journal (ib_logfile) et purge le fichier journal (écriture dans le stockage) toutes les secondes. Cependant, elle ne fait rien lorsque la transaction est validée. En cas de panne de courant ou de panne du système, aucune des données non rincées n'est récupérable car elles ne sont pas écrites sur le fichier journal ou les lecteurs.</block>
  <block id="5967bb5566cb7cd8bdb0b372ceb21565" category="list-text">Lorsque vous réglez<block ref="1ab7a7611b59147e84a38b6f3e7d9d09" prefix=" " category="inline-code"></block>, InnoDB écrit la mémoire tampon du journal dans le journal de transactions et vide jusqu'à un stockage durable pour chaque transaction. Par exemple, pour toutes les validations de transactions, InnoDB écrit dans le journal, puis écrit dans le stockage. Un stockage plus lent affecte négativement les performances. Par exemple, le nombre de transactions InnoDB par seconde est réduit.</block>
  <block id="9e9b3a43cb7a1b13c5ee3f6519d7f60e" category="list-text">Lorsque vous réglez<block ref="44d4dfee9b1c95f8768bec989cd3baf5" prefix=" " category="inline-code"></block>, InnoDB écrit la mémoire tampon du journal dans le fichier journal à chaque validation ; cependant, il n'écrit pas de données dans le stockage. InnoDB vide les données une fois par seconde. Même en cas de panne de courant ou de panne du système, les données de l'option 2 sont disponibles dans le fichier journal et peuvent être récupérées.</block>
  <block id="14f3e0328e25aa02b37bd6817a442a58" category="paragraph">Si la performance est l'objectif principal, définissez la valeur sur 2. Comme InnoDB écrit sur les disques une fois par seconde, pas pour chaque validation de transaction, les performances s'améliorent considérablement. En cas de panne de courant ou de panne de courant, les données peuvent être récupérées à partir du journal de transactions.</block>
  <block id="4a34cbb1957909093a2e216fc1cd0962" category="paragraph">Si la sécurité des données est l'objectif principal, définissez la valeur sur 1 afin que, pour chaque validation de transaction, InnoDB vide les lecteurs. Cependant, les performances peuvent être affectées.</block>
  <block id="53be3047aa6f8a62c640cc8b4d6089c6" category="admonition">*NetApp recommande* de définir la valeur innodb_flush_log_trx_commit sur 2 pour de meilleures performances.</block>
  <block id="2199371f8380c97ad11a03fba3b501c9" category="doc">innodb_io_capacity</block>
  <block id="ac165f23bb7435219b226ed6e76c5fa4" category="paragraph">Dans le plug-in InnoDB, un nouveau paramètre appelé innodb_io_Capacity a été ajouté à partir de MySQL 5.7.</block>
  <block id="b4f38c42ef968074288f239b42e92b7f" category="paragraph">Il contrôle le nombre maximal d'IOPS qu'InnoDB exécute (qui inclut la vitesse de vidage des pages sales ainsi que la taille de lot du tampon d'insertion [ibuf]). Le paramètre innodb_io_Capacity définit une limite supérieure sur les IOPS par les tâches d'arrière-plan InnoDB, telles que le vidage des pages du pool de mémoire tampon et la fusion des données à partir du tampon de changement.</block>
  <block id="9679a08c293f29d9546c42207b09d418" category="paragraph">Définissez le paramètre innodb_io_Capacity sur le nombre approximatif d'opérations d'E/S que le système peut effectuer par seconde. Idéalement, maintenez le paramètre aussi bas que possible, mais pas si bas que les activités en arrière-plan ralentissent. Si le paramètre est trop élevé, les données sont supprimées du pool de mémoire tampon et la mémoire tampon est insérée trop rapidement pour que la mise en cache offre un avantage significatif.</block>
  <block id="668b6acc98c3469094062ed50b43e43a" category="admonition">*NetApp recommande* que si vous utilisez ce paramètre sur NFS, analysez le résultat du test d'IOPS (SysBench/FiO) et définissez le paramètre en conséquence. Utilisez la plus petite valeur possible pour le vidage et la purge pour continuer à fonctionner, sauf si vous voyez plus de pages modifiées ou sales que vous le souhaitez dans le pool de mémoire tampon InnoDB.</block>
  <block id="038b11d42ee14bd77b6370c575c63b16" category="admonition">N'utilisez pas de valeurs extrêmes telles que 20,000 ou plus, sauf si vous avez prouvé que des valeurs inférieures ne suffisent pas à votre charge de travail.</block>
  <block id="62385f5ceb285bca676cb0561555d719" category="paragraph">Le paramètre InnoDB_IO_Capacity régule les débits de rinçage et les E/S associées</block>
  <block id="58d94bb6e53e154e2f4b16efa09f4c0d" category="paragraph">Les bases de données plus petites peuvent être placées sur une paire de LUN standard tant que les besoins en E/S et en capacité se situent dans les limites d'un seul système de fichiers LUN. Par exemple, une base de données qui nécessite environ 2 000 IOPS aléatoires peut être hébergée sur un système de fichiers unique sur une seule LUN. De même, une base de données de 100 Go seulement serait prise en charge sur une seule LUN sans problème de gestion.</block>
  <block id="c33bcb4f520265bb106616e844397ffb" category="paragraph">Les bases de données plus grandes nécessitent plusieurs LUN. Par exemple, une base de données qui nécessite 100 000 IOPS aurait probablement besoin d'au moins huit LUN. Un seul LUN deviendrait un goulot d'étranglement en raison du nombre insuffisant de canaux SCSI vers les disques. Une base de données de 10 To serait tout aussi difficile à gérer sur un seul LUN de 10 To. Les gestionnaires de volumes logiques sont conçus pour lier les performances et les capacités de plusieurs LUN afin d'améliorer les performances et la gestion.</block>
  <block id="428e88a1415b00f5eb396829b4bd9a2c" category="paragraph">Dans les deux cas, une paire de volumes ONTAP doit suffire. Dans une configuration simple, le LUN du fichier de données serait placé dans un volume dédié, tout comme le LUN du journal. Avec une configuration de gestionnaire de volumes logique, toutes les LUN du groupe de volumes de fichiers de données se trouvent dans un volume dédié, et les LUN du groupe de volumes de logs se trouvent dans un second volume dédié.</block>
  <block id="e8c31916b755be39cb0a66804a1d8f8b" category="paragraph">*NetApp recommande* l'utilisation de deux systèmes de fichiers pour les déploiements MySQL sur SAN :</block>
  <block id="fe9d8ca2c46747e16ed31f64638e66e6" category="list-text">Le premier système de fichiers stocke toutes les données MySQL, y compris l'espace table, les données et l'index.</block>
  <block id="04d82ed32fa1eeaa6df117c178062441" category="list-text">Le second système de fichiers stocke tous les journaux (journaux binaires, journaux lents et journaux des transactions).</block>
  <block id="15bcb76b7e8b441c0d2a6e723f70c20c" category="paragraph">Il existe plusieurs raisons de séparer les données de cette manière :</block>
  <block id="02774797d31a8f1c6d805860038c32a3" category="list-text">Les modèles d'E/S des fichiers de données et des fichiers journaux diffèrent. De les séparer, on disposerait d'un plus grand nombre d'options avec les contrôles de QoS.</block>
  <block id="6cab2c793e807e2d0c57f5b0d96505c1" category="list-text">Pour optimiser l'utilisation de la technologie Snapshot, vous devez pouvoir restaurer les fichiers de données de manière indépendante. La connexion de fichiers de données avec des fichiers journaux interfère avec la restauration des fichiers de données.</block>
  <block id="553ad1f7b6f5cfee021e5cf56e56a289" category="list-text">La technologie SnapMirror de NetApp peut être utilisée pour fournir une fonctionnalité de reprise d'activité simple à faible RPO pour une base de données. Toutefois, le planning de réplication des fichiers de données et des journaux doit être différent.</block>
  <block id="ff5f52a69a35dd41da3e3c4b810e4f94" category="admonition">Utilisez cette disposition de base à deux volumes pour pérenniser votre solution et utiliser toutes les fonctionnalités ONTAP si nécessaire.</block>
  <block id="7b755794e9de5716b2d6305bd10bee1b" category="paragraph">*NetApp recommande* de formater votre lecteur avec le système de fichiers ext4 en raison des fonctionnalités suivantes :</block>
  <block id="fa92f58d5035dec5e24a787f76504783" category="list-text">Approche étendue des fonctions de gestion des blocs utilisées dans le système de fichiers de journalisation (JFS) et fonctions d'allocation différée du système de fichiers étendu (XFS).</block>
  <block id="a72d73cde02c10703b72dcae6bc7c812" category="list-text">Ext4 autorise des systèmes de fichiers allant jusqu'à 1 exbioctet (2^60 octets) et des fichiers allant jusqu'à 16 tébioctets (16 * 2^40 octets). En revanche, le système de fichiers ext3 ne prend en charge qu'une taille de système de fichiers maximale de 16 To et une taille de fichier maximale de 2 To.</block>
  <block id="56b4168424fa999bc383d24daf2da4eb" category="list-text">Dans les systèmes de fichiers ext4, l'allocation multi-blocs (mballoc) alloue plusieurs blocs pour un fichier en une seule opération, au lieu de les allouer un par un, comme dans ext3. Cette configuration réduit la surcharge liée à l'appel de l'ALlocator de bloc plusieurs fois et optimise l'allocation de mémoire.</block>
  <block id="632635d22b347f0140fb15d0eb0ed09e" category="list-text">Bien que XFS soit la valeur par défaut pour de nombreuses distributions Linux, il gère les métadonnées différemment et ne convient pas à certaines configurations MySQL.</block>
  <block id="aff8b2ed0a4719f014e5baeb861ea7d4" category="paragraph">*NetApp recommande* d'utiliser les options de taille de bloc de 4 ko avec l'utilitaire mkfs pour l'aligner avec la taille de LUN de bloc existante.</block>
  <block id="0a24d0336b7b0b29a9daa97f88499884" category="paragraph"><block ref="018d13c1d8b9abcae080b8abbc7c2d8b" prefix="" category="inline-code"></block></block>
  <block id="86fc8cb3bf2cae621315896a94b35f67" category="paragraph">Les LUN NetApp stockent les données dans des blocs physiques de 4 Ko, ce qui produit huit blocs logiques de 512 octets.</block>
  <block id="5f441ceabc94de2a9cced94d9f53a2d0" category="paragraph">Si vous ne configurez pas la même taille de bloc, les E/S ne seront pas alignées avec les blocs physiques correctement et pourraient écrire sur deux disques différents dans un groupe RAID, ce qui entraîne une latence.</block>
  <block id="236ac851d05b8822524001920948f23d" category="admonition">Il est important d'aligner les E/S pour que les opérations de lecture/écriture soient fluides. Cependant, lorsque les E/S commencent au niveau d'un bloc logique qui n'est pas au début d'un bloc physique, les E/S sont mal alignées. Les opérations d'E/S ne sont alignées que lorsqu'elles commencent au niveau d'un bloc logique, le premier bloc logique d'un bloc physique.</block>
  <block id="3225a10b07f1580f10dee4abc3779e6c" category="cell">Paramètres</block>
  <block id="c82a6100dace2b41087ba6cf99a5976a" category="cell">Valeurs</block>
  <block id="b10db909b8fda84e70bf9b308d0938d9" category="cell">256M</block>
  <block id="c81e728d9d4c2f636f067f89cc14862c" category="cell">2</block>
  <block id="7ccc31934ae8244d8263d3c09bcee186" category="cell">innodb_doublewrite</block>
  <block id="e590322920bebc1156ab585bd6597d76" category="cell">fsync</block>
  <block id="adb0c1ec32461889a5093441599260eb" category="cell">11G</block>
  <block id="774412967f19ea61d448977ad9749078" category="cell">8192</block>
  <block id="311887a53ec7390fc383fa2ad813f012" category="cell">innodb_buffer_pool_instances</block>
  <block id="c9f0f895fb98ab9159f51fd0297e236d" category="cell">8</block>
  <block id="1006f82d8df7d2325439b28ea691737c" category="cell">open_file_limit</block>
  <block id="3c9b5f1cd6a030bcb7bed9eac80589fb" category="cell">65535</block>
  <block id="c9f5a4d3ede4d084dda0a788ed06783c" category="paragraph">Pour définir les paramètres décrits dans cette section, vous devez les modifier dans le fichier de configuration MySQL (my.cnf). Les meilleures pratiques NetApp sont le résultat de tests réalisés en interne.</block>
  <block id="6a554ff1dc93539a626e576bf0d28a02" category="paragraph">La conteneurisation des bases de données MySQL est de plus en plus répandue.</block>
  <block id="bcc002a9f2e2ade112438f50a6630498" category="paragraph">La gestion des conteneurs de faible niveau est presque toujours effectuée via Docker. Les plateformes de gestion de conteneurs comme OpenShift et Kubernetes simplifient encore la gestion des grands environnements de conteneurs. La conteneurisation présente des avantages à moindre coût, car il n'est pas nécessaire de posséder une licence pour un hyperviseur. De plus, les conteneurs permettent à plusieurs bases de données de s'exécuter isolées les unes des autres tout en partageant le même noyau et le même système d'exploitation sous-jacents. Les conteneurs sont provisionnés en quelques microsecondes.</block>
  <block id="14d9b10c6196045941347a9e85704b50" category="inline-link-macro">Documentation Astra Trident</block>
  <block id="b8c3891a902a70c4f7f774363652f4b4" category="summary">Structure de fichier MySQL</block>
  <block id="5713a921d815fd7d19875846450f8ea8" category="doc">Structure de fichier</block>
  <block id="4955922857da5499a2f1be602a96b0ff" category="paragraph">InnoDB agit comme la couche intermédiaire entre le stockage et le serveur MySQL, il stocke les données sur les lecteurs.</block>
  <block id="5d416cf65dd1e2c908bf430f957c89f8" category="paragraph">Les E/S MySQL sont classées en deux types :</block>
  <block id="e8a320970c929abda9ae744b0b9e8f5f" category="list-text">E/S de fichiers aléatoires</block>
  <block id="85430c0aa096ec282f2a14156baa312e" category="list-text">E/S séquentielles de fichiers</block>
  <block id="b7b9a4c6983139a2673988826094a3cf" category="paragraph">Les fichiers de données sont lus et écrasés de manière aléatoire, ce qui entraîne un nombre élevé d'IOPS. Un stockage SSD est donc recommandé.</block>
  <block id="322f79fd77365edecd173807cb429ca2" category="paragraph">Les fichiers redo log et les fichiers log binaires sont des journaux transactionnels. Ils sont écrits de manière séquentielle, ce qui vous permet d'obtenir de bonnes performances sur le disque dur avec le cache d'écriture. Une lecture séquentielle a lieu lors de la restauration, mais cela provoque rarement un problème de performance, car la taille du fichier journal est généralement inférieure à celle des fichiers de données et les lectures séquentielles sont plus rapides que les lectures aléatoires (se produisant sur les fichiers de données).</block>
  <block id="a898d206a27508975fea2e241af2f04e" category="paragraph">La mémoire tampon en double écriture est une fonction spéciale d'InnoDB. InnoDB écrit d'abord les pages vidées dans le tampon de double écriture, puis écrit les pages à leur position correcte sur les fichiers de données. Ce processus empêche la corruption de la page. Sans le tampon de double écriture, la page peut être corrompue si une panne de courant se produit pendant le processus d'écriture sur les lecteurs. L'écriture sur la mémoire tampon en double écriture étant séquentielle, elle est optimisée pour les disques durs. Les lectures séquentielles ont lieu lors de la restauration.</block>
  <block id="363512900e45bc17bdd6edfa50582862" category="paragraph">Comme la mémoire NVRAM ONTAP fournit déjà une protection en écriture, la mise en mémoire tampon en double écriture n'est pas nécessaire. MySQL a un paramètre,<block ref="02d3c518a4019ea00e34e16491d826b4" prefix=" " category="inline-code"></block>, pour désactiver le tampon de double écriture. Cette fonction peut améliorer considérablement les performances.</block>
  <block id="49a7df723922bddb4df4002b51087a1c" category="paragraph">Le tampon d'insertion est également une fonction spéciale d'InnoDB. Si des blocs d'index secondaires non uniques ne sont pas en mémoire, InnoDB insère des entrées dans le tampon d'insertion pour éviter les opérations d'E/S aléatoires. Périodiquement, le tampon d'insertion est fusionné dans les arborescences d'index secondaires de la base de données. La mémoire tampon d'insertion réduit le nombre d'opérations d'E/S en fusionnant les demandes d'E/S vers le même bloc ; les opérations d'E/S aléatoires peuvent être séquentielles. Le tampon d'insertion est également hautement optimisé pour les disques durs. Les écritures et les lectures séquentielles ont lieu pendant les opérations normales.</block>
  <block id="6a0190340f27f29279bbfd319800289d" category="paragraph">Les segments d'annulation sont orientés E/S aléatoires. Pour garantir la simultanéité multiversion (MVCC), InnoDB doit enregistrer les anciennes images dans les segments d'annulation. La lecture des images précédentes à partir des segments d'annulation nécessite des lectures aléatoires. Si vous exécutez une longue transaction avec des lectures reproductibles (comme mysqldump—single transaction) ou exécutez une longue requête, les lectures aléatoires peuvent se produire. Par conséquent, le stockage des segments d'annulation sur des disques SSD est préférable dans ce cas. Si vous exécutez uniquement des transactions ou des requêtes courtes, les lectures aléatoires ne sont pas un problème.</block>
  <block id="a27e0d4b650aa6db30fdd95b54c94b27" category="paragraph">*NetApp recommande* la disposition de conception de stockage suivante en raison des caractéristiques d'E/S InnoDB.</block>
  <block id="defc1bfda928f419df5e4af79c98343e" category="list-text">Un volume pour stocker des fichiers MySQL orientés E/S aléatoires et séquentielles</block>
  <block id="7fd750411093ebd1faa0d99dd2608514" category="list-text">Un autre volume pour stocker des fichiers MySQL orientés E/S purement séquentiels</block>
  <block id="0561a3b014eef0e5125fa63e1626cf57" category="paragraph">Cette disposition vous aide également à concevoir des stratégies et des règles de protection des données.</block>
  <block id="9166d970028a28a614af39e6286371b7" category="paragraph">Vous pouvez désactiver ce paramètre avec<block ref="8cafbd8d9096941261e87f4f9152ab92" prefix=" " category="inline-code"></block> pour les bancs d'essai ou lorsque vous êtes davantage préoccupé par les performances que par l'intégrité des données ou par les défaillances possibles. InnoDB utilise une technique de vidage de fichier appelée double écriture. Avant d'écrire des pages dans les fichiers de données, InnoDB les écrit dans une zone contiguë appelée tampon de double écriture. Une fois l'écriture et le vidage de la mémoire tampon en double écriture terminés, InnoDB écrit les pages dans leur position correcte dans le fichier de données. Si le système d'exploitation ou un processus mysqld se bloque lors d'une écriture de page, InnoDB peut plus tard trouver une bonne copie de la page à partir du tampon de double écriture pendant la récupération après panne.</block>
  <block id="3dfd4b9a526f8a8cf17021e34638b375" category="admonition">*NetApp recommande* de désactiver le tampon en double écriture. La mémoire NVRAM de ONTAP remplit la même fonction. La double mise en mémoire tampon endommagera inutilement les performances.</block>
  <block id="0e5e83102103fcdd25af430bf7327034" category="paragraph">La documentation MySQL recommande d'utiliser NFSv4 pour les déploiements NAS.</block>
  <block id="ca0d9fdc80b88e73b548638af421788f" category="section-title">Tailles de transfert NFS ONTAP</block>
  <block id="efcd0ba3fcbee9896a25804677e70b4b" category="paragraph">Par défaut, ONTAP limite les tailles d'E/S NFS à 64 Ko. Les E/S aléatoires avec une base de données MySQL utilisent une taille de bloc bien inférieure à la taille maximale de 64 Ko. Les E/S de bloc volumineux sont généralement parallélisées de sorte que le maximum de 64 000 ne constitue pas non plus une limitation.</block>
  <block id="4655f686de75b23f16d530ed7351c447" category="paragraph">Dans certains cas, le maximum de 64 000 charges de travail entraîne une limitation. En particulier, les opérations à thread unique, telles que les opérations de sauvegarde d'analyse de table complète, s'exécuteront plus rapidement et plus efficacement si la base de données peut exécuter moins d'E/S, mais de plus grande taille. La taille optimale de gestion des E/S pour ONTAP avec charges de travail de base de données est de 256 Ko. Les options de montage NFS répertoriées pour les systèmes d'exploitation spécifiques ci-dessous ont été mises à jour de 64 Ko à 256 Ko en conséquence.</block>
  <block id="3ab93db30f3dded2c8d71859afbb53f6" category="admonition">Ne diminuez jamais la taille de transfert maximale autorisée sur ONTAP en dessous de la valeur de rsize/wsize des systèmes de fichiers NFS actuellement montés. Cela peut provoquer des blocages ou même une corruption des données avec certains systèmes d'exploitation. Par exemple, si les clients NFS sont actuellement définis sur une taille rsize/wsize de 65536, la taille maximale du transfert ONTAP peut être ajustée entre 65536 et 1048576 sans effet car les clients eux-mêmes sont limités. Réduire la taille de transfert maximale en dessous de 65536 peut endommager la disponibilité ou les données.</block>
  <block id="5ea0bb5d4dab46d7971fef94ccde9369" category="paragraph">*NetApp recommande*</block>
  <block id="09c6aa928c90ba68a4e03deadfeaa644" category="paragraph">Définition du paramètre NFSv4 fstab (/etc/fstab) suivant :</block>
  <block id="0ae3c9648bc2d8c33fa57415604da370" category="paragraph"><block ref="a63a3dc825ff52908de7c9dfcb29ffa5" prefix="" category="inline-code"></block></block>
  <block id="3e0b2c100b093560f63ad57c6849bc8a" category="admonition">NFSv3 présentait fréquemment un problème de verrouillage des fichiers journaux InnoDB après une panne de courant. L'utilisation du temps ou la commutation des fichiers journaux a résolu ce problème. Cependant, NFSv4 dispose d'opérations de verrouillage et assure le suivi des fichiers ouverts et des délégations.</block>
  <block id="62e4eb800d20b46085ccb975da78bafe" category="sidebar">ONTAP constitue le socle de la gestion et de la protection des données pour de nombreuses applications d'entreprise et technologies de base de données. Les pages suivantes fournissent des conseils sur les meilleures pratiques et les procédures d'implémentation pour l'infrastructure et les applications ONTAP et d'entreprise.</block>
  <block id="78898e52fcbdc5337204a384f2456d4f" category="sidebar">Microsoft SQL Server</block>
  <block id="4f60acc41a8bf3fa75e7f74768637787" category="sidebar">Protection des données Microsoft SQL Server</block>
  <block id="b8529ff730dcf8dd2178d72de271dc4d" category="sidebar">Bases de données open source</block>
  <block id="bb9a5a6fadabab849d2e87f0898d7601" category="sidebar">MariaDB et MySQL sur ONTAP</block>
  <block id="5ad2a11eceac3ebd7cbf3b534ebdb1db" category="sidebar">PostgreSQL sur ONTAP</block>
  <block id="c30dd1a85cf86d95b11c1a08f70130ce" category="sidebar">Base de données Oracle</block>
  <block id="4948dede9f4e7c3dfe48c38f7902f6e5" category="sidebar">Oracle sur ONTAP</block>
  <block id="d71074394b511143c8d1108e74a81abb" category="sidebar">Protection des données Oracle</block>
  <block id="f4d8825927d11df25770df5e00d6a52e" category="sidebar">Migration Oracle</block>
  <block id="86083f3ea21c2385b4f013aae3c57858" category="sidebar">SAP HANA</block>
  <block id="677f2e7e550075f7bbbdac91e0918f2f" category="sidebar">Solutions SAP</block>
  <block id="1b83f2b1c0b7fb3af048c2a59624fe3b" category="sidebar">SAP HANA avec AFF et FC</block>
  <block id="6ab3c3f05076d213f0b1feff267607c6" category="sidebar">SAP HANA avec AFF et NFS</block>
  <block id="56079badd056a19303cc26e6a4fcc7e0" category="sidebar">VMware</block>
  <block id="f07084a11252c9bca97503ea9a627c89" category="sidebar">Volumes virtuels (vVols) avec ONTAP</block>
  <block id="2d90ac09cbf108bddad31dd341f8614e" category="sidebar">VMware site Recovery Manager et ONTAP</block>
  <block id="b0dae11b82e63781abdc8f893c41b3c0" category="sidebar">Les applications d'entreprise</block>
  <block id="999bc6b18351bbe817d26f559ba408ae" category="sidebar">SAP</block>
  <block id="2d2eef88dbdd0c34bde24e2632d9944f" category="sidebar">SAP HANA et AnyDB</block>
  <block id="399bd1ee587245ecac6f39beaa99886f" category="sidebar">PostgreSQL</block>
  <block id="f4f70727dc34561dfde1a3c529b6205c" category="sidebar">Paramètres</block>
  <block id="7d219314ccabde6609510141bb175a6c" category="sidebar">Instance partagée ou instance dédiée</block>
  <block id="d5363ae19ecaede49e2ced297df7737a" category="sidebar">Configuration de la mémoire</block>
  <block id="500c09aa1bb9af431f2c18348e69bfd0" category="sidebar">Fichiers tempdb</block>
  <block id="4c5d94eb4dc4bff93f6a96a08ab7b244" category="sidebar">Sécurité des données</block>
  <block id="cf91513c6fc63cebe4b63a6647238d6d" category="sidebar">RAID</block>
  <block id="83db97189c47f7bb4edd879e8756f6e6" category="sidebar">Limites de capacité</block>
  <block id="af81930661b267e8f1e68c4d66e9ee56" category="sidebar">Basculement et basculement</block>
  <block id="dfd1f50170457b961c15bb13ad7e3bed" category="sidebar">Tailles des fichiers de données et des blocs de reprise</block>
  <block id="49f83bf3a15b8626eb91fde93c6b1788" category="sidebar">RAC Oracle</block>
  <block id="13d80777c8fd43e555c1f5b1b72d7ef0" category="sidebar">Configuration de l'hôte</block>
  <block id="7e6bb0931a72759d39514aa924b420bc" category="sidebar">AIX</block>
  <block id="6bb83af717367dd4a47f75801ae7a2b0" category="sidebar">Linux avec ASMlib et AFD</block>
  <block id="619615da0f93507e22a6054ef2aea4f1" category="sidebar">Interfaces logiques</block>
  <block id="aca8e861c6f30fe2d42d0310a387312b" category="sidebar">Configuration Ethernet</block>
  <block id="63a5b8bd41978e8124f9ccdfa9063e9e" category="sidebar">Configuration FC SAN</block>
  <block id="c3f378ef942f6bf228a43aaacc628fea" category="sidebar">Marquage LVM</block>
  <block id="254f642527b45bc260048e30704edb39" category="sidebar">Configuration</block>
  <block id="f3a78e25ce9f95fc3c61ccc39f32fb4d" category="sidebar">Oracle Direct NFS (dNFS)</block>
  <block id="989cefa74de0e10a575103f446258d99" category="sidebar">Locations et verrouillages NFS</block>
  <block id="0d695ec265a3b0b5e7e32e33ffe4ed22" category="sidebar">Mise en cache NFS</block>
  <block id="eb4d10d6eda7c9266cd36c4eb0a223cf" category="sidebar">Utilitaire de récupération ASM</block>
  <block id="297e2ac2ec0bd88ad598062f4c07ee45" category="sidebar">Règles de hiérarchisation</block>
  <block id="9af6f452cd88c83f2bde555de8f93690" category="sidebar">Envoi de données à un magasin d'objets</block>
  <block id="08af6d4e6b562e2d0b418d7198f5a0f7" category="sidebar">Récupération des données dans le magasin d'objets</block>
  <block id="02d01636975b3ae0c0ab22368cea8d54" category="sidebar">Stratégies de Tiering</block>
  <block id="7fbd108e1fc6910c941094e95a677878" category="sidebar">Fichiers entiers</block>
  <block id="eb43c2427eb06b9f561363863b4a4f0b" category="sidebar">Fichiers partiels</block>
  <block id="1afe200fa26ba361f59b603b22ad6392" category="sidebar">Sélectionnez fichiers</block>
  <block id="448d15345bb99c834095da225c529b8a" category="sidebar">Disponibilité des données</block>
  <block id="5869e10a9dea6d88d61bb10040557f35" category="sidebar">Intégrité des données</block>
  <block id="7b68149402c05a52968bda6af0435c8a" category="sidebar">Sauvegardes en ligne basées sur des snapshots</block>
  <block id="49ba0ee205d016d8236db9c1e8c130e5" category="sidebar">Sauvegardes optimisées pour les snapshots de stockage</block>
  <block id="2c6d98297c340e390e0783220b038545" category="sidebar">Architecture physique</block>
  <block id="13a854bdd11f8f57a0b25c00631f1430" category="sidebar">Architecture logique</block>
  <block id="5e7988aeba0e1d3c15c5c78a0db738d1" category="sidebar">SyncMirror</block>
  <block id="5ba8ee2f32815884475d1f2244ba16a6" category="sidebar">Scénarios d'échec</block>
  <block id="e31593850dc03f8f10d036df5dc8633b" category="sidebar">Migration de la base de données Oracle</block>
  <block id="5102abd5a9cc202678054b832caf678d" category="sidebar">Procédures</block>
  <block id="1495d3ed3ebff783c0f480b583372450" category="sidebar">Copie des données de l'hôte</block>
  <block id="d81ca5686c955ed50927409eb8c14bb0" category="sidebar">Importation de LUN étrangères</block>
  <block id="2fea59b7e470acac5ec1589d504da14e" category="sidebar">Achèvement</block>
  <block id="e9cc85ef98d982c3c3e53d6b82293126" category="sidebar">Conversion de protocoles</block>
  <block id="fbbd0e8905df3950eca4d1d8f55881ad" category="sidebar">Remarques supplémentaires</block>
  <block id="ac0465a970688dc3c326dcdd8fe2805e" category="sidebar">Optimisation des performances et analyse comparative</block>
  <block id="7cb9c3cd8b9873d39a1fe87c083cd55c" category="sidebar">Verrous NFS obsolètes</block>
  <block id="c0916addb4f26afa58c5a6df4f463fa5" category="sidebar">Le stockage unifié</block>
  <block id="c0032c6bab44eeeb6886c7a4aa67cf77" category="sidebar">Outils de virtualisation</block>
  <block id="1c77ac70000b6804e930748d5df7be5e" category="sidebar">Gestion basée sur des règles de stockage et des volumes virtuels</block>
  <block id="217601d383b816e6a2548e57b5006f92" category="sidebar">Clonage</block>
  <block id="8f2db90dd4a6fbd95ba8f0bc54fd6b27" category="sidebar">La QoS</block>
  <block id="09b4a81ec7b05cbacc7cbfa13e006254" category="sidebar">Gestion basée sur des règles de stockage</block>
  <block id="2e8526cbe762cb1b8393d935a3b0bf16" category="sidebar">Paramètres recommandés</block>
  <block id="10a764f91b59ce3c8931d55c2fd54222" category="sidebar">Déploiement du stockage vVols</block>
  <block id="30f6724a02fc69093960468c0a2fbcd4" category="sidebar">Sécurité des produits</block>
  <block id="3390e3575b3e341afa2b7172ff5b33a7" category="sidebar">Plug-in SnapCenter pour VMware vSphere</block>
  <block id="62a004b95946bb97541afa471dcca73a" category="sidebar">MySQL</block>
  <block id="7f1a6761f7160e33a32105202e47303b" category="sidebar">Conteneurisation</block>
  <block id="bd57f4f74ca087a92a48b23d45753729" category="paragraph">Le fournisseur VASA des outils ONTAP se charge de la gestion des igroups FCP et iSCSI ainsi que des sous-systèmes NVMe dans ONTAP en fonction des initiateurs détectés d'hôtes ESXi gérés. Toutefois, il ne s'intègre pas aux commutateurs Fibre Channel pour gérer la segmentation. La segmentation doit être effectuée conformément aux meilleures pratiques avant tout provisionnement. Voici un exemple de segmentation à un seul initiateur sur quatre systèmes ONTAP :</block>
  <block id="6b14e3f4a37881185acf7a766f8f6272" category="paragraph">Segmentation à un seul initiateur :</block>
  <block id="17ccf64e30cb518fd7ca87ce752ad738" category="paragraph"><block ref="17ccf64e30cb518fd7ca87ce752ad738" category="inline-image-macro-rx" type="image"></block></block>
  <block id="58b5cd2a94730c2e044c14891f1e0e87" category="paragraph">Pour plus d'informations sur les meilleures pratiques, reportez-vous aux documents suivants :</block>
  <block id="fc9e4d789d968936f8ff5ae5a99847e0" category="paragraph"><block ref="fc9e4d789d968936f8ff5ae5a99847e0" category="inline-link-rx"></block></block>
  <block id="d748a2834a7220eef4ec4775a51632f9" category="paragraph"><block ref="d748a2834a7220eef4ec4775a51632f9" category="inline-link-rx"></block></block>
  <block id="80dad10df0d1a031764e7c648c46aa23" category="paragraph">*Pensez à utiliser Max IOPS pour contrôler des machines virtuelles inconnues ou tester des machines virtuelles.*</block>
  <block id="93e4f73afe8b787b33161ec273ca087f" category="paragraph">Disponible pour la première fois dans VASA Provider 7.1, Max IOPS peut être utilisé pour limiter les IOPS à un vVol spécifique pour une charge de travail inconnue afin d'éviter tout impact sur d'autres charges de travail plus stratégiques. Pour plus d'informations sur la gestion des performances, consultez le Tableau 4.</block>
  <block id="4e0d7e0587bf99c9b7a64a84fd42f6bd" category="paragraph">Reportez-vous aux autres guides des meilleures pratiques de NetApp et VMware spécifiques au protocole sélectionné. En général, il n'y a pas d'autres changements que ceux déjà mentionnés.</block>
  <block id="97f87e9ab1d660463c63beb8745fd9e5" category="paragraph">*Exemple de configuration réseau utilisant vVols sur NFS v3*</block>
  <block id="c80b3cc8b5013bd4039769fb0f783e60" category="paragraph"><block ref="c80b3cc8b5013bd4039769fb0f783e60" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dee28dd6d1a9ef7bf399f642fd9d588f" category="section-title">Tailles de transfert NFS</block>
  <block id="d8299d00f914e35b80644e5781e47a77" category="paragraph"><block ref="d8299d00f914e35b80644e5781e47a77" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5a656ddcc72bacc3a5900c23edf7a08e" category="paragraph"><block ref="5a656ddcc72bacc3a5900c23edf7a08e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="073ce0a0568adc64d52dd9b1d8c02c54" category="paragraph"><block ref="073ce0a0568adc64d52dd9b1d8c02c54" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3401a9880dfc322da8a56c4d632361f6" category="paragraph"><block ref="3401a9880dfc322da8a56c4d632361f6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="87f823f4f3b4258445d5af029afe5ad9" category="paragraph"><block ref="87f823f4f3b4258445d5af029afe5ad9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9213fe9d391179276ff6c03552486255" category="paragraph"><block ref="9213fe9d391179276ff6c03552486255" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3105b4c0642b9710179c18edcf8e8718" category="paragraph"><block ref="3105b4c0642b9710179c18edcf8e8718" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1a43000eb9893bff7ab7b1ce1d3fd6a8" category="paragraph"><block ref="1a43000eb9893bff7ab7b1ce1d3fd6a8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4b7a8562c98b8c652bdfb6aa79788222" category="paragraph"><block ref="4b7a8562c98b8c652bdfb6aa79788222" category="inline-image-macro-rx" type="image"></block></block>
  <block id="acce752526553bfa73c92799accd9cb8" category="summary">Présentation de la protection des données Oracle</block>
  <block id="deb8cb7644231cae002f5f37c725b86f" category="paragraph">La migration sur de longues distances nécessite généralement une approche plus créative, comme le processus d'expédition des journaux expliqué dans <block ref="86efe12ea0d3a769a4b7cfc2b6362f49" category="inline-link-macro-rx"></block>. Les réseaux IP longue distance disposent rarement d'une bande passante proche des vitesses LAN ou SAN. Dans un cas, NetApp a participé à la migration à distance d'une base de données de 220 To avec des taux de génération de journaux d'archivage très élevés. L'approche choisie pour le transfert de données a été l'expédition quotidienne de bandes, parce que cette méthode offrait la bande passante maximale possible.</block>
  <block id="055362c7082175c34483772a43b776cf" category="paragraph">Par exemple, la copie d'une base de données de 10 To prend généralement environ sept heures. Si l'entreprise a besoin d'une interruption de service de sept heures, la copie de fichiers est une option simple et sûre pour la migration. Si cinq heures sont inacceptables, un simple processus d'envoi de journaux (voir <block ref="eee8a7589b6555fc3411165c58a62ca5" category="inline-link-macro-rx"></block>) peut être configuré en déployant un minimum d'efforts afin de réduire le délai de mise en service à environ 15 minutes. Pendant ce temps, un administrateur de base de données peut terminer le processus. Si 15 ce n'est pas le cas, le processus de mise en service final peut être automatisé par script afin de réduire le délai de mise en service à quelques minutes seulement. Vous pouvez toujours accélérer une migration, mais cette opération a un coût en temps et en efforts. Les délais de mise en service doivent être déterminés en fonction des objectifs acceptables pour l'entreprise.</block>
  <block id="911e63244fc82405263306a64e535c69" category="paragraph">Un zpool ne doit être créé qu'après les étapes de la <block ref="e8673fdb712a2edcdf56742c7eec0045" category="inline-link-macro-rx"></block> sont effectuées. Si la procédure n'est pas effectuée correctement, les performances risquent d'être sérieusement dégradées en raison de l'alignement des E/S. Pour des performances optimales sur ONTAP, les E/S doivent être alignées sur une limite de 4 Ko sur un disque. Les systèmes de fichiers créés sur un zpool utilisent une taille de bloc effective qui est contrôlée par un paramètre appelé<block ref="81df978a8e3da4bee74b135548f390f3" prefix=" " category="inline-code"></block>, qui peut être affiché en exécutant la commande<block ref="1615297782a0dff59b20451e2ca97ea7" prefix=" " category="inline-code"></block>.</block>
  <block id="b2ca9da17ac7a0807fb313343c1ba9cb" category="list-text">La partition a été créée avec un décalage de 33 secteurs au lieu du décalage de 32 par défaut. Répétez la procédure décrite à la section <block ref="6ba0f94fdd8f9504e3fef5712023fb85" category="inline-link-macro-rx"></block>. L'histogramme s'affiche comme suit :</block>
  <block id="eb7f9a88026c895932f70c650c364132" category="list-text">Augmentez la taille des LUN</block>
  <block id="0f11c45e6e7377b9d10a93534d0fa2f3" category="list-text">Ajoutez une LUN à un groupe de volumes existant et développez le volume logique contenu</block>
  <block id="e4da750cce448393b2597f8f66086894" category="paragraph">Un groupe initiateur (igroup) fait partie de l'architecture de masquage des LUN ONTAP. L'accès à une LUN nouvellement créée n'est pas accessible à moins qu'un hôte ne bénéficie au préalable d'un accès. Pour ce faire, vous devez créer un groupe initiateur qui répertorie les WWN FC ou les noms d'initiateurs iSCSI auxquels l'accès doit être accordé. Au moment de la rédaction de ce rapport, FLI était pris en charge uniquement pour les LUN FC. Cependant, la conversion en iSCSI après migration est une tâche simple, comme illustré dans la <block ref="43085dc2a05784d4912331d1ed1db91d" category="inline-link-macro-rx"></block>.</block>
  <block id="525e71fb331412cd820122c3d51d453c" category="paragraph">Cela permet aux administrateurs de bases de données de récupérer de l'espace sur la baie de stockage après la suppression des données. ONTAP intercepte les zéros et désalloue l'espace de la LUN. Le processus de récupération est extrêmement rapide, car aucune donnée n'est écrite dans le système de stockage.</block>
  <block id="be17af715060572d2df93d7ffe4ce6dd" category="paragraph">Les systèmes de stockage ONTAP offrent une grande flexibilité de création de datastores pour les machines virtuelles et les disques virtuels. Bien que la plupart des meilleures pratiques relatives à ONTAP soient appliquées lors du provisionnement de datastores pour vSphere (voir la section dans cette section) <block ref="2e24324ebf41be836715e1e0dd648f4f" category="inline-link-macro-rx"></block>), voici quelques lignes directrices supplémentaires à prendre en compte :</block>
  <block id="141c3dc68be34b8f11c2a120b36a1eb8" category="list-text">Dans certains cas, vous n'aurez même pas besoin d'un datastore. Pour obtenir des performances et une gestion optimales, évitez d'utiliser un datastore pour des applications d'E/S élevées telles que les bases de données et certaines applications. Prenez plutôt en compte les systèmes de fichiers invités, tels que les systèmes de fichiers NFS ou iSCSI, gérés par l'invité ou par RDM. Pour une assistance spécifique aux applications, consultez les rapports techniques de NetApp pour votre application. Par exemple : <block ref="cfa0393f870bc70fd8973ae18376facc" category="inline-link-macro-rx"></block> dispose d'une section sur la virtualisation avec des détails utiles.</block>
  <block id="14bdf3569ec0024259b2b02c5a668eae" category="paragraph">Quand<block ref="7ccc31934ae8244d8263d3c09bcee186" prefix=" " category="inline-code"></block> Est activé (valeur par défaut), InnoDB stocke toutes les données deux fois : d'abord dans le tampon de double écriture, puis dans les fichiers de données réels.</block>
  <block id="394ad91b4701dbd32675896bed204755" category="sidebar">Configuration de l'hôte pour PostgreSQL</block>
  <block id="9852487272d9b2aa9026d0fddc0616fc" category="sidebar">Configuration du stockage pour PostgreSQL</block>
  <block id="bc237072428e0e4c415160b898946d4c" category="sidebar">Protection des données pour PostgreSQL</block>
  <block id="3423582eed75b4bd6632c18238fd78e4" category="sidebar">Configuration de la base de données pour Microsoft SQL Server</block>
  <block id="6e97cf67ec5979ab5828852639efa208" category="sidebar">Configuration du stockage pour Microsoft SQL Server</block>
  <block id="5a4517368fb2ab5498fc2108c2ea64c5" category="sidebar">Configuration de la base de données pour Oracle Database</block>
  <block id="e483c0ecf3a2b1a60f886d4a5ac553ff" category="sidebar">Configuration de l'hôte pour Oracle Database</block>
  <block id="06b078afa802a679ad4694d13a8a2495" category="sidebar">Configuration réseau pour Oracle Database</block>
  <block id="f1991b28c5d48cb53798755acf9dfe62" category="sidebar">Configuration du stockage pour Oracle Database</block>
  <block id="ea9cdfcbfcf1906c15b6779f0f327028" category="sidebar">Configuration de base de données pour MySQL</block>
  <block id="308f8f580d0248ac023557cfd4b10d83" category="sidebar">Configuration de l'hôte pour MySQL</block>
  <block id="830f353b3e6055499fac447b16b0c935" category="sidebar">Configuration du stockage pour MySQL</block>
  <block id="3106f8f17f2974fe05da16fb0cc50505" category="summary">Bases de données PostgreSQL avec SAN sur ONTAP</block>
  <block id="74cacb0c34a37e2859e3b054938a344d" category="doc">PostgreSQL avec systèmes de fichiers SAN</block>
  <block id="1758f5c81d60f1a0ac8600fddc99a919" category="paragraph">Les bases de données PostgreSQL avec SAN sont généralement hébergées sur des systèmes de fichiers xfs, mais d'autres peuvent être utilisées si elles sont prises en charge par le fournisseur du système d'exploitation</block>
  <block id="d73e7b56b7baa813a32c521ca074e7c4" category="paragraph">Même si un seul LUN peut généralement prendre en charge jusqu'à 100 000 IOPS, les bases de données exigeantes en E/S nécessitent généralement l'utilisation de LVM avec répartition.</block>
  <block id="f7cc8c4234952826818ad4d0c2050ac9" category="paragraph">Les bases de données PostgreSQL peuvent être hébergées sur les systèmes de fichiers NFSv3 ou NFSv4. La meilleure option dépend de facteurs extérieurs à la base de données.</block>
  <block id="1482c42acc1dd31ee8496c71a805e73c" category="paragraph">Par exemple, le comportement de verrouillage NFSv4 peut être préférable dans certains environnements en cluster. (Voir <block ref="bc3a7e667477b8b3590fa1451dcb924c" category="inline-link-macro-rx"></block> pour plus d'informations)</block>
  <block id="9674525687765646f35916d0e569eda9" category="paragraph">Dans le cas contraire, les fonctionnalités de la base de données doivent être proches des mêmes, y compris les performances. La seule exigence est l'utilisation du<block ref="d64a84456adc959f56de6af685d0dadd" prefix=" " category="inline-code"></block> option de montage. Ceci est nécessaire pour garantir que les délais d'expiration ne produisent pas d'erreurs d'E/S irrécupérables.</block>
  <block id="0c6430fad6c643c444b5d6d52b18edb4" category="paragraph">Si NFSv4 est choisi en tant que protocole, NetApp recommande d'utiliser NFSv4.1. Certaines améliorations fonctionnelles du protocole NFSv4 dans NFSv4.1 améliorent la résilience sur NFSv4.0.</block>
  <block id="248212b04c23627e2719e106224d2eb3" category="paragraph">Utilisez les options de montage suivantes pour les charges de travail de base de données générales :</block>
  <block id="9efbdff43e91279291e95690414bec95" category="paragraph">Une fois la taille de transfert augmentée au niveau ONTAP, les options de montage suivantes sont utilisées :</block>
  <block id="395201f6a339cc4cf6b345e0c259f383" category="section-title">Tables d'emplacements TCP NFSv3</block>
  <block id="1f8260aa2c5a5b35bf771c26828d2096" category="paragraph">Si NFSv3 est utilisé avec Linux, il est essentiel de définir correctement les tables d'emplacements TCP.</block>
  <block id="92d0a1aef2134a70d5c0f0279dc22ec6" category="doc">Copies Snapshot</block>
  <block id="0c47b4eb567b018e3d2e5882b88eaca9" category="paragraph">Les snapshots de stockage sont des répliques instantanées des données cible. La mise en œuvre d'ONTAP permet de définir diverses règles et de stocker jusqu'à 1024 copies Snapshot par volume. Les copies Snapshot dans ONTAP sont compactes. L'espace est uniquement utilisé lorsque le dataset d'origine change. Ils sont également en lecture seule. Un snapshot peut être supprimé, mais il ne peut pas être modifié.</block>
  <block id="7986a4827296ca9cd0b991ded9f8a10d" category="paragraph">Dans certains cas, les snapshots peuvent être programmés directement sur ONTAP. Dans d'autres cas, des logiciels tels que SnapCenter peuvent être requis pour orchestrer les opérations d'application ou de système d'exploitation avant de créer des snapshots. Quelle que soit l'approche la plus adaptée à votre charge de travail, une stratégie Snapshot agressive peut assurer la sécurité des données grâce à un accès facile et fréquent aux sauvegardes de tous les éléments, des LUN de démarrage aux bases de données stratégiques.</block>
  <block id="c4bf0f56feeec9a45e973768fbc4f47e" category="section-title">Des snapshots inviolables</block>
  <block id="38fef959179f8d3eb79a68a5ce747bdc" category="paragraph">Cela permet de s'assurer qu'un intrus, un collaborateur malveillant ou même une attaque par ransomware ne peut pas compromettre les sauvegardes, même s'il a pu accéder au système ONTAP lui-même. Associée à une planification Snapshot fréquente, cette solution offre une protection des données extrêmement puissante avec un RPO très faible.</block>
  <block id="a1f41e52e9ddbd9f87ecd032c237b1c0" category="section-title">Réplication SnapMirror</block>
  <block id="18d315ae923785b3f9c5234724b0ab42" category="paragraph">Un deuxième système ouvre également de nouvelles options pour la sécurité administrative. Par exemple, certains clients NetApp isolent les informations d'authentification pour les systèmes de stockage primaire et secondaire. Aucun utilisateur administratif n'a accès aux deux systèmes, ce qui signifie qu'un administrateur malveillant ne peut pas supprimer toutes les copies des données.</block>
  <block id="500569e3cc0764260a592cb176921ca3" category="section-title">Ordinateurs virtuels de stockage</block>
  <block id="597cb258dd509add7cd999794c60d430" category="paragraph">Par exemple, vous pouvez configurer un SVM pour les charges de travail de production stratégiques et un second SVM sur un autre segment réseau pour les activités de développement. Vous pouvez alors restreindre l'accès au SVM de production à certains administrateurs, tout en accordant aux développeurs un contrôle plus étendu sur les ressources de stockage du SVM de développement. Vous devrez peut-être également proposer un troisième SVM à vos équipes financières et RH afin de stocker des données sensibles uniquement.</block>
  <block id="7d0fc71fe28e011ca49b06214469d484" category="section-title">RBAC d'administration</block>
  <block id="4f0dae2ba2fd11c533349d6ade4f81de" category="paragraph">ONTAP offre un puissant contrôle d'accès basé sur des rôles (RBAC) pour les connexions d'administration. Certains administrateurs peuvent avoir besoin d'un accès complet au cluster, tandis que d'autres n'ont besoin que de l'accès à certains SVM. Le personnel du service d'assistance avancé peut avoir besoin d'augmenter la taille des volumes. Vous pouvez ainsi accorder aux utilisateurs administratifs l'accès requis pour s'acquitter de leurs responsabilités professionnelles, et rien de plus. De plus, vous pouvez sécuriser ces connexions à l'aide de PKI provenant de différents fournisseurs, restreindre l'accès aux clés ssh uniquement et appliquer les verrouillages de tentatives de connexion échouées.</block>
  <block id="852741d2a7fb0a8a1a5dd748dbbd6734" category="section-title">RBAC D'API</block>
  <block id="bbbea5fec67f15424fa77aa563754c49" category="paragraph">L'automatisation nécessite des appels d'API, mais tous les outils ne nécessitent pas un accès administratif complet. Pour sécuriser les systèmes d'automatisation, le RBAC est également disponible au niveau des API. Vous pouvez limiter les comptes d'utilisateur d'automatisation aux appels d'API requis. Par exemple, le logiciel de surveillance n'a pas besoin d'un accès de modification, il ne nécessite qu'un accès en lecture. Les flux de travail qui provisionnent le stockage n'ont pas besoin d'être supprimés.</block>
  <block id="7604bad489eaec7e27d112c63d3e2936" category="paragraph">L'authentification multifacteur peut être encore plus poussée en exigeant que deux administrateurs différents, chacun disposant de leurs propres informations d'identification, approuvent certaines activités. Cela inclut la modification des autorisations de connexion, l'exécution des commandes de diagnostic et la suppression des données.</block>
  <block id="b39c0496b44447232912303246b46aaa" category="paragraph">Si des E/S séquentielles lourdes sont attendues, la taille du transfert NFS peut être augmentée comme décrit dans la section suivante.</block>
  <block id="959e8f746f4ff03f6225b95cf646e65f" category="admonition">Cette documentation remplace le rapport technique _TR-4590 : guide des meilleures pratiques pour Microsoft SQL Server avec ONTAP_</block>
  <block id="36d72286c0ef70108b2f7791b73fdc6d" category="list-text">Les guides précédents ont recommandé de créer la LIF pour la localisation des données. C'est-à-dire toujours monter un datastore à l'aide d'une LIF située sur le nœud qui détient physiquement le volume. Ce n'est plus une exigence dans les versions modernes de ONTAP 9. Dans la mesure du possible, et si des informations d'identification avec périmètre du cluster sont fournies, les outils ONTAP choisissent toujours d'équilibrer la charge entre les LIF locales aux données, mais il ne s'agit pas d'une exigence de haute disponibilité ou de performance.</block>
  <block id="aa131b86ebd9f719bab1aba612ae3c3f" category="list-text">SRM fonctionne mieux lorsque le nombre de datastores et donc les groupes de protection sont limités dans vos plans de reprise d'activité. Par conséquent, vous devez envisager d'optimiser la densité des machines virtuelles dans les environnements protégés par SRM où le RTO est essentiel.</block>
  <block id="afab42482b97a8b43c62320c373ded74" category="list-text">Utilisez Distributed Resource Scheduler (DRS) pour équilibrer la charge sur vos clusters ESXi protégés et de récupération. N'oubliez pas que si vous prévoyez de revenir en arrière, lorsque vous exécutez une reprotection, les clusters précédemment protégés deviennent les nouveaux clusters de récupération. Le DRS contribue à équilibrer le placement dans les deux sens.</block>
  <block id="8ed6c5d9143eeb92cf75bb8a08bb7819" category="list-text">Dans la mesure du possible, évitez d'utiliser la personnalisation IP avec SRM car cela peut augmenter votre RTO.</block>
  <block id="8baa3b91d59f004ee489f4f3fd3dd4e4" category="paragraph">À partir de SRM 8.3, la protection des machines virtuelles à l'aide des datastores vVols est prise en charge. Les planifications SnapMirror sont exposées aux règles de stockage de VM par le VASA Provider lorsque la réplication de vvols est activée dans le menu des paramètres des outils ONTAP, comme indiqué dans les captures d'écran suivantes.</block>
  <block id="3c1a2fd7a7a41ca20efeae84dc73ba0a" category="paragraph">L'exemple suivant montre l'activation de la réplication vVols.</block>
  <block id="fc7cd76ae57374916b5edd5a2dd19fee" category="paragraph">À la différence des précédents datastores vvols, les datastores vvols répliqués doivent être créés dès le début avec une réplication activée, et ils doivent utiliser des volumes pré-créés sur les systèmes ONTAP avec des relations SnapMirror. Cela nécessite de pré-configurer des éléments tels que le peering de cluster et de SVM. Ces activités doivent être réalisées par votre administrateur ONTAP, car elles permettent une séparation stricte des responsabilités entre ceux qui gèrent les systèmes ONTAP sur plusieurs sites et ceux qui sont principalement responsables des opérations vSphere.</block>
  <block id="e2e7245b1b3cf4a13a6b703ead49ebee" category="paragraph">Un gestionnaire de matrices est créé pour chaque paire de matrices. Avec les outils SRM et ONTAP, chaque association de baie s'effectue au sein d'un SVM, même si vous utilisez les identifiants du cluster. Vous pouvez ainsi segmenter les flux de travail de reprise après incident entre des locataires, en fonction des SVM qu'ils ont affectés à la gestion. Vous pouvez créer plusieurs gestionnaires de baies pour un cluster donné, qui peuvent être asymétriques. Vous pouvez « Fan-Out » ou « Fan-In » sur différents clusters ONTAP 9. Par exemple, il peut y avoir des SVM-A et SVM-B dans le Cluster-1 en cours de réplication vers SVM-C dans le Cluster-2, SVM-D dans le Cluster-3 ou vice-versa.</block>
  <block id="3233e61306af256f9de7fd3086bc08bf" category="paragraph">Il existe plusieurs facteurs à prendre en compte dans les groupes de réplication et dans la manière dont vous distribuez les machines virtuelles sur les volumes FlexVol. Le regroupement de machines virtuelles similaires dans un même volume peut améliorer l'efficacité du stockage avec les systèmes ONTAP plus anciens qui n'offrent pas de déduplication au niveau de l'agrégat. Cependant, ce regroupement augmente la taille du volume et réduit la simultanéité E/S du volume. Les systèmes ONTAP modernes offrent un équilibre parfait entre performance et efficacité du stockage en distribuant les machines virtuelles entre les volumes FlexVol au sein d'un même agrégat. La déduplication au niveau de l'agrégat améliore la parallélisation des E/S sur plusieurs volumes. Vous pouvez restaurer des VM dans les volumes simultanément, car un groupe de protection (voir ci-dessous) peut contenir plusieurs groupes de réplication. L'inconvénient de cette disposition est que les blocs peuvent être transmis plusieurs fois sur le réseau, car SnapMirror volume ne prend pas en compte la déduplication dans l'agrégat.</block>
  <block id="670ea4d89ef5c48c4f2d840baf48688c" category="paragraph">Par exemple, votre entreprise peut disposer d'une application stratégique de niveau 1 qui repose sur un serveur Microsoft SQL pour sa base de données. Vous décidez donc de placer vos machines virtuelles dans le groupe de priorité 1. Au sein du groupe de priorité 1, vous commencez à planifier la commande afin d'obtenir des services. Vous devez probablement démarrer votre contrôleur de domaine Microsoft Windows avant votre serveur Microsoft SQL, qui devra être en ligne avant votre serveur d'applications, etc. Vous devez ajouter toutes ces machines virtuelles au groupe de priorité, puis définir les dépendances, car elles ne s'appliquent qu'à un groupe de priorité donné.</block>
  <block id="512ee19e5020f3ee80a9e25f3f5a6468" category="paragraph">Il est recommandé de toujours effectuer un basculement de test dès que la configuration d'un stockage protégé d'ordinateurs virtuels modifie. Ainsi, en cas d'incident, vous avez l'assurance que site Recovery Manager peut restaurer les services au sein de la cible de délai de restauration prévue.</block>
  <block id="4da3f855cd505741909cfd49d743e68e" category="paragraph">SRM vous permet également de modifier la configuration réseau d'une machine virtuelle lors de sa restauration. Cette reconfiguration inclut des paramètres tels que les adresses IP, les adresses de passerelle et les paramètres du serveur DNS. Différents paramètres réseau, qui sont appliqués aux machines virtuelles individuelles au fur et à mesure qu'elles sont restaurées, peuvent être spécifiés dans les paramètres de propriété d'une machine virtuelle dans le plan de reprise.</block>
  <block id="e409450ce49f3558b068c69a77a9623a" category="paragraph">Après la restauration, vous devez confirmer auprès de toutes les parties prenantes que leurs services ont été renvoyés à la normale avant d'exécuter à nouveau reprotéger.</block>
  <block id="a42cf9beb4788dddb7d317e05cc08e23" category="sidebar">Fichiers de base de données et groupes de fichiers</block>
  <block id="8858bb6564a2efc189c9183c495ce545" category="sidebar">Alignement LUN</block>
  <block id="02bc4ad8a694d41c8b598dfbcb12f069" category="sidebar">Nombre de LUN et taille de LUN</block>
  <block id="066f208a93617bd82090d42624ce63cc" category="sidebar">Redimensionnement de la LUN</block>
  <block id="9eeba6fd02cf3b6d8aee35e0ce9bf8fe" category="sidebar">Répartition LVM</block>
  <block id="183bdb28f19bee640319f68825827aea" category="sidebar">RPO, RTO et SLA</block>
  <block id="2172b5d51273924b537842b0db78bfd4" category="sidebar">Notions de base sur la sauvegarde et la restauration</block>
  <block id="3403aac944f3cb6e2d2c7f7d52bc44b9" category="paragraph">Avec la croissance exponentielle des données, la gestion des données devient de plus en plus complexe pour les entreprises. Cette complexité augmente les coûts de licence, d'exploitation, de support et de maintenance. Pour réduire le coût total de possession, envisagez de passer de bases de données commerciales à des bases de données open source grâce à un stockage interne fiable et haute performance.</block>
  <block id="dcac08882e3396bd30210108baa1641d" category="paragraph">ONTAP est une plateforme idéale, car ONTAP est littéralement conçu pour les bases de données. De nombreuses fonctionnalités, telles que l'optimisation de la latence d'E/S aléatoire, pour la qualité de service (QoS) avancée et les fonctionnalités FlexClone de base, ont été spécialement conçues pour répondre aux besoins des charges de travail des bases de données.</block>
  <block id="1429a98a71e16287326edd7fc1f999fd" category="paragraph">Des fonctionnalités supplémentaires, telles que les mises à niveau sans interruption (y compris le remplacement du stockage), assurent la disponibilité de vos bases de données stratégiques. Vous pouvez également bénéficier d'une reprise après incident instantanée pour les environnements volumineux via MetroCluster ou sélectionner des bases de données à l'aide de la synchronisation active SnapMirror.</block>
  <block id="8df3fb35ff15e02683bfb1bc7f852c93" category="paragraph">Plus important encore, ONTAP offre des performances inégalées avec la possibilité de dimensionner la solution en fonction de vos besoins spécifiques. Nos systèmes haut de gamme peuvent fournir plus de 1 million d'IOPS à des latences mesurées en microsecondes. Toutefois, si vous n'avez besoin que de 100 000 IOPS, vous pouvez ajuster la taille de votre solution de stockage à l'aide d'un contrôleur plus petit, qui exécute toujours le même système d'exploitation du stockage.</block>
  <block id="97b4cda00dd31f5be69440f48c4da149" category="summary">Configuration de la base de données PostgreSQL avec ONTAP</block>
  <block id="c4f52498c0db572381512887d7584e53" category="summary">Bases de données PostgreSQL et snapshots de stockage</block>
  <block id="b0792163c858a7c221b236d84619b5ef" category="summary">PostgreSQL bases de données NFS avec ONTAP</block>
  <block id="189950ed46e5e8b7e92941531a5bb88b" category="doc">Bases de données PostgreSQL avec systèmes de fichiers NFS</block>
  <block id="6cabd4dcf3582d38c441228705da3bda" category="doc">Protection des données PostgreSQL</block>
  <block id="383a6a5241ecfc558b9fec1d7cff5239" category="summary">Tablespaces PostgreSQL</block>
  <block id="20d0e2519b3555a0a2927c8914c17280" category="summary">Logiciel de protection des données PostgreSQL</block>
  <block id="29e2aec511a8e307ecceacbd86c22f14" category="summary">Paramètres d'initialisation PostgreSQL</block>
  <block id="035ecd1be6cacde993302b440e396bc2" category="paragraph">La majorité des clients de base de données choisissent désormais des baies 100 % Flash, ce qui entraîne d'autres considérations. Prenons l'exemple des tests de performances sur un système AFF A900 à deux nœuds :</block>
  <block id="33f545d041b93838074263c0efd2e9da" category="list-text">Avec un ratio de lecture/écriture de 80/20, deux nœuds A900 peuvent fournir plus de 1 million d'IOPS de base de données aléatoires avant que la latence ne dépasse même le seuil de 150 µs. Au-delà des exigences de performance actuelles de la plupart des bases de données, il est difficile de prévoir l'amélioration attendue. Le stockage serait largement effacé comme un goulot d'étranglement.</block>
  <block id="0445195555faac96ebff962dbff126ea" category="summary">Paramètres de configuration MySQL</block>
  <block id="c0b7708ffcd66fd65a9d2a4801091563" category="paragraph">NetApp recommande quelques paramètres de configuration MySQL importants pour obtenir des performances optimales.</block>
  <block id="10eb8b7e75da1815860da31490513841" category="summary">MySQL avec NFS</block>
  <block id="5249e05857621fbfae51371a73006c44" category="summary">Tables d'emplacements MySQL et NFSv3</block>
  <block id="d058f95e3a8d4b7b46802139d6b95982" category="paragraph">Les performances de NFSv3 sous Linux dépendent d'un paramètre appelé<block ref="453f2cc2326f82af1053f4aa4b75400b" prefix=" " category="inline-code"></block>.</block>
  <block id="bf2bdc980948fb9084a63963398846b2" category="paragraph">ONTAP est une plate-forme idéale pour les bases de données MySQL car ONTAP est littéralement conçu pour les bases de données. De nombreuses fonctionnalités, telles que l'optimisation de la latence d'E/S aléatoire, pour la qualité de service (QoS) avancée et les fonctionnalités FlexClone de base, ont été spécialement conçues pour répondre aux besoins des charges de travail des bases de données.</block>
  <block id="1b3804b7e2292e18f5e66d54f7a9fafc" category="paragraph">Plus important encore, ONTAP offre des performances inégalées avec la possibilité de dimensionner la solution en fonction de vos besoins spécifiques. Nos systèmes haut de gamme peuvent fournir plus de 1 million d'IOPS à des latences mesurées en microsecondes. Toutefois, si vous n'avez besoin que de 100 000 IOPS, vous pouvez dimensionner correctement votre solution de stockage avec un contrôleur plus petit, qui exécute toujours le même système d'exploitation du stockage.</block>
  <block id="1339877637a3f7f59745a00e04f304fd" category="summary">MySQL et innodb_log_file_size</block>
  <block id="c1c4e722764621d56a075e42ce48d0c0" category="summary">MySQL et innodb_buffer_pool_size</block>
  <block id="ae14ab6d1e5edd0e782d8897d1721eb4" category="summary">MySQL et innodb_doublenitrite</block>
  <block id="689c52e3f5db5d2dafccd7d93cf1abc4" category="summary">MySQL et innodb_flush_log_at_trx_commi</block>
  <block id="639600080c225673dfdfa012fdbd6146" category="summary">Planificateurs MySQL et IO</block>
  <block id="72985ac51e91797345b2437088a4362e" category="summary">MySQL avec SAN</block>
  <block id="d5ef0a45fe252b03f538bfd134b168db" category="summary">MySQL et innodb_lru_scan_depth</block>
  <block id="df657260453f6ef228ee0ca22dd7a415" category="summary">Conteneurisation MySQL</block>
  <block id="2828450fc6669c8df75f937e227996f1" category="doc">Descripteurs de fichier MySQL</block>
  <block id="9420010a756fb6d3ddeadfa63d2170f6" category="paragraph">Pour s'exécuter, le serveur MySQL a besoin de descripteurs de fichier et les valeurs par défaut ne sont pas suffisantes.</block>
  <block id="62414a5a9c0e2fc12a8d028ad29164b8" category="summary">MySQL et innodb_io_Capacity</block>
  <block id="6219c45bc8c26437c0b7e1a69d4cbe58" category="summary">MySQL et innodb_flush_method</block>
  <block id="35d1a5d7b12999ec27f5233dccba043f" category="summary">MySQL et open_file_limits</block>
  <block id="c031febc35017c70bf3b526723756b2a" category="doc">ISCSI et NVMe/TCP</block>
  <block id="4da35d461815e71b97bda03476e89b7b" category="paragraph">Un hôte utilisant iSCSI ou NVMe/TCP peut être directement connecté à un système de stockage et fonctionner normalement. La raison en est le chemin d'accès. Les connexions directes à deux contrôleurs de stockage distincts donnent lieu à deux chemins de flux de données indépendants. La perte du chemin, du port ou du contrôleur n'empêche pas l'autre chemin d'être utilisé.</block>
  <block id="40715d81cea527f13cdf470773fc3a65" category="paragraph">Vous pouvez utiliser un stockage NFS à connexion directe, mais avec une limitation importante : le basculement ne fonctionnera pas sans script important, ce qui incombera au client.</block>
  <block id="d0b13bfd23c05f64222869de30f81000" category="paragraph">Ce qui complique la reprise après incident avec un stockage NFS à connexion directe, c'est le routage qui se produit sur le système d'exploitation local. Par exemple, supposons qu'un hôte a une adresse IP 192.168.1.1/24 et qu'il est directement connecté à un contrôleur ONTAP avec une adresse IP 192.168.1.50/24. Lors du basculement, cette adresse 192.168.1.50 peut basculer vers l'autre contrôleur et sera disponible pour l'hôte, mais comment l'hôte peut-il détecter sa présence ? L'adresse 192.168.1.1 d'origine existe toujours sur la carte réseau hôte qui ne se connecte plus à un système opérationnel. Le trafic destiné à 192.168.1.50 continuerait d'être envoyé à un port réseau inutilisable.</block>
  <block id="288a0a5ebbc70fb3b968ec58d36d71ab" category="paragraph">Le second NIC du système d'exploitation peut être configuré sur 19 2.168.1.2 et serait capable de communiquer avec l'adresse en panne sur 192.168.1.50, mais les tables de routage locales auraient par défaut l'utilisation d'une adresse *et d'une seule adresse* pour communiquer avec le sous-réseau 192.168.1.0/24. Un administrateur système pourrait créer un framework de scripts qui détecterait une connexion réseau défaillante et modifierait les tables de routage locales ou rendrait les interfaces « up and down ». La procédure exacte dépend du système d'exploitation utilisé.</block>
  <block id="d6ce8522932df7ae76aa0b963ad9ef7d" category="paragraph">Dans la pratique, les clients NetApp disposent d'un protocole NFS à connexion directe, mais généralement uniquement pour les charges de travail où une pause des E/S est acceptable pendant les basculements. Lorsque des montages durs sont utilisés, aucune erreur d'E/S ne doit se produire lors de ces pauses. L'E/S doit se bloquer jusqu'à ce que les services soient restaurés, soit par un retour arrière, soit par une intervention manuelle pour déplacer les adresses IP entre les cartes réseau de l'hôte.</block>
  <block id="3436a7073ac9f4071820b6720a7789fc" category="section-title">Connexion directe FC</block>
  <block id="b7981516813a09695906aa429b07f48f" category="paragraph">Il n'est pas possible de connecter directement un hôte à un système de stockage ONTAP à l'aide du protocole FC. La raison en est l'utilisation de NPIV. Le WWN qui identifie un port FC ONTAP sur le réseau FC utilise un type de virtualisation appelé NPIV. Tout périphérique connecté à un système ONTAP doit pouvoir reconnaître un WWN NPIV. Aucun fournisseur actuel de HBA ne propose de HBA pouvant être installé sur un hôte et capable de prendre en charge une cible NPIV.</block>
  <block id="97db606ac6781989ea3b189d7be28bf2" category="section-title">Réseau à connexion directe</block>
  <block id="d078ae9a339971900f939db9e82f253d" category="paragraph">Les administrateurs du stockage préfèrent parfois simplifier leurs infrastructures en supprimant les commutateurs réseau de la configuration. Cela peut être pris en charge dans certains scénarios.</block>
  <block id="e817ecc2f82a2b78d828ec8704031da3" category="section-title">Connexion directe au réseau</block>
  <block id="87e6f97c8ec2f31df616ef84401ffaf4" category="paragraph">Plusieurs ressources de dépannage sont disponibles avec des informations supplémentaires.</block>
  <block id="52d04863ac62a6fa67e1b49a31086928" category="paragraph">Les sections suivantes présentent les meilleures pratiques opérationnelles pour VMware SRM et le stockage ONTAP.</block>
  <block id="f24ef4a42850a2b3e3d77e610ae46fee" category="doc">Résilience pour les événements planifiés et non planifiés</block>
  <block id="4bce11924453ef2ee7e40109f79dc66d" category="paragraph">NetApp MetroCluster et la synchronisation active SnapMirror sont des outils puissants qui améliorent la haute disponibilité et la continuité de l'activité du matériel NetApp et du logiciel ONTAP®.</block>
  <block id="52f49b6400100ac4558d31582b90ca4e" category="paragraph">Ces outils assurent une protection à l'échelle du site pour l'ensemble de l'environnement de stockage, garantissant ainsi la disponibilité permanente de vos données. Que vous utilisiez des serveurs autonomes, des clusters à haute disponibilité, des conteneurs Docker ou des serveurs virtualisés, la technologie NetApp assure la disponibilité du stockage de manière transparente en cas de panne totale due à une coupure d'alimentation, à des problèmes de climatisation, de connectivité réseau, à l'arrêt des baies de stockage ou à une erreur de fonctionnement.</block>
  <block id="d267775072875ddbb24c16a41c22d8a2" category="paragraph">La synchronisation active MetroCluster et SnapMirror propose trois méthodes de base pour la continuité des données en cas d'événements planifiés ou non :</block>
  <block id="1d3027d09fc1db3087f05f2163af2cb7" category="list-text">Des composants redondants pour une protection contre les défaillances d'un seul composant</block>
  <block id="f3b83f3b77289efe3b53cf537b7b77f5" category="list-text">Basculement de haute disponibilité locale en cas d'événements affectant un contrôleur unique</block>
  <block id="b6ed0cba165f6f9664dc1e57ac3419ec" category="list-text">Protection complète du site – reprise rapide du service en déplaçant le stockage et l'accès client du cluster source vers le cluster de destination</block>
  <block id="16afcbe8821dfa582521cd62c1ec130d" category="paragraph">Cela signifie que les opérations se poursuivent en toute transparence en cas de défaillance d'un seul composant et reviennent automatiquement au fonctionnement redondant lorsque le composant défectueux est remplacé.</block>
  <block id="8fab78e8b214cad43d962b802bf568f8" category="paragraph">Tous les clusters ONTAP, à l'exception des clusters à un seul nœud (en général, les versions Software-defined, telles que ONTAP Select, par exemple), disposent de fonctionnalités haute disponibilité intégrées appelées Takeover et giveback. Chaque contrôleur du cluster est couplé à un autre contrôleur, formant une paire haute disponibilité. Ces paires garantissent que chaque nœud est connecté localement au stockage.</block>
  <block id="83e1749664841043ce8b1e894769a201" category="paragraph">Le basculement est un processus automatisé qui consiste à prendre le contrôle du stockage d'un nœud pour assurer les services de données. Le rétablissement est le processus inverse qui restaure le fonctionnement normal. Le basculement peut être planifié, par exemple lors de la maintenance matérielle ou des mises à niveau ONTAP, ou non planifié, suite à une panne matérielle ou de panique sur un nœud.</block>
  <block id="834d83f4ff04b7e3948831f336559b7c" category="paragraph">Lors d'un basculement, les interfaces logiques NAS dans les configurations MetroCluster basculent automatiquement. Toutefois, les LIF SAN (Storage Area Network) ne basculent pas ; elles continuent d'utiliser le chemin direct vers les LUN (Logical Unit Numbers).</block>
  <block id="0b0403a9258293da1f6a5fc84d24a18e" category="inline-link">Présentation de la gestion des paires HAUTE DISPONIBILITÉ</block>
  <block id="df5ca9bc3ee60e70aa9fd870a1ce1065" category="paragraph">Pour plus d'informations sur le basculement et le rétablissement HA, reportez-vous au<block ref="5a72801b431f75b7489a0e7de50680bf" category="inline-link-rx"></block>. Notez que cette fonctionnalité n'est pas spécifique à la synchronisation active MetroCluster ou SnapMirror.</block>
  <block id="cf654073ce9eb8f38d3f05292ed83cc5" category="paragraph">Le basculement de site avec MetroCluster a lieu lorsqu'un site est hors ligne ou lors d'une activité planifiée pour la maintenance à l'échelle du site. Le site restant assume la propriété des ressources de stockage (disques et agrégats) du cluster hors ligne, et les SVM sur le site en panne sont mis en ligne et redémarrés sur le site en cas de sinistre, tout en préservant leur identité complète pour l'accès des clients et des hôtes.</block>
  <block id="4dd2305dcb9d7412784238dd42dcdc21" category="paragraph">Avec la synchronisation active SnapMirror, dans la mesure où les deux copies sont activement utilisées simultanément, vos hôtes existants continueront de fonctionner. Le médiateur NetApp est nécessaire pour garantir que le basculement de site se produit correctement.</block>
  <block id="823bd5c6c005e340599d915e134d851c" category="summary">Présentation de la solution VMware vSphere</block>
  <block id="be26d39d86de44047c65c1fed157d529" category="paragraph">VCenter Server Appliance (VCSA) est le puissant système de gestion centralisée et une interface unique pour vSphere qui permet aux administrateurs d'exploiter efficacement les clusters ESXi. Cet outil facilite les fonctions clés telles que le provisionnement des machines virtuelles, les opérations vMotion, la haute disponibilité (HA), Distributed Resource Scheduler (DRS), Tanzu Kubernetes Grid et bien plus encore. Elle constitue un composant essentiel des environnements clouds VMware et doit être conçue en tenant compte de la disponibilité du service.</block>
  <block id="8ba8694e23f6560a60d85c4de549122b" category="section-title">Haute disponibilité vSphere</block>
  <block id="4b5543b81af03f01e26fcb74614f7062" category="paragraph">La technologie de cluster de VMware regroupe les serveurs ESXi en pools de ressources partagées pour les machines virtuelles et fournit la haute disponibilité (HA) vSphere. VSphere HA offre une haute disponibilité et une simplicité d'utilisation pour les applications qui s'exécutent sur des machines virtuelles. Lorsque la fonction de haute disponibilité est activée sur le cluster, chaque serveur ESXi maintient la communication avec les autres hôtes de sorte que si un hôte ESXi ne répond plus ou est isolé, le cluster de haute disponibilité peut négocier la restauration des machines virtuelles qui s'exécutaient sur cet hôte ESXi parmi les hôtes survivants du cluster. En cas de défaillance d'un système d'exploitation invité, vSphere HA redémarre la machine virtuelle concernée sur le même serveur physique. La haute disponibilité vSphere permet de réduire les temps d'indisponibilité planifiés, d'éviter les temps d'indisponibilité non planifiés et de restaurer rapidement les données en cas de panne.</block>
  <block id="01036edb3159652090a3f7149fe1ce2f" category="paragraph">Cluster vSphere HA qui récupère les machines virtuelles à partir d'un serveur défaillant.</block>
  <block id="15496c3917565cea1f21bbc7e6eba996" category="image-alt">Schéma VMSC</block>
  <block id="c1bb7aa3a002a819d935439c7e347826" category="paragraph">Il est important de comprendre que VMware vSphere ne connaît pas la synchronisation active NetApp MetroCluster ou SnapMirror et que tous les hôtes ESXi du cluster vSphere sont identifiés comme des hôtes éligibles pour les opérations de cluster haute disponibilité selon les configurations d'affinité de l'hôte et du groupe de machines virtuelles.</block>
  <block id="dcff37ab37f2cb6a72aeb3c30e3ed5aa" category="section-title">Détection de défaillance de l'hôte</block>
  <block id="7069d861b63dd4095cfb7b2ee30587f5" category="paragraph">Dès la création du cluster HA, tous les hôtes du cluster participent à des élections et l'un des hôtes devient maître. Chaque esclave exécute une pulsation réseau vers le maître, et le maître effectue à son tour une pulsation réseau sur tous les hôtes esclaves. L'hôte maître d'un cluster vSphere HA est responsable de la détection de la défaillance des hôtes esclaves.</block>
  <block id="73b629afd8ef39d8d0147696412538c8" category="paragraph">En fonction du type de défaillance détecté, les machines virtuelles exécutées sur les hôtes peuvent avoir besoin d'être basculées.</block>
  <block id="e12cf4015a45ff29f1f84ae1a3ee0390" category="paragraph">Dans un cluster vSphere HA, trois types de défaillance d'hôte sont détectés :</block>
  <block id="4eac346eb6cdd3a1a98ee9bc71ebccaa" category="list-text">Défaillance - Un hôte cesse de fonctionner.</block>
  <block id="3875a4c584a7715edf4a221ce53d45fc" category="list-text">Isolation - Un hôte devient isolé du réseau.</block>
  <block id="82fba11358d642111efbcf36273159f2" category="list-text">Partition : Un hôte perd la connectivité réseau avec l'hôte maître.</block>
  <block id="5f72ceebd161159fe623ff01ac0cf1b4" category="paragraph">L'hôte maître surveille les hôtes esclaves du cluster. Cette communication s'effectue par échange de battements de cœur réseau toutes les secondes. Lorsque l'hôte maître cesse de recevoir ces battements de cœur d'un hôte esclave, il vérifie la livenité de l'hôte avant de déclarer l'échec de l'hôte. La vérification de la livenité effectuée par l'hôte maître consiste à déterminer si l'hôte esclave échange des pulsations avec l'un des datastores. En outre, l'hôte maître vérifie si l'hôte répond aux requêtes ping ICMP envoyées à ses adresses IP de gestion pour détecter s'il est simplement isolé de son nœud maître ou complètement isolé du réseau. Pour ce faire, il exécute une commande ping sur la passerelle par défaut. Une ou plusieurs adresses d'isolement peuvent être spécifiées manuellement pour améliorer la fiabilité de la validation de l'isolement.</block>
  <block id="5546466ab10e5cbfbc4b286cd60b8b4a" category="section-title">_Meilleure pratique_</block>
  <block id="0456a7ce7bf92fb68980571fdd2defa1" category="paragraph">NetApp recommande de spécifier au moins deux adresses d'isolement supplémentaires, et que chacune de ces adresses soit site-local. Cela améliorera la fiabilité de la validation de l'isolement.</block>
  <block id="19c262cd1e1bb07c491e359333f04a29" category="section-title">Réponse d'isolation de l'hôte</block>
  <block id="7a2723aad08de3c674693adf221e4a48" category="paragraph">Isolation Response est un paramètre de vSphere HA qui détermine l'action déclenchée sur les machines virtuelles lorsqu'un hôte d'un cluster vSphere HA perd ses connexions réseau de gestion mais continue à s'exécuter. Il existe trois options pour ce paramètre, « Désactivé », « Arrêter et redémarrer les machines virtuelles » et « Arrêter et redémarrer les machines virtuelles ».</block>
  <block id="715e310d886b45856c3ab0f69b06241b" category="paragraph">Il est préférable d'arrêter le système plutôt que de le mettre hors tension, qui ne vide pas les dernières modifications apportées au disque ou ne commet pas les transactions. Si les machines virtuelles ne s'arrêtent pas dans les 300 secondes, elles sont éteintes. Pour modifier le temps d'attente, utilisez l'option avancée das.isolashutdowntimeout.</block>
  <block id="620b4ae663a26c98656d1c81bec1a6c2" category="paragraph">Avant que la haute disponibilité ne lance la réponse d'isolation, elle vérifie d'abord si l'agent principal vSphere HA possède le datastore qui contient les fichiers de configuration de la machine virtuelle. Si ce n'est pas le cas, l'hôte ne déclenchera pas la réponse d'isolation, car il n'y a pas de maître pour redémarrer les machines virtuelles. L'hôte vérifie régulièrement l'état du datastore pour déterminer s'il est demandé par un agent vSphere HA qui détient le rôle principal.</block>
  <block id="6824ef1b1c5e58e8ea5ebc8b2cf94be2" category="paragraph">NetApp recommande de définir la « réponse d'isolation de l'hôte » sur Désactivé.</block>
  <block id="6bd7b146f345eefac88b336a89aa3754" category="paragraph">Une condition de split-brain peut se produire si un hôte est isolé ou partitionné à partir de l'hôte maître vSphere HA et que le maître ne peut pas communiquer via des datastores heartbeat ou par ping. Le maître déclare l'hôte isolé comme étant mort et redémarre les machines virtuelles sur les autres hôtes du cluster. Une condition de split-brain existe maintenant parce qu'il y a deux instances de la machine virtuelle en cours d'exécution, dont une seule peut lire ou écrire les disques virtuels. Il est désormais possible d'éviter les conditions de split-brain en configurant VM Component protection (VMCP).</block>
  <block id="df05a421ed8ba49f97f18dc085495ee4" category="section-title">Protection des composants VM (VMCP)</block>
  <block id="1418d127ee81cc7f3e114029e9ba6856" category="paragraph">L'une des améliorations de vSphere 6, concernant la haute disponibilité, est VMCP. VMCP offre une protection améliorée contre les conditions de tous les chemins d'accès (APD) et de perte permanente de périphérique (PDL) pour le stockage bloc (FC, iSCSI, FCoE) et de fichiers (NFS).</block>
  <block id="fc35e15d00ef5b037a1a56c77ef3e17c" category="section-title">Perte permanente de périphérique (PDL)</block>
  <block id="967b20f28092443585be2b9649d0ba93" category="paragraph">PDL est une condition qui se produit lorsqu'un périphérique de stockage tombe en panne de manière permanente ou est supprimé administrativement et ne devrait pas revenir. La baie de stockage NetApp émet un code de détection SCSI pour ESXi déclarant que le périphérique est définitivement perdu. Dans la section Conditions de défaillance et réponse de la machine virtuelle de vSphere HA, vous pouvez configurer la réponse après la détection d'une condition PDL.</block>
  <block id="7cf4fdbfc8e1deb9f567848f2df19e91" category="paragraph">NetApp recommande de définir la "réponse du datastore avec PDL" sur "*éteindre et redémarrer les machines virtuelles*". Lorsque cette condition est détectée, une machine virtuelle est redémarrée instantanément sur un hôte sain dans le cluster vSphere HA.</block>
  <block id="6d623de2ea8c5007def6f2349d9ad8b9" category="section-title">Tous les chemins en panne (APD)</block>
  <block id="15d2d9b1f25022e7080482582e155265" category="paragraph">L'APD est une condition qui se produit lorsqu'un périphérique de stockage devient inaccessible à l'hôte et qu'aucun chemin vers la matrice n'est disponible. ESXi considère cela comme un problème temporaire avec le périphérique et s'attend à ce qu'il redevienne disponible.</block>
  <block id="f89caca297ba86d190d90ef30c409ccf" category="paragraph">Lorsqu'une condition APD est détectée, une minuterie démarre. Au bout de 140 secondes, la condition APD est officiellement déclarée et le périphérique est marqué comme étant hors délai APD. Lorsque les 140 secondes sont écoulées, la haute disponibilité commence à compter le nombre de minutes spécifié dans le délai d'attente pour le basculement de machine virtuelle. Une fois le délai spécifié écoulé, la haute disponibilité redémarre les machines virtuelles impactées. Vous pouvez configurer VMCP pour qu'il réponde différemment si vous le souhaitez (désactivé, événements de problème ou mise hors tension et redémarrage des machines virtuelles).</block>
  <block id="8f179a61d789dab9b994ecd0ca8c53cb" category="paragraph">NetApp recommande de configurer la « réponse pour le datastore avec APD » sur « * mettre hors tension et redémarrer les machines virtuelles (conservatrices)* ».</block>
  <block id="76d29c3c5f57a16a7f080459356c3793" category="paragraph">Conservateur fait référence à la probabilité que la haute disponibilité soit capable de redémarrer les machines virtuelles. Si elle est définie sur conservateur, la haute disponibilité ne redémarrera la machine virtuelle concernée par l'APD que si elle sait qu'un autre hôte peut la redémarrer. Dans le cas d'un environnement agressif, la haute disponibilité essaiera de redémarrer la machine virtuelle même si elle ne connaît pas l'état des autres hôtes. Cela peut entraîner le redémarrage des machines virtuelles si aucun hôte n'a accès au datastore sur lequel elles se trouvent.</block>
  <block id="c64ef72a18526e28efe7c08b3ff3889a" category="paragraph">Si le statut APD est résolu et que l'accès au stockage est restauré avant le délai d'expiration, la haute disponibilité ne redémarrera pas inutilement la machine virtuelle, sauf si vous la configurez explicitement pour le faire. Si une réponse est souhaitée, même lorsque l'environnement a récupéré de la condition APD, la réponse pour la restauration APD après le délai APD doit être configurée pour réinitialiser les machines virtuelles.</block>
  <block id="580bc3953adcf3e3a20c5497f67f8b2c" category="paragraph">NetApp recommande de configurer la réponse pour la récupération APD après le délai APD sur Désactivé.</block>
  <block id="a067a9a0e98c97f62fba4698bde30edc" category="section-title">Implémentation de VMware DRS pour NetApp MetroCluster</block>
  <block id="3bf3e67966e8b0e07b0812dae7b86ce7" category="paragraph">VMware DRS est une fonctionnalité qui regroupe les ressources hôtes dans un cluster et est principalement utilisée pour équilibrer la charge au sein d'un cluster dans une infrastructure virtuelle. VMware DRS calcule principalement les ressources CPU et mémoire pour effectuer l'équilibrage de charge dans un cluster. Étant donné que vSphere ne connaît pas la mise en cluster étendue, il prend en compte tous les hôtes des deux sites lors de l'équilibrage de charge. Pour éviter le trafic intersite, NetApp recommande de configurer des règles d'affinité DRS pour gérer une séparation logique des machines virtuelles. Cela permet de garantir que, sauf en cas de défaillance complète du site, les systèmes HA et DRS n'utilisent que les hôtes locaux.</block>
  <block id="b9e04f46a88c8139fbb91780a2ff9064" category="paragraph">Si vous créez une règle d'affinité DRS pour votre cluster, vous pouvez spécifier comment vSphere applique cette règle lors du basculement d'une machine virtuelle.</block>
  <block id="f903d43a0acb7412db93e8201ab12be3" category="paragraph">Vous pouvez spécifier deux types de règles pour le basculement de vSphere HA :</block>
  <block id="a96c8bab3a450bb828e3093d16f7e32c" category="list-text">Les règles d'anti-affinité pour les machines virtuelles forcent les machines virtuelles spécifiées à rester séparées pendant les opérations de basculement.</block>
  <block id="1fa3a04279011cbc6001c96c0f6f27fb" category="list-text">Les règles d'affinité des hôtes VM placent les machines virtuelles spécifiées sur un hôte particulier ou un membre d'un groupe défini d'hôtes lors des actions de basculement.</block>
  <block id="225e3f7204b6e5bf6cd388af7bb16eb4" category="paragraph">En utilisant les règles d'affinité pour les hôtes de machine virtuelle dans VMware DRS, il est possible d'avoir une séparation logique entre le site A et le site B, de sorte que la machine virtuelle s'exécute sur l'hôte au même site que la baie configurée comme contrôleur de lecture/écriture principal pour un datastore donné. De plus, les règles d'affinité des hôtes de VM permettent aux machines virtuelles de rester locales au stockage, ce qui à son tour ascert la connexion de la machine virtuelle en cas de défaillances réseau entre les sites.</block>
  <block id="db03e2255e35df6fa9719c800850c397" category="paragraph">Voici un exemple de groupes d'hôtes de machine virtuelle et de règles d'affinité.</block>
  <block id="d400b2cf908bc5f979847146ff8ac816" category="paragraph">NetApp recommande de mettre en place des règles « a » plutôt que des règles « a », car elles sont violées par vSphere HA en cas de défaillance. L'utilisation de règles « must » peut entraîner des interruptions de service.</block>
  <block id="e9503bc9ad84f6517ddc938c85541dd5" category="paragraph">La disponibilité des services doit toujours prévaloir sur les performances. Lorsqu'un data Center complet tombe en panne, les règles « must » doivent choisir les hôtes du groupe d'affinité des hôtes de la machine virtuelle et, lorsque le data Center n'est pas disponible, les machines virtuelles ne redémarrent pas.</block>
  <block id="b3c45603f3738ac1e1f8e1e87569c00c" category="section-title">Implémentation de VMware Storage DRS avec NetApp MetroCluster</block>
  <block id="4669dbcf4d42583b3fae1c79fa228078" category="paragraph">Le contrôle des E/S du stockage est activé par défaut sur les clusters DRS compatibles avec Storage DRS. Le contrôle des E/S du stockage permet à un administrateur de contrôler la quantité d'E/S de stockage allouée aux serveurs virtuels pendant les périodes d'encombrement des E/S. Ainsi, les serveurs virtuels plus importants sont préfénables aux serveurs virtuels moins importants pour l'allocation des ressources d'E/S.</block>
  <block id="f06483bf36a941eebbb2f78a89b6bf68" category="paragraph">Storage DRS utilise Storage vMotion pour migrer les machines virtuelles vers différents datastores au sein d'un cluster de datastores. Dans un environnement NetApp MetroCluster, la migration des machines virtuelles doit être contrôlée dans les datastores de ce site. Par exemple, la machine virtuelle A, qui s'exécute sur un hôte du site A, doit idéalement migrer au sein des datastores du SVM sur le site A. Si ce n'est pas le cas, la machine virtuelle continue à fonctionner mais avec des performances dégradées, puisque la lecture/l'écriture du disque virtuel se fera à partir du site B via des liens inter-sites.</block>
  <block id="2438f6a80b933cf058ad052d26ac0703" category="paragraph">Le clonage d'un objet de stockage vous permet de créer rapidement des copies pour ensuite les utiliser, par exemple le provisionnement de machines virtuelles supplémentaires, les opérations de sauvegarde/restauration, etc.</block>
  <block id="1a795345e422d7dbcca8fe38671a9371" category="summary">Directives de conception et de mise en œuvre VMSC.</block>
  <block id="b73deaadc37ea1c7a13ad17af6730c42" category="doc">Directives de conception et de mise en œuvre VMSC</block>
  <block id="3512760e2d3fc1a9dd2116e83bb0cada" category="paragraph">Ce document présente les lignes directrices en matière de conception et d'implémentation pour vMSC avec systèmes de stockage ONTAP.</block>
  <block id="556669df5b5073ab3d2ddcf638e942d9" category="section-title">Configuration du stockage NetApp</block>
  <block id="7f4d4fbe08a8a895671d05c4a82b0c85" category="inline-link">Documentation MetroCluster</block>
  <block id="002eb41870df47521a2b59424d251f60" category="inline-link">Présentation de la continuité de l'activité SnapMirror</block>
  <block id="447566f62201eb825a1f6fb7a570873f" category="paragraph">Une fois que vous avez configuré MetroCluster, son administration revient à gérer un environnement ONTAP traditionnel. Vous pouvez configurer des machines virtuelles de stockage (SVM) à l'aide de divers outils tels que l'interface de ligne de commande (CLI), System Manager ou Ansible. Une fois les SVM configurés, créez des interfaces logiques (LIF), des volumes et des LUN sur le cluster qui seront utilisés pour les opérations normales. Ces objets seront automatiquement répliqués sur l'autre cluster à l'aide du réseau de peering de cluster.</block>
  <block id="b5486be95ed9ae2e4681a39cf8fe8041" category="inline-link">Présentation des groupes de cohérence</block>
  <block id="57166da54d8751e1ed084f00b3f169e3" category="section-title">Créer un cluster haute disponibilité vSphere</block>
  <block id="829006223e7bdcfd478d2261f1d5ac40" category="inline-link">Comment créer et configurer des clusters dans vSphere client sur docs.vmware.com</block>
  <block id="2bbae4763835d2e2dd123c1b4b0ae73d" category="paragraph">La création d'un cluster vSphere HA est un processus en plusieurs étapes entièrement documenté à l'adresse<block ref="dd51ccd863dd3c9fbca770681f8e68a9" category="inline-link-rx"></block>. En bref, vous devez d'abord créer un cluster vide, puis, à l'aide de vCenter, vous devez ajouter des hôtes et spécifier les paramètres vSphere HA et autres du cluster.</block>
  <block id="d50e63b9f70efedde8dc093be8ec12b2" category="inline-link">Bonnes pratiques pour VMware vSphere Metro Storage Cluster</block>
  <block id="950954623b197b80e3ebb95b0adcc3de" category="paragraph">Pour configurer un cluster HA, effectuez les étapes suivantes :</block>
  <block id="1073102bd8c6cbd17340f2a19043583f" category="list-text">Connectez-vous à l'interface utilisateur vCenter.</block>
  <block id="ebf69ea3a3e34739bde13d589e85ef10" category="list-text">Dans hôtes et clusters, accédez au data Center où vous souhaitez créer votre cluster haute disponibilité.</block>
  <block id="d8fd85bbc0cd4746e5d80e291696b86c" category="list-text">Cliquez avec le bouton droit de la souris sur l'objet de data Center et sélectionnez Nouveau cluster. Dans les notions de base, assurez-vous d'avoir activé vSphere DRS et vSphere HA. Suivez l'assistant.</block>
  <block id="f2c634ca704e26f96be1723db6dda32a" category="image-alt">Capture d'écran d'une description d'ordinateur générée automatiquement</block>
  <block id="f4f59bf1e324854573172ca2b5070d45" category="list-text">Sélectionnez le cluster et accédez à l'onglet configure. Sélectionnez vSphere HA et cliquez sur Edit.</block>
  <block id="329c69e52a7de6215aa4dbfa19940f2d" category="list-text">Sous surveillance de l'hôte, sélectionnez l'option Activer la surveillance de l'hôte.</block>
  <block id="9fc231ac455a53f2fabc59f29ab537ad" category="list-text">Toujours sous l'onglet défaillances et réponses, sous surveillance VM, sélectionnez l'option VM Monitoring Only ou VM and application Monitoring.</block>
  <block id="58aea8c81a7e8b8160584574af309fbb" category="list-text">Sous contrôle d'admission, définissez l'option de contrôle d'admission HA sur réserve de ressources de cluster ; utilisez 50 % CPU/MEM.</block>
  <block id="d94a9f01bee7dcc2643864bf92ab4e59" category="list-text">Cliquez sur OK.</block>
  <block id="3f059eee365aa5c64c0be1d6dba81d69" category="list-text">Sélectionnez DRS et cliquez sur EDIT.</block>
  <block id="7b5f9be03fd1421a9da56c2c7677ad69" category="list-text">Définissez le niveau d'automatisation sur manuel, sauf si vos applications en ont besoin.</block>
  <block id="a8ee10582e28e3623629963a88ff5ec9" category="image-alt">vmsc 3 5</block>
  <block id="256164bb48582e5267e408f2e67e1939" category="inline-link">docs.vmware.com</block>
  <block id="91fb89f03b846483f7108d3f1bfb0156" category="list-text">Activer la protection des composants VM, voir<block ref="fc88c93ad20ad804a211f4e6fea63e56" category="inline-link-rx"></block>.</block>
  <block id="918c2d8e02dbd2c1f4cc3a0062690387" category="list-text">Les paramètres vSphere HA supplémentaires suivants sont recommandés pour vMSC avec MCC :</block>
  <block id="d64ed3e9c10229648e069f56e32f4c8e" category="cell">Réponse</block>
  <block id="f3c1d0e4118d5d9501e1a7aeed19d224" category="cell">Défaillance d'hôte</block>
  <block id="45d583cd5692c76d45e96536edce2a0e" category="cell">Redémarrage des machines virtuelles</block>
  <block id="1c3a7ae924920b573baede481becd22f" category="cell">Isolation de l'hôte</block>
  <block id="2e011e74abc75a2823c627b7ee9e22a7" category="cell">Datastore avec perte de périphérique permanente (PDL)</block>
  <block id="49476a1ad365d5f8deb36464de7fe33b" category="cell">Mettez les machines virtuelles hors tension et redémarrez-les</block>
  <block id="e7bbd35db169028c75e7c8ae655bf6ae" category="cell">Datastore avec tous les chemins en panne (APD)</block>
  <block id="e7480b00a5e3efd904a08ca88804de45" category="cell">Client qui ne bat pas</block>
  <block id="e8896c595f3effde37ef29d7c6233703" category="cell">Réinitialiser les VM</block>
  <block id="59695df3d45a3a21b8ff0bf57fda6a2b" category="cell">Règle de redémarrage de machine virtuelle</block>
  <block id="a150f56b87fd99bf9bf019f8447ba68b" category="cell">Déterminé par l'importance de la machine virtuelle</block>
  <block id="370a480458a8c63a838940f1241e14ee" category="cell">Réponse pour l'isolation de l'hôte</block>
  <block id="11f30f9be08cd4f9e500290222ddc552" category="cell">Arrêtez et redémarrez les machines virtuelles</block>
  <block id="fb53fafa45c0de9bd41d368c7455c9f1" category="cell">Réponse pour datastore avec PDL</block>
  <block id="d7c3b9f5568eb60f08076b29490afcaf" category="cell">Réponse pour le datastore avec APD</block>
  <block id="423b2d98eae113ae3391aa0b12f11935" category="cell">Mise hors tension et redémarrage des machines virtuelles (prudent)</block>
  <block id="132bbe6dbceb01227dba5ab04db7202b" category="cell">Délai de basculement de machine virtuelle pour APD</block>
  <block id="8d15ed7d27d83ed6229a66b1f44b7696" category="cell">3 minutes</block>
  <block id="8c7b0644547f0ee3fe537e8ba441566d" category="cell">Réponse pour la restauration APD avec délai d'expiration APD</block>
  <block id="4dea08318b2824f845e9b889a6e17778" category="cell">Sensibilité de surveillance des machines virtuelles</block>
  <block id="f535a28adc173e28610c129d0dc578ae" category="cell">Présélection haute</block>
  <block id="83164803a765d1ea1f10d50dfdd26130" category="section-title">Configurez les datastores pour Heartbeat</block>
  <block id="22c81b09ec3086b2dce8f68867a221e0" category="paragraph">VSphere HA utilise les datastores pour surveiller les hôtes et les machines virtuelles en cas de panne du réseau de gestion. Vous pouvez configurer la façon dont vCenter sélectionne les datastores Heartbeat. Pour configurer des datastores pour les pulsations, procédez comme suit :</block>
  <block id="64809e5386c9dc53f894f772f27d1b44" category="list-text">Dans la section pulsation du datastore, sélectionnez utiliser les datastores dans la liste spécifiée et complétez automatiquement si nécessaire.</block>
  <block id="fc66ba7317ceb4220dc88aa267db085d" category="list-text">Sélectionnez les datastores que vCenter doit utiliser sur les deux sites et appuyez sur OK.</block>
  <block id="1d2b14769d080b9214d9e407dfc92a64" category="section-title">Configurer les options avancées</block>
  <block id="a9316d69e5abcfaffc56fc8f5e645412" category="paragraph">Les événements d'isolation se produisent lorsque les hôtes d'un cluster haute disponibilité perdent la connectivité au réseau ou à d'autres hôtes du cluster. Par défaut, vSphere HA utilise la passerelle par défaut de son réseau de gestion comme adresse d'isolation par défaut. Toutefois, vous pouvez spécifier des adresses d'isolement supplémentaires pour que l'hôte puisse envoyer une requête ping afin de déterminer si une réponse d'isolement doit être déclenchée. Ajoutez deux adresses IP d'isolation pouvant être ping, une par site. N'utilisez pas l'adresse IP de la passerelle. Le paramètre avancé de vSphere HA utilisé est das.isolaaddress. Vous pouvez utiliser des adresses IP ONTAP ou Mediator à cette fin.</block>
  <block id="3f44bb4a3b9420d495e400b9afbda2c7" category="paragraph">L'ajout d'un paramètre avancé appelé das.heartbeatDsPerHost peut augmenter le nombre de datastores de pulsation. Utilisez quatre datastores de pulsation (DSS HB)—deux par site. Utilisez l'option « Sélectionner dans la liste mais compléter ». Ceci est nécessaire car si un site tombe en panne, vous avez toujours besoin de deux DSS HB. Toutefois, ceux-ci n'ont pas à être protégés avec la synchronisation active MCC ou SnapMirror.</block>
  <block id="eaa1dfe3982e06655ce64e240c139b81" category="paragraph">Affinité avec VMware DRS pour NetApp MetroCluster</block>
  <block id="e32221c52eb3b0bbeb3ca79aad6c90f6" category="paragraph">Dans cette section, nous créons des groupes DRS pour les machines virtuelles et les hôtes pour chaque site/cluster dans l'environnement MetroCluster. Ensuite, nous configurons les règles VM/Host pour aligner l'affinité des hôtes VM avec les ressources de stockage locales. Par exemple, les machines virtuelles du site A appartiennent au groupe de machines virtuelles sitea_VM et les hôtes du site A appartiennent au groupe d'hôtes sitea_hosts. Ensuite, dans VM\Host Rules, nous faisons état que sitea_vm doit s'exécuter sur les hôtes de sitea_hosts.</block>
  <block id="5bfa0d712f66aef47f8a2ea582bc0b72" category="list-text">NetApp recommande vivement la spécification *devrait s'exécuter sur les hôtes du groupe* plutôt que la spécification *doit s'exécuter sur les hôtes du groupe*. En cas de défaillance d'un hôte sur un site, les machines virtuelles Du site A doivent être redémarrées sur les hôtes du site B via vSphere HA, mais cette dernière spécification ne permet pas à HA de redémarrer les machines virtuelles sur le site B, car il s'agit d'une règle stricte. Il s'agit d'une règle souple qui ne sera pas respectée en cas de haute disponibilité, garantissant ainsi la disponibilité plutôt que la performance.</block>
  <block id="cc6a363013bd2a8c1e05304f1c6abd79" category="inline-link">Surveillance et performances vSphere</block>
  <block id="124de7d2bc72d75be9e481c1cc56ada2" category="section-title">Créer des groupes d'hôtes DRS</block>
  <block id="0759e9476d3bf1868f88356025adafb2" category="paragraph">Pour créer des groupes d'hôtes DRS spécifiques au site A et au site B, procédez comme suit :</block>
  <block id="a69dff3dd4b284f60243dfd62fa4e57f" category="list-text">Dans le client Web vSphere, cliquez avec le bouton droit de la souris sur le cluster dans l'inventaire et sélectionnez Paramètres.</block>
  <block id="a130b4af254ead99e9ea83044e54ea1d" category="list-text">Cliquez sur VM\Host Groups.</block>
  <block id="1bb250fbf1946dd1bd7ad228032f8803" category="list-text">Cliquez sur Ajouter.</block>
  <block id="62c4d1538f957af2951f2c93ee191d0b" category="list-text">Saisissez le nom du groupe (par exemple, sitea_hosts).</block>
  <block id="df22605898fc890edbcb2a126aa202ce" category="list-text">Dans le menu Type, sélectionnez Groupe d'hôtes.</block>
  <block id="57c0028584902f6cee210dcc13bc9745" category="list-text">Cliquez sur Ajouter et sélectionnez les hôtes souhaités sur le site A, puis cliquez sur OK.</block>
  <block id="583e6d8c3b1006b0561d4b360e58994f" category="list-text">Répétez ces étapes pour ajouter un autre groupe d'hôtes pour le site B.</block>
  <block id="18d0ad44a1e563aaf9f5871e32535a6c" category="list-text">Cliquez sur OK.</block>
  <block id="154964ee7fc6d3261ec55811b0ff9972" category="section-title">Créer des groupes VM DRS</block>
  <block id="40c1eaba5f178f243c57b595b6af4d5e" category="paragraph">Pour créer des groupes VM DRS spécifiques au site A et au site B, procédez comme suit :</block>
  <block id="9a209a741c26968fc13ed8192523df15" category="list-text">Saisissez le nom du groupe (par exemple, sitea_vm).</block>
  <block id="f947c7c9f173289b1c2565b3297095f0" category="list-text">Dans le menu Type, sélectionnez VM Group.</block>
  <block id="40a2a21a084c8d16395113cb79a19ebb" category="list-text">Cliquez sur Ajouter, sélectionnez les machines virtuelles souhaitées sur le site A, puis cliquez sur OK.</block>
  <block id="e2e7af699096077fe178ebf021fb2273" category="section-title">Créer des règles d'hôte VM</block>
  <block id="0a6075f3d3fdbe7c133268face0f5c82" category="paragraph">Pour créer des règles d'affinité DRS spécifiques au site A et au site B, procédez comme suit :</block>
  <block id="df4f9bcca0ceb7a67ba25d886a18743b" category="list-text">Cliquez sur VM\Host Rules.</block>
  <block id="876a25c102b5c301814921d1a9c0e625" category="list-text">Tapez le nom de la règle (par exemple, sitea_affinité).</block>
  <block id="d4b5f57f4e2bd5c357ad9b1fbdc2cf8e" category="list-text">Vérifiez que l'option Activer la règle est cochée.</block>
  <block id="d1169f525bd934df7f1a7e3bcf401997" category="list-text">Dans le menu Type, sélectionnez ordinateurs virtuels vers hôtes.</block>
  <block id="77328c16c697ce1d6c036c3f950e7542" category="list-text">Sélectionnez le groupe VM (par exemple, sitea_vm).</block>
  <block id="b36943ce975d4c5c6e9481a4ca396270" category="list-text">Sélectionnez le groupe Host (par exemple, sitea_hosts).</block>
  <block id="32fbcb32cfae9a0656233943c28f7c94" category="list-text">Répétez ces étapes pour ajouter une autre règle VM\Host pour le site B.</block>
  <block id="488f70e76f3c9ddf155b693e31c5a1e1" category="paragraph">Pour configurer un cluster de datastore pour chaque site, procédez comme suit :</block>
  <block id="1dfbc2b980c0b56a5d9889c6d9a25460" category="list-text">À l'aide du client web vSphere, accédez au data Center où réside le cluster HA sous Storage.</block>
  <block id="dfc332b252ad3de167b6a336d7e70d46" category="list-text">Cliquez avec le bouton droit de la souris sur l'objet datacenter et sélectionnez Storage &gt; New datastore Cluster.</block>
  <block id="829b62dbd6a4923b66591b2bff38ed5b" category="list-text">Sélectionnez le cluster HA et cliquez sur Next.</block>
  <block id="30fe6cfa0a4c5fb23fccfe149cefc006" category="list-text">Sélectionnez les datastores appartenant au site A et cliquez sur Suivant.</block>
  <block id="4ea461b22638db4c94aa076d62a2065f" category="list-text">Vérifiez les options et cliquez sur Terminer.</block>
  <block id="7b79e97caff76847cf350f1197c49953" category="list-text">Répétez ces étapes pour créer le cluster de datastore du site B et vérifier que seuls les datastores du site B sont sélectionnés.</block>
  <block id="d8f83b09bd6b864f22076c109cfaae66" category="section-title">Disponibilité du serveur vCenter</block>
  <block id="605b8c1efcf2de9164e5d5425c67bdcd" category="paragraph">Vos appliances vCenter Server (VCSA) doivent être protégées avec vCenter HA. VCenter HA vous permet de déployer deux VCSA dans une paire haute disponibilité actif-passif. Un dans chaque domaine de défaillance. Pour en savoir plus sur vCenter HA, rendez-vous sur<block ref="173ca8434bdf39dd0a60efe576d066cd" category="inline-link-rx"></block>.</block>
  <block id="70901a02a148fd2dfc1ff5736f4f5336" category="list-text">Trafic du réseau de stockage séparé des autres réseaux Un réseau distinct peut être obtenu à l'aide d'un VLAN dédié ou de commutateurs distincts pour le stockage. Si le réseau de stockage partage des chemins physiques, tels que des liaisons ascendantes, vous pouvez avoir besoin de la qualité de service ou de ports supplémentaires pour garantir une bande passante suffisante. Ne connectez pas les hôtes directement au stockage ; utilisez les commutateurs pour disposer de chemins redondants et permettez à VMware HA de fonctionner sans intervention. Voir <block ref="2d54da766c3f840b00eab5923273fca5" category="inline-link-macro-rx"></block> pour plus d'informations.</block>
  <block id="59cfc5aaa0678bcb883492b4397c71b8" category="cell">Oui (ONTAP 9.14.1)</block>
  <block id="a58c81d13cac4e9b37bba2bd7fc3a93d" category="paragraph">L'hyperviseur vSphere de pointe de VMware peut être déployé en tant que cluster étendu appelé vMSC (vSphere Metro Storage Cluster).</block>
  <block id="e3224e391e08365c1593c07b9fe99cfa" category="section-title">Disponibilité continue pour les environnements vSphere</block>
  <block id="ffa76ec5527e36c51f49fe091541cca6" category="paragraph">NetApp MetroCluster utilise la fonction HA (basculement du contrôleur ou CFO) de NetApp pour se protéger contre les défaillances du contrôleur. Elle inclut également la technologie SyncMirror locale, le basculement de cluster en cas d'incident (basculement du contrôleur à la demande ou CFOD), la redondance matérielle et la séparation géographique pour atteindre des niveaux élevés de disponibilité. SyncMirror met en miroir les données de manière synchrone sur les deux moitiés de la configuration MetroCluster en écrivant les données sur deux plexes : le plex local (sur le tiroir local) assure activement le service des données et le plex distant (sur le tiroir distant) n'assure généralement pas le service des données. La redondance matérielle est mise en place pour tous les composants MetroCluster, tels que les contrôleurs, le stockage, les câbles, les commutateurs (utilisés avec Fabric MetroCluster) et les adaptateurs.</block>
  <block id="d3e911c902a6b066f9c31d471d16fb21" category="paragraph">Pour créer un cluster VMware HA/DRS sur deux sites, les hôtes ESXi sont utilisés et gérés par une appliance vCenter Server (VCSA). Les réseaux de gestion vSphere, vMotion® et machine virtuelle sont connectés via un réseau redondant entre les deux sites. Le serveur vCenter gérant le cluster HA/DRS peut se connecter aux hôtes ESXi sur les deux sites et doit être configuré à l'aide de vCenter HA.</block>
  <block id="da76be2bc20d4e043d9a2019b817214f" category="inline-link">Comment créer et configurer des clusters dans le client vSphere</block>
  <block id="e02f3e9258a23204655bd512ec53911d" category="paragraph">Reportez-vous à la section<block ref="c06ae090600e7aa086edfa28514435e7" category="inline-link-rx"></block> Pour configurer vCenter HA.</block>
  <block id="38910d3dab2318849fd5f1a1dfbe0152" category="inline-link">Guide de compatibilité du stockage VMware</block>
  <block id="838b66b875df1b432ac420a98cba3db6" category="paragraph">Pour plus d'informations sur les conseils de conception pour vSphere Metro Storage Cluster, reportez-vous à la documentation suivante :</block>
  <block id="07aaf2aebfd07b8763284018d1ebbf57" category="inline-link">Prise en charge de VMware vSphere avec NetApp MetroCluster</block>
  <block id="a4a5fd5b00daf98bd381d80257378acd" category="list-text"><block ref="a4a5fd5b00daf98bd381d80257378acd" category="inline-link-rx"></block></block>
  <block id="c3dc11e39d996a00b095022f4e56583d" category="inline-link">Prise en charge de VMware vSphere avec la continuité de l'activité NetApp SnapMirror</block>
  <block id="8f675397d9c0ef95aa8b3f0ada9d601a" category="list-text"><block ref="f53214cfd764fa0267c92323be0d7337" category="inline-link-rx"></block> (Maintenant appelé synchronisation active SnapMirror)</block>
  <block id="ee0a206d2287c89b2a7b780e07929b81" category="paragraph">Selon les considérations relatives à la latence, NetApp MetroCluster peut être déployé dans deux configurations différentes pour une utilisation avec vSphere :</block>
  <block id="b553530def78406c0977f70d5e90b9e8" category="list-text">MetroCluster extensible</block>
  <block id="2d90abe978ed8084d304295ad0a8c8fd" category="list-text">MetroCluster de structure</block>
  <block id="b03023e82bda6a71adc49c4834e3b6ab" category="paragraph">Voici une illustration de la topologie générale d'Stretch MetroCluster.</block>
  <block id="b0c20dc8226bb49f35f0f68f7ef77bba" category="image-alt">Schéma VMSC avec MCC</block>
  <block id="119be031ef4485d20c7683d291d0e9f6" category="inline-link">Documentation MetroCluster</block>
  <block id="ad9122c6d75ebaa024669fde1c0bdfb8" category="paragraph">Reportez-vous à la section<block ref="d8a206747dbcec13122724b2aee18957" category="inline-link-rx"></block> Pour obtenir des informations spécifiques sur la conception et le déploiement de MetroCluster.</block>
  <block id="b47354fcd7d17ab4fbb3283f71677efe" category="paragraph">La synchronisation active SnapMirror peut également être déployée de deux manières différentes.</block>
  <block id="314084a577b998d8089dff72c98c58b0" category="list-text">Asymétrique</block>
  <block id="bca8b52c503406abc3e9e50c5352d0a2" category="paragraph">Ce document présente la solution ONTAP pour VMware site Recovery Manager (SRM), le logiciel de reprise après incident de pointe de VMware, qui inclut les dernières informations produit et les meilleures pratiques permettant de rationaliser le déploiement, de réduire les risques et de simplifier la gestion au quotidien.</block>
  <block id="4f46fffb0ac7017fd2b42c10d6aa03fc" category="paragraph">La sauvegarde et la restauration rapide de vos machines virtuelles font partie des grands atouts de ONTAP pour vSphere. C'est facile à gérer au sein de vCenter grâce au plug-in SnapCenter pour VMware vSphere.</block>
  <block id="b69cd5a82aaf0c524a71d46ec6fdd29c" category="cell">L'agrégation de sessions NFS v4.1 requiert ONTAP 9.14.1 et versions ultérieures</block>
  <block id="80303385ad0f7147caa1af6d2162852b" category="paragraph">Le plug-in est également l'interface de gestion de nombreuses fonctions de VASA Provider pour ONTAP, prenant en charge la gestion basée sur des règles de stockage avec vvols. Une fois les outils ONTAP pour VMware vSphere enregistrés, utilisez-le pour créer des profils de capacité de stockage, les mapper au stockage, et assurez-vous que le datastore est conforme aux profils au fil du temps. Vasa Provider fournit également une interface pour créer et gérer les datastores vvol.</block>
  <block id="d9c9eb44a58ee1ce90daa68527aa8930" category="summary">Scénarios de panne pour vMSC avec MCC</block>
  <block id="e7c7574b0826c9074f480de76c889ba8" category="paragraph">Les sections suivantes décrivent les résultats attendus de différents scénarios de défaillance avec les systèmes vMSC et NetApp MetroCluster.</block>
  <block id="c8a2eebb480fef69e6ed917ea7f7a9d3" category="section-title">Défaillance d'un seul chemin de stockage</block>
  <block id="b99e8e694b032f593bbd01f6205b4a98" category="paragraph">Dans ce scénario, si des composants tels que le port HBA, le port réseau, le port du commutateur de données frontal ou un câble FC ou Ethernet échouent, ce chemin particulier vers le périphérique de stockage est marqué comme mort par l'hôte ESXi. Si plusieurs chemins sont configurés pour le périphérique de stockage en fournissant la résilience au niveau du port HBA/réseau/commutateur, ESXi effectue idéalement un basculement de chemin. Pendant cette période, les ordinateurs virtuels restent en fonctionnement sans être affectés, car la disponibilité du stockage est assurée par plusieurs chemins vers le périphérique de stockage.</block>
  <block id="80fc15dd1deb985234440745e8a78d4c" category="paragraph">Dans les environnements dans lesquels les volumes NFS/iSCSI sont utilisés, NetApp recommande de configurer au moins deux liaisons montantes réseau pour le port vmkernel NFS dans le vSwitch standard et la même pour le groupe de ports où l'interface vmkernel NFS est mappée pour le vSwitch distribué. Le regroupement de cartes réseau peut être configuré en mode actif-actif ou actif-veille.</block>
  <block id="0c8694e8ef7f8935edbfac605753bc95" category="paragraph">En outre, pour les LUN iSCSI, les chemins d'accès multiples doivent être configurés en liant les interfaces vmkernel aux adaptateurs réseau iSCSI. Pour plus d'informations, reportez-vous à la documentation sur le stockage vSphere.</block>
  <block id="0fc808fdb968eb089fbc5124c0a8e15a" category="paragraph">Dans les environnements dans lesquels des LUN Fibre Channel sont utilisées, NetApp recommande d'avoir au moins deux HBA, ce qui garantit la résilience au niveau des HBA/ports. NetApp recommande également la segmentation entre un initiateur unique et une seule cible comme meilleure pratique pour la configuration de la segmentation.</block>
  <block id="238c3d1c7bf8b5b42237392383a4c7ab" category="paragraph">Virtual Storage Console (VSC) doit être utilisé pour définir des règles de chemins d'accès multiples, car il définit des règles pour tous les périphériques de stockage NetApp, nouveaux ou existants.</block>
  <block id="217811709dfb096c78e73934de01271c" category="section-title">Défaillance d'un hôte ESXi unique</block>
  <block id="93bc89a0478478dd84d8159a18f6c1a2" category="image-alt">Défaillance d'un seul hôte.</block>
  <block id="15023af3b440b4004f509e961bfe1e30" category="paragraph">Dans ce scénario, en cas de défaillance de l'hôte ESXi, le nœud maître du cluster VMware HA détecte la panne de l'hôte, car il ne reçoit plus de pulsations réseau. Pour déterminer si l'hôte est réellement en panne ou uniquement une partition réseau, le nœud maître surveille les pulsations du datastore et, s'il est absent, il effectue une vérification finale en envoyant une requête ping aux adresses IP de gestion de l'hôte en panne. Si toutes ces vérifications sont négatives, le nœud maître déclare cet hôte comme étant en panne et toutes les machines virtuelles qui s'exécutaient sur cet hôte en panne sont redémarrées sur l'hôte survivant du cluster.</block>
  <block id="9a11158d52f71012ae8722b09bf8bf29" category="paragraph">Si les règles d'affinité des machines virtuelles DRS et des hôtes ont été configurées (les machines virtuelles du groupe de machines virtuelles sitea_vm doivent exécuter des hôtes dans le groupe d'hôtes sitea_hosts), le maître haute disponibilité vérifie d'abord les ressources disponibles sur le site A. Si aucun hôte n'est disponible sur le site A, le maître tente de redémarrer les machines virtuelles sur les hôtes du site B.</block>
  <block id="7922c92ff860eb0508dc8cc8aae3ffdd" category="paragraph">Il est possible que les machines virtuelles soient démarrées sur les hôtes ESXi de l'autre site s'il existe une contrainte de ressource sur le site local. Cependant, les règles d'affinité VM et hôte DRS définies seront correctes si des règles sont enfreintes en migrant les machines virtuelles vers des hôtes ESXi survivants sur le site local. Dans les cas où DRS est défini sur manuel, NetApp recommande d'invoquer DRS et d'appliquer les recommandations pour corriger le positionnement de la machine virtuelle.</block>
  <block id="387b5a49326be3a47e081682e75e19b4" category="paragraph">Dans ce scénario, le comportement de MetroCluster n'a pas changé et tous les datastores sont toujours intacts sur leurs sites respectifs.</block>
  <block id="a11ffa7d20dab792fe5aa9c27017493e" category="section-title">Isolation de l'hôte ESXi</block>
  <block id="17e01652089acd413e26ea89cf98a2b8" category="image-alt">Isolation de l'hôte ESXi</block>
  <block id="8a4b746274e9d7129602d54434624806" category="paragraph">Dans ce scénario, si le réseau de gestion de l'hôte ESXi est en panne, le nœud principal du cluster HA ne recevra aucun battement de cœur. Cet hôte est donc isolé dans le réseau. Pour déterminer s'il a échoué ou s'il est isolé uniquement, le nœud maître commence à surveiller le battement de cœur du datastore. S'il est présent, l'hôte est déclaré isolé par le nœud maître. Selon la réponse d'isolement configurée, l'hôte peut choisir de mettre hors tension, d'arrêter les machines virtuelles ou même de laisser les machines virtuelles sous tension. L'intervalle par défaut pour la réponse d'isolement est de 30 secondes.</block>
  <block id="a070f7923919fed39772c5d3f91bf482" category="section-title">Panne de tiroir disque</block>
  <block id="e8acf0e4f25cdd641c9a047482d56ba5" category="paragraph">Dans ce scénario, il y a une panne de plus de deux disques ou d'un tiroir entier. Les données sont servies depuis le plex opérationnel sans interruption des services de données. La défaillance de disque peut affecter un plex local ou distant. Les agrégats s'affichent en mode dégradé, car un seul plex est actif. Une fois les disques défaillants remplacés, les agrégats affectés resynchroniseront automatiquement pour reconstruire les données. Après la resynchronisation, les agrégats reviennent automatiquement en mode miroir normal. Si plus de deux disques au sein d'un même groupe RAID sont défaillants, le plex doit être reconstruit à partir de zéro.</block>
  <block id="4f90d34a41c7ebc83024a5e3ca35ff3a" category="image-alt">Une panne de tiroir disque.</block>
  <block id="1c872dcd4bcebb1d7567f383901dfc0d" category="section-title">Panne d'un seul contrôleur de stockage</block>
  <block id="68badb604dbd29653979fdc7083cbffe" category="paragraph">Dans ce scénario, l'un des deux contrôleurs de stockage tombe en panne sur un site. Comme il existe une paire haute disponibilité sur chaque site, la panne d'un nœud entraîne le basculement vers l'autre nœud de manière transparente et automatique. Par exemple, si le nœud A1 tombe en panne, son stockage et ses charges de travail sont automatiquement transférés vers le nœud A2. Les machines virtuelles ne seront pas affectées, car tous les plexes restent disponibles. Les nœuds du second site (B1 et B2) ne sont pas affectés. En outre, vSphere HA ne prendra aucune action, car le nœud maître du cluster recevra toujours les battements de cœur du réseau.</block>
  <block id="0ac25682ea568511724f2e0819127d89" category="image-alt">Défaillance d'un seul nœud</block>
  <block id="e7b4c0523308b3fd46189b6ab4867fe5" category="paragraph">Si le basculement fait partie d'un incident en cours (le nœud A1 bascule vers A2) et qu'il y a une panne ultérieure de A2, ou la panne complète du site A, le basculement après un incident peut se produire sur le site B.</block>
  <block id="7b590b52d9f3d4d40cda67758ff92ba1" category="section-title">Défaillances de liaison entre commutateurs</block>
  <block id="9df08f82abe35d87c6f7c96b18dab755" category="section-title">Défaillance de la liaison inter-commutateur sur le réseau de gestion</block>
  <block id="ed0711cbc7a050952e0e370bab079bff" category="image-alt">Défaillance de la liaison entre les commutateurs au niveau du réseau de gestion</block>
  <block id="a32c6c77bb8d407cf5825aec175bab4b" category="paragraph">Dans ce scénario, si les liaisons ISL du réseau de gestion de l'hôte frontal tombent en panne, les hôtes ESXi du site A ne pourront pas communiquer avec les hôtes ESXi du site B. Cela entraîne une partition réseau, car les hôtes ESXi d'un site particulier ne peuvent pas envoyer les battements de cœur du réseau au nœud maître du cluster HA. Ainsi, il y aura deux segments de réseau en raison de la partition et il y aura un nœud maître dans chaque segment qui protégera les machines virtuelles des défaillances de l'hôte au sein du site particulier.</block>
  <block id="628309883a8d1307131d205b200c56ae" category="section-title">Défaillance de la liaison intercommutateur sur le réseau de stockage</block>
  <block id="a9da7e2a43bcea673a22b949355e619d" category="image-alt">Défaillance de la liaison de l'interswitch au niveau du réseau de stockage</block>
  <block id="625db96c5ee1e9b5197b6cb3c1715021" category="paragraph">Dans ce scénario, si les liaisons ISL du réseau de stockage back-end tombent en panne, les hôtes du site A perdront l'accès aux volumes de stockage ou aux LUN du cluster B sur le site B et vice versa. Les règles VMware DRS sont définies de manière à ce que l'affinité entre l'hôte et le site de stockage facilite l'exécution des machines virtuelles sans impact sur le site.</block>
  <block id="8d9609f32cbee8fa5080f95d71a2a142" category="paragraph">Pendant cette période, les machines virtuelles restent en cours d'exécution sur leurs sites respectifs et le comportement de MetroCluster n'a pas changé dans ce scénario. Tous les datastores sont toujours intacts sur leurs sites respectifs.</block>
  <block id="719831bfdda20be14c04e2b165cce85e" category="paragraph">Si, pour une raison quelconque, la règle d'affinité a été enfreinte (par exemple, VM1, qui était censé s'exécuter à partir du site A où ses disques résident sur les nœuds du cluster A local, s'exécute sur un hôte du site B), le disque de la machine virtuelle est accessible à distance via des liens ISL. En raison d'une défaillance de la liaison ISL, VM1 exécuté sur le site B ne pouvait pas écrire sur ses disques, car les chemins vers le volume de stockage sont en panne et cette machine virtuelle est en panne. Dans ce cas, VMware HA ne prend aucune action, car les hôtes envoient activement des battements du cœur. Ces machines virtuelles doivent être manuellement désactivées et activées sur leurs sites respectifs. La figure suivante illustre une machine virtuelle violant une règle d'affinité DRS.</block>
  <block id="09ba89b1ea49214c15fbf8ea6f129cb0" category="image-alt">Une machine virtuelle violant une règle d'affinité DRS ne peut pas écrire sur les disques après une panne de lien ISL</block>
  <block id="49f26967af2ad76cacf7888cbeeb0590" category="section-title">Défaillance de tous les commutateurs ou partition complète du centre de données</block>
  <block id="bc331d84348670dff6731555166fa378" category="paragraph">Dans ce scénario, toutes les liaisons ISL entre les sites sont en panne et les deux sites sont isolés les uns des autres. Comme nous l'avons vu dans les scénarios précédents, tels que la défaillance des liens ISL au niveau du réseau de gestion et du réseau de stockage, les machines virtuelles ne sont pas affectées par la défaillance complète des liens ISL.</block>
  <block id="a40e8cf2a5b5b1e22fec9f26cce85b9d" category="paragraph">Une fois les hôtes ESXi partitionnés entre les sites, l'agent vSphere HA vérifie la présence de battements de cœur du datastore et, sur chaque site, les hôtes ESXi locaux pourront mettre à jour les battements de cœur du datastore vers leur volume/LUN de lecture/écriture respectif. Les hôtes du site A partent du principe que les autres hôtes ESXi du site B ont échoué car il n'y a pas de pulsations réseau/datastore. VSphere HA sur le site A tentera de redémarrer les machines virtuelles du site B, ce qui finira par échouer car les datastores du site B ne seront pas accessibles en raison d'une panne de lien ISL du stockage. Une situation similaire est répétée sur le site B.</block>
  <block id="3543d47d1f3a8dc6989a32f62ce3ea77" category="image-alt">Toute panne de lien ISL ou partition complète du data Center</block>
  <block id="3a096ef571101010add81b37081d3276" category="paragraph">NetApp recommande de déterminer si une machine virtuelle a enfreint les règles DRS. Toutes les machines virtuelles exécutées à partir d'un site distant sont en panne, car elles ne pourront pas accéder au datastore. VSphere HA redémarrera cette machine virtuelle sur le site local. Une fois les liens ISL de nouveau en ligne, la machine virtuelle qui s'exécutait sur le site distant est arrêtée, car il ne peut pas y avoir deux instances de machines virtuelles fonctionnant avec les mêmes adresses MAC.</block>
  <block id="87e9384cb464ff9a4ce385fc59a178a2" category="image-alt">Partition de centre de données où VM1 a violé une règle d'affinité DRS</block>
  <block id="0951e388ebea20c49e71af25ef84947d" category="section-title">Défaillance de la liaison inter-commutateur sur les deux fabriques dans NetApp MetroCluster</block>
  <block id="1e9be78885a356d1a2ec0ab0d4a4cecb" category="paragraph">Dans le cas d'une défaillance d'un ou de plusieurs liens ISL, le trafic continue à travers les liens restants. Si toutes les liaisons ISL des deux structures échouent, de sorte qu'il n'y ait pas de liaison entre les sites pour le stockage et la réplication NVRAM, chaque contrôleur continue de transmettre ses données locales. Lors de la restauration d'un ISL au moins, la resynchronisation de tous les plexes se fera automatiquement.</block>
  <block id="715cbc6f6bcf5da6b73f10233847d3a1" category="paragraph">Toute écriture effectuée après l'arrêt de toutes les ISL ne sera pas mise en miroir sur l'autre site. Un basculement sur incident, dans cet état, entraînerait la perte des données non synchronisées. Dans ce cas, une intervention manuelle est requise pour la restauration après le basculement. S'il est probable qu'aucune ISL ne soit disponible pendant une période prolongée, l'administrateur peut choisir de fermer tous les services de données afin d'éviter tout risque de perte de données en cas de basculement en cas d'incident. L'exécution de cette action doit être comparée à la probabilité d'un incident nécessitant un basculement avant qu'au moins un lien ISL ne soit disponible. Sinon, si les liens ISL échouent dans un scénario en cascade, un administrateur peut déclencher un basculement planifié vers l'un des sites avant que tous les liens n'aient échoué.</block>
  <block id="89f375bfe8be0893bf175b89ce754b8e" category="image-alt">Défaillance de la liaison entre les commutateurs sur les deux fabriques du NetApp MetroCluster.</block>
  <block id="bc813a6fdbbeebf4d230b7e33d8c3a76" category="section-title">Défaillance du lien de peering de cluster</block>
  <block id="1919456d1613248a128c65a84b235fe5" category="paragraph">Dans le cas d'une défaillance de liaison de cluster peering, les liens ISL de la structure sont toujours actifs, les services de données (lectures et écritures) continuent sur les deux sites vers les deux plexes. Toute modification de la configuration du cluster (par exemple, ajout d'un SVM, provisionnement d'un volume ou d'une LUN dans un SVM existant) ne peut pas être propagée à l'autre site. Ils sont conservés dans les volumes de métadonnées CRS locaux et automatiquement propagés à l'autre cluster lors de la restauration du lien du cluster peering. Si un basculement forcé est nécessaire avant la restauration de la liaison de cluster peering, les modifications de la configuration du cluster en attente seront automatiquement lues à partir de la copie répliquée à distance des volumes de métadonnées sur le site survivant dans le cadre du processus de basculement.</block>
  <block id="77130a0b52e4379c6b6667cf7f8e155c" category="image-alt">Défaillance du lien de peering de cluster</block>
  <block id="9dc32d7afddc9a265c5c2713db55fc70" category="section-title">Défaillance complète du site</block>
  <block id="d0d6a03c382bc5412f1822e5c97d5142" category="paragraph">Dans un scénario de défaillance de site complet A, les hôtes ESXi du site B n'obtiennent pas la pulsation réseau des hôtes ESXi du site A car ils sont en panne. Le maître haute disponibilité sur le site B vérifie que les pulsations du datastore ne sont pas présentes, déclare que les hôtes du site A sont en panne et tente de redémarrer le site A des machines virtuelles sur le site B. Pendant cette période, l'administrateur du stockage effectue un basculement pour reprendre les services des nœuds défaillants sur le site survivant, ce qui restaure tous les services de stockage du site A sur le site B. Une fois que les volumes ou les LUN du site A sont disponibles sur le site B, l'agent principal de haute disponibilité tente de redémarrer le site A des machines virtuelles sur le site B.</block>
  <block id="23e5761401326cc21bcf9d108b9e3e7f" category="paragraph">Si la tentative de redémarrage d'une machine virtuelle par l'agent principal vSphere HA (qui implique son enregistrement et sa mise sous tension) échoue, le redémarrage est relancé après un délai. Le délai entre les redémarrages peut être configuré jusqu'à un maximum de 30 minutes. VSphere HA tente ces redémarrages au maximum pour un nombre maximal de tentatives (six tentatives par défaut).</block>
  <block id="085a4a3eba6c30fa589bfee20eb0c294" category="paragraph">Si le site A été basculé, la panne suivante de l'un des nœuds du site B survivant peut être gérée de manière transparente par le basculement vers le nœud survivant. Dans ce cas, le travail de quatre nœuds est désormais effectué par un seul nœud. Dans ce cas, la restauration consiste à effectuer un rétablissement vers le nœud local. Ensuite, lorsque le site A est restauré, une opération de rétablissement est effectuée pour restaurer le fonctionnement en état stable de la configuration.</block>
  <block id="2b9b713afb0d80ef371a0b55e58366b6" category="image-alt">Les pannes générales du site</block>
  <block id="e6364c2f5314a32cd95be04b4c2112e6" category="paragraph">Les sections suivantes présentent les procédures et les bonnes pratiques d'utilisation de VMware vVols avec le stockage ONTAP.</block>
  <block id="a9da618400fb93b20c20f5343efaefa7" category="sidebar">Cluster de stockage VMware vSphere Metro avec ONTAP</block>
  <block id="2f58fa882a22b5af5f0741f03abaf611" category="sidebar">Cluster de stockage vSphere Metro avec ONTAP</block>
  <block id="4a884da785a62e8b1758932191ff42de" category="paragraph">La virtualisation des bases de données avec VMware, Oracle OLVM ou KVM est un choix de plus en plus courant pour les clients NetApp qui ont choisi la virtualisation, même pour leurs bases de données les plus stratégiques.</block>
  <block id="3a8ba1ff8824968961222d6b447b4973" category="section-title">Prise en charge</block>
  <block id="3231d83af741101eb02b16e5d7a6dffc" category="paragraph">Il existe de nombreuses idées fausses sur les politiques de prise en charge d'Oracle pour la virtualisation, en particulier pour les produits VMware. Il n'est pas rare d'entendre qu'Oracle ne prend pas en charge la virtualisation. Cette notion est incorrecte et ne permet pas de bénéficier de la virtualisation. Oracle Doc ID 249212.1 traite des besoins réels et est rarement considéré par les clients comme un problème.</block>
  <block id="722bd611ee4f38780607b400c8a604c0" category="paragraph">Si un problème se produit sur un serveur virtualisé et que ce problème n'est pas encore connu du support Oracle, le client peut être invité à reproduire le problème sur du matériel physique. Si un client Oracle exécute une version de pointe d'un produit, il est possible qu'il ne souhaite pas utiliser la virtualisation en raison de problèmes de prise en charge potentiels, mais cette situation n'est pas réelle pour les clients qui utilisent des versions de produits Oracle généralement disponibles.</block>
  <block id="c8a4476ecddeda66dbd2c354c8fb2c6b" category="paragraph">Les clients qui envisagent de virtualiser leurs bases de données doivent baser leurs décisions de stockage sur leurs besoins métier. Bien qu'il s'agisse généralement d'une véritable déclaration pour toutes les décisions IT, elle est particulièrement importante pour les projets de base de données, car la taille et le champ d'application des exigences varient considérablement.</block>
  <block id="835ce293f862d9fb74e50f4cf928c56d" category="paragraph">Il existe trois options de base pour la présentation du stockage :</block>
  <block id="327813abbc0ae1e9d3abe282303bf00c" category="list-text">LUN virtualisées sur les datastores de l'hyperviseur</block>
  <block id="1a1af5efffda8c766ead9f73fc782e0e" category="list-text">Systèmes de fichiers NFS montés par la machine virtuelle (pas à partir d'un datastore basé sur NFS)</block>
  <block id="f9bf9489147891f7ee7ba15126a27fda" category="list-text">Mappages directs de périphériques. Les clients ne préfèrent pas les RDM VMware, mais les périphériques physiques sont souvent mappés directement avec la virtualisation KVM et OLVM.</block>
  <block id="69b0ac6bf6ea8e1ab4e4fc896294da01" category="paragraph">La méthode de présentation du stockage à un invité virtualisé n'a généralement pas d'incidence sur les performances. Les systèmes d'exploitation hôtes, les pilotes réseau virtualisés et les implémentations de datastores d'hyperviseurs sont tous optimisés et peuvent généralement utiliser toute la bande passante réseau FC ou IP disponible entre l'hyperviseur et le système de stockage, dans la mesure où les meilleures pratiques de base sont respectées. Dans certains cas, il peut être légèrement plus facile d'obtenir des performances optimales en utilisant une approche de présentation du stockage par rapport à une autre, mais le résultat final devrait être comparable.</block>
  <block id="a2e8fb5328f6558e3a119d8c224a1897" category="paragraph">Le facteur clé dans la décision de présenter le stockage à un invité virtualisé est la mangeabilité. Il n'y a pas de bonne ou de mauvaise méthode. La meilleure approche dépend des besoins, des compétences et des préférences opérationnels de l'IT.</block>
  <block id="e4919ac0a074fa1bba5303f596a5f591" category="paragraph">Les facteurs à prendre en compte sont les suivants :</block>
  <block id="c422e10bbf04c180f4c47f81ed9a1f7a" category="list-text">*Transparence.* lorsqu'une machine virtuelle gère ses systèmes de fichiers, il est plus facile pour un administrateur de base de données ou un administrateur système d'identifier la source des systèmes de fichiers pour leurs données. L'accès aux systèmes de fichiers et aux LUN est différent de celui d'un serveur physique.</block>
  <block id="42de52ad09be3101fc535dea2aedce1d" category="list-text">*Cohérence.* lorsqu'une machine virtuelle possède ses systèmes de fichiers, l'utilisation ou la non-utilisation d'une couche hyperviseur affecte la gestion. Les mêmes procédures de provisionnement, de surveillance, de protection des données, etc. Peuvent être utilisées dans l'ensemble du parc, y compris dans les environnements virtualisés et non virtualisés.</block>
  <block id="0562446bc5eefe9a584e23ffb3061cbf" category="paragraph">Par contre, dans un data Center 100 % virtualisé, il peut être préférable d'utiliser un stockage basé sur un datastore pour l'ensemble de l'encombrement, selon la même logique que celle mentionnée ci-dessus. Cohérence : possibilité d'utiliser les mêmes procédures de provisionnement, de protection, de regroupement et de protection des données.</block>
  <block id="7269a37b557c66664c0377693f62ec8a" category="list-text">*Stabilité et dépannage.* lorsqu'une machine virtuelle possède ses systèmes de fichiers, il est plus simple de fournir des performances stables et de résoudre les problèmes car la pile de stockage complète est présente sur la machine virtuelle. Le seul rôle de l'hyperviseur est de transporter des trames FC ou IP. Lorsqu'un datastore est inclus dans une configuration, il complique la configuration en introduisant un autre ensemble d'expirations de délai, de paramètres, de fichiers journaux et de bogues potentiels.</block>
  <block id="c160b6d86853c20a432e2407b82866e6" category="list-text">*Dépendance vis-à-vis d'un fournisseur.* une fois les données placées dans un datastore, il devient difficile d'utiliser un hyperviseur différent ou de retirer les données de l'environnement virtualisé.</block>
  <block id="a42abd01a1e0c89cfa2112dc09378967" category="list-text">*Activation de Snapshot.* les procédures de sauvegarde traditionnelles dans un environnement virtualisé peuvent devenir problématiques en raison de la bande passante relativement limitée. Par exemple, un agrégat 10 GbE à quatre ports peut suffire pour répondre aux besoins quotidiens en performances de nombreuses bases de données virtualisées, mais ce trunk ne permet pas d'effectuer des sauvegardes à l'aide de RMAN ou d'autres produits de sauvegarde nécessitant le streaming d'une copie complète des données. Résultat : un environnement virtualisé de plus en plus consolidé doit effectuer des sauvegardes via des snapshots de stockage. Ainsi, il n'est pas nécessaire de surconstruire la configuration de l'hyperviseur uniquement pour prendre en charge les besoins en bande passante et en CPU dans la fenêtre de sauvegarde.</block>
  <block id="86c36175331b4a95c083fabdcca8b8a0" category="paragraph">L'utilisation de systèmes de fichiers détenus par les clients facilite parfois l'exploitation des sauvegardes et des restaurations basées sur des snapshots, car les objets de stockage nécessitant une protection peuvent être ciblés plus facilement. Cependant, de plus en plus de produits de protection des données de virtualisation s'intègrent bien aux datastores et aux snapshots. La stratégie de sauvegarde doit être totalement adoptée avant de décider comment présenter le stockage à un hôte virtualisé.</block>
  <block id="8c19dda4c4cab5e52edf9463f196b97d" category="section-title">Répartition des datastores</block>
  <block id="8fa77493c52e71f201ccdb67db26446d" category="paragraph">Lorsque vous utilisez des bases de données avec des datastores, un facteur critique est à prendre en compte en ce qui concerne la répartition des performances.</block>
  <block id="53ab623a905e6ec84d908f0b99a8d1c8" category="paragraph">Les technologies de datastore, telles que VMFS, peuvent couvrir plusieurs LUN, mais ne sont pas des périphériques répartis. Les LUN sont concaténées. Il peut en résulter des points sensibles de la LUN. Par exemple, une base de données Oracle standard peut disposer d'un groupe de disques ASM à 8 LUN. Les 8 LUN virtualisées pourraient être provisionnées sur un datastore VMFS de 8 LUN, mais il n'y a aucune garantie sur les LUN sur lesquelles les données résideront. La configuration résultante peut être les 8 LUN virtualisées occupant une seule LUN au sein du datastore VMFS. Cela risque d'engorgement des performances.</block>
  <block id="e6bb99e411f5495b03c1e0a4e75a1434" category="paragraph">La répartition est généralement requise. Avec certains hyperviseurs, dont KVM, il est possible de créer un datastore à l'aide de la répartition LVM, comme décrit ci-dessous <block ref="dd0ff2598ebb26feb9ff73a59186b79f" category="inline-link-macro-rx"></block>. Avec VMware, l'architecture semble un peu différente. Chaque LUN virtualisée doit être placée sur un datastore VMFS différent.</block>
  <block id="506c2c0c7f5b70af3df68c45c46f45a7" category="paragraph">Par exemple :</block>
  <block id="6ec151851a31c86edd358bc49f80908c" category="paragraph"><block ref="6ec151851a31c86edd358bc49f80908c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="70ff2667d6b190dea65bae42217aa310" category="paragraph">Le facteur principal de cette approche n'est pas le ONTAP. En raison de la limitation inhérente du nombre d'opérations qu'une seule machine virtuelle ou LUN d'hyperviseur peut traiter en parallèle, En règle générale, un LUN ONTAP peut prendre en charge beaucoup plus d'IOPS qu'un hôte ne peut en demander. La limite de performances d'une seule LUN est presque universellement due au système d'exploitation hôte. Ainsi, la plupart des bases de données ont besoin de 4 à 8 LUN pour répondre à leurs besoins de performance.</block>
  <block id="59f9d8d1b212a8ff6bd3476975e17620" category="paragraph">Les architectures VMware doivent planifier soigneusement leurs architectures pour s'assurer que cette approche ne permet pas d'optimiser le datastore et/ou le chemin LUN. Par ailleurs, il n'est pas nécessaire de disposer d'un ensemble unique de datastores VMFS pour chaque base de données. Le principal besoin est de s'assurer que chaque hôte dispose d'un ensemble propre de 4-8 chemins d'E/S entre les LUN virtualisées et les LUN back-end sur le système de stockage lui-même. Dans de rares cas, des exigences de performances vraiment extrêmes peuvent se révéler bénéfiques pour encore plus de données, mais 4-8 LUN suffisent généralement pour 95 % de toutes les bases de données. Un volume ONTAP unique contenant 8 LUN peut prendre en charge jusqu'à 250,000 000 IOPS de bloc Oracle aléatoires avec une configuration type OS/ONTAP/réseau.</block>
  <block id="7564f732469e12963d8b416572cf4efb" category="section-title">Qu'est-ce que le cluster de stockage vSphere Metro ?</block>
  <block id="830d984ea50f71fa76636d0524167a3a" category="doc">Présentation des fonctionnalités de datastore et de protocole vSphere</block>
  <block id="cc0f7f705e4495c607aea288505e31bf" category="sidebar">Présentation de VMSC</block>
  <block id="de9a829f775bc333b77fdacbc333f7a1" category="sidebar">Solution vSphere HA</block>
  <block id="70b29c8dabeb7a16884003c35e163f96" category="sidebar">Conception VMSC</block>
  <block id="6c4755219197ce467bf892a552c8663a" category="sidebar">Résilience VMSC</block>
  <block id="13376e3e9b02a56731aa64aeb10947b2" category="sidebar">Scénarios VMSC avec MCC</block>
  <block id="f0a36f02b824ef55cbd63aa2700a4ec9" category="summary">Sauvegardes et restaurations basées sur des snapshots de bases de données Oracle</block>
  <block id="77243afc69ab08d8277d0e23dda813d9" category="doc">Sauvegardes en ligne des bases de données Oracle</block>
  <block id="4ac7e99e454283880f5bdf93e9d59eb9" category="summary">Tiering FabricPool des fichiers complets des bases de données Oracle</block>
  <block id="3dd6786160916127fc2f6fc2ec955bbe" category="summary">Utilitaire de récupération ASM avec détection de blocs zéro ONTAP</block>
  <block id="89c60635365825dfa13d154785577592" category="summary">Configuration Oracle et TCP/IP et ethernet</block>
  <block id="aaa024a70ffabce1e14fdc1a4b17fe8d" category="doc">Configuration TCP/IP et ethernet pour les bases de données Oracle</block>
  <block id="665de76ea0059ac13982f04e19e74216" category="summary">Bases de données Oracle avec Microsoft Windows</block>
  <block id="0d4fbbc8820271a0ce5d46a15e7bf90f" category="paragraph">Rubriques de configuration pour la base de données Oracle sous Microsoft Windows avec ONTAP.</block>
  <block id="422956aac4f76239935ded6a492144f2" category="summary">ONTAP est conçu pour les bases de données Oracle. Découvrez comment.</block>
  <block id="795da6575a33e265d7d9a5774cd10e6f" category="summary">Sauvegardes de groupes de cohérence pour les bases de données Oracle sur ONTAP</block>
  <block id="33c729820ffa60f55745fa3c259e273c" category="doc">Sauvegardes de groupes de cohérence de la base de données Oracle</block>
  <block id="56abf0735f338713ce53e8cdecd6994e" category="paragraph">Pour la sauvegarde la plus simple possible, il vous suffit de placer l'intégralité de la base de données Oracle dans un seul volume ONTAP</block>
  <block id="190d2bad1c6e231bc18c33e002e663c7" category="summary">Base de données Oracle et connectivité ONTAP à connexion directe</block>
  <block id="4a3f422632f7d08bf0e6c05affea24e4" category="summary">Les bases de données Oracle avec SyncMirror</block>
  <block id="5bbdf1e19bb3f7b70de51a3764fc5f19" category="doc">Sauvegardes optimisées pour les snapshots de stockage de bases de données Oracle</block>
  <block id="a962af081661ee46d4ef879de33c841e" category="paragraph">La sauvegarde et la restauration basées sur des snapshots sont devenues encore plus simples au moment du lancement d'Oracle 12c. En effet, il n'est pas nécessaire de placer une base de données en mode de sauvegarde à chaud. Il est possible de planifier des sauvegardes Snapshot directement sur un système de stockage et d'effectuer des restaurations complètes ou à un point dans le temps.</block>
  <block id="fdf9dde4dc297fff7ac7b3c1458b0dad" category="doc">Répartition LVM avec les bases de données Oracle</block>
  <block id="d3c8171a7167ce43c547aac8fdd86cfb" category="doc">Migration des fichiers de données Oracle</block>
  <block id="9718528cb14225785c79e3afc4152efc" category="doc">Dimensionnement des LUN de la base de données Oracle et nombre de LUN</block>
  <block id="ea7df930bd6bec6222e23d2b3af02a50" category="paragraph">La synchronisation active SnapMirror prend en charge deux types d'opérations de basculement du stockage, planifiées et non planifiées, qui fonctionnent de manières légèrement différentes. Un basculement planifié est initié manuellement par l'administrateur pour permettre un basculement rapide vers un site distant, tandis que le basculement non planifié est automatiquement initié par le médiateur sur le troisième site. L'objectif principal d'un basculement planifié est d'effectuer des correctifs et des mises à niveau incrémentiels, d'effectuer des tests de reprise après incident ou d'adopter une politique formelle de basculement des opérations entre les sites tout au long de l'année afin de démontrer la capacité de synchronisation active complète.</block>
  <block id="f7c8b0ba16967990d91c2ca78d655eaa" category="paragraph">Les diagrammes présentent ce qui se produit pendant les opérations normales, de basculement et de restauration. Pour plus de clarté, ils représentent un LUN répliqué. Dans une configuration de synchronisation active SnapMirror, la réplication est basée sur des volumes, où chaque volume contient une ou plusieurs LUN, mais pour simplifier l'image, la couche du volume a été supprimée.</block>
  <block id="cfa86460b638615878bbee89b1b6d4c7" category="paragraph">La ligne verte est un chemin actif, mais elle subirait plus de latence, car les E/S sur ce chemin devront être transmises sur le chemin de synchronisation actif SnapMirror. La latence supplémentaire dépend de la vitesse de l'interconnexion entre les sites utilisés pour la synchronisation active SnapMirror.</block>
  <block id="22ea45ef5d49a1b807d571799d80613d" category="paragraph">Une fois le système source remis en service, la synchronisation active SnapMirror peut resynchroniser la réplication, tout en exécutant l'autre direction. La configuration est maintenant essentiellement la même que le point de départ, sauf que les sites actifs-miroirs ont été inversés.</block>
  <block id="2702e101c97ce9a58738b1a4089319df" category="summary">Architecture logique MetroCluster et bases de données Oracle</block>
  <block id="784fdd6bf0ebb9c00eaefafc3f9a9cee" category="doc">RAID et les bases de données Oracle</block>
  <block id="204d288bf0e9d1ee9912d68d6282d7a9" category="summary">Bases de données Oracle avec AIX</block>
  <block id="90b3697759466f587c318ce55df76258" category="doc">Bases de données Oracle avec IBM AIX</block>
  <block id="14ab10a24aa8f6c18bfdfd0d8a394dcb" category="paragraph">Rubriques de configuration pour la base de données Oracle sous IBM AIX avec ONTAP.</block>
  <block id="b67d277a8a8f29f7b869c9bdbff5fcd1" category="summary">Bases de données Oracle et règles de récupération FabricPool</block>
  <block id="2e34d4efdcf01f27eb9407a010ca1621" category="summary">Migration Oracle avec FLI - mise en service</block>
  <block id="c5753b0ef1dfc2c724f24235a689d1ab" category="summary">Règles de Tiering FabricPool de la base de données Oracle</block>
  <block id="57d15767e9302dbb67058ed0bd9eebac" category="doc">Bases de données Oracle et NVFAIL</block>
  <block id="4f03272fa32b53344924740fd30fc52d" category="summary">Bases de données Oracle avec Solaris</block>
  <block id="206960915d76763c590449d5ef03639a" category="summary">Bases de données Oracle sur ONTAP et le rôle des snapshots</block>
  <block id="4bc550014af4fefad8f4cc8f0827c4b5" category="doc">Bases de données Oracle et sauvegardes basées sur des snapshots</block>
  <block id="cf5bc9d838fb937caa7978b4a9b0f98a" category="paragraph">La technologie Snapshot de NetApp constitue le socle de la protection des données des bases de données Oracle sur ONTAP.</block>
  <block id="ba5a23e78f51c1bcb1b82efbe1797502" category="summary">Paramètres de base de données Oracle - db_file_multiblock_read_count</block>
  <block id="ea84db84607112a0d40fca3ff45dfffa" category="summary">Gestion des performances des bases de données Oracle avec la QoS ONTAP</block>
  <block id="0af83eb081b1a831789867d7f0867610" category="summary">Outils d'automatisation et de gestion des bases de données Oracle</block>
  <block id="7c58d5a62a9c29d2a846b210deea95f2" category="paragraph">Dans un environnement de base de données Oracle, la principale valeur de ONTAP provient des principales technologies ONTAP, telles que les copies Snapshot instantanées, la réplication simple SnapMirror et la création efficace de volumes FlexClone.</block>
  <block id="591b3149d6cb247a04883c411dab3e24" category="summary">Checksums et intégrité de la base de données Oracle</block>
  <block id="56f014c6fc8fac3e242c9d2e42c654c0" category="paragraph">ONTAP et les protocoles qu'il prend en charge incluent de nombreuses fonctionnalités qui protègent l'intégrité des bases de données Oracle, notamment les données au repos et les données transmises sur le réseau.</block>
  <block id="31b3368edcb737b712ee02926409c837" category="doc">Bases de données Oracle, MetroCluster et NVFAIL</block>
  <block id="490e2f530e53cf85f8ce9b052a8336ec" category="paragraph">NVFAIL est une fonctionnalité d'intégrité générale des données de ONTAP conçue pour optimiser la protection de l'intégrité des données avec les bases de données.</block>
  <block id="f2cf6b943d224a732c92223538580ee9" category="doc">Instance unique Oracle sur MetroCluster</block>
  <block id="ea1d91c32fcf0f4a1090fd0da341c014" category="paragraph">Contrairement à d'autres solutions de reprise après incident du stockage, la synchronisation active SnapMirror offre une flexibilité asymétrique de la plateforme. Le matériel de chaque site n'a pas besoin d'être identique. Cette fonctionnalité vous permet d'ajuster la taille du matériel utilisé pour prendre en charge la synchronisation active SnapMirror. Le système de stockage distant peut être identique au site principal s'il doit prendre en charge une charge de travail de production complète, mais si un incident entraîne une réduction des E/S, un système plus petit sur le site distant peut être plus économique.</block>
  <block id="3873b13983c66ae61dd877b0443a3828" category="summary">Reprise après incident de la base de données Oracle et du groupe de cohérence</block>
  <block id="ede2d3fcaec1bb9dcda5a75c90f37368" category="summary">Optimisation de la disponibilité avec Oracle Database sur ONTAP</block>
  <block id="9688c9c1c1d15e2f91a3a5b8e5f14bd4" category="doc">Disponibilité de la base de données Oracle avec ONTAP</block>
  <block id="44e95a6c3878f189a550b4c0314d3b33" category="paragraph">NetApp sait que les bases de données contient les données les plus stratégiques.</block>
  <block id="7aa93b5fc17b83fc9e4816155f8f59ab" category="summary">Test des performances des bases de données Oracle</block>
  <block id="0b3a030b64747fb3830c79e1ffbef7ee" category="summary">Interruptions d'accès aux bases de données Oracle et aux magasins d'objets</block>
  <block id="99a1755be2504777b7e266ed14b33168" category="doc">Basculement/basculement des bases de données Oracle et du contrôleur ONTAP</block>
  <block id="8dbb58cb7fbd4c7db3f14b9674e7d4e6" category="summary">Restauration rapide des bases de données Oracle avec SnapRestore</block>
  <block id="fd0d4a1100bcbce28e8252537f7c4ef4" category="summary">SLA de protection des données de bases de données Oracle</block>
  <block id="48130805e35d0c7ab5afbcb71abb1ad0" category="doc">Planification des RTO, RPO et SLA des bases de données Oracle</block>
  <block id="f359cd007fda575e70269cac76fab4af" category="paragraph">ONTAP vous permet d'adapter facilement une stratégie de protection des données des bases de données Oracle aux besoins de votre entreprise.</block>
  <block id="05f9f35345d8f2164958f3b6b7098fa7" category="summary">Tiering FabricPool de fichiers partiels Oracle</block>
  <block id="48e2495d3eeb1b57ea7d073e06620063" category="doc">Migration de la base de données Oracle via l'envoi de journaux</block>
  <block id="2cba4042f0a43491e4ea8f14238ae6e4" category="summary">Tiering des snapshots Oracle et FabricPool</block>
  <block id="6f7b1d0f996b7d49f60586ce7fbeca36" category="doc">Oracle avec Tiering Snapshot FabricPool</block>
  <block id="35b12c67685c33721c1a59e8b736fd61" category="summary">Mise en cache NFS avec les bases de données Oracle</block>
  <block id="1404b2da267c376dac716bd5455f4ff3" category="summary">Migration Oracle avec FLI : conversion des protocoles</block>
  <block id="c37c1629ee55e6d553c16bbab86adbde" category="doc">Migration des bases de données Oracle vers des systèmes de stockage ONTAP</block>
  <block id="f1d34b6e878aac7179a735d301e4fb76" category="paragraph">L'exploitation des capacités d'une nouvelle plateforme de stockage implique une seule nécessité : les données doivent être placées sur le nouveau système de stockage. ONTAP simplifie le processus de migration, notamment les migrations et les mises à niveau de ONTAP vers ONTAP, les importations de LUN étrangères et les procédures d'utilisation directe du système d'exploitation hôte ou du logiciel de base de données Oracle.</block>
  <block id="b7433f552fcf8a4e34f2ccc357037d4e" category="doc">Copie des données hôte de la base de données Oracle</block>
  <block id="1cede70bc6077ecbac9a77b03d1bc6e1" category="summary">Planification de la protection des données pour les bases de données Oracle</block>
  <block id="e2bc0913921cafeb725765069883b685" category="paragraph">La bonne architecture de protection des données de base de données Oracle dépend des exigences de l'entreprise en matière de conservation des données, de capacité de restauration et de tolérance aux perturbations lors de divers événements.</block>
  <block id="c0b79db5f258f0c991a383cbdbf001dd" category="inline-link-macro">Synchronisation active SnapMirror</block>
  <block id="8a05777f407870cbc2668230c8117503" category="summary">Bases de données Oracle avec Linux et pilote de filtre ASMlib/ASM</block>
  <block id="494900ae2c2cdb5abdba3806f4dfaeb0" category="doc">Bases de données Oracle avec ASMLib/AFD (pilote de filtre ASM)</block>
  <block id="afae47e326854c63cbc85989720416e0" category="summary">Migration Oracle avec FLI : planification</block>
  <block id="85cef7bf4ac9d983cf8e1e11785eeef1" category="summary">Migration Oracle avec FLI : exécution</block>
  <block id="0c5284e14535835121effc8afb702b28" category="summary">Reprise après incident de la base de données Oracle avec ONTAP</block>
  <block id="2ba21d57ee7f1d78a405b9e80c6aaf6b" category="paragraph">Pour la plupart des clients, la reprise après incident ne suffit pas à posséder une copie distante des données. Il est donc nécessaire de pouvoir les exploiter rapidement. NetApp propose deux technologies pour répondre à ce besoin : MetroCluster et SnapMirror Active Sync</block>
  <block id="107bcc34799abe752a088be24869419c" category="paragraph">La synchronisation active SnapMirror est basée sur SnapMirror synchrone. Avec MetroCluster, chaque contrôleur ONTAP est responsable de la réplication des données de son disque vers un emplacement distant. Avec la synchronisation active SnapMirror, deux systèmes ONTAP différents conservent des copies indépendantes de vos données LUN, mais fonctionnent ensemble pour présenter une seule instance de ce LUN. Du point de vue de l'hôte, il s'agit d'une entité LUN unique.</block>
  <block id="50ae143b75fc238e91c09c750cf211c1" category="summary">Paramètres de la base de données Oracle - filesytemio_options</block>
  <block id="cf451e0aed3c944d3f1c761387762e56" category="summary">Les bases de données Oracle sous Linux</block>
  <block id="e712ed441aacc4eeecb5656d5493c99c" category="summary">Bases de données Oracle avec HP-UX</block>
  <block id="c36ae718fe9d7978c8781b19d0b3dee0" category="paragraph">Rubriques de configuration pour la base de données Oracle sur HP-UX avec ONTAP.</block>
  <block id="45df37151f6a0fd8a3b55d0423459f82" category="doc">Alignement des LUN pour les E/S de la base de données Oracle</block>
  <block id="857a8adc9eda2d9e197a52323daca558" category="doc">Présentation du Tiering FabricPool des bases de données Oracle</block>
  <block id="fd73b1ca3b942a1514078a7e59c7433b" category="summary">Base de données Oracle et verrous NFSv3 obsolètes</block>
  <block id="102aeb54bf1a69403672f53090c52878" category="summary">Reprise après incident de la base de données Oracle via l'envoi de journaux</block>
  <block id="d470f5db851ef84aaa776600805af48b" category="summary">Introduction à la virtualisation des bases de données Oracle</block>
  <block id="b8fc1174bb3f1c65475334182829f75e" category="doc">Virtualisation des bases de données Oracle</block>
  <block id="b1b3f70e4333a9dbda75a98ceb78db39" category="summary">Architecture physique MetroCluster et bases de données Oracle</block>
  <block id="250bce9fbefc7872908d9c2708fc753b" category="doc">Tiering des sauvegardes de bases de données Oracle</block>
  <block id="4fbe2d000cdf5390ca980149d98eec4d" category="summary">Planification de la migration de la base de données Oracle</block>
  <block id="d11e22f56fe0c9dd85597038a25cd80d" category="doc">Bases de données Oracle et gestion de la capacité de stockage</block>
  <block id="1234e92308935cf0a5a22541f312c541" category="summary">Bases de données Oracle avec SnapMirror et SyncMirror</block>
  <block id="a4cdac841b6453db2f51ce52a1303209" category="paragraph">La réplication SnapMirror et la relation SnapMirror de groupe de cohérence continue préservent la cohérence entre les volumes. Les technologies SnapMirror synchrone et SnapMirror synchrone et la synchronisation active préservent la cohérence entre les volumes constitutifs.</block>
  <block id="454ff7e5f4a8d37cf6b16b804deca2b6" category="summary">Tailles des blocs de base de données Oracle</block>
  <block id="eed7df980a6ae17f8e0fecdecf0e25f4" category="doc">Exemples de scripts de procédure de migration Oracle</block>
  <block id="fac6d6b61dd6bd3ee73d5b425bc5a3b7" category="doc">Provisionnement fin avec les bases de données Oracle</block>
  <block id="35ebaedc3385b350dff13e0cfa869c9f" category="summary">Délais d'expiration Oracle RAC</block>
  <block id="710cf627a103721a0452cb72494ea742" category="admonition">Reportez-vous aux sections ci-dessous sur le provisionnement fin pour une explication de l'interaction entre l'efficacité du stockage et la réservation fractionnaire.</block>
  <block id="8bc1cc1880ea3a623cb9b80b8cbb7b72" category="paragraph">Il existe plusieurs façons de compresser les données. De nombreuses bases de données incluent leurs propres fonctionnalités de compression, mais ce phénomène est rarement observé dans les environnements clients. La raison en est généralement la réduction des performances pour un *changement* de données compressées, plus avec certaines applications, il existe des coûts de licence élevés pour la compression au niveau de la base de données. Enfin, il y a les conséquences globales sur les performances des opérations des bases de données. Il est peu judicieux de payer un coût de licence par processeur élevé pour un processeur qui effectue la compression et la décompression des données plutôt que le véritable travail de base de données. Une meilleure option consiste à décharger la tâche de compression sur le système de stockage.</block>
  <block id="3e98696b9bb83904c14603458a8c3728" category="admonition">La taille de bloc utilisée par la compression adaptative peut être augmentée jusqu'à 32 Ko. Cela peut améliorer l'efficacité du stockage et doit être envisagé pour les fichiers de repos tels que les journaux de transactions et les fichiers de sauvegarde lorsqu'une quantité importante de ces données est stockée sur la baie. Dans certains cas, les bases de données actives qui utilisent une taille de bloc de 16 ou 32 Ko peuvent également tirer parti de l'augmentation de la taille de bloc de la compression adaptative pour qu'elle corresponde. Consultez un représentant NetApp ou partenaire pour savoir si cette solution convient à votre charge de travail.</block>
  <block id="0e6f69b7cb8364ed908c411686154808" category="admonition">Les tailles de bloc de compression supérieures à 8 Ko ne doivent pas être utilisées avec la déduplication sur les destinations de sauvegarde en streaming. Les petites modifications apportées aux données sauvegardées affectent la fenêtre de compression de 32 Ko. Si la fenêtre change, les données compressées obtenues diffèrent dans l'ensemble du fichier. La déduplication a lieu après la compression, ce qui signifie que le moteur de déduplication voit chaque sauvegarde compressée différemment. Si la déduplication des sauvegardes en continu est nécessaire, seule une compression adaptative de bloc de 8 Ko doit être utilisée. Il est préférable d'utiliser la compression adaptative, car elle fonctionne à des blocs de taille réduite sans perturber l'efficacité de la déduplication. Pour des raisons similaires, la compression côté hôte interfère également avec l'efficacité de la déduplication.</block>
  <block id="e8a7060409e1a82af9dacfe72458ffac" category="paragraph">Par exemple, une écriture de 8 Ko dans un fichier est compressée uniquement si elle s'aligne sur une limite de 8 Ko dans le système de fichiers lui-même. Ce point signifie qu'il doit figurer sur le premier 8 Ko du fichier, le deuxième 8 Ko du fichier, etc. La manière la plus simple de garantir un alignement correct est d'utiliser le type de LUN correct, toute partition créée doit avoir un décalage par rapport au début du périphérique qui est un multiple de 8K, et utiliser une taille de bloc du système de fichiers qui est un multiple de la taille de bloc de la base de données.</block>
  <block id="96738983d52a374cb4a8c958e924836e" category="paragraph">Les données telles que les sauvegardes ou les journaux de transactions sont des opérations écrites de manière séquentielle sur plusieurs blocs, qui sont tous compressés. Par conséquent, il n'est pas nécessaire de considérer l'alignement. Le seul modèle d'E/S préoccupant est l'écrasement aléatoire des fichiers.</block>
  <block id="1afe2c0821b67085f9ea2d2deeb2e92a" category="paragraph">La compaction est une technologie qui améliore l'efficacité de la compression. Comme indiqué précédemment, la compression adaptative à elle seule permet d'économiser 2:1 au maximum, car elle se limite au stockage d'une E/S de 8 Ko dans un bloc WAFL de 4 Ko. Les méthodes de compression avec des blocs de taille supérieure améliorent l'efficacité. Cependant, elles ne conviennent pas aux données soumises à des remplacements de blocs de petite taille. La décompression d'unités de données de 32 Ko, la mise à jour d'une partie de 8 Ko, la recompression et l'écriture sur les disques entraînent une surcharge.</block>
  <block id="82116b39cd4d0d1920fab1ab4515603b" category="paragraph">Le degré d'économie obtenu varie. En général, les données déjà compressées ou chiffrées ne peuvent pas être compressées davantage et, par conséquent, la compaction de ces datasets ne peut pas être bénéfique. À contrario, les fichiers de données récemment initialisés ne contiennent qu'un petit peu plus que des métadonnées de bloc et des zéros compressent jusqu'à 80:1.</block>
  <block id="2608473fa5767385d01f256eccbc1cc4" category="paragraph">De nombreuses baies concurrentes prétendent être capables de dédupliquer des bases de données en présumant qu'une base de données est copiée plusieurs fois. Il est également possible d'utiliser la déduplication NetApp, mais ONTAP offre une meilleure option : la technologie FlexClone de NetApp. Le résultat final est le même : plusieurs copies d'une base de données qui partagent la plupart des blocs physiques sous-jacents sont créées. L'utilisation de FlexClone est bien plus efficace que de prendre le temps de copier les fichiers de base de données, puis de les dédupliquer. Il s'agit en effet de la non-duplication plutôt que de la déduplication, car un doublon n'est jamais créé à la première place.</block>
  <block id="7e96c1b651af3f28c27b78807f0310e2" category="paragraph">Le provisionnement fin est fortement recommandé car il simplifie la gestion tout en améliorant la capacité exploitable avec les économies associées. La raison en est simple : les environnements de base de données comportent souvent beaucoup d'espace vide, un grand nombre de volumes et de LUN, ainsi que des données compressibles. Le provisionnement fin entraîne la réservation d'espace sur le stockage pour les volumes et les LUN au cas où un jour ils se traduirait par une saturation de 100 % et contiendraient des données non compressibles à 100 %. Il est peu probable que cela se produise. Le provisionnement fin permet de récupérer et d'utiliser cet espace ailleurs. Il permet également de gérer la capacité en fonction du système de stockage lui-même, plutôt que de nombreux volumes et LUN plus petits.</block>
  <block id="f67b854e2d644480b0ec40d7de2b773d" category="paragraph">Les volumes créés sur ONTAP et exécutés sur un système AFF 100 % Flash sont à allocation dynamique, avec l'activation de toutes les fonctionnalités d'efficacité à la volée. Bien que les bases de données ne bénéficient généralement pas de la déduplication et puissent inclure des données non compressibles, les paramètres par défaut conviennent néanmoins à la plupart des charges de travail. ONTAP est conçu pour traiter efficacement tous les types de données et de modèles d'E/S, qu'ils entraînent ou non des économies. Les valeurs par défaut ne doivent être modifiées que si les raisons sont parfaitement comprises et si un écart est bénéfique.</block>
  <block id="649141c6b8267ea3df10949a853d22cb" category="list-text">N'utilisez pas la compression et la déduplication de 32 Ko pour les sauvegardes de bases de données. Voir la section <block ref="57ee2712afc5e59236f86db0537b05dc" category="inline-xref-macro-rx"></block> pour plus d'informations.</block>
  <block id="5059ada12bae6c7e7fac9338d88301b5" category="doc">Tiering des journaux d'archivage de bases de données Oracle</block>
  <block id="4abda684ecc952239d7800547dcf2995" category="sidebar">Oracle si sur MetroCluster</block>
  <block id="bdebc59bb8c11012c00a4be61b8bdb5d" category="summary">Déploiement d'instances Microsoft SQL Server</block>
  <block id="030194212f0e1890126b205fdbcfe852" category="summary">Sécurisation de Microsoft SQL Server sur ONTAP</block>
  <block id="972d09960af01a5f3831f2eac1c75d12" category="summary">Reprise après incident de Microsoft SQL Server avec ONTAP</block>
  <block id="db78788a721b9a9a669c4935d455a593" category="paragraph">Les bases de données d'entreprise et les infrastructures applicatives ont souvent besoin d'une réplication pour se protéger contre les catastrophes naturelles ou les perturbations imprévues, avec un temps d'interruption minimal.</block>
  <block id="fad02ab7a45b438ba1a4c024b9edb2be" category="paragraph">Voici les recommandations pour SnapMirror pour SQL Server :</block>
  <block id="ff1af055b96eb7cd0f0ab71b2cc80c3d" category="list-text">À des fins de cohérence, ne planifiez pas les mises à jour SnapMirror depuis les contrôleurs. Activez plutôt les mises à jour SnapMirror depuis SnapCenter pour mettre à jour SnapMirror une fois la sauvegarde complète ou la sauvegarde du journal terminée.</block>
  <block id="60654048dbcae98cde53dc0449c8e47b" category="summary">Considérations relatives au stockage Microsoft SQL Server</block>
  <block id="71cc52562b241f23c0f5c74c589fc56c" category="paragraph">Les agrégats constituent les conteneurs de stockage de niveau le plus bas pour les configurations de stockage NetApp. Il existe sur Internet une documentation existante qui recommande de séparer les E/S sur différents jeux de disques sous-jacents. Ceci n'est pas recommandé avec ONTAP. NetApp a effectué plusieurs tests de caractérisation des charges de travail d'E/S à l'aide d'agrégats partagés et dédiés, avec des fichiers de données et des fichiers journaux de transactions séparés. Les tests montrent qu'un grand agrégat avec plus de disques et de groupes RAID optimise et améliore les performances du stockage et est plus facile à gérer pour les administrateurs pour deux raisons :</block>
  <block id="994dbcbb2492daba25572c539cc12968" category="list-text">Un grand agrégat rend les capacités d'E/S de tous les disques disponibles pour tous les fichiers.</block>
  <block id="900188651b4134e36897865047c3fb5b" category="list-text">Définissez la valeur de la réserve d'instantanés dans le volume sur zéro pour faciliter la surveillance d'un point de vue opérationnel.</block>
  <block id="27d9533edb3ad60370502d101cd38d2b" category="list-text">Désactivez les planifications d'instantanés et les stratégies de conservation. Utilisez plutôt SnapCenter pour coordonner les copies Snapshot des volumes de données SQL Server.</block>
  <block id="a09a2d9023a555d2d5a72621bf3395b3" category="list-text">Placez les bases de données système SQL Server sur un volume dédié.</block>
  <block id="7b3c6a2d089eb1b6f8959e7e61a50c07" category="section-title">LUN</block>
  <block id="a2f15f0d2a5091a4b232a8fa89bb43f8" category="paragraph">Lorsqu'une requête est exécutée, SQL Server tente d'allouer la quantité optimale de mémoire pour s'exécuter efficacement.</block>
  <block id="a549d3d5e3e6aa1db52e782527a9664d" category="summary">Placement des fichiers de base de données Microsoft SQL Server</block>
  <block id="329282f5b4d197877079b3b130756d76" category="paragraph">Il est essentiel de placer correctement les fichiers de base de données SQL Server sur ONTAP lors de la phase de déploiement initiale. Vous bénéficiez ainsi de performances optimales, d'un temps de gestion de l'espace, de sauvegarde et de restauration qui peuvent être configurés pour répondre aux besoins de votre entreprise.</block>
  <block id="d8969d8106a5ac08f38277a3c0b813dc" category="paragraph">La possibilité de placer plusieurs fichiers de données dans le groupe de fichiers vous permet de répartir la charge entre les différents périphériques de stockage, ce qui contribue à améliorer les performances d'E/S du système. En revanche, le journal de transactions ne bénéficie pas des multiples fichiers car SQL Server écrit dans le journal de transactions de manière séquentielle.</block>
  <block id="bd87ed7f70b7f9173319df18e5b5b751" category="paragraph">Chaque fois que SQL Server augmente la taille des fichiers, il remplit l'espace nouvellement alloué avec des zéros. Ce processus bloque toutes les sessions qui doivent écrire dans le fichier correspondant ou, en cas de croissance du journal de transactions, générer des enregistrements de journal de transactions.</block>
  <block id="7a64f7e9c9b5737a434bdcc8f935c5ce" category="summary">Efficacité du stockage Microsoft SQL Server et ONTAP</block>
  <block id="9df29e7c756637e30b37f014d02117ef" category="paragraph">SQL Server lui-même dispose également de fonctionnalités pour compresser et gérer efficacement les données. SQL Server prend actuellement en charge deux types de compression de données : la compression de ligne et la compression de page.</block>
  <block id="09ddfa236e0fa1173f8d86a5ad0c148f" category="summary">Répertoire du journal Microsoft SQL Server</block>
  <block id="cc2c23339c0ad05c5ae1704b4a0ecb37" category="paragraph">Le répertoire du journal est spécifié dans SQL Server pour stocker les données de sauvegarde du journal de transactions au niveau de l'hôte. Si vous utilisez SnapCenter pour sauvegarder les fichiers journaux, chaque hôte SQL Server utilisé par SnapCenter doit disposer d'un répertoire de journaux hôte configuré pour effectuer des sauvegardes de journaux. SnapCenter dispose d'un référentiel de base de données. Les métadonnées liées aux opérations de sauvegarde, de restauration ou de clonage sont donc stockées dans un référentiel de base de données central.</block>
  <block id="59412263456ecc0573b76fe1c40d55fb" category="paragraph">ONTAP propose une solution de sécurité et de performances pour vos bases de données Microsoft SQL Server, tout en fournissant des outils de pointe pour gérer votre environnement.</block>
  <block id="e8b13d430655a3ab009ba8e90e51ce5a" category="paragraph">NetApp suppose que le lecteur a une connaissance pratique des éléments suivants :</block>
  <block id="c7f2945182947499933dea6fafeb22d3" category="summary">Placement de tempdb Microsoft SQL Server sur ONTAP</block>
  <block id="03162932e80c8f83c1ad9e36b16c1dcf" category="summary">Configuration du processeur Microsoft SQL Server</block>
  <block id="074e88cde37f7aba58ac120bbc874e77" category="paragraph">Il existe deux options de licence pour SQL Server. Le premier est connu sous le nom de modèle serveur + licence d'accès client (CAL) ; le second est le modèle par cœur de processeur. Bien que vous puissiez accéder à toutes les fonctionnalités du produit disponibles dans SQL Server avec la stratégie serveur + CAL, il existe une limite matérielle de 20 cœurs de processeur par socket. Même si vous disposez de SQL Server Enterprise Edition + CAL pour un serveur avec plus de 20 cœurs de processeur par socket, l'application ne peut pas utiliser tous ces cœurs à la fois sur cette instance.</block>
  <block id="cc3873d6002920194cf7e9dd493c5863" category="paragraph">Il est peu probable que vous ayez à modifier les valeurs par défaut de l'affinité du processeur à moins que vous ne rencontriez des problèmes de performances, mais il est toujours utile de comprendre ce qu'elles sont et comment elles fonctionnent.</block>
  <block id="4317f0d20ae625ae3139762a94175cbd" category="paragraph">Par défaut, SQL Server utilise tous les CPU disponibles pendant l'exécution d'une requête si la licence par cœur de processeur est choisie.</block>
  <block id="ff03ad08d7a38270e44c8c74372d0e7c" category="summary">Protection des bases de données Microsoft SQL Server sur ONTAP avec les commandes SnapCenter et T-SQL.</block>
  <block id="a72812111b6cfc428e19135820c476bc" category="paragraph">SnapCenter est le logiciel NetApp de protection des données pour les applications d'entreprise. Les bases de données SQL Server peuvent être protégées rapidement et facilement grâce au plug-in SnapCenter pour SQL Server et aux opérations du système d'exploitation gérées par le plug-in SnapCenter pour Microsoft Windows.</block>
  <block id="62c187efa0cd9f4191b84ae987d522c9" category="paragraph">L'instance SQL Server peut être une instance de cluster d'installation autonome ou de basculement, ou elle peut être toujours sur le groupe de disponibilité. Le résultat est que depuis une fenêtre unique, les bases de données peuvent être protégées, clonées et restaurées à partir d'une copie principale ou secondaire. SnapCenter peut gérer les bases de données SQL Server à la fois sur site, dans le cloud et dans des configurations hybrides.des copies de bases de données peuvent également être créées en quelques minutes sur l'hôte original ou alternatif à des fins de développement ou de reporting.</block>
  <block id="8a3aceb6ed4b21af2f2c00ecb032f75f" category="paragraph">Dans SQL Server 2022, Microsoft a introduit des snapshots T-SQL qui permettent de réaliser des scripts et d'automatiser les opérations de sauvegarde. Au lieu d'effectuer des copies complètes, vous pouvez préparer la base de données pour les snapshots. Une fois la base de données prête pour la sauvegarde, vous pouvez utiliser les API REST de ONTAP pour créer des snapshots.</block>
  <block id="eeeb4e610a7896c1b1f2e2ea9b3f52a0" category="list-text">Figez une base de données à l'aide de la commande ALTER. La base de données est ainsi préparée pour un snapshot cohérent sur le stockage sous-jacent. Après le gel, vous pouvez dégeler la base de données et enregistrer le snapshot avec la commande BACKUP.</block>
  <block id="fd95362fecccbbb7b017317e8bede3b5" category="admonition">Cette documentation sur ONTAP et la base de données MySQL remplace la base de données _TR-4722: Base de données MySQL sur les meilleures pratiques ONTAP._</block>
  <block id="887757e2405372a0b9e17cc054ab38f3" category="paragraph">La rapidité et l'efficacité de SnapRestore sont dues à la nature d'une copie Snapshot, qui offre essentiellement une vue en lecture seule parallèle du contenu d'un volume à un moment donné. Les blocs actifs sont les blocs réels qui peuvent être modifiés, tandis que le snapshot offre une vue en lecture seule de l'état des blocs qui constituent les fichiers et les LUN au moment de la création du snapshot.</block>
  <block id="f9b673452d1da030fef3f976bbbbb103" category="paragraph">Dans cet exemple, la base de données source se trouve sur un système ONTAP. La méthode la plus simple pour créer une sauvegarde d'une base de données consiste à utiliser un instantané. La base de données est placée en mode de sauvegarde à chaud pendant quelques secondes<block ref="252ce13e6c150af4d3e7eea5fca266bc" prefix=" " category="inline-code"></block> l'opération est exécutée sur le volume hébergeant les fichiers de données.</block>
  <block id="630a571b99791968d41f9caba4a3e39c" category="paragraph">Le résultat est un instantané sur le disque appelé<block ref="a8b3bc9f12cd194b80d404c30e9015ee" prefix=" " category="inline-code"></block> qui contient une image des fichiers de données en mode de sauvegarde à chaud. Lorsqu'elles sont combinées avec les journaux d'archivage appropriés pour assurer la cohérence des fichiers de données, les données de cet instantané peuvent servir de base à une restauration ou à un clone. Dans ce cas, il est répliqué sur le nouveau serveur.</block>
  <block id="96a1129a5a4b32943286cafd5e0ca2e1" category="paragraph">Dans cet exemple, SnapMirror est utilisé pour répliquer la sauvegarde à chaud de snapshot vers un nouvel emplacement.</block>
  <block id="0c4e214451012c456ece194f5465deb2" category="paragraph">SnapCenter inclut les fonctions de base telles que les sauvegardes et restaurations basées sur des snapshots, SnapMirror et la réplication SnapVault, ainsi que d'autres fonctionnalités nécessaires pour fonctionner à grande échelle pour les grandes entreprises. Ces fonctionnalités avancées incluent un contrôle d'accès basé sur des rôles (RBAC) étendu, des API RESTful pour l'intégration de produits d'orchestration tiers, une gestion centralisée et sans interruption des plug-ins SnapCenter sur des hôtes de base de données et une interface utilisateur conçue pour les environnements à l'échelle du cloud.</block>
  <block id="ee4b6ce05339d0d985309ece9b7d4372" category="inline-link-macro">Tr-4067 NFS sur les meilleures pratiques ONTAP</block>
  <block id="7a3ba6ac400bdd362b5db9daabcefca2" category="paragraph">Le protocole NFS comprend plusieurs versions aux exigences variables. Pour une description complète de la configuration NFS avec ONTAP, reportez-vous à la section <block ref="d594eac583da3f61bc51209142764c76" category="inline-link-macro-rx"></block>. Les sections suivantes couvrent certaines des exigences les plus critiques et des erreurs utilisateur courantes.</block>
  <block id="dabc72adea00cc712e7650b066f1d8c6" category="inline-link">Tr-4067 NFS sur les meilleures pratiques ONTAP</block>
  <block id="36911cfd2b35ef0ca97dab53c7e045f0" category="paragraph">Le passage à NFSv4 est plus compliqué que de simplement changer les options de montage de vers=3 en vers=4.1. Pour une explication plus complète de la configuration de NFSv4 avec ONTAP, notamment des conseils sur la configuration du système d'exploitation, voir<block ref="92f446ddde3e320c4e32b449cbe3112d" category="inline-link-rx"></block>. Les sections suivantes de ce TR expliquent certaines des exigences de base relatives à l'utilisation de NFSv4.</block>
  <block id="a80438f1b3354b284cf31082c45b33b3" category="summary">Infrastructure de stockage Hyper-V avec ONTAP</block>
  <block id="cfbb26e347d5746581822f8046be20c4" category="paragraph">Une infrastructure de stockage Hyper-V peut être hébergée sur des systèmes de stockage ONTAP. Le stockage d'Hyper-V pour stocker les fichiers de la machine virtuelle et ses disques peut être fourni à l'aide de LUN NetApp ou de partages CIFS NetApp, comme illustré dans la figure ci-dessous.</block>
  <block id="25aa60030552ee28c6e802f74d96f111" category="inline-image-macro">Infrastructure de stockage Hyper-V sur NetApp, largeur=624, hauteur=338</block>
  <block id="818a20c74e71223c5a644895a6dd4095" category="paragraph"><block ref="818a20c74e71223c5a644895a6dd4095" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a9c5672e01a7d0a8e068c2573fbdd4c2" category="section-title">Stockage Hyper-V sur LUN NetApp</block>
  <block id="1d9f855d005777411eca330fd3c883a1" category="inline-link-macro">Le provisionnement dans des environnements SAN</block>
  <block id="d02671c8f4f293bf5688d34f44e5b87b" category="list-text">Provisionner un LUN NetApp sur le serveur Hyper-V. Pour plus d'informations, reportez-vous à la section «<block ref="9659d1fb07c4af2143cd165cb4b6822e" category="inline-link-macro-rx"></block>."</block>
  <block id="2771a58b129233810f1c389eedd2207f" category="list-text">Ouvrez Hyper-V Manager dans la section Outils de Server Manager.</block>
  <block id="ee15a170a42b1f37e0d70bf3b367f2ee" category="list-text">Sélectionnez le serveur Hyper-V et cliquez sur Paramètres Hyper-V.</block>
  <block id="b9cc0276ae5386d0ed5e9ed31ceb340d" category="list-text">Spécifiez le dossier par défaut pour stocker la machine virtuelle et son disque en tant que LUN. Le chemin par défaut est alors défini comme LUN pour le stockage Hyper-V. Si vous souhaitez spécifier explicitement le chemin d'accès à une machine virtuelle, vous pouvez le faire lors de la création de la machine virtuelle.</block>
  <block id="72feffd29972ad4bc2fb9f5705e60864" category="inline-link-macro">Le provisionnement dans les environnements SMB</block>
  <block id="ace87f7890ab6204f4ef6abd0afaf28a" category="paragraph">Avant de commencer les étapes énumérées dans cette section, passez en revue la section «<block ref="f9d723fa339e7968f40a99719593036c" category="inline-link-macro-rx"></block>." Pour configurer le stockage Hyper-V sur le partage CIFS NetApp, effectuez les opérations suivantes :</block>
  <block id="d3f9aa7fc4289533bdeb015bbd645a22" category="list-text">Spécifiez le dossier par défaut pour stocker la machine virtuelle et son disque en tant que partage CIFS. Le chemin par défaut est alors défini comme partage CIFS pour le stockage Hyper-V. Si vous souhaitez spécifier explicitement le chemin d'accès à une machine virtuelle, vous pouvez le faire lors de la création de la machine virtuelle.</block>
  <block id="a531c67c9d6be93b7864c891efc5480a" category="paragraph">Chaque machine virtuelle d'Hyper-V peut à son tour être fournie avec les LUN NetApp et les partages CIFS fournis à l'hôte physique. Cette procédure est la même que pour tout hôte physique. Les méthodes suivantes peuvent être utilisées pour provisionner du stockage sur une VM :</block>
  <block id="b7756c6e1b92d15f0367db534aa4fdc2" category="list-text">Ajout d'une LUN de stockage à l'aide de l'initiateur FC au sein de la machine virtuelle</block>
  <block id="dda418820dd5a8b649a681b73da4ba97" category="list-text">Ajout d'une LUN de stockage à l'aide de l'initiateur iSCSI dans la machine virtuelle</block>
  <block id="ee0537a6d83f8b83e99ac0b7b3d0af82" category="list-text">Ajout d'un disque physique pass-through à une machine virtuelle</block>
  <block id="a842c008b079c30c444ab4c9d78524e6" category="list-text">Ajout de VHD/VHDX à une machine virtuelle à partir de l'hôte</block>
  <block id="50fba9282607c757ab39ad110cd0fde4" category="list-text">Lorsqu'un serveur virtuel et ses données sont stockés sur un système de stockage NetApp, NetApp recommande d'exécuter régulièrement la déduplication NetApp au niveau du volume. Cette pratique permet de réaliser d'importantes économies d'espace lorsque des machines virtuelles identiques sont hébergées sur un partage CSV ou SMB. La déduplication s'exécute sur le contrôleur de stockage et n'affecte pas le système hôte ni les performances des machines virtuelles.</block>
  <block id="6421e175d1ef977d73a52a6a90626eb8" category="list-text">Lorsque vous utilisez des LUN iSCSI pour Hyper-V, assurez-vous de les activer<block ref="0a6a9fc5db5706ee3ac704f21780cb07" prefix=" " category="inline-code"></block> et<block ref="d8ed6ba87266cde713ed7ac6c907ff7e" prefix=" " category="inline-code"></block> Dans les paramètres du pare-feu sur l'hôte Hyper-V. Le trafic iSCSI peut ainsi passer de et vers l'hôte Hyper-V et le contrôleur NetApp.</block>
  <block id="6b4ecf09c5310b6b905c86b910a57012" category="list-text">NetApp recommande de décocher l'option Autoriser le système d'exploitation de gestion à partager cette carte réseau pour le commutateur virtuel Hyper-V. Cela crée un réseau dédié pour les machines virtuelles.</block>
  <block id="d39c100d166d09a8e573d5c4980c0674" category="list-text">Le provisionnement d'une machine virtuelle à l'aide de la technologie Fibre Channel virtuelle requiert un N_Port ID Virtualisationâ€"Enabled FC HBA. Quatre ports FC au maximum sont pris en charge.</block>
  <block id="8f20505d01de58b8e00048581d2d7244" category="list-text">Si le système hôte est configuré avec plusieurs ports FC et présenté à la machine virtuelle, MPIO doit être installé dans la machine virtuelle pour activer les chemins d'accès multiples.</block>
  <block id="e003acc3eceda748125d4c7bf41052e7" category="list-text">Les disques directs ne peuvent pas être provisionnés vers l'hôte si MPIO est utilisé sur cet hôte, car les disques directs ne prennent pas en charge MPIO.</block>
  <block id="aa7c5f68a034b43fa3bafa90ea6a6c2b" category="list-text">Le disque utilisé pour les fichiers VHD/VHDx doit utiliser un formatage de 64 Ko pour l'allocation.</block>
  <block id="bc8be72fdc9d6054f356bb2b7f80fd12" category="inline-link">Matrice d'interopérabilité NetApp</block>
  <block id="34de012edea0d70cf76edda88efae407" category="list-text">Pour plus d'informations sur les HBA FC, reportez-vous au<block ref="03bbc27528de80852aa5d0d1250f8442" category="inline-link-rx"></block>.</block>
  <block id="5aa08a9ab39b4ff0ad3ec476f9c0a7a9" category="inline-link">Présentation de Hyper-V Virtual Fibre Channel</block>
  <block id="17d2fe1a1b42dbc4c914a82ff9a06cbf" category="list-text">Pour plus d'informations sur la technologie Fibre Channel virtuelle, consultez le document Microsoft<block ref="ffefda586e5fabc71f0e43393b116d4c" category="inline-link-rx"></block> page.</block>
  <block id="6736b7040d05d12679268b13fae93377" category="paragraph">Avec ODX, il est plus rapide et efficace de copier des fichiers au sein des partages SMB, au sein des LUN et entre les partages SMB et les LUN s'ils se trouvent dans le même volume. Cette approche s'avère plus utile dans le cas où plusieurs copies de l'image de référence d'un système d'exploitation (VHD/VHDX) sont requises au sein du même volume. Plusieurs copies de la même image de référence peuvent être réalisées en beaucoup moins de temps si les copies se trouvent dans le même volume. ODX est également appliqué à la migration dynamique du stockage Hyper-V pour le déplacement du stockage des machines virtuelles.</block>
  <block id="53003aec095203ae2075a8150e8ead4e" category="paragraph">Si la copie se trouve sur plusieurs volumes, les performances peuvent ne pas être nettement supérieures à celles des copies basées sur l'hôte.</block>
  <block id="80f704dacc785527bc57a7851889f8b3" category="paragraph">Pour activer la fonction ODX sur CIFS, exécutez les commandes CLI suivantes sur le contrôleur de stockage NetApp :</block>
  <block id="9c8ee5398727fdb2573f25e0535d686d" category="list-text">Activez ODX pour CIFS.
#définissez le niveau de privilège sur diagnostic
cluster:&gt; diagnostic set -privilege</block>
  <block id="574eac1c36a4e6832136e6cf051cc147" category="list-text">Pour activer la fonction ODX sur SAN, exécutez les commandes CLI suivantes sur le contrôleur de stockage NetApp :
#définissez le niveau de privilège sur diagnostic
cluster:&gt; diagnostic set -privilege</block>
  <block id="ea782640f98557c065767874aded89e7" category="list-text">Pour CIFS, ODX est disponible uniquement lorsque le client et le serveur de stockage prennent en charge SMB 3.0 et la fonction ODX.</block>
  <block id="c2dca5b1810c92e856cc04f6f2a88586" category="list-text">Pour les environnements SAN, ODX est disponible uniquement lorsque le client et le serveur de stockage prennent en charge la fonctionnalité ODX.</block>
  <block id="f41987326c80680c60b359697adfa4cc" category="inline-link">Amélioration des performances de Microsoft Remote Copy</block>
  <block id="fcb65106bb1fd73c88cf9528cb579ed5" category="inline-link">Transferts de données allégés par Microsoft</block>
  <block id="65994fb0563b49bfe0e59359edf5513d" category="paragraph">Pour plus d'informations sur ODX, voir<block ref="29f9e15a4017cdf9ae06e098a7a28381" category="inline-link-rx"></block> et<block ref="f884f78ec6d36ebebd3d9fc57e8c3734" category="inline-link-rx"></block> .</block>
  <block id="20029977789a74e480e6f8d14c07b48a" category="paragraph">Les clusters de basculement offrent une haute disponibilité et une évolutivité aux serveurs Hyper-V. Un cluster de basculement est un groupe de serveurs Hyper-V indépendants qui fonctionnent ensemble pour améliorer la disponibilité et l'évolutivité des machines virtuelles.</block>
  <block id="1b5f8c43b61e9249f3c82e39f9649160" category="section-title">Volumes partagés de cluster</block>
  <block id="c3e01cf065f02a4feb72ac75d534fa2e" category="paragraph">Les CSV permettent à plusieurs nœuds d'un cluster de basculement de disposer simultanément d'un accès en lecture/écriture vers le même LUN NetApp provisionné en tant que volume NTFS ou ReFS. Avec les CSV, les rôles en cluster peuvent basculer rapidement d'un nœud à un autre sans nécessiter de changement de propriétaire de disque, ni de démontage/remontage d'un volume. Les CSV simplifient également la gestion d'un nombre potentiellement important de LUN dans un cluster de basculement. Les CSV proposent un système de fichiers en cluster à usage général qui se superpose au-dessus de NTFS ou ReFS.</block>
  <block id="92f30d2ddb9cc7fbf92029307c6dbe98" category="inline-image-macro">Cluster de basculement Hyper-V et NetApp,largeur=624,hauteur=271</block>
  <block id="873c6f06eca771e8f918112aaf233170" category="paragraph"><block ref="873c6f06eca771e8f918112aaf233170" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7c1d777ad1068fcefc91b140eba543bf" category="list-text">NetApp recommande de désactiver les communications de cluster sur le réseau iSCSI pour empêcher les communications de cluster internes et le trafic CSV de circuler sur le même réseau.</block>
  <block id="b53334a2710cb18a4e717240b312807f" category="list-text">NetApp recommande de disposer de chemins réseau redondants (plusieurs commutateurs) pour assurer la résilience et la qualité de service.</block>
  <block id="f251ad17cf6806e0e3667148cda40e43" category="list-text">Les disques utilisés pour CSV doivent être partitionnés avec NTFS ou ReFS. Les disques formatés avec FAT ou FAT32 ne peuvent pas être utilisés pour un CSV.</block>
  <block id="161432666d89990b3c1112afe633ff8e" category="list-text">Les disques utilisés pour les CSV doivent utiliser un formatage de 64 Ko pour l'allocation.</block>
  <block id="36cf7806cbb55a382b64bd9b65b2939b" category="inline-link-macro">Déployez le cluster Hyper-V.</block>
  <block id="390167e852a9bfc97d6ed31462a05b2f" category="paragraph">Pour plus d'informations sur le déploiement d'un cluster Hyper-V, reportez-vous à l'Annexe B : <block ref="8a150f92c22920868769b8738759e23d" category="inline-link-macro-rx"></block>.</block>
  <block id="32730f5882545bbe6a81ac49049968f0" category="section-title">Hyper-V Live migration : migration de machines virtuelles</block>
  <block id="d7f2f7b4116921a3d8d4b8e5892420a7" category="paragraph">Il est parfois nécessaire pendant toute la durée de vie des machines virtuelles de les déplacer vers un autre hôte du cluster Windows. Cela peut être nécessaire si l'hôte manque de ressources système ou si l'hôte doit redémarrer pour des raisons de maintenance. De même, il peut être nécessaire de déplacer une machine virtuelle vers une autre LUN ou un autre partage SMB. Cette condition peut être nécessaire si l'espace du LUN ou du partage actuel est insuffisant ou présente des performances inférieures à la valeur attendue. La migration dynamique Hyper-V déplace les machines virtuelles en cours d'exécution d'un serveur Hyper-V physique vers un autre sans affecter la disponibilité des machines virtuelles pour les utilisateurs. Vous pouvez migrer en direct des machines virtuelles entre des serveurs Hyper-V faisant partie d'un cluster de basculement ou entre des serveurs Hyper-V indépendants qui ne font pas partie d'un cluster.</block>
  <block id="92829881718abd402c6c73b34be944da" category="section-title">Migration dynamique dans un environnement en cluster</block>
  <block id="e8881f62af8c1495a1f4869b97e95505" category="paragraph">Les machines virtuelles peuvent être déplacées de manière transparente entre les nœuds d'un cluster. La migration des machines virtuelles est instantanée, car tous les nœuds du cluster partagent le même stockage et ont accès à la machine virtuelle et à son disque. La figure suivante illustre la migration en direct dans un environnement en cluster.</block>
  <block id="8cda6697809dd81e112a12c43f6f89f4" category="inline-image-macro">Migration dynamique dans un environnement en cluster,largeur=580,hauteur=295</block>
  <block id="d668981cacbbf412643956687c03fc0d" category="paragraph"><block ref="d668981cacbbf412643956687c03fc0d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4797d6b2727c9902e114fa95ed076fc2" category="list-text">Disposer d'un port dédié pour le trafic de migration en direct.</block>
  <block id="7c021f26d9ab2ec9934fc24d167ceaa4" category="list-text">Disposer d'un réseau dédié de migration dynamique des hôtes pour éviter les problèmes liés au réseau pendant la migration.</block>
  <block id="a725857d2338d476a409fd1fb67b1f56" category="inline-link-macro">Annexe C : déploiement de la migration dynamique Hyper-V dans un environnement en cluster</block>
  <block id="45f7134e494aae2cba3b60b3fe769caa" category="paragraph">Pour plus d'informations sur le déploiement de la migration dynamique dans un environnement en cluster, reportez-vous à la section <block ref="b584c2d96a6b139fbe05976580afae94" category="inline-link-macro-rx"></block>.</block>
  <block id="07cb5e9c694ee3a8dcc475a38371ad5c" category="paragraph">Il est possible de migrer un serveur virtuel en direct entre deux serveurs Hyper-V indépendants non mis en cluster. Ce processus peut utiliser une migration dynamique sans partage ou partagée.</block>
  <block id="87b94a12a79a6dbc08decd540810bb26" category="inline-image-macro">Migration dynamique partagée dans un environnement non mis en cluster,largeur=331,hauteur=271</block>
  <block id="f442dd66197cc65f49ad8ec9c50e8076" category="paragraph"><block ref="f442dd66197cc65f49ad8ec9c50e8076" category="inline-image-macro-rx" type="image"></block></block>
  <block id="207d1150dff7488c7f8bfafe7036a222" category="list-text">Dans le cas d'une migration dynamique sans partage, chaque serveur Hyper-V dispose de son propre stockage local (il peut s'agir d'un partage SMB, d'une LUN ou d'un DAS) et le stockage de la machine virtuelle est local sur son serveur Hyper-V. Lors de la migration en direct d'une machine virtuelle, le stockage de la machine virtuelle est mis en miroir sur le serveur de destination via le réseau client, puis la machine virtuelle est migrée. La machine virtuelle stockée sur le DAS, une LUN ou un partage SMB/CIFS peut être déplacée vers un partage SMB/CIFS sur l'autre serveur Hyper-V, comme illustré dans la figure ci-dessous. Il est également possible de le déplacer vers une LUN, comme illustré dans la seconde figure.</block>
  <block id="8df9231bc9de1239aa92c6a9d1116db4" category="inline-image-macro">Migration dynamique sans partage dans un environnement non mis en cluster vers des partages SMB,largeur=624,hauteur=384</block>
  <block id="c6acea552c059bcc9ccb207ad6b8cee1" category="paragraph"><block ref="c6acea552c059bcc9ccb207ad6b8cee1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="559b3e5c1d4ea7b8f3eaf8cbc0e4155e" category="inline-image-macro">Migration dynamique sans partage dans un environnement non mis en cluster vers des LUN,largeur=624,hauteur=384</block>
  <block id="3d0d53528ff4699abb6fab11a6bf756d" category="paragraph"><block ref="3d0d53528ff4699abb6fab11a6bf756d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b19cfe6ea61be3a5ed442a8a975a6406" category="inline-link-macro">Annexe D : déploiement de la migration dynamique Hyper-V en dehors d'un environnement en cluster</block>
  <block id="b7c375b5c0ef95eecd45b0a4614c2c68" category="paragraph">Pour plus d'informations sur le déploiement de la migration dynamique en dehors d'un environnement en cluster, reportez-vous à la section <block ref="52490817f607e6265e62f91bb3c3799a" category="inline-link-macro-rx"></block>.</block>
  <block id="061731a1a3266df0eda8efe87e649dbb" category="section-title">Hyper-V Storage Live migration</block>
  <block id="ecaa2ddd351a3f5a9704aaea9a13abaf" category="paragraph">Au cours de la durée de vie d'un serveur virtuel, vous devrez peut-être déplacer le stockage du serveur virtuel (VHD/VHDX) vers un autre LUN ou partage SMB. Cette condition peut être nécessaire si l'espace du LUN ou du partage actuel est insuffisant ou présente des performances inférieures à la valeur attendue.</block>
  <block id="1f976b42d4bb2c18a943d132252997d6" category="paragraph">La LUN ou le partage qui héberge actuellement la machine virtuelle peut être à court d'espace, reconverti ou offre des performances réduites. Dans ces circonstances, la machine virtuelle peut être déplacée sans interruption vers une autre LUN ou un autre partage sur un autre volume, agrégat ou cluster. Ce processus est plus rapide si le système de stockage dispose de fonctionnalités de copie auxiliaire. Les systèmes de stockage NetApp sont dotés de la fonctionnalité de copie auxiliaire activée par défaut dans les environnements CIFS et SAN.</block>
  <block id="bbaae8d50419225b92db654852107b29" category="paragraph">La fonctionnalité ODX effectue des copies de fichiers complets ou de sous-fichiers entre deux répertoires résidant sur des serveurs distants. Une copie est créée en copiant les données entre les serveurs (ou le même serveur si les fichiers source et de destination se trouvent tous deux sur le même serveur). La copie est créée sans que le client ait lu les données à partir de la source ou écrit dans la destination. Ce processus réduit l'utilisation du processeur et de la mémoire pour le client ou le serveur et réduit la bande passante E/S du réseau. La copie est plus rapide si elle se trouve dans le même volume. Si la copie se trouve sur plusieurs volumes, les performances peuvent ne pas être nettement supérieures à celles des copies basées sur l'hôte. Avant de procéder à une opération de copie sur l'hôte, vérifiez que les paramètres de déchargement de copie sont configurés sur le système de stockage.</block>
  <block id="843c69ad55fb8bac002321dee51a4770" category="paragraph">Lorsque la migration dynamique du stockage de machine virtuelle est initiée à partir d'un hôte, la source et la destination sont identifiées, et l'activité de copie est déchargée sur le système de stockage. Étant donné que l'activité est effectuée par le système de stockage, l'utilisation du processeur, de la mémoire ou du réseau de l'hôte est négligeable.</block>
  <block id="27d2fda0da241bb37583fba1af25cd09" category="paragraph">Les contrôleurs de stockage NetApp prennent en charge les différents scénarios d'ODX suivants :</block>
  <block id="48a53ae81ff0c821cba0e11bd2383bf3" category="list-text">*IntraSVM.* les données sont détenues par le même SVM :</block>
  <block id="ec3d44fd176b5d51f4f60dff319cea6b" category="list-text">*Intravope, intranode.* les fichiers source et de destination ou les LUN résident dans le même volume. La copie s'effectue à l'aide de la technologie de fichiers FlexClone, ce qui offre d'autres avantages en termes de performances de copie à distance.</block>
  <block id="980ca02c9855a39b86e9fbf5acd955b4" category="list-text">*Intervolue, intranode.* les fichiers source et de destination ou les LUN se trouvent sur des volumes différents qui se trouvent sur le même nœud.</block>
  <block id="8a4d33d47a803a1796b431a0df5a8016" category="list-text">*Intervolue, internœuds.* les fichiers source et de destination ou les LUN se trouvent sur des volumes différents situés sur des nœuds différents.</block>
  <block id="81d5c73c98489729a8f91afe4936dbd2" category="list-text">*InterSVM.* les données appartiennent à différents SVM.</block>
  <block id="ea9799ac312b9050a36864c98be8f73f" category="list-text">*Intervolue, internœuds.* les fichiers source et de destination ou les LUN se trouvent sur des volumes différents qui se trouvent sur des nœuds différents.</block>
  <block id="3693f5a47e6bfc0762c5b2c174e653be" category="list-text">*Intercluster.* depuis ONTAP 9.0, ODX est également pris en charge pour les transferts de LUN intercluster dans des environnements SAN. ODX intercluster est pris en charge pour les protocoles SAN uniquement, et non pour SMB.</block>
  <block id="8e459b300b9b5f521f0cc464bc1a7137" category="paragraph">Une fois la migration terminée, les règles de sauvegarde et de réplication doivent être reconfigurées pour refléter le nouveau volume contenant les machines virtuelles. Les sauvegardes précédentes qui ont été effectuées ne peuvent pas être utilisées.</block>
  <block id="9cabe6ff649f754acc3a863e852828e8" category="paragraph">Le stockage des serveurs virtuels (VHD/VHDX) peut être migré entre les types de stockage suivants :</block>
  <block id="49a63af944b72883bd718eb8c8ff01c8" category="list-text">Le stockage DAS et le partage SMB</block>
  <block id="85fbd1c03217c7c62157aac97d16ecf9" category="list-text">DAS et LUN</block>
  <block id="876c6424f49d57e8be596b8caadf5a61" category="list-text">Un partage SMB et un LUN</block>
  <block id="1518cb86dc78f6083ed8b1d292b87ed8" category="list-text">Entre LUN</block>
  <block id="7257cd316393b74da62868c27652c6c0" category="list-text">Entre partages SMB</block>
  <block id="17785c3ef4bbda06e9db9c15908dc0c6" category="inline-image-macro">Migration dynamique du stockage Hyper-V, largeur=339, hauteur=352</block>
  <block id="eccf932baf8f6019c69035ea09e26c2c" category="paragraph"><block ref="eccf932baf8f6019c69035ea09e26c2c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="319572d5872182625e2834b8615517f2" category="inline-link-macro">Annexe E : déploiement de la migration dynamique du stockage Hyper-V.</block>
  <block id="04a136595cb35e5c42e3ea764e9cd259" category="paragraph">Pour plus d'informations sur le déploiement de la migration dynamique du stockage, reportez-vous à la section <block ref="e0d213bcf75379722df0c1b3af5063a2" category="inline-link-macro-rx"></block>.</block>
  <block id="86174aa4d77b1853f72b6e1a6f32c753" category="paragraph">Le réplica Hyper-V réplique les machines virtuelles Hyper-V depuis un site principal vers des machines virtuelles de réplica sur un site secondaire, assurant ainsi une reprise après incident asynchrone pour les machines virtuelles. Le serveur Hyper-V sur le site principal hébergeant les machines virtuelles est appelé serveur principal ; le serveur Hyper-V sur le site secondaire qui reçoit les machines virtuelles répliquées est appelé serveur de réplica. Un exemple de scénario de réplica Hyper-V est illustré dans la figure suivante. Vous pouvez utiliser Hyper-V Replica pour les machines virtuelles entre des serveurs Hyper-V faisant partie d'un cluster de basculement ou entre des serveurs Hyper-V indépendants qui ne font pas partie d'un cluster.</block>
  <block id="28e90920ae557bd81a8056f93fb4b0ee" category="inline-image-macro">Réplique Hyper-V,largeur=624,hauteur=201</block>
  <block id="4fc821418df9e4488323cc70692d5083" category="paragraph"><block ref="4fc821418df9e4488323cc70692d5083" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8c340dc334134096f68b880b42a8692c" category="section-title">La réplication</block>
  <block id="b9bce4677e5b3ea1c310fddca6123c9f" category="paragraph">Lorsque Hyper-V Replica est activé pour une machine virtuelle sur le serveur principal, la réplication initiale crée une machine virtuelle identique sur le serveur de réplica. Après la réplication initiale, Hyper-V Replica conserve un fichier journal pour les VHD de la machine virtuelle. Le fichier journal est relu dans l'ordre inverse vers le VHD de réplica en fonction de la fréquence de réplication. Ce journal et l'utilisation de l'ordre inverse permettent de s'assurer que les dernières modifications sont stockées et répliquées de manière asynchrone. Si la réplication ne se produit pas conformément à la fréquence attendue, une alerte est émise.</block>
  <block id="ec9fc8b78968b1d0daadf7598a4e2ab6" category="paragraph">Hyper-V Replica prend en charge la réplication étendue dans laquelle un serveur de réplica secondaire peut être configuré pour la reprise après incident. Un serveur de réplica secondaire peut être configuré pour que le serveur de réplica reçoive les modifications sur les machines virtuelles de réplica. Dans un scénario de réplication étendue, les modifications apportées aux machines virtuelles primaires du serveur principal sont répliquées sur le serveur de réplica. Les modifications sont ensuite répliquées sur le serveur de réplica étendu. Les machines virtuelles peuvent être défaillantes vers le serveur de réplica étendu uniquement lorsque les serveurs principal et de réplica sont en panne.</block>
  <block id="a3f36244dba1d116dac91134dda3b9db" category="paragraph">Le basculement n'est pas automatique. Le processus doit être déclenché manuellement. Il existe trois types de basculement :</block>
  <block id="f8487dcb10cf762a4d3f28da4635bd2a" category="list-text">*Test failover.* ce type est utilisé pour vérifier qu'une machine virtuelle de réplica peut démarrer avec succès sur le serveur de réplica et qu'elle est lancée sur la machine virtuelle de réplica. Ce processus crée une machine virtuelle de test en double lors du basculement, sans affecter la réplication de production normale.</block>
  <block id="09f4056fddf2108616fe7bf3194540ba" category="list-text">*Basculement planifié.* ce type est utilisé pour basculer les machines virtuelles pendant les temps d'arrêt planifiés ou les interruptions prévues. Ce processus est lancé sur la machine virtuelle principale, qui doit être désactivée sur le serveur principal avant l'exécution d'un basculement planifié. Après le basculement de la machine, Hyper-V Replica démarre la machine virtuelle de réplica sur le serveur de réplica.</block>
  <block id="0ad8df7e141c378e7ad1debc5721cecf" category="list-text">*Basculement non planifié.* ce type est utilisé lorsque des pannes inattendues se produisent. Ce processus est lancé sur la machine virtuelle de réplica et ne doit être utilisé que si la machine principale échoue.</block>
  <block id="d8afbc541b39d23648c823057cffe3a5" category="section-title">Reprise après incident</block>
  <block id="53b169078c7c6ecee01802b49b675c54" category="paragraph">Lorsque vous configurez la réplication pour une machine virtuelle, vous pouvez spécifier le nombre de points de restauration. Les points de restauration représentent des points dans le temps à partir desquels les données peuvent être récupérées à partir d'une machine répliquée.</block>
  <block id="31e96602ee944674a6ee07052bc6552a" category="inline-link-macro">Déploiement d'un réplica Hyper-V en dehors d'un environnement en cluster</block>
  <block id="fd09d6344b235cdd2863e5027a2716e8" category="list-text">Pour plus d'informations sur le déploiement d'un réplica Hyper-V en dehors d'un environnement en cluster, reportez-vous à la section «<block ref="376f647d5b86bfed7dfffbd7c50e7d1e" category="inline-link-macro-rx"></block>."</block>
  <block id="23b6fa788d78e992f84931ddd3cef629" category="inline-link-macro">Déployez le réplica Hyper-V dans un environnement en cluster</block>
  <block id="a3538f75015c27ee42ac1f1c0b535a61" category="list-text">Pour plus d'informations sur le déploiement d'un réplica Hyper-V dans un environnement en cluster, reportez-vous à la section «<block ref="e81baea973ee37d0bb61473f872cfb84" category="inline-link-macro-rx"></block>."</block>
  <block id="57a0eb5139789611b6b213a5f3fa5412" category="summary">Cette annexe décrit le déploiement d'un cluster Hyper-V haute disponibilité sur un système de stockage NetApp.</block>
  <block id="e286734bc8843e9f46f2812455917ea5" category="paragraph">Cette annexe décrit le déploiement d'un cluster Hyper-V.</block>
  <block id="fa0edb5816386e7e049e5c77d9cdb367" category="list-text">Au moins deux serveurs Hyper-V sont connectés l'un à l'autre.</block>
  <block id="a7bad6853c4b367ee245a88ab3195af0" category="list-text">Au moins un commutateur virtuel est configuré sur chaque serveur Hyper-V.</block>
  <block id="ebdc83ef4c8d2993b67ae667bcb0cd50" category="list-text">La fonctionnalité cluster de basculement est activée sur chaque serveur Hyper-V.</block>
  <block id="65e98c7fa4c69ce7bd0d182ede13991a" category="list-text">Les partages SMB ou les CSV sont utilisés comme stockage partagé pour stocker les machines virtuelles et leurs disques pour la mise en cluster Hyper-V.</block>
  <block id="22f4b86bcfebce25bb61ddd3ee8d6f7f" category="list-text">Le stockage ne doit pas être partagé entre des clusters différents. Vous ne devez avoir qu'un seul partage CSV/CIFS par cluster.</block>
  <block id="c2377be670723e586c1324a4a12607a5" category="list-text">Si le partage SMB est utilisé comme stockage partagé, les autorisations sur le partage SMB doivent être configurées de manière à accorder l'accès aux comptes ordinateur de tous les serveurs Hyper-V du cluster.</block>
  <block id="ea355214fd4bc7c57f471bd92918879b" category="section-title">Déploiement</block>
  <block id="3627e168149dcf185918371a7adb5680" category="list-text">Connectez-vous à l'un des serveurs Windows Hyper-V en tant que membre du groupe d'administrateurs.</block>
  <block id="0cc618f3a272a1fc35b193fc6efa1122" category="list-text">Démarrez Server Manager**.**</block>
  <block id="f30124a5c887cea53cc6397d6c9e40a6" category="list-text">Dans la section Outils, cliquez sur Gestionnaire de clusters de basculement.</block>
  <block id="54be8be618f1803d7fc1579e2fad9a6c" category="list-text">Cliquez sur le menu Créer un cluster à partir des actions.</block>
  <block id="6bcb4b141d153c7cee9fc6b2633a703c" category="list-text">Fournir des détails sur le serveur Hyper-V qui fait partie de ce cluster.</block>
  <block id="58ee4cb30b6b0dd4665be3c60c65e0f1" category="list-text">Validez la configuration du cluster. Sélectionnez Oui lorsque vous êtes invité à valider la configuration du cluster, puis sélectionnez les tests requis pour vérifier si les serveurs Hyper-V satisfont aux conditions préalables requises pour faire partie du cluster.</block>
  <block id="8a2ec0e7f4a4ecb848794b1aba47839b" category="list-text">Une fois la validation réussie, l'assistant de création de cluster démarre. Dans l'assistant, indiquez le nom du cluster et l'adresse IP du nouveau cluster. Un nouveau cluster de basculement est ensuite créé pour le serveur Hyper-V.</block>
  <block id="ce73c2e33e5d228466b28690400c8c14" category="list-text">Cliquez sur le nouveau cluster créé dans Failover Cluster Manager et gérez-le.</block>
  <block id="904aa93ec80c2a5ca93ed8ace0e52220" category="list-text">Définir le stockage partagé à utiliser par le cluster. Il peut s'agir d'un partage SMB ou d'un fichier CSV.</block>
  <block id="d69f1a0923232e84331ec6d30315124c" category="list-text">L'utilisation d'un partage SMB comme stockage partagé ne nécessite pas d'étapes spéciales.</block>
  <block id="3b045123cc5f216c3aa18614a4cabf45" category="list-text">Configurez un partage CIFS sur un contrôleur de stockage NetApp. Pour ce faire, reportez-vous à la section «<block ref="f9d723fa339e7968f40a99719593036c" category="inline-link-macro-rx"></block>«.</block>
  <block id="c0edb31f94845e5a1f67d2f79db4408f" category="list-text">Pour utiliser un fichier CSV comme stockage partagé, procédez comme suit :</block>
  <block id="dfd86a662700832b7931201c3abdf13f" category="list-text">Configurer les LUN sur un contrôleur de stockage NetApp Pour ce faire, reportez-vous à la section « provisionnement dans les environnements SAN ».</block>
  <block id="49873862ecc43076ac3a4de327f3efdb" category="list-text">Assurez-vous que tous les serveurs Hyper-V du cluster de basculement peuvent voir les LUN NetApp. Pour ce faire pour tous les serveurs Hyper-V faisant partie du cluster de basculement, assurez-vous que leurs initiateurs sont ajoutés au groupe initiateur sur le stockage NetApp. Assurez-vous également que leurs LUN sont détectées et que MPIO est activé.</block>
  <block id="4fe4609b22418e84ea85667368c2e742" category="list-text">Sur l'un des serveurs Hyper-V du cluster, effectuez les opérations suivantes :</block>
  <block id="de824a62ee353b5481bb4eeb5c13d899" category="list-text">Mettre la LUN en ligne, initialiser le disque, créer un nouveau volume simple et le formater à l'aide de NTFS ou de ReFS.</block>
  <block id="340f3a4d7fad2c45eadfe69d5b56ce38" category="list-text">Dans le Gestionnaire de clusters de basculement, développez le cluster, développez stockage, cliquez avec le bouton droit de la souris sur disques, puis cliquez sur Ajouter des disques. L'assistant Ajouter des disques à un cluster s'ouvre alors et affiche la LUN comme disque. Cliquez sur OK pour ajouter la LUN en tant que disque.</block>
  <block id="a685089b1d550296b9407033a7411217" category="list-text">La LUN s'appelle désormais disque en cluster et est affichée comme stockage disponible sous disques.</block>
  <block id="2970ece9496766e632c3e2c23145cfcf" category="list-text">Cliquez avec le bouton droit de la souris sur la LUN (disque en cluster), puis cliquez sur Ajouter aux volumes partagés du cluster. La LUN s'affiche désormais au format CSV.</block>
  <block id="c473a447596255e12e2e772012c42b17" category="list-text">Le CSV est visible et accessible simultanément depuis tous les serveurs Hyper-V du cluster de basculement à son emplacement local C:\ClusterStorage\.</block>
  <block id="b735c11dd95d1b42d173adb43b3a1df2" category="list-text">Créer un serveur virtuel hautement disponible :</block>
  <block id="27f977a1c170f87899be67daf203a268" category="list-text">Dans Failover Cluster Manager, sélectionnez et développez le cluster créé précédemment.</block>
  <block id="569f3bea800216a760ac935540b72c1e" category="list-text">Cliquez sur rôles, puis sur machines virtuelles dans actions. Cliquez sur Nouvelle machine virtuelle.</block>
  <block id="4380a9c5c56776fad0f4492a0d3c63f5" category="list-text">Sélectionnez dans le cluster le nœud sur lequel la machine virtuelle doit résider.</block>
  <block id="a8be7e73ae88a070ad15a4a6f6d515fe" category="list-text">Dans l'assistant Virtual machine Creation (création d'une machine virtuelle), indiquez le stockage partagé (partage SMB ou CSV) comme chemin d'accès pour stocker la machine virtuelle et ses disques.</block>
  <block id="9da4e10b0da989c65844cd59ed2a0991" category="list-text">Utilisez Hyper-V Manager pour définir le stockage partagé (partage SMB ou CSV) comme chemin par défaut pour stocker la machine virtuelle et ses disques pour un serveur Hyper-V.</block>
  <block id="064cd683bf50cb65205de6b9298201b3" category="list-text">Tester le basculement non planifié. Arrêtez le service de cluster sur le serveur propriétaire de la machine virtuelle.</block>
  <block id="c7bfaead2ee1aea320b1d91da7ba31d7" category="summary">En savoir plus sur le stockage NetApp et l'environnement de serveur Windows</block>
  <block id="5c8c98e7f403562b754941b4d0c17f65" category="paragraph">Comme indiqué dans le <block ref="ba92ae7cf3bb4a058d2b231c16067714" category="inline-link-macro-rx"></block>, Les contrôleurs de stockage NetApp offrent une architecture réellement unifiée qui prend en charge les protocoles de fichiers, de blocs et d'objets. Notamment SMB/CIFS, NFS, NVMe/TCP, NVMe/FC, iSCSI, FC(FCP) et S3 créent un accès client et hôte unifié. Le même contrôleur de stockage peut fournir simultanément un service de stockage bloc sous la forme de LUN SAN et de service de fichiers comme NFS et SMB/CIFS. ONTAP est également disponible en tant que baie 100 % SAN (ASA) qui optimise l'accès à l'hôte via des chemins d'accès multiples symétriques actif-actif avec iSCSI et FCP, tandis que les systèmes ONTAP unifiés utilisent des chemins d'accès multiples asymétriques actifs/actifs. Dans les deux modes, ONTAP utilise ANA pour la gestion des chemins d'accès multiples NVMe over Fabrics (NVMe-of).</block>
  <block id="b39d47dbcb48e2064ea0978dea0793ae" category="list-text">Machines virtuelles hébergées dans des partages SMB 3.0 disponibles en continu</block>
  <block id="be1d5dd432dd053b97f14401fc060813" category="list-text">Serveurs virtuels hébergés sur des LUN CSV (Cluster Shared Volume) s'exécutant sur iSCSI ou FC</block>
  <block id="fc27a7625c9ffb2fe9dd539f1960c978" category="list-text">Bases de données SQL Server sur partages SMB 3.0</block>
  <block id="658f98073361780ad39f8c0d45eca2f8" category="list-text">Bases de données SQL Server sur NVMe-of, iSCSI ou FC</block>
  <block id="d2ed21657f98def30346884514f11cce" category="list-text">Autres charges de travail applicatives</block>
  <block id="b7da44d6d6578097c611512549b04555" category="paragraph">Par ailleurs, les fonctionnalités d'efficacité du stockage NetApp telles que la déduplication, les copies NetApp FlexClone ®, la technologie Snapshot NetApp, le provisionnement fin, la compression, de plus, le Tiering du stockage apporte une valeur ajoutée considérable aux charges de travail exécutées sur Windows Server.</block>
  <block id="b76d8ce5a4b5758745257d0223494701" category="section-title">Gestion des données ONTAP</block>
  <block id="37b74b1418c82d2f0f3a093c4da8e7de" category="paragraph">ONTAP est un logiciel de gestion qui s'exécute sur un contrôleur de stockage NetApp. Appelé nœud, le contrôleur de stockage NetApp est un périphérique matériel doté d'un processeur, d'une mémoire RAM et d'une mémoire NVRAM. Le nœud peut être connecté à des disques SATA, SAS ou SSD, ou à une combinaison de ces disques.</block>
  <block id="16e8274a6170bfb8f7a4b80869edaca0" category="paragraph">Plusieurs nœuds sont agrégés dans un système en cluster. Les nœuds du cluster communiquent entre eux de manière continue pour coordonner les activités du cluster. Les nœuds peuvent également déplacer les données de manière transparente d'un nœud à l'autre à l'aide de chemins redondants vers un réseau de clusters dédié composé de deux commutateurs Ethernet 10 Gbit/s. Les nœuds du cluster peuvent se prendre en charge pour assurer une haute disponibilité dans tous les scénarios de basculement. Les clusters sont administrés dans l'ensemble du cluster plutôt que par nœud, tandis que les données sont servies depuis un ou plusieurs serveurs virtuels de stockage (SVM). Un cluster doit disposer d'au moins un SVM pour assurer le service des données.</block>
  <block id="a93b9d090163c0668a090fac714f7578" category="paragraph">L'unité de base d'un cluster est le nœud, et des nœuds sont ajoutés au cluster dans le cadre d'une paire haute disponibilité. Les paires HAUTE DISPONIBILITÉ assurent une haute disponibilité en communiquant les unes avec les autres via une interconnexion haute disponibilité (distincte du réseau de cluster dédié) et en maintenant des connexions redondantes aux disques de la paire haute disponibilité. Les disques ne sont pas partagés entre les paires haute disponibilité, bien que les tiroirs puissent contenir des disques appartenant à l'un ou l'autre des membres d'une paire haute disponibilité. La figure suivante illustre le déploiement d'un système de stockage NetApp dans un environnement Windows Server.</block>
  <block id="4472647bb1219b68f4b76e737a20ce52" category="inline-image-macro">Déploiement du stockage NetApp dans un environnement Windows Server,largeur=624,hauteur=479</block>
  <block id="79ea3c938053f84aab6e3d9a963056f6" category="paragraph"><block ref="79ea3c938053f84aab6e3d9a963056f6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7df39ad25b0e96b5a09cafef15c90e83" category="paragraph">Un SVM ONTAP est un serveur de stockage logique qui permet d'accéder aux données des LUN et/ou d'un espace de noms NAS à partir d'une ou plusieurs interfaces logiques (LIF). La SVM est donc l'unité de base de segmentation du stockage qui permet une colocation sécurisée dans ONTAP. Chaque SVM est configuré pour ses propres volumes de stockage provisionnés à partir d'un agrégat physique et d'interfaces logiques (LIF) attribuées à un réseau Ethernet physique ou à des ports cibles FC.</block>
  <block id="ded35f53d6a4c12f9aa23622a273290c" category="paragraph">Des disques logiques (LUN) ou des partages CIFS sont créés au sein des volumes d'un SVM et sont mappés sur des hôtes et des clusters Windows afin de leur fournir de l'espace de stockage, comme illustré dans la figure ci-dessous. Les SVM sont indépendants des nœuds et basés sur le cluster. Ils peuvent utiliser des ressources physiques telles que des volumes ou des ports réseau n'importe où dans le cluster.</block>
  <block id="66bfba6c82925242c27d2f07403b627e" category="inline-image-macro">Machine virtuelle de stockage ONTAP, largeur=572, hauteur=443</block>
  <block id="9bcb5e161ae4c106ccd0f2dc96989097" category="paragraph"><block ref="9bcb5e161ae4c106ccd0f2dc96989097" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8f64c369fcdc9c990f5540ce53430671" category="paragraph">Le stockage peut être provisionné sur Windows Server dans les environnements SAN et NAS. Dans un environnement SAN, le stockage est fourni sous forme de disques provenant de LUN sur un volume NetApp en tant que stockage en mode bloc. Dans un environnement NAS, le stockage est fourni sous forme de partages CIFS/SMB sur des volumes NetApp comme stockage de fichiers. Ces disques et partages peuvent être appliqués dans Windows Server comme suit :</block>
  <block id="8572daf67b8cf4929b8a104909d42a03" category="list-text">Stockage pour les hôtes Windows Server pour les charges de travail applicatives</block>
  <block id="460622219d2e0a7fe2d7339d37894127" category="list-text">Stockage pour Nano Server et conteneurs</block>
  <block id="24148b9d626dc3494e0f1a07f5ddf180" category="list-text">Stockage des hôtes Hyper-V individuels pour stocker les machines virtuelles</block>
  <block id="c9d2a95802a3dc0a7c1033928d3cfc3f" category="list-text">Stockage partagé pour les clusters Hyper-V sous la forme de CSV pour le stockage des machines virtuelles</block>
  <block id="76c319d8818e93b50538dff2f4427cbc" category="list-text">Stockage pour bases de données SQL Server</block>
  <block id="13a4fb282282699692756c149d94bbbe" category="paragraph">Pour connecter, configurer et gérer le stockage NetApp à partir de Windows Server 2016, utilisez l'une des méthodes suivantes :</block>
  <block id="81ef8774b45c60d7387b0e91d9c4eb05" category="list-text">*Secure Shell (SSH).* utilisez n'importe quel client SSH sur Windows Server pour exécuter les commandes CLI de NetApp.</block>
  <block id="935df6062271011aad64300fe0f8a6c7" category="list-text">*System Manager.* il s'agit du produit de gestion basé sur l'interface graphique de NetApp.</block>
  <block id="85c7991eb4ed1078ecb54aacffe3a3a2" category="list-text">*Boîte à outils PowerShell NetApp.* il s'agit du kit d'outils PowerShell NetApp pour l'automatisation et la mise en œuvre de scripts et de flux de travail personnalisés.</block>
  <block id="1fb25b443082bb79703b1237630cd9b6" category="section-title">Kit NetApp PowerShell</block>
  <block id="a5038d870bfecae7a8fb1fb0d8ba892b" category="list-text">NetApp ne prend pas en charge les espaces de stockage Windows Server. Les espaces de stockage sont utilisés uniquement pour JBOD (une simple concaténation de disques) et ne fonctionnent avec aucun type RAID (stockage DAS ou SAN).</block>
  <block id="b37ae3efea13417cff3fdb198db41274" category="list-text">Les pools de stockage en cluster dans Windows Server ne sont pas pris en charge par ONTAP.</block>
  <block id="436593f3429fec64588705fe44025823" category="list-text">NetApp prend en charge le format de disque dur virtuel partagé (VHDX) pour une mise en cluster invitée dans les environnements SAN Windows.</block>
  <block id="a3a862b96d666cb7005617313f703378" category="list-text">Windows Server ne prend pas en charge la création de pools de stockage à l'aide de LUN iSCSI ou FC.</block>
  <block id="570d38aae09bbf84ba37f9219909a7cb" category="list-text">Pour plus d'informations sur le kit NetApp PowerShell, rendez-vous sur le<block ref="12f72d9ce1eab5b7cd58718fecdd145c" category="inline-link-rx"></block>.</block>
  <block id="699f0a44719fb3de5404046fc6caa8af" category="inline-link">Tr-4475 : guide des bonnes pratiques du kit NetApp PowerShell</block>
  <block id="532d077f114744273b1a7cd2a4794077" category="list-text">Pour plus d'informations sur les bonnes pratiques du kit NetApp PowerShell, reportez-vous à la section<block ref="87b47631a9123c9d2a382039a9ba503e" category="inline-link-rx"></block>.</block>
  <block id="64f3248fbae79dd41841377bf7dd37c6" category="paragraph">Les réseaux Ethernet peuvent être répartis de manière large en plusieurs groupes :</block>
  <block id="0047d4a23ffec6d4afe912d0a2598e58" category="list-text">Un réseau client pour les VM</block>
  <block id="d6cf6da705ce58c7b649fea1cd43c470" category="list-text">Un autre réseau de stockage (connexion iSCSI ou SMB aux systèmes de stockage)</block>
  <block id="0d8658721aaab8eb43f9b6d72283b8f8" category="list-text">Un réseau de communication en cluster (battement de cœur et autre communication entre les nœuds du cluster)</block>
  <block id="338c97ec16c135df1c972ba5b92db129" category="list-text">Un réseau de gestion (pour surveiller et dépanner le système)</block>
  <block id="7b6753ef35b59e8866faf1b43b213520" category="list-text">Un réseau de migration (pour la migration en direct des hôtes)</block>
  <block id="0f31fc2f15105bd45773e0fe5a33814a" category="list-text">Réplication de machine virtuelle (réplication Hyper-V)</block>
  <block id="11ef3cd9dc7173f009417493a7a51f57" category="list-text">NetApp recommande de disposer de ports physiques dédiés à chacune des fonctionnalités précédentes pour l'isolation du réseau et les performances.</block>
  <block id="84f729d0d6ae07e1ea7697e418337328" category="list-text">Pour chacune des exigences réseau précédentes (à l'exception des exigences de stockage), plusieurs ports réseau physiques peuvent être agrégés pour répartir la charge ou fournir une tolérance aux pannes.</block>
  <block id="89831505b6fb0eb3bfb78852c3e8838a" category="list-text">NetApp recommande de créer un commutateur virtuel dédié sur l'hôte Hyper-V pour la connexion au stockage invité au sein de la machine virtuelle.</block>
  <block id="301b0a1048a669cb6b56215ce25f83d2" category="list-text">Assurez-vous que les chemins de données iSCSI de l'hôte Hyper-V et de l'invité utilisent différents ports physiques et commutateurs virtuels pour une isolation sécurisée entre l'invité et l'hôte.</block>
  <block id="38d14a6f7d54295d21bfb890bbfac145" category="list-text">NetApp recommande d'éviter le regroupement de cartes réseau pour les cartes réseau iSCSI.</block>
  <block id="3b5eab23ccdc37978e26fa584647f2f5" category="list-text">NetApp recommande d'utiliser le protocole MPIO (ONTAP Multipath Input/Output) configuré sur l'hôte à des fins de stockage.</block>
  <block id="6395caf6c767d5f8026b684721c1e27e" category="list-text">NetApp recommande d'utiliser MPIO sur une machine virtuelle invitée si des initiateurs iSCSI invités sont utilisés. L'utilisation de MPIO doit être évitée au sein de l'invité si vous utilisez des disques directs. Dans ce cas, l'installation de MPIO sur l'hôte devrait suffire.</block>
  <block id="55892ded4e0eac09cd2bd256ea8e4f49" category="list-text">NetApp recommande de ne pas appliquer de règles de qualité de service au commutateur virtuel attribué au réseau de stockage.</block>
  <block id="9e33949565ff57eed3e484a27adca687" category="list-text">NetApp recommande de ne pas utiliser l'adressage IP privé automatique (APIPA) sur les cartes réseau physiques car APIPA n'est pas routable et n'est pas enregistré dans le DNS.</block>
  <block id="b06f6cf7b5c4e8ac8117fe6238a15184" category="list-text">NetApp recommande d'activer les trames Jumbo pour les réseaux CSV, iSCSI et de migration dynamique afin d'augmenter le débit et de réduire les cycles du processeur.</block>
  <block id="d34fac956ae63cd93b204c541399ec3f" category="list-text">NetApp recommande de décocher l'option Autoriser le système d'exploitation de gestion à partager cette carte réseau pour que le commutateur virtuel Hyper-V crée un réseau dédié pour les machines virtuelles.</block>
  <block id="0d3e51fc3c7ecb31cb6dcf3ea104060c" category="list-text">NetApp recommande de créer des chemins réseau redondants (plusieurs commutateurs) pour la migration en direct et le réseau iSCSI pour assurer la résilience et la qualité de service.</block>
  <block id="72a46482f366b350b6b0215baa631137" category="summary">Ressources supplémentaires pour Microsoft Windows et Hyper-V.</block>
  <block id="4bb047f8c530785002e490ef17fa725e" category="doc">Où trouver des informations complémentaires</block>
  <block id="0650b34324cf33e3bf1ba6d5db9aa14c" category="list-text">Nouveautés d'Hyper-V sur Windows Server +
<block ref="8508224d602483e88bde8402b5d1f2d1" category="inline-link-rx"></block></block>
  <block id="1139a59d4aa15acd59f31d05c5a9d642" category="summary">Cette annexe décrit le déploiement d'un réplica Hyper-V en dehors d'un environnement en cluster.</block>
  <block id="be9cfe5b3b6e5354686be0cb736fe70d" category="list-text">Vous avez besoin de serveurs Hyper-V autonomes situés dans le même emplacement géographique ou dans des emplacements distincts servant de serveurs principaux et de serveurs de réplica.</block>
  <block id="427aef80e259ae74b835c2b646e8fba8" category="list-text">Si des sites distincts sont utilisés, le pare-feu de chaque site doit être configuré pour permettre la communication entre les serveurs principal et de réplica.</block>
  <block id="3ac92c1d06a47463c6ea9f2c4289a625" category="list-text">Le serveur de réplica doit disposer d'un espace suffisant pour stocker les charges de travail répliquées.</block>
  <block id="6db575d6d23958eefd722c2559c2ae2b" category="list-text">Configurez le serveur de réplica.</block>
  <block id="f348eb2699776a23b340068fa13ba378" category="list-text">Pour que les règles de pare-feu entrantes autorisent le trafic de réplication entrant, exécutez l'applet de commande PowerShell suivante :</block>
  <block id="b3741a0bf4f272b05520af3145ce6b20" category="list-text">Cliquez sur Paramètres Hyper-V dans actions.</block>
  <block id="0b81c69f5b40344714e859c333f7e46d" category="list-text">Cliquez sur Configuration de la réplication et sélectionnez Activer cet ordinateur en tant que serveur de réplica.</block>
  <block id="23e173753ad1fc5a192335afcd91aaa2" category="list-text">Dans la section authentification et ports, sélectionnez la méthode et le port d'authentification.</block>
  <block id="c67571ac7fd00493d3ca7147b7756914" category="list-text">Dans la section autorisation et stockage, spécifiez l'emplacement où stocker les machines virtuelles et les fichiers répliqués.</block>
  <block id="c6f470c780ac40391a73366709e36fae" category="list-text">Activez la réplication des machines virtuelles sur le serveur principal. La réplication des machines virtuelles est activée par machine virtuelle, et non pour l'ensemble du serveur Hyper-V.</block>
  <block id="84f81856434a0c817bfd8ec7ba575d63" category="list-text">Dans Hyper-V Manager, cliquez avec le bouton droit de la souris sur un serveur virtuel, puis cliquez sur Activer la réplication pour ouvrir l'assistant Activer la réplication.</block>
  <block id="bb27dca619d145c6538ad523a5c5aec7" category="list-text">Indiquez le nom du serveur de réplica sur lequel la machine virtuelle doit être répliquée.</block>
  <block id="368e47c642802a224da6a1e9196c2345" category="list-text">Indiquez le type d'authentification et le port du serveur de réplica qui a été configuré pour recevoir le trafic de réplication sur le serveur de réplica.</block>
  <block id="df839b9a847de722b03fb6f8db4abd3d" category="list-text">Sélectionnez les VHD à répliquer.</block>
  <block id="7e2b2defa62bab724dad332e0efe93d4" category="list-text">Choisissez la fréquence (durée) à laquelle les modifications sont envoyées au serveur de réplica.</block>
  <block id="f1358329d5a84d751f47c4d4e4882286" category="list-text">Configurez les points de récupération pour spécifier le nombre de points de récupération à conserver sur le serveur de réplica.</block>
  <block id="13bb9737452c217970585237bf9a3c67" category="list-text">Choisissez méthode de réplication initiale pour spécifier la méthode de transfert de la copie initiale des données de la machine virtuelle vers le serveur de réplica.</block>
  <block id="e7773df7e8bec8a84ededaaba6cc3b5c" category="list-text">Vérifiez le résumé et cliquez sur Terminer.</block>
  <block id="eaa408dd6135876f9368b7e9e8447340" category="list-text">Ce processus crée une réplique de machine virtuelle sur le serveur de réplica.</block>
  <block id="c6c9686c38a42b00345f77c5ddbe044a" category="list-text">Exécutez un basculement de test pour vous assurer que la machine virtuelle de réplica fonctionne correctement sur le serveur de réplica. Le test crée une machine virtuelle temporaire sur le serveur de réplica.</block>
  <block id="4b07a5223e241d6b4d7935c2282616a5" category="list-text">Connectez-vous au serveur de réplica.</block>
  <block id="baaaeb9b824a8922645198d46a10e27a" category="list-text">Dans Hyper-V Manager, cliquez avec le bouton droit de la souris sur un serveur virtuel de réplica, cliquez sur réplication, puis sur Test Failover.</block>
  <block id="b9950331695e861c821d48077fe8b1f1" category="list-text">Choisissez le point de restauration à utiliser.</block>
  <block id="b1d034cdaa7ef0d2bc761b948c78838a" category="list-text">Ce processus crée un VM du même nom ajouté à -Test.</block>
  <block id="8c95c5ef4d5593fe860313c283fab784" category="list-text">Vérifier la machine virtuelle pour s'assurer que tout fonctionne correctement.</block>
  <block id="e5c73308bdacf8978516ccda5462e80a" category="list-text">Après le basculement, la machine virtuelle de test de réplica est supprimée si vous sélectionnez Arrêter le basculement de test pour elle.</block>
  <block id="c4eacda4a6022cafe1bfc0d735075dce" category="list-text">Exécutez un basculement planifié pour répliquer les dernières modifications sur la machine virtuelle principale vers la machine virtuelle de réplica.</block>
  <block id="7c3c0f256f21e1f117a98a5afa47dd56" category="list-text">Connectez-vous au serveur principal.</block>
  <block id="2d6fd035cbd8062dcc29935ff448420e" category="list-text">Désactivez la machine virtuelle à basculer.</block>
  <block id="582c3456f1d3f75fd04a3dfcdb20c132" category="list-text">Dans Hyper-V Manager, cliquez avec le bouton droit de la souris sur le serveur virtuel désactivé, cliquez sur réplication, puis sur basculement planifié.</block>
  <block id="4ed0c56504eba0632689dfc8056e3c49" category="list-text">Cliquez sur basculement pour transférer les dernières modifications apportées à la machine virtuelle vers le serveur de réplica.</block>
  <block id="f490046b13ec9105a4adb8f885b5688f" category="list-text">Exécuter un basculement non planifié en cas de défaillance de la machine virtuelle principale.</block>
  <block id="c01438bcded7cda6d1ee326fa268f93c" category="list-text">Dans Hyper-V Manager, cliquez avec le bouton droit de la souris sur un serveur virtuel de réplica, cliquez sur réplication, puis sur basculement.</block>
  <block id="94faab2d3840f3d8320e20ad4a90e6cd" category="list-text">Cliquez sur basculement pour basculer le serveur virtuel.</block>
  <block id="4be45953e45cfa5fc987ba108c1e5793" category="summary">Cette annexe décrit le déploiement de la migration dynamique dans un environnement en cluster.</block>
  <block id="388b92a1de3321595dcfbdc1c67ce749" category="paragraph">Pour utiliser la migration dynamique dans un environnement en cluster, procédez comme suit :</block>
  <block id="b66a6c742469f1d08a2d11bcf4f211ff" category="list-text">Dans Failover Cluster Manager, sélectionnez et développez le cluster. Si le cluster n'est pas visible, cliquez sur Gestionnaire de cluster de basculement, cliquez sur se connecter au cluster et indiquez le nom du cluster.</block>
  <block id="e3883376513ba0aeb2f3d190d4e0377d" category="list-text">Cliquez sur rôles, qui répertorie toutes les machines virtuelles disponibles dans un cluster.</block>
  <block id="e164db40505184b94012bbbd4aa4c1a2" category="list-text">Cliquez avec le bouton droit de la souris sur la machine virtuelle et cliquez sur déplacer. Vous disposez ainsi de trois options :</block>
  <block id="6a1e101231f8f4bcd4a75390cc0eddc2" category="list-text">*Migration dynamique.* vous pouvez sélectionner un nœud manuellement ou autoriser le cluster à sélectionner le meilleur nœud. Dans le cadre de la migration dynamique, le cluster copie la mémoire utilisée par la machine virtuelle du nœud actuel vers un autre nœud. Par conséquent, lorsque la machine virtuelle est migrée vers un autre nœud, la mémoire et les informations d'état requises par la machine virtuelle sont déjà en place pour cette dernière. Cette méthode de migration est quasi instantanée, mais une seule machine virtuelle peut être migrée en direct à la fois.</block>
  <block id="4374953843b8a5507e79ee5145fd88cd" category="list-text">*Migration rapide.* vous pouvez sélectionner un nœud manuellement ou autoriser le cluster à sélectionner le meilleur nœud. Lors d'une migration rapide, le cluster copie la mémoire utilisée par une machine virtuelle sur un disque du système de stockage. Par conséquent, lorsque la machine virtuelle est migrée vers un autre nœud, l'autre nœud peut rapidement lire la mémoire et les informations d'état requises par la machine virtuelle à partir du disque. Grâce à une migration rapide, plusieurs machines virtuelles peuvent être migrées simultanément.</block>
  <block id="f1321d73ebfb5a92e710d313fd53c21c" category="list-text">*Migration du stockage de la machine virtuelle.* cette méthode utilise l'assistant de déplacement du stockage de la machine virtuelle. Cet assistant vous permet de sélectionner le disque de la machine virtuelle ainsi que d'autres fichiers à déplacer vers un autre emplacement, qui peut être un partage CSV ou SMB.</block>
  <block id="36397d251acf4232a7e91edc7ae649c7" category="summary">Stockage NAS ONTAP pour Hyper-V utilisant SMB3</block>
  <block id="a06ae7fcee90c7ab1e1321d0dd8b2242" category="paragraph">ONTAP fournit un stockage NAS résilient et hautes performances pour les machines virtuelles Hyper-V utilisant le protocole SMB3.</block>
  <block id="2efbb65fec3bad963652820bc484fe59" category="paragraph">Lorsqu'un SVM est créé avec le protocole CIFS, un serveur CIFS s'exécute en plus du SVM faisant partie du domaine Windows Active Directory. Les partages SMB peuvent être utilisés pour un répertoire local et pour héberger les charges de travail Hyper-V et SQL Server. ONTAP prend en charge les fonctionnalités SMB 3.0 suivantes :</block>
  <block id="55339f66c60fe6973920932c368d5b51" category="list-text">Pointeurs permanents (partages de fichiers disponibles en continu)</block>
  <block id="94713d3b3a69a2fd695bffeb252007d3" category="list-text">Protocole témoin</block>
  <block id="adb115272d11e09afdfd8702a652d626" category="list-text">Basculement client en cluster</block>
  <block id="f5025b9fcd1b24276af8ec2da3aa4cd7" category="list-text">Sensibilisation au scale-out</block>
  <block id="81abcea6e16bc538d9843e8808b2066b" category="list-text">ODX</block>
  <block id="f4ad9c4d51155dbb3fb746c7c497c145" category="list-text">VSS distant</block>
  <block id="56a26f5f5f602966c3a3088fc05c7383" category="paragraph">L'utilisation d'un stockage NetApp dans des environnements NAS sous Windows Server présente les conditions suivantes :</block>
  <block id="5f3a2953a5f6d187ed4babba3c754b95" category="list-text">Le cluster ONTAP dispose d'une licence CIFS valide.</block>
  <block id="2744237d602ca5ed3f1a6370ed8ebe91" category="list-text">Au moins un agrégat est créé.</block>
  <block id="89917a1bea2d5c48569d9ed0a9526f74" category="list-text">Une interface logique de données (LIF) est créée et la LIF de données doit être configurée pour CIFS.</block>
  <block id="87a2c188e55f400a5936550cc2f91148" category="list-text">Un serveur de domaine Windows Active Directory configuré par DNS et des informations d'identification d'administrateur de domaine sont présentes.</block>
  <block id="da920c4d42bb062c9dbfd877c84ef133" category="list-text">Chaque nœud du cluster NetApp est synchronisé avec le contrôleur de domaine Windows.</block>
  <block id="f04e0c239705cd7c6e249d3ed6991627" category="section-title">Contrôleur de domaine Active Directory</block>
  <block id="2e0bc40db7949b4af757ea11110ae955" category="paragraph">Il est possible de joindre un contrôleur de stockage NetApp à un serveur Active Directory similaire à un serveur Windows et de le faire fonctionner au sein de celui-ci. Lors de la création du SVM, vous pouvez configurer le DNS en fournissant le nom de domaine et les détails du serveur de noms. Le SVM tente de rechercher un contrôleur de domaine Active Directory en interrogeant le DNS pour un serveur LDAP (Active Directory/Lightweight Directory Access Protocol) d'une manière similaire à Windows Server.</block>
  <block id="dee2aa3e7614e2fc47c6fbbb5cd123b5" category="paragraph">Pour que la configuration CIFS fonctionne correctement, les contrôleurs de stockage NetApp doivent être synchronisés dans le temps avec le contrôleur de domaine Windows. NetApp recommande de ne pas dépasser cinq minutes entre le contrôleur de domaine Windows et le contrôleur de stockage NetApp. Il est recommandé de configurer le serveur NTP (Network Time Protocol) afin que le cluster ONTAP se synchronise avec une source de temps externe. Pour configurer le contrôleur de domaine Windows en tant que serveur NTP, exécutez la commande suivante sur votre cluster ONTAP :</block>
  <block id="2d60b04429a0c7bcf1dc0021d1c01046" category="list-text">Créer un SVM avec le protocole NAS CIFS activé Il est possible de créer un SVM avec l'une des méthodes suivantes :</block>
  <block id="26ed02718973e705cd69ee6e109400e0" category="list-text">System Manager</block>
  <block id="fc05c3b0a7017fa6841b856230e365bb" category="list-text">Kit NetApp PowerShell</block>
  <block id="bbee3ec15cf30d6e65d6a020f6d4af1e" category="list-text">Configuration du protocole CIFS</block>
  <block id="8de4bddcd1cd8e4614e52342eef41752" category="list-text">Indiquez le nom du serveur CIFS.</block>
  <block id="a817c1f7bf7af809fd90c63b2a8e4447" category="list-text">Indiquez l'Active Directory auquel le serveur CIFS doit être joint. Vous devez disposer des informations d'identification de l'administrateur de domaine pour joindre le serveur CIFS à Active Directory.</block>
  <block id="bf8cf0b24d936c2fe2e3681004650bf0" category="list-text">Assigner le SVM avec des LIFs sur chaque nœud de cluster.</block>
  <block id="5d77fb569194f93fead7154a8d1d1bc3" category="list-text">Démarrer le service CIFS sur le SVM</block>
  <block id="547edc4d2fb156c3e495e6325eae5a4a" category="list-text">Créez un volume avec le style de sécurité NTFS à partir de l'agrégat.</block>
  <block id="1418b945a2d25e4f6514fc52e9d6c7ef" category="list-text">Créer un qtree sur le volume (facultatif).</block>
  <block id="f0bbe023b40d4d11ed83d36a68894cae" category="list-text">Créez des partages correspondant au volume ou au répertoire qtree afin qu'ils soient accessibles depuis Windows Server. Sélectionnez Activer la disponibilité continue pour Hyper-V lors de la création du partage si celui-ci est utilisé pour le stockage Hyper-V. Cela permet une haute disponibilité pour les partages de fichiers.</block>
  <block id="9ef47a6b1a5d19245750aa732054173a" category="list-text">Modifiez le partage créé et modifiez les autorisations nécessaires pour accéder au partage. Les autorisations du partage SMB doivent être configurées pour accorder l'accès aux comptes d'ordinateur de tous les serveurs accédant à ce partage.</block>
  <block id="053003e418b94e54d509f16e6a5ac54f" category="paragraph">Pour détecter le partage CIFS créé précédemment avec Windows Server, procédez comme suit :</block>
  <block id="9eb306535570bd14746bad4f0768684f" category="list-text">Connectez-vous à Windows Server en tant que membre du groupe d'administrateurs.</block>
  <block id="4cac21133029fce3cd01fb6d42f8bedb" category="list-text">Accédez à run.exe et saisissez le chemin d'accès complet du partage CIFS créé pour accéder au partage.</block>
  <block id="cf48b5bae22bbcd1956b57470865f653" category="list-text">Pour mapper le partage de façon permanente sur le serveur Windows, cliquez avec le bouton droit de la souris sur ce PC, cliquez sur connecter un lecteur réseau et indiquez le chemin du partage CIFS.</block>
  <block id="304c9374426bb10ac275b8d050d77a72" category="list-text">Pour ouvrir la console MMC dans Windows Server, cliquez sur gestion de l'ordinateur dans la section Outils de Server Manager.</block>
  <block id="e731a6a9193d81f0140801ba9fb7c316" category="list-text">Cliquez sur autres actions et connectez-vous à un autre ordinateur, ce qui ouvre la boîte de dialogue Sélectionner un ordinateur.</block>
  <block id="92b70da99a18efe7530353abe1820089" category="list-text">Entrer le nom du serveur CIFS ou l'adresse IP du LIF du SVM pour se connecter au serveur CIFS.</block>
  <block id="2d6dbdc8809506c631cd711d19c21958" category="list-text">Développez Outils système et dossiers partagés pour afficher et gérer les fichiers, sessions et partages ouverts.</block>
  <block id="3a38167e840fd7939f34e194afadd957" category="list-text">Pour vérifier qu'il n'y a pas de temps d'indisponibilité lorsqu'un volume est déplacé d'un nœud vers un autre ou en cas de défaillance d'un nœud, NetApp vous recommande d'activer l'option de disponibilité continue sur le partage de fichiers.</block>
  <block id="7a98f276625e5966a817f0783982ef86" category="list-text">Lors du provisionnement d'ordinateurs virtuels dans un environnement Hyper-V-over-SMB, NetApp vous recommande d'activer la fonction de déchargement des copies sur le système de stockage. Le temps de provisionnement des ordinateurs virtuels est ainsi réduit.</block>
  <block id="8bb66ec4b6ef9437bd1c4c88328028b9" category="list-text">Si le cluster de stockage héberge plusieurs charges de travail SMB, telles que SQL Server, Hyper-V et des serveurs CIFS, NetApp recommande d'héberger différentes charges de travail SMB sur des SVM distincts, sur des agrégats distincts. Cette configuration est avantageuse, car chacune de ces charges de travail garantit une disposition unique du réseau et des volumes de stockage.</block>
  <block id="ce424317fa59851e16cfbe4cbac13386" category="list-text">Lors de la migration de machines virtuelles d'un partage SMB 3.0 vers un autre, NetApp recommande d'activer la fonctionnalité de déchargement des copies CIFS sur le système de stockage afin d'accélérer la migration.</block>
  <block id="be7159d8a65544f2712c72dc0254f9be" category="list-text">Lorsque vous provisionnez des volumes pour les environnements SMB, les volumes doivent être créés avec le style de sécurité NTFS.</block>
  <block id="bb17c7edf27266c09bc64edcc1299db5" category="list-text">Les paramètres de temps des nœuds du cluster doivent être configurés en conséquence. Utilisez le protocole NTP si le serveur CIFS NetApp doit participer au domaine Windows Active Directory.</block>
  <block id="261b72d9729025ebf489205324a048d5" category="list-text">Les pointeurs permanents fonctionnent uniquement entre les nœuds d'une paire haute disponibilité.</block>
  <block id="e185fb0d3a49c7a3318c954d8aa25c05" category="list-text">Le protocole témoin fonctionne uniquement entre les nœuds d'une paire haute disponibilité.</block>
  <block id="67d7fd26a92bba839041dd45a19cec56" category="list-text">Les partages de fichiers disponibles en continu sont pris en charge uniquement pour les charges de travail Hyper-V et SQL Server.</block>
  <block id="fa2e04a9f0cdcb5ad0e9f1e5ad1ada82" category="list-text">Le multicanal SMB est pris en charge à partir de ONTAP 9.4.</block>
  <block id="f357368b2f195de4f8b4463eed2bf004" category="list-text">RDMA n'est pas pris en charge.</block>
  <block id="f55cb235b18bf3d499f9276cd235bfb6" category="list-text">Les références ne sont pas prises en charge.</block>
  <block id="fb97dc994a0600d8610daca021159b33" category="paragraph">Le serveur nano n'a pas besoin d'un logiciel client supplémentaire pour accéder aux données du partage CIFS sur un contrôleur de stockage NetApp.</block>
  <block id="2be09e0be799992463b5c9542ce31dd8" category="paragraph">Pour copier des fichiers de Nano Server vers un partage CIFS, exécutez les applets de commande suivantes sur le serveur distant :</block>
  <block id="2e0d4f41db110bf64a66493b31c9b168" category="list-text"><block ref="6f88c516ba3d9ab0cd23b81fc43dd697" prefix="" category="inline-code"></block> Est le partage CIFS sur le contrôleur de stockage NetApp.</block>
  <block id="5e017ad7a7df43934bccc7c27031a140" category="list-text">Pour copier des fichiers sur Nano Server, exécutez l'applet de commande suivante :</block>
  <block id="d153ba0c2e04ac16dcece009a842216e" category="paragraph">Pour copier l'intégralité du contenu d'un dossier, spécifiez le nom du dossier et utilisez le paramètre -RECURSE à la fin de l'applet de commande.</block>
  <block id="c9f4515194bc7b2927aa17b7d9b4aa25" category="summary">Comment configurer la migration dynamique du stockage Hyper-V.</block>
  <block id="a49764977574be237e816e868b16bd9e" category="doc">Déployez Hyper-V Storage Live migration</block>
  <block id="587db979ac1f69c45774cb09d6d6670b" category="paragraph">Découvrez comment configurer la migration dynamique du stockage Hyper-V.</block>
  <block id="0146445d75059a401441fd65f1bae1e0" category="list-text">Vous devez disposer d'un serveur Hyper-V autonome avec stockage indépendant (DAS ou LUN) ou d'un stockage SMB (local ou partagé entre d'autres serveurs Hyper-V).</block>
  <block id="71c2ecf4798ba7bf00669c37826cb55b" category="inline-link-macro">Migration dynamique en dehors d'un environnement en cluster</block>
  <block id="4a8052295fad176b01067c772f7c7e5d" category="list-text">Le serveur Hyper-V doit être configuré pour la migration en direct. Passez en revue la section sur le déploiement dans <block ref="0e7f526c94c2d5b9ef424b7a8a1c9587" category="inline-link-macro-rx"></block>.</block>
  <block id="43434644e024fa3073cc9c64dba551d0" category="list-text">Ouvrez Hyper-V Manager.</block>
  <block id="3999a6e17f16c7f048684f76a1a59e38" category="list-text">Cliquez avec le bouton droit de la souris sur une machine virtuelle et cliquez sur déplacer.</block>
  <block id="1d838d1a72e03329477d7f4024eec108" category="list-text">Sélectionnez déplacer le stockage de l'ordinateur virtuel.</block>
  <block id="45d2d7245527e5e6e9be62e79d5a46d8" category="list-text">Sélectionnez les options de déplacement du stockage en fonction de vos préférences.</block>
  <block id="13d0ba1c0320910efd0d040f2d461527" category="list-text">Indiquez le nouvel emplacement des éléments de la machine virtuelle.</block>
  <block id="6efadc6e298c560f1699100ac97c7378" category="list-text">Vérifiez le récapitulatif et cliquez sur OK pour déplacer le stockage de la machine virtuelle.</block>
  <block id="b2d949a2d7f46bb1e39037d38eea14e4" category="summary">Efficacité du stockage ONTAP avec Microsoft Hyper-V.</block>
  <block id="bd2eab4ffe0ab602b60386dfdd3ef913" category="paragraph">ONTAP offre une efficacité du stockage de pointe pour les environnements virtualisés tels que Microsoft Hyper-V. NetApp propose également des programmes de garantie d'efficacité du stockage.</block>
  <block id="e957a0e8016b502f05bb1966b2ec6064" category="paragraph">La déduplication NetApp supprime les blocs dupliqués au niveau du volume de stockage et ne stocke qu'une seule copie physique, quel que soit le nombre de copies logiques présentes. Par conséquent, la déduplication crée l'illusion qu'il y a de nombreuses copies de ce bloc. La déduplication supprime automatiquement les blocs de données dupliqués au niveau d'un bloc de 4 Ko répartis sur un volume entier. Ce processus récupère le stockage pour réaliser des économies d'espace et de performances potentielles en réduisant le nombre d'écritures physiques sur le disque. La déduplication permet de réaliser des économies d'espace supérieures à 70 % dans les environnements Hyper-V.</block>
  <block id="44ee5e4157e5291ffc8bc5d1d9b5959d" category="paragraph">Le provisionnement fin constitue un moyen efficace de provisionner le stockage, car celui-ci n'est pas préalloué à l'avance. En d'autres termes, lorsqu'un volume ou une LUN est créé à l'aide du provisionnement fin, l'espace sur le système de stockage n'est pas utilisé. L'espace reste inutilisé jusqu'à ce que les données soient écrites sur la LUN ou le volume. Seul l'espace nécessaire pour stocker les données est utilisé. NetApp recommande d'activer le provisionnement fin sur le volume et de désactiver la réservation de LUN.</block>
  <block id="8bc14f0cb78851f59e85c1d447c2c99f" category="section-title">Qualité de service</block>
  <block id="5f4c07a9f526ef861fd661ab7d801ef0" category="paragraph">La QoS du stockage de clustered ONTAP vous permet de regrouper des objets de stockage et de définir des limites de débit sur le groupe. La QoS du stockage peut être utilisée pour limiter le débit aux charges de travail et surveiller la performance des charges de travail. L'administrateur du stockage peut ainsi séparer les charges de travail par organisation, application, entité commerciale ou environnement de production ou de développement.</block>
  <block id="8649c492f1adfda9b6ab44990a1a7580" category="paragraph">Dans les environnements d'entreprise, la QoS du stockage contribue à atteindre les objectifs suivants :</block>
  <block id="ca944817219b4a5d2cb25894ee7bac2d" category="list-text">Évitez que les charges de travail des utilisateurs ne s'entraffectent.</block>
  <block id="1d5819479882e9b1b8133fda618801e5" category="list-text">Protège les applications stratégiques avec des temps de réponse spécifiques qui doivent être respectés dans les environnements IT à la demande (ITaaS).</block>
  <block id="b06d1116eb0db3e3c8c51d1707dfcf99" category="list-text">Empêche les locataires de s'entraffecter.</block>
  <block id="1d7dd784ada3e9fe62630025fa82dc80" category="list-text">Évite la dégradation des performances avec l'ajout de chaque nouveau locataire.</block>
  <block id="3c7577ceba90e087950e69f357ce949b" category="paragraph">La QoS vous permet de limiter la quantité d'E/S envoyées à un SVM, un volume flexible, un LUN ou un fichier. Les E/S peuvent être limitées par le nombre d'opérations ou le débit brut.</block>
  <block id="0ac164a0cdedc812bd371348407d8df2" category="paragraph">La figure suivante illustre une SVM avec sa propre règle de QoS appliquée appliquant une limite de débit maximale.</block>
  <block id="4cd97525569a4c4f332a1fbadea31367" category="inline-image-macro">Machine virtuelle de stockage avec sa propre règle de qualité de service, largeur=319, hauteur=341</block>
  <block id="11751e265ace69b487d325224006c7e5" category="paragraph"><block ref="11751e265ace69b487d325224006c7e5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="42674eda4c194d913efb361684c8b8c6" category="paragraph">Pour configurer un SVM avec ses propres politiques de QoS et surveiller le groupe de règles, exécutez les commandes suivantes sur votre cluster ONTAP :</block>
  <block id="2398ac10b8f12f8d175464af41b6cc27" category="summary">Découvrez comment déployer Microsoft Windows Nano Server</block>
  <block id="60aa20a9330bfedece833eb6496e61dc" category="doc">Déployez Nano Server</block>
  <block id="751f4ae88fb7c0e83c557b594f24f467" category="paragraph">Découvrez comment déployer Microsoft Windows Nano Server.</block>
  <block id="ffd8df9c68fc3e1710ed9dc15dec9225" category="paragraph">Pour déployer un Nano Server en tant qu'hôte Hyper-V, procédez comme suit :</block>
  <block id="2c8cf6c7616e7bf4d627844c10ef6914" category="list-text">Copiez le dossier NanoServerImageGenerator du dossier \NanoServer dans l'ISO Windows Server sur le disque dur local.</block>
  <block id="e93afc2a7bab8945ac834e9f955ab2c8" category="list-text">Pour créer un Nano Server VHD/VHDX, procédez comme suit :</block>
  <block id="f0b4451826a1b48587dce5ccbdf7a1e7" category="list-text">Démarrez Windows PowerShell en tant qu'administrateur, accédez au dossier NanoServerImageGenerator copié sur le disque dur local et exécutez l'applet de commande suivante :</block>
  <block id="3b515a3daeec18784951623c4ef02332" category="list-text">Créez un VHD pour le Nano Server en tant qu'hôte Hyper-V en exécutant l'applet de commande PowerShell suivante. Cette commande vous invite à entrer un mot de passe administrateur pour le nouveau VHD.</block>
  <block id="2ef6d24f20fa6986cbd70ea844d3e16e" category="list-text">Dans l'exemple suivant, nous créons un disque dur virtuel Nano Server avec la fonctionnalité hôte Hyper-V avec mise en cluster de basculement activée. Cet exemple crée un disque dur virtuel Nano Server à partir d'un fichier ISO monté à f:\. Le VHD nouvellement créé est placé dans un dossier nommé NanoServer dans le dossier à partir duquel l'applet de commande est exécutée. Le nom de l'ordinateur est NanoServer et le VHD obtenu contient l'édition standard de Windows Server.</block>
  <block id="7f165cd40e3ab8b56d69cfdf799ebb23" category="list-text">Avec l'applet de commande New-NanoServerImage, configurez les paramètres qui définissent l'adresse IP, le masque de sous-réseau, la passerelle par défaut, le serveur DNS, le nom de domaine, et ainsi de suite.</block>
  <block id="9ba9f17628c7c8e123a1c4d0b154e1e0" category="list-text">Utilisez le VHD sur une machine virtuelle ou un hôte physique pour déployer Nano Server en tant qu'hôte Hyper-V :</block>
  <block id="7482916c1c66ae16c274920ca01eda80" category="list-text">Pour le déploiement sur une machine virtuelle, créez une nouvelle machine virtuelle dans Hyper-V Manager et utilisez le VHD créé à l'étape 3.</block>
  <block id="8a1f197a1a3903636fe46d151b55f1a4" category="list-text">Pour le déploiement sur un hôte physique, copiez le VHD sur l'ordinateur physique et configurez-le pour qu'il démarre à partir de ce nouveau VHD. Tout d'abord, montez le VHD, exécutez bcdboot e:\Windows (où le VHD est monté sous E:\), démontez le VHD, redémarrez l'ordinateur physique et démarrez le Nano Server.</block>
  <block id="1a2fbb26db89a11f849f5a17170449b5" category="list-text">Connectez le Nano Server à un domaine (facultatif) :</block>
  <block id="fa966a71fb7e787a036cc8ae2df719c2" category="list-text">Connectez-vous à n'importe quel ordinateur du domaine et créez un blob de données en exécutant l'applet de commande PowerShell suivante :</block>
  <block id="5e83141959914643e6e309d32cb02675" category="list-text">Copiez le fichier odjblob sur le Nano Server en exécutant les applets de commande PowerShell suivantes sur un ordinateur distant :</block>
  <block id="9493ca9bfebee08582b48c95f6ad1768" category="list-text">Redémarrez le serveur Nano.</block>
  <block id="24d48ec9863eca883370d9e471e7dec1" category="section-title">Connectez-vous au Nano Server</block>
  <block id="11e7dceca10309920a26c38df3c5f421" category="paragraph">Pour vous connecter au Nano Server à distance à l'aide de PowerShell, procédez comme suit :</block>
  <block id="08d7b9e67b4bbd447b1fa3d9103976e8" category="list-text">Ajoutez le Nano Server en tant qu'hôte de confiance sur l'ordinateur distant en exécutant l'applet de commande suivante sur le serveur distant :</block>
  <block id="0b1f1a420d35761f550f4a9f3b9e2ecb" category="list-text">Si l'environnement est sûr et si vous souhaitez définir tous les hôtes à ajouter en tant qu'hôtes de confiance sur un serveur, exécutez la commande suivante :</block>
  <block id="06879aa989dffc1c877a92441f72d474" category="list-text">Démarrez la session distante en exécutant l'applet de commande suivante sur le serveur distant. Saisissez le mot de passe du Nano Server lorsque vous y êtes invité.</block>
  <block id="c5363e6f2cab660a02c04316d65097b5" category="paragraph">Pour vous connecter au Nano Server à distance à l'aide des outils de gestion de l'interface utilisateur graphique à partir d'un serveur Windows distant, exécutez les commandes suivantes :</block>
  <block id="d97c0d550aa0ad1af548a89c27d9f7ea" category="list-text">Connectez-vous au serveur Windows en tant que membre du groupe d'administrateurs.</block>
  <block id="ff621b1b3a7bcf389fc4c97a55bf9505" category="list-text">Pour gérer un Nano Server à distance à partir de Server Manager, cliquez avec le bouton droit de la souris sur tous les serveurs, cliquez sur Ajouter des serveurs, indiquez les informations du Nano Server et ajoutez-le. Vous pouvez maintenant voir le Nano Server dans la liste des serveurs. Sélectionnez le Nano Server, cliquez dessus avec le bouton droit de la souris et commencez à le gérer à l'aide des différentes options fournies.</block>
  <block id="2343c80f9e6b008ea95cc15026c9c094" category="list-text">Pour gérer les services sur un Nano Server à distance, procédez comme suit :</block>
  <block id="1430c8ff3134db821cc65ac53e010d4d" category="list-text">Ouvrez Services dans la section Outils de Server Manager.</block>
  <block id="358fe30f1157bd64dad7a3aba4e40f94" category="list-text">Cliquez avec le bouton droit de la souris sur Services (local).</block>
  <block id="72fa515e487f796b536e03179e63e7db" category="list-text">Cliquez sur se connecter au serveur.</block>
  <block id="50ec7cc625733992673123275ff834d6" category="list-text">Fournissez les détails du Nano Server pour afficher et gérer les services sur le Nano Server.</block>
  <block id="f322fcdc841439901a45a176928f80e0" category="list-text">Si le rôle Hyper-V est activé sur le Nano Server, procédez comme suit pour le gérer à distance à partir d'Hyper-V Manager :</block>
  <block id="14994643f0c569708527514d0405c1e5" category="list-text">Cliquez avec le bouton droit de la souris sur Gestionnaire Hyper-V.</block>
  <block id="8e0877f5a8a5d540837664b9de1070ca" category="list-text">Cliquez sur se connecter au serveur et indiquez les détails du Nano Server. Le Nano Server peut désormais être géré en tant que serveur Hyper-V pour créer et gérer des machines virtuelles.</block>
  <block id="b2c5e9024429f1b7f8581d1747d25fd6" category="list-text">Si le rôle de mise en cluster de basculement est activé sur le Nano Server, procédez comme suit pour le gérer à distance à partir du gestionnaire de cluster de basculement :</block>
  <block id="31b3efaeee0b35b5bde4f1353f947b93" category="list-text">Ouvrez le Gestionnaire de clusters de basculement à partir de la section Outils de Server Manager.</block>
  <block id="2cb85a898a7a975600dcc1bea85df531" category="list-text">Effectuez des opérations de mise en cluster avec le Nano Server.</block>
  <block id="2810ba8ba9d5e4319af85df66ddf2286" category="summary">Sécurité du stockage ONTAP avec Hyper-V.</block>
  <block id="2fae32629d4ef4fc6341f1751b405e45" category="doc">Sécurité</block>
  <block id="6ca21561032e8c064bc8514ab2e92740" category="paragraph">ONTAP fournit un système de stockage sécurisé pour le système d'exploitation Windows.</block>
  <block id="615e826f5576798f024d7959ccefc794" category="section-title">Antivirus Windows Defender</block>
  <block id="2861d3b5f4351fd51979bf98547a050b" category="paragraph">Windows Defender est un logiciel antimalware installé et activé par défaut sur Windows Server. Ce logiciel protège activement Windows Server contre les programmes malveillants connus et peut régulièrement mettre à jour les définitions d'antimalware via Windows Update. Les LUN NetApp et les partages SMB peuvent être analysés à l'aide de Windows Defender.</block>
  <block id="a86f08bae2bbd68aa81b64f748f3ccb8" category="inline-link">Présentation de Windows Defender</block>
  <block id="4b51dd417e2be3fdc9a793c3290e3a63" category="paragraph">Pour plus d'informations, reportez-vous au<block ref="d66127569e4d44a2d0a35bc9d20b1ea7" category="inline-link-rx"></block>.</block>
  <block id="ce71fc775b37c52dabd938808de8d0f9" category="section-title">BitLocker</block>
  <block id="8d9091beebb755bb6e68a4f04d3288f6" category="paragraph">Le chiffrement de lecteur BitLocker est une fonction de protection des données, suite à Windows Server 2012. Ce chiffrement protège les disques physiques, les LUN et les CSV.</block>
  <block id="0494cad48bf6f5dd2105391f0426af1a" category="paragraph">Avant d'activer BitLocker, le CSV doit être mis en mode de maintenance. Par conséquent, NetApp recommande de prendre des décisions relatives à la sécurité basée sur BitLocker avant de créer des machines virtuelles sur le CSV afin d'éviter les temps d'arrêt.</block>
  <block id="e2e4ca1a6c3bcca61ed5ec3ea10c90c0" category="summary">Découvrez comment déployer et configurer une réplique Hyper-V avec le cluster de basculement Windows Server.</block>
  <block id="5674fdbee301f444dd0ca3836c682957" category="list-text">Si des sites distincts sont utilisés, le pare-feu de chaque site doit être configuré pour permettre la communication entre les clusters principal et de réplica.</block>
  <block id="6cc66ed27b17f9c380f924d533e633d6" category="list-text">Le cluster de réplica doit disposer d'un espace suffisant pour stocker les charges de travail répliquées.</block>
  <block id="ff71768b9e039ee5012c181eb29bdc39" category="list-text">Activez les règles de pare-feu sur tous les nœuds d'un cluster. Exécutez l'applet de commande PowerShell suivante avec des privilèges d'administrateur sur tous les nœuds des clusters principal et de réplica.</block>
  <block id="ac005fe375c3903e88ed3801a8646b0a" category="list-text">Configurer le cluster de réplica.</block>
  <block id="3a57da55cdc319b0580af329b8776df6" category="list-text">Configurez le courtier de réplica Hyper-V avec un nom NetBIOS et une adresse IP à utiliser comme point de connexion au cluster utilisé comme cluster de réplica.</block>
  <block id="643ce0b9206c6c138b36b79315a468f2" category="list-text">Ouvrez Failover Cluster Manager.</block>
  <block id="52243c461a19e74a8e4b64d801979142" category="list-text">Développez le cluster, cliquez sur rôles, puis sur le volet configurer le rôle à partir des actions.</block>
  <block id="f87ee1c8e6945b31ba45ee813ea7c124" category="list-text">Sélectionnez Hyper-V Replica Broker dans la page Sélectionner un rôle.</block>
  <block id="fdbea454936dca227734d3f978334254" category="list-text">Indiquez le nom NetBIOS et l'adresse IP à utiliser comme point de connexion au cluster (point d'accès client).</block>
  <block id="bb8627cc57d25f02546b85f38d97ae04" category="list-text">Ce processus crée un rôle de courtier de réplica Hyper-V. Vérifiez qu'elle est bien en ligne.</block>
  <block id="9b11f91c42607554f82ca0c4a5739d14" category="list-text">Configurer les paramètres de réplication.</block>
  <block id="662af7cfca9243c46223a416df05d774" category="list-text">Cliquez avec le bouton droit de la souris sur le courtier de répliques créé lors des étapes précédentes, puis cliquez sur Paramètres de réplication.</block>
  <block id="45375ee44c681920240b13f25bf53d9e" category="list-text">Sélectionnez Activer ce cluster en tant que serveur de réplica.</block>
  <block id="88aeceb8128e3b94092a3e66ac2236db" category="list-text">Dans la section autorisation et stockage, sélectionnez les serveurs autorisés à répliquer des machines virtuelles sur ce cluster. Spécifiez également l'emplacement par défaut où les VM répliquées sont stockées.</block>
  <block id="3d9241b7079c08f25c850a7d8ac5eebd" category="inline-link-macro">Réplique hors d'un environnement en cluster</block>
  <block id="3077be518a570235f65497aa5b227e9b" category="paragraph">La réplication est similaire au processus décrit dans la section <block ref="85d27647a4d4ffb042b0371e9654ea4c" category="inline-link-macro-rx"></block>.</block>
  <block id="f8b7d7bb25e13b6b771e58da1fa078cb" category="summary">Provisionnez le stockage ONTAP pour Windows et Hyper-V dans les environnements SAN</block>
  <block id="24294828f9d26e2b73b5b1e0eda7a2d0" category="paragraph">Les SVM ONTAP prennent en charge les protocoles de niveau bloc iSCSI et FC. Lorsqu'un SVM est créé avec un protocole de bloc iSCSI ou FC, le SVM obtient respectivement un nom qualifié iSCSI (IQN) ou un nom WWN FC. Cet identifiant présente une cible SCSI aux hôtes qui accèdent au stockage en bloc NetApp.</block>
  <block id="7f33f1b99e752967fce41fe3dec9f051" category="section-title">Provisionnement de LUN NetApp sur Windows Server</block>
  <block id="025d3d39bb1937ffe40a12b1917e28b6" category="paragraph">L'utilisation d'un stockage NetApp dans des environnements SAN sous Windows Server présente les conditions suivantes :</block>
  <block id="3e306b32d1acc6cfcca681b93d8d57cd" category="list-text">Un cluster NetApp est configuré avec un ou plusieurs contrôleurs de stockage NetApp.</block>
  <block id="3e0ea625c6f590606b5242be6455347c" category="list-text">Le cluster NetApp ou les contrôleurs de stockage disposent d'une licence iSCSI valide.</block>
  <block id="5bf7c7c03ed76506f8822badb526f0a8" category="list-text">Des ports configurés iSCSI et/ou FC sont disponibles.</block>
  <block id="46434438c1896350bc085c1a67785198" category="list-text">La segmentation FC est effectuée sur un commutateur FC pour FC.</block>
  <block id="1e704db41d570618bd723b41d0db395e" category="list-text">Un SVM doit avoir une LIF par réseau Ethernet ou une structure Fibre Channel sur chaque contrôleur de stockage qui va transmettre des données via iSCSI ou Fibre Channel.</block>
  <block id="daa700de515c2e157d34b0e12c154478" category="list-text">Créez un SVM avec le protocole de bloc iSCSI et/ou FC activé. Il est possible de créer un SVM avec l'une des méthodes suivantes :</block>
  <block id="ec642b047305fbfe6db973f313768eae" category="list-text">Commandes CLI sur le stockage NetApp</block>
  <block id="43736124eda42b8dec979b188b9d891b" category="list-text">Configuration du protocole iSCSI et/ou FC</block>
  <block id="51dbb9050f89d2c5cbfda6a46bb48963" category="list-text">Démarrer le service iSCSI et/ou FC sur le SVM</block>
  <block id="5058f1af8388633f609cadb75a75dc9d" category="paragraph">.</block>
  <block id="80967cdacf7a48c49276c07097765c46" category="list-text">Créez des datasets de ports iSCSI et/ou FC à l'aide des LIF du SVM.</block>
  <block id="2d59cbd9d3169fc27e47164a0bf60c42" category="list-text">Créez un groupe initiateur iSCSI et/ou FC pour Windows à l'aide du jeu de ports créé.</block>
  <block id="b6efc79e22c0381d9fcc8c3f40ff674f" category="list-text">Ajouter un initiateur au groupe initiateur. L'initiateur est l'IQN pour iSCSI et WWPN pour FC. Ils peuvent être interrogés à partir de Windows Server en exécutant l'applet de commande PowerShell Get-InitiatorPort.</block>
  <block id="ab39c1b30c8045ee5b2419b682b64e5c" category="paragraph">L'IQN pour iSCSI sur Windows Server peut également être vérifié dans la configuration des propriétés de l'initiateur iSCSI.</block>
  <block id="83f0120a854049de17bd46bb97e5c5fa" category="list-text">Créez une LUN à l'aide de l'assistant de création de LUN et associez-la au groupe initiateur créé.</block>
  <block id="186c31b1cbf72f8c54f9c6a0edca1cfe" category="paragraph">Windows Server utilise l'extension ALUA (Asymmetrical Logical Unit Access) MPIO pour déterminer les chemins directs et indirects vers les LUN. Bien que chaque LIF appartenant à un SVM accepte des demandes de lecture/écriture pour ses LUN, seul un des nœuds du cluster possède les disques sur lesquels cette LUN est supports à un moment donné. Cela divise les chemins disponibles pour une LUN en deux types, directs ou indirects, comme indiqué dans la figure suivante.</block>
  <block id="7dc177b120da05827161978955c8104e" category="paragraph">Un chemin direct pour une LUN est un chemin sur lequel résident les LIFs d'un SVM et la LUN accédée sur le même nœud. Pour passer d'un port cible physique à un disque, il n'est pas nécessaire de traverser le réseau de cluster.</block>
  <block id="b456728920702bd70bc705a1af06be72" category="paragraph">Les chemins indirects sont des chemins de données sur lesquels les LIFs du SVM et la LUN accédée résident sur différents nœuds. Les données doivent traverser le réseau de cluster pour passer d'un port cible physique au disque.</block>
  <block id="6b08a0deb0bef5f6429e5fb7bab4da29" category="inline-image-macro">Chemins multiples dans l'environnement SAN,largeur=624,hauteur=232</block>
  <block id="e5106eaf1ca3b8ff0d6a4555b38845de" category="paragraph"><block ref="e5106eaf1ca3b8ff0d6a4555b38845de" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7e6c7f4878b6fa562299bd45be030c4d" category="section-title">MPIO</block>
  <block id="90881f9a41c6c14a994dd6d410b5eae3" category="section-title">Activez MPIO</block>
  <block id="1f4614ecf24e855792cb4a72e2ca4a86" category="paragraph">Pour activer MPIO sur Windows Server, procédez comme suit :</block>
  <block id="bb35cb72ffe2e8dd1a02cf65b86c6cd3" category="list-text">Démarrez Server Manager.</block>
  <block id="d580309cd21fec5dd6a0fc9e095dacbe" category="list-text">Dans la section gérer, cliquez sur Ajouter des rôles et des fonctions.</block>
  <block id="19c0c759d805032bc93817553dbc8ef9" category="list-text">Dans la page Sélectionner les fonctionnalités, sélectionnez E/S multivoies</block>
  <block id="63c2082592ff76eac0541130a24e7670" category="section-title">Configurer MPIO</block>
  <block id="655995aa16b525227f20b4e6b55a22cf" category="paragraph">Lorsque vous utilisez le protocole iSCSI, vous devez demander à Windows Server d'appliquer la prise en charge des chemins d'accès multiples aux périphériques iSCSI dans les propriétés MPIO.</block>
  <block id="3cdb8cf9c5fe85e070ceba959169e83f" category="paragraph">Pour configurer MPIO sur Windows Server, procédez comme suit :</block>
  <block id="bd27f39c0a288d0682b789a806d1eec7" category="list-text">Connectez-vous à Windows Server en tant que membre du groupe d'administrateurs.</block>
  <block id="a267872bfc142a132ea159cb0904930f" category="list-text">Dans la section Outils, cliquez sur MPIO.</block>
  <block id="46205f4b1d4b254565cae2fd6970a3a6" category="list-text">Dans Propriétés MPIO sur Discover Multi-Path, sélectionnez Add support for iSCSI Devices et cliquez sur Add. Une invite vous demande ensuite de redémarrer l'ordinateur.</block>
  <block id="8c372bcf6ff4084f9e072d698d449b18" category="list-text">Redémarrez Windows Server pour voir le périphérique MPIO répertorié dans la section périphériques MPIO des Propriétés MPIO.</block>
  <block id="28f21ae88e9953ac3d80686cfb49832b" category="section-title">Configurez iSCSI</block>
  <block id="a12e2e6108a8b8cb032c190ebe798d79" category="paragraph">Pour détecter le stockage en mode bloc iSCSI sur Windows Server, procédez comme suit :</block>
  <block id="623f636e32ba5729ab907ad3eeeb5adb" category="list-text">Dans la section Outils, cliquez sur initiateur iSCSI.</block>
  <block id="d259349ad54c81b69ffb57d045a7c135" category="list-text">Sous l'onglet découverte, cliquez sur découvrir le portail.</block>
  <block id="9055f8c4230cf1268018d9b81d1c30e0" category="list-text">Fournir l'adresse IP des LIFs associées au SVM créé pour le protocole NetApp Storage for SAN. Cliquez sur Avancé, configurez les informations dans l'onglet général, puis cliquez sur OK.</block>
  <block id="56fe767f1eb1a3401bb37455b6e1c804" category="list-text">L'initiateur iSCSI détecte automatiquement la cible iSCSI et la répertorie dans l'onglet cibles.</block>
  <block id="f6357f1aad932cb8ef210a786e72e1e9" category="list-text">Sélectionnez la cible iSCSI dans cibles découvertes. Cliquez sur connexion pour ouvrir la fenêtre connexion à la cible.</block>
  <block id="28d26404caba20cb28577f61c51a7e1f" category="list-text">Vous devez créer plusieurs sessions à partir de l'hôte Windows Server vers les LIFs iSCSI cibles sur le cluster de stockage NetApp. Pour ce faire, procédez comme suit :</block>
  <block id="3aef6deb3c61c368bc66313781c8e351" category="list-text">Dans la fenêtre se connecter à la cible, sélectionnez Activer MPIO et cliquez sur Avancé.</block>
  <block id="d754cac9ca73d1113c5fa5908ca2dc97" category="list-text">Dans Paramètres avancés sous l'onglet général, sélectionnez la carte locale en tant qu'initiateur Microsoft iSCSI et sélectionnez l'adresse IP de l'initiateur et l'adresse IP du portail cible.</block>
  <block id="fdcb9587e9c4d393ea337f94fb0e1f5f" category="list-text">Vous devez également vous connecter à l'aide du second chemin. Par conséquent, répétez les étapes 5 à 8, mais cette fois, sélectionnez l'adresse IP de l'initiateur et l'adresse IP du portail cible pour le second chemin.</block>
  <block id="cb35c153406b8cdeb5963bd9a0ceb501" category="list-text">Sélectionnez la cible iSCSI dans cibles découvertes dans la fenêtre principale des propriétés iSCSI et cliquez sur Propriétés.</block>
  <block id="2a3977b58760a2b4c9e557175a5e494e" category="list-text">La fenêtre Propriétés indique que plusieurs sessions ont été détectées. Sélectionnez la session, cliquez sur périphériques, puis cliquez sur MPIO pour configurer la stratégie d'équilibrage de charge. Tous les chemins configurés pour le périphérique sont affichés et toutes les stratégies d'équilibrage de charge sont prises en charge. NetApp recommande généralement la permutation circulaire avec sous-ensemble, et ce paramètre est le paramètre par défaut pour les baies pour lesquelles le protocole ALUA est activé. Round Robin est la valeur par défaut pour les baies actives/actives qui ne prennent pas en charge ALUA.</block>
  <block id="7b7b8262c038321869fc17ba522bbe07" category="paragraph">Pour détecter un stockage en mode bloc iSCSI ou FC sur Windows Server, effectuez les opérations suivantes :</block>
  <block id="7554b29976a023cca6089775e3a7fd73" category="list-text">Cliquez sur gestion de l'ordinateur dans la section Outils du Gestionnaire de serveur.</block>
  <block id="b7e726cedaa814db32dbfe4395773cc4" category="list-text">Dans gestion de l'ordinateur, cliquez sur la section gestion des disques dans le stockage, puis cliquez sur autres actions et sur Nouvelle analyse des disques. Les LUN iSCSI brutes s'affichent alors.</block>
  <block id="8fd13d2e47a19c784864b40dc7e4621f" category="list-text">Cliquez sur la LUN découverte et mettez-la en ligne. Sélectionnez ensuite initialiser le disque à l'aide de la partition MBR ou GPT. Créez un nouveau volume simple en indiquant la taille du volume et la lettre du lecteur et formatez-le à l'aide de FAT, FAT32, NTFS ou du système de fichiers résilient (ReFS).</block>
  <block id="31ef353687ab7c0fb280206b2eba67d0" category="list-text">NetApp recommande d'activer le provisionnement fin sur les volumes hébergeant les LUN.</block>
  <block id="de065768c0f0b724b1926b25d92fdcef" category="list-text">Pour éviter les problèmes de chemins d'accès multiples, NetApp recommande d'utiliser toutes les sessions de 10 Gbits ou toutes les sessions de 1 Gbit vers une LUN donnée.</block>
  <block id="ed4eb5407c23e138e99781446b4170d8" category="list-text">NetApp vous recommande de vérifier que le protocole ALUA est activé sur le système de stockage. ALUA est activé par défaut sur ONTAP.</block>
  <block id="df0f70c4f2bca2f5f0216ab40982d08a" category="list-text">Sur l'hôte Windows Server auquel est mappée la LUN NetApp, activez le service iSCSI (TCP-in) pour le service entrant et le service iSCSI (TCP-out) pour le service sortant dans les paramètres du pare-feu. Ces paramètres permettent au trafic iSCSI de passer de et vers l'hôte Hyper-V et le contrôleur NetApp.</block>
  <block id="defe090ca065bb89790c1a0b2d533ad0" category="section-title">Provisionnement des LUN NetApp sur le serveur Nano</block>
  <block id="a7b1fc24d300b03d303a4e66fd5eaf19" category="inline-link-macro">Déployez Nano Server.</block>
  <block id="c56e09ae358fe6206c8e4059eb76252b" category="paragraph">En plus des conditions préalables mentionnées dans la section précédente, le rôle de stockage doit être activé du côté Nano Server. Par exemple, Nano Server doit être déployé à l'aide de l'option -Storage. Pour déployer Nano Server, reportez-vous à la section "<block ref="00a4a5119b1e43564baa188fc895d5ff" category="inline-link-macro-rx"></block>«</block>
  <block id="152dbede177bc5347922fdc2b306adf2" category="paragraph">Pour provisionner des LUN NetApp sur un serveur Nano, procédez comme suit :</block>
  <block id="fe02f402a046a8784957e096b11835e3" category="list-text">Connectez-vous au Nano Server à distance en suivant les instructions de la section "<block ref="60e7ef5a283935545371795472ceb490" category="inline-link-macro-rx"></block>."</block>
  <block id="1b3c1a51c3603283ec4f7ab199a89ad3" category="list-text">Pour configurer iSCSI, exécutez les applets de commande PowerShell suivantes sur le Nano Server :</block>
  <block id="5e885af04f617a09b29600bd064e0a82" category="list-text">Ajouter un initiateur au groupe initiateur.</block>
  <block id="8a73c7acbdf9fc31a87cebe8de47a176" category="list-text">Configurer MPIO.</block>
  <block id="8e08d5639ddc5bf9f71aeea2f9df6706" category="list-text">Détecter le stockage bloc.</block>
  <block id="ad04ba98fa2a26c6e2a4f71314b1c4c7" category="section-title">Démarrage à partir du réseau SAN</block>
  <block id="e29512aa6180bca309f145289f08337c" category="paragraph">Un hôte physique (serveur) ou une machine virtuelle Hyper-V peut démarrer le système d'exploitation Windows Server directement à partir d'un LUN NetApp au lieu de son disque dur interne. Dans l'approche de démarrage à partir du SAN, l'image du système d'exploitation à partir de réside sur un LUN NetApp connecté à un hôte physique ou à une machine virtuelle. Dans le cas d'un hôte physique, le HBA de l'hôte physique est configuré pour utiliser le LUN NetApp pour le démarrage. Dans le cas d'une machine virtuelle, le LUN NetApp est connecté en tant que disque pass-through pour le démarrage.</block>
  <block id="2cf07cb81d5366158ac32b0d02e3bf39" category="paragraph">Grâce à la technologie NetApp FlexClone, les LUN de démarrage avec une image du système d'exploitation peuvent être clonées instantanément et reliées aux serveurs et aux serveurs virtuels pour fournir rapidement des images de système d'exploitation propres, comme illustré dans la figure suivante.</block>
  <block id="e60c0a021a1a11ca0fd66050c818b441" category="inline-image-macro">Démarrage de LUN à l'aide de NetApp FlexClone,width=561,height=357</block>
  <block id="79f4f54e05eb2f1c2084e0542e66f182" category="paragraph"><block ref="79f4f54e05eb2f1c2084e0542e66f182" category="inline-image-macro-rx" type="image"></block></block>
  <block id="738e6a96e2bf795b59ac62d4827a779e" category="list-text">L'hôte physique (serveur) dispose d'une carte HBA iSCSI ou FC appropriée.</block>
  <block id="7957c1b3b06b3ca5c17a05da5e59c9ec" category="list-text">Vous avez téléchargé un pilote de périphérique HBA approprié pour le serveur prenant en charge Windows Server.</block>
  <block id="1810f78aa22a9972644e65ac2cdad107" category="list-text">Le serveur dispose d'un lecteur de CD/DVD ou d'un support virtuel approprié pour insérer l'image ISO Windows Server et le pilote de périphérique HBA a été téléchargé.</block>
  <block id="0af744e0f07c6b198e478b2ba83aca3a" category="list-text">Une LUN NetApp iSCSI ou FC est provisionnée sur le contrôleur de stockage NetApp.</block>
  <block id="30e2bee2ccadbae82d2d5aeddd5b4078" category="paragraph">Pour configurer le démarrage à partir du réseau SAN pour un hôte physique, procédez comme suit :</block>
  <block id="7d90eb9f56cbfbfe2930a2d651f51f3a" category="list-text">Activez BootBIOS sur le HBA du serveur.</block>
  <block id="034cb1858f7a3762e67e18bff38aa62a" category="list-text">Pour les HBA iSCSI, configurez l'adresse IP de l'initiateur, le nom du nœud iSCSI et le mode d'amorçage de l'adaptateur dans les paramètres du BIOS d'amorçage.</block>
  <block id="aeae1f3a4453e2d3e333de58d3f28c4a" category="list-text">Lors de la création d'un groupe initiateur pour iSCSI et/ou FC sur un contrôleur de stockage NetApp, ajoutez l'initiateur HBA du serveur au groupe. L'initiateur HBA du serveur est le WWPN correspondant au HBA FC ou au nom du nœud iSCSI du HBA iSCSI.</block>
  <block id="1ec419dd357b1eacb28eec8cfd657908" category="list-text">Créez une LUN sur le contrôleur de stockage NetApp avec l'ID de LUN 0 et associez-la au groupe initiateur créé à l'étape précédente. Cette LUN sert de LUN de démarrage.</block>
  <block id="52ec2612ed3c17b60d5c662122410366" category="list-text">Limitez le HBA à un seul chemin vers la LUN de démarrage. Des chemins supplémentaires peuvent être ajoutés après l'installation de Windows Server sur la LUN de démarrage pour exploiter la fonctionnalité de chemins d'accès multiples.</block>
  <block id="0fa69ac9076a9031393e6f5d4aa909d5" category="list-text">Utilisez l'utilitaire BootBIOS du HBA pour configurer le LUN en tant que périphérique d'amorçage.</block>
  <block id="58347d33bbc0409dce93e92c5983619a" category="list-text">Redémarrez l'hôte et accédez à l'utilitaire BIOS de l'hôte.</block>
  <block id="1b9013d7a416c62e05336b3791451d0d" category="list-text">Configurez le BIOS hôte pour que la LUN de démarrage soit le premier périphérique dans l'ordre de démarrage.</block>
  <block id="3472e7b0e2c4389366cf3e0f09f6376d" category="list-text">À partir de l'ISO Windows Server, lancez la configuration de l'installation.</block>
  <block id="8423662d97649ae1012d665b6594f514" category="list-text">Lorsque l'installation vous demande « où voulez-vous installer Windows ? », cliquez sur Charger le pilote en bas de l'écran d'installation pour lancer la page Sélectionner le pilote à installer. Indiquez le chemin du pilote de périphérique HBA téléchargé précédemment et terminez l'installation du pilote.</block>
  <block id="4d0de28cb0fe5a517374a0c7fdaaff27" category="list-text">La LUN de démarrage créée précédemment doit maintenant être visible sur la page d'installation de Windows. Sélectionnez la LUN de démarrage pour l'installation de Windows Server sur la LUN de démarrage et terminez l'installation.</block>
  <block id="0dbc8e7afe6136a3b34471c047b28f83" category="paragraph">Pour configurer le démarrage à partir du SAN pour une machine virtuelle, procédez comme suit :</block>
  <block id="6af97eac32eef9a62687eac41262ae48" category="list-text">Lors de la création d'un groupe initiateur pour iSCSI ou FC sur un contrôleur de stockage NetApp, ajoutez l'IQN pour iSCSI ou le WWN pour FC du serveur Hyper-V au contrôleur.</block>
  <block id="c18de5a7c8558c6b9b749ea9d61336da" category="list-text">Créez des LUN ou des clones de LUN sur le contrôleur de stockage NetApp et associez-les au groupe initiateur créé à l'étape précédente. Ces LUN servent de LUN de démarrage pour les machines virtuelles.</block>
  <block id="dac33c93e3d9b5c90a34c39aa579711a" category="list-text">Détecter les LUN sur le serveur Hyper-V, les mettre en ligne et les initialiser.</block>
  <block id="441d10873880501fa764914d0bf1f044" category="list-text">Mettez les LUN hors ligne.</block>
  <block id="0490d2908eb59e831010f6c50ebdf6ea" category="list-text">Créez des machines virtuelles avec l'option connecter un disque dur virtuel ultérieurement sur la page connecter un disque dur virtuel.</block>
  <block id="2b2b3b281225dec976273bad7f4dacf0" category="list-text">Ajout d'une LUN en tant que disque pass-through à une VM</block>
  <block id="ab82d3a85d9187f45c1cac0bd2922647" category="list-text">Ouvrez les paramètres de la machine virtuelle.</block>
  <block id="d2e03542bea91031de7772d6cb0b7b13" category="list-text">Cliquez sur contrôleur IDE 0, sélectionnez disque dur, puis cliquez sur Ajouter. Si vous sélectionnez IDE Controller 0, ce disque devient le premier périphérique d'amorçage pour la machine virtuelle.</block>
  <block id="1904d13d92aac636b46007dec34eb357" category="list-text">Sélectionnez disque dur physique dans les options disque dur et sélectionnez un disque dans la liste comme disque intermédiaire. Les disques sont les LUN configurés dans les étapes précédentes.</block>
  <block id="19e47f17e14687afa5f6c07833dbd7aa" category="list-text">Installez Windows Server sur le disque d'intercommunication.</block>
  <block id="30f837081d56a5f1605e52592a38d5f4" category="list-text">Assurez-vous que les LUN sont hors ligne. Sinon, le disque ne peut pas être ajouté en tant que disque pass-through à une machine virtuelle.</block>
  <block id="9865f9e3af02eaca8b480229a22515f4" category="list-text">Lorsqu'il existe plusieurs LUN, veillez à noter le numéro de disque de la LUN dans la gestion de disque. Cette opération est nécessaire car les disques répertoriés pour la machine virtuelle sont répertoriés avec le numéro de disque. De même, la sélection du disque en tant que disque pass-through pour la machine virtuelle est basée sur ce numéro de disque.</block>
  <block id="15b11e66e58b25dffc74ff36f6529d4d" category="list-text">NetApp recommande d'utiliser le MPIO ONTAP configuré sur l'hôte à des fins de stockage.</block>
  <block id="154e178d8f948264ecf34dcfd8ad3112" category="summary">Cette annexe explique comment utiliser la migration dynamique Hyper-V en dehors d'un environnement en cluster</block>
  <block id="3a37015d23bf5b95b8aaeeb60e7149f6" category="paragraph">Cette section décrit le déploiement de la migration dynamique Hyper-V en dehors d'un environnement en cluster.</block>
  <block id="34076d85579973b175bda646666488f5" category="list-text">Serveurs Hyper-V autonomes avec stockage indépendant ou stockage SMB partagé.</block>
  <block id="6d3867adf71fde2bd2e28c3530f980e2" category="list-text">Rôle Hyper-V installé à la fois sur les serveurs source et de destination.</block>
  <block id="860a24a5665c79d337512cf7091c1f27" category="list-text">Les deux serveurs Hyper-V appartiennent au même domaine ou aux domaines qui se font confiance.</block>
  <block id="599b01a5eeab6af8dcd5d22203b25b3b" category="paragraph">Pour effectuer une migration en direct dans un environnement non mis en cluster, configurez les serveurs Hyper-V source et de destination afin qu'ils puissent envoyer et recevoir des opérations de migration en direct. Sur les deux serveurs Hyper-V, procédez comme suit :</block>
  <block id="5c8aa736f4d71f22237d67e44338e090" category="list-text">Dans actions, cliquez sur Paramètres Hyper-V.</block>
  <block id="146cc3da35b3cb4807f19e5c342f3d0b" category="list-text">Cliquez sur migrations dynamiques et sélectionnez Activer les migrations dynamiques entrantes et sortantes.</block>
  <block id="000104d6631c201d8476c728987584e9" category="list-text">Choisissez d'autoriser le trafic de migration en direct sur n'importe quel réseau disponible ou uniquement sur des réseaux spécifiques.</block>
  <block id="bbba185068a3a5aa887f5064ee5fc3de" category="list-text">Vous pouvez également configurer le protocole d'authentification et les options de performances à partir de la section Avancé de Live migrations.</block>
  <block id="0d91ef025d958a7706b6abf25f2160a5" category="list-text">Si CredSSP est utilisé comme protocole d'authentification, assurez-vous de vous connecter au serveur Hyper-V source à partir du serveur Hyper-V de destination avant de déplacer la machine virtuelle.</block>
  <block id="4671ab6d9ed8f69134f49812ab7a7c35" category="list-text">Si Kerberos est utilisé comme protocole d'authentification, configurez la délégation contrainte. Pour ce faire, vous devez accéder au contrôleur de domaine Active Directory. Pour configurer la délégation, procédez comme suit :</block>
  <block id="3c3a519ac45fd3a37ae321645897af94" category="list-text">Connectez-vous au contrôleur de domaine Active Directory en tant qu'administrateur.</block>
  <block id="15be526c72b91c88e16f64f6c832eb6b" category="list-text">Dans la section Outils, cliquez sur utilisateurs et ordinateurs Active Directory.</block>
  <block id="444f95dff8ac9b4c8c6335d66d6ae4a7" category="list-text">Développez le domaine et cliquez sur ordinateurs.</block>
  <block id="a07ecc7f9ab368b241540687975a30aa" category="list-text">Sélectionnez le serveur Hyper-V source dans la liste, cliquez dessus avec le bouton droit de la souris et cliquez sur Propriétés.</block>
  <block id="a3a23c7b6ce827c11b3cdb698108c307" category="list-text">Dans l'onglet délégation, sélectionnez faire confiance à cet ordinateur pour la délégation aux services spécifiés uniquement.</block>
  <block id="4070350eb1a20fec8173f5ee230b8566" category="list-text">Sélectionnez utiliser Kerberos uniquement.</block>
  <block id="36d92877123542287dffc5912e198436" category="list-text">Cliquez sur Ajouter pour ouvrir l'assistant Ajouter des services.</block>
  <block id="2a206fdec4cfdbdd63ff3dd2265bbb34" category="list-text">Dans Ajouter des services, cliquez sur utilisateurs et ordinateurs, ce qui ouvre Sélectionner utilisateurs ou ordinateurs**.**</block>
  <block id="6fb0c1f70349caf1f37bdb1c7b73efe4" category="list-text">Indiquez le nom du serveur Hyper-V de destination et cliquez sur OK.</block>
  <block id="261db7be66ebd6db420e928cb4b402f7" category="list-text">Pour déplacer le stockage de la machine virtuelle, sélectionnez CIFS.</block>
  <block id="f4288db12d8f66e52ec2ac189f491e82" category="list-text">Pour déplacer des machines virtuelles, sélectionnez le service Microsoft Virtual System migration.</block>
  <block id="9149d965e2ccf728685f671fb1046ab9" category="list-text">Dans l'onglet délégation, cliquez sur OK.</block>
  <block id="9bc766cbcc4911cf673963ca303576bc" category="list-text">Dans le dossier ordinateurs, sélectionnez le serveur Hyper-V de destination dans la liste et répétez le processus. Dans Sélectionner utilisateurs ou ordinateurs, indiquez le nom du serveur Hyper-V source.</block>
  <block id="5868e6c6d4568bb2c1245c731ab1f681" category="list-text">Déplacer la VM.</block>
  <block id="ab102f10122268c6b0663d464d3192da" category="list-text">Choisissez déplacer la machine virtuelle.</block>
  <block id="8b95cb0524fdc80c99bdf8cb976556d2" category="list-text">Spécifier le serveur Hyper-V de destination pour la machine virtuelle.</block>
  <block id="25b70b154b120ba061f03c292637a9a4" category="list-text">Choisissez les options de déplacement. Pour Shared Live migration, choisissez déplacer uniquement la machine virtuelle. Pour Shared Nothing Live migration, choisissez l'une des deux autres options en fonction de vos préférences.</block>
  <block id="8c60fc97ae35b3af22d644ab2b9186e7" category="list-text">Indiquez l'emplacement de la machine virtuelle sur le serveur Hyper-V de destination en fonction de vos préférences.</block>
  <block id="dd714dbbaab89194e2aefdf439089cff" category="list-text">Vérifiez le récapitulatif et cliquez sur OK pour déplacer la machine virtuelle.</block>
  <block id="8ab11353f8fda3f130084c6ff3c1f32e" category="summary">Présentation de la virtualisation Microsoft Windows et Hyper-V avec ONTAP</block>
  <block id="e905fd86484ea1bf5b665b34fc9e24b4" category="paragraph">Microsoft Windows Server est un système d'exploitation (OS) professionnel qui couvre la mise en réseau, la sécurité, la virtualisation, le cloud privé, le cloud hybride, infrastructure de postes de travail virtuels, protection des accès, protection des informations, services web, infrastructure de plate-forme applicative, et bien plus encore.</block>
  <block id="16b5970810caafa8d6f89bee6e0398f2" category="admonition">*Cette documentation remplace les rapports techniques publiés précédemment _TR-4568: Consignes de déploiement NetApp et meilleures pratiques de stockage pour Windows Server_*</block>
  <block id="dbf037f8e99a1d5b52fe58af78568561" category="list-text">Architecture unifiée prenant en charge les protocoles de fichiers, d'objets et de blocs. Les contrôleurs de stockage peuvent ainsi agir en tant que périphériques NAS et SAN, ainsi qu'en tant que magasins d'objets</block>
  <block id="23748de0bc860150d3c6b27a4d472042" category="list-text">Une baie 100 % SAN (ASA) axée uniquement sur les protocoles de niveau bloc et qui optimise les temps de reprise des E/S (IORT) en ajoutant un chemins d'accès multiples actif-actif symétrique pour les hôtes connectés</block>
  <block id="d0114359083804284c542907b2f8cd60" category="list-text">Architecture unifiée Software-defined</block>
  <block id="30063e1e8c837a5b52057909e747b2d8" category="list-text">ONTAP Select s'exécutant sur VMware vSphere ou KVM</block>
  <block id="0f76eddbf2cd8ceb8e89447591876ab9" category="list-text">Cloud Volumes ONTAP s'exécutant en tant qu'instance cloud native</block>
  <block id="f7d26dbdc8e2b21b211abf2157e73536" category="list-text">Offres propriétaires de fournisseurs de cloud hyper-évolutif</block>
  <block id="4d82a1ec1af02725042c8c785564ee7a" category="list-text">Amazon FSX pour NetApp ONTAP</block>
  <block id="7450cfde7058dc5e1f7909d0280fd7ae" category="list-text">Azure NetApp Files</block>
  <block id="1215f8190533dfdf63d2224a6d88266f" category="list-text">Google Cloud NetApp volumes</block>
  <block id="7ad18871bdb08a3899a3f7ed4e463284" category="paragraph">ONTAP offre des fonctionnalités d'efficacité du stockage NetApp telles que la technologie Snapshot(R) NetApp, le clonage, la déduplication, le provisionnement fin, la réplication fine, la compression, la hiérarchisation du stockage virtuel et bien plus encore avec des performances et une efficacité améliorées.</block>
  <block id="538a662f2ecbeba6af56e41386484f67" category="paragraph">Ensemble, Windows Server et ONTAP peuvent fonctionner dans de grands environnements et apporter une valeur considérable à la consolidation des data centers et aux déploiements de clouds privés ou hybrides. Cette combinaison assure également des charges de travail efficaces sans interruption et assure une évolutivité transparente.</block>
  <block id="8f0442ea7c58fe8ab4000f5aaeac415b" category="paragraph">Ce document est destiné aux architectes système et de stockage qui conçoivent des solutions de stockage NetApp pour Windows Server.</block>
  <block id="f6f27d1607ed17a4b610676f16f68357" category="paragraph">Nous faisons les hypothèses suivantes dans ce document :</block>
  <block id="e9d690b9eb25093e460ea369baa55496" category="inline-link">Guide d'administration du système destiné aux administrateurs du cluster</block>
  <block id="d54e01b4234443b582b1d0cc44ce1c19" category="list-text">Le lecteur a une connaissance générale des solutions matérielles et logicielles NetApp. Voir la<block ref="87244016000a25428f0fcae2d3732d46" category="inline-link-rx"></block> pour plus d'informations.</block>
  <block id="c501659fe58b766ec2ead9a0c974e530" category="inline-link">Gestion de l'environnement SAN clustered Data ONTAP</block>
  <block id="75ac79ee68c2245f6d8b8cc32a3eae9e" category="inline-link">Gestion NAS</block>
  <block id="48fa880bcded409e494bd8e2e8c64a97" category="list-text">Le lecteur possède des connaissances générales sur les protocoles d'accès aux blocs, tels que iSCSI, FC et le protocole d'accès aux fichiers SMB/CIFS. Voir la<block ref="123a6e61ead9566ba44616c8f29f1ba3" category="inline-link-rx"></block> Pour obtenir des informations sur SAN. Voir la<block ref="9933d9f07fd1633df051103d1b03340e" category="inline-link-rx"></block> Pour des informations relatives à CIFS/SMB.</block>
  <block id="02279515531a2de57bfdffa958d40813" category="list-text">Le lecteur a des connaissances générales sur le système d'exploitation Windows Server et Hyper-V.</block>
  <block id="e1e99607c6efe5e3439e886c50500015" category="paragraph">Pour obtenir une matrice complète et régulièrement mise à jour des configurations SAN et NAS testées et prises en charge, consultez le<block ref="5555d80b97794db0ba7e8564a4b85ca4" category="inline-link-rx"></block> Sur le site de support NetApp. Avec IMT, vous pouvez déterminer les versions de produits et de fonctionnalités prises en charge pour votre environnement spécifique. Le NetApp IMT définit les composants et versions du produit compatibles avec les configurations prises en charge par NetApp. Les résultats dépendent des installations de chaque client et de leur conformité aux spécifications publiées.</block>
  <block id="3eb0aeddd8b10d858bd2028c6f983308" category="summary">Meilleures pratiques opérationnelles pour VMware SRM et le stockage ONTAP</block>
  <block id="35d022831f6b84d57c0d19770bd37b82" category="list-text">ONTAP 9 peut être configuré pour supprimer automatiquement les snapshots afin de préserver la disponibilité en cas de manque d'espace lorsque la taille automatique ne peut pas fournir une capacité d'urgence suffisante. Le paramètre par défaut de cette fonctionnalité ne supprime pas automatiquement les snapshots créés par SnapMirror. Si des snapshots SnapMirror sont supprimés, NetApp SRA ne peut pas inverser et resynchroniser la réplication pour le volume affecté. Pour empêcher ONTAP de supprimer des snapshots SnapMirror, configurez la fonctionnalité de suppression automatique de snapshots.</block>
  <block id="70ca1a895029f273d425b715900ff37a" category="inline-image-macro">Réplication vVols</block>
  <block id="0c1274faebf0b61ccee15ede78b00b55" category="paragraph"><block ref="0c1274faebf0b61ccee15ede78b00b55" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c2c5aade1021a3c4cd296db5e8cca90b" category="inline-image-macro">Planifications SnapMirror</block>
  <block id="a1066290411892a896db86292d410eb3" category="paragraph"><block ref="a1066290411892a896db86292d410eb3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1079afba0a1986bf5bb313da40d31a49" category="inline-image-macro">mappage de règles</block>
  <block id="32e0e862ac943abe75cff3d58b3e5d2b" category="paragraph"><block ref="32e0e862ac943abe75cff3d58b3e5d2b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3dd63afe980253ca98d9e32784c2f1fc" category="paragraph">Cette exigence est nouvelle pour le compte de l'administrateur vSphere. Les volumes étant créés hors du cadre des outils ONTAP, il n'est pas tenu de suivre les modifications apportées par votre administrateur ONTAP tant que la période de redécouverte planifiée n'est pas au moment de la prochaine découverte. C'est pourquoi il est recommandé de toujours exécuter la redécouverte chaque fois que vous créez un volume ou une relation SnapMirror à utiliser avec vvols. Il vous suffit de cliquer avec le bouton droit de la souris sur l'hôte ou le cluster et de sélectionner Outils ONTAP &gt; mettre à jour les données d'hôte et de stockage, comme illustré dans la capture d'écran suivante.</block>
  <block id="2802aa9f39078d087d6ee0f565b18e51" category="inline-image-macro">Mettre à jour les données d'hôte et de stockage</block>
  <block id="416223ee42c638c719e40efc871fe8a1" category="paragraph"><block ref="416223ee42c638c719e40efc871fe8a1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="06b2d4b91b5c9eaa8c20a1c270f95b3c" category="inline-image-macro">cluster</block>
  <block id="6c0893d9a45aaff00c1ef0daf0867ada" category="paragraph"><block ref="6c0893d9a45aaff00c1ef0daf0867ada" category="inline-image-macro-rx" type="image"></block></block>
  <block id="820b71b9a8a55fe48690a5f973c5480e" category="paragraph">L'ingénierie logicielle avec les outils ONTAP pour VMware vSphere utilise les activités de développement sécurisé suivantes :</block>
  <block id="ecdc76c84c9674a3148f3d464298469c" category="paragraph">Les outils ONTAP pour VMware vSphere comprennent les fonctions de sécurité suivantes dans chaque version.</block>
  <block id="0785fa6b3221e7345916be824259dc2f" category="paragraph">Lorsque vous utilisez DES DTS avec les outils ONTAP pour VMware vSphere, vous devez d'abord créer un datastore avec le plug-in, utiliser vCenter pour créer le cluster de datastores, puis y ajouter le datastore. Une fois le cluster datastore créé, des datastores supplémentaires peuvent être ajoutés au cluster datastore directement à partir de l'assistant de provisionnement sur la page Détails.</block>
  <block id="043d75b2a25cf6f38bccaf9211c5bcc5" category="summary">Cette page décrit les bonnes pratiques d'implémentation d'une solution de stockage ONTAP dans un environnement VMware vSphere.</block>
  <block id="760f70bd45ae12af9fa6bee90f402eeb" category="cell">Se reporter à NFS.MaxQueueDepth dans <block ref="1f38ac07598dbb4b06912539aafa4211" category="inline-link-macro-rx"></block>.</block>
  <block id="647fe6e64f77a1f54f9bb61154ab2a4f" category="summary">Plus de ressources vVols</block>
  <block id="852ee2d26adc87d2379ffeb9287f7642" category="inline-image-macro">Tableau de bord des outils ONTAP pour VMware vSphere 9.8 vVols</block>
  <block id="12947c7ceaf237f27fd206edb07cc0c1" category="paragraph"><block ref="12947c7ceaf237f27fd206edb07cc0c1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e2c48e84c0d02dd4e236da05038bd9a" category="paragraph">ONTAP prend en charge les datastores VMFS et NFS vvol. L'utilisation de vvols avec des datastores SAN apporte certains des avantages de NFS tels que la granularité au niveau des VM. Voici quelques meilleures pratiques à prendre en compte, et vous trouverez des informations supplémentaires dans le <block ref="7be3ce63e842612697a6d91b19b8afcd" category="inline-link-macro-rx"></block>:</block>
  <block id="436b5d96360742275889cb237fe2ab70" category="inline-image-macro">Composants vVols</block>
  <block id="1706c14e85f152d61bab2f65d32810a1" category="paragraph"><block ref="1706c14e85f152d61bab2f65d32810a1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="43f38d7beb04aa98b65d2317c2f1659f" category="inline-image-macro">Outils ONTAP pour vSphere</block>
  <block id="aa5b1d896aebe8a04ceac7c2a16b2cd3" category="paragraph"><block ref="aa5b1d896aebe8a04ceac7c2a16b2cd3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c4b0e8af5e898d44e394489b0c629abb" category="image-alt">Groupes d'hôtes VM et règles d'affinité</block>
  <block id="9a2f41e25337439aa55e14c7e16bf211" category="summary">La solution ONTAP pour VMware site Recovery Manager (SRM)</block>
  <block id="a2fca395a283b61cb3e85ebc206c6274" category="paragraph">Depuis son introduction dans le data Center moderne en 2002, ONTAP est une solution de stockage leader pour les environnements VMware vSphere. De plus, il continue d'ajouter des fonctionnalités innovantes pour simplifier la gestion tout en réduisant les coûts.</block>
  <block id="f98dd9d12416a648450df8c99d10878a" category="summary">Présentation des volumes virtuels VMware vSphere (vVols) avec ONTAP</block>
  <block id="674c41ba00ec77fc9d294abbba7e7b7d" category="paragraph">ONTAP est une solution de stockage leader pour les environnements VMware vSphere depuis plus de vingt ans et continue d'ajouter des fonctionnalités innovantes pour simplifier la gestion tout en réduisant les coûts.</block>
  <block id="ae7454da5e20b82b7fe67eb1ff88c923" category="admonition">Cette documentation remplace les rapports techniques _TR-4400 : VMware vSphere Virtual volumes (vVols) par ONTAP_</block>
  <block id="ee82b7a98212a75a2397dd9c5f9b1ab4" category="paragraph">ONTAP prend en charge la spécification VASA depuis sa sortie initiale en 2012. Si d'autres systèmes de stockage NetApp peuvent prendre en charge VASA, ce document est axé sur les versions actuellement prises en charge de ONTAP 9.</block>
  <block id="669b30b7e6d5ef1d862fe65880b816a8" category="paragraph">Outre ONTAP 9 sur les systèmes AFF, ASA et FAS, NetApp prend en charge les workloads VMware sur ONTAP Select, Amazon FSX pour NetApp avec VMware Cloud sur AWS, Azure NetApp Files avec la solution Azure VMware, Cloud Volumes Service avec Google Cloud VMware Engine et le stockage privé NetApp dans Equinix, mais certaines fonctionnalités peuvent varier en fonction du fournisseur de services et de la connectivité réseau disponible. L'accès, depuis les invités vSphere, aux données stockées dans ces configurations ainsi qu'à Cloud Volumes ONTAP est également disponible.</block>
  <block id="afd715f07b1ec06fe77bf23a2d7bf185" category="paragraph">_Pour plus d'informations sur les meilleures pratiques ONTAP et VMware vSphere, voir <block ref="5dbb4949ffa7cb97fe4eaffc517a1111" category="inline-link-macro-rx"></block>_</block>
  <block id="bfdc61fd18bd1a23d9660561bc8999b7" category="list-text">*Cloud Volumes ONTAP.* le logiciel de gestion des données NetApp Cloud Volumes ONTAP permet de contrôler et de protéger les données et d'optimiser l'efficacité du stockage, tout en bénéficiant de la flexibilité du cloud de votre choix. Cloud Volumes ONTAP est un logiciel de gestion des données cloud basé sur le stockage ONTAP. Utilisez-les conjointement avec Cloud Manager pour déployer et gérer des instances Cloud Volumes ONTAP avec vos systèmes ONTAP sur site. Profitez des fonctionnalités NAS avancées et SAN iSCSI combinées à la gestion unifiée des données, notamment les copies Snapshot et la réplication SnapMirror.</block>
  <block id="e88c947a5d8f4c0daec271a8595604a7" category="inline-image-macro">Vue machines virtuelles Active IQ Unified Manager</block>
  <block id="9078040b61fc8a9bd0215e8f35ff788c" category="paragraph"><block ref="9078040b61fc8a9bd0215e8f35ff788c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0ef2f850d3f17cacfbd404bade7eed5b" category="inline-image-macro">Topologie étendue AIQUM</block>
  <block id="75817aa97084cb93e0292a1f0549551f" category="paragraph"><block ref="75817aa97084cb93e0292a1f0549551f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cbd6cdb70073007e002f1ae45c2f7e4a" category="summary">Topologies de réplication utilisant ONTAP avec SnapMirror et VMware SRM.</block>
  <block id="4e749568996a3331860532ac7a470fdb" category="inline-image-macro">La disposition des relations SnapMirror</block>
  <block id="3d2c169d59a49a498b2d7e714c5a6ce2" category="paragraph"><block ref="3d2c169d59a49a498b2d7e714c5a6ce2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="706bdd824ec69e00026180eaf2801d2e" category="paragraph"><block ref="706bdd824ec69e00026180eaf2801d2e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ba1aebb9b3c7be6b408863c12bbc2844" category="paragraph"><block ref="ba1aebb9b3c7be6b408863c12bbc2844" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ea07c4b81c3f00ae8bbef49ac8562d1c" category="paragraph"><block ref="ea07c4b81c3f00ae8bbef49ac8562d1c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12a757dd793cbe082927530094a72d26" category="inline-image-macro">paires de baies</block>
  <block id="263506cdbbc7c35e461fc5f1044b9c79" category="paragraph"><block ref="263506cdbbc7c35e461fc5f1044b9c79" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b26873df0260bdc332a7511f6823cf63" category="inline-image-macro">Configurations non prises en charge</block>
  <block id="120528a3f7d5a39fdd0d67fb0e2b94a4" category="paragraph"><block ref="120528a3f7d5a39fdd0d67fb0e2b94a4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="160a69c7a04198d870353b06dbf714a9" category="paragraph"><block ref="160a69c7a04198d870353b06dbf714a9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="742a3ab0c9a97e5a438c8edfb1b271d2" category="paragraph"><block ref="742a3ab0c9a97e5a438c8edfb1b271d2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d0a05359b36f0932509cfa007b46e853" category="inline-image-macro">Cascade de relations SnapMirror</block>
  <block id="2057708d80974a7573d92b3e0d8a9258" category="paragraph"><block ref="2057708d80974a7573d92b3e0d8a9258" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cd92dffb12f75e4b81ad67d8668ae698" category="inline-image-macro">SnapMirror en cascade vers SnapVault</block>
  <block id="13ece5df0d16f65585acbfb9ebad113c" category="paragraph"><block ref="13ece5df0d16f65585acbfb9ebad113c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c74d71595c83ecb05581a89554ca8bb2" category="inline-image-macro">Inversion de la cascade de SnapMirror vers SnapVault</block>
  <block id="5bb35c000e450925b37eff3feca75a24" category="paragraph"><block ref="5bb35c000e450925b37eff3feca75a24" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2ab367df5e87b988bc086e5ee534793e" category="summary">Cette page décrit les bonnes pratiques d'implémentation de VMware vSphere avec les datastores ONTAP et NFS.</block>
  <block id="0e768c8183bcbfc87718f59d9dfd61eb" category="inline-link-macro">les datastores</block>
  <block id="e6a172fa04a2b585ad34762a7e8991da" category="list-text">Reportez-vous aux notes du tableau interopérabilité NFS v4.1 dans le <block ref="6a9c495bd8eb9d28b9471f77a4372a63" category="inline-link-macro-rx"></block> Pour les niveaux de correctifs VMware ESXi spécifiques requis pour la prise en charge.</block>
  <block id="622b235a9123d972c612737c81eb55a1" category="inline-link-macro">Fonctionnalité NFSv3 nConnect avec NetApp et VMware</block>
  <block id="d94a770977f68948a4930f4a2edbabb9" category="image-alt">Nouveau cluster</block>
  <block id="f5c7047b98efcb8c7eef2db6ef31faf4" category="image-alt">Activer l'option surveillance de l'hôte</block>
  <block id="239aaf78fcb42b02d3709057d2a7978a" category="image-alt">Surveillance des machines virtuelles</block>
  <block id="a7765f8868404f7c3cb890ce051f7de4" category="image-alt">Contrôle d'admission</block>
  <block id="e5bd6e5564d38885fef18a28e48861b4" category="image-alt">Cluster HA</block>
  <block id="8e00c91ecf143f76c94e3aa1668fc92b" category="inline-image-macro">Clonage ONTAP</block>
  <block id="9c7295440be885852a164f5880627146" category="paragraph"><block ref="9c7295440be885852a164f5880627146" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1eed6756a7834e04fb7716ee8d830425" category="inline-link-macro"><block ref="1eed6756a7834e04fb7716ee8d830425" category="inline-link-rx"></block></block>
  <block id="0e4a75553a081fffff029a37e55f5d71" category="inline-link-macro"><block ref="0e4a75553a081fffff029a37e55f5d71" category="inline-link-rx"></block></block>
  <block id="32fd58743bd2ce579949a47db1b95ca8" category="summary">La réplication des vVols avec VASA offre des fonctionnalités uniques par rapport à SRA et aux datastores classiques.</block>
  <block id="570bfadf5783125790b6c87f55842fb2" category="inline-image-macro">Déploiement SnapCenter</block>
  <block id="71ca4878111d253f9883f471e5de9594" category="paragraph"><block ref="71ca4878111d253f9883f471e5de9594" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bd90e11d4c9fc73f37adda8029276215" category="summary">Cette page décrit les bonnes pratiques d'implémentation d'une solution de stockage ONTAP dans un environnement VMware vSphere.</block>
  <block id="ab906277df9ce070b1e11724f8ccf589" category="list-text">Utiliser une interface logique (LIF) unique pour chaque SVM sur chaque nœud du cluster ONTAP. Les recommandations précédentes d'une LIF par datastore ne sont plus nécessaires. L'accès direct (LIF et datastore sur le même nœud) est préférable, mais ne vous inquiétez pas pour l'accès indirect, car l'effet de performance est généralement minimal (microsecondes).</block>
  <block id="8dc90de75c19a4114217f443b0ca2866" category="inline-image-macro">Connectivité d'un hôte vSphere à un datastore ONTAP NFS</block>
  <block id="36b9a8da16a1d2fad06b788e662b7c4a" category="paragraph"><block ref="36b9a8da16a1d2fad06b788e662b7c4a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bb6d2d52dfe07f9662232c444256aece" category="paragraph">Un hôte utilisant iSCSI ou NVMe/TCP peut être directement connecté à un système de stockage et fonctionner normalement. La raison en est le chemin d'accès. Les connexions directes à deux contrôleurs de stockage distincts donnent lieu à deux chemins de flux de données indépendants. La perte du chemin, du port ou du contrôleur n'empêche pas l'autre chemin d'être utilisé.</block>
  <block id="0d761ccb2787bad60b77ac971f6d3914" category="summary">Cette page décrit les bonnes pratiques d'implémentation des volumes ONTAP FlexGroup dans un environnement VMware vSphere.</block>
  <block id="adc6ae60e2ce9c7497e70727d5232a2d" category="paragraph">Utilisez des volumes ONTAP et FlexGroup avec VMware vSphere pour disposer de datastores simples et évolutifs exploitant toute la puissance d'un cluster ONTAP.</block>
  <block id="53c3353b925071c58c705888c2ba7f14" category="paragraph">ONTAP 9.8, ainsi que les outils ONTAP pour VMware vSphere 9.8 et le plug-in SnapCenter pour VMware 4.4, ont ajouté la prise en charge des datastores FlexGroup avec volumes dans vSphere. Les volumes FlexGroup simplifient la création de grands datastores et créent automatiquement les volumes distribués nécessaires sur le cluster ONTAP afin d'optimiser les performances d'un système ONTAP.</block>
  <block id="3f004d1e872dca374feb3f23565997c6" category="paragraph">Utilisez les volumes FlexGroup avec vSphere si vous avez besoin d'un datastore vSphere unique et évolutif doté de la puissance d'un cluster ONTAP complet ou si vous disposez de charges de travail de clonage très importantes pouvant bénéficier du nouveau mécanisme de clonage FlexGroup.</block>
  <block id="55e0e7799b68cd76cf68be0ee82fef7b" category="section-title">Copie auxiliaire</block>
  <block id="6dda3ca3c4d8fee4a726d8e72402d30a" category="paragraph">Outre les tests approfondis du système avec les charges de travail vSphere, ONTAP 9.8 a ajouté un nouveau mécanisme de déchargement des copies pour les datastores FlexGroup. Ce nouveau système utilise un moteur de copie amélioré pour répliquer les fichiers entre les composants en arrière-plan tout en permettant l'accès à la source et à la destination. Ce cache local est ensuite utilisé pour instancier rapidement des clones de machine virtuelle à la demande.</block>
  <block id="aa27f776099657de8054550adc71803c" category="inline-link">Comment configurer les FlexGroups ONTAP pour permettre le déchargement des copies VAAI</block>
  <block id="52b5c3310b38cd7b3015770aa7de4aa7" category="paragraph">Pour activer le déchargement de copie optimisé pour FlexGroup, reportez-vous à la section<block ref="cbb2bc98314efa36f692ba86393a7074" category="inline-link-rx"></block></block>
  <block id="0db4fc806176bc768d44fa59cf3c36aa" category="paragraph">Si vous utilisez le clonage VAAI, mais que le clonage n'est pas suffisant pour maintenir le cache chaud, vos clones ne seront peut-être pas plus rapides qu'une copie basée sur hôte. Si c'est le cas, vous pouvez régler le délai d'expiration du cache pour mieux répondre à vos besoins.</block>
  <block id="1e8e371d8058e71f2444bc0cd42517eb" category="paragraph">Chaque nouvelle tâche de clonage reçue par un volume réinitialise le délai d'expiration. Si un volume composant de l'exemple FlexGroup ne reçoit pas de requête de clone avant le délai d'expiration, le cache de cette machine virtuelle sera effacé et le volume devra être à nouveau rempli. De même, si la source du clone d'origine change (par exemple, si vous avez mis à jour le modèle), le cache local de chaque composant sera invalidé pour éviter tout conflit. Comme indiqué précédemment, le cache peut être réglé en fonction des besoins de votre environnement.</block>
  <block id="6bcf203b609d41b14c06e319cede61d7" category="section-title">Paramètres QoS</block>
  <block id="9ab9903a16c07ff38214a043719957fd" category="paragraph">La configuration de la qualité de service au niveau FlexGroup à l'aide de ONTAP System Manager ou du shell du cluster est prise en charge, mais elle ne prend pas en charge la reconnaissance des machines virtuelles ni l'intégration de vCenter.</block>
  <block id="d9450aaad95d69e8cc75ddc0a69a9026" category="paragraph">La qualité de service (IOPS max/min) peut être définie sur des VM individuelles ou sur toutes les VM d'un datastore à ce moment dans l'interface utilisateur vCenter ou via les API REST à l'aide des outils ONTAP. La définition de la qualité de service sur toutes les VM remplace tous les paramètres distincts par VM. Les paramètres ne s'étendent pas ultérieurement aux nouvelles machines virtuelles ou aux machines virtuelles migrées ; définissez la qualité de service sur les nouvelles machines virtuelles ou appliquez à nouveau la qualité de service à toutes les machines virtuelles du datastore.</block>
  <block id="43a70a1e984a991b55dc01f4e4c6bda0" category="paragraph">Notez que VMware vSphere traite toutes les E/S d'un datastore NFS comme une seule file d'attente par hôte, et que la limitation de la qualité de service sur une machine virtuelle peut avoir un impact sur les performances des autres machines virtuelles du même datastore. Cela contraste avec les vVols qui peuvent maintenir leurs paramètres de politique de QoS s'ils migrent vers un autre datastore et n'ont pas d'impact sur les E/S d'autres machines virtuelles lorsqu'ils sont restreints.</block>
  <block id="f32c3edaacea72c0ddb30ecf0135c4de" category="section-title">Métriques</block>
  <block id="ed7927d72c6154d79bedf6b19ea8fc83" category="paragraph">ONTAP 9.8 a également ajouté de nouveaux metrics de performance basés sur des fichiers (IOPS, débit et latence) pour FlexGroup Files. Ces metrics peuvent être consultées dans les outils ONTAP pour les rapports sur les machines virtuelles et le tableau de bord VMware vSphere. Les outils ONTAP pour le plug-in VMware vSphere vous permettent également de définir des règles de qualité de service (QoS) en combinant des IOPS minimales et/ou maximales. Ils peuvent être définis au sein de toutes les machines virtuelles d'un datastore ou individuellement pour des machines virtuelles spécifiques.</block>
  <block id="c2ffe02d76c4f089648f1647b43e4ee5" category="section-title">Et des meilleures pratiques</block>
  <block id="43fc84d75bb64307120a48d004166174" category="inline-link-macro">Datastores et protocoles - NFS</block>
  <block id="b43cf2a2c13b864c3b2547368e95b2c5" category="list-text">Utilisez les outils ONTAP pour créer des datastores FlexGroup afin de vous assurer que votre FlexGroup est créé de manière optimale et que les règles d'exportation sont configurées pour correspondre à votre environnement vSphere. Cependant, après avoir créé le volume FlexGroup avec les outils ONTAP, vous constaterez que tous les nœuds de votre cluster vSphere utilisent une seule adresse IP pour monter le datastore. Cela pourrait entraîner un goulot d'étranglement sur le port réseau. Pour éviter ce problème, démontez le datastore, puis remontez-le à l'aide de l'assistant standard vSphere datastore en utilisant un nom DNS round-Robin qui équilibre la charge entre les LIF du SVM. Après le remontage, les outils ONTAP pourront à nouveau gérer le datastore. Si les outils ONTAP ne sont pas disponibles, utilisez les paramètres par défaut de FlexGroup et créez votre règle d'export en suivant les instructions de la section <block ref="1dcda1ccb6404fd747bdfa52cd9e0cc2" category="inline-link-macro-rx"></block>.</block>
  <block id="689367b2abf9b4f7fdef5f8589689dbc" category="list-text">Lors du dimensionnement d'un datastore FlexGroup, n'oubliez pas que le FlexGroup est constitué de plusieurs petits volumes FlexVol qui créent un espace de noms plus important. Par conséquent, dimensionnez le datastore pour qu'il soit au moins 8 fois (en supposant que les 8 composants par défaut) la taille de votre fichier VMDK le plus volumineux, plus une marge inutilisée de 10 à 20 % pour permettre un rééquilibrage flexible. Par exemple, si votre environnement comporte 6 To de VMDK, dimensionnez le datastore FlexGroup d'une capacité inférieure à 52,8 To (6 x 8 + 10 %).</block>
  <block id="098d1f2818677f5cc4dd7c08e40b3f41" category="list-text">VMware et NetApp prennent en charge la mise en circuit de session NFSv4.1 à partir de ONTAP 9.14.1. Pour plus d'informations sur les versions, reportez-vous aux notes de la matrice d'interopérabilité NetApp NFS 4.1. NFSv3 ne prend pas en charge plusieurs chemins physiques vers un volume, mais prend en charge nconnect à partir de vSphere 8.0U2. Pour plus d'informations sur nconnect, consultez le <block ref="390300af711b584cff3623a0769fdf9b" category="inline-link-macro-rx"></block>.</block>
  <block id="ac08f555cdca1e9107c33a3e4f5eca2b" category="list-text">Utilisez le plug-in NFS pour VMware VAAI pour la copie auxiliaire. Notez que même si le clonage est amélioré dans un datastore FlexGroup, comme mentionné précédemment, ONTAP n'offre pas d'avantages significatifs en termes de performances par rapport à la copie hôte ESXi lors de la copie de machines virtuelles entre des volumes FlexVol et/ou FlexGroup. Prenez donc en compte vos charges de travail de clonage lorsque vous décidez d'utiliser VAAI ou FlexGroups. L'une des façons d'optimiser le clonage basé sur FlexGroup consiste à modifier le nombre de volumes constitutifs. Tout comme le réglage du délai d'expiration du cache mentionné précédemment.</block>
  <block id="0906d77ff43b190c03c912f8e47c3230" category="list-text">Utilisez les outils ONTAP pour VMware vSphere 9.8 ou version ultérieure pour surveiller les performances des machines virtuelles FlexGroup à l'aide de metrics ONTAP (tableaux de bord et rapports sur les machines virtuelles) et gérer la qualité de service sur chaque machine virtuelle. Ces metrics ne sont pas encore disponibles via les commandes ou les API ONTAP.</block>
  <block id="315f464c64861565200e97577a6eabde" category="list-text">Le plug-in SnapCenter pour VMware vSphere version 4.4 et ultérieure prend en charge la sauvegarde et la restauration des machines virtuelles dans un datastore FlexGroup sur le système de stockage principal. Le distributeur sélectif 4.6 ajoute la prise en charge de SnapMirror pour les datastores basés sur FlexGroup. L'utilisation de snapshots basés sur les baies et de la réplication est le moyen le plus efficace de protéger vos données.</block>
  <block id="6c5f0256b71da4e103acbeed0dfcc379" category="summary">Ce document décrit les aspects de sécurité du plug-in SnapCenter pour VMware.</block>
  <block id="3fd4fd8640d78da436f762569919841f" category="list-text">*Activité de réponse aux incidents de sécurité des produits.* les vulnérabilités de sécurité sont découvertes à la fois en interne et en externe dans l'entreprise et peuvent constituer un risque sérieux pour la réputation de NetApp si elles ne sont pas traitées dans les délais impartis. Pour faciliter ce processus, l'équipe d'intervention en cas d'incident de sécurité des produits (PSIRT) signale et effectue le suivi des vulnérabilités.</block>
  <block id="a2132633bc2804871caed9697d50a10d" category="summary">Prise en charge des fonctionnalités, limites et vVols avec les outils ONTAP.</block>
  <block id="2fa76de41291847c8d191ea664c53395" category="summary">En savoir plus sur le cluster de stockage vSphere Metro avec ONTAP</block>
  <block id="0ecd760f5e697e57a60b2f1597be9d54" category="admonition">Pour plus d'informations sur les volumes virtuels VMware vSphere, SPBM et ONTAP, voir <block ref="2e6ec19fbf81081d6cc68364fb2fb656" category="inline-link-macro-rx"></block>.</block>
  <block id="431a88aaf8eee90b865aec0ca23cfc8c" category="paragraph">NMP et ONTAP prennent en charge le protocole ALUA (Asymmetric Logical Unit Access) pour négocier des chemins optimisés et non optimisés. Dans ONTAP, un chemin optimisé pour le protocole ALUA suit un chemin d'accès direct aux données, utilisant un port cible sur le nœud qui héberge la LUN accédée. ALUA est activé par défaut dans vSphere et ONTAP. Le NMP reconnaît le cluster ONTAP en tant que ALUA, et il utilise le plug-in ALUA de type baie de stockage <block ref="d4f7bd3bf4872a2f8cd0cbe400fb23d0" prefix="(" category="inline-code"></block>) et sélectionne le plug-in de sélection de chemin de tourniquet <block ref="4646bb781f9a95f64c182af129e43c7c" prefix="(" category="inline-code"></block>).</block>
  <block id="7dbbfa4d228c6ffe9a64c938bc057b0d" category="inline-image-macro">connectivité multivoie</block>
  <block id="4525956d57ef52f4b2a4f341fbeec28e" category="paragraph"><block ref="4525956d57ef52f4b2a4f341fbeec28e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8692ff2ea8c35b5c4c7cea90481e416c" category="summary">Ce document classe et énumère les paramètres de stockage et de réseau recommandés.</block>
  <block id="ff6fdc6e7749c69219fc26d54c625bd5" category="paragraph">NetApp a développé un ensemble de paramètres hôtes ESXi optimaux pour les protocoles NFS et les protocoles en mode bloc. Des conseils spécifiques sont également fournis concernant les paramètres de chemins d'accès multiples et de délai d'expiration des HBA pour un comportement correct avec ONTAP basé sur les tests internes NetApp et VMware.</block>
  <block id="bc25cf0638b9454338db449fa254150f" category="paragraph">Ces valeurs sont facilement définies à l'aide des outils ONTAP pour VMware vSphere : dans le tableau de bord Résumé, cliquez sur Modifier les paramètres dans le portlet systèmes hôtes ou cliquez avec le bouton droit de la souris sur l'hôte dans vCenter, puis accédez à Outils ONTAP &gt; définir les valeurs recommandées.</block>
  <block id="baee97fad9d55c529dc7a7eb07fd1ba4" category="cell">VSphere 6.0 ou version ultérieure, défini sur 256
Toutes les autres configurations NFS définies sur 64.</block>
  <block id="b3fd5cebc3e5891cccea8f8df97003e0" category="paragraph">Les sections suivantes présentent les meilleures pratiques de déploiement avec ONTAP et VMware SRM.</block>
  <block id="c89f9fd1a8019dc4d7a2559a982d3aa8" category="inline-link-macro">Présentation de la configuration S3</block>
  <block id="f14de37f621abb28f0bf089cae467a29" category="paragraph">À l'origine, cette approche unifiée faisait référence à la prise en charge des protocoles NAS et SAN sur un système de stockage unique. ONTAP continue d'être l'une des principales plateformes pour SAN, tout comme sa puissance initiale en matière de stockage NAS. ONTAP prend désormais également en charge le protocole objet S3. Bien que S3 ne soit pas utilisé pour les datastores, vous pouvez l'utiliser pour les applications hôtes. Pour en savoir plus sur la prise en charge du protocole S3 dans ONTAP, consultez le <block ref="9a0a48164e4b196191c2134bda6f342d" category="inline-link-macro-rx"></block>.</block>
  <block id="8eb06904cba6440e6130ac3e32b68aba" category="paragraph">*REMARQUE :* pour plus d'informations sur les SVM, le stockage unifié et l'accès client, voir <block ref="9e7286a7ad3ab81fa024704c7a52e505" category="inline-link-macro-rx"></block> Dans le centre de documentation ONTAP 9.</block>
  <block id="d96a9839a4f7a8d356a868bd23816516" category="summary">ONTAP est une solution de stockage leader pour les environnements VMware vSphere depuis près de vingt ans et continue d'ajouter des fonctionnalités innovantes pour simplifier la gestion tout en réduisant les coûts. Ce document présente la solution ONTAP pour vSphere, comprenant les dernières informations sur les produits et les meilleures pratiques, afin de rationaliser le déploiement, de réduire les risques et de simplifier la gestion.</block>
  <block id="93fbb268e5e551ae95265cfe3b3b6c7a" category="paragraph">PostgreSQL est fourni avec des variantes incluant PostgreSQL, PostgreSQL plus et EDB Postgres Advanced Server (EPAS). PostgreSQL est généralement déployé en tant que base de données interne pour les applications multiniveaux. Il est pris en charge par les logiciels middleware courants (tels que PHP, Java, Python, Tcl/TK, ODBC, Et JDBC) et a toujours été un choix populaire pour les systèmes de gestion de bases de données open source. ONTAP constitue un excellent choix pour l'exécution des bases de données PostgreSQL et ses fonctionnalités de gestion des données fiables, performantes et efficaces.</block>
  <block id="bbc2d665b02dc421c5c756db4b973610" category="sidebar">Microsoft Hyper-V</block>
  <block id="672553790d8814b967eb8623e754ea84" category="sidebar">Instructions de déploiement et meilleures pratiques de stockage</block>
  <block id="c5865855c43d734069987786177edd98" category="sidebar">Hyper-V</block>
  <block id="230dea8fdf5e53eb32282fb3f8d4d9f6" category="sidebar">Instructions de déploiement et meilleures pratiques de stockage</block>
  <block id="3c0fa9c86e8d92c7a146b2d71467ab2e" category="sidebar">Stockage NetApp et environnement Windows Server</block>
  <block id="1ed211700a6cc31a2b45adb662dcbb8a" category="sidebar">Le provisionnement dans des environnements SAN</block>
  <block id="41ffc5ff950f2260951b6b6150c36f6b" category="sidebar">Le provisionnement dans les environnements SMB</block>
  <block id="e5f52b64058cb937fdd114369219d380" category="sidebar">Infrastructure de stockage Hyper-V sur NetApp</block>
  <block id="4380100fa910735712157068aeec0575" category="sidebar">Déployer Hyper-V Live migration dans un environnement en cluster</block>
  <block id="0726f4e9c3c98564af638f1b4cd17a9e" category="sidebar">Déployer Hyper-V Live migration en dehors d'un environnement en cluster</block>
  <block id="1bbd09497cd931a02f8dc0ee3cfcf19d" category="sidebar">Déployer la réplique Hyper-V en dehors d'un environnement en cluster</block>
  <block id="832a116d7f9184d8880a539553a0cb52" category="sidebar">Déployer la réplique Hyper-V dans un environnement en cluster</block>
  <block id="1a85c0d242c43eb56cc500e60d323331" category="paragraph">VMFS est un système de fichiers en cluster hautes performances qui fournit des datastores sous forme de pools de stockage partagés. Les datastores VMFS peuvent être configurés avec des LUN accessibles via FC, iSCSI, FCoE ou avec des espaces de noms NVMe accessibles via les protocoles NVMe/FC ou NVMe/TCP. VMFS permet à chaque serveur ESX d'un cluster d'accéder simultanément au stockage. La taille de LUN maximale est généralement de 128 To à partir de ONTAP 9.12.1P2 (et versions antérieures avec les systèmes ASA). Par conséquent, un datastore VMFS 5 ou 6 de 64 To de taille maximale peut être créé à l'aide d'une seule LUN.</block>
  <block id="8983ee0717807e5385f3c8b2c70a177c" category="list-text">Tr-4597 : VMware vSphere pour ONTAP
<block ref="0bff808225ac084b8184e7670c17aa52" category="inline-link-macro-rx"></block></block>
  <block id="1f7ff87198d4a8563ac0d42354d47052" category="list-text">Tr-4400 : volumes virtuels VMware vSphere avec ONTAP
<block ref="57ea579fe6c0d333a496008248ad03e2" category="inline-link-macro-rx"></block></block>
  <block id="ef8c76bd50596fa93881a13dac3f23b3" category="inline-link-macro"><block ref="ef8c76bd50596fa93881a13dac3f23b3" category="inline-link-rx"></block></block>
  <block id="6e5923e0b2d91653ee7dd35aa5f48141" category="list-text">Tr-4015 Guide des meilleures pratiques en matière de configuration de SnapMirror pour ONTAP 9
<block ref="6a851721cd10ebeb2f9cfa107f963956" category="inline-link-macro-rx"></block></block>
  <block id="1e626dbc797733633cd43ac045564b36" category="list-text">Créateur d'utilisateurs RBAC pour ONTAP
<block ref="51416f5c8b6f7981eb23be678ab313ad" category="inline-link-macro-rx"></block></block>
  <block id="eaef75afe923a97ffd4ccab86876f8da" category="list-text">Outils ONTAP pour les ressources VMware vSphere
<block ref="9d52dd6d1c195e015d4baef3146522a8" category="inline-link-macro-rx"></block></block>
  <block id="58b39d11ffaef440efc4e3c365487610" category="list-text">Documentation VMware site Recovery Manager
<block ref="18c037ca2f7fe7180f506030fe7e514c" category="inline-link-macro-rx"></block></block>
  <block id="bc11d67bfced1da7778c2cabee9e7615" category="paragraph">Reportez-vous à la <block ref="de89165a46abdf575eb9a1ba0995e131" category="inline-link-macro-rx"></block> Le site de support NetApp vous assure que les versions de produits et de fonctionnalités mentionnées dans le présent document sont prises en charge par votre environnement. NetApp IMT définit les composants et versions de produits qu'il est possible d'utiliser pour créer des configurations prises en charge par NetApp. Les résultats dépendent des installations de chaque client et de leur conformité aux spécifications publiées.</block>
  <block id="e651877073d877e1ee090d986eafc550" category="list-text">Vous devez disposer de clusters Hyper-V situés dans le même emplacement ou dans des emplacements géographiques distincts, et servant de clusters principal et de clusters de réplica. Révision <block ref="8a150f92c22920868769b8738759e23d" category="inline-link-macro-rx"></block> pour en savoir plus.</block>
  <block id="8762adae157b34ee542f2e614401603a" category="list-text">Concepts relatifs à ONTAP
<block ref="836022e29667128997850a15d18e8759" category="inline-link-rx"></block></block>
  <block id="e7b3912abd11fa36935a211d0189ebc2" category="list-text">Bonnes pratiques pour le SAN moderne
<block ref="49df8abaa6163afdde37b69f7f59185c" category="inline-link-rx"></block></block>
  <block id="05c54431756e1b1a7114938bc6f4b199" category="list-text">Disponibilité et intégrité des données des baies SAN 100 % Flash de NetApp avec NetApp ASA
<block ref="8f140ecff12b563e3c96a8cff991aedb" category="inline-link-rx"></block></block>
  <block id="bc96f334e3988ce96701a7082c0e23b5" category="list-text">Mise en route avec Nano Server +
<block ref="abdd6de84336a7f761fbe384605879e9" category="inline-link-rx"></block></block>
  <block id="0e660b82d6e28b6935041a5223ed1aed" category="paragraph">Pour déployer la migration en direct, vous devez configurer des serveurs Hyper-V dans un cluster de basculement avec stockage partagé. Révision <block ref="8a150f92c22920868769b8738759e23d" category="inline-link-macro-rx"></block> pour en savoir plus.</block>
  <block id="1dd1e97374852e1f244963d9fdb0c414" category="list-text">Test du basculement planifié. Déplacez des machines virtuelles vers un autre nœud via une migration dynamique, une migration rapide ou une migration du stockage (déplacement). Révision <block ref="ba8afff2d0e4662eeb47d28935e79828" category="inline-link-macro-rx"></block> pour en savoir plus.</block>
  <block id="8737a5d2bc43b0eb76ab5674d0fcb094" category="sidebar">Présentation de SRM avec ONTAP</block>
  <block id="76f6daa4bfab6ca8a7350e46d3d6718f" category="sidebar">Informations supplémentaires pour SRM</block>
  <block id="3ebf71fd7bd7392466a892c2228b2f58" category="section-title">Provisionnement des partages SMB sur Windows Server</block>
  <block id="674b9c5bbf2379d6c48343d029972e53" category="section-title">Intégration de l'hôte</block>
  <block id="16ce478a465011bacaa6e508063c2648" category="section-title">Choses à retenir</block>
  <block id="83f04319244758f7531b398c51aa9f38" category="section-title">Provisionnement des partages SMB sur Nano Server</block>
  <block id="2323e97f7cf2da464750911f1f3e1af6" category="doc">Déployer la réplique Hyper-V dans un environnement en cluster</block>
  <block id="36b10adb4505559b63b091b53614af1f" category="section-title">Déduplication NetApp</block>
  <block id="1ba5c1747d37a3d7ae84fd1dcac77603" category="section-title">Lecture ultérieure</block>
  <block id="50802d3e5a25b93d471686a10da03dd8" category="section-title">Et des meilleures pratiques</block>
  <block id="67bd1e9f90c0abcd3fe89dce2e8b6307" category="doc">Déployer Hyper-V Live migration en dehors d'un environnement en cluster</block>
  <block id="f2b84afd0523a6df7547c404aa3647d8" category="section-title">Public visé</block>
  <block id="458ed20ed5d1729b427e233e0e52f797" category="section-title">Provisionnement du stockage NetApp pour Windows Server</block>
  <block id="e648c74a53b161f90c8e915624ce6135" category="section-title">Gestion du stockage NetApp</block>
  <block id="9292ee6bce21e93911c38cd0a1c2e209" category="section-title">Meilleures pratiques en matière de mise en réseau</block>
  <block id="381400d1babe5b80783d5e46896d832e" category="doc">Déploiement du serveur Nano</block>
  <block id="02676c7c18a8d411999242a1f5731de2" category="section-title">Stockage Hyper-V sur NetApp CIFS</block>
  <block id="00a66fbc09172147ac7be9c85b708a6b" category="section-title">Transfert de données allégé</block>
  <block id="39d0bfdf27f1fc555ae2f030e21f8818" category="section-title">Mise en cluster Hyper-V : haute disponibilité et évolutivité pour les machines virtuelles</block>
  <block id="10fd9c0040ca7b99a67758c3cd638746" category="section-title">Migration dynamique dans un environnement en cluster</block>
  <block id="ed7cd01cb26e2db33a36eaa87ac85ff1" category="section-title">Migration dynamique en dehors d'un environnement en cluster</block>
  <block id="023196611fee49915adf49422b3289e6" category="section-title">Hyper-V Replica : reprise après incident pour les machines virtuelles</block>
  <block id="e78f6d0414a6dde66f4e12a3e218620b" category="section-title">Réplication étendue</block>
  <block id="e43f3be13a49d6eeab4304d80790eaa0" category="section-title">Détecter le stockage bloc</block>
  <block id="adc95a9707f2f351740aa0d52f08981e" category="section-title">Approche NetApp FlexClone</block>
  <block id="0bee1618a00f62535bd1e3f03af6a8f0" category="section-title">Démarrage à partir du SAN pour l'hôte physique</block>
  <block id="68468d5f213be162fe50260787894f8f" category="section-title">Démarrage à partir du SAN pour la machine virtuelle</block>
  <block id="5b6253395cb699e828a4e33bbe3ad99e" category="doc">Déployer le réplica Hyper-V en dehors d'un environnement en cluster</block>
  <block id="c56bd6d44fe37df3133f12e09059b492" category="doc">Déployez le cluster Hyper-V.</block>
  <block id="284558d4613b1e72103300f1b8973b3b" category="paragraph">Lors de l'installation initiale, ESX ne possède pas de fonctionnalités préconfigurées, telles que l'hébergement d'un système d'exploitation invité ou la prise en charge d'une application utilisateur. Il s'agit d'un conteneur vide jusqu'à ce qu'une machine virtuelle (VM) soit définie. ONTAP fonctionne de manière similaire : Lors de la première installation de ONTAP, aucune fonctionnalité de service des données n'est disponible tant qu'un SVM n'est pas créé. Pour configurer les services de données.</block>
  <block id="2737c9012caaebb1cbb9e526400a2345" category="paragraph">Dans un environnement de colocation, on peut attribuer à chaque locataire une SVM dédiée aux données. La limite du nombre de SVM et de LIF par cluster, paire HA et nœud dépend du protocole utilisé, du modèle de nœud et de la version de ONTAP.  Consulter le <block ref="41f66f34b3a905f864500c9319fdff8f" category="inline-link-macro-rx"></block> pour ces limites.</block>
  <block id="50812cc1b8d48579d382b689e4393be6" category="paragraph">Certaines données ne contiennent pas de données dupliquées. Par exemple, un bloc Oracle contient un en-tête globalement unique à la base de données et une bande-annonce presque unique. Par conséquent, la déduplication d'une base de données Oracle permet rarement de réaliser plus de 1 % d'économies. La déduplication avec les bases de données MS SQL est légèrement meilleure, mais les métadonnées uniques au niveau des blocs restent une limitation.</block>
  <block id="e237dd01ca20b300861ea50239fefbf9" category="paragraph">Il s'agit notamment de mesures de planification courantes, telles que l'assurance d'une bande passante suffisante sur le SAN entre l'hôte et le système de stockage, la vérification de la présence de tous les chemins SAN entre tous les périphériques requis, l'utilisation des paramètres de port FC requis par le fournisseur du commutateur FC, la prévention des conflits ISL, et à l'utilisation d'un système de surveillance de la structure SAN approprié.</block>
  <block id="bab63c3a8b4ae009c3596c809e27d73b" category="paragraph">La réplication MetroCluster repose sur la technologie NetApp SyncMirror, conçue pour basculer efficacement en mode synchrone et en sortir. Cette fonctionnalité répond aux exigences des clients qui demandent une réplication synchrone, mais qui ont également besoin d'une haute disponibilité pour leurs services de données. Par exemple, si la connectivité à un site distant est coupée, il est généralement préférable que le système de stockage continue de fonctionner dans un état non répliqué.</block>
  <block id="bf4d44f407dab4b746f1eaeb06e897af" category="paragraph">De nombreuses solutions de réplication synchrone ne peuvent fonctionner qu'en mode synchrone. Ce type de réplication « tout ou rien » est parfois appelé mode domino. Ces systèmes de stockage cessent d'accéder aux données au lieu d'interrompre la synchronisation des copies locales et distantes des données. Si la réplication est forcée, la resynchronisation peut prendre beaucoup de temps et laisser un client exposé à des pertes de données complètes pendant la période de rétablissement de la mise en miroir.</block>
  <block id="8f076395fe8f8f46c03efb655db313e6" category="section-title">Connexion directe FC</block>
  <block id="722830ffc5e46dbe206670f85cd1d889" category="paragraph">ONTAP et certains autres produits NetApp prennent désormais en charge l'authentification multifacteur (MFA) selon plusieurs méthodes. Le résultat est un nom d'utilisateur/mot de passe compromis seul n'est pas un thread de sécurité sans les données du deuxième facteur, tel qu'un FOB ou une application de smartphone.</block>
  <block id="37c43820ab88f1340855c30955eec330" category="section-title">Vérification multiadministrateur</block>
  <block id="1910dc5a02cb649cc24df5670c631e34" category="paragraph"><block ref="1910dc5a02cb649cc24df5670c631e34" category="inline-image-macro-rx" type="image"></block></block>
  <block id="416d0d3efc5f3919abcdaaa2364738d9" category="paragraph"><block ref="416d0d3efc5f3919abcdaaa2364738d9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="28c6217e46797f76e427c591070cf50c" category="paragraph"><block ref="28c6217e46797f76e427c591070cf50c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d03e09c345dd723011486de3855c13b2" category="list-text">Documentation SMB
<block ref="409ef354547d1e3428907ed7fdd2dc6e" category="inline-link-rx"></block></block>
  <block id="834873443aaaf2c09b851c8b0f7b2497" category="section-title">Compression des bases de données</block>
  <block id="2ee3c7318caa2523e9c749e4e2152266" category="paragraph">L'un des points de confusion les plus courants avec les nouveaux clients ONTAP est l'utilisation des volumes FlexVol, communément appelés simplement « volumes ».</block>
  <block id="ff2dabe8a40c84d01b0584c50319a79e" category="paragraph">Un volume n'est pas une LUN. Ces termes sont utilisés de façon synonymie avec de nombreux autres produits de fournisseurs, y compris les fournisseurs de cloud. Les volumes ONTAP sont des conteneurs de gestion simples. Ils ne fournissent pas les données en eux-mêmes, ni n'occupent l'espace. Il s'agit de conteneurs pour les fichiers et les LUN. Ils permettent d'améliorer et de simplifier la gestion, notamment à grande échelle.</block>
  <block id="92a5781e05d0d9b7044f44e2ef7bff84" category="section-title">Volumes et LUN</block>
  <block id="faf1e8eebcac2d18d4ac10e75f416a3f" category="paragraph">Les LUN associées sont généralement situées en colocation dans un seul volume. Par exemple, une base de données qui nécessite 10 LUN doit généralement avoir les 10 LUN placées sur le même volume.</block>
  <block id="3a5bf2895b95fa2b89fce4dcf94fd2f9" category="list-text">L'utilisation d'un rapport LUN/volumes de 1:1, c'est-à-dire une LUN par volume, n'est *pas* une bonne pratique formelle.</block>
  <block id="1886f4ac4aa2f64bf8224f178a36ba92" category="list-text">À la place, les volumes doivent être considérés comme des conteneurs pour les charges de travail ou les datasets. Il peut y avoir une seule LUN par volume ou il peut y en avoir plusieurs. La bonne réponse dépend des exigences de gestion.</block>
  <block id="0de05608a70e8ec5863afc41ba150178" category="list-text">La diffusion des LUN sur un nombre inutile de volumes peut entraîner une surcharge supplémentaire et des problèmes de planification pour des opérations telles que les opérations de snapshot, un nombre excessif d'objets affichés dans l'interface utilisateur et entraîner l'atteinte des limites de volume de la plate-forme avant que la limite de LUN ne soit atteinte.</block>
  <block id="0955dbd01a9f8194cad5a6876b931f5a" category="section-title">Volumes, LUN et snapshots</block>
  <block id="9bbd4f2fca3a1e1aaa76abf8cb43351c" category="paragraph">Les règles et planifications Snapshot sont placées sur le volume, et non sur la LUN. Un jeu de données composé de 10 LUN ne nécessite qu'une seule règle de snapshot lorsque ces LUN sont co-localisées dans le même volume.</block>
  <block id="f34f28bb7a1701ded173c2ab504f5c20" category="paragraph">En outre, la colocation de toutes les LUN associées à un jeu de données donné dans un seul volume permet d'effectuer des opérations de snapshot atomiques. Par exemple, une base de données résidant sur 10 LUN ou un environnement d'application VMware comprenant 10 systèmes d'exploitation différents peut être protégé comme un objet unique et cohérent si les LUN sous-jacentes sont tous placés sur un seul volume. S'ils sont placés sur des volumes différents, les snapshots peuvent être synchronisés à 100 %, même s'ils sont programmés en même temps.</block>
  <block id="fe7797cb1dbe36223357d4c25ff30c9e" category="paragraph">Dans certains cas, il peut être nécessaire de diviser un jeu de LUN associé en deux volumes différents en raison des exigences de restauration. Par exemple, une base de données peut contenir quatre LUN pour les fichiers de données et deux LUN pour les journaux. Dans ce cas, un volume de fichiers de données avec 4 LUN et un volume de journaux avec 2 LUN peuvent être la meilleure option. La raison en est une capacité de restauration indépendante. Par exemple, le volume des fichiers de données peut être restauré de manière sélective à un état antérieur, ce qui signifie que les quatre LUN seraient rétablies à l'état du snapshot, tandis que le volume du journal contenant ses données stratégiques ne serait pas affecté.</block>
  <block id="66383d632fe33f1b7c20af9c1c142028" category="section-title">Volumes, LUN et SnapMirror</block>
  <block id="8fb29c5f40886ece62abcd994f1aa202" category="paragraph">Les règles et opérations SnapMirror sont, tout comme les opérations Snapshot, exécutées sur le volume, et non sur la LUN.</block>
  <block id="7d8d0afc8d9998a7e6457c6251b4defc" category="paragraph">La colocation de LUN associées dans un seul volume vous permet de créer une relation SnapMirror unique et de mettre à jour toutes les données qu'elle contient en une seule mise à jour. Comme pour les instantanés, la mise à jour sera également une opération atomique. La destination SnapMirror dispose d'une réplique instantanée unique des LUN source. Si les LUN ont été réparties sur plusieurs volumes, les répliques peuvent être cohérentes les unes avec les autres.</block>
  <block id="e45ffde45b5f4090fe8c92a49d38bcb2" category="section-title">Volumes, LUN et QoS</block>
  <block id="756a4c619fb81eafd00bc072334a5877" category="paragraph">S'il est possible d'appliquer la QoS de manière sélective à chaque LUN, il est généralement plus facile de la configurer au niveau du volume. Par exemple, toutes les LUN utilisées par les invités dans un serveur ESX donné peuvent être placées sur un seul volume, puis une règle de qualité de service adaptative de ONTAP peut être appliquée. Vous obtenez ainsi une limite d'IOPS par To qui s'applique à toutes les LUN.</block>
  <block id="fb219ca81e7a635609b70d290a7a3aa2" category="paragraph">De même, si une base de données nécessitait 100 000 IOPS et occupait 10 LUN, il serait plus facile de définir une seule limite de 100 000 IOPS sur un seul volume que de définir 10 limites individuelles de 10 000 IOPS, une sur chaque LUN.</block>
  <block id="56739402ea66bd29b7303b69ee165d5b" category="section-title">Dispositions multi-volumes</block>
  <block id="c509cb5f7def30cc77b15b0e91ab39a4" category="paragraph">Dans certains cas, la distribution de LUN sur plusieurs volumes peut être avantageuse. La principale raison est la répartition des contrôleurs. Par exemple, un système de stockage haute disponibilité peut héberger une base de données unique dans laquelle chaque contrôleur a besoin du potentiel de traitement et de mise en cache complet. Dans ce cas, la conception type consisterait à placer la moitié des LUN dans un seul volume sur le contrôleur 1 et l'autre moitié des LUN dans un seul volume sur le contrôleur 2.</block>
  <block id="ad328d1793d6c3621e91d83556548a01" category="paragraph">De même, la répartition des contrôleurs peut être utilisée pour l'équilibrage de la charge. Un système haute disponibilité hébergeant 100 bases de données de 10 LUN chacune peut être conçu où chaque base de données reçoit un volume de 5 LUN sur chacun des deux contrôleurs. Il en résulte une charge symétrique garantie de chaque contrôleur au fur et à mesure que des bases de données supplémentaires sont provisionnées.</block>
  <block id="4cd2d5d8d873ad1f707d88334324153a" category="paragraph">Cependant, aucun de ces exemples ne correspond à un ratio volume/LUN de 1:1. L'objectif reste d'optimiser la gestion en co-localisant les LUN associées dans les volumes.</block>
  <block id="a9fd7be1f3363701ad1b35b16af02c9e" category="paragraph">Par exemple, la conteneurisation est un rapport LUN/volume 1:1. Chaque LUN peut représenter une seule charge de travail et doit être gérée individuellement. Dans ce cas, un rapport de 1:1 peut être optimal.</block>
  <block id="64e5a77897fe6326f14436eaaaf5432b" category="section-title">Allocation d'espace libre et d'espace LVM</block>
  <block id="702db8f3db66a0eec35817fe5d2e4544" category="inline-link-macro">ASMRU</block>
  <block id="096ca5ad0b3774fee4699e2da1bfa884" category="paragraph">L'efficacité du provisionnement fin des LUN actives dans un environnement de système de fichiers peut être perdue au fil du temps suite à la suppression des données. À moins que les données supprimées ne soient écrasées par des zéros (voir également <block ref="5b58c4ec517e475a59d0a785f87cabdc" category="inline-link-macro-rx"></block> Ou l'espace est libéré avec la récupération d'espace TRIM/UNMAP, les données « effacées » occupent de plus en plus d'espace non alloué dans le système de fichiers. En outre, l'utilisation du provisionnement fin des LUN actives est limitée dans de nombreux environnements de base de données, car les fichiers de données sont initialisés sur leur taille complète au moment de la création.</block>
  <block id="ceb8ec6ec593174c2c6f33be2ca966eb" category="summary">Placement des volumes et des LUN Oracle et ONTAP</block>
  <block id="0724b56ced27e0a66fb4692a57fb1436" category="doc">Placement des LUN de la base de données Oracle</block>
  <block id="f595bf3bf71ab0c91a5503ba4efb8ea4" category="paragraph">Le placement optimal des LUN de base de données dans les volumes ONTAP dépend principalement de l'utilisation des différentes fonctionnalités ONTAP.</block>
  <block id="05a1ffdb277b8c7ac1dca78adae0017e" category="sidebar">Placement des LUN</block>
  <block id="9d5c13d45bbf74999764cfe8d4798562" category="summary">Guide de renforcement de la sécurité des outils ONTAP pour VMware vSphere, gestion des certificats HTTPS.</block>
  <block id="d6a1787b51b08315bfcc44f3a9bb4b2f" category="paragraph">Par défaut, les outils ONTAP utilisent un certificat auto-signé automatiquement créé lors de l'installation pour sécuriser l'accès HTTPS à l'interface utilisateur Web. Les outils ONTAP offrent les fonctionnalités suivantes :</block>
  <block id="1eddd0f3479da31541c39e5ddddfa930" category="list-text">Régénérer le certificat HTTPS</block>
  <block id="61bf3033b18d202012951f5bf7be4fa9" category="paragraph">Lors de l'installation des outils ONTAP, un certificat d'autorité de certification HTTPS est installé et le certificat est stocké dans le magasin de clés. L'utilisateur a la possibilité de régénérer le certificat HTTPS via la console maint.</block>
  <block id="b363a018e3596ec66080579ce5bd4c2d" category="paragraph">Les options ci-dessus sont accessibles dans _maint_ console en accédant à _'Configuration de l'application' → 'régénérer les certificats'._</block>
  <block id="43d609906e5ac2fd9406eddd67d6f82a" category="summary">Guide de renforcement de la sécurité des outils ONTAP pour VMware vSphere, points d'accès utilisateur.</block>
  <block id="3562b87b566382dc56e8b6fb2b849126" category="doc">Outils ONTAP pour les points d'accès VMware vSphere (utilisateurs)</block>
  <block id="c015e2af845448c5e88873c4e51c8cac" category="paragraph">L'installation des outils ONTAP pour VMware vSphere crée et utilise trois types d'utilisateurs :</block>
  <block id="6399e228248ba3e1f084750197938b67" category="list-text">Utilisateur système : compte utilisateur root</block>
  <block id="2a408bd40a0a3130a390340955a699ef" category="list-text">Utilisateur de l'application : l'utilisateur administrateur, l'utilisateur maint et les comptes utilisateur db</block>
  <block id="5d212a60c02bc59306c8863b31342276" category="list-text">Utilisateur de support : compte utilisateur diag</block>
  <block id="3c2b7b0ce42bb5eb8141643a9729f4ee" category="section-title">1. Utilisateur du système</block>
  <block id="b277c4882e7365ab0ac88d56cd6154b3" category="paragraph">L'utilisateur System(root) est créé par l'installation des outils ONTAP sur le système d'exploitation sous-jacent (Debian).</block>
  <block id="155b9191864da17a7eaaf07b64d596d8" category="list-text">Un utilisateur système par défaut "root" est créé sur Debian par l'installation des outils ONTAP. Sa valeur par défaut est désactivée et peut être activée ad hoc via la console « maint ».</block>
  <block id="159efbffccd1957bc8c4c78b2a74c085" category="section-title">2. Utilisateur de l'application</block>
  <block id="170cab8b15d5b37a17e43144afe7308d" category="paragraph">L'utilisateur de l'application est nommé en tant qu'utilisateur local dans les outils ONTAP. Il s'agit d'utilisateurs créés dans l'application Outils ONTAP. Le tableau ci-dessous répertorie les types d'utilisateurs d'applications :</block>
  <block id="e01ca242f9b1bef82800de4c209149c7" category="cell">*Utilisateur*</block>
  <block id="f14c276c07197ebef1394a5a219087a1" category="cell">*Description*</block>
  <block id="9eb92414db7b53ac16645af9b0f64e58" category="cell">Utilisateur administrateur</block>
  <block id="ccf6887baccb4288ae3579b56fac8d2a" category="cell">Il est créé lors de l'installation des outils ONTAP et l'utilisateur fournit les informations d'identification lors du déploiement des outils ONTAP. Les utilisateurs ont la possibilité de modifier le mot de passe dans la console « maint ». Le mot de passe expirera dans 90 jours et les utilisateurs devraient changer de mot de passe.</block>
  <block id="55df75b800db0f96de770b3c38f676b4" category="cell">Utilisateur de maintenance</block>
  <block id="a2bc121b09cae43d6c478870f5298ae5" category="cell">Il est créé lors de l'installation des outils ONTAP et l'utilisateur fournit les informations d'identification lors du déploiement des outils ONTAP. Les utilisateurs ont la possibilité de modifier le mot de passe dans la console « maint ». Il s'agit d'un utilisateur de maintenance créé pour exécuter les opérations de la console de maintenance.</block>
  <block id="b124032a093d41b9efbb43f40c538bcb" category="cell">Utilisateur de la base de données</block>
  <block id="86a670227d3e81e8fa34eb4aede3129a" category="section-title">3. Support user(diag user)</block>
  <block id="e482d8f0e37161e7916c7a78d2cf7210" category="paragraph">Lors de l'installation des outils ONTAP, un utilisateur du support est créé. Cet utilisateur peut accéder aux outils ONTAP en cas de problème ou de panne du serveur et collecter les journaux. Par défaut, cet utilisateur est désactivé, mais il peut être activé sur une base ad hoc via la console « maint ». Il est important de noter que cet utilisateur sera automatiquement désactivé après une certaine période.</block>
  <block id="562596399deefc1e2a6cc32eb489976c" category="summary">Guide de renforcement de la sécurité des outils ONTAP pour VMware vSphere.</block>
  <block id="80dd7fd00106118cf9c10abf911b7111" category="paragraph">La liste ci-dessous répertorie les ports et les protocoles requis permettant la communication entre les outils ONTAP pour le serveur VMware vSphere et d'autres entités telles que les systèmes de stockage géré, les serveurs et d'autres composants.</block>
  <block id="d40dfcfdaecc4e8015535acd5de00398" category="section-title">Ports entrants et sortants requis pour OTV</block>
  <block id="834b74ce890c61455ad330759d44eff2" category="paragraph">Veuillez noter le tableau ci-dessous qui répertorie les ports entrants et sortants requis pour le bon fonctionnement des outils ONTAP. Il est important de s'assurer que seuls les ports mentionnés dans le tableau sont ouverts pour les connexions à partir de machines distantes, tandis que tous les autres ports doivent être bloqués pour les connexions à partir de machines distantes. Cela permet d'assurer la sécurité de votre système.</block>
  <block id="5732d3577c35dfcce968ba967a9a6149" category="cell">*Port TCP v4/v6 #*</block>
  <block id="e71a4b7488a97c0e5d8b3ab3efe619e4" category="cell">*Direction*</block>
  <block id="bc437eb0df24b836c84a74f47b391093" category="cell">*Fonction*</block>
  <block id="576fe92cf4e45714b61ed10e5c856aa5" category="cell">Connexions HTTPS +
Utilisé pour les connexions SOAP sur HTTPS +
Ce port doit être ouvert pour permettre à un client de se connecter au serveur d'API des outils ONTAP.</block>
  <block id="4e31bd5bdc8239bb7c98471d3500d951" category="cell">Connexions HTTPS - VP et SRA +
Utilisé pour les connexions SOAP sur HTTPS</block>
  <block id="7e6b20d014d1c659e4eaf20dc2dcd7eb" category="cell">8443</block>
  <block id="aaa2d7fe63bee55de8ffca52cb61fbd5" category="cell">Plug-in distant</block>
  <block id="25fa62922a9b3c1c2763bbf88014e217" category="cell">Port de base de données Derby, uniquement entre cet ordinateur et lui-même, connexions externes non acceptées — connexions internes uniquement</block>
  <block id="c68bd9055776bf38d8fc43c0ed283678" category="cell">8150</block>
  <block id="b482bc4bf0e383b0858c5d9eb0e96ba9" category="cell">Le service d'intégrité des journaux s'exécute sur le port</block>
  <block id="9956361dfa33899fc0efed6ee3946512" category="section-title">Contrôle de l'accès à distance à la base de données Derby</block>
  <block id="58b7326b56820f4b18dfd73dc9707831" category="paragraph">Les administrateurs peuvent accéder à la base de données derby à l'aide des commandes suivantes. Il est accessible via la machine virtuelle locale des outils ONTAP ainsi qu'un serveur distant en procédant comme suit :</block>
  <block id="296068c08046bbf197300e38c4e851cb" category="paragraph">*[.souligné]#exemple:#*</block>
  <block id="10046bc1eb8463e6ca6ae51bd3b7a574" category="inline-image-macro">Derby,largeur=468,hauteur=136</block>
  <block id="36434da35edb72a1f85cbbcc1ff2b197" category="paragraph"><block ref="36434da35edb72a1f85cbbcc1ff2b197" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f21dd7ffc271f1301878c3078a59692d" category="summary">Guide de renforcement de la sécurité des outils ONTAP pour VMware vSphere, bannière de connexion.</block>
  <block id="67f78f0bab8fe81a2b6971543c716d3d" category="paragraph">La bannière de connexion suivante s'affiche lorsque l'utilisateur saisit un nom d'utilisateur dans l'invite de connexion. Notez que SSH est désactivé par défaut et n'autorise que les connexions uniques lorsqu'elles sont activées à partir de la console de la machine virtuelle.</block>
  <block id="ae20daf991a940f9de7033ff0a1af410" category="paragraph">Une fois que l'utilisateur a terminé sa connexion via le canal SSH, le texte suivant s'affiche :</block>
  <block id="8f1b6f904292913013b1f6e578d7b074" category="summary">Guide de renforcement de la sécurité des outils ONTAP pour VMware vSphere, contrôle d'intégrité.</block>
  <block id="cedd87fff2ad5101cd8565e33950e1fb" category="doc">Vérification de l'intégrité des outils ONTAP pour les packages d'installation VMware vSphere</block>
  <block id="aeeb9f5277554716592480db544d25f3" category="paragraph">Deux méthodes sont disponibles pour vérifier l'intégrité des packages d'installation des outils ONTAP.</block>
  <block id="126ba7383e25522e071a963ddd6f220f" category="list-text">Vérification des checksums</block>
  <block id="deccc645a0c8869a44e645f2f4247dbd" category="list-text">Vérification de la signature</block>
  <block id="e5f3970dd7fabab1726b53d58d636de2" category="paragraph">Les sommes de contrôle sont fournies sur les pages de téléchargement des paquets d'installation d'OTV. Les utilisateurs doivent vérifier les sommes de contrôle des paquets téléchargés par rapport à la somme de contrôle fournie sur la page de téléchargement.</block>
  <block id="7452fe022f94726684aeea655673eb0f" category="section-title">Vérification de la signature des outils ONTAP OVA</block>
  <block id="373d060b52f94a014177952dcca0c4e9" category="paragraph">Le paquet d'installation de vApp est livré sous la forme d'une boule de commande. Ce tarball contient des certificats intermédiaires et racine pour l'appliance virtuelle, ainsi qu'un fichier README et un package OVA. Le fichier README guide les utilisateurs sur la façon de vérifier l'intégrité du progiciel VApp OVA.</block>
  <block id="48fefdb76906b256f183e6f68b23eba1" category="paragraph">Les clients doivent également télécharger les certificats racine et intermédiaire fournis sur vCenter version 7.0U3E et ultérieure.  Pour les versions vCenter comprises entre 7.0.1 et 7.0.U3E, la fonctionnalité de vérification du certificat n'est pas prise en charge par VMware. Les clients n'ont pas besoin de télécharger de certificat pour vCenter versions 6.x.</block>
  <block id="84a005842347a9560b170cfcd79c5203" category="section-title">Téléchargement du certificat racine sécurisé vers vCenter</block>
  <block id="57f60da4817dc5d71c45890bb182781e" category="list-text">Connectez-vous à vCenter Server à l'aide du client VMware vSphere.</block>
  <block id="72282f16a7aca6b61acfc6fe27ce55c7" category="list-text">Spécifiez le nom d'utilisateur et le mot de passe de laman@vspher.locl ou d'un autre membre du groupe administrateurs d'authentification unique vCenter. Si vous avez spécifié un domaine différent lors de l'installation, connectez-vous en tant qu'administrateur@mondomaine.</block>
  <block id="9470c9e64c285d5b66a039ab668ab64a" category="list-text">Accédez à l'interface utilisateur de la gestion des certificats : a. Dans le menu Accueil, sélectionnez Administration. b. Sous certificats, cliquez sur gestion des certificats.</block>
  <block id="43a75b176810226695d2db6f52c87b73" category="list-text">Si le système vous y invite, entrez les informations d'identification de votre serveur vCenter.</block>
  <block id="5f51c5b3cb2f48fd1d670bf384d1006d" category="list-text">Sous certificats racine approuvés, cliquez sur Ajouter.</block>
  <block id="55c3b759c54a437c7ced6432f1c62de0" category="list-text">Cliquez sur Parcourir et sélectionnez l'emplacement du fichier .pem du certificat (OTV_OVA_INTER_ROOT_CERT_CHAIN.pem).</block>
  <block id="8acdedaaa4134bb6ae49472b4bc268a7" category="list-text">Cliquez sur Ajouter. Le certificat est ajouté au magasin.</block>
  <block id="e2200da08ea15bdea0f97dbfc4e9f1c7" category="inline-link-macro">Ajoutez un certificat racine de confiance au magasin de certificats</block>
  <block id="6eeecddd909e7e017ba2732e46dc739c" category="paragraph">Reportez-vous à la section <block ref="b8e45b03638af10d852f253eba7e63e3" category="inline-link-macro-rx"></block> pour en savoir plus. Lors du déploiement d'une vApp (à l'aide du fichier OVA), la signature numérique du package vApp peut être vérifiée sur la page « Review details » (vérifier les détails). Si le package vApp téléchargé est authentique, la colonne « Éditeur » affiche « certificat de confiance » (comme dans la capture d'écran suivante).</block>
  <block id="a13b63a149750821fb588cd3cb41c209" category="inline-image-macro">Certificat de confiance</block>
  <block id="a83d8109f7a0cf9c4a04c65c40ecd354" category="paragraph"><block ref="a83d8109f7a0cf9c4a04c65c40ecd354" category="inline-image-macro-rx" type="image"></block></block>
  <block id="61dc5ac976a8bd4a8744d8890305d26e" category="section-title">Vérification de la signature des outils ONTAP ISO et SRA tar.gz</block>
  <block id="d4f26c1c073b64ba200e3fa71762c256" category="paragraph">NetApp partage son certificat de signature de code avec les clients sur la page de téléchargement du produit, ainsi que les fichiers zip du produit pour OTV-ISO et SRA.tgz.</block>
  <block id="a7ac1e7561da5cc70126cfea891de159" category="paragraph">À partir du certificat de signature de code, les utilisateurs peuvent extraire la clé publique comme suit :</block>
  <block id="5f4345a6f62f7a3926b2c3d92f5574f6" category="paragraph">Ensuite, la clé publique doit être utilisée pour vérifier la signature pour iso et tgz produit zip comme ci-dessous :</block>
  <block id="81eeab9506186e2dca8faefa78d54067" category="paragraph">Exemple :</block>
  <block id="c6666237b03fcb86e315a0a06e73b6ef" category="summary">Guide de renforcement de la sécurité des outils ONTAP pour VMware vSphere, chiffrement TLS mutuel pour les connexions de gestion du stockage.</block>
  <block id="53893182b7e17fb2da37935ee3ffda55" category="paragraph">Les versions 9.7 et ultérieures de ONTAP prennent en charge les communications TLS mutuelles. Depuis les outils ONTAP pour VMware et vSphere 9.12, le protocole TLS mutuel est utilisé pour la communication avec les nouveaux clusters ajoutés (selon la version de ONTAP).</block>
  <block id="1be712dee4c47804142318ffb739e46b" category="paragraph">Pour tous les systèmes de stockage précédemment ajoutés : lors d'une mise à niveau, tous les systèmes de stockage ajoutés font l'objet d'une fiabilité automatique et les mécanismes d'authentification basés sur des certificats sont configurés.</block>
  <block id="d39adf53eaace0fbba30d4e13760a974" category="paragraph">Comme dans la capture d'écran ci-dessous, la page de configuration du cluster affiche l'état d'authentification mutuelle TLS (Certificate Based Authentication), configurée pour chaque cluster.</block>
  <block id="c036889d83926f57571c8b12e4f7fb6f" category="inline-image-macro">image2,largeur=468,hauteur=158</block>
  <block id="095064767a4b9cadb4016dfc2788237c" category="paragraph"><block ref="095064767a4b9cadb4016dfc2788237c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="53f061d401dd80027634ccca2a19cd8d" category="section-title">*Cluster Add*</block>
  <block id="7ce4b2757e70979f49bcf8f64ba36363" category="paragraph">Lors du workflow d'ajout de cluster, si le cluster ajouté prend en charge MTLS, MTLS sera configuré par défaut. L'utilisateur n'a pas besoin d'effectuer de configuration pour cela. La capture d'écran ci-dessous présente l'écran présenté à l'utilisateur lors de l'ajout d'un cluster.</block>
  <block id="3c1556a297200019d3a0b8045c0956b9" category="inline-image-macro">Ajouter un système de stockage,largeur=450,hauteur=400</block>
  <block id="3a225aabc3c5c25670ad0b4d131da24f" category="paragraph"><block ref="3a225aabc3c5c25670ad0b4d131da24f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="987de6e025f6af1fc4451710295ca76f" category="inline-image-macro">Ajouter un système de stockage,largeur=468,hauteur=416</block>
  <block id="576a9128888c73fc82869b3ae173c7d2" category="paragraph"><block ref="576a9128888c73fc82869b3ae173c7d2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="307eba22b8070bb93e642827620f8588" category="paragraph"><block ref="307eba22b8070bb93e642827620f8588" category="inline-image-macro-rx" type="image"></block></block>
  <block id="71cfed326a2cabd3b505c6580123a459" category="inline-image-macro">Ajouter un système de stockage,largeur=468,hauteur=516</block>
  <block id="a3a8f9da50b3f15d69f3186129f159f6" category="paragraph"><block ref="a3a8f9da50b3f15d69f3186129f159f6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3b3ebbeea272602ddec07bb77e34668a" category="section-title">Modification du cluster</block>
  <block id="d2562e450657937f981a45d9d18ff4ec" category="paragraph">Lors de l'opération d'édition de cluster, il existe deux scénarios :</block>
  <block id="500bcb89776517849e2e07073aad4eca" category="list-text">Si le certificat ONTAP expire, l'utilisateur devra obtenir le nouveau certificat et le télécharger.</block>
  <block id="edf2227e3378b5b0864ef73e58d39d77" category="list-text">Si le certificat OTV expire, l'utilisateur peut le régénérer en cochant la case.</block>
  <block id="6db8cdf80049c7cf629fe6f8f6e3a9c0" category="list-text">_Générer un nouveau certificat client pour ONTAP._</block>
  <block id="acba923a9524c642724d6ff34f5dac93" category="inline-image-macro">Modifier le système de stockage,largeur=468,hauteur=461</block>
  <block id="6a59df9970674c274e20b1d91be2df8a" category="paragraph"><block ref="6a59df9970674c274e20b1d91be2df8a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="75545011d3e6abe8a2cd8cd5bc21c6fd" category="paragraph"><block ref="75545011d3e6abe8a2cd8cd5bc21c6fd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="14a73da2f5fe352620bed1b49a3319ed" category="summary">Guide de renforcement de la sécurité des outils ONTAP pour VMware vSphere, protection de la sécurité réseau contre les attaques dos.</block>
  <block id="8f7e7bd942f453f0550dc4f907e88810" category="paragraph">Par défaut, le nombre maximal de requêtes simultanées par utilisateur est de 48. L'utilisateur root des outils ONTAP peut modifier cette valeur en fonction des besoins de son environnement. *Cette valeur ne doit pas être définie sur une valeur très élevée car cela fournit un mécanisme contre les attaques par déni de service (DOS).*</block>
  <block id="99c1088ea27d16b42c6b45d794f59d3f" category="paragraph">Les utilisateurs peuvent modifier le nombre maximal de sessions simultanées et d'autres paramètres pris en charge dans le fichier *_/opt/netapp/vscserver/etc/dofilterParams.json_*.</block>
  <block id="5e7c907630f5a432ac6b39f0b8c04c28" category="paragraph">Nous pouvons configurer le filtre en utilisant les paramètres suivants :</block>
  <block id="a35f2f4ccb228969a85b8719ea25b047" category="list-text">*_delayMS_*: Le délai en millisecondes donné à toutes les demandes au-delà de la limite de taux avant qu'elles ne soient prises en compte. Donnez -1 pour rejeter simplement la demande.</block>
  <block id="f1b9d5fde713093a3a80f140d1439d37" category="list-text">*_étrangletMs_*: Combien de temps pour attendre le sémaphore en mode asynchrone.</block>
  <block id="aa363bec6acd7600aedeee5377470bde" category="list-text">*_maxRequestMS_* : durée d'exécution de cette requête.</block>
  <block id="351b695725caafd647abb749c50a7e6f" category="list-text">*_ipWhitelist_*: Une liste d'adresses IP séparées par des virgules qui ne seront pas à débit limité. (Il peut s'agir d'adresses IP vCenter, ESXi et SRA)</block>
  <block id="058e1fe7e6afcd3bcff86482a583976b" category="list-text">*_maxRequestsPerSec_* : nombre maximal de requêtes provenant d'une connexion par seconde.</block>
  <block id="1c1496a21f967d57b50fe5ebb0e62125" category="paragraph">*Valeurs par défaut dans le fichier _dofilterParams_:*</block>
  <block id="9afb15056a8bc8b4402d55eba2274dad" category="summary">Guide de renforcement de la sécurité des outils ONTAP pour VMware vSphere, configuration NTP.</block>
  <block id="48edbd8a951efb0ad617f7868b27a6c0" category="paragraph">Des problèmes de sécurité peuvent parfois se produire en raison de différences dans les configurations de l'heure du réseau. Il est important de s'assurer que tous les périphériques d'un réseau disposent de paramètres d'heure précis pour éviter de tels problèmes.</block>
  <block id="a55d703ea2930e8e72e94ce11c3297ab" category="section-title">*Appareil virtuel*</block>
  <block id="5a65f4c9ca6d99f573528348d36914fa" category="paragraph">Vous pouvez configurer le ou les serveurs NTP à partir de la console de maintenance de l'appliance virtuelle.  Les utilisateurs peuvent ajouter les détails du serveur NTP sous _System Configuration_ =&gt; _Add New NTP Server_ option</block>
  <block id="90ab4fc7a1c530bceac36bda71efbc5f" category="paragraph">Par défaut, le service NTP est ntpd. Il s'agit d'un service hérité qui ne fonctionne pas bien pour les machines virtuelles dans certains cas.</block>
  <block id="6801ecdb823d018c7370042d27b5ee2c" category="section-title">*Debian*</block>
  <block id="dc3bb5166d38d2aec53765aca7c0d24c" category="paragraph">Sous Debian, l'utilisateur peut accéder au fichier /etc/ntp.conf pour obtenir des détails sur le serveur ntp.</block>
  <block id="fec65f0c33739368ce5845fadb6cb880" category="paragraph">Ces guides s'appliquent à la fois aux applications et au système d'exploitation invité de l'appliance elle-même.</block>
  <block id="5aaf8fc9424d7872cf500fb7adcb3b97" category="summary">Guide de renforcement de la sécurité des outils ONTAP pour VMware vSphere, configuration des stratégies de mots de passe.</block>
  <block id="53477738359cebc12d4e01727ee8b5e7" category="paragraph">Les utilisateurs qui déploient des outils ONTAP pour la première fois ou qui effectuent une mise à niveau vers la version 9.12 ou ultérieure devront suivre la stratégie de mot de passe robuste pour l'administrateur et les utilisateurs de base de données. Au cours du processus de déploiement, les nouveaux utilisateurs seront invités à entrer leurs mots de passe. Pour les utilisateurs de brownfield qui effectuent une mise à niveau vers la version 9.12 ou ultérieure, l'option de suivre la stratégie de mot de passe fort sera disponible dans la console de maintenance.</block>
  <block id="7afd9be20a239f83f98bdbc7f90512ef" category="list-text">Une fois que l'utilisateur se connecte à la console maint, les mots de passe sont vérifiés par rapport au jeu de règles complexes et s'il n'est pas suivi, l'utilisateur est invité à les réinitialiser.</block>
  <block id="1e048d74f3d9375186833526a00f4309" category="list-text">La validité par défaut du mot de passe est de 90 jours et après 75 jours, l'utilisateur commence à recevoir la notification de modification du mot de passe.</block>
  <block id="dbb73ef3f8e9b61d387a809281a654cc" category="list-text">Il est nécessaire de définir un nouveau mot de passe à chaque cycle, le système ne prendra pas le dernier mot de passe comme nouveau mot de passe.</block>
  <block id="210b05d5e7375bcb02bcf09a873bbda6" category="list-text">Chaque fois qu'un utilisateur se connecte à la console maint, il vérifie les stratégies de mot de passe comme les captures d'écran ci-dessous avant de charger le menu principal :</block>
  <block id="bc66b4fce20ef49b05e4a54f053e65a6" category="inline-image-macro">Menu principal,largeur=468,hauteur=116</block>
  <block id="4661acb75237098be364b3c05d7d9b7c" category="paragraph"><block ref="4661acb75237098be364b3c05d7d9b7c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8f09c69f731d4d6f2e8d6135082aa8e4" category="list-text">S'il n'est pas trouvé en suivant la stratégie de mot de passe ou sa configuration de mise à niveau à partir des outils ONTAP 9.11 ou antérieurs. L'utilisateur verra alors l'écran suivant pour réinitialiser le mot de passe :</block>
  <block id="4499d4bfb9610056781e2e61956dd0ca" category="inline-image-macro">Écran de réinitialisation du mot de passe,largeur=468,hauteur=116</block>
  <block id="a84278f7bf3ee281e39e467fca1fe454" category="paragraph"><block ref="a84278f7bf3ee281e39e467fca1fe454" category="inline-image-macro-rx" type="image"></block></block>
  <block id="47e6664ac0a72e1d719cfc288383b4f8" category="list-text">Si l'utilisateur tente de définir un mot de passe faible ou donne à nouveau le dernier mot de passe, l'erreur suivante s'affiche :</block>
  <block id="fe04952c38b6a9a7db1a75bbb4905232" category="inline-image-macro">Erreur de mot de passe faible,largeur=468,hauteur=101</block>
  <block id="2c59de9ea5183e73d5fa6382fa7f3fc1" category="paragraph"><block ref="2c59de9ea5183e73d5fa6382fa7f3fc1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8463a61dd94ff5934036d4c8a8936e32" category="doc">Délai d'inactivité</block>
  <block id="704c7fc6c4d40b9af6aafb7cf9b44022" category="paragraph">Pour empêcher tout accès non autorisé, un délai d'inactivité est défini, ce qui déconnecte automatiquement les utilisateurs inactifs pendant une certaine période pendant l'utilisation des ressources autorisées. Cela permet de garantir que seuls les utilisateurs autorisés peuvent accéder aux ressources et contribue à maintenir la sécurité.</block>
  <block id="80f9ebebc8f94450338d28bcb4a2164d" category="inline-link">Configurez la valeur du délai d'expiration du client vSphere</block>
  <block id="3748702da26b5718f1f7c769ce58b009" category="list-text">Par défaut, les sessions du client vSphere se ferment après 120 minutes d'inactivité, ce qui oblige l'utilisateur à se reconnecter pour reprendre à l'aide du client. Vous pouvez modifier la valeur du délai d'attente en modifiant le fichier webclient.properties. Vous pouvez configurer le délai d'expiration du client vSphere<block ref="ec8715bde1a929a6f64160d5372f4574" category="inline-link-rx"></block></block>
  <block id="e4306c4cf124046d8f90518752cd5021" category="list-text">Les outils ONTAP ont un délai de déconnexion de session de l'interface de ligne de commande Web de 30 minutes.</block>
  <block id="7fb0cadcdae6feac05c7b8274b97b3c7" category="sidebar">Présentation du renforcement de la sécurité des outils ONTAP</block>
  <block id="10b486896b1a91f5d38214dfb30c4263" category="sidebar">Vérification de l'intégrité des packages d'installation des outils ONTAP</block>
  <block id="7c7c4cc4771d6114aa8b4d38f5817a85" category="sidebar">Ports et protocoles</block>
  <block id="919e26ea009ce7fa2dcc499a27ccc6aa" category="sidebar">Points d'accès (utilisateurs)</block>
  <block id="333dd505db0523536c6885f47456518c" category="sidebar">Protocole commun</block>
  <block id="6a3f3799bc264d32568bb7169ddd515a" category="sidebar">Certificat HTTPS</block>
  <block id="4b7ad38343c4b2010cf81e6b2933e186" category="sidebar">Bannière de connexion</block>
  <block id="bfdb89134acf30ff5da790924cefa0ac" category="sidebar">Délai d'inactivité dépassé</block>
  <block id="cb197b06aa92a742d01e256d58d3e34b" category="sidebar">Attaque dos</block>
  <block id="d870a4bd29f74339732a958574d2c4eb" category="sidebar">Configuration NTP</block>
  <block id="339ce1d4220ba7045e3a35ef35279ad3" category="sidebar">Stratégies de mot de passe</block>
  <block id="3698338a95ad1801e25ed154adaf1a70" category="summary">Guide sur le renforcement de la sécurité des outils ONTAP pour VMware vSphere, présentation et introduction.</block>
  <block id="47d29daaa26fbfa9c9a069d4cd023ac1" category="doc">Guide de renforcement de la sécurité des outils ONTAP pour VMware vSphere</block>
  <block id="fe0e23a929284a636c245a362ada6472" category="paragraph">Le guide de renforcement de la sécurité des outils ONTAP pour VMware vSphere fournit un ensemble complet d'instructions pour configurer les paramètres les plus sécurisés.</block>
  <block id="bc86ce4caa57368f9094a93dd72ffd28" category="paragraph">Si le mode domino est requis, NetApp propose SnapMirror synchrone (SM-S). Des options au niveau de l'application existent également, comme Oracle DataGuard ou SQL Server Always On Availability Groups. La mise en miroir des disques au niveau du système d'exploitation peut être optionnelle. Pour plus d'informations et d'options, consultez votre équipe de compte NetApp ou partenaire.</block>
  <block id="8059304404c995bd8a349056e7d40e32" category="inline-link">_Solutions NetApp de virtualisation avec VMware de Broadcom_</block>
  <block id="cc5363f91541e771ebd890b2330cb8ba" category="paragraph"><block ref="cc5363f91541e771ebd890b2330cb8ba" category="inline-link-rx"></block></block>
  <block id="c90946faf2ed37e17d936e0b3acde7a7" category="summary">Le chiffrement des données au repos s'étend au-delà des données classiques pour s'étendre à tous les types de données stockées.</block>
  <block id="b1e1676a19b222da72a55b95aa86d3e9" category="paragraph">Pour en savoir plus sur la sécurité, consultez ces ressources.</block>
  <block id="e6bd708199eed7d8bf33ef8308be0b3e" category="inline-link-macro">Rapports techniques sur la sécurité</block>
  <block id="fb7f6edb08c080e81bd91a922a9d08f8" category="list-text"><block ref="fb7f6edb08c080e81bd91a922a9d08f8" category="inline-link-macro-rx"></block></block>
  <block id="ff8c9f0959eb84d21416835c3f9c89d6" category="inline-link-macro">Guides de renforcement de la sécurité</block>
  <block id="589b1ebfaed268e1548717208be6131f" category="list-text"><block ref="589b1ebfaed268e1548717208be6131f" category="inline-link-macro-rx"></block></block>
  <block id="e44de13cc4b452eccde9961bbe9da42b" category="inline-link-macro">La documentation produit relative à la sécurité et au chiffrement des données ONTAP</block>
  <block id="c76e848365d3a2199dfced47ddbf8690" category="list-text"><block ref="c76e848365d3a2199dfced47ddbf8690" category="inline-link-macro-rx"></block></block>
  <block id="0e8f1228bcea37dc870b3c00ddfebb6b" category="list-text">*Offres proposées par NetApp* Amazon FSX pour NetApp ONTAP, Google Cloud NetApp volumes et Azure NetApp Files pour ANF offrent des services de stockage gérés multiprotocole haute performance dans les principaux environnements de cloud public. Elles peuvent être utilisées directement par VMware Cloud on AWS(VMC on AWS), Azure VMware solution(AVS) et Google Cloud VMware Engine(GCVE) en tant que datastores ou stockage pour les systèmes d'exploitation invités (GOS) et les instances de calcul.</block>
  <block id="2c95b4b56070479502ffc85344c7d8b2" category="list-text">*Services cloud* utilisez la sauvegarde et la restauration BlueXP ou SnapMirror Cloud pour protéger les données des systèmes sur site via le stockage dans le cloud public. Cloud Sync vous aide à migrer et à synchroniser vos données sur les systèmes NAS, les magasins d'objets et le stockage Cloud Volumes Service. La reprise d'activité BlueXP est économique et efficace et permet d'exploiter les technologies NetApp comme base d'une solution de reprise d'activité robuste et efficace pour la reprise d'activité dans le cloud, la reprise d'activité sur site et sur site vers un environnement sur site.</block>
  <block id="1a523ba4ece9125275b92ebb41e3cf23" category="inline-link-macro">Documentation Cloud Volumes ONTAP</block>
  <block id="e4501a9ef639002a658af0113906add9" category="list-text"><block ref="e4501a9ef639002a658af0113906add9" category="inline-link-macro-rx"></block></block>
  <block id="7436b418bed093768e360d32105591d2" category="inline-link-macro">Documentation ONTAP Select</block>
  <block id="82fe32c89de73116e2188701ca735c39" category="list-text"><block ref="82fe32c89de73116e2188701ca735c39" category="inline-link-macro-rx"></block></block>
  <block id="c756b6b1ba6b752239a8d49eda5ad2a4" category="inline-link-macro">Documentation sur la sauvegarde et la restauration BlueXP</block>
  <block id="f99b2e5828a20fe99efc9b8c25b42d83" category="list-text"><block ref="f99b2e5828a20fe99efc9b8c25b42d83" category="inline-link-macro-rx"></block></block>
  <block id="b044111e167403664c9e3432eca1f25a" category="inline-link-macro">Documentation sur la reprise d'activité BlueXP</block>
  <block id="ec39a9c8e559c87efc4a1ac3c8dfd136" category="list-text"><block ref="ec39a9c8e559c87efc4a1ac3c8dfd136" category="inline-link-macro-rx"></block></block>
  <block id="f5c286d9dc4cdaffcb8e5c86388e6ed8" category="list-text"><block ref="f5c286d9dc4cdaffcb8e5c86388e6ed8" category="inline-link-macro-rx"></block></block>
  <block id="4dab2f9796b0af6304d00e21e2b9dfb4" category="inline-link-macro">VMware Cloud sur AWS</block>
  <block id="560d5b2cd40977bd7b77b31d7088f657" category="list-text"><block ref="560d5b2cd40977bd7b77b31d7088f657" category="inline-link-macro-rx"></block></block>
  <block id="e6aa20b5d3923ee0466f5d7e7bfed821" category="inline-link-macro">Qu'est-ce que Azure NetApp Files ?
</block>
  <block id="810dc5c2e801b56b11325dd2aca0775c" category="list-text"><block ref="810dc5c2e801b56b11325dd2aca0775c" category="inline-link-macro-rx"></block></block>
  <block id="9789f0612fda153726aa8ad87265e4b9" category="inline-link-macro">Solution Azure VMware</block>
  <block id="f068ad668d317d445bc0da61125c318f" category="list-text"><block ref="f068ad668d317d445bc0da61125c318f" category="inline-link-macro-rx"></block></block>
  <block id="8cb69aa5b1609d0a39f0fcd576c07df6" category="inline-link-macro">Moteur VMware Google Cloud</block>
  <block id="dadb2f85467c159b9d8387744cdd0ce6" category="list-text"><block ref="dadb2f85467c159b9d8387744cdd0ce6" category="inline-link-macro-rx"></block></block>
  <block id="e6288bb2b93ca74537fbff66317f01d9" category="inline-link-macro">Qu'est-ce que Google Cloud NetApp volumes ?</block>
  <block id="e19aa8cca2f701dba5fc123376bebdb5" category="list-text"><block ref="e19aa8cca2f701dba5fc123376bebdb5" category="inline-link-macro-rx"></block></block>
  <block id="b44c4aa4ed40a2c01a89549bc8746cbd" category="cell">Défini sur 512 Mo pour la plupart des versions vSphere 6.X.
Réglez sur la valeur par défaut (1024 Mo) pour 6.5U3, 6.7U3 et 7.0 ou ultérieure.</block>
  <block id="f3c4f211a4831f8f7c223705b0fccd5d" category="paragraph">Les limites de débit sont utiles pour contrôler les niveaux de service, gérer les charges de travail inconnues ou tester les applications avant le déploiement pour s'assurer qu'elles n'affectent pas les autres charges de travail en production. Elles peuvent également être utilisées pour contraindre une charge de travail dominante après son identification.</block>
  <block id="5ab12aefceb83851b73081a686bd30ab" category="section-title">Prise en charge des règles de QoS de ONTAP</block>
  <block id="8aa45e69fd8330d5e4d2f6e16309ff41" category="paragraph">Des niveaux minimaux de service basés sur des IOPS sont également pris en charge pour assurer des performances prévisibles pour les objets SAN d'ONTAP 9.2 et pour les objets NAS d'ONTAP 9.3.</block>
  <block id="98d229565d14d4d286f57a588a784c1e" category="inline-link-macro">Contrôle des performances et présentation de la gestion</block>
  <block id="b7629a90716592b8dcae7480ad66d224" category="paragraph">Reportez-vous à la section <block ref="de4b907e949a377b72cd0f0b0595d155" category="inline-link-macro-rx"></block> pour en savoir plus.</block>
  <block id="81eba6b819a671b6c8962061afd13a78" category="section-title">Datastores NFS non vVols</block>
  <block id="5bafceb9f14cf4b07086992cd31326a5" category="paragraph">Une règle de qualité de service ONTAP peut être appliquée au datastore entier ou aux fichiers VMDK individuels qu'il contient. Toutefois, il est important de comprendre que toutes les machines virtuelles d'un datastore NFS traditionnel (non vVols) partagent une file d'attente d'E/S commune à partir d'un hôte donné. Si une règle de qualité de service ONTAP limite un ordinateur virtuel, toutes les E/S de ce datastore semblent alors restreintes pour cet hôte.</block>
  <block id="1520a4910ffa6efc27379931cc307d0b" category="paragraph">*Exemple:*
* Vous configurez une limite QoS sur vm1.vmdk pour un volume monté en tant que datastore NFS traditionnel par l'hôte esxi-01.
* Le même hôte (esxi-01) utilise vm2.vmdk et se trouve sur le même volume.
* Si vm1.vmdk est étranglé, alors vm2.vmdk semble également être étranglé car il partage la même file d'attente d'E/S avec vm1.vmdk.</block>
  <block id="caf18b31d986fc095c3c0cd6a1f19f9e" category="paragraph">À partir de vSphere 6.5, vous pouvez gérer les limites granulaires au niveau des fichiers sur les datastores non vVols en utilisant la gestion basée sur des règles de stockage (SPBM) avec le contrôle des E/S de stockage (SIOC) v2.</block>
  <block id="c28029445f9803e209550517678387a9" category="paragraph">Pour plus d'informations sur la gestion des performances avec les règles SIOC et SPBM, reportez-vous aux liens suivants.</block>
  <block id="8bef032522908e987555b77fb50dbb85" category="inline-link-macro">Règles basées sur l'hôte SPBM : SIOC v2</block>
  <block id="98a7507b3e8be801707c07e336bc5506" category="inline-link-macro">Gestion des ressources d'E/S de stockage avec vSphere</block>
  <block id="37b0c263c77e85e59d9f00438e870fa4" category="paragraph"><block ref="ea373db41b8c05446b96b46f4bbe1141" category="inline-link-macro-rx"></block>
<block ref="c5badf4fd27434d786395fe52801b533" category="inline-link-macro-rx"></block></block>
  <block id="cd6af799ac31b0fbf81bcbba1d3d6bf1" category="list-text">La politique doit être appliquée au<block ref="3b9aef0680339707b430261c2f800255" prefix=" " category="inline-code"></block> qui contient l'image réelle du disque virtuel, pas le<block ref="aa26c73336ecfd98ed727b3e249c7f90" prefix=" " category="inline-code"></block> (fichier de descripteur de disque virtuel) ou<block ref="092eb4dd2ca488962f4c22b3e8cc4ca0" prefix=" " category="inline-code"></block> (Fichier de descripteur de machine virtuelle).</block>
  <block id="9aa28dc739b66a86d9f73ba24b9dd4c2" category="paragraph">Les datastores FlexGroup offrent des fonctionnalités QoS améliorées lors de l'utilisation des outils ONTAP pour VMware vSphere 9.8 et versions ultérieures. Vous pouvez facilement définir la qualité de service sur toutes les machines virtuelles d'un datastore ou sur des machines virtuelles spécifiques. Consultez la section FlexGroup de ce rapport pour plus d'informations. Notez que les limitations de QoS mentionnées précédemment s'appliquent toujours avec les datastores NFS classiques.</block>
  <block id="b5380e34617914719b059f6d55b97b66" category="section-title">Datastores VMFS</block>
  <block id="b74c42e3de8c5b901769e263bf236711" category="paragraph">Avec des LUN ONTAP, les règles de qualité de service peuvent être appliquées au volume FlexVol qui contient les LUN ou les LUN individuelles, mais pas aux fichiers VMDK individuels car ONTAP ne connaît pas le système de fichiers VMFS.</block>
  <block id="e122a7a507ac1f580cc5b9f2632a851c" category="section-title">Datastores vVols</block>
  <block id="be1ca5bcad3b34c08e2b2d7bfc8a95e3" category="paragraph">La qualité de service minimale et/ou maximale peut être facilement définie sur des machines virtuelles individuelles ou des VMDK sans affecter les autres machines virtuelles ou VMDK à l'aide de la gestion basée sur des règles de stockage et des vVols.</block>
  <block id="f5ac983ee93a7017d283971566bc828e" category="paragraph">Lors de la création du profil de capacité de stockage pour le conteneur vVol, spécifiez une valeur IOPS max et/ou min sous la fonctionnalité de performance, puis indiquez ce SCP avec la stratégie de stockage de la VM. Utilisez cette règle lors de la création de la machine virtuelle ou appliquez-la à une machine virtuelle existante.</block>
  <block id="1f23e960871a0a77a49731a6b47646c5" category="inline-link-macro">VMware vSphere Virtual volumes (vVols) avec ONTAP</block>
  <block id="8743b08c4d707cd145a4e7acce189480" category="cell">Oui (le datastore peut être limité)</block>
  <block id="b2891bc898f2a418aa349b623568299e" category="summary">Active IQ Unified Manager permet de surveiller et de résoudre les problèmes de stockage et de performance NetApp dans votre environnement VMware vSphere.</block>
  <block id="b7ce758ec5c25cb23edfa4ead0d0097e" category="admonition">*NetApp recommande* un minimum de 15 % d'espace libre lorsque des disques rotatifs sont utilisés. Cela inclut tout l'espace inutilisé, y compris l'espace libre au sein de l'agrégat ou d'un volume, ainsi que tout espace libre alloué en raison de l'utilisation du provisionnement complet, mais qui n'est pas utilisé par les données réelles. Les performances seront affectées à mesure que l'espace libre approche 10 %.</block>
  <block id="5a7f49be424e282d22b4c3889f5cd341" category="paragraph">MetroCluster est une fonctionnalité ONTAP qui protège vos bases de données Oracle avec une mise en miroir synchrone RPO=0 sur tous les sites. Elle peut évoluer jusqu'à prendre en charge des centaines de bases de données sur un seul système MetroCluster.</block>
  <block id="30160293c6cf2d26d13cbd294af7fb4c" category="paragraph">Il est également simple à utiliser. L'utilisation de MetroCluster n'ajoute pas nécessairement à ou ne modifie pas nécessairement les meilleures ractiques pour l'exploitation des applications et bases de données d'entreprise.</block>
  <block id="c77924ff430fa98df17795d4f5c5885f" category="doc">Certificat HTTPS des outils ONTAP</block>
  <block id="641cc5f60c71fe9f9a2e15c5cc680ec3" category="summary">Guide de renforcement de la sécurité des outils ONTAP pour VMware vSphere, ports et protocoles TCP</block>
  <block id="872cba2a662a784946eb48675276dee2" category="doc">Protocole TLS mutuel (authentification basée sur certificat)</block>
  <block id="5a4857ad48868097d482a4a448f48bd9" category="doc">Nombre maximal de requêtes simultanées par utilisateur (protection de la sécurité réseau/attaque DOS)</block>
  <block id="0af211d5cda5cc4bb17dd7751e741595" category="doc">La configuration du protocole NTP (Network Time Protocol)</block>
  <block id="273eb98a312e607888044e87e0210015" category="section-title">Prise en charge des vVols de NetApp</block>
  <block id="551e3b0a48f99995daac658b17a1de62" category="list-text">*Meilleure gestion des capacités.* Les outils VASA et ONTAP permettent de consulter la capacité de stockage jusqu'au niveau des agrégats individuels si nécessaire et de fournir plusieurs couches d'alertes en cas de début d'exécution de la capacité.</block>
  <block id="38653f1dd04b13c5276f4f4a82e8506f" category="admonition">Le terme « connectivité » fait référence à la connexion au cluster utilisée pour la réplication entre sites. Il ne fait pas référence aux protocoles hôtes. Tous les protocoles côté hôte sont pris en charge comme d'habitude dans une configuration MetroCluster, quel que soit le type de connexion utilisé pour les communications entre clusters.</block>
  <block id="6f343e6c5daed91ac953577dd5e1e06e" category="doc">Perte de la connectivité de réplication</block>
  <block id="6f04ca443b44ef3da2adedd7c0cf36fa" category="paragraph">Pour les exemples suivants, supposons que le site A est configuré comme le site préféré.</block>
  <block id="f553ed0b13f8b38932589ba34432ab5a" category="paragraph">Si la réplication SM-AS est interrompue, l'E/S d'écriture ne peut pas être terminée, car un cluster ne peut pas répliquer les modifications sur le site opposé.</block>
  <block id="2ef1646841c5728f668289819e837437" category="section-title">Site A (site préféré)</block>
  <block id="47d7b1b43310c2ce615be2e71aed414d" category="paragraph">Le résultat de l'échec de la liaison de réplication sur le site préféré sera une pause d'environ 15 secondes dans le traitement des E/S d'écriture, car ONTAP relance les opérations d'écriture répliquées avant de déterminer que la liaison de réplication est véritablement inaccessible. Au bout de 15 secondes, le site A du système reprend le traitement des E/S de lecture et d'écriture. Les chemins SAN ne changent pas et les LUN restent en ligne.</block>
  <block id="bb713afeab82bcb45a45d3cc1411e3eb" category="section-title">Site B</block>
  <block id="dc68c1abbc392a93905ce712c45999eb" category="paragraph">Le site B n'étant pas le site privilégié de synchronisation active SnapMirror, ses chemins de LUN deviennent indisponibles au bout de 15 secondes environ.</block>
  <block id="3784559d5087e35dc7372b1c51cf920e" category="section-title">Panne du système de stockage</block>
  <block id="901afcf3108cffc70b3209e8613babf0" category="paragraph">Le résultat d'une défaillance du système de stockage est presque identique au résultat de la perte du lien de réplication. Le site survivant devrait subir une pause d'E/S d'environ 15 seconde. Une fois cette période de 15 secondes écoulée, l'E/S reprend sur ce site comme d'habitude.</block>
  <block id="0ce6f0c843cdd28d3ff7284039730959" category="section-title">Perte du médiateur</block>
  <block id="6b9600f6a35d60a0773b02ff771e5be1" category="paragraph">Le service médiateur ne contrôle pas directement les opérations de stockage. Il fonctionne comme un chemin de contrôle alternatif entre les clusters. Il existe principalement pour automatiser le basculement sans les risques associés à un scénario « split-brain ». En conditions normales de fonctionnement, chaque cluster réplique les modifications apportées à son partenaire et chaque cluster peut donc vérifier que le cluster partenaire est en ligne et qu'il transmet les données. Si le lien de réplication échoue, la réplication s'arrête.</block>
  <block id="878273b0ad33bf4f330480ad6262d08c" category="paragraph">La raison pour laquelle un médiateur est nécessaire pour un basculement automatisé sécurisé est parce qu'il serait autrement impossible à un cluster de stockage de déterminer si la perte de la communication bidirectionnelle était le résultat d'une panne du réseau ou d'une défaillance réelle du stockage.</block>
  <block id="7bccc28ee4a5fac4fa93b691ca9733bc" category="paragraph">Le médiateur fournit un chemin alternatif pour chaque cluster afin de vérifier l'état de santé de son partenaire. Les scénarios sont les suivants :</block>
  <block id="7ba0268be94dd09db527214e2f2862b4" category="list-text">Si un cluster peut contacter directement son partenaire, les services de réplication sont opérationnels. Aucune action requise.</block>
  <block id="5c3163ce1d24869bf6e6594bcd37901d" category="list-text">Si un site privilégié ne peut pas contacter son partenaire directement ou via le médiateur, il suppose que le partenaire est réellement indisponible ou a été isolé et a mis ses chemins LUN hors ligne. Le site préféré va ensuite publier l'état RPO=0 et continuer à traiter les E/S en lecture et en écriture.</block>
  <block id="e2c06d8468f627e9f8fdc9380204f00f" category="list-text">Si un site non préféré ne peut pas contacter directement son partenaire, mais peut le contacter via le médiateur, il mettra ses chemins hors ligne et attend le retour de la connexion de réplication.</block>
  <block id="f7fd4567c8be042fc3f9be5b45124d76" category="list-text">Si un site non privilégié ne peut pas contacter son partenaire directement ou via un médiateur opérationnel, il suppose que le partenaire est réellement indisponible ou a été isolé et a mis ses chemins LUN hors ligne. Le site non privilégié va ensuite publier l'état RPO=0 et continuer le traitement des E/S en lecture et en écriture. Il assumera le rôle de la source de réplication et deviendra le nouveau site préféré.</block>
  <block id="1286d22222876588b31270c148d8c480" category="paragraph">Si le médiateur n'est pas disponible :</block>
  <block id="3cc95aae492aaec45753d6e6b7d91c12" category="list-text">En cas de défaillance des services de réplication, quelle qu'en soit la raison, y compris la défaillance du site ou du système de stockage non privilégié, le site préféré libère l'état RPO=0 et reprend le traitement des E/S de lecture et d'écriture. Le site non préféré mettra ses chemins hors ligne.</block>
  <block id="92395625e4bc805c933a9b4f52c5c594" category="list-text">La défaillance du site préféré entraînera une panne, car le site non préféré ne pourra pas vérifier que le site opposé est réellement hors ligne et, par conséquent, il ne serait pas sûr que le site non préféré puisse reprendre ses services.</block>
  <block id="3450c1f3c1166bb5f38dd42c45eb1b70" category="section-title">Restauration des services</block>
  <block id="5a0a7b8380bda809ef1b210c3bb41b93" category="paragraph">Après résolution d'une panne, par exemple lors de la restauration de la connectivité site à site ou de la mise sous tension d'un système défaillant, les terminaux de synchronisation active SnapMirror détectent automatiquement la présence d'une relation de réplication défectueuse et la raverront à l'état RPO=0. Une fois la réplication synchrone rétablie, les chemins défaillants se reconnectent.</block>
  <block id="8f3219fa36fad5d789373fdf883d28b1" category="paragraph">Dans de nombreux cas, les applications en cluster détectent automatiquement le retour des chemins défaillants, et ces applications sont également reconnectées. Dans d'autres cas, une analyse SAN au niveau de l'hôte peut être nécessaire ou les applications doivent être reconnectées manuellement. Cela dépend de l'application et de la façon dont elle est configurée et, en général, de telles tâches peuvent être facilement automatisées. La fonctionnalité ONTAP elle-même est dotée d'une fonctionnalité d'autorétablissement et ne nécessite aucune intervention de l'utilisateur pour reprendre les opérations de stockage avec un objectif de point de récupération de 0.</block>
  <block id="52ec8762530eb85c0734309b6747a861" category="section-title">Basculement manuel</block>
  <block id="afe62727c9717a186ce014753f902c8a" category="paragraph">La modification du site préféré nécessite une opération simple. L'E/S s'interrompt pendant une ou deux secondes car l'autorité sur le comportement de réplication change entre les clusters, mais l'E/S n'est pas affectée.</block>
  <block id="2d430e41b39275608ed6816ee435f2c4" category="paragraph">Le médiateur n'est pas vraiment un casse-barre, bien que c'est effectivement la fonction qu'il fournit. Il ne prend aucune action ; il fournit plutôt un canal de communication alternatif pour la communication cluster à cluster.</block>
  <block id="caeb8c810d4965bfc8ad369332977e54" category="inline-image-macro">Diagramme de synchronisation active SnapMirror avec médiateur</block>
  <block id="2767cf2bbeaf5540c1e615745cfead81" category="paragraph">Le principal défi lié au basculement automatisé est le problème des réseaux partagés, qui se pose en cas de perte de connectivité entre les deux sites. Que doit-on faire ? Vous ne voulez pas que deux sites différents se désignent comme les copies restantes des données, mais comment un seul site peut-il faire la différence entre la perte réelle du site opposé et l'incapacité à communiquer avec le site opposé ?</block>
  <block id="661d0a9679d7d1af0f76f646c941e5cc" category="paragraph">C'est là que le médiateur entre dans la photo. S'il est placé sur un troisième site, et chaque site a une connexion réseau distincte à ce site, alors vous avez un chemin supplémentaire pour chaque site pour valider l'état de santé de l'autre. Examinez à nouveau l'image ci-dessus et examinez les scénarios suivants.</block>
  <block id="d0c23d9c3fc0a960d3362e7ba10243f5" category="list-text">Que se passe-t-il si le médiateur échoue ou est inaccessible à partir d'un ou des deux sites ?</block>
  <block id="123c024944e0a1dd3f71661e6d0e5005" category="list-text">Les deux clusters peuvent toujours communiquer entre eux sur le même lien que celui utilisé pour les services de réplication.</block>
  <block id="00a2d2948ebb25dba32d9366b8655dfc" category="list-text">Les données restent protégées avec un objectif de point de récupération de 0</block>
  <block id="7ac2e4e468f2c732023f530f71ac9dbb" category="list-text">Que se passe-t-il si le site A tombe en panne ?</block>
  <block id="ce89434a9a13b39dccbbded97d674de0" category="list-text">Le site B verra les deux canaux de communication tomber en panne.</block>
  <block id="0a22d4bfa3bb021654f02d82cdbb9422" category="list-text">Le site B prendra le contrôle des services de données, mais sans mise en miroir RPO=0</block>
  <block id="2a7681a43b5e9647d24566f342ab0b27" category="list-text">Que se passe-t-il si le site B tombe en panne ?</block>
  <block id="1c8ff8325f78bcc084c3c197606b5482" category="list-text">Le site A verra les deux canaux de communication tomber en panne.</block>
  <block id="8a8e5bd62b16753898cefd37bdf7ccb4" category="list-text">Le site A prend le relais des services de données, mais sans mise en miroir avec un objectif de point de récupération de 0</block>
  <block id="11b1ce76911fece428e0edd5c9e7682f" category="paragraph">Il y a un autre scénario à prendre en compte : la perte du lien de réplication des données. En cas de perte de la liaison de réplication entre les sites, la mise en miroir avec un objectif de point de récupération de 0 sera évidemment impossible. Que devrait-on alors se passer ?</block>
  <block id="3e2a78d8ed8be1e5b40ff81cc9e2a2d6" category="paragraph">Ceci est contrôlé par le statut du site préféré. Dans une relation SM-AS, l'un des sites est secondaire à l'autre. Cela n'a aucun effet sur les opérations normales, et tout accès aux données est symétrique. Toutefois, si la réplication est interrompue, le nœud devra être rompu pour reprendre les opérations. Par conséquent, le site privilégié continuera les opérations sans mise en miroir et le site secondaire arrêtera le traitement des E/S jusqu'à ce que la communication de réplication soit restaurée.</block>
  <block id="225caaa9ecf3ac7dfb141c808a1c1651" category="paragraph">La synchronisation active SnapMirror (anciennement SnapMirror Business Continuity ou SM-bc) permet à chaque base de données et application SQL Server de continuer à fonctionner en cas d'interruption, avec un basculement transparent du stockage sans intervention manuelle.</block>
  <block id="700cb79deb6ef819c0aacbb228c5a16b" category="paragraph">La synchronisation active SnapMirror (SM-AS) est basée sur SnapMirror synchrone. Les deux peuvent assurer une réplication synchrone des données avec un objectif de point de récupération de 0, mais la solution SM-AS va encore plus loin en fournissant une disponibilité RTO quasi nulle pour les données SAN. Pour cela, l'automatisation gère les chemins SAN afin d'assurer la disponibilité continue de vos données. Les défaillances de site, de contrôleur et de communication sont toutes gérées automatiquement par ONTAP.</block>
  <block id="c159224eea5fb4a30b3cc9be6e90cd6c" category="paragraph">La synchronisation active SnapMirror fournit des LUN qui existent sur deux sites différents. En fonctionnement normal, il n'y a pas de « source » ou de « destination ». La direction est bidirectionnelle. Toutes les E/S de lecture dirigées par un chemin de LUN donné seront gérées par le contrôleur local en utilisant sa copie locale des données. Toutes les écritures seront répliquées vers le partenaire distant et écrites localement avant d'être reconnues.</block>
  <block id="4a85397e66688e4e619ffe832e627548" category="inline-image-macro">Présentation de la synchronisation active SnapMirror</block>
  <block id="ddc1e5dc440806435445e7a532ad1198" category="paragraph">Logiquement, le comportement se présente comme un seul ensemble de LUN. Les E/S peuvent être dirigées vers ces LUN logiques via des chemins SAN situés sur deux clusters différents, mais les données sont toujours les mêmes. Le comportement des E/S est symétrique, ce qui est essentiel pour de nombreuses configurations d'applications actives-actives.</block>
  <block id="ddc5ca7c74db522011a3b2ddccda5b40" category="inline-image-macro">Conception logique de synchronisation active SnapMirror</block>
  <block id="daadd24f5163a10f9a2f016019883886" category="section-title">Gestion des chemins</block>
  <block id="9bb9bee58b329761e36c7d9bf8900d6f" category="paragraph">Il existe deux approches de la topologie de réseau synchrone SnapMirror, uniforme et non uniforme. Lors du choix d'un accès uniforme ou non uniforme, la principale considération est de savoir si vous pouvez ou devez étendre le SAN sur plusieurs sites. La synchronisation active SnapMirror peut être utilisée dans les deux situations.</block>
  <block id="1f46c4a6c97a8add22ae7c23181c23d8" category="paragraph">Le médiateur ONTAP est une application logicielle téléchargée à partir du site de support NetApp et généralement déployée sur une machine virtuelle.</block>
  <block id="91e17573d84d7d626cc27e989a3957bc" category="inline-link-macro">Documentation ONTAP sur la synchronisation active SnapMirror</block>
  <block id="ae81dd17263728532627374843ee0ff8" category="paragraph">Pour les étapes de planification et de configuration, reportez-vous à  la section <block ref="44f5d8051247437425911d96f84db248" category="inline-link-macro-rx"></block> .</block>
  <block id="5abea2d56204d1c15aa063dc90ccfb4f" category="paragraph">La synchronisation active SnapMirror considère un site comme la « source » et l'autre comme la « destination ». Cela implique une relation de réplication unidirectionnelle, mais cela ne s'applique pas au comportement d'E/S. La réplication est bidirectionnelle et symétrique. Les temps de réponse d'E/S sont identiques de part et d'autre du miroir.</block>
  <block id="e5086daa5843466ff5f04f20d4c19d74" category="paragraph">La<block ref="36cd38f49b9afa08222c0dc9ebfe35eb" prefix=" " category="inline-code"></block> désignation est le contrôle du site préféré. En cas de perte du lien de réplication, les chemins de LUN sur la copie source continueront à transmettre des données tandis que les chemins de LUN sur la copie de destination deviendront indisponibles jusqu'à ce que la réplication soit rétablie et que SnapMirror repasse à l'état synchrone. Les chemins reprennent alors le service des données.</block>
  <block id="a0bbe7bd1e93252f1267d98703905552" category="paragraph">La configuration source/destination peut être affichée via SystemManager :</block>
  <block id="13d0a54956b2dd09d5e909acadfb1694" category="inline-image-macro">Capture d'écran SM de SM-AS source</block>
  <block id="5b53b7d18b58af25bcf47dc21678038f" category="paragraph">Ou sur l'interface de ligne de commande :</block>
  <block id="498b1bbe0e017f1ad405fe4c77fb8ea1" category="paragraph">La clé est que la source est le SVM sur le cluster1. Comme mentionné ci-dessus, les termes « source » et « destination » ne décrivent pas le flux des données répliquées. Les deux sites peuvent traiter une écriture et la répliquer sur le site opposé. En effet, les deux grappes sont des sources et des destinations. La désignation d'un cluster comme source contrôle simplement le cluster qui survit en tant que système de stockage en lecture/écriture en cas de perte du lien de réplication.</block>
  <block id="18a07170e14f5cbc26533f0a136dfdd0" category="inline-image-macro">SnapMirror actif Sync mise en réseau non uniforme</block>
  <block id="9532c9e7afcd43c7d9bb5740695fc259" category="paragraph">Le principal avantage de cette approche est la simplicité du SAN : vous n'avez plus besoin d'étendre un SAN sur le réseau. Certains clients ne disposent pas d'une connectivité à faible latence suffisante entre les sites, ou n'ont pas l'infrastructure nécessaire pour acheminer le trafic SAN FC sur un réseau intersite.</block>
  <block id="439caacb19fa16f2c21563703ed645d7" category="paragraph">L'inconvénient de l'accès non uniforme est que certains scénarios de défaillance, notamment la perte du lien de réplication, entraînent la perte de l'accès au stockage par certains hôtes. En cas de perte de la connectivité du stockage local, les applications qui s'exécutent en tant qu'instances uniques, telles qu'une base de données non en cluster et qui ne s'exécute intrinsèquement que sur un hôte unique sur un montage donné, échouent. Les données seraient toujours protégées, mais le serveur de base de données n'aurait plus accès. Il doit être redémarré sur un site distant, de préférence par le biais d'un processus automatisé. Par exemple, VMware HA peut détecter une situation de tous les chemins d'accès sur un serveur et redémarrer une machine virtuelle sur un autre serveur sur lequel les chemins d'accès sont disponibles.</block>
  <block id="9fad44ede04fb95c16ea64be5e51836c" category="paragraph">Dans de nombreux cas, la surcharge liée à la latence supplémentaire qu'une application accède au système de stockage via une liaison site à site ne serait pas acceptable. Cela signifie que l'amélioration de la disponibilité des réseaux uniformes est minime, car la perte de stockage sur un site entraînerait la nécessité de fermer les services sur ce site défaillant.</block>
  <block id="15da96ce40136a3259e04ae0dc25fc95" category="paragraph">Il existe des chemins redondants à travers le cluster local qui ne sont pas illustrés sur ces schémas pour plus de simplicité. Les systèmes de stockage ONTAP étant dotés de la haute disponibilité, une panne du contrôleur ne devrait pas entraîner de panne sur le site. Il devrait simplement entraîner une modification dans laquelle les chemins locaux sont utilisés sur le site affecté.</block>
  <block id="bb12626aefb7c36f9b13694d35dadd5d" category="paragraph">L'une des caractéristiques importantes de SM-AS est la capacité de configurer les systèmes de stockage pour savoir où se trouvent les hôtes. Lorsque vous mappez les LUN sur un hôte donné, vous pouvez indiquer si elles sont proximales ou non à un système de stockage donné.</block>
  <block id="4590bab77464ba1a9c8ee6b8095eef60" category="inline-image-macro">SnapMirror actif Sync AFF uniforme de mise en réseau</block>
  <block id="2b2fdfa824f1319cc47992b1277faa78" category="paragraph">En fonctionnement normal, toutes les E/S sont des E/S locales. Les opérations de lecture et d'écriture sont gérées à partir de la baie de stockage locale. Bien entendu, les E/S en écriture devront également être répliquées par le contrôleur local sur le système distant avant d'être acquittées, mais toutes les E/S en lecture seront gérées localement et ne subiront pas de latence supplémentaire en traversant la liaison SAN entre les sites.</block>
  <block id="97b2bb0cfbae3fe49433caf537e819ec" category="paragraph">Le seul moment où les chemins non optimisés seront utilisés est la perte de tous les chemins actifs/optimisés. Par exemple, si l'ensemble de la baie sur le site A est hors tension, les hôtes du site A peuvent toujours accéder aux chemins d'accès à la baie sur le site B et donc rester opérationnels, même s'ils connaissent une latence plus élevée.</block>
  <block id="5ab085bf88338486e590861594d3947a" category="paragraph">Les systèmes NetApp ASA proposent des chemins d'accès multiples actif-actif sur tous les chemins d'accès à un cluster. Cela s'applique également aux configurations SM-AS.</block>
  <block id="6511f0e2589c08e82bc8dd3e9bc93185" category="inline-image-macro">SnapMirror actif Sync ASA uniforme de mise en réseau</block>
  <block id="c3fe6771b27ffcb15a75ae88f6d57c4b" category="paragraph">Une configuration ASA avec un accès non uniforme fonctionnera en grande partie comme avec AFF. Avec un accès uniforme, l'E/S traverserait le WAN. Cela peut être souhaitable ou non.</block>
  <block id="498a9faf271a73dcf026b1041b66ef2a" category="paragraph">Si les deux sites étaient distants de 100 mètres avec une connectivité à fibre optique, il ne devrait pas y avoir de latence supplémentaire détectable traversant le WAN, mais si les sites étaient éloignés, les performances de lecture seraient affectées sur les deux sites. À l'inverse, avec AFF, ces chemins WAN seraient utilisés uniquement s'il n'existait aucun chemin local disponible et si les performances quotidiennes seraient meilleures, car toutes les E/S seraient des E/S locales. ASA avec un réseau d'accès non uniforme serait une option pour bénéficier des avantages de ASA en termes de coûts et de fonctionnalités sans engendrer de pénalités de latence entre les sites.</block>
  <block id="15ab92b8042738f6acc912e2d98ae17a" category="paragraph">ASA avec SM-as dans une configuration à faible latence offre deux avantages intéressants. Tout d'abord, elle double *les performances de n'importe quel hôte, car les E/S peuvent être traitées par deux fois plus de contrôleurs en utilisant deux fois plus de chemins. Ensuite, dans un environnement à site unique, elle offre une disponibilité extrême, car l'intégralité du système de stockage peut être perdue sans interrompre l'accès aux hôtes.</block>
  <block id="41c719032afe187deaf4b4b2af41aa36" category="paragraph">L'efficacité de stockage sensible à la température (TSSE) est disponible dans ONTAP 9.8 et versions ultérieures. Il s'appuie sur des cartes thermiques d'accès aux blocs pour identifier les blocs peu utilisés et les compresser à l'aide d'une meilleure efficacité.</block>
  <block id="8284eb5a9d9bef8f0f1ece257656d0fe" category="summary">Informations supplémentaires sur Epic sur ONTAP</block>
  <block id="345245c83d2b2c4c2a5eb9f2887da627" category="paragraph">Pour en savoir plus sur les informations fournies dans ce document, consultez ces documents et/ou sites web :</block>
  <block id="bc4fe2352063642d68529f2aa0ca7ca3" category="inline-link-macro">Documentation produit NetApp</block>
  <block id="0897605072547ea93ef25a4b355ac5f6" category="list-text"><block ref="0897605072547ea93ef25a4b355ac5f6" category="inline-link-macro-rx"></block></block>
  <block id="5358757de9216cc29d688612a3d72fe1" category="inline-link-macro">Documentation ONTAP 9</block>
  <block id="3973235e869d719328cf4b37e59562e5" category="list-text"><block ref="3973235e869d719328cf4b37e59562e5" category="inline-link-macro-rx"></block></block>
  <block id="c9cefb6ed873a418f8c8232dca6879d2" category="inline-link-macro">Groupes de cohérence</block>
  <block id="10d6aff3e86ebe3712a2616b45008fb3" category="list-text"><block ref="10d6aff3e86ebe3712a2616b45008fb3" category="inline-link-macro-rx"></block></block>
  <block id="0d3cc094235677831b5697c5bab76394" category="inline-link-macro">Ressources de documentation du gestionnaire de système ONTAP et ONTAP</block>
  <block id="3b2c8ae1d985c88d539bf7851e067922" category="list-text"><block ref="3b2c8ae1d985c88d539bf7851e067922" category="inline-link-macro-rx"></block></block>
  <block id="e9bf68ed54b6d1ff63e8bda8c0b6a70f" category="inline-link-macro">Tr-3930i : instructions de dimensionnement NetApp pour Epic</block>
  <block id="920aa6d447930899ad56517c79fd12fc" category="list-text"><block ref="b6ff45309a811037a92ca1e6262c74a8" category="inline-link-macro-rx"></block> (Connexion NetApp requise)</block>
  <block id="840f4016fe968750d45ea4545f2f1893" category="section-title">Documents d'orientation client Epic</block>
  <block id="a839c9787ec80291f4b34dc5451786a5" category="paragraph">Epic fournit aux clients les documents suivants à des fins d'assistance sur les serveurs, le stockage et le réseau. Ces documents sont référencés dans ce rapport technique.</block>
  <block id="67bab37630accce3ea259fb1601fca2e" category="list-text">Considérations relatives au réseau de stockage</block>
  <block id="0fe2c5f32f45114c27e3b7a7ca0ba0ad" category="list-text">Guide des solutions techniques de continuité de l'activité</block>
  <block id="2163e1881d92ff554d8969998a7d618f" category="list-text">Guide de référence sur la stratégie d'architecture 100 % Flash</block>
  <block id="b332ca8d59cd86adb52c28aef982cc69" category="list-text">Produits de stockage et état de la technologie</block>
  <block id="a0107bedc201b2df3694df573f65ae32" category="list-text">Considérations relatives au cloud EPIC</block>
  <block id="0cf7d14c360e7f8755d749057b348718" category="list-text">Guide de configuration matérielle (spécifique au client)</block>
  <block id="50923dab9020d1e069418763d0bd15a3" category="list-text">Recommandations relatives à l'infrastructure de stockage de la base de données (spécifique au client)</block>
  <block id="4e1249f2da2104e56555dec5d4d51e6a" category="summary">Architecture à quatre nœuds Epic</block>
  <block id="7baf69c8e83ff08e0583426d011bc650" category="paragraph">Les figures ci-dessous illustrent la disposition du stockage pour une architecture à quatre nœuds : une paire haute disponibilité en production et une paire haute disponibilité en reprise après incident. La taille des contrôleurs et le nombre de disques sont basés sur la dernière image de dimensionnement.</block>
  <block id="70ccc987c3596ca363e7b8d980858220" category="paragraph">NetApp garantit des performances minimales au niveau du sol en acceptant les politiques de gestion de la qualité de service recommandées par SLM. Epic prend en charge la consolidation des pools de stockage sur ONTAP sur beaucoup moins de matériel. Pour plus d'informations, consultez le document Epic Quarterly SPATS. En fait, pool1, pool2 et NAS1 (répertoriés dans l'Epic Hardware Configuration Guide) peuvent toutes être exécutés sur une seule paire haute disponibilité, les charges de travail étant réparties de manière homogène entre les deux contrôleurs. Dans le cadre de la reprise sur incident, les pools Epic 3 et NAS 3 sont également répartis entre les deux contrôleurs de la paire haute disponibilité.</block>
  <block id="34557edb2bf88cd4f837f2384ead1830" category="paragraph">Les environnements de copie complète de test (SUP, REL et PJX, par exemple) sont clonés à partir d'Epic production, d'Epic Report ou d'Epic Disaster Recovery. Pour plus d'informations sur la sauvegarde et l'actualisation d'Epic, reportez-vous à la section intitulée « gestion des données ».</block>
  <block id="5c8423bf649a8a50f33626549581cce9" category="section-title">Architecture à quatre nœuds</block>
  <block id="f42ac2802f367c372897f3fb06218d2d" category="inline-image-macro">Architecture Epic à 4 nœuds</block>
  <block id="848f13dbd455e0190684bb8052ef94d6" category="paragraph"><block ref="848f13dbd455e0190684bb8052ef94d6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="14b8013c3961c3eb9f2d01aff2c9d430" category="section-title">Placement des workloads à quatre nœuds</block>
  <block id="8e576f920186d1c7001b6f1da66f2359" category="inline-image-macro">Placement Epic à 4 nœuds</block>
  <block id="34594b0fc43be2425a0a68f14928bc8d" category="paragraph"><block ref="34594b0fc43be2425a0a68f14928bc8d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="145a177f694025424b761a3b22ca2f6b" category="summary">Architecture Epic à 6 nœuds</block>
  <block id="7682e26e53b5af35c13c22f5034f788a" category="paragraph">Les clients peuvent commencer par une conception à six nœuds ou évoluer horizontalement de manière fluide de quatre à six nœuds en fonction de la demande croissante. L'évolutivité scale-out permet de déplacer des charges de travail entre les nœuds et de rééquilibrer les opérations sans interruption dans le cluster.</block>
  <block id="121ec45abd57b78d2c63e13a01970fbf" category="paragraph">Cette architecture offre le meilleur équilibre entre performances et capacité sur le cluster. Les applications Epic production, Epic Report et Epic Test s'exécutent sur la première paire haute disponibilité. La deuxième paire haute disponibilité est utilisée pour la clarté, l'hyperespace, VMware, NAS1 et les autres workloads Epic. La reprise sur incident est identique à l'architecture à quatre nœuds de la section précédente.</block>
  <block id="628e6fdb5831f5144730fdfb620a1a2a" category="section-title">Architecture à six nœuds</block>
  <block id="5d28884b83f218379ec90c789e2e382b" category="inline-image-macro">Architecture Epic à 6 nœuds</block>
  <block id="a5cf77b4851a534d4e7f8cbfc10e7734" category="paragraph"><block ref="a5cf77b4851a534d4e7f8cbfc10e7734" category="inline-image-macro-rx" type="image"></block></block>
  <block id="214d949b6d12c893a63f49d862292640" category="section-title">Placement des workloads à 6 nœuds</block>
  <block id="65ea1ebb7d9c2d858f8701fcbecd438d" category="inline-image-macro">Placement Epic à 6 nœuds</block>
  <block id="77e8933cdf526d7670fcd797f57f81a7" category="paragraph"><block ref="77e8933cdf526d7670fcd797f57f81a7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a3ab98b5217808d71238c069623fa0ff" category="summary">Architecture Epic à huit nœuds</block>
  <block id="ab4e8eb50674d5d1bee79a6682b49325" category="paragraph">Les figures ci-dessous illustrent l'architecture scale-out à huit nœuds. Là encore, vous pouvez commencer avec quatre nœuds, puis les faire évoluer jusqu'à six, et continuer jusqu'à huit nœuds au-delà. Cette architecture offre le meilleur équilibre entre performance et capacité sur les six nœuds en production.</block>
  <block id="0ef10ffde0c0ebd21feabe96ec890f72" category="paragraph">Dans cette conception, les environnements de test sont clonés à partir du rapport au lieu de la production. La production peut ainsi décharger les environnements de test et les contrôles d'intégrité.</block>
  <block id="211891edb616b1a6e25c469a73cd07c9" category="section-title">Architecture à huit nœuds</block>
  <block id="3b31cb391c5fb328f6bcf768909f68a2" category="paragraph"><block ref="3b31cb391c5fb328f6bcf768909f68a2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c344a01a287e43ab2ef2793cf550435a" category="section-title">Placement des workloads à huit nœuds</block>
  <block id="80a544c0b0187e121e581e019d0902a9" category="inline-image-macro">Placement Epic à 8 nœuds</block>
  <block id="e374fdf5079d6709ca8206b4c77be000" category="paragraph"><block ref="e374fdf5079d6709ca8206b4c77be000" category="inline-image-macro-rx" type="image"></block></block>
  <block id="17e9ce8e967d60724d7f53d467470a10" category="summary">Architecture « Epic »</block>
  <block id="b1830ae1e99adb346ce1da353cd6c089" category="paragraph">Cette section décrit l'environnement logiciel Epic et les composants clés qui nécessitent un stockage. Fournit les principaux éléments à prendre en compte pour guider la conception du stockage.</block>
  <block id="4db273f137d059bd4ffd23818c367214" category="paragraph">Epic, dont le siège social se trouve à Vérone, dans le Wisconsin, propose des logiciels pour les groupes médicaux de taille moyenne à grande, les hôpitaux et les organismes de santé intégrés. Les clients comprennent également des hôpitaux communautaires, des établissements universitaires, des organisations pour enfants, des fournisseurs de filet de sécurité et des systèmes multi-hospitaliers. Le logiciel intégré au système Epic couvre les fonctions cliniques, d'accès et de revenu et s'étend à la maison.</block>
  <block id="27cd823999704d6e14cdee1e83bef7f0" category="paragraph">Il n'est pas question du champ d'application de ce document de couvrir le large éventail de fonctions prises en charge par le logiciel Epic. Cependant, pour le système de stockage, tous les logiciels Epic partagent une base de données unique axée sur le patient pour chaque déploiement. EPIC passe de la base de données InterSystems Caché à la nouvelle base de données InterSystems Iris. Comme les exigences de stockage sont les mêmes pour Caché et Iris, nous nous référons à la base de données comme Iris tout au long du reste de ce document. Iris est disponible pour les systèmes d'exploitation AIX et Linux.</block>
  <block id="4e25ab2bd75f003927aabf72608c3610" category="section-title">Iris InterSystems</block>
  <block id="0af82ac784148ef3818d2fe5b04763fa" category="paragraph">InterSystems Iris est la base de données utilisée par l'application Epic. Dans cette base de données, le serveur de données est le point d'accès des données stockées de manière persistante. Le serveur d'applications gère les requêtes de base de données et envoie des requêtes de données au serveur de données. Pour la plupart des environnements logiciels Epic, l'utilisation de l'architecture multiprocesseur symétrique (SMP) dans un seul serveur de base de données suffit pour répondre aux demandes de base de données des applications Epic. Dans les déploiements de grande envergure, un modèle distribué peut être pris en charge à l'aide du protocole ECP (Enterprise Caché Protocol) d'InterSystems.</block>
  <block id="8dfea4e602a85bafff792b879b2d056b" category="paragraph">L'utilisation d'un matériel en cluster prenant en charge le basculement permet à un serveur de données de secours d'accéder au même stockage que le serveur de données principal. Il permet également au serveur de données de secours de prendre en charge les responsabilités de traitement en cas de panne matérielle.</block>
  <block id="c77ab217583518f1b67702b591baf929" category="paragraph">InterSystems fournit également des technologies qui répondent aux besoins en termes de réplication des données, de reprise après incident et de haute disponibilité. La technologie de réplication d'InterSystems permet de répliquer une base de données Iris de manière synchrone ou asynchrone depuis un serveur de données principal vers un ou plusieurs serveurs de données secondaires. NetApp SnapMirror est utilisé pour répliquer le stockage WebBLOB ou pour la sauvegarde et la reprise après incident.</block>
  <block id="df2e58f9c6f746010ccdd5cf07673500" category="paragraph">La mise à jour de la base de données Iris présente de nombreux avantages :</block>
  <block id="f8ffd660138274e3b7b31f900153e4b6" category="list-text">Évolutivité accrue et consolidation en une plus grande instance grâce à plusieurs instances Epic.</block>
  <block id="242ef58734fef1421d6cc1e1154bd041" category="list-text">Offre de licence permettant aux clients de passer d'AIX à Red Hat Enterprise Linux (RHEL) sans payer de nouvelle licence de plate-forme.</block>
  <block id="08a78b85487809e2116574e4ff97dec5" category="section-title">Serveurs de base de données Caché et utilisation du stockage</block>
  <block id="4cc33a0396ddd5a29816a3a40d01a6b5" category="list-text">*Production* dans les environnements logiciels Epic, une base de données unique centrée sur le patient est déployée. Dans les exigences matérielles d'Epic, le serveur physique hébergeant le serveur de données Iris de lecture/écriture principal est appelé serveur de base de données de production. Ce serveur nécessite un stockage 100 % Flash haute performance pour les fichiers appartenant à l'instance de base de données primaire. Pour la haute disponibilité, Epic prend en charge l'utilisation d'un serveur de base de données de basculement ayant accès aux mêmes fichiers. Iris utilise Epic Mirror pour répliquer en lecture seule des rapports, la reprise après incident et la prise en charge des copies en lecture seule. Chaque type de serveur de base de données peut être basculé en mode lecture/écriture pour des raisons de continuité d'activité.</block>
  <block id="cdbcd4cba3ac1d1b15d302df69df1198" category="list-text">*Report* Un serveur de base de données miroir fournit un accès en lecture seule aux données de production. Il héberge un serveur de données Iris configuré comme miroir de sauvegarde du serveur de données Iris de production. Les besoins en capacité de stockage du serveur de la base de données de production sont les mêmes que ceux du serveur de la base de données de production. Les rapports de performances d'écriture sont identiques à ceux de la production, mais les caractéristiques de la charge de travail de lecture sont différentes et dimensionnées différemment.</block>
  <block id="10938a446d1d37c3afcad8aac850f514" category="list-text">*Prend en charge la lecture seule* ce serveur de base de données est facultatif et n’est pas illustré ci-dessous. Un serveur de base de données en miroir peut également être déployé pour prendre en charge la fonctionnalité Epic en lecture seule, dans laquelle l'accès est fourni à une copie de production en mode lecture seule. Ce type de serveur de base de données peut être basculé en mode lecture/écriture pour des raisons de continuité d'activité.</block>
  <block id="32042e6794444e49e092cad346b66b28" category="list-text">*Récupération après sinistre* pour atteindre les objectifs de continuité de l'activité et de reprise après sinistre, un serveur de base de données miroir de reprise après sinistre est généralement déployé sur un site distinct géographiquement des serveurs de base de données miroir de production et/ou de génération de rapports. Un serveur de base de données miroir de reprise après sinistre héberge également un serveur de données Iris configuré comme miroir de sauvegarde du serveur de données Iris de production. Si le site de production devient indisponible pendant une période prolongée, ce serveur de base de données miroir de sauvegarde peut être configuré pour agir en tant qu'instance de lecture/écriture miroir (SRW). Le serveur de base de données miroir de sauvegarde a les mêmes besoins en stockage de fichiers que le serveur de base de données de production. En revanche, le stockage de la base de données en miroir de sauvegarde est dimensionné de la même manière que le stockage de production du point de vue des performances, pour assurer la continuité de l'activité.</block>
  <block id="d05c7e253f48b314f8488aba0e85b3b4" category="inline-image-macro">Epic IRIS ODB</block>
  <block id="90cb7e5b029ac3a1b754d9f0d75bfbb9" category="paragraph"><block ref="90cb7e5b029ac3a1b754d9f0d75bfbb9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b101ffd23847579c0cf3cb028fc314ee" category="list-text">*Test* les organismes de santé déploient souvent des environnements de développement, de test et de transfert. Les serveurs de données Iris supplémentaires pour ces environnements nécessitent également un stockage, qui peut être pris en charge par le même système de stockage. Epic présente des exigences et des contraintes spécifiques pour fournir du stockage supplémentaire à partir d'un système de stockage partagé. Ces exigences spécifiques sont traitées de façon générique par les meilleures pratiques de ce document.</block>
  <block id="5c52f2993ead7ce33b4600c9955d9657" category="paragraph">Outre les serveurs de données ODB Iris, les environnements logiciels Epic incluent généralement d'autres composants, tels que les suivants et comme illustré dans la figure ci-dessous :</block>
  <block id="c352fde153a95627d87a161b60e9e211" category="list-text">Serveur de base de données Oracle ou Microsoft SQL Server en tant que back-end des outils de reporting d'entreprise Clarity d'Epic</block>
  <block id="72e364f0316ce75144d3bcbc76627977" category="admonition">Clarity est utilisé pour générer des rapports sur les données extraites quotidiennement de la base de données Iris.</block>
  <block id="9c7d7e54119a875f7f730fac34d86939" category="list-text">Serveur WebBLOB (SMB)</block>
  <block id="7f140c68d528349ef23a9adde829618a" category="list-text">Serveur de base de données polyvalent</block>
  <block id="db670b036ce103ccc68fe4a2f746bcbb" category="list-text">Machines virtuelles polyvalentes</block>
  <block id="46f49acf82ce78d08668061bb78e679a" category="list-text">Hyperspace pour l'accès client</block>
  <block id="847ce339c80d3a544fdd1e3ea23f89ed" category="inline-image-macro">Base de données Epic</block>
  <block id="ddc0ff60fb0cba83974547cb2fd7a40e" category="paragraph"><block ref="ddc0ff60fb0cba83974547cb2fd7a40e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="300c335aaf3a97bb6020a19be0b8ca96" category="paragraph">Les besoins en stockage de toutes ces charges de travail multiples, pools, protocoles NAS et SAN peuvent être consolidés et hébergés par un seul cluster ONTAP. Cette consolidation permet aux établissements de santé de disposer d'une stratégie de gestion des données unique pour tous les workloads Epic et non Epic.</block>
  <block id="4a7de8a55a290fb3a0a4efd490ec781b" category="section-title">Charges de travail opérationnelles des bases de données</block>
  <block id="a627911d38337b81dddab9711a61842c" category="paragraph">Chaque serveur de base de données Epic effectue des E/S sur les types de fichiers suivants :</block>
  <block id="458648f675593beefe031e7b7ba9fcdd" category="list-text">Fichiers de base de données</block>
  <block id="07599d3aee2c26c36cae1cb305a0d120" category="list-text">Fichiers journaux</block>
  <block id="b9c807a9cbbe80f3b710d64a47334ecf" category="list-text">Fichiers d'application</block>
  <block id="4b11d0da3422be079767b9c81ea967cb" category="paragraph">La charge de travail d'un serveur de base de données dépend de son rôle dans l'environnement logiciel Epic. Par exemple, les fichiers de base de données de production sont généralement soumis à la charge de travail la plus exigeante, constituée de 100 % de requêtes en E/S aléatoires. La charge de travail des bases de données en miroir est généralement moins exigeante et présente moins de demandes de lecture. Les workloads de fichiers journaux sont principalement séquentiels.</block>
  <block id="6908d08a516bc86d102ccafa6c2ece9d" category="paragraph">Epic maintient un modèle de charge de travail pour le banc d'essai des performances de stockage et la charge de travail des clients. Pour plus d'informations sur le modèle de charge de travail Epic, les résultats d'un banc d'essai et des conseils sur l'utilisation des outils de dimensionnement NetApp pour dimensionner correctement le stockage dans les environnements Epic, voir<block ref="81c36a9e6d224e9d42c9630dffaa9434" category="inline-link-rx"></block> (connexion NetApp requise).</block>
  <block id="f71d6b15e61746171efc106f495b60cd" category="paragraph">Epic fournit également à chaque client un guide de configuration matérielle personnalisé contenant les projections d'E/S et les besoins en capacité de stockage. Les exigences de stockage finales peuvent inclure des environnements de développement, de test et/ou intermédiaires, ainsi que toute autre charge de travail auxiliaire qui peut être consolidée. Les clients peuvent utiliser le guide de configuration matérielle pour communiquer les besoins totaux en stockage à NetApp. Ce guide contient toutes les données nécessaires au dimensionnement d'un déploiement Epic.</block>
  <block id="c7a0b1a5f7a146b9b72947b2bba045ed" category="paragraph">Lors de la phase de déploiement, Epic fournit un guide d'organisation du stockage de base de données, qui fournit des informations plus granulaires au niveau des LUN et peut être utilisé dans le cadre d'une conception de stockage avancée. Notez que le Guide d'organisation du stockage de la base de données est une recommandation générale en matière de stockage et n'est pas spécifique à NetApp. Ce guide vous aidera à déterminer l'infrastructure de stockage la plus adaptée sur NetApp.</block>
  <block id="ab3b24e1e2a3f9784a9c6cad8db20a76" category="summary">Dimensionnement Epic</block>
  <block id="706a0ec5dbae849750639964dc6b852f" category="paragraph">Lors du dimensionnement d'un environnement de stockage Epic, la taille de la base de données ODB fait partie des points clés à prendre en compte pour l'architecture.</block>
  <block id="abe227b9b306ed7c0527800b44a2f1d0" category="paragraph">Vous pouvez utiliser le schéma ci-dessous pour sélectionner une architecture de stockage Epic de petite, moyenne et grande taille. Ces conceptions incluent l'exécution de toutes les charges de travail répertoriées dans le Guide de configuration matérielle. L'arbre de dimensionnement est basé sur les données de plus de 100 guides de configuration matérielle et doit être principalement une estimation précise.</block>
  <block id="be0322041cc582d91f5f470df1ef2ba4" category="paragraph">Il est important de noter qu'il ne s'agit que d'un point de départ. Vous devez collaborer avec notre équipe Alliance Epic pour confirmer tous les designs Epic. L'équipe peut être rejointe sur Epic@NetApp.com. Chaque déploiement doit répondre aux demandes des clients tout en respectant les bonnes pratiques recommandées par Epic et NetApp.</block>
  <block id="20e8e833e31ffb5776ac701658144bd3" category="list-text">Petite architecture Epic avec une base de données Epic moins de 10 To</block>
  <block id="5d8ee21ec144a04a8287c0171b9a8527" category="list-text">Architecture Epic de taille moyenne avec une base de données Epic de 10 To à 50 To</block>
  <block id="79ac7005a81d3ad4f64a1a5f5db00c7e" category="list-text">Grande architecture Epic avec une base de données Epic de plus de 50 To</block>
  <block id="650c96055e8747d8b8a4c503b32aea8d" category="inline-image-macro">Conseils de dimensionnement Epic</block>
  <block id="1c2004236bc67ea5f8fcc53a967ce698" category="paragraph"><block ref="1c2004236bc67ea5f8fcc53a967ce698" category="inline-image-macro-rx" type="image"></block></block>
  <block id="431d999c23fb9c149586aa971425928e" category="summary">Exigences de stockage Epic</block>
  <block id="8afb3f2b206e0239313a484fe51999d7" category="paragraph">Des ressources de stockage dédiées sont généralement fournies pour la base de données de production, tandis que les instances de base de données en miroir partagent des ressources de stockage secondaires avec d'autres composants logiciels Epic, tels que les outils de reporting Clarity.</block>
  <block id="d31081e8762bd0903adf5d3f0b769e73" category="paragraph">D'autres environnements de stockage logiciels, tels que ceux utilisés pour les fichiers d'applications et de systèmes, sont également fournis par les ressources de stockage secondaires.</block>
  <block id="ed879cdc9a77683dfbe5be59441dec43" category="paragraph">Outre les considérations de dimensionnement, Epic propose les règles d'infrastructure de stockage supplémentaires suivantes et les considérations clés suivantes :</block>
  <block id="ba76cf08b10101b5fee8e2e6d0da268e" category="list-text">Depuis 2020, toutes les charges de travail opérationnelles de la base de données (ODB) doivent se trouver sur des baies 100 % Flash.</block>
  <block id="542f0f7c69fde2bd55b5a36854a84fa3" category="list-text">Epic recommande que chaque pool de stockage se trouve sur du matériel physique distinct, notamment pool1, pool2, pool3, NAS1 et NAS2.</block>
  <block id="919d67cad73121e6af0b2b20169d947b" category="admonition">Un nœud d'un cluster peut être considéré comme un pool de stockage. Avec ONTAP 9.4 ou version ultérieure et AQoS, vous pouvez créer des pools protégés à l'aide de stratégies.</block>
  <block id="4449a7b5d2b5dfb4b1bad2ed2f86b5fd" category="list-text">Nouvelle recommandation de sauvegarde Epic 3-2-1.</block>
  <block id="b560499317ab0447790f01d7acd5401b" category="list-text">Copie située dans le site distant (reprise après incident)</block>
  <block id="09d6c5f51239ea513e80e433549993f4" category="list-text">L'une de ces copies doit se trouver sur une plateforme de stockage différente de la copie principale</block>
  <block id="df5be706f042b26557014aa77c608eb6" category="list-text">Des copies des données</block>
  <block id="47311b53e9ae798223e097c4249a0668" category="admonition">Les clients qui utilisent NetApp SnapMirror pour la sauvegarde de NetApp ne répondent pas aux recommandations 3-2-1. La raison en est que ONTAP to ONTAP ne satisfait pas à la deuxième exigence indiquée ci-dessus. Vous pouvez utiliser SnapMirror directement depuis ONTAP vers le stockage objet sur site (via StorageGRID, par exemple) ou vers le cloud pour répondre aux exigences d'Epic.</block>
  <block id="fef74abf89ce7520dbdabb6ae983ee4b" category="paragraph">Pour plus d'informations sur les impératifs de stockage, consultez les guides Epic suivants disponibles dans Galaxy :</block>
  <block id="bed1a6db332388739ca169835c6c3425" category="list-text">Considérations relatives aux SAN</block>
  <block id="9080906c2106e0567c91717cc003d027" category="list-text">Produits de stockage et état de la technologie (SPAT)</block>
  <block id="81b560a1124b6edc7fe2858e332661b6" category="list-text">Guide de configuration matérielle</block>
  <block id="db11e37a9250a9db4d48618851771913" category="summary">Configuration de snapshots de stockage Epic</block>
  <block id="4cbb03cae0c07fb5c8e5d5e6df97064e" category="doc">Configuration de l'efficacité du stockage Epic</block>
  <block id="bc9c71d0bf41f8b2c8bde032eb1d97d0" category="paragraph">Les applications avec stockage réparti sur plusieurs volumes avec une ou plusieurs LUN de quantité appropriée à la charge de travail nécessitent que le contenu soit sauvegardé ensemble pour assurer la cohérence de la protection des données.</block>
  <block id="d43039551f875a24f15f154306be2586" category="paragraph">Les groupes de cohérence (CGS pour Short) proposent cette fonctionnalité et bien plus encore. Elles peuvent être utilisées chaque nuit pour créer des copies Snapshot cohérentes à la demande ou planifiées à l'aide d'une règle. Vous pouvez l'utiliser pour restaurer, cloner et même répliquer des données.</block>
  <block id="cbe00f2bdd9a3c8aaaf5f8159a8750c1" category="paragraph">Pour plus d'informations sur CGS, reportez-vous au <block ref="acc09d7e0c59ae3310cafae5d547383a" category="inline-link-macro-rx"></block></block>
  <block id="e62f16b222adc7aecc70ff7b56e652dc" category="paragraph">Une fois les volumes et les LUN provisionnés comme détaillé dans les sections précédentes de ce document, ils peuvent ensuite être configurés dans un ensemble de groupes de cohérence. La meilleure pratique recommandée est de les configurer comme indiqué dans l'image ci-dessous :</block>
  <block id="7dd784e39903a42471f96a6d0d6ae420" category="inline-image-macro">Disposition des groupes de cohérence Epic</block>
  <block id="909e3795441b963b86fcad387196919f" category="paragraph"><block ref="909e3795441b963b86fcad387196919f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45dbe5c870e6de731da235aab8c51046" category="paragraph">Un planning de snapshots de groupe de cohérence doit être défini chaque jour sur les groupes de cohérence enfant associés aux volumes fournissant du stockage pour la base de données de production. Cela donnera lieu à un nouvel ensemble de sauvegardes cohérentes de ces CGS chaque nuit. Vous pouvez ensuite les utiliser pour cloner la base de données de production afin de les utiliser dans des environnements hors production, tels que le développement et le test. NetApp a développé des workflows Ansible automatisés basés sur un groupe de cohérence propriétaire pour Epic afin d'automatiser la sauvegarde des bases de données de production, l'actualisation et les environnements de test.</block>
  <block id="a93362f9de0aff40adccba50a939a6fa" category="paragraph">Les snapshots de groupe de cohérence peuvent être utilisés pour prendre en charge les opérations de restauration de la base de données de production d'Epic.</block>
  <block id="4bf6f09e67952b918985533c270b0668" category="paragraph">Pour les volumes SAN, désactivez la règle de snapshot par défaut sur chaque volume utilisé pour les groupes de cohérence. Ces snapshots sont généralement gérés par l'application de sauvegarde utilisée ou le service d'automatisation Epic Ansible de NetApp.</block>
  <block id="7082753514151e011ff039e6fe23eba2" category="paragraph">Pour les volumes SAN, désactivez la règle de snapshot par défaut sur chaque volume. Ces snapshots sont généralement gérés par une application de sauvegarde ou par l'automatisation Ansible d'Epic.[NS2]</block>
  <block id="669d2da75a76d767cc8259b5f37cacc3" category="paragraph">Les datasets WebBLOB et VMware doivent être configurés comme des volumes uniquement, et non associés à CGS. Vous pouvez utiliser SnapMirror pour conserver les snapshots sur des systèmes de stockage distincts de la production.</block>
  <block id="5a6fb6753e1c4f748d223c8e329133fb" category="paragraph">Une fois la configuration terminée, elle se présente comme suit :</block>
  <block id="926ce6c3b85cb26b415b6fc7e43f2879" category="inline-image-macro">Epic avec snapshots de groupe de cohérence</block>
  <block id="a578d209aa95904cf62330de918a003d" category="paragraph"><block ref="a578d209aa95904cf62330de918a003d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="193e03aa51a18f1e5d72b6a9dd240ed7" category="paragraph">Les fonctionnalités d'efficacité à la volée de ONTAP sont activées par défaut et fonctionnent indépendamment du protocole, de l'application ou du Tier de stockage.</block>
  <block id="f900dc6292f9bf9dcf98291ad5846d4b" category="paragraph">Les fonctionnalités d'efficacité réduisent la quantité de données écrites sur un système de stockage Flash coûteux et le nombre de disques requis. ONTAP préserve l'efficacité de la réplication. L'efficacité n'a que peu, voire pas du tout d'effet sur les performances, même pour une application sensible à la latence comme Epic.</block>
  <block id="936d07f32ce5afcd55e98c4a8cbce642" category="paragraph">*NetApp recommande* d'activer tous les paramètres d'efficacité pour optimiser l'utilisation du disque. Ces paramètres sont activés par défaut sur les systèmes AFF et ASA.</block>
  <block id="d4a551eeebb2992a4ffff1ad1083479a" category="paragraph">Les fonctionnalités suivantes rendent ce stockage efficace possible :</block>
  <block id="cc0df1dcdfa0541f9c5dde8e0b570a36" category="list-text">La déduplication économise de l'espace sur le stockage primaire en supprimant les copies redondantes des blocs d'un volume qui héberge des LUN. Cette option recommandée est activée par défaut.</block>
  <block id="db37fd6533f852997b6ae076ae5e86e0" category="list-text">La compression à la volée réduit la quantité de données à écrire sur le disque, et les workloads Epic réalisent des économies d'espace considérables. Cette option recommandée est activée par défaut.</block>
  <block id="c8afff3d362092825c7eda5b0b6b39af" category="list-text">La compaction à la volée permet de combiner des blocs de 4 ko moins de moitié pleins dans un seul bloc. Cette option recommandée est activée par défaut.</block>
  <block id="b158d6ac5a43e19d1be67d7ba849494d" category="list-text">La réplication fine est au cœur de la gamme de logiciels de protection des données NetApp, qui inclut le logiciel NetApp SnapMirror. La réplication fine de SnapMirror protège les données stratégiques tout en limitant les besoins en capacité de stockage. *NetApp recommande* d'activer cette option.</block>
  <block id="13fb0a52e16b7b3839f151b0847cd0d1" category="list-text">Déduplication dans l'agrégat. La déduplication a toujours été au niveau du volume. Avec ONTAP 9.2, la déduplication de l'agrégat est désormais disponible, ce qui permet de réaliser des économies supplémentaires en termes de réduction de disque. La déduplication post-traitement dans l'agrégat a été ajoutée à ONTAP 9.3. *NetApp recommande* d'activer cette option.</block>
  <block id="46269eefafcbb08ab4667022c6491767" category="summary">Protocoles Epic et de fichiers</block>
  <block id="73a17ad0a24141989f242b5b099eec4f" category="paragraph">Il est possible d'associer NAS et SAN au sein d'une même baie 100 % Flash.</block>
  <block id="688ffca27fb85bfb71c8a7632a871ec1" category="paragraph">*NetApp recommande* d'utiliser des volumes FlexGroup pour les partages NAS, tels que WebBLOB (si disponible).</block>
  <block id="55449fd175613962d882ab450cfc5f3c" category="inline-link-macro">FabricPool</block>
  <block id="1cd6516d7f54730b868069e2db63b528" category="paragraph">WebBLOB représente jusqu'à 95 % des données inactives. Vous pouvez également libérer de l'espace sur votre baie 100 % Flash et procéder au Tiering des sauvegardes et des données inactives vers un stockage objet sur site ou dans le cloud à l'aide de la <block ref="e722be9b80fb0aa9c356c4300710e630" category="inline-link-macro-rx"></block>fonctionnalité ONTAP. Tout cela peut être réalisé sans effet notable sur les performances. FabricPool est une fonctionnalité incluse dans ONTAP. Les clients peuvent générer un rapport de données inactives pour évaluer les bénéfices potentiels grâce à l'activation de FabricPool. Vous pouvez définir l'âge des données à hiérarchiser via une règle. Les clients Epic ont réalisé des économies considérables grâce à cette fonctionnalité.</block>
  <block id="fc3145f7fe85a0cdfffb31f4034ada3b" category="summary">Epic sur ONTAP - utilitaires hôtes</block>
  <block id="f2f8d65f0baeae6d15c1016784ddadbf" category="paragraph">Les utilitaires d'hôte NetApp sont des packs logiciels destinés à divers systèmes d'exploitation qui contiennent des utilitaires de gestion tels que<block ref="3a8e4afa851609127d534b04e7d29c08" prefix=" " category="inline-code"></block> le binaire de l'interface de ligne de commande, les pilotes multivoies et d'autres fichiers importants requis pour effectuer correctement des opérations SAN.</block>
  <block id="23cfb87b0ff3960aab8099cbbb63b50b" category="inline-link-macro">Hôtes SAN</block>
  <block id="b0a8af1d81527bdd65ec0e8fb2a4b4e0" category="paragraph">*NetApp recommande* d'installer les utilitaires hôtes NetApp sur les hôtes connectés aux systèmes de stockage NetApp et qui y accèdent. Pour plus d'informations, reportez-vous à  la section <block ref="b2445b429f9784426e3dc1158e67c70d" category="inline-link-macro-rx"></block> et <block ref="7d7a0f71ed9bf2fe94a10fa9e1aeb381" category="inline-link-macro-rx"></block>à la documentation.</block>
  <block id="54ed29e411552372c5b6b9e2e1617e6d" category="admonition">Avec AIX, il est particulièrement important que les utilitaires hôtes soient installés avant de découvrir les LUN. Cela permet de s'assurer que le comportement de chemins d'accès multiples de la LUN est correctement configuré. Si la découverte a été effectuée sans les utilitaires hôtes, les LUN doivent être déconfigurées du système à l'aide de la<block ref="9442434081221d63eaaa2c4799062866" prefix=" " category="inline-code"></block> commande, puis redécouvertes via<block ref="fe54d1c30028417038a4ffe0fc5eb503" prefix=" " category="inline-code"></block> ou un redémarrage.</block>
  <block id="e7a8be60cff2fec7b8ed793c4d2dddfe" category="summary">Configuration de volume et de LUN Epic</block>
  <block id="acdbb325faec5e3e2d86b3dbbaf90c54" category="paragraph">Le document recommandations d'Epic Database Storage Layout fournit des conseils sur la taille et le nombre de LUN pour chaque base de données.</block>
  <block id="a620ecf0a73eb209a145eb913a29bc5a" category="paragraph">Il est important de consulter ce document avec l'aide d'Epic DBA et d'Epic, et de finaliser le nombre de LUN et la taille de LUN en cas d'ajustement. Ces recommandations de stockage sont importantes pour la profondeur de file d'attente des HBA, les performances de stockage, la facilité d'exploitation et la facilité d'extension.</block>
  <block id="21ebeea1f14a138dfebb1b9599a4c3dd" category="paragraph">Pour optimiser les performances d'une charge de travail, comme Epic ODB ou Clarity, chaque disposition est également optimisée pour le stockage NetApp. Avec huit volumes utilisés, les E/S d'écriture sont réparties de façon homogène entre les contrôleurs, optimisant ainsi l'utilisation du processeur. Pour la réplication et la sauvegarde, il est préférable de limiter le nombre de volumes à huit pour simplifier les opérations.</block>
  <block id="90adf331b7868c7af46ad6e035e93844" category="section-title">Options d'évolutivité</block>
  <block id="b323bb297a66afc2eea7b89dd4019798" category="section-title">Disposition des volumes et 8 LUN</block>
  <block id="66d125e77a6185ef5cf43b2a6bffea80" category="inline-image-macro">Disposition Epic 8 LUN</block>
  <block id="99a54ac1eaa5bd57b4c4c29d6a63f1ac" category="paragraph"><block ref="99a54ac1eaa5bd57b4c4c29d6a63f1ac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bad4d79343f04d8b64999875ad328086" category="list-text">Équilibrez les charges de travail sur toute la paire haute disponibilité afin d'optimiser les performances et l'efficacité.</block>
  <block id="26b591a32a8a235db7f742995589a455" category="list-text">Utilisation de volumes et de LUN à provisionnement fin</block>
  <block id="9fb0aaeb125238e83485971ae6b7e2fc" category="list-text">Utilisez au moins huit LUN de base de données, deux LUN de journal et deux LUN d'application. Cette configuration optimise les performances du stockage et la profondeur de la file d'attente du système d'exploitation. Vous pouvez utiliser davantage de ressources si nécessaire pour des raisons de capacité ou autres.</block>
  <block id="ba5e00554d1ba1b8ca0fc2eaeda44672" category="list-text">Si vous devez ajouter des LUN à des groupes de volumes, ajoutez huit LUN à la fois.</block>
  <block id="08c8ec6a9fefcf9c5c7dff1258aacf67" category="list-text">Les groupes de cohérence sont requis pour la sauvegarde conjointe du groupe de volumes et des LUN.</block>
  <block id="f513b81222a1b44f552ae172aeb697c9" category="list-text">N'utilisez pas QoS pendant le Genio ou les performances d'E/S.</block>
  <block id="b77a34499937c829a2c5c5a1cdc17f05" category="list-text">Après les tests Genio ou Clarity, NetApp recommande de supprimer le stockage et de le reprovisionner avant de charger les données de production.</block>
  <block id="186bc47646aec5e2abf40b2605a16461" category="list-text">Il est important que<block ref="54645d7349dcc4fe9d7d19985a40c2c9" prefix=" " category="inline-code"></block> l'option activé soit définie sur les LUN. Si ce n'est pas le cas, les données supprimées des LUN ne sont pas visibles par ONTAP et peuvent entraîner des problèmes de capacité. Pour plus d'informations, consultez le guide de référence rapide de la configuration du stockage Epic.</block>
  <block id="153c47e1653d87804319da1fe347f29b" category="summary">Gestion des performances Epic</block>
  <block id="912975539030067a6f1874223cda9b75" category="paragraph">La plupart des baies 100 % Flash offrent les performances requises pour les workloads Epic. L'atout de NetApp est sa capacité à définir des règles de performance au niveau du sol et à garantir une performance prévisible pour chaque application.</block>
  <block id="edfc4c86589e31546a8fb2d8b085b8c9" category="section-title">Qualité de service (QoS)</block>
  <block id="8080e6f80ff76b571829265ee2917e87" category="paragraph">NetApp recommande d'utiliser la QoS. Le bénéfice de la QoS est la possibilité de consolider tous les workloads Epic. Tous les protocoles et les pools de stockage peuvent résider sur moins de matériel. Il n'est pas nécessaire de séparer les pools de stockage.</block>
  <block id="44c2f7cd7c41efaae67916780bf96079" category="list-text">NetApp recommande d'attribuer à toutes les charges de travail du cluster une politique de qualité de service afin de mieux gérer la marge sur le cluster.</block>
  <block id="d90d7fd828646173964451dadbe758c1" category="list-text">NetApp recommande d'équilibrer toutes les charges de travail de façon homogène dans la paire haute disponibilité.</block>
  <block id="a77412a540f86bfc443abfcef22db414" category="list-text">N'utilisez pas les règles de qualité de service lors des tests d'E/S ; dans le cas contraire, les tests Genio échoueront. Analysez les différents workloads de production pendant 2-4 semaines avant d'attribuer des règles de QoS.</block>
  <block id="c36c006dced61f1e460ff43516fa7294" category="summary">Epic sur ONTAP - protocoles</block>
  <block id="0f079f7da3a6e5c8a52a3aca113fd3e6" category="paragraph">FCP est le protocole privilégié pour la présentation des LUN.</block>
  <block id="97ec588f063ba0f25df2b93eda2639c8" category="paragraph">*NetApp recommande* une segmentation à un seul initiateur : un initiateur par zone avec tous les ports cibles requis sur le stockage à l'aide des WWPN (Worldwide Port Name). La présence de plusieurs initiateurs dans une même zone est susceptible d'entraîner une diaphonie intermittente des HBA, ce qui provoque des perturbations importantes.</block>
  <block id="880bc24c60e1d6eb559f57440c27f955" category="paragraph">Une fois la LUN créée, mappez-la sur le groupe initiateur (igroup) contenant les WWPN de l'hôte pour permettre l'accès.</block>
  <block id="d8609b6e37acaad082fff919da3c6691" category="paragraph">NetApp prend également en charge l'utilisation de NVMe/FC (si certaines versions des systèmes d'exploitation AIX et RHEL sont compatibles) et améliore les performances. FCP et NVMe/FC peuvent coexister sur la même structure.</block>
  <block id="2586e87005565fe66fa19a3af50f632c" category="summary">Dimensionnement du stockage pour Epic</block>
  <block id="5e3e8694114d62a133f86c691b0d1d68" category="paragraph">Vous devez collaborer avec notre équipe Alliance Epic pour confirmer tous les designs Epic. L'équipe peut être rejointe sur Epic@NetApp.com. Chaque déploiement doit répondre aux demandes des clients tout en respectant les bonnes pratiques recommandées par Epic et NetApp.</block>
  <block id="c77c62342c6d144df81571fee8e8a4e8" category="paragraph">Pour plus d'informations sur l'utilisation des outils de dimensionnement NetApp afin de déterminer la taille et le nombre corrects de groupes RAID pour les besoins de stockage de l'environnement logiciel Epic, reportez-vous à la section <block ref="b6ff45309a811037a92ca1e6262c74a8" category="inline-link-macro-rx"></block> (connexion NetApp requise).</block>
  <block id="6fff8a4d9dc5db1aefc3e3a86c26dbd7" category="admonition">Vous devez disposer d'un accès au Field Portal NetApp.</block>
  <block id="1484157a851d4053990c9bf55fb59e58" category="summary">Exemple de déploiement Epic sur ONTAP : agrégats</block>
  <block id="e8f3d574ecc3fdf160285a0c9a5a7046" category="paragraph">Pour obtenir la documentation la plus récente sur le provisionnement des agrégats, cliquez sur <block ref="a20b867e80db6cfd4fb8336d84c1fcc5" category="inline-link-macro-rx"></block>.</block>
  <block id="f2871c08962452bb98a23ee83880a7dd" category="admonition">Les paramètres par défaut optimisent les performances et la capacité. Un grand agrégat est créé par nœud.</block>
  <block id="46b67d0e3c5baea52f318c392862983a" category="summary">Exemple de déploiement EPIC sur ONTAP - systèmes de fichiers</block>
  <block id="ff902a0a262960f8bf9189923c1ff7d9" category="paragraph">Pour plus d'informations sur le montage de LUN, la création de groupes de volumes et de volumes logiques et la configuration des systèmes de fichiers, reportez-vous au Guide de référence rapide de configuration de stockage Epic. Utilisez les exemples de commandes suivants pour configurer les serveurs de production Epic pour RHEL.</block>
  <block id="f54e4ad7066826fa3c18dcb8a62ddd03" category="section-title">Système de fichiers et options de montage</block>
  <block id="ca487f2e3d336dbbead8ef7ce6f1dc6c" category="paragraph">Une fois les LUN créées et mappées et le zoning terminé, utilisez la procédure suivante pour connecter le stockage au serveur.</block>
  <block id="232aac42537fa2491071068a6dacfe10" category="admonition">Dans cet exemple, nous avons utilisé 8 LUN de 24 Go pour la base de données, 2 LUN de 24 Go pour les journaux et 2 LUN de 24 Go pour les installations d'applications.</block>
  <block id="cdf658da371089bb06d8dc79b4ae2e2e" category="section-title">E/S asynchrones</block>
  <block id="86c5811d8dc490e1467aed33484d89f2" category="paragraph">Une copie du livre blanc « considérations SAN d'Epic » et du document de référence rapide sur la configuration du stockage explique comment configurer les hôtes et se connecter au stockage. Cette section explique comment configurer un hôte Red Hat Enterprise Linux. Les détails AIX sont disponibles dans les documents référencés.</block>
  <block id="81cba0a3715b5297330ade2beaa9dc7d" category="summary">Exemple de déploiement d'Epic sur ONTAP - LUN</block>
  <block id="30baf86157b500051493cda4ff1be0c3" category="paragraph">&gt;&gt;&gt; espace réservé à la phrase ou au paragraphe principal descriptif</block>
  <block id="6aa18085c59b7b34360d5dff15bf6e84" category="paragraph">Créer une LUN</block>
  <block id="6a761ce5c1cf1122b1aaea2aec3cfc85" category="paragraph">Pour créer une LUN :<block ref="18244093c882fe4e65acdec6d61f9f95" category="inline-link-rx"></block></block>
  <block id="8ede5bcd129cb7b52add8d233c5e5867" category="paragraph">Ajouter des volumes au groupe de cohérence</block>
  <block id="4bd3faeb169131a1ecbf00026f146a6f" category="paragraph">Pour créer ou modifier des groupes de cohérence :<block ref="52ad8c1ba289849e0c6ebe85b916c91a" category="inline-link-rx"></block></block>
  <block id="1093fcc785c9f0e59ff32142b73ff3a5" category="paragraph">Mapper la LUN</block>
  <block id="9e5dabcfb97ff08290166a6dd001c95e" category="paragraph">Pour mapper la LUN :<block ref="8b5a6c46b302a4299b28e891d262657f" category="inline-link-rx"></block></block>
  <block id="73a228bbb9b14b5f966f329a201b115d" category="paragraph">Selon la version de ONTAP, le paramètre par défaut pour la réserve fractionnaire sur le volume peut être de 100 %. Cette configuration doit être définie sur 0.</block>
  <block id="b13aace07f0445cf1ff16be054bcc01e" category="summary">Exemple de déploiement Epic sur ONTAP</block>
  <block id="cca1d6e8ff542fcd4d1315f7f9033467" category="paragraph">Cette section vous présente une configuration avancée complète d'un cluster ONTAP, le provisionnement et la présentation du stockage à un serveur Epic.</block>
  <block id="df8f0aad2b90e887efba35ecbc7e6546" category="paragraph">Pour capturer des détails et faciliter la documentation, la ligne de commande est utilisée. Si l'interface utilisateur graphique est préférée, vous pouvez provisionner tous les paramètres dans System Manager.</block>
  <block id="d706ffe8745cb55ce7b7d1c7dfa458dd" category="paragraph">Historiquement, la configuration initiale de gros projets est généralement plus rapide en utilisant les commandes répertoriées dans le tableau 1, surtout si vous concaténez les commandes dans une feuille de calcul. Cette liste de commandes sert également d'excellente documentation de construction.</block>
  <block id="12c8172fde8f9b3f81c3ed0d2805f3d4" category="paragraph">Une autre option de provisionnement consiste à utiliser des scripts d'automatisation dès le premier jour et à l'aide d'Ansible. NetApp dispose de centaines de playbooks Ansible disponibles au téléchargement, y compris la collection Ansible Galaxy via la commande ansible-Galaxy collection install NetApp.ONTAP.</block>
  <block id="80455b40cdd7b477184d76f23f747af1" category="paragraph">L'interface graphique fonctionne également très bien avec un LUN d'une seule page et un provisionnement partagé. L'interface graphique est particulièrement utile pour les opérations d'ajout, de modification ou de suppression de stockage. Les deux options conviennent si vous appliquez les paramètres de stockage des meilleures pratiques du Tableau 1.</block>
  <block id="d7441f24bee2c1922760ce27f5e978ec" category="paragraph">La configuration complète du cluster et le provisionnement du stockage/de l'hôte ne doivent pas prendre plus d'une heure lors de leur mise en place.</block>
  <block id="3924c8a2656c72cc0c7d6a27f9ad08ea" category="paragraph">*Paramètres de stockage des meilleures pratiques*</block>
  <block id="51ac4bf63a0c6a9cefa7ba69b4154ef1" category="cell">Réglage</block>
  <block id="689202409e48743b914713f96d93947c" category="cell">Valeur</block>
  <block id="2ee34178bb8415b7d7234cd27b83aed6" category="cell">Agrégat</block>
  <block id="ae6bd8a277455ba774ffc217a2f8a539" category="cell">Provisionnement automatique par défaut, un agrégat ADP par nœud avec RAID DEP</block>
  <block id="63555da25f96be027cd722d9f281cffa" category="cell">Deux SVM en cas d'utilisation de Multiprocol (SVM bloc et SVM SMB/NFS) Utilisez Epic et la convention de nommage des protocoles. Utilisez un style de sécurité approprié</block>
  <block id="aec0819ab194aee8aab8a5e40aad8343" category="cell">Garantie d'espace pour les volumes</block>
  <block id="334c4a4c42fdb79d7ebc3e73b517e6f8" category="cell">Aucune</block>
  <block id="d374cbba7f603e6be8e6450a6b3feb45" category="cell">Règle de snapshot du volume</block>
  <block id="8285885018fdba6d87edc774237f0e24" category="cell">Dimensionnement automatique du volume</block>
  <block id="4d200fce73a8e1cc965cfc2c43343824" category="cell">Grandir</block>
  <block id="948111f101cd4e13c4a1e21775e9742d" category="cell">Taille automatique maximale du volume</block>
  <block id="fde7826aacd46b7610beed2b0ef8d81e" category="cell">Taille de LUN 2 T ou 2 X.</block>
  <block id="ca714a7089246aff7f85bbda97ba660b" category="cell">Suppression automatique du Snapshot de volume</block>
  <block id="a10311459433adf322f2590a4987c423" category="cell">activé</block>
  <block id="6bb41960470a19d97556b9240ac0b3ff" category="cell">Taille du volume</block>
  <block id="9bba382221ce257d09f3f50492803815" category="cell">1.5 x taille de LUN</block>
  <block id="dc85eb20ed6dd71700df76a7f9acd32b" category="cell">Disposition des volumes</block>
  <block id="370e47099244ee43c575d91449bb7e36" category="cell">Distribué même sur plusieurs contrôleurs</block>
  <block id="ca301c828c76b7b6b1a9b621ba37f603" category="cell">type d'igroup</block>
  <block id="d6c56de514a4a8fe23f54d6b42dd23af" category="cell">OS lorsqu'il est utilisé avec des serveurs physiques, type VMware lorsqu'il est utilisé avec ESX.</block>
  <block id="bbd68bf55ab562da30e73449f1b87424" category="summary">Exemple de déploiement Epic sur ONTAP - protocoles</block>
  <block id="589b83bd3c7696acc0086c7f233e64e3" category="doc">Exemple de déploiement Epic sur ONTAP - plateformes</block>
  <block id="05f72896244a448167caa4a410eb4ecf" category="paragraph">Pour les bases de données ODB, les journaux et les workloads applicatifs Epic recommande de présenter le stockage aux serveurs sous forme de LUN FCP.</block>
  <block id="d2ec366dff0b7a3eda35e6acf91f6898" category="paragraph">Les clients NetApp ont exécuté avec succès tous les workloads Epic dans le cloud Azure. AWS peut également exécuter les workloads Epic. Avec NetApp Cloud Volumes ONTAP et NetApp Cloud volumes Services, NetApp fournit les fonctionnalités haute performance et les performances requises pour exécuter efficacement Epic dans le cloud. Les options cloud de NetApp offrent des fonctionnalités de stockage bloc sur iSCSI et de fichiers sur NFS ou SMB.</block>
  <block id="a3a5d01a736b2f5bc994d2ff7b0da8c5" category="summary">Exemple de déploiement Epic sur ONTAP - protocole FCP</block>
  <block id="dc0e595680f18844673c0930ecf1ca6b" category="paragraph">Une fois le SVM créé, vous devez lui ajouter des protocoles.</block>
  <block id="263a628397d3f78e3b61f40863b0868f" category="paragraph">Pour créer des LIFs de données FCP, cliquez sur <block ref="8f46d074b2d46f416cb36dce6f8bd76d" category="inline-link-macro-rx"></block>.</block>
  <block id="663c2decd75c93fbad53179b6016c0d1" category="paragraph">Les groupes initiateurs permettent au serveur d'accéder aux LUN. Pour créer un iGroup, cliquez sur <block ref="c6345eebd77187b1723cf47095ffbd0f" category="inline-link-macro-rx"></block>.</block>
  <block id="93f7209bec244568b95ac2f8f50896d7" category="summary">Exemple de déploiement d'Epic sur ONTAP - SVM</block>
  <block id="39ce7fcbb7e39843ad7e81e460901359" category="paragraph">NetApp virtualise le stockage et l'accès utilisateur est assuré par le SVM.</block>
  <block id="8c22ab38f47a2a116e19714defb5f005" category="paragraph">Pour Epic, il existe un SVM FCP et un SVM SMB. Selon la façon dont vous souhaitez gérer votre stockage et éventuellement la colocation, vous pouvez utiliser davantage de SVM.</block>
  <block id="99889a411324e95bb7313521d10d972b" category="paragraph">Pour configurer un SVM, cliquer sur <block ref="cb8e547e3f29ee63864aeed75c724bf1" category="inline-link-macro-rx"></block></block>
  <block id="abf025601df70d9ba931fe67b1cc4a79" category="summary">Exemple de déploiement Epic sur ONTAP - volumes</block>
  <block id="02594c71ca915876e2512e474d8b462d" category="paragraph">Pour créer des volumes, voir<block ref="b6546da834bc505016791ad9e7ec9d1e" category="inline-link-rx"></block></block>
  <block id="36e2bc00e48fbcfe5ae35a8a6056788c" category="admonition">Depuis la version ONTAP 9.7, le chiffrement des agrégats et des volumes est activé par défaut lorsque vous disposez d'une licence NVE et d'une gestion des clés intégrée ou externe. Pour activer la déduplication au niveau des volumes, définissez la panne add -crypt sur la commande volume create/modify (si vous disposez d'une licence NVE).</block>
  <block id="7a112f92e38a30129ab13d18331e21ce" category="section-title">Suppression automatique des instantanés</block>
  <block id="f118801694edca90b5e446d3fe39cda0" category="paragraph">Pour supprimer automatiquement des instantanés :<block ref="ecea59d033fb2dad1d38e75fbdc1c820" category="inline-link-rx"></block></block>
  <block id="e324e68086bb9c9e930b9d1168f1de5d" category="summary">Disponibilité Epic sur ONTAP</block>
  <block id="8339b88fddad3cfe433f684a83da04eb" category="paragraph">La continuité de l'activité est au cœur de ONTAP et vous permet d'éviter les interruptions coûteuses de vos activités.</block>
  <block id="ca7972f1caf7a478b4f931e986112b62" category="paragraph">NetApp assure une disponibilité supérieure à 99.999999 % sur les données de production, qui sont appelées « maison » via NetApp Active IQ. Chaque paire haute disponibilité dans le cluster ne présente pas de point de défaillance unique. Depuis 1992, ONTAP est le logiciel de gestion des données le plus largement déployé au monde. Depuis, sa fiabilité de stockage a fait ses preuve d'une expérience exceptionnelle. Active IQ surveille et résout automatiquement 97 % des problèmes de manière proactive. La disponibilité est ainsi accrue et le nombre de dossiers de demande de support est considérablement réduit.</block>
  <block id="43a21754b069ee170b1858e00c4072df" category="paragraph">Epic recommande l'utilisation de systèmes de stockage haute disponibilité pour limiter les défaillances de composants matériels. Cette recommandation s'étend du matériel de base (par exemple, les alimentations redondantes) aux réseaux (par exemple, les réseaux à chemins d'accès multiples).</block>
  <block id="58992d12f27d940ad0ced78080987a44" category="paragraph">Lorsque vous devez mettre à niveau le stockage, le faire évoluer verticalement, le faire évoluer horizontalement ou rééquilibrer les charges de travail dans le cluster, les soins aux patients ne sont pas pris en charge. Vous pouvez déplacer des données, mais les patients ne doivent plus jamais interrompre les soins lors des migrations de données ou des mises à niveau majeures. Optez pour une technologie nouvelle génération, pérenne et sans dépendance vis-à-vis d'un seul matériel. NetApp garantit même une disponibilité écrite de 100 %.</block>
  <block id="071a41c2bfc6123073746c5459501089" category="inline-link-macro">Fiabilité, disponibilité, facilité de maintenance et sécurité du système NetApp ONTAP</block>
  <block id="c38a90bcf1a9aa5905c0c4e6fbac331b" category="paragraph">Pour plus d'informations sur la fiabilité, la disponibilité, la facilité de maintenance et les fonctions de sécurité de NetApp, consultez le <block ref="c4f5dec030b0bd57318efbed2e25e7a7" category="inline-link-macro-rx"></block>livre blanc.</block>
  <block id="12a3215a6e17b2d4e547b8c9ddb4db59" category="summary">Protection des données Epic</block>
  <block id="e2f4ffd17d85ea8c667a8fa10eaa81bd" category="doc">Clonage Epic</block>
  <block id="d777ff146845d0c5a59b451dcdd63eff" category="paragraph">Epic reconnaît que la technologie Snapshot NetApp basée sur des nœuds de stockage n'a aucun impact sur les performances des workloads de production par rapport aux sauvegardes classiques basées sur des fichiers. Lorsque les sauvegardes Snapshot sont utilisées comme source de restauration pour la base de données de production, la méthode de sauvegarde doit être implémentée en tenant compte de la cohérence de la base de données.</block>
  <block id="7952c7481879c42a618f85cfab77dc0b" category="paragraph">Un snapshot est une copie de sauvegarde en lecture seule d'un volume à un point dans le temps. NetApp FlexClone® prend un instantané et le rend instantanément lisible et inscriptible. Les volumes FlexClone sont particulièrement utiles pour créer des copies Snapshot en lecture seule cohérentes au niveau des applications et des volumes FlexClone inscriptibles à partir des données de production. Cette fonctionnalité native a un impact significatif sur les économies de stockage, le temps d'exploitation et les fonctionnalités d'automatisation.</block>
  <block id="dd12a5170cc960b0ed4afe4f23fd727b" category="paragraph">Pour le processus d'actualisation, des volumes FlexClone sont utilisés.</block>
  <block id="198010d8bf8a3ff0f084ffd059a9a1da" category="section-title">La gestion des données</block>
  <block id="31949f92a027681e10fa0ae809d62bcd" category="paragraph">Dans le cadre de sa solution, NetApp propose une solution de sauvegarde et d'actualisation des tests entièrement automatisée à l'aide des outils ONTAP natifs. Cette solution a été conçue pour simplifier la gestion des données Epic tout particulièrement pour la grande communauté d'administrateurs de bases de données Epic :</block>
  <block id="bde282ad1e62a3d8d64bcbebfd99918c" category="list-text">Epic Mirror est utilisé pour répliquer les données vers la reprise sur incident et le rapport (indiqué en vert).</block>
  <block id="89c4ed523f61f9d3446182d80a53c8b6" category="list-text">Vidage quotidien des données du rapport à Clarity.</block>
  <block id="c3d37da5ec71148ab4d2292c5fc62181" category="list-text">Sauvegardes automatisées NetApp (indiquées en jaune)</block>
  <block id="f417d841f910f45d16ac64fccd850be8" category="list-text">Actualisation des tests automatisés NetApp du SUP, du REP et d'autres (indiquée en bleu).</block>
  <block id="2a7a6372892435f5d284e730df618c35" category="list-text">Les environnements de test sont destinés aux environnements à copie intégrale, et non aux copies de copie de copie de base plus petites.</block>
  <block id="88b2dcefc205727508d4017aacafaafd" category="paragraph">Pour plus d'informations, contactez les services NetApp pour applications Epic.</block>
  <block id="4e3e281c19bf41f436de9fe363daa25c" category="paragraph">Les groupes de cohérence (CGS pour Short) proposent cette fonctionnalité et bien plus encore. Elles peuvent être utilisées chaque nuit pour créer des copies Snapshot cohérentes à la demande ou planifiées à l'aide d'une règle. Vous pouvez l'utiliser pour restaurer, cloner et même répliquer des données.</block>
  <block id="f5de57234e68f27cbd82acfc80f2d5cb" category="inline-link-macro">Documentation NetApp sur les groupes de cohérence</block>
  <block id="f7e43fe614bf53ff9721f7494c0caf16" category="paragraph">Pour plus d'informations sur CGS, reportez-vous à <block ref="0efc681e89d66f1c589ad00a8ae67afa" category="inline-link-macro-rx"></block></block>
  <block id="9f42082fda47a6a26e6c6e6bcc14526e" category="section-title">Configuration de groupes de cohérence pour Epic</block>
  <block id="7d381e222258ec55bcf215684ae70097" category="inline-image-macro">Groupes Epic et Consistency</block>
  <block id="4eb8f91ee432a8e69615314961db4f88" category="paragraph"><block ref="4eb8f91ee432a8e69615314961db4f88" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4294e0bf4b67190ddcb91a01b3c4356c" category="section-title">Snapshots de groupes de cohérence</block>
  <block id="86cfb45aaa741215d8d8d58223948dcc" category="paragraph">Les jeux de données WebBLOB et VMare doivent être configurés en tant que volumes uniquement, et non associés à CGS. Vous pouvez utiliser la technologie SnapMirror ou SnapVault pour conserver vos copies Snapshot sur des systèmes de stockage distincts de la production.</block>
  <block id="f5445123331a1b74a34fd1f392e9e946" category="inline-image-macro">Snapshots épiques de groupe de cohérence</block>
  <block id="92aabd14a16803d9fa65ca4f94488322" category="paragraph"><block ref="92aabd14a16803d9fa65ca4f94488322" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9c71026f6349a81cd2a3cfcfa8ea9ceb" category="summary">Epic sur la consolidation ONTAP</block>
  <block id="569a30a99d3744f0871a7c36162f469c" category="paragraph">L'un des principaux défis dans le domaine de la santé est l'inefficacité des environnements en silos.</block>
  <block id="87b522a84cee7651eb3ea5c59d4c9a35" category="paragraph">Plusieurs solutions ponctuelles sont créées par divers groupes qui empêchent le progrès. Une stratégie unifiée de gestion des données apporte de l'efficacité pour accélérer la transformation. Des technologies perturbatrices, telles que la numérisation des dossiers médicaux, les ransomwares et l'IA générative, qui sont autant d'éléments qui nécessitent une consolidation.</block>
  <block id="882f36b3d76e4e5b9ac08850c1e7a15a" category="paragraph">Avec ONTAP, vous pouvez consolider les fichiers, les blocs et les objets ainsi que chacun de vos workloads de Tier 0/1/2/3, sur site et dans le cloud, qui s'exécutent tous sur ONTAP.</block>
  <block id="0b153e0d191221abe8c325950ab9a03b" category="summary">Epic sur l'efficacité ONTAP</block>
  <block id="12ca553efec3e73a9120d8c050d405a9" category="paragraph">Epic s'exécute sur des baies 100 % Flash, où la majeure partie du coût est le disque. Par conséquent, l'efficacité du stockage est essentielle pour réaliser des économies.</block>
  <block id="aac466a460fe672b45d2e43b476f772e" category="paragraph">L'efficacité du stockage à la volée de NetApp permet de réaliser des économies de stockage de pointe sans effets sur les performances, et nous proposons même une garantie d'efficacité écrite avec les baies 100 % Flash.</block>
  <block id="436525ee58a117eefbde96bb2f0cae02" category="paragraph">Lors du calcul de l'efficacité du stockage, il est important de mesurer la capacité brute à la capacité utilisable réelle.</block>
  <block id="bbf547b93564824fe00f04646269a56e" category="list-text">*Capacité brute* avant d'appliquer un RAID, taille du disque par nombre de disques.</block>
  <block id="29cabda6c17d251ab3bba7feb41646fc" category="list-text">*Capacité utilisable* après application de RAID, combien de stockage utilisable est disponible.</block>
  <block id="9edb4e889ca40d3881217c9433ecb376" category="list-text">*Capacité effective* quantité de stockage provisionnée et présentée à l'hôte ou au client.</block>
  <block id="21e10a177fbffc69f63f5dcdb44175f5" category="paragraph">La figure ci-dessous est un exemple de calcul d'efficacité pour un déploiement Epic classique, incluant toutes les charges de travail nécessitant 852 To de stockage effectif et avec un ratio d'efficacité de 5.2:1 pour 1,32 po de données effectives totales.</block>
  <block id="c8c2fd097c28062ec912ad0d2f9bbe11" category="admonition">La capacité brute à utilisable varie légèrement en fonction du nombre de disques.</block>
  <block id="f0a0c9b18011b122c315d8970dbcce49" category="inline-image-macro">Efficacité du stockage Epic</block>
  <block id="d145883b21ccbccb471abc3a5dac40f3" category="paragraph"><block ref="d145883b21ccbccb471abc3a5dac40f3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bf8acecf163b9e71e2e9331bc87c5e90" category="admonition">NetApp n'utilise pas la technologie Snapshot de NetApp ni le provisionnement fin pour calculer l'efficacité du programme de garantie. Cela démontre une efficacité irréaliste entre 30 et 100:1, ce qui ne veut rien dire lors du dimensionnement de la capacité de stockage réelle.</block>
  <block id="f4f81a0ab85224d234bc465988b5b871" category="summary">Présentation d'Epic sur ONTAP</block>
  <block id="35b4c598dd74c59e91d978c12210cc03" category="doc">EPIC sur ONTAP</block>
  <block id="52aaae321a4b3f69eaf3448c22d2d55c" category="paragraph">Epic est plus facile avec ONTAP.</block>
  <block id="76d68daeac9b3e7a8cfb0c3d904ac7de" category="paragraph">ONTAP est une plateforme de gestion des données qui vous permet de consolider les workloads Epic tout en répondant à vos besoins de performances, de protection des données et de gestion des données.</block>
  <block id="85e6f9f2e3539043a3a60b16af5a654f" category="paragraph">Seul NetApp permet de standardiser tous vos workloads de santé pour SAN, NAS et objet sur une plateforme unique de gestion des données haute disponibilité. ONTAP est la plateforme logicielle de stockage la plus largement déployée au monde et s'accompagne de près de 30 ans d'innovation constante. Vous pouvez relever tous vos défis Epic grâce aux outils de gestion des données ONTAP natifs et à l'intégration des applications. Nul besoin d'acheter une multitude d'outils tiers pour combler les lacunes de la solution.</block>
  <block id="54fed3d17b1233bcc7ab7b0d3f6eddca" category="paragraph">De nombreux fournisseurs de stockage proposent un stockage bloc classique, fiable et rapide. Elles fonctionnent bien, mais sont généralement déployées en silos pour exécuter une seule charge de travail, telle que la production, le reporting, la clarté, l'infrastructure de postes de travail virtuels, VMware et NAS. Chacun de ces silos possède du matériel et des outils de gestion différents, et sont généralement gérés par des groupes INFORMATIQUES différents. Cette approche traditionnelle ajoute au plus gros problème dans le domaine de la santé aujourd'hui : la complexité.</block>
  <block id="58ad32957aed88a3c14ef81e5f254bd3" category="paragraph">NetApp facilite et optimise la gestion des données. Au lieu d'investir dans des silos surdimensionnés, ONTAP utilise l'innovation et la technologie pour fournir un niveau de service cohérent et garanti pour chaque charge de travail sur une plateforme unique, quel que soit le protocole utilisé avec la protection des données intégrée. Ces fonctionnalités et outils s'étendent également au cloud de votre choix, comme illustré ci-dessous.</block>
  <block id="0d9c98d3832defc892b59655abcfacfc" category="inline-image-macro">Évolutivité et simplicité pour le secteur de la santé avec ONTAP</block>
  <block id="4277ed476100dc05b0a4e0e837c3d9b9" category="paragraph"><block ref="4277ed476100dc05b0a4e0e837c3d9b9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="63cc4e5664cd9022b0fc1580682f9995" category="summary">Performances Epic sur ONTAP</block>
  <block id="6762c0b102338c245945f7d09da83fa4" category="paragraph">ONTAP a introduit les technologies Flash en 2009 et prend en charge les disques SSD depuis 2010. Cette longue expérience du stockage Flash permet à NetApp d'ajuster les fonctionnalités de ONTAP afin d'optimiser les performances des disques SSD et d'améliorer la longévité des supports Flash tout en conservant les fonctionnalités avancées de ONTAP.</block>
  <block id="8e0c14b7c96a8748c07c3916510ebd8b" category="paragraph">Depuis l'année 2020, tous les workloads ODB d'Epic doivent être hébergés sur du stockage 100 % Flash. Les charges de travail Epic fonctionnent généralement à environ 1,000 à 2,000 IOPS par téraoctet de stockage (bloc de 8 Ko, ratio lecture/écriture de 75 à 25 % et aléatoire de 100 %). Epic est très sensible à la latence, et une latence élevée a un impact visible sur l'expérience utilisateur, ainsi que sur les tâches opérationnelles telles que l'exécution de rapports, de sauvegardes, de vérifications d'intégrité et de mises à jour de l'environnement.</block>
  <block id="4a9928f04affb2a4fe321fb9e2b003fd" category="list-text">Les baies 100 % Flash n'étant pas le facteur limitant, elles se limitent aux disques, mais à l'utilisation des contrôleurs.</block>
  <block id="11a9dfbe9a015ca567ecd5f77959dc1f" category="list-text">ONTAP utilise une architecture actif-actif. Pour les performances, les deux nœuds de la paire haute disponibilité écrivent sur les disques.</block>
  <block id="3a5c5db6ac361794af4c29a626c584f5" category="list-text">Il en résulte une utilisation optimisée du processeur, qui est le facteur le plus important qui permet à NetApp de publier les meilleures performances Epic du secteur.</block>
  <block id="2f6b137b593d6a732992bc619827ee36" category="list-text">Les technologies NetApp RAID DP, ADP (Advanced Disk Partitioning) et WAFL répondent à tous les besoins Epic. Toutes les charges de travail distribuent les E/S sur tous les disques. Sans goulot d'étranglement.</block>
  <block id="0ce3d3de991180e05a5a0818efc312ef" category="list-text">ONTAP est optimisé pour l'écriture. Les écritures sont reconnues une fois écrites sur la NVRAM en miroir avant d'être écrites sur le disque à la vitesse de la mémoire en ligne.</block>
  <block id="ca65639a4e206f319202179e1d9a4ff4" category="list-text">WAFL, NVRAM et l'architecture modulaire permettent à NetApp d'utiliser le logiciel pour innover avec des fonctionnalités d'efficacité à la volée, de chiffrement et de performance. Ils permettent également à NetApp de lancer de nouvelles fonctionnalités sans affecter les performances.</block>
  <block id="f13349f1404495d87711104e964b1cef" category="list-text">Jusqu'à présent, chaque nouvelle version de ONTAP a enregistré une augmentation des performances et de l'efficacité de l'ordre de 30 à 50 %. Toujours à jour avec ONTAP, les performances sont optimales.</block>
  <block id="70d9e3c68d42d6ec42ab792e06c44357" category="section-title">NVMe</block>
  <block id="42fa4afed0f941a60ea00e82671c421d" category="paragraph">Lorsque les performances sont primordiales, NetApp prend également en charge NVMe/FC, le protocole FC SAN nouvelle génération.</block>
  <block id="1e4d4890d3f90b04841095b53183f782" category="paragraph">Comme le montre la figure ci-dessous, nos tests Genio ont réalisé un nombre beaucoup plus élevé d'IOPS en utilisant le protocole NVMe/FC par rapport au protocole FC. La solution connectée NVMe/FC a atteint plus de 700 000 IOPS avant de dépasser le seuil du cycle d'écriture de 45 secondes. Le remplacement des commandes SCSI par NVMe permet également de réduire considérablement l'utilisation sur l'hôte.</block>
  <block id="0b336e7e203efd55d17ecfaa03c134f5" category="inline-image-macro">Graphique EPIC Genio</block>
  <block id="293e47073bb00e514b986ef28fbbb2e1" category="paragraph"><block ref="293e47073bb00e514b986ef28fbbb2e1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9ff8735576a58daba5ba20974f92a584" category="summary">Epic sur l'évolutivité ONTAP</block>
  <block id="1027782bab261904e6adf43f2b137951" category="paragraph">Le Guide de configuration du matériel Epic représente environ 20 % de croissance annuelle pendant 3 ans. Cependant, les environnements peuvent également se développer de manière inattendue.</block>
  <block id="39e52e339ff39b5620d48036812e09ec" category="paragraph">NetApp peut facilement faire évoluer les performances et la capacité jusqu'à 12 nœuds pour les clusters NAS, SAN et objet. Par conséquent, vous pouvez évoluer horizontalement et verticalement sans interruption pour accompagner la croissance de votre entreprise.</block>
  <block id="49c5cdfe08202e574deefaa3d26c332a" category="inline-link-macro">Epic sur l'architecture vérifiée NetApp sur le SAN moderne</block>
  <block id="12cb4beeba752f647712c749e3076fbf" category="paragraph">EPIC Iris offre des capacités d'évolutivité supplémentaires. Il permet aux clients de plus grande taille disposant de plusieurs instances Epic de procéder à la consolidation vers une seule instance. <block ref="5d13d58e489e8fe43bb727515c1d9ff2" category="inline-link-macro-rx"></block>Ce document démontre qu'Epic peut faire évoluer de manière fluide les charges de travail consolidées à 720 000 IOPS sur une seule haute disponibilité et évoluer en mode scale-out jusqu'à plus de 4 millions d'IOPS dans un cluster. Vous pouvez évoluer en mode « scale-up » sans interrompre l'activité en mettant à niveau les contrôleurs ou en ajoutant des disques aux clusters existants.</block>
  <block id="196097993185ddccf60443ac3f86e89f" category="paragraph">Les données NAS, SAN et objet peuvent également être déplacées sans interruption entre les nœuds du cluster. Chaque paire haute disponibilité dans le cluster peut correspondre à n'importe quelle combinaison de types et de tailles de systèmes ONTAP FAS et AFF. Vous pouvez équilibrer vos charges de travail sur un seul cluster afin d'optimiser votre investissement en stockage.</block>
  <block id="6abd4957b4615c500bd2a32425316211" category="paragraph">ONTAP permet également d'utiliser le stockage objet sur StorageGRID ou le cloud comme cible de sauvegarde et/ou cible de Tiering automatique du stockage à froid. Ainsi, vous pouvez libérer automatiquement des disques 100 % Flash coûteux, des snapshots de Tiering et des données inactives dans un environnement objet.</block>
  <block id="8d3f76f475a5e81f188f700429c71a9e" category="paragraph">Le résultat : Epic fonctionne simplement mieux avec le portefeuille de produits NetApp, exploitant ONTAP, plusieurs protocoles, StorageGRID et le cloud de votre choix. Ces produits proposent des options de reprise après incident, d'archivage, d'analytique, de Tiering, etc.</block>
  <block id="1e3ccee88df9552e4751ba4ad173de96" category="summary">Epic sur la sécurité ONTAP</block>
  <block id="32e1bf49ff775c9283c882fe7f3ec873" category="paragraph">La sécurité est aujourd'hui la principale préoccupation des entreprises et des cadres de la santé. Sa gestion n'a jamais été aussi difficile et les entreprises sont confrontées à des défis tels que la conformité, la gouvernance des données, la protection antivirus et les ransomwares.</block>
  <block id="0d6ce08690a300cb8ce00d77e1c31a5e" category="inline-link-macro">Guide sur le renforcement de la sécurité de la solution ONTAP</block>
  <block id="40e97866feb53c48881b34e5f97ca61f" category="paragraph">Le présent document ne contient pas de guide complet sur Epic et la sécurité du stockage. Il détaille toutefois <block ref="471b0f2cfbad0f2ec4e54df06500d580" category="inline-link-macro-rx"></block>toutes les fonctionnalités de sécurité avancées et étendues disponibles avec ONTAP.</block>
  <block id="1408f921f799efe0e585aeba5fa9ed58" category="inline-link-macro">TR-4569</block>
  <block id="f87d3f3c7c3e6e9ab1153c53d78b40b1" category="paragraph">NetApp Active IQ Unified Manager surveille les violations de sécurité en fonction des informations incluses dans  et les signale dans le <block ref="1b2ca6a48e0bf52cc6351680c5ee6170" category="inline-link-macro-rx"></block>tableau de bord afin de simplifier la gestion de la sécurité. Ces outils peuvent aider votre entreprise à atteindre ses objectifs de sécurité en matière de protection, de détection et de résolution des attaques.</block>
  <block id="a1fbc1f9fe3c77416c96f491ba933c4a" category="inline-link-macro">NetApp FPolicy</block>
  <block id="96f76ddccc0adcaf0fc9a2fc6c834374" category="inline-link-macro">Authentification multifacteur (MFA)</block>
  <block id="a754af2f708573321f76c2d36bea9f02" category="paragraph">NetApp a également établi des partenariats avec des fournisseurs de solutions de sécurité pour permettre une intégration par le biais de <block ref="48fae993b7aeb9944f39dadc4618e2b6" category="inline-link-macro-rx"></block> logiciels permettant d'améliorer vos offres de sécurité. En outre, <block ref="b5ae90d3a2df9b77f2db834fe0dc7b7d" category="inline-link-macro-rx"></block> ils peuvent être ajoutés pour sécuriser votre environnement Epic contre tout accès non autorisé avec des informations d'identification qui ont fui.</block>
  <block id="91d998bab304adb0fd27858a4295dcac" category="inline-link-macro">Cyber-coffre ONTAP</block>
  <block id="e9c1c7d4ca860adb553d87c2c1d9ef35" category="inline-link-macro">Solution NetApp pour ransomware</block>
  <block id="63ab8aaa1f35361bdf5c84b3d1dd4765" category="inline-link-macro">NetApp et le modèle « zéro confiance »</block>
  <block id="a67fe844bc4d3e5cf5ebac11dea00b01" category="paragraph">Enfin, les copies Snapshot natives ONTAP et les technologies SnapLock immuables avec <block ref="79305a8b61b53acc892506e6bcd6f49f" category="inline-link-macro-rx"></block>, offrent une fonctionnalité d'air Gap unique pour protéger vos dossiers médicaux contre les ransomwares. Voir la documentation NetApp sur <block ref="910d0617bba4ff1a9d41b4b330096d85" category="inline-link-macro-rx"></block>. Pour une approche plus stratégique de la sécurité, voir <block ref="aaf21a490837c9b392e59c6c9110165d" category="inline-link-macro-rx"></block>.</block>
  <block id="28caba838e7a7ff7ff218bae8235208a" category="summary">Snapshots Epic et clonage</block>
  <block id="8ad0c394ef79d2b18983fabe84f658fc" category="paragraph">Un snapshot est une copie instantanée d'un volume en lecture seule.</block>
  <block id="568043eed0b44992a4b4a1cc21f8b633" category="paragraph">Un snapshot place un verrou logique sur tous les blocs du système de fichiers actif. Les copies Snapshot NetApp ONTAP sont quasi instantanées et n'utilisent aucun stockage supplémentaire.</block>
  <block id="04a00b93a2db41946dc3d263cf6c294c" category="paragraph">Write anwhere File Layout, ou WAFL, est un système de fichiers en écriture seule ; il n'effectue pas d'E/S supplémentaires, telles que la copie des données dans un bloc protégé par copie Snapshot avant d'être écrasé. Aucune donnée n'est jamais déplacée. Par conséquent, les copies Snapshot n'ont aucun impact sur la capacité de stockage ou les performances. Les copies Snapshot permettent de réaliser des économies de stockage considérables tout en augmentant la solution de sauvegarde.</block>
  <block id="a701f5d044348085ee4f97fef6636845" category="section-title">FlexClone</block>
  <block id="16f57611d3d44b74ce1c1b134cb8e798" category="paragraph">Un volume NetApp ONTAP FlexClone est un clone d'un volume existant ou un snapshot d'un volume existant. Il s'agit autrement d'un volume ONTAP comme tout autre, et il peut lui-même être cloné, protégé par des copies Snapshot et configuré avec une règle de qualité de service.</block>
  <block id="e0c3236990160654182a79c89baab29f" category="paragraph">Comme pour les snapshots, un volume FlexClone ne nécessite aucun espace supplémentaire au moment de sa création. Seules les modifications apportées au clone nécessitent une capacité supplémentaire.</block>
  <block id="9a9ff90c24c36543bf54b1f2136fd9e0" category="paragraph">Epic requiert entre 10 et 30 copies des bases de données de production pour répondre à divers besoins opérationnels, tels que les sauvegardes en continu, les vérifications d'intégrité et les environnements de mise à niveau intermédiaire. La nécessité d'une solution basée sur les volumes FlexClone s'est accrue avec le passage à des mises à niveau plus fréquentes.</block>
  <block id="dad816f366caa0b8cae67daaeb85deb0" category="admonition">Une solution de sauvegarde Epic entièrement automatisée et une solution d'actualisation Epic sont fournies par NetApp dans le cadre de la solution à l'aide d'Ansible et des outils NetApp natifs.</block>
  <block id="53f102b306ab1aba43e9e20701dc32f2" category="doc">Epic sur ONTAP</block>
  <block id="3bfc8ddd725eed5b674d1a480bc650d2" category="paragraph">La clé de la transformation digitale consiste à en faire plus avec vos données.</block>
  <block id="2b82426bc0bfa4ea3efb779d165629a4" category="admonition">Cette documentation remplace le rapport technique _TR-3923 : meilleures pratiques de NetApp pour Epic_.</block>
  <block id="fdf0f3f3a2bae0d66ca5ecb45e1f3d85" category="paragraph">Les hôpitaux exigent d'importants volumes de données pour amorcer la transformation digitale. Une partie du processus de traitement des patients, de gestion des horaires du personnel et des ressources médicales consiste à recueillir et à traiter les informations. Cependant, de nombreuses actions sont toujours exécutées manuellement ou via des systèmes obsolètes. La seule constante est que la quantité de données continue à croître de manière exponentielle et donc, devient de plus en plus difficile à gérer.</block>
  <block id="74090662bfdb94e49dfc286a6946cc5c" category="paragraph">La principale cause de ce problème est que les données hospitalières sont souvent stockées dans des silos de données. Trop de temps est consacré aux entrées et mises à jour manuelles, ce qui entraîne des pannes et des erreurs. Ce document s'applique à environ une partie des données de santé, soit le dossier médical électronique (DME) Epic. Cependant, la stratégie de gestion des données couverte ici peut et doit être appliquée à toutes les données de santé. Depuis longtemps déjà, NetApp modernise et simplifie l'infrastructure digitale. Notre infrastructure de données intelligente est à la base de la transformation digitale.</block>
  <block id="b68a1112138fe0c0c1beafc2aea18949" category="paragraph">NetApp propose une solution unique de gestion des données pour tous les besoins de santé. Nous pouvons guider les hôpitaux tout au long de leur transition vers la transformation digitale. En construisant une base avec une structure et des solutions intelligentes, les soins de santé peuvent extraire toute la valeur de ces précieuses informations. Ce cadre peut aider les médecins à diagnostiquer les maladies plus rapidement et à élaborer des plans de traitement individualisés pour mieux soutenir les processus de prise de décision dans les situations d'urgence. Vous pourrez également créer votre propre infrastructure de données intelligente et permettre à votre hôpital d'exploiter les silos de données, de faciliter l'interopérabilité des données et de protéger les informations confidentielles des patients.</block>
  <block id="6b5a360f7d15046cfd935db963e3da66" category="paragraph">Ce document vous aidera à construire et à mettre en œuvre avec succès des DME EPIC. Plutôt que de créer plusieurs silos Epic, créez une infrastructure de données Epic unique et transformez votre hôpital.</block>
  <block id="261addf78c7b2c961032b3dd08ba0b1f" category="section-title">Objectif</block>
  <block id="b8954f46b76dae4370058c7bd9ae0c97" category="paragraph">Ce document présente les bonnes pratiques d'intégration du stockage NetApp dans un environnement logiciel Epic. Il contient les sections suivantes :</block>
  <block id="6c5022fa1197168f37c42e56f80d36aa" category="list-text">Connaissance technique de l'environnement logiciel Epic et de ses besoins en stockage dans différentes configurations.</block>
  <block id="a9da176a5abe5a618e8ed6a88bdbf21b" category="list-text">Considérations relatives au stockage Epic et description des facteurs importants de prise de décision pour les solutions Epic.</block>
  <block id="8b3f0902644adbb7e0435ae9c9a284e2" category="list-text">Recommandations sur le stockage NetApp, décrivant les bonnes pratiques de configuration du stockage NetApp et permettant de répondre aux besoins de stockage d'Epic.</block>
  <block id="5d113f2038d289f391614c39043629e8" category="section-title">Portée</block>
  <block id="217eb7cf1ad7503a42f61ad3cffb47fb" category="paragraph">Ce document ne couvre pas les sujets suivants :</block>
  <block id="f900b8ede5ddf3a0471176dab052001d" category="list-text">Exigences quantitatives en matière de performances et conseils de dimensionnement, qui sont abordés dans le<block ref="81c36a9e6d224e9d42c9630dffaa9434" category="inline-link-rx"></block> (connexion NetApp requise)</block>
  <block id="ef1e6887c579ba81dcedc3f4e3793cd2" category="section-title">Public</block>
  <block id="2f215f5ba67ae7978ce4846a4a1cdc08" category="paragraph">NetApp suppose que le lecteur possède les connaissances de base suivantes :</block>
  <block id="6cfde17644914efa6d0a4d0c21a8f9db" category="list-text">Une solide compréhension des concepts SAN et NAS</block>
  <block id="c86456e4299d4b0ad43e030d0fdd0af5" category="list-text">Connaissance technique des systèmes de stockage ONTAP</block>
  <block id="59eba43c04b655e21f087af920398a2a" category="list-text">Connaissance technique de la configuration et de l'administration de ONTAP</block>
  <block id="b7c45da218d2e29ec939a31cdd81f2be" category="paragraph">Un contrôleur de stockage NetApp exécutant ONTAP peut prendre en charge les charges de travail suivantes dans un environnement Windows Server :</block>
  <block id="ba0a81fc95587bfae3e0ac0bf44e562a" category="paragraph">Le kit NetApp PowerShell (PSTK) est un module PowerShell qui offre une automatisation de bout en bout et permet d'administrer le stockage ONTAP. Le module ONTAP contient plus de 2,000 cmdlets et aide à l'administration de FAS, NetApp de AFF (FAS 100 % Flash), de matériel générique et de ressources cloud.</block>
  <block id="f43e8d35e63b48bc73d5dc074df829ae" category="paragraph">Microsoft ODX, également appelé allègement de la charge des copies, permet des transferts directs de données au sein d'un dispositif de stockage ou entre des dispositifs de stockage compatibles sans transférer les données via l'ordinateur hôte. ONTAP prend en charge la fonction ODX pour les protocoles CIFS et SAN. ODX peut améliorer les performances si les copies se trouvent dans le même volume, réduire l'utilisation du processeur et de la mémoire sur le client et réduire l'utilisation de la bande passante des E/S réseau.</block>
  <block id="e033e4d03ff089011c11d7d2fa80d475" category="paragraph">Les serveurs en cluster Hyper-V (appelés nœuds) sont connectés par le réseau physique et par un logiciel de cluster. Ces nœuds utilisent un stockage partagé pour stocker les fichiers de la machine virtuelle, notamment les fichiers de configuration, les fichiers des disques durs virtuels (VHD) et les copies Snapshot. Le stockage partagé peut être un partage SMB/CIFS NetApp ou un fichier CSV sur un LUN NetApp, comme illustré ci-dessous. Ce stockage partagé fournit un namespace cohérent et distribué auquel tous les nœuds du cluster peuvent accéder simultanément. Par conséquent, si un nœud tombe en panne dans le cluster, l'autre nœud assure le service par un processus appelé basculement. Les clusters de basculement peuvent être gérés à l'aide du composant logiciel enfichable Failover Cluster Manager et des applets de commande de mise en cluster de basculement Windows PowerShell.</block>
  <block id="72960f8df48c0debc035454921c1b5d3" category="list-text">Dans la migration dynamique partagée, la machine virtuelle est stockée sur un partage SMB. Par conséquent, lorsque vous migrez une machine virtuelle en direct, le stockage de la machine virtuelle reste sur le partage SMB central pour un accès instantané par l'autre nœud, comme illustré ci-dessous.</block>
  <block id="5a002cf26db634ca1b1fff75461d2427" category="list-title">ONTAP s'exécute sur les contrôleurs de stockage NetApp. Il est disponible dans plusieurs formats.</block>
  <block id="6011d6a859985e0b6d7c13b0907896ca" category="paragraph">ONTAP fournit un stockage hautement disponible dans lequel plusieurs chemins d'accès peuvent exister entre le contrôleur de stockage et le serveur Windows. Les chemins d'accès multiples correspondent à la capacité d'avoir plusieurs chemins de données entre un serveur et une baie de stockage. Les chemins d'accès multiples protègent contre les pannes matérielles (coupures de câbles, défaillance du switch et de l'adaptateur de bus hôte [HBA], etc.). Ils peuvent également offrir des limites de performances plus élevées en utilisant les performances d'agrégat de plusieurs connexions. Lorsqu'un chemin ou une connexion devient indisponible, le logiciel de chemins d'accès multiples déplace automatiquement la charge vers l'un des autres chemins disponibles. La fonctionnalité MPIO combine les chemins physiques multiples vers le stockage comme un chemin logique unique utilisé pour l'accès aux données, afin d'assurer la résilience du stockage et l'équilibrage de la charge. Pour utiliser cette fonctionnalité, la fonctionnalité MPIO doit être activée sur Windows Server.</block>
  <block id="8bbfb9edfb90853f3f9439d77ce59441" category="list-text">Commandes CLI sur ONTAP</block>
  <block id="e72f4a4f5fcfab964176e743af1f3196" category="paragraph">Le protocole NAS CIFS est intégré en mode natif à ONTAP. Par conséquent, Windows Server n'a pas besoin d'un logiciel client supplémentaire pour accéder aux données sur ONTAP. Un contrôleur de stockage NetApp apparaît sur le réseau en tant que serveur de fichiers natif et prend en charge l'authentification Microsoft Active Directory.</block>
  <block id="ab2d1dd1b024fd7be648c22c4a43997b" category="list-text">Certaines tâches de gestion CIFS peuvent être effectuées à l'aide de la console MMC (Microsoft Management Console). Avant d'effectuer ces tâches, vous devez connecter la console MMC au stockage ONTAP à l'aide des commandes de menu MMC.</block>
  <block id="1d5ba6202d85466a95188b58c37dccc8" category="list-text">NetApp recommande de connecter les hôtes Hyper-V et le stockage ONTAP à un réseau de 10 Go, le cas échéant. Dans le cas d'une connectivité réseau de 1 Go, NetApp recommande de créer un groupe d'interfaces composé de plusieurs ports de 1 Go.</block>
  <block id="79d467fa842b9015f2f12ada4fa1c7fc" category="paragraph">Les performances de SQL Server dépendent de plusieurs unités centrales et de la configuration principale.</block>
  <block id="4403546c5938500562a9d8677deb1c38" category="section-title">Cœurs et gestion des licences</block>
  <block id="c325fde2d51a1ea2ddd8c9dd51cfdf9c" category="paragraph">L'image ci-dessous montre le message du journal SQL Server après le démarrage indiquant l'application de la limite de noyau.</block>
  <block id="e59dc8056170cddb696ba9bff812c325" category="paragraph">SQL Server utilise tous les processeurs disponibles dans le système d'exploitation (si la licence par processeur est choisie). Il crée également des planificateurs f0r chaque CPU pour optimiser l'utilisation des ressources pour une charge de travail donnée. En mode multitâche, le système d'exploitation ou d'autres applications du serveur peuvent basculer les threads de traitement d'un processeur à un autre. SQL Server est une application qui consomme beaucoup de ressources et les performances peuvent en être affectées. Pour minimiser l'impact, vous pouvez configurer les processeurs de sorte que toute la charge SQL Server soit dirigée vers un groupe de processeurs présélectionné. Pour ce faire, utilisez le masque d'affinité du processeur.</block>
  <block id="e40a45aed8142e74026f5aa7a6ee1122" category="paragraph">L'option de masque d'E/S d'affinité lie les E/S de disque SQL Server à un sous-ensemble de processeurs. Dans les environnements OLTP SQL Server, cette extension peut considérablement améliorer les performances des threads SQL Server exécutant des opérations d'E/S.</block>
  <block id="16dce493fdad96fe48148f47dc552bfb" category="admonition">*NetApp recommande* pour DSS comme les data warehouses, commencez par<block ref="1abedc5f6ab369ab9fcd16d6b7990638" prefix=" " category="inline-code"></block> 50 et explorez le réglage vers le haut ou vers le bas si nécessaire. Assurez-vous de mesurer les requêtes critiques dans votre application lorsque vous effectuez des modifications.</block>
  <block id="0add8d6e7be42a854cd7e0161c7f9bcc" category="paragraph">Normalement, un thread de système d'exploitation distinct est créé pour chaque requête. Si des centaines de connexions simultanées sont effectuées sur SQL Server, la configuration à un thread par requête peut consommer un excès de ressources système. Cette<block ref="a9233738c364090bbc418d8a0e08a79e" prefix=" " category="inline-code"></block> option permet d'améliorer les performances en permettant à SQL Server de créer un pool de threads de travail pouvant traiter collectivement un plus grand nombre de requêtes.</block>
  <block id="29daf9697a41a463dbe76855a2053a87" category="paragraph">L'exemple suivant montre comment configurer l'option max Work threads à l'aide de T-SQL.</block>
  <block id="7039e99a0fdcc0d3ef80074ed42bf4e4" category="paragraph">Les stratégies de sauvegarde des bases de données doivent être basées sur des exigences métier identifiées, et non sur des capacités théoriques. En combinant la technologie Snapshot de ONTAP et en exploitant les API de Microsoft SQL Server, vous pouvez effectuer rapidement des sauvegardes cohérentes au niveau des applications, quelle que soit la taille des bases de données utilisateur. Pour une gestion des données plus avancée ou scale-out, NetApp propose SnapCenter.</block>
  <block id="4cd6720df070a1784bae9c6f525f483d" category="admonition">*NetApp recommande* d'utiliser SnapCenter pour créer des copies Snapshot. La méthode T-SQL décrite ci-dessous fonctionne également, mais SnapCenter offre une automatisation complète du processus de sauvegarde, de restauration et de clonage. Il effectue également une découverte pour s'assurer que les snapshots corrects sont créés. Aucune préconfiguration n'est requise.</block>
  <block id="97e73fdb42ddecb63ed519a484ff3c9b" category="paragraph">SQL Server nécessite également une coordination entre le système d'exploitation et le stockage pour s'assurer que les données correctes sont présentes dans les snapshots au moment de la création. Dans la plupart des cas, la seule méthode sûre pour ce faire est SnapCenter ou T-SQL. Les snapshots créés sans cette coordination supplémentaire peuvent ne pas être récupérables de manière fiable.</block>
  <block id="9d831cc4c73b8a2915ce6d8928d55915" category="paragraph">La fonction de réplication de groupe de disponibilité en continu de SQL Server peut constituer une excellente option, et NetApp offre des options pour intégrer la protection des données à la disponibilité continue. Toutefois, dans certains cas, il peut être intéressant d'opter pour la technologie de réplication ONTAP. Il existe trois options de base.</block>
  <block id="dd432f8769e4d3db8acf8bf9df94680a" category="paragraph">La technologie SnapMirror offre une solution d'entreprise rapide et flexible pour la réplication de données sur des réseaux LAN et WAN. La technologie SnapMirror transfère uniquement les blocs de données modifiés vers la destination après la création du miroir initial, ce qui réduit considérablement les besoins en bande passante réseau. Il peut être configuré en mode synchrone ou asynchrone.</block>
  <block id="fce5f84d02dbd5c9e3cfedf18e809644" category="summary">Microsoft SQL Server et NetApp MetroCluster</block>
  <block id="41900c1c2eb669e401e4abee9091b40b" category="paragraph">Le déploiement de Microsoft SQL Server avec un environnement MetroCluster nécessite une explication de la conception physique d'un système MetroCluster.</block>
  <block id="60359402d81f6673550c3df489efb034" category="paragraph">MetroCluster met en miroir les données et la configuration de manière synchrone entre deux clusters ONTAP dans des emplacements distincts ou dans des domaines à défaillance. MetroCluster fournit aux applications du stockage disponible en continu en gérant automatiquement deux objectifs :</block>
  <block id="abf0aedf685f58c3cf3abe3e41ca549c" category="list-text">Objectif de point de restauration (RPO) nul via une mise en miroir synchrone des données écrites sur le cluster.</block>
  <block id="1194ac032fc54dbcf779ac23fbc73dd5" category="list-text">Objectif de délai de restauration (RTO) proche de zéro grâce à la mise en miroir de la configuration et à l'automatisation de l'accès aux données sur le second site.</block>
  <block id="9aa45379205d52916f2958359e92c1c8" category="paragraph">MetroCluster simplifie la mise en miroir automatique des données et la configuration entre les deux clusters indépendants situés dans les deux sites. Le stockage étant provisionné dans un cluster, il est automatiquement mis en miroir sur le second cluster sur le second site. NetApp SyncMirror® fournit une copie complète de toutes les données avec un RPO nul. Cela signifie que les charges de travail d'un site peuvent basculer à tout moment sur le site opposé et continuer à transférer des données sans perte de données. MetroCluster gère le processus de basculement pour l'accès aux données provisionnées NAS et SAN sur le second site. La conception de la solution validée MetroCluster inclut le dimensionnement et la configuration qui permettent d'effectuer un basculement dans les délais impartis (en général moins de 120 secondes). Il en résulte un RPO proche de zéro et les applications peuvent continuer à accéder aux données sans produire de défaillances.MetroCluster est disponible selon plusieurs variations définies par le fabric de stockage interne.</block>
  <block id="47985b72c36de8197de21d06517f1a03" category="paragraph">La protection pour SQL Server avec MetroCluster repose sur SyncMirror, qui offre une technologie de mise en miroir synchrone à évolutivité horizontale et aux performances maximales.</block>
  <block id="96a36329b3e96b1619b1d635a806bb3f" category="summary">Microsoft SQL Server avec NetApp MetroCluster</block>
  <block id="9fcf1f7a4c16b536048dc5875b61d4b1" category="paragraph">MetroCluster est une option de protection des bases de données SQL Server avec un RPO nul. MetroCluster est une technologie de réplication simple, haute performance avec un objectif de point de récupération de 0, qui vous permet de répliquer facilement toute une infrastructure sur plusieurs sites.</block>
  <block id="8a7f9ca86b522c62318d9b1eb5b51625" category="paragraph">SQL Server peut évoluer jusqu'à des milliers de bases de données sur un seul système MetroCluster. Il peut y avoir des instances autonomes SQL Server ou des instances de cluster de basculement ; le système MetroCluster n'ajoute pas nécessairement ou ne modifie pas les meilleures pratiques de gestion d'une base de données.</block>
  <block id="43135677cc98d0d6872d9ec24bef82e4" category="paragraph">Une explication complète de MetroCluster dépasse le champ d'application de ce document, mais les principes sont simples. MetroCluster peut fournir une solution de réplication RPO=0 avec basculement rapide. La base que vous exploitez dépend de vos besoins.</block>
  <block id="046797023ebbfe8b6dd24d4fc7cab0be" category="paragraph">Par exemple, une procédure de reprise sur incident rapide de base après une perte soudaine du site peut utiliser les étapes de base suivantes :</block>
  <block id="f8b79e7c0c5914411ccfda1cbaa25414" category="list-text">Force le basculement MetroCluster</block>
  <block id="740d5da1ae0060ef63f290d3aed64929" category="list-text">Découverte de LUN FC/iSCSI (SAN uniquement)</block>
  <block id="89c617c4ed9cac275e572a67b1c52b29" category="list-text">Montez les systèmes de fichiers</block>
  <block id="f08329445e69fa49a8223bf365f09e47" category="list-text">Démarrez SQL Services</block>
  <block id="b7aabeea5e06b7371d4372fd7f698f88" category="paragraph">Cette approche doit avant tout se passer d'un système d'exploitation en cours d'exécution sur le site distant. Il doit être préconfiguré avec la configuration de SQL Server et doit être mis à jour avec une version de build équivalente. Les bases de données système SQL Server peuvent également être mises en miroir sur le site distant et montées en cas d'incident.</block>
  <block id="2b963bb5f627aa0ffda026b4d97b6474" category="summary">Scénarios de basculement de Microsoft SQL Server et SM-as</block>
  <block id="b0bb805a1ea68ad43ceacf65954b4b4b" category="paragraph">La planification d'une architecture complète d'applications de synchronisation active SnapMirror nécessite de comprendre comment les SM-AS répondront dans divers scénarios de basculement planifiés et non planifiés.</block>
  <block id="511d40fa1b50f901027391480dff9c67" category="paragraph">Le médiateur est requis pour automatiser le basculement en toute sécurité. Dans l'idéal, elle serait placée sur un site tiers indépendant, mais elle peut toujours fonctionner pour la plupart des besoins si elle est en colocation avec l'un des clusters participant à la réplication.</block>
  <block id="cef962a099d3ff2b834420d0c97f5bc1" category="summary">Microsoft SQL Server et SM-AS accès non uniforme</block>
  <block id="3ef2650b3e4d89df6ea0248f432e6c2c" category="paragraph">La mise en réseau à accès non uniforme signifie que chaque hôte n'a accès qu'aux ports du système de stockage local. Le SAN n'est pas étendu sur les sites (ou les domaines de défaillance au sein du même site).</block>
  <block id="7c58b14cf1e27ff24a5b6a0656848380" category="summary">Synchronisation active de Microsoft SQL Server et SnapMirror</block>
  <block id="64affc06244780af1f97a68438460989" category="paragraph">La synchronisation active SnapMirror permet à chaque base de données et application SQL Server de continuer les opérations pendant les interruptions du stockage et du réseau, grâce à un basculement transparent du stockage, sans intervention manuelle.</block>
  <block id="0a19f1ca74616d0d4972b2c02c3f7fee" category="paragraph">À partir de ONTAP 9.15.1, la synchronisation active SnapMirror prend en charge l'architecture active/active symétrique en plus de la configuration asymétrique existante. La fonctionnalité actif-actif symétrique offre une réplication bidirectionnelle synchrone pour la continuité de l'activité et la reprise après incident. Il vous aide à protéger l'accès aux données pour les workloads SAN stratégiques avec un accès simultané en lecture et en écriture aux données dans plusieurs domaines à défaillance. Vous bénéficiez ainsi d'une continuité de l'activité et d'une réduction des temps d'indisponibilité en cas d'incident ou de panne système.</block>
  <block id="d17dae030927ab027095c1e44df8fbf1" category="paragraph">Les hôtes SQL Server accèdent au stockage via des LUN Fibre Channel (FC) ou iSCSI. Réplication entre chaque cluster hébergeant une copie des données répliquées. Étant donné que cette fonctionnalité est une réplication au niveau du stockage, les instances SQL Server exécutées sur des instances d'hôte autonome ou de cluster de basculement peuvent effectuer des opérations de lecture/écriture sur l'un ou l'autre des clusters. Pour les étapes de planification et de configuration, reportez-vous à  la section <block ref="44f5d8051247437425911d96f84db248" category="inline-link-macro-rx"></block> .</block>
  <block id="b2f689709f901a51858096aaf9637eb4" category="paragraph">**Réplication synchrone**</block>
  <block id="71ed2e619a97a27f6fe533714a412725" category="paragraph">En fonctionnement normal, chaque copie correspond à une réplique synchrone RPO=0 à tout moment, à une exception près. Si les données ne peuvent pas être répliquées, ONTAP exige de répliquer les données et de reprendre le traitement des E/S sur un site pendant que les LUN de l'autre site sont mises hors ligne.</block>
  <block id="331b5c7e8c01ec1e37b60de5a5efba6c" category="paragraph">**Matériel de stockage**</block>
  <block id="588068838f06fe39dec548e2210ddf2f" category="paragraph">Le médiateur ONTAP est une application logicielle téléchargée depuis la prise en charge de NetApp et généralement déployée sur une petite machine virtuelle. Le médiateur ONTAP n'est pas un tiebreaker. Il s'agit d'un canal de communication alternatif pour les deux clusters qui participent à la réplication SnapMirror active Sync. Les opérations automatisées sont dirigées par ONTAP sur la base des réponses reçues du partenaire via des relations directes et via le médiateur.</block>
  <block id="6fda40460e9cbbefd704b9c01ea2c18c" category="summary">Microsoft SQL Server et SM-en tant que site privilégié</block>
  <block id="ac420a2d1b21182a80148191683bc9f7" category="paragraph">Le comportement de la synchronisation active SnapMirror est symétrique, avec une exception importante : la configuration du site préféré.</block>
  <block id="3ccf31c781c6df95109107d66199a8f6" category="section-title">Instance autonome de SQL Server</block>
  <block id="bd53ef250bf6f7a012cc7ed01c62f8cd" category="inline-link-macro">SQL Server sur ONTAP</block>
  <block id="d0d5aa4f66a3624a91ad4b11bbc2250f" category="paragraph">Les meilleures pratiques en matière de mise en page des fichiers et de configuration des serveurs sont les mêmes que celles recommandées dans <block ref="c89905de54b32eb552c83786b7590df9" category="inline-link-macro-rx"></block> la documentation.</block>
  <block id="a489ffed938ef1b9e86889bc413501ee" category="inline-link-macro">uniforme</block>
  <block id="ee289d07b4c3d14dcc9cc162df065f99" category="paragraph">Avec une configuration autonome, SQL Server ne peut être exécuté que sur un site. L'accès serait probablement <block ref="b88135502d93a28469d0c520f73e7e7d" category="inline-link-macro-rx"></block>utilisé.</block>
  <block id="50c137c2af8db8930fd9881b4ece5d99" category="inline-image-macro">Un hôte unique avec accès uniforme</block>
  <block id="327efeeabe7ad30552ef39a61284b93b" category="paragraph">Avec un accès uniforme, une panne de stockage sur l'un ou l'autre site n'interromprait pas les opérations de la base de données. Une défaillance complète du site incluant le serveur de base de données entraînerait, bien sûr, une panne.</block>
  <block id="5bc465d840f8a329d264340f938ab253" category="paragraph">Certains clients peuvent configurer un système d'exploitation s'exécutant sur le site distant avec une configuration SQL Server préconfigurée, mise à jour avec une version de build équivalente à celle de l'instance de production. Le basculement nécessite l'activation de cette instance autonome de SQL Server sur le site secondaire, la découverte des LUN et le démarrage de la base de données. Le processus complet peut être automatisé avec l'applet de commande Windows PowerShell, car aucune opération n'est requise côté stockage.</block>
  <block id="ea7bbefe18f9ad7af62904dd6da19c33" category="inline-link-macro">Non uniforme</block>
  <block id="b53a3ef75c6e33a4f8945589cbe8beee" category="paragraph"><block ref="56d4a3cb11d7ad2b0e560d2cc8afde2c" category="inline-link-macro-rx"></block> l'accès peut également être utilisé, mais il en résulte une panne de la base de données si le système de stockage sur lequel était situé le serveur de base de données avait échoué car la base de données ne disposait pas de chemins d'accès au stockage. Cela peut toujours être acceptable dans certains cas. La synchronisation active SnapMirror offre toujours une protection des données avec un objectif de point de récupération de 0. En cas de défaillance du site, la copie restante est active et prête à reprendre les opérations en suivant la même procédure utilisée avec un accès uniforme que celle décrite ci-dessus.</block>
  <block id="a2e30e760061ab42fd5030c552306712" category="paragraph">Un processus de basculement simple et automatisé peut être configuré plus facilement grâce à l'utilisation d'un hôte virtualisé. Par exemple, si les fichiers de données SQL Server sont répliqués de manière synchrone sur le stockage secondaire avec un VMDK de démarrage, l'environnement complet peut être activé sur l'autre site en cas d'incident. Un administrateur peut activer manuellement l'hôte sur le site survivant ou automatiser le processus via un service tel que VMware HA.</block>
  <block id="f04055c72ba32a95b9830308e4508cb1" category="section-title">Instance de cluster de basculement SQL Server</block>
  <block id="21fd4631916f5c0e63ef67f98d413d6a" category="paragraph">Les instances de basculement SQL Server peuvent également être hébergées sur un cluster de basculement Windows s'exécutant sur un serveur physique ou virtuel en tant que système d'exploitation invité. Cette architecture multi-hôtes fournit l'instance SQL Server et la résilience du stockage. Ce déploiement est utile dans les environnements très exigeants qui recherchent des processus de basculement robustes tout en maintenant des performances améliorées. Dans une configuration de cluster de basculement, lorsqu'un hôte ou un stockage primaire est affecté, SQL Services effectue un basculement vers l'hôte secondaire et, dans le même temps, le stockage secondaire est disponible pour transmettre les E/S. Aucun script d'automatisation ni aucune intervention de l'administrateur n'est nécessaire.</block>
  <block id="58daef667c5e83ded89d712a683c532b" category="summary">Microsoft SQL Server et SM-en tant qu'accès uniforme</block>
  <block id="b8c5c455d22a62b43bd58615af0a569e" category="paragraph">Un réseau d'accès uniforme signifie que les hôtes peuvent accéder aux chemins sur les deux sites (ou domaines de défaillance au sein du même site).</block>
  <block id="fdbd6bb11fa9bf15b9e53c8f359e821c" category="list-text">Si SMB est utilisé, le SVM de destination doit être membre du même domaine Active Directory dont le SVM source est membre, de sorte que les listes de contrôle d'accès (ACL) stockées dans les fichiers NAS ne soient pas interrompues pendant la reprise après un incident.</block>
  <block id="d5a7d81e3f495111d65621aede2e26a4" category="list-text">L'utilisation de noms de volume de destination identiques aux noms de volume source n'est pas requise, mais peut faciliter la gestion du processus de montage des volumes de destination dans la destination. Si SMB est utilisé, vous devez rendre l'espace de noms NAS de destination identique dans les chemins et la structure de répertoires vers l'espace de noms source.</block>
  <block id="4dd0779e2b7f46c37eb5ec38cdde3bb6" category="list-text">Utiliser la réplication synchrone où la demande de restauration rapide des données est plus élevée et les solutions asynchrones pour plus de flexibilité dans le RPO.</block>
  <block id="829f5bea960b53b5f1e50e8288a740d4" category="paragraph">La séparation entre le placement d'objets logiques dans les groupes de fichiers et les fichiers de base de données physiques vous permet d'affiner la disposition des fichiers de base de données, en tirant le meilleur parti du sous-système de stockage. Le nombre de fichiers de données prenant en charge une charge de travail donnée peut varier en fonction des besoins pour prendre en charge les exigences d'E/S et la capacité prévue, sans affecter l'application. Ces variations dans la disposition de la base de données sont transparentes pour les développeurs d'applications, qui placent les objets de base de données dans les groupes de fichiers plutôt que dans les fichiers de base de données.</block>
  <block id="df42f2a843e18c9b5f6adccba2ffcbf9" category="paragraph">La tâche effectuer une maintenance de volume est simplifiée dans SQL Server 2016 et est fournie ultérieurement en option pendant le processus d'installation. Cette figure affiche l'option permettant d'accorder au service du moteur de base de données SQL Server le privilège d'effectuer la tâche de maintenance du volume.</block>
  <block id="8c0ea2438ef8ec6eede8f5ae6996c5a0" category="paragraph">Une autre option de base de données importante qui contrôle la taille des fichiers de base de données est la fonction de transmission automatique. Lorsque cette option est activée, SQL Server réduit régulièrement les fichiers de base de données, réduit leur taille et libère de l'espace dans le système d'exploitation. Cette opération consomme beaucoup de ressources et est rarement utile car les fichiers de base de données augmentent à nouveau après l'arrivée de nouvelles données dans le système. La fonction Autohrink ne doit pas être activée sur la base de données.</block>
  <block id="58083df92a650a52d9ea6e4d544ffbd8" category="list-text">Créez le répertoire des journaux hôtes sur un volume dédié sur lequel SnapCenter copie les journaux de transactions.</block>
  <block id="42ad46ab967ef7af8287ca8a5c12f2d1" category="paragraph">La section suivante décrit les paramètres de mémoire SQL Server requis pour optimiser les performances de la base de données.</block>
  <block id="4e6b5a65dde214f8e25b7adbac9c9583" category="paragraph">L'option max. De mémoire du serveur définit la quantité maximale de mémoire que l'instance SQL Server peut utiliser. Il est généralement utilisé si plusieurs applications s'exécutent sur le même serveur que SQL Server et que vous voulez vous assurer que ces applications disposent de suffisamment de mémoire pour fonctionner correctement.</block>
  <block id="fb182faf8ee092092118e8cbb568ae0d" category="paragraph">Certaines applications n'utilisent que la mémoire disponible au démarrage et ne demandent pas de mémoire supplémentaire, même si elles sont sous pression. C'est là que le paramètre de mémoire maximale du serveur entre en jeu.</block>
  <block id="c7af956e7765f16c090e0eab836fb42a" category="paragraph">L'utilisation de SQL Server Management Studio pour ajuster la mémoire minimale ou maximale du serveur nécessite un redémarrage du service SQL Server. Vous pouvez également ajuster la mémoire du serveur à l'aide de Trantransaction SQL (T-SQL) à l'aide du code suivant :</block>
  <block id="0abaf38d5c4f997a2507fe6e57682b0b" category="paragraph">L'accès à la mémoire non uniforme (NUMA) est une technologie d'optimisation de l'accès à la mémoire qui permet d'éviter une charge supplémentaire sur le bus du processeur.</block>
  <block id="87dfe44a851d25873ee6bd0691ac0c6e" category="paragraph">Si NUMA est configuré sur un serveur sur lequel SQL Server est installé, aucune configuration supplémentaire n'est requise car SQL Server est compatible avec NUMA et fonctionne bien sur le matériel NUMA.</block>
  <block id="7cf384150f5c5317f48125af9bf68c31" category="paragraph">L'option index create memory est une autre option avancée qui ne devrait normalement pas avoir besoin d'être modifiée par défaut.</block>
  <block id="64e199b7fb089ffb63f4c4396bac2cd1" category="paragraph">Par défaut, la mémoire min par paramètre de requête alloue &gt;= à 1024 Ko pour chaque requête à exécuter. Il est recommandé de laisser ce paramètre à la valeur par défaut afin de permettre à SQL Server de gérer de façon dynamique la quantité de mémoire allouée aux opérations de création d'index. Cependant, si SQL Server dispose de plus de RAM que nécessaire pour fonctionner efficacement, les performances de certaines requêtes peuvent être améliorées si vous augmentez ce paramètre. Par conséquent, tant que la mémoire est disponible sur le serveur qui n'est pas utilisé par SQL Server, toute autre application ou le système d'exploitation, l'augmentation de ce paramètre peut aider à améliorer les performances globales de SQL Server. Si aucune mémoire disponible n'est disponible, l'augmentation de ce paramètre peut nuire aux performances globales.</block>
  <block id="d4b44030b0eb9280a0e984cd6565e3b3" category="list-text">Le logiciel de sauvegarde SnapCenter comprend les composants suivants :</block>
  <block id="95a3a11e77f5071b2a97b611548b866c" category="paragraph">La portée de cette section sur les meilleures pratiques se limite à la conception technique basée sur les principes et les normes préconisant NetApp pour l'infrastructure de stockage. L'implémentation de bout en bout n'est pas concernée.</block>
  <block id="133dcf168b09b98ab4e6c6f77a743a14" category="paragraph">Pour plus d'informations sur la compatibilité entre les produits NetApp, consultez le <block ref="18e7fcfe606d6d0912191de7fd9eb56a" category="inline-link-macro-rx"></block>.</block>
  <block id="961963c19132b001c6c7289519292be5" category="paragraph">Avant de déployer SQL Server, vous devez comprendre les exigences de charge de travail des applications prises en charge par vos instances de base de données SQL Server. Chaque application a des exigences variables en termes de capacité, de performance et de disponibilité. Par conséquent, chaque base de données doit être conçue de manière à répondre de manière optimale à ces exigences. De nombreuses entreprises classent les bases de données en plusieurs niveaux de gestion, en utilisant les exigences des applications pour définir des contrats de niveau de service. Les charges de travail SQL Server sont souvent classées comme décrit ci-dessous :</block>
  <block id="d748a2050ea9de15020c9f22e1c8a802" category="list-text">OLTP, qui sont souvent les bases de données les plus stratégiques d'une entreprise. Ces bases de données prennent généralement en charge les applications orientées client et sont considérées comme essentielles aux opérations stratégiques de l'entreprise. Les bases de données OLTP stratégiques et les applications qu'elles prennent en charge respectent souvent des SLA qui exigent des performances élevées, qui sont sensibles à la dégradation des performances et qui exigent une disponibilité maximale. Ils peuvent également être candidats pour toujours sur les clusters de basculement ou pour toujours sur les groupes de disponibilité. La combinaison d'E/S sur ces types de bases de données se caractérise généralement par une lecture aléatoire de 75 à 90 % et une écriture de 25 à 10 %.</block>
  <block id="542d0aad1735dc536565c8a1ec4b579f" category="list-text">Bases de données du système d'aide à la décision (DSS), parfois appelées entrepôts de données. Ces bases de données jouent un rôle stratégique pour de nombreuses entreprises qui s'appuient sur l'analytique pour leurs activités. Ces bases de données sont sensibles à l'utilisation du CPU et aux opérations de lecture à partir du disque lors de l'exécution de requêtes. Dans de nombreuses entreprises, les bases de données DSS sont les plus critiques à la fin du mois, du trimestre et de l'année Ce workload présente généralement un mélange d'E/S de lecture de près de 100 %, et le débit d'E/S est souvent plus important que les IOPS.</block>
  <block id="af2a7a153f6f4904cc7384604809cf3c" category="paragraph">SQL Server peut être configuré en tant qu'instance unique par serveur ou en tant que plusieurs instances. La bonne décision dépend généralement de facteurs tels que l'utilisation du serveur pour la production ou le développement, que l'instance soit considérée comme stratégique pour le fonctionnement de l'entreprise et les objectifs de performances.</block>
  <block id="8f66f557400d1222f6352dbc8811ec03" category="paragraph">Les configurations d'instances partagées peuvent être initialement plus faciles à configurer, mais elles peuvent entraîner des problèmes de division ou de verrouillage des ressources, ce qui entraîne des problèmes de performances pour d'autres applications dont les bases de données sont hébergées sur l'instance SQL Server partagée.</block>
  <block id="40d6bdd2be551c4046e5ad632c4dfe71" category="paragraph">L'association des solutions de stockage ONTAP et de Microsoft SQL Server permet de concevoir un stockage de base de données adapté aux besoins des applications les plus exigeantes.</block>
  <block id="9e020f08745f560c049f43a1b5ead190" category="paragraph">Pour optimiser une solution SQL Server sur ONTAP, il est nécessaire de comprendre le modèle et les caractéristiques d'E/S SQL Server. Une infrastructure de stockage bien conçue pour une base de données SQL Server doit répondre aux besoins de performances de SQL Server, tout en assurant une gestion maximale de l'infrastructure dans son ensemble. Une bonne disposition du stockage permet également de réussir le déploiement initial et d'assurer une croissance progressive de l'environnement à mesure que l'entreprise se développe.</block>
  <block id="9eb2f26da39e165d9e3a1c48b5798690" category="paragraph">les volumes sont créés et résident dans des agrégats. Ce terme peut parfois engendrer une confusion, car un volume ONTAP n'est pas une LUN. Un volume ONTAP est un conteneur de gestion de données. Un volume peut contenir des fichiers, des LUN ou même des objets S3. Un volume ne prend pas d'espace, il est uniquement utilisé pour la gestion des données contenues.</block>
  <block id="64999620676d7bc615f88fabe256272f" category="list-text">Si vous installez SQL Server sur un partage SMB, assurez-vous que Unicode est activé sur les volumes SMB pour la création de dossiers.</block>
  <block id="b0874893f6e3e7030833ec488dc9da90" category="list-text">Placez les fichiers de données utilisateur <block ref="937f38432beb92fdba3d47780720bdf7" prefix="(" category="inline-code"></block>) sur des volumes distincts, car il s'agit de charges de travail en lecture/écriture aléatoires. Il est courant de créer des sauvegardes du journal de transactions plus fréquemment que les sauvegardes de bases de données. Pour cette raison, placez les fichiers journaux <block ref="cb15b9539ae0d984ff8740c68b52561c" prefix="(" category="inline-code"></block>de transactions ) sur un volume distinct ou un fichier VMDK à partir des fichiers de données afin que des planifications de sauvegarde indépendantes puissent être créées pour chaque. Cette séparation isole également les E/S d'écriture séquentielle des fichiers journaux des E/S de lecture/écriture aléatoires des fichiers de données et améliore considérablement les performances de SQL Server.</block>
  <block id="f7f1cb17ab4960f1a8e4c28a7fbccb0d" category="list-text">Ne mélangez pas des fichiers de base de données et des fichiers autres que des bases de données, tels que des fichiers de recherche en texte intégral, sur le même LUN.</block>
  <block id="58ccb3e2006ffa82c78944061df94b30" category="paragraph">L'efficacité du stockage ONTAP est optimisée pour stocker et gérer les données SQL Server de manière à utiliser la quantité la plus faible d'espace de stockage sans affecter les performances.</block>
  <block id="f250d23ef016c3e48436a679c5dab1df" category="list-text">N'activez pas la déduplication sur les volumes contenant des fichiers de données SQL Server, sauf si le volume contient plusieurs copies des mêmes données, telles que la restauration de la base de données à partir de sauvegardes sur un seul volume.</block>
  <block id="6f80e9146e2184b9ec3c46b6d7dd903f" category="paragraph">Des conflits de page peuvent se produire sur les pages GAM (Global allocation map), SGAM (Shared global allocation map) ou PFS (page Free Space) lorsque SQL Server doit écrire sur des pages système spéciales pour allouer de nouveaux objets. Les loquets verrouillent ces pages en mémoire. Sur une instance SQL Server occupée, l'obtention d'un verrou sur une page système dans tempdb peut prendre un certain temps. Cela ralentit les temps d'exécution des requêtes et est appelé conflit de type LATCH. Consultez les meilleures pratiques suivantes pour la création de fichiers de données tempdb :</block>
  <block id="255bd5c00b8de4b2f998369f766b2b5e" category="paragraph">Cette section traite de la protection des données à distance, pour laquelle les données sont répliquées vers un site distant à des fins de stockage hors site sécurisé et de reprise sur incident. Notez que ces tableaux ne traitent pas de la protection des données de mise en miroir synchrone. Pour cette exigence, consultez la documentation NetApp MetroCluster, y compris <block ref="06d0604733fc7f7e3f9befaa1239278d" category="inline-link-macro-rx"></block> et <block ref="87f167af2516b222ddeec7405581e8b8" category="inline-link-macro-rx"></block></block>
  <block id="ad8d77efdce72d372a83929b50a127d1" category="paragraph">Une sauvegarde cohérente après panne d'un dataset fait référence à la capture de l'ensemble de la structure du dataset à un point dans le temps. Si le dataset est stocké dans un seul volume, le processus est simple ; il est possible de créer une copie Snapshot à tout moment. Si un dataset s'étend sur plusieurs volumes, un snapshot de groupe de cohérence doit être créé. Plusieurs options sont disponibles pour la création des snapshots de groupe de cohérence, notamment le logiciel NetApp SnapCenter, les fonctionnalités natives de groupe de cohérence ONTAP et les scripts gérés par l'utilisateur.</block>
  <block id="3c27a8d13352bda1e272615270d5faba" category="paragraph">Une sauvegarde cohérente après panne d'une base de données fait référence à la capture à un moment précis de l'ensemble de la structure de la base de données, y compris les fichiers de données, les journaux de reprise et les fichiers de contrôle. Si la base de données est stockée sur un seul volume, le processus est simple ; il est possible de créer un Snapshot à tout moment. Si la base de données s'étend sur plusieurs volumes, un snapshot de groupe de cohérence doit être créé. Plusieurs options sont disponibles pour la création des snapshots de groupe de cohérence, notamment le logiciel NetApp SnapCenter, les fonctionnalités natives de groupe de cohérence ONTAP et les scripts gérés par l'utilisateur.</block>
  <block id="7589d3d0b42e170fc0a459aba0b87fd6" category="paragraph">La technologie VBSR est recommandée pour les bases de données très volumineuses ou si une restauration doit être effectuée le plus rapidement possible et que l'utilisation de VBSR nécessite l'isolement des fichiers de données. Dans un environnement NFS, les fichiers de données d'une base de données doivent être stockés sur des volumes dédiés non endommagés par d'autres types de fichiers. Dans un environnement SAN, les fichiers de données doivent être stockés sur des LUN dédiés sur des volumes dédiés. Si un gestionnaire de volumes est utilisé (y compris Oracle Automatic Storage Management (ASM)), le groupe de disques doit également être dédié aux fichiers de données.</block>
  <block id="d8c4de538bee7abe14d3527c343afee7" category="paragraph">Si un RAC étendu actif-actif est requis, la synchronisation active SnapMirror doit être considérée à la place de MetroCluster. La réplication SM-AS permet de privilégier une réplique spécifique des données. Par conséquent, un cluster RAC étendu peut être intégré dans lequel toutes les lectures se produisent localement. Les E/S de lecture ne traversent jamais les sites, ce qui assure la latence la plus faible possible. Toute activité d'écriture doit toujours transiter la connexion intersite, mais ce trafic est inévitable avec toute solution de mise en miroir synchrone.</block>
  <block id="be6001fc2ab5bfaacf123c0267e58a0a" category="admonition">Si des LUN de démarrage, y compris des disques de démarrage virtualisés, sont utilisés avec Oracle RAC, il<block ref="7c13d022c9fda6e792c4349a043a6c74" prefix=" " category="inline-code"></block> peut être nécessaire de modifier le paramètre. Pour plus d'informations sur les paramètres de délai d'expiration du RAC, reportez-vous à la section <block ref="1d616ba7dc3776fc2ecabd1cd20f420f" category="inline-link-macro-rx"></block>.</block>
  <block id="2bd32004298994cdcbc5a1672f2b8c95" category="summary">Oracle Single instance avec synchronisation active SnapMirror</block>
  <block id="b704207e8ec8f6bbae1764da78cb5232" category="doc">Oracle avec synchronisation active SnapMirror</block>
  <block id="93c480a0b6f335159bf44fcf2e2bec93" category="paragraph">L'utilisation de la synchronisation active SnapMirror n'ajoute pas nécessairement aux meilleures pratiques d'exploitation d'une base de données ou ne modifie pas nécessairement ces pratiques.</block>
  <block id="30bca7463d8c7b2108be553aabb70549" category="paragraph">La meilleure architecture dépend des besoins de l'entreprise. Par exemple, si l'objectif est de bénéficier d'une protection RPO=0 contre la perte de données, mais que l'objectif RTO est assoupli, l'utilisation de bases de données Oracle Single instance et la réplication des LUN avec SM-AS peuvent suffire et être moins coûteuses d'un standard de licences Oracle. Toute panne du site distant n'interrompt pas les opérations, et la perte du site principal entraînerait la présence de LUN en ligne et prêtes à être utilisées sur le site survivant.</block>
  <block id="34ff499afe445b877410a8ae3527a84f" category="paragraph">Si le RTO était plus strict, l'automatisation actif-passif de base via des scripts ou des clusters comme Pacemaker ou Ansible améliorerait le délai de basculement. Par exemple, VMware HA peut être configuré pour détecter une panne de VM sur le site principal et activer cette dernière sur le site distant.</block>
  <block id="63cededd737a118049828e08a2a7e8c7" category="paragraph">Enfin, pour un basculement extrêmement rapide, Oracle RAC peut être déployé sur plusieurs sites. L'objectif de délai de restauration serait essentiellement égal à zéro, car la base de données serait en ligne et disponible à tout moment sur les deux sites.</block>
  <block id="5d0f4a1c768b6f8fc0a38580e17ef62b" category="summary">Oracle Extended RAC avec synchronisation active SnapMirror</block>
  <block id="596d088e9c01a0ceec54de24c763f7c4" category="paragraph">De nombreux clients optimisent leur RTO en étendant un cluster Oracle RAC sur plusieurs sites, offrant une configuration entièrement active/active. La conception globale devient plus complexe car elle doit inclure la gestion du quorum d'Oracle RAC.</block>
  <block id="c128a5dcb6cee18ff198d2c48937cea1" category="paragraph">La mise en cluster RAC étendue traditionnelle s'est appuyée sur la mise en miroir ASM pour assurer la protection des données. Cette approche fonctionne, mais elle implique également de nombreuses étapes manuelles de configuration et entraîne une surcharge de l'infrastructure réseau. À l'inverse, la réplication des données peut être prise en charge par la synchronisation active SnapMirror, ce qui simplifie considérablement la solution. Les opérations telles que la synchronisation, la resynchronisation après les interruptions, les basculements et la gestion du quorum sont plus simples. En outre, le SAN n'a pas besoin d'être distribué entre les sites, ce qui simplifie la conception et la gestion du SAN.</block>
  <block id="74f82d1e2ecf05353775ddaeb38bcddd" category="paragraph">Pour comprendre la fonctionnalité RAC sur SnapMirror Active Sync, il est essentiel de considérer le stockage comme un ensemble unique de LUN hébergés sur un stockage en miroir. Par exemple :</block>
  <block id="68dcade92edf97d052fd54be2dc6b60c" category="inline-image-macro">Accès logique à Oracle</block>
  <block id="9c4d005ebe3fb148615bd62837da8194" category="paragraph"><block ref="9c4d005ebe3fb148615bd62837da8194" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b88e2c412773438221951df1b45aa00c" category="paragraph">Il n'y a pas de copie principale ou miroir. Pour schématiser, il n'y a qu'une seule copie de chaque LUN et cette LUN est disponible sur les chemins SAN situés sur deux systèmes de stockage différents. Du point de vue de l'hôte, il n'y a pas de basculement de stockage ; il y a des changements de chemin. Plusieurs défaillances peuvent entraîner la perte de certains chemins vers la LUN, tandis que les autres chemins restent en ligne. La synchronisation active SnapMirror garantit la disponibilité des mêmes données sur tous les chemins opérationnels.</block>
  <block id="31c1d5c6e07b5b3d11e0585af763dc13" category="paragraph">Dans cet exemple de configuration, les disques ASM sont configurés de la même manière que dans n'importe quelle configuration RAC à site unique sur le stockage d'entreprise. Étant donné que le système de stockage assure la protection des données, la redondance ASM externe est utilisée.</block>
  <block id="f016e2bef75fc762898fb65f21fb9836" category="section-title">Accès uniforme ou non informé</block>
  <block id="c70bc2caf8d25b4a91254d72909c7e75" category="paragraph">L'élément le plus important à prendre en compte avec Oracle RAC sur SnapMirror Active Sync est de savoir s'il faut utiliser un accès uniforme ou non.</block>
  <block id="7cb7fcd446ee1d35aa27d2af5532e2ea" category="paragraph">Un accès uniforme signifie que chaque hôte peut voir les chemins sur les deux clusters. L'accès non uniforme signifie que les hôtes peuvent uniquement voir les chemins vers le cluster local.</block>
  <block id="53934f78a11bd68da05d52b4f83ec9fc" category="paragraph">Aucune de ces options n'est spécifiquement recommandée ou déconseillée. Certains clients ont facilement accès à la fibre noire pour connecter les sites, d'autres ne disposent pas d'une telle connectivité ou leur infrastructure SAN ne prend pas en charge l'ISL longue distance.</block>
  <block id="53772793c4bb5f4dac1c6c0eade7403c" category="section-title">Accès non uniforme</block>
  <block id="68f708ec0a3f5091f6e432be351bf3cc" category="paragraph">L'accès non uniforme est plus simple à configurer du point de vue du SAN.</block>
  <block id="b923541ce3d0d3feae5be9fb6199f770" category="inline-image-macro">Accès Oracle RAC non uniforme</block>
  <block id="b7d64dea0436c64fbd1652575479aa68" category="paragraph"><block ref="b7d64dea0436c64fbd1652575479aa68" category="inline-image-macro-rx" type="image"></block></block>
  <block id="58dcba3041e7c7c3352e2c7f9f497eb5" category="inline-link-macro">accès non uniforme</block>
  <block id="52aa3a00cda7a8077552683f88c13e20" category="paragraph">L'inconvénient principal de cette <block ref="56ad9440d84c5145567c05e340b22f93" category="inline-link-macro-rx"></block> approche est que la perte de la connectivité ONTAP site à site ou la perte d'un système de stockage entraînera la perte des instances de base de données sur un site. Cela n'est évidemment pas souhaitable, mais cela peut constituer un risque acceptable en échange d'une configuration SAN plus simple.</block>
  <block id="4f7fff29e362cc56706e5fe5d34884b6" category="section-title">Accès uniforme</block>
  <block id="df51b4c411cdf825abbf60c345b2886c" category="paragraph">L'accès uniforme requiert l'extension du SAN sur les sites. Le principal avantage est que la perte d'un système de stockage n'entraîne pas la perte d'une instance de base de données. Au lieu de cela, cela entraînerait une modification des chemins d'accès multiples dans lesquels les chemins sont actuellement utilisés.</block>
  <block id="bb79831252d74e631b0f64224932d6e6" category="paragraph">Il existe plusieurs façons de configurer l'accès non uniforme.</block>
  <block id="8ce82023c8f26832db1e79b32f2f7171" category="admonition">Dans les schémas ci-dessous, il existe également des chemins actifs mais non optimisés qui seraient utilisés en cas de défaillances simples du contrôleur, mais ces chemins ne sont pas affichés dans l'intérêt de simplifier les diagrammes.</block>
  <block id="15670c5b41a372b781730d1a2677ed57" category="section-title">AFF avec paramètres de proximité</block>
  <block id="e2b2f6d768064f58804cd8cb2f295266" category="paragraph">En cas de latence importante entre les sites, les systèmes AFF peuvent être configurés avec des paramètres de proximité des hôtes. Cela permet à chaque système de stockage d'identifier les hôtes locaux et distants, et d'attribuer les priorités de chemin en conséquence.</block>
  <block id="5ffb901a29d38d4d4f7c462ffbd0ad7f" category="inline-image-macro">RAC avec accès uniforme</block>
  <block id="efdefb56bfdac6f3b9194f8ce94b9ae9" category="paragraph"><block ref="efdefb56bfdac6f3b9194f8ce94b9ae9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e106da7d1088531e38324a9d76b9a988" category="paragraph">En fonctionnement normal, chaque instance Oracle utilisera de préférence les chemins locaux actifs/optimisés. Par conséquent, toutes les lectures seront traitées par la copie locale des blocs. La latence est ainsi la plus faible possible. Les E/S d'écriture sont envoyées de la même manière vers le contrôleur local. L'E/S doit toujours être répliquée avant d'être reconnue, ce qui entraîne toujours une latence supplémentaire en traversant le réseau site à site, mais cela ne peut pas être évité dans une solution de réplication synchrone.</block>
  <block id="889ea87800d5947e36cda77f7d1b16b4" category="section-title">ASA / AFF sans paramètres de proximité</block>
  <block id="a92e6cf0c610f6072564d047ffa516be" category="paragraph">S'il n'y a pas de latence significative entre les sites, les systèmes AFF peuvent être configurés sans paramètres de proximité des hôtes, ou ASA peut être utilisé.</block>
  <block id="7760495be1250342ca752bb9cdc684ee" category="paragraph"><block ref="7760495be1250342ca752bb9cdc684ee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6bad71277bac94b02b8ad4267095b9e1" category="paragraph">Chaque hôte pourra utiliser tous les chemins opérationnels sur les deux systèmes de stockage. Cela améliore considérablement les performances en permettant à chaque hôte d'exploiter le potentiel de performance de deux clusters, et non d'un seul.</block>
  <block id="56473d7f95c121dd938752e3ee76807e" category="paragraph">Avec ASA, non seulement tous les chemins vers les deux clusters sont considérés comme actifs et optimisés, mais les chemins sur les contrôleurs partenaires sont également actifs. Il en résulte des chemins SAN entièrement actifs sur l'ensemble du cluster, à tout moment.</block>
  <block id="22ede275964a6c559bc3f8f6d60e47ff" category="admonition">Les systèmes ASA peuvent également être utilisés dans une configuration d'accès non uniforme. Étant donné qu'il n'existe aucun chemin entre les sites, les performances ne seraient pas améliorées par le franchissement de l'ISL par les E/S.</block>
  <block id="263e6bb36868a481a8831ae728712452" category="summary">Synchronisation active Oracle SnapMirror</block>
  <block id="d1864442faf9b87db487ba86c72892a9" category="paragraph">Les exemples décrits ci-dessous illustrent certaines des nombreuses options de déploiement des bases de données Oracle Single instance avec la réplication SnapMirror Active Sync.</block>
  <block id="1bd45bc28deaa95af95dd782d94963fa" category="inline-image-macro">Oracle si avec accès non uniforme</block>
  <block id="c94bc93663b0f709f6a6885553fe9153" category="paragraph"><block ref="c94bc93663b0f709f6a6885553fe9153" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b29b2b92ebd168fbb013ea878c5c1075" category="paragraph">La synchronisation active SnapMirror fournit une copie synchrone des données au niveau du site de reprise d'activité. Toutefois, la mise à disposition des données requiert un système d'exploitation et les applications associées. L'automatisation de base peut considérablement améliorer le délai de basculement de l'environnement global. Les produits Clusterware tels que Pacemaker sont souvent utilisés pour créer un cluster sur les sites et, dans la plupart des cas, le processus de basculement peut être piloté par des scripts simples.</block>
  <block id="1e953e50c45ead229eae67ed609a3a1e" category="paragraph">En cas de perte des nœuds principaux, le cluster (ou les scripts) mettra les bases de données en ligne sur le site secondaire. Une option consiste à créer des serveurs de secours préconfigurés pour les ressources SAN qui constituent la base de données. En cas de défaillance du site principal, le logiciel de mise en cluster ou l'alternative scriptée effectue une séquence d'actions similaires à celles décrites ci-dessous :</block>
  <block id="861373097ad1daff7221c81f1ffb8bd2" category="list-text">Détection d'une défaillance du site principal</block>
  <block id="471eb645214523a67e69f308fd203df5" category="list-text">Effectuez la détection des LUN FC ou iSCSI</block>
  <block id="aaae9cdb1dc3caf850c21cbae6cb7dd9" category="paragraph">La procédure d'activation réelle est simple. Les commandes telles que la découverte de LUN ne nécessitent que quelques commandes par port FC. Le montage du système de fichiers n'est rien de plus qu'une<block ref="19822b1b15d9eefc54c07ab49f87b100" prefix=" " category="inline-code"></block> commande et les bases de données et ASM peuvent être démarrés et arrêtés sur l'interface de ligne de commande à l'aide d'une seule commande.</block>
  <block id="81760e5cf8ff0457c9927339fe0d7987" category="list-text">Démarrage manuel des bases de données ou configuration des machines virtuelles pour démarrer automatiquement les bases de données.</block>
  <block id="17ad404af9b36204bcadadd073042e1c" category="paragraph">Par exemple, un cluster ESX peut couvrir des sites. En cas d'incident, les machines virtuelles peuvent être mises en ligne sur le site de reprise après incident après le basculement.</block>
  <block id="06c019e625f0595de8528ac88cab1815" category="section-title">Protection contre les défaillances du stockage</block>
  <block id="0559887c95614fe388b0dc7f8914a2db" category="paragraph">Le diagramme ci-dessus montre l'utilisation de <block ref="56ad9440d84c5145567c05e340b22f93" category="inline-link-macro-rx"></block>, où le SAN n'est pas étendu entre les sites. Cela peut être plus simple à configurer et, dans certains cas, peut être la seule option étant donné les fonctionnalités SAN actuelles, mais cela signifie également que la défaillance du système de stockage principal entraînerait une panne de la base de données jusqu'à ce que l'application ait été ratée.</block>
  <block id="5cbfe7798787ccd0e92fcaceca503314" category="inline-link-macro">accès uniforme</block>
  <block id="38a1b98129ec5892c90cdda2967b957c" category="paragraph">Pour une résilience supplémentaire, la solution pourrait être déployée avec <block ref="8c3bdda17267bf34dafd546406201d13" category="inline-link-macro-rx"></block>. Cela permettrait aux applications de continuer à fonctionner en utilisant les chemins annoncés à partir du site opposé.</block>
  <block id="d77ca8b041bbb54326491bb1aeb6fadf" category="doc">Synchronisation active Oracle et SnapMirror - RAC Tiebreaker</block>
  <block id="084a4c8d8d6223c9b3c0749a4097bf8f" category="paragraph">Bien que le RAC étendu utilisant la synchronisation active SnapMirror soit une architecture symétrique par rapport aux E/S, il existe une exception qui est connectée à la gestion du split-brain.</block>
  <block id="f0dd83fae83b5ba13b4e8c760578f47f" category="paragraph">Que se passe-t-il si le lien de réplication est perdu et qu'aucun des sites n'a le quorum ? Que doit-on faire ? Cette question s'applique à la fois au comportement d'Oracle RAC et de ONTAP. Si les modifications ne peuvent pas être répliquées sur tous les sites et que vous souhaitez reprendre les opérations, l'un des sites devra survivre et l'autre site devra être indisponible.</block>
  <block id="58dc7db50a2e11a9de9e6cc092c59d4d" category="inline-link-macro">Médiateur de ONTAP</block>
  <block id="406abe933a832eefeb56c0390b824200" category="paragraph">Le système <block ref="6663df057ff17bcadb83516e8fd742b7" category="inline-link-macro-rx"></block> répond à cette exigence au niveau de la couche ONTAP. Il existe plusieurs options pour le tricover RAC.</block>
  <block id="1a7cedbe5066c42f7f901bffc7905f59" category="section-title">Disjoncteurs Oracle</block>
  <block id="236ca78f8e5b54033dbbd133abe79e60" category="paragraph">La meilleure méthode pour gérer les risques Oracle RAC split-brain consiste à utiliser un nombre impair de nœuds RAC, de préférence à l'aide d'un Tiebreaker 3rd site. Si un troisième site n'est pas disponible, l'instance Tiebreaker pourrait être placée sur un site des deux sites, ce qui la désignerait en fait un site de survivant préféré.</block>
  <block id="af70ccf0217a2356d2bcebb6fab5a25b" category="section-title">Oracle et CSS_Critical</block>
  <block id="e7c7cde013ca0177a945b339ca49fe1d" category="paragraph">Avec un nombre pair de nœuds, le comportement par défaut d'Oracle RAC est que l'un des nœuds du cluster sera considéré plus important que les autres nœuds. Le site avec ce nœud de priorité supérieure survivra à l'isolation du site tandis que les nœuds de l'autre site seront supprimés. La hiérarchisation est basée sur plusieurs facteurs, mais vous pouvez également contrôler ce comportement à l'aide du<block ref="6124b1cbe711d49d95a1c41d4e2701b4" prefix=" " category="inline-code"></block> paramètre.</block>
  <block id="1a79a4d60de6718e8e5b326e338ae533" category="inline-link-macro">exemple</block>
  <block id="6ae35dd8ffe888ab910de0d5d5e3a45a" category="paragraph">Dans l'<block ref="0a286933b98d5160dd3059338d9fd4c7" category="inline-link-macro-rx"></block>architecture, les noms d'hôte des nœuds RAC sont jfs12 et jfs13. Les paramètres actuels de<block ref="6124b1cbe711d49d95a1c41d4e2701b4" prefix=" " category="inline-code"></block> sont les suivants :</block>
  <block id="d05ceaa3e91a5aa94cbe7a8ac83ad048" category="paragraph">Si vous voulez que le site avec jfs12 soit le site préféré, définissez cette valeur sur oui sur un site Un noeud et redémarrez les services.</block>
  <block id="d7e25fc2f6769b17d752bc3cde6d0266" category="summary">Basculement de la synchronisation active Oracle et SnapMirror</block>
  <block id="f0972b46fa5671c4841c63750ccdebb9" category="doc">SnapMirror actif sync : perte de réplication Oracle RAC</block>
  <block id="8a6c7e7b423c27776aad808ff121ced3" category="paragraph">La perte du lien de réplication RAC Oracle produira un résultat similaire à la perte de la connectivité SnapMirror, sauf que les délais d'expiration seront plus courts par défaut. Dans les paramètres par défaut, un nœud RAC Oracle attend 200 secondes après une perte de connectivité du stockage avant d'être supprimé, mais il n'attend que 30 secondes après la perte du signal de détection du réseau RAC.</block>
  <block id="488bd272072f6a962dc0b8f69fc362b8" category="paragraph">Les messages CRS sont similaires à ceux indiqués ci-dessous. Vous pouvez voir le délai d'expiration de 30 secondes. Comme css_Critical a été défini sur jfs12, situé sur le site A, ce sera le site pour survivre et jfs13 sur le site B sera supprimé.</block>
  <block id="80f8fcffb7c608c6d25e68111eb38b2d" category="summary">Synchronisation active Oracle et SnapMirror - basculement manuel</block>
  <block id="0d97f4e7841f881ee429033c005d63ef" category="paragraph">Le terme « basculement » ne fait pas référence au sens de la réplication avec la synchronisation active SnapMirror, car il s'agit d'une technologie de réplication bidirectionnelle. En revanche, le terme « basculement » désigne le système de stockage qui sera le site privilégié en cas de défaillance.</block>
  <block id="669420d9776c5672f6a1edf3bbf41604" category="paragraph">Par exemple, vous pouvez effectuer un basculement pour modifier le site préféré avant d'arrêter un site pour des raisons de maintenance ou avant d'effectuer un test de reprise après incident.</block>
  <block id="1a5cda38e5f45bb47ad55cae28a62d58" category="paragraph">Exemple d'interface graphique :</block>
  <block id="dd8c4d4a8c7db09b331d019e9ba3a643" category="inline-image-macro">Clip SystemManager de SM-en tant que site préféré</block>
  <block id="50925d08482582f6a3178736557a9d6c" category="paragraph"><block ref="50925d08482582f6a3178736557a9d6c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="beecd91de8185d21ecef9d430e18d4dc" category="paragraph">Exemple de modification via l'interface de ligne de commande :</block>
  <block id="3877a64f9dbc63cfbdca7e30e66c42a2" category="summary">Synchronisation active Oracle et SnapMirror - défaillance du médiateur</block>
  <block id="9daff60ceba391d4160d5e54f14037d8" category="paragraph">Le service médiateur ne contrôle pas directement les opérations de stockage. Il fonctionne comme un chemin de contrôle alternatif entre les clusters. Il existe principalement pour automatiser le basculement sans les risques associés à un scénario « split-brain ».</block>
  <block id="13ce4a149213a3a389210201d2850f7c" category="paragraph">En conditions normales de fonctionnement, chaque cluster réplique les modifications apportées à son partenaire et chaque cluster peut donc vérifier que le cluster partenaire est en ligne et qu'il transmet les données. Si le lien de réplication échoue, la réplication s'arrête.</block>
  <block id="381c63e25d0de40f5be6677aa1346b0e" category="paragraph">Un médiateur est nécessaire pour des opérations automatisées sécurisées, car il serait autrement impossible pour les clusters de stockage de déterminer si la perte de la communication bidirectionnelle était due à une panne du réseau ou à une défaillance réelle du stockage.</block>
  <block id="e51e3b7c6dff02b4ab76ceab7b000eb8" category="list-text">En cas de défaillance des services de réplication, quelle qu'en soit la raison, le site préféré libère l'état RPO=0 et reprend le traitement des E/S en lecture et en écriture. Le site non préféré mettra ses chemins hors ligne.</block>
  <block id="957e90f10d8268ba74dc866bec3ed2fa" category="doc">Synchronisation active SnapMirror : perte totale de la connectivité</block>
  <block id="4470e5dd55a8a6253ccfd5dca462e193" category="paragraph">Si la liaison de réplication entre les sites est totalement perdue, la synchronisation active SnapMirror et la connectivité RAC Oracle seront interrompues.</block>
  <block id="cd48b65842aa3ca6718bf9d05c82a272" category="paragraph">La détection d'Oracle RAC à cerveau divisé dépend du pulsation du stockage Oracle RAC. Si la perte de la connectivité site à site entraîne la perte simultanée du signal de détection du réseau RAC et des services de réplication du stockage, les sites RAC ne pourront pas communiquer entre sites via l'interconnexion RAC ou les disques de vote RAC. Le résultat d'un ensemble de nœuds à numéro pair peut être l'exclusion des deux sites sous les paramètres par défaut. Le comportement exact dépend de la séquence des événements et de la synchronisation des sondages de pulsation du réseau RAC et du disque.</block>
  <block id="d76ecbc1eb83c7a69064a5bb857c85c9" category="inline-link-macro">disjoncteur d'attache</block>
  <block id="acef32b29f0767a38d288d2517fd82e4" category="paragraph">Le risque d'une panne sur deux sites peut être résolu de deux manières. Tout d'abord, une <block ref="5eea39840e87052aa3c632ea60116716" category="inline-link-macro-rx"></block> configuration peut être utilisée.</block>
  <block id="f52f16ab0735aaefebdd18f6be0a1d9a" category="paragraph">Si aucun site tiers n'est disponible, ce risque peut être résolu en ajustant le paramètre misscount sur le cluster RAC. Sous les valeurs par défaut, le délai d'expiration de la pulsation réseau du RAC est de 30 secondes. Il est généralement utilisé par RAC pour identifier les nœuds RAC défaillants et les supprimer du cluster. Il dispose également d'une connexion à la pulsation du disque de vote.</block>
  <block id="c2b5462b64e9fc5a5b57a31b233c8857" category="paragraph">Si, par exemple, le conduit transportant le trafic intersite pour Oracle RAC et les services de réplication de stockage est coupé par une pelle rétro, le compte à rebours des erreurs de 30 secondes commence. Si le nœud du site RAC préféré ne peut pas rétablir le contact avec le site opposé dans les 30 secondes et qu'il ne peut pas utiliser les disques de vote pour confirmer que le site opposé est en panne dans la même fenêtre de 30 secondes, les nœuds du site préféré seront également supprimés. Il en résulte une interruption complète de la base de données.</block>
  <block id="db651e89ed200f74c11c1ae1c5d2b32d" category="paragraph">Selon le moment où l'interrogation du compte erroné se produit, 30 secondes peuvent ne pas suffire à la temporisation de la synchronisation active SnapMirror et à permettre au stockage du site préféré de reprendre les services avant l'expiration de la fenêtre de 30 secondes. Cette fenêtre de 30 secondes peut être augmentée.</block>
  <block id="dbdaf8435bc0aa414eca4876e6c308d2" category="paragraph">Cette valeur permet au système de stockage sur le site préféré de reprendre les opérations avant que le délai d'erreur n'expire. Le résultat sera alors la suppression uniquement des nœuds sur le site où les chemins de LUN ont été supprimés. Exemple ci-dessous :</block>
  <block id="e231fb490ed068ec9b23beb7dd95220e" category="paragraph">Le support Oracle déconseille fortement de modifier les paramètres misscount ou disktimeout pour résoudre les problèmes de configuration. Toutefois, la modification de ces paramètres peut s'avérer justifiée et inévitable dans de nombreux cas, notamment dans les configurations de démarrage SAN, de virtualisation et de réplication du stockage. Si, par exemple, vous avez rencontré des problèmes de stabilité avec un réseau SAN ou IP qui ont entraîné des expulsions RAC, vous devez résoudre le problème sous-jacent et ne pas facturer les valeurs de l'erreur de décompte ou du dépassement de disque. La modification des délais pour résoudre les erreurs de configuration masque un problème et non pas résout un problème. La modification de ces paramètres pour configurer correctement un environnement RAC basé sur les aspects de conception de l'infrastructure sous-jacente est différente et est conforme aux instructions de support Oracle. Avec le démarrage SAN, il est courant d'ajuster misscount jusqu'à 200 pour correspondre au disktimeout. Voir <block ref="ba774c2123df7855b7691ef15a557a8c" category="inline-link-macro-rx"></block> pour plus d'informations.</block>
  <block id="cb5f127f654db8aa1847f5e9e6c5118e" category="summary">Synchronisation active Oracle et SnapMirror - restauration du service</block>
  <block id="894265e54aece56ce813211a980cdfe2" category="paragraph">SnapMirror propose une fonctionnalité d'autorétablissement. La synchronisation active SnapMirror détecte automatiquement la présence d'une relation de réplication défectueuse et la ramène à un état RPO=0. Une fois la réplication synchrone rétablie, les chemins reviennent en ligne.</block>
  <block id="c512ae64a9e9927a6314fdd926760a72" category="paragraph">Dans de nombreux cas, les applications en cluster détectent automatiquement le retour des chemins défaillants, et ces applications sont également reconnectées. Dans d'autres cas, une analyse SAN au niveau de l'hôte peut être nécessaire ou les applications doivent être reconnectées manuellement.</block>
  <block id="c83e8f0dcd2a1773693ac06c752f2ddd" category="paragraph">Cela dépend de l'application et de la façon dont elle est configurée et, en général, ces tâches peuvent être facilement automatisées. La synchronisation active SnapMirror elle-même est auto-fixing et ne nécessite aucune intervention de l'utilisateur pour reprendre les opérations de stockage avec un objectif de point de récupération de 0 une fois l'alimentation et la connectivité restaurées.</block>
  <block id="b55bb91b49684d644a2314af260f5584" category="doc">Exemple d'architecture Oracle avec SnapMirror Active Sync</block>
  <block id="8ba2bb4ebd97f28e7d98a180d8b06c1a" category="paragraph">Les exemples détaillés de défaillances présentés dans cette section sont basés sur l'architecture présentée ci-dessous.</block>
  <block id="5d10516d162cd9f09cf5dc249d499836" category="admonition">Il ne s'agit que de l'une des nombreuses options pour les bases de données Oracle sur la synchronisation active SnapMirror. Cette conception a été choisie parce qu'elle illustre certains des scénarios les plus complexes.</block>
  <block id="ce2a1d07c1660eb99608e2aeb9ffda20" category="inline-link-macro">site préféré</block>
  <block id="93d235b3b3adb1fcc631cc9720911156" category="paragraph">Dans cette conception, supposons que le site A est défini sur <block ref="0a07e9e6141ed78f0b7013768c76c4a9" category="inline-link-macro-rx"></block>.</block>
  <block id="3f35d87b783da3d0c6ab04c2222e88cc" category="inline-image-macro">Exemple d'Oracle sur la conception SM-as</block>
  <block id="65d5312cbb5d7497db9571af7d19e76d" category="paragraph"><block ref="65d5312cbb5d7497db9571af7d19e76d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="af82c537bd0f6778b9916dc78da8c55a" category="paragraph">Le résultat d'une défaillance du site ou du système de stockage est presque identique au résultat de la perte du lien de réplication. Le site survivant doit subir une pause d'E/S d'environ 15 secondes sur les écritures. Une fois cette période de 15 secondes écoulée, l'E/S reprend sur ce site comme d'habitude.</block>
  <block id="24f2945a7c742e126cdf5dcdfb08ec89" category="paragraph">Si seul le système de stockage a été affecté, le nœud Oracle RAC sur le site en panne perdra les services de stockage et entrera le même compte à rebours de 200 secondes avant la suppression et le redémarrage suivant.</block>
  <block id="0cff2ae5f5c305f11d8d8a333bd1da2c" category="paragraph">L'état du chemin SAN sur le nœud RAC qui a perdu des services de stockage se présente comme suit :</block>
  <block id="e33921fb5e166f433573176882c09294" category="paragraph">L'hôte linux a détecté la perte des chemins beaucoup plus rapidement que 200 secondes, mais du point de vue de la base de données, les connexions client à l'hôte sur le site défaillant seront toujours bloquées pendant 200 secondes sous les paramètres Oracle RAC par défaut. Les opérations complètes de la base de données ne reprendront qu'une fois la suppression terminée.</block>
  <block id="db34db4ac9bd7910a9eded83e1ff30f9" category="paragraph">Pendant ce temps, le nœud Oracle RAC sur le site opposé enregistre la perte de l'autre nœud RAC. Dans le cas contraire, le système continue de fonctionner normalement.</block>
  <block id="ad08bdae586fc05e13eff6bd6d9f0ee2" category="paragraph">Si la liaison de réplication SnapMirror active Sync, l'E/S d'écriture ne peut pas être terminée, car un cluster ne peut pas répliquer les modifications sur le site opposé.</block>
  <block id="564a95e2696af68aa1c3a4953ecd1ce9" category="section-title">Site A</block>
  <block id="18fe52a46fad1fa4c9873ea81b6e885f" category="paragraph">Le site A qui présente une défaillance de liaison de réplication entraînera une pause d'environ 15 secondes dans le traitement des E/S d'écriture au fur et à mesure que ONTAP tente de répliquer des écritures avant de déterminer que la liaison de réplication est réellement inutilisable. Au bout de 15 secondes, le cluster ONTAP sur le site A reprend le traitement des E/S de lecture et d'écriture. Les chemins SAN ne changent pas et les LUN restent en ligne.</block>
  <block id="657e60cc43634129c8f9314afdd5c48b" category="paragraph">Le lien de réplication a été coupé à l'horodatage 15:19:44. Le premier avertissement d'Oracle RAC arrive 100 secondes plus tard lorsque le délai d'expiration de 200 secondes (contrôlé par le paramètre Oracle RAC disktimeout) approche.</block>
  <block id="f29d4b902de1f9de93b8673047367cb3" category="paragraph">Une fois que le délai d'expiration du disque de vote de 200 secondes a été atteint, ce nœud RAC Oracle s'expulse automatiquement du cluster et redémarre.</block>
  <block id="b864ca7c3ca6173547e4a66ba059c688" category="summary">Oracle,SM-AS,synchronisation active,médiateur</block>
  <block id="01682ebdcacbc827e3ef8083e7b4c060" category="summary">Oracle et SM-as accès non uniforme</block>
  <block id="f6dbb06140585fe45ddeaf49cae9418e" category="summary">Synchronisation active Oracle et SnapMirror</block>
  <block id="d6e7dde9799f39cece01cbc4b2728cdf" category="paragraph">La synchronisation active SnapMirror vous permet de créer des environnements de base de données Oracle à ultra haute disponibilité où des LUN sont disponibles à partir de deux clusters de stockage différents.</block>
  <block id="13645bda5e7e84c7e547caee4c6325b2" category="paragraph">Avec la synchronisation active SnapMirror, il n'y a pas de copie « principale » ni de copie « secondaire » des données. Chaque cluster peut fournir des E/S de lecture à partir de sa copie locale des données, et chaque cluster réplique une écriture vers son partenaire. Le résultat est un comportement d'E/S symétrique.</block>
  <block id="36b94662a6696bbaee0152aefe40ed13" category="paragraph">Entre autres options, vous pouvez exécuter Oracle RAC en tant que cluster étendu avec des instances opérationnelles sur les deux sites. Vous pouvez également créer des clusters de bases de données actif-passif RPO=0, dans lesquels les bases de données à instance unique peuvent être déplacées entre les sites en cas de panne sur le site. Ce processus peut également être automatisé via des produits tels que Pacemaker ou VMware HA. Toutes ces options reposent sur la réplication synchrone gérée par SnapMirror Active Sync.</block>
  <block id="d1a363496283d60774ff9c9c51ffe653" category="paragraph">En fonctionnement normal, la synchronisation active SnapMirror fournit en permanence une réplique synchrone avec un objectif de point de récupération de 0, à une exception près. Si les données ne peuvent pas être répliquées, ONTAP exige de répliquer les données et de reprendre le traitement des E/S sur un site pendant que les LUN de l'autre site sont mises hors ligne.</block>
  <block id="72f31f711b37dc7ce7b34e00dd56b5ae" category="paragraph">Le médiateur ONTAP est une application logicielle téléchargée depuis la prise en charge de NetApp et généralement déployée sur une petite machine virtuelle. Le Mediator ONTAP n'est pas un Tiebreaker lorsqu'il est utilisé avec la synchronisation active SnapMirror. Il s'agit d'un canal de communication alternatif pour les deux clusters qui participent à la réplication SnapMirror active Sync. Les opérations automatisées sont dirigées par ONTAP sur la base des réponses reçues du partenaire via des relations directes et via le médiateur.</block>
  <block id="b06e5b68abe4f23a716133f1fa1a4472" category="summary">Oracle et SM-comme site préféré</block>
  <block id="6d14548094c3b2a5b0a69049f8497fa8" category="doc">Oracle et SM-AS accès uniforme</block>
  <block id="36ba939f32969ddc6751427944e3569d" category="paragraph">Il est donc primordial d'isoler les fichiers de données dans un ou plusieurs volumes dédiés. Ils doivent être non contaminés par tout autre type de fichier. La raison est de s'assurer que la réplication des fichiers de données est totalement indépendante de la réplication d'autres types de données tels que les journaux d'archivage. Pour plus d'informations sur les mises en page de fichiers et pour obtenir des détails importants sur la manière de s'assurer que la disposition du stockage est adaptée aux instantanés, reportez-vous à <block ref="c87a7212960b8cc2aca49adb1795e291" category="inline-link-macro-rx"></block>la section .</block>
  <block id="64c93f87be857cf43f66e341a377693a" category="paragraph">Le système d'exploitation peut détecter le fait que<block ref="9ad16912cc0ba54a259b1a15d233c264" prefix=" " category="inline-code"></block> et<block ref="1da707b60c3b55bd01cb7df7c171a368" prefix=" " category="inline-code"></block> résident sur le même volume, qui est le même système de fichiers source. Le système d'exploitation utilise ensuite le même descripteur de périphérique pour accéder aux données. Cela améliore l'utilisation de la mise en cache du système d'exploitation et de certaines autres opérations, mais interfère avec dNFS. Si dNFS doit accéder à un fichier, par exemple<block ref="1737629d60b511cf45957529a8f046e2" prefix=" " category="inline-code"></block> , sur ,<block ref="1da707b60c3b55bd01cb7df7c171a368" prefix=" " category="inline-code"></block> il peut essayer par erreur d'utiliser le mauvais chemin d'accès aux données. Le résultat est une opération d'E/S défaillante. Dans ces configurations, ajoutez<block ref="4740c034d97ca90a96b8050082816605" prefix=" " category="inline-code"></block> l'option de montage à tout système de fichiers NFS qui partage un volume source avec un autre système de fichiers NFS de cet hôte. Cela force le système d'exploitation Linux à allouer un descripteur de périphérique indépendant pour ce système de fichiers.</block>
  <block id="30d0582d4c5a0b280454304dcff9c28f" category="paragraph">Solaris 11 a inclus un changement dans la façon dont il traite les opérations d'E/S importantes, ce qui peut entraîner de graves problèmes de performances sur les baies de stockage SAN. Le problème est documenté NetApp suivi bug report 630173, "Solaris 11 ZFS Performance regression".</block>
  <block id="c041cd46ed4caba0947ab494ac5bb1d9" category="paragraph">Il ne s'agit pas d'un bogue de ONTAP. Il s'agit d'un défaut Solaris suivi sous les défauts Solaris 7199305 et 7082975.</block>
  <block id="a83650b3549679a1591275f0f9cd38e0" category="paragraph">Vous pouvez consulter le support Oracle pour savoir si votre version de Solaris 11 est affectée, ou vous pouvez tester la solution de contournement en la changeant<block ref="954f82599f7db0212a28fd448e03bdf3" prefix=" " category="inline-code"></block> à une valeur plus petite.</block>
  <block id="65711e429e82120028dff2df28b4b92d" category="paragraph">Pour ce faire, exécutez la commande suivante en tant que root :</block>
  <block id="f0eff8c4d89b44c0cf8b8c323abeaa20" category="paragraph">Si vous avez besoin d'un processus hors ligne, retardez la redécouverte ou le redémarrage des services jusqu'à ce que la<block ref="1ab15ef2c245a4434fcea3cc3149f4f4" prefix=" " category="inline-code"></block> commande indique que la migration a abouti. Vous pouvez ensuite terminer le processus de migration comme décrit à la section <block ref="bfe85b0236d22bff0d0d13e4e3fecb98" category="inline-link-macro-rx"></block>.</block>
  <block id="dbd3f1a817d137c052ec01ef60940131" category="inline-link">Documentation relative à l'importation de LUN étrangères de ONTAP</block>
  <block id="1e63fd2b99b2fef1f5d2ae61ebd5b4a3" category="paragraph">Les procédures de migration des ressources SAN à l'aide de FLI sont décrites dans NetApp<block ref="3a5bd22edab525577a3f095f01c2551b" category="inline-link-rx"></block> .</block>
  <block id="4fc57ef291a6bc6be0f3f8c81e4f9b44" category="paragraph">L'organigramme ci-dessous présente les différents éléments à prendre en compte pour déterminer le chemin de migration le plus approprié. Vous pouvez cliquer avec le bouton droit de la souris sur l'image et l'ouvrir dans un nouvel onglet pour améliorer la lisibilité.</block>
  <block id="17ed98f652bb960b10b3357e44785f38" category="inline-image-macro">Organigramme de la migration</block>
  <block id="f420007a3c90420b30780388a0e05dbc" category="paragraph"><block ref="6ee66f70cd2b82e9dd03128a50a38de9" category="inline-image-macro-rx" type="image"></block>.</block>
  <block id="fb3e908ec44ab0657a364e90a649adee" category="admonition">Reportez-vous à la remarque à propos de<block ref="4740c034d97ca90a96b8050082816605" prefix=" " category="inline-code"></block> la <block ref="6ada863f3548cecdf5d7a06e9c4201cd" category="inline-link-macro-rx"></block> pour un problème dNFS spécifique à Linux qui peut produire des résultats inhabituels.</block>
  <block id="7dde30333f2f14b8935a6f394318dd19" category="paragraph">Directive non résolue dans &lt;stdin&gt; - include::lun-alignment.adoc[]</block>
  <block id="baeaebf1ec4083a8b5a2278617a67479" category="paragraph">Voir également la discussion sur l'alignement des blocs de compression dans la section <block ref="936e7f76dd05eeca0e082776361dee38" category="inline-link-macro-rx"></block>. Toute disposition alignée avec les limites des blocs de compression de 8 Ko est également alignée avec les limites de 4 Ko.</block>
  <block id="62cc2062c0bb14fd9ee41267e11b9824" category="paragraph">Directive non résolue dans &lt;stdin&gt; - include::database-alignment-warnings.adoc[]</block>
  <block id="779e77f14b9599d3021cc1c978703d8e" category="paragraph">Les plateformes de gestion de données NetApp optimisées par ONTAP sont parmi les solutions de stockage les plus largement utilisées pour SRM. Les raisons en sont nombreuses : une plateforme de gestion des données sécurisée, haute performance et multiprotocole unifié (NAS et SAN ensemble) qui fournit l'efficacité du stockage, la colocation, le contrôle de la qualité de service, la protection des données avec des copies Snapshot compactes et la réplication avec SnapMirror. Exploitez l'intégration native du multicloud hybride pour protéger vos charges de travail VMware et bénéficier de nombreux outils d'automatisation et d'orchestration à portée de main.</block>
  <block id="f05beeac7e71de747ac87dd710b5100f" category="list-text">Le plug-in vCenter, précédemment appelé Virtual Storage Console (VSC), simplifie les fonctionnalités de gestion et d'efficacité du stockage, améliore la disponibilité et réduit les coûts de stockage ainsi que les charges opérationnelles, que vous utilisiez SAN ou NAS. Il s'appuie sur les bonnes pratiques pour le provisionnement des datastores et optimise les paramètres d'hôte ESXi pour les environnements de stockage NFS et bloc. Pour tous ces avantages, NetApp recommande ce plug-in lors de l'utilisation de vSphere avec les systèmes exécutant ONTAP.</block>
  <block id="0452707f6213531bbf4f41e5f16cdead" category="paragraph">Le clonage peut être déchargé sur les systèmes qui exécutent ONTAP par le biais de plusieurs mécanismes, généralement au niveau des VM, vVol ou datastore. Ces champs d'application incluent :</block>
  <block id="a4ec3dfc79c8493b1e9fcaee6b06b5a8" category="summary">ONTAP prend en charge le cloud hybride.</block>
  <block id="14f3c0fa1399e57b5998b528cc5f3515" category="paragraph">ONTAP est, entre autres, une baie NAS scale-out de grande qualité. ONTAP permet à VMware vSphere d'accéder simultanément aux datastores connectés par NFS à partir de nombreux hôtes VMware ESXi, ce qui dépasse de loin les limites imposées aux systèmes de fichiers VMFS. L'utilisation de NFS avec vSphere offre des avantages en termes de facilité d'utilisation et d'efficacité du stockage, comme indiqué dans la <block ref="72b655a9973dbed02099f5e63762d591" category="inline-link-macro-rx"></block> section.</block>
  <block id="8fabf36e54be557b0b3c16cc181ccef7" category="paragraph">SLM limite les nœuds qui annoncent les chemins vers une LUN donnée. Il est recommandé à NetApp d'utiliser au moins une LIF par nœud par SVM et SLM pour limiter les chemins annoncés vers le nœud hébergeant la LUN et son partenaire de haute disponibilité. Bien que d'autres chemins existent, ils ne sont pas annoncés par défaut. Il est possible de modifier les chemins annoncés avec les arguments de noeud de rapport ajouter et supprimer dans SLM. Notez que les LUN créées dans les versions antérieures à 8.3 annoncent tous les chemins et doivent être modifiés uniquement pour annoncer les chemins vers la paire HA d'hébergement. Pour plus d'informations sur SLM, consultez la section 5.9 de<block ref="a2bae1e6a9d1ce7703c1f95bb6ec1d6e" category="inline-link-rx"></block>. La méthode précédente de ensembles de ports peut également être utilisée pour réduire davantage les chemins disponibles pour une LUN. Les jeux de ports permettent de réduire le nombre de chemins visibles via lesquels les initiateurs d'un groupe initiateur peuvent voir les LUN.</block>
  <block id="0783a52eeafbf6085600efe3ac209a9c" category="paragraph">Les systèmes exécutant ONTAP prennent en charge les principaux protocoles de stockage. Les clients peuvent ainsi choisir l'environnement le mieux adapté à leur environnement, en fonction de l'infrastructure réseau existante et planifiée, et des compétences du personnel. Les tests effectués par NetApp n'ont généralement pas permis de faire la différence entre les protocoles s'exécutant à des vitesses de ligne similaires. Il est donc préférable de se concentrer sur votre infrastructure réseau et sur les capacités des équipes par rapport aux performances des protocoles bruts.</block>
  <block id="ef7f5a0b4e0866202a92874cc85a2fd2" category="list-text">Les machines virtuelles qui nécessitent une migration plus minutieuse incluent les bases de données et les applications qui utilisent le stockage associé. De manière générale, envisagez l'utilisation des outils de l'application pour gérer la migration. Pour Oracle, envisagez d'utiliser des outils Oracle tels que RMAN ou ASM pour migrer les fichiers de base de données. Voir<block ref="74eec9db95a0d18126c677c2dcc1d6f1" category="inline-link-rx"></block> pour plus d'informations. De même, pour SQL Server, envisagez d'utiliser soit SQL Server Management Studio, soit des outils NetApp tels qu'SnapManager pour SQL Server, soit SnapCenter.</block>
  <block id="4adbfc6cb6ee114e186e01168d24a89b" category="paragraph">La meilleure pratique la plus importante lors de l'utilisation de vSphere avec des systèmes exécutant ONTAP consiste à installer et à utiliser le plug-in ONTAP Tools for VMware vSphere (anciennement Virtual Storage Console). Ce plug-in vCenter simplifie la gestion du stockage, améliore la disponibilité et réduit les coûts de stockage ainsi que les charges opérationnelles, que ce soit via SAN ou NAS. Il tire parti des bonnes pratiques pour le provisionnement des datastores et optimise les paramètres des hôtes ESXi pour les délais entre les chemins d'accès multiples et les HBA (ces paramètres sont décrits dans l'annexe B). Comme il s'agit d'un plug-in vCenter, il est disponible pour tous les clients Web vSphere qui se connectent au serveur vCenter.</block>
  <block id="8c796e9ce33123891311630e9843b227" category="paragraph">La configuration des paramètres réseau lors de l'utilisation de vSphere avec des systèmes exécutant ONTAP est simple et similaire à celle des autres configurations réseau. Voici quelques points à prendre en compte :</block>
  <block id="14089d94b95e85f3c910fdfee996412f" category="list-text">NetApp recommande uniquement la désactivation du contrôle de flux réseau sur les ports réseau du cluster dans un cluster ONTAP. NetApp ne recommande pas d'autres recommandations sur les meilleures pratiques pour les ports réseau restants utilisés pour le trafic de données. Vous devez activer ou désactiver si nécessaire. Voir<block ref="3455dc2b3e7cd12a38e508bec690aa67" category="inline-link-rx"></block> pour plus d'informations sur le contrôle de flux.</block>
  <block id="0ced8c876dd50237bb9d7be301c0041e" category="paragraph">Enfin, pour une protection optimale des données, envisagez une configuration VMware vSphere Metro Storage Cluster (vMSC) utilisant NetApp MetroCluster. VMSC est une solution certifiée VMware qui associe la réplication synchrone à la mise en cluster basée sur baie, offrant les mêmes avantages qu'un cluster haute disponibilité, mais distribuée sur des sites distincts pour vous protéger contre les incidents sur site. NetApp MetroCluster propose des configurations économiques pour la réplication synchrone avec restauration transparente en cas de défaillance d'un composant de stockage unique, ainsi qu'une restauration par commande unique en cas d'incident sur site. VMSC est décrit plus en détail dans la section<block ref="252912db8b98e51588a897ab91b985e0" category="inline-link-rx"></block>.</block>
  <block id="49dd4c85a332616209949697018e3112" category="paragraph">Les systèmes qui exécutent ONTAP simplifient la protection de toutes les données au moyen du chiffrement des données au repos. NetApp Storage Encryption (NSE) utilise des lecteurs de disque à chiffrement automatique avec ONTAP pour protéger les données SAN et NAS. NetApp propose également NetApp Volume Encryption et NetApp Aggregate Encryption comme une approche logicielle simple pour le chiffrement des volumes sur tous les disques. Ce chiffrement logiciel ne nécessite pas de disques spéciaux ni de gestionnaires de clés externes. Il est disponible gratuitement pour les clients ONTAP. Vous pouvez procéder à une mise à niveau et commencer à l'utiliser sans perturber vos clients ou applications. Elles sont validées par la norme FIPS 140-2 de niveau 1, y compris le gestionnaire de clés intégré.</block>
  <block id="66149c951df015fb5f7aa252fa92bf64" category="paragraph">La configuration des paramètres réseau lors de l'utilisation de vSphere avec des systèmes exécutant ONTAP est simple et similaire à celle des autres configurations réseau.</block>
  <block id="cd03a9a043676fafd38958ae11e85ca8" category="list-text">NetApp recommande uniquement la désactivation du contrôle de flux réseau sur les ports réseau du cluster dans un cluster ONTAP. NetApp ne recommande pas d'autres recommandations sur les meilleures pratiques pour les ports réseau restants utilisés pour le trafic de données. Vous devez l'activer ou la désactiver si nécessaire. Voir<block ref="3455dc2b3e7cd12a38e508bec690aa67" category="inline-link-rx"></block> pour plus d'informations sur le contrôle de flux.</block>
  <block id="2fd6bc533dedf28bc2b73262be20ec88" category="list-text">*Stockage unifié.* Les systèmes qui exécutent ONTAP sont unifiés de plusieurs manières. À l'origine, cette approche était appelée protocoles NAS et SAN, et ONTAP continue d'être une plateforme SAN de premier plan en plus de ses capacités d'origine dans le stockage NAS. Dans le monde de vSphere, cette approche peut également se traduire par un système unifié d'infrastructure de postes de travail virtuels (VDI) avec une infrastructure de serveurs virtuels (VSI). Les systèmes qui exécutent ONTAP sont généralement moins onéreux pour VSI que les baies d'entreprise traditionnelles, tout en offrant des fonctionnalités avancées d'efficacité du stockage pour la gestion de l'infrastructure VDI dans le même système. ONTAP unifie également une grande variété de supports de stockage, des SSD aux SATA, et peut s'étendre facilement au cloud. Il n'est pas nécessaire d'acheter une baie Flash pour les performances, une baie SATA pour l'archivage ou des systèmes distincts pour le cloud. ONTAP les lie tous ensemble.</block>
  <block id="bfcd75cb17a665212ae0889e787a7330" category="paragraph">Les systèmes qui exécutent ONTAP peuvent utiliser la fonction QoS du stockage pour limiter le débit en Mbit/s et/ou en E/S par seconde (IOPS) de différents objets de stockage comme les fichiers, les LUN, les volumes ou des SVM entiers.</block>
  <block id="5c60617d5730a7a614bfa0383a2affbd" category="admonition">Cela ne s'applique pas aux vVols.</block>
  <block id="b78488659ce8aad3288a0ad7f27c84fb" category="admonition">VVols a besoin des outils ONTAP pour VMware vSphere qui fonctionnent comme le VASA Provider pour ONTAP. Reportez-vous à <block ref="2486a36e844a24e9d1cf22351b1f1514" category="inline-link-macro-rx"></block> la pour connaître les bonnes pratiques vVols.</block>
  <block id="58da89a03db394d8f73b6516f5a75882" category="paragraph">La QoS ONTAP et le contrôle des E/S du stockage VMware vSphere sont des technologies complémentaires que les administrateurs de stockage et vSphere peuvent utiliser conjointement pour gérer les performances des VM vSphere hébergées sur les systèmes exécutant ONTAP. Chaque outil a ses propres forces, comme le montre le tableau suivant. En raison des différents champs d'application de VMware vCenter et de ONTAP, certains objets peuvent être vus et gérés par un système et non par l'autre.</block>
  <block id="bf0dee50832ba16a28008161612fd476" category="paragraph">ONTAP unifie le stockage selon une approche Software-defined simplifiée pour une gestion sécurisée et efficace, des performances améliorées et une évolutivité transparente. Cette approche améliore la protection des données et permet une utilisation efficace des ressources cloud.</block>
  <block id="4021b205a984157ad20475f3b9a2555c" category="paragraph">Une machine virtuelle de stockage (SVM) est l'unité de la colocation sécurisée dans ONTAP. Il s'agit d'une structure logique permettant aux clients d'accéder aux systèmes exécutant ONTAP. Les SVM peuvent transmettre simultanément les données par le biais de plusieurs protocoles d'accès aux données via des interfaces logiques (LIF). Les SVM fournissent un accès aux données de niveau fichier via les protocoles NAS, tels que CIFS et NFS, et un accès aux données de niveau bloc via les protocoles SAN, tels que iSCSI, FC/FCoE et NVMe. Les SVM peuvent fournir des données aux clients SAN et NAS de façon indépendante et en même temps avec S3.</block>
  <block id="a6848cf51eef6140971685faf5c7a111" category="paragraph">Dans le monde de vSphere, cette approche peut également se traduire par un système unifié d'infrastructure de postes de travail virtuels (VDI) avec une infrastructure de serveurs virtuels (VSI). Les systèmes qui exécutent ONTAP sont généralement moins onéreux pour VSI que les baies d'entreprise traditionnelles, tout en offrant des fonctionnalités avancées d'efficacité du stockage pour la gestion de l'infrastructure VDI dans le même système. ONTAP unifie également une grande variété de supports de stockage, des SSD aux SATA, et peut s'étendre facilement au cloud. Il n'est pas nécessaire d'acheter une baie Flash pour les performances, une baie SATA pour l'archivage ou des systèmes distincts pour le cloud. ONTAP les lie tous ensemble.</block>
  <block id="57ee1b10de81b96324fc044045bf301b" category="paragraph">Les outils ONTAP pour VMware vSphere sont un ensemble d'outils permettant d'utiliser le stockage ONTAP avec vSphere. Le plug-in vCenter, précédemment appelé Virtual Storage Console (VSC), simplifie les fonctionnalités de gestion et d'efficacité du stockage, améliore la disponibilité et réduit les coûts de stockage ainsi que les charges opérationnelles, que vous utilisiez SAN ou NAS. Il s'appuie sur les bonnes pratiques pour le provisionnement des datastores et optimise les paramètres d'hôte ESXi pour les environnements de stockage NFS et bloc. Pour tous ces avantages, NetApp recommande d'utiliser ces outils ONTAP comme bonne pratique lors de l'utilisation de vSphere avec les systèmes exécutant ONTAP. Elle comprend une appliance serveur, des extensions d'interface utilisateur pour vCenter, VASA Provider et Storage Replication adapter. La quasi-totalité des outils ONTAP peuvent être automatisés à l'aide d'API REST simples et consommables par la plupart des outils d'automatisation modernes.</block>
  <block id="3a5159fa23e450460f03e5a885a6c51c" category="paragraph">* [NOTE]</block>
  <block id="d235766de3bd77aa4983181862c135d7" category="admonition">Dans ce scénario, le comportement de MetroCluster n'a pas changé et tous les datastores sont toujours intacts sur leurs sites respectifs.</block>
  <block id="14d627875de76f84985b8a3b27c96633" category="list-text">Au cours de cette période, les opérations d'E/S du serveur virtuel ne sont pas affectées, mais les performances sont réduites du fait de l'accès aux données depuis le tiroir disque distant via des liens ISL.</block>
  <block id="290cbdcb6abb203d45786213f3c43662" category="admonition">Pendant cette période, les machines virtuelles restent en cours d'exécution et le comportement de MetroCluster n'a pas changé dans ce scénario. Tous les datastores sont toujours intacts sur leurs sites respectifs.</block>
  <block id="9a18dc3c2c9a217a632ca45b5b93a004" category="admonition">Le maître haute disponibilité ne lance pas les tentatives de redémarrage tant que le gestionnaire des placements n'a pas trouvé le stockage approprié. Dans le cas d'une défaillance complète du site, cela reviendrait à une fois le basculement effectué.</block>
  <block id="e3f530e977d74053c6d70eb84886e756" category="sidebar">Epic</block>
  <block id="faeaec9eda6bc4c8cb6e1a9156a858be" category="sidebar">Disponibilité</block>
  <block id="4289ad5c614f8037a8810e869b56facd" category="sidebar">Consolidation</block>
  <block id="bc967dc2d57e6eff184a821bf7577a80" category="sidebar">Évolutivité</block>
  <block id="86a69bd2f501f95ed83bb7014fac7e30" category="sidebar">Snapshots et clonage</block>
  <block id="58bc025e75c4b3fd1adf3ea672dd4424" category="sidebar">Architecture et design Epic</block>
  <block id="92672a7a2b909945fbfa9f44f057c7a1" category="sidebar">Dimensionnement</block>
  <block id="41b36522e1e1020bad35b072e2f4caeb" category="sidebar">Conditions de stockage</block>
  <block id="ddb04c3c1835c48b34dced1c453450e9" category="sidebar">Configuration et meilleures pratiques</block>
  <block id="3e23b54348b2b8424e24a426570dc9f2" category="sidebar">Utilitaires hôtes</block>
  <block id="6e19e43ad6dccde81e8d288a0c9ce380" category="sidebar">Configuration des LUN et des volumes</block>
  <block id="a2ddb4431dcf2a898d386c1f3b82c926" category="sidebar">Services de fichiers</block>
  <block id="9985b4390c40137573e6da05caf85874" category="sidebar">Protocoles</block>
  <block id="894445e8ea6df545bfbc4247797a2162" category="sidebar">Dimensionnement du stockage</block>
  <block id="051c025eb3cc7303bf3116bffdb7e95d" category="sidebar">Architecture MetroCluster</block>
  <block id="a1930436e8ea74adaf54ff76d868829b" category="sidebar">SQL Server avec MetroCluster</block>
  <block id="33673f825b847c6610f7c7115da0bbde" category="sidebar">Site préféré</block>
  <block id="57848b20be1bd330229089d2e136d982" category="sidebar">Topologie réseau</block>
  <block id="3a1c15502275494d5a57fe7f225fa951" category="sidebar">SQL Server avec SM-AS</block>
  <block id="e30da740afd1eb5c7fc5ade391ee694d" category="sidebar">Configurations Oracle</block>
  <block id="3d9396f3fc3010d09439c0c007a897aa" category="sidebar">Instance unique Oracle</block>
  <block id="87e1ed5a71c4eb8ff653400f9dd917a0" category="sidebar">Oracle RAC et Tiebreakers</block>
  <block id="4a1483b5d5deb83e67e3184b05202d31" category="sidebar">Exemple d'architecture</block>
  <block id="8b7786259860e64596ef2df3349d25e1" category="sidebar">Échec de l'interconnexion du RAC</block>
  <block id="d65b736af70982866f4f95287faab7ac" category="sidebar">Échec de communication SnapMirror</block>
  <block id="9b7da52d3b31b3d0a034473609a069e5" category="sidebar">Échec total de l'interconnexion réseau</block>
  <block id="1163a74136e40a05bc320e61f567a4df" category="sidebar">Panne du site</block>
  <block id="29a8ec19326654cdf89bb8516725720a" category="sidebar">Défaillance du médiateur</block>
  <block id="38ea1deaf691187fc38ab915566310c5" category="sidebar">Restauration du service après une panne</block>
  <block id="9132b772b1437e64c8acac2be79a7a0f" category="sidebar">Basculements manuels</block>
  <block id="05b66cacce7105ad4a548ef5054997f0" category="doc">Paramètres de proximité</block>
  <block id="eccafd14420b568fff639755b251d1bd" category="paragraph">La proximité fait référence à une configuration par cluster qui indique qu'un WWN d'hôte ou un ID d'initiateur iSCSI appartient à un hôte local. Il s'agit d'une deuxième étape facultative de configuration de l'accès aux LUN.</block>
  <block id="d99ea4fad7d0a9010283969d9ddf89aa" category="paragraph">La première étape correspond à la configuration habituelle du groupe initiateur. Chaque LUN doit être mappée sur un groupe initiateur qui contient les ID WWN/iSCSI des hôtes devant accéder à cette LUN. Cela contrôle quel hôte a _accès_ à un LUN.</block>
  <block id="bba32ce1a7b85dd9ba50c49b1a53fe4c" category="paragraph">La deuxième étape facultative consiste à configurer la proximité de l'hôte. Cela ne contrôle pas l'accès, il contrôle _Priority_.</block>
  <block id="98271aec6138a28e374c8f3724a535b6" category="paragraph">Par exemple, un hôte du site A peut être configuré pour accéder à une LUN protégée par la synchronisation active SnapMirror. Le SAN étant étendu entre les sites, les chemins d'accès sont disponibles pour cette LUN via le stockage sur le site A ou le stockage sur le site B.</block>
  <block id="81959299f52ddb567fd902f3e1ae5311" category="paragraph">Sans paramètres de proximité, cet hôte utilisera les deux systèmes de stockage de la même manière, car les deux systèmes de stockage annonceront des chemins actifs/optimisés. Si la latence SAN et/ou la bande passante entre les sites est limitée, il se peut que cela ne soit pas désirable, et vous pouvez vous assurer que, pendant le fonctionnement normal, chaque hôte utilise de préférence des chemins vers le système de stockage local. Cette configuration s'effectue en ajoutant l'ID WWN/iSCSI de l'hôte au cluster local en tant qu'hôte proximal. Cette opération peut être effectuée à partir de l'interface de ligne de commande ou de SystemManager.</block>
  <block id="f08670cf73640d447fb34d01b0f6418f" category="paragraph">Avec un système AFF, les chemins apparaissent comme indiqué ci-dessous lorsque la proximité de l'hôte a été configurée.</block>
  <block id="85a2564342597a065a3926228b7e9fcd" category="paragraph">SQL Server peut être configuré pour fonctionner avec la synchronisation active SnapMirror de plusieurs façons. La bonne réponse dépend de la connectivité réseau disponible, des exigences de RPO et de la disponibilité.</block>
  <block id="d60999416cfb11e4fa51f3dbe7386d64" category="paragraph">Si les solutions SM-AS et MetroCluster sont similaires en termes de fonctionnalité globale, elles présentent d'importantes différences dans la mise en œuvre de la réplication avec un objectif de point de récupération de 0 et sa gestion. Les modes asynchrone et synchrone de SnapMirror peuvent également être utilisés dans le cadre d'un plan de reprise d'activité, mais ils ne sont pas conçus pour être utilisés en tant que technologies de réplication haute disponibilité.</block>
  <block id="e122442a5a5728cd45ffc4ddd170a36f" category="list-text">Une configuration MetroCluster ressemble davantage à un cluster intégré avec des nœuds distribués sur plusieurs sites. SM-AS se comporte comme deux clusters indépendants qui coopèrent pour fournir des LUN répliquées synchrones avec RPO=0 sélectionnés.</block>
  <block id="dbbbd9519f58f000ae618fd3a3f2f38c" category="list-text">Les données d'une configuration MetroCluster ne sont accessibles qu'à partir d'un site particulier à la fois. Une deuxième copie des données est présente sur le site opposé, mais les données sont passives. Il est impossible d'y accéder sans un basculement du système de stockage.</block>
  <block id="72d2ba33caf4a678d0b02c7a4a562662" category="list-text">La mise en miroir des systèmes MetroCluster et SM-AS effectue des opérations à différents niveaux. La mise en miroir MetroCluster s'effectue au niveau de la couche RAID. Les données de bas niveau sont stockées dans un format miroir à l'aide de SyncMirror. L'utilisation de la mise en miroir est pratiquement invisible au niveau des couches LUN, volume et protocole.</block>
  <block id="33613d29368b0b312d33bd204505f12b" category="list-text">En revanche, la mise en miroir SM-AS se produit au niveau de la couche de protocole. Les deux clusters sont globalement indépendants. Une fois les deux copies de données synchronisées, les deux clusters n'ont besoin que de mettre en miroir les écritures. Lorsqu'une écriture a lieu sur un cluster, elle est répliquée sur l'autre. L'écriture est uniquement validée par l'hôte lorsque l'écriture est terminée sur les deux sites. En dehors de ce comportement de fractionnement de protocole, les deux clusters sont des clusters ONTAP normaux.</block>
  <block id="c6ce2d48c3feb0ac105233b1d47d6785" category="list-text">Le rôle principal de MetroCluster est la réplication à grande échelle. Vous pouvez répliquer une baie complète avec un objectif de point de récupération RPO=0 et un objectif de durée de restauration proche de zéro. Le processus de basculement est ainsi simplifié, car il n'y a qu'une seule « chose » à basculer et il offre une excellente évolutivité en termes de capacité et d'IOPS.</block>
  <block id="22c8f7d4250a7117dcec5e795cf01979" category="list-text">L'une des principales utilisations de SM-AS est la réplication granulaire. Parfois, vous ne souhaitez pas répliquer toutes les données en tant qu'unité unique ou vous devez pouvoir basculer sélectivement sur certains workloads.</block>
  <block id="466f5e6d5af96a45aba533d742d1f30e" category="list-text">Autre cas d'utilisation clé de la solution SM-as pour les opérations actives/actives : vous souhaitez que des copies de données entièrement exploitables soient disponibles sur deux clusters différents situés à deux emplacements différents avec des performances identiques et, si vous le souhaitez, vous n'avez pas besoin d'étendre le SAN sur plusieurs sites. Vos applications peuvent déjà s'exécuter sur les deux sites, ce qui réduit le RTO global pendant les opérations de basculement.</block>
  <block id="3ab2196c18fe1cd72bf252059597387b" category="section-title">Synchronisation active NetApp MetroCluster et SnapMirror</block>
  <block id="95da439be4f858e05c58cde4b5946324" category="paragraph">Pour de nombreux clients, la reprise après incident ne suffit pas à posséder une copie distante des données. Il est donc impératif de pouvoir les exploiter rapidement. NetApp propose deux technologies pour répondre à ce besoin : MetroCluster et SnapMirror Active Sync</block>
  <block id="3e6b18011054436086bb6cf813b0cb23" category="section-title">Comparaison SM-AS et MCC</block>
  <block id="4ab72a69aa303ab33d610a6f6e594e68" category="section-title">Checksums</block>
  <block id="0a4a3e3ef29b5fc4ea4e557f166532b4" category="paragraph">La synchronisation active SnapMirror (SM-AS) est basée sur la synchronisation SnapMirror synchrone. Avec MetroCluster, chaque contrôleur ONTAP est responsable de la réplication des données de son disque vers un emplacement distant. Avec la synchronisation active SnapMirror, deux systèmes ONTAP différents conservent des copies indépendantes de vos données LUN, mais fonctionnent ensemble pour présenter une seule instance de ce LUN. Du point de vue de l'hôte, il s'agit d'une entité LUN unique.</block>
  <block id="2f589372957b08ce09879b8a2ab6e58c" category="section-title">Activation de dNFS</block>
  <block id="1a89d30b5bb0e2de334e029001a92f8a" category="paragraph">Oracle dNFS peut fonctionner avec NFSv3 sans aucune configuration nécessaire au-delà de l'activation de la bibliothèque dNFS (voir la documentation Oracle pour la commande spécifique requise). Toutefois, si dNFS ne parvient pas à établir la connectivité, il peut revenir en arrière silencieux au client NFS du noyau. Dans ce cas, les performances peuvent être gravement affectées.</block>
  <block id="9cb0e5a02b9facf3c0e654f08ceceda4" category="paragraph">Si vous souhaitez utiliser le multiplexage dNFS sur plusieurs interfaces, avec NFSv4.X, ou utiliser le chiffrement, vous devez configurer un fichier oranfstab. La syntaxe est extrêmement stricte. De petites erreurs dans le fichier peuvent entraîner l'affichage du démarrage ou le contournement du fichier orangfstab.</block>
  <block id="3c04631b254b4b0e971a2c82517f50cb" category="paragraph">La seule façon d'être certain que dNFS fonctionne comme prévu est d'interroger les tables v$dnfs.</block>
  <block id="21986e459426718105f7dc1a16e88bd0" category="paragraph">Vous trouverez ci-dessous un exemple de fichier oranfstab situé dans /etc Il s'agit de l'un des emplacements multiples où un fichier oranfstab peut être placé.</block>
  <block id="1d4338d2de6e933a6941c8605def3a39" category="paragraph">La première étape consiste à vérifier que dNFS est opérationnel pour les systèmes de fichiers spécifiés :</block>
  <block id="75bc8bd82bedf61e91351f8667b97e13" category="paragraph">Ce résultat indique que dNFS est utilisé avec ces deux systèmes de fichiers, mais que *pas* signifie que oranfstab est opérationnel. Si une erreur était présente, dNFS aurait détecté automatiquement les systèmes de fichiers NFS de l'hôte et il se peut que vous voyiez toujours la même sortie à partir de cette commande.</block>
  <block id="f4327e73856b2069e10b045605d3fbe9" category="paragraph">Les chemins d'accès multiples peuvent être vérifiés comme suit :</block>
  <block id="99dc2d8bc11eb27fb0b920ca969e43e1" category="paragraph">Il s'agit des connexions que dNFS utilise. Deux chemins et canaux sont visibles pour chaque entrée SVRNAME. Cela signifie que les chemins d'accès multiples fonctionnent, ce qui signifie que le fichier oranfstab a été reconnu et traité.</block>
  <block id="d99de907aa06fa04c7b19ffceff68307" category="admonition">Les sections suivantes sont à jour depuis ONTAP 9.15.1, mais le comportement de bail et de verrouillage ainsi que les options de réglage peuvent changer de version à version. Si vous avez besoin d'ajuster les délais de location/verrouillage de NFSv4, veuillez consulter le support NetApp pour obtenir les informations les plus récentes.</block>
  <block id="4bf95f1ea9ecf4f42a7b323970405bb4" category="paragraph">Cette période de grâce contrôle la récupération de bail pendant les modifications de l'interface réseau, mais il existe une deuxième période de grâce qui contrôle la récupération pendant le basculement du stockage<block ref="d75aeb1a8759ea7475fe0ddcd2058ca1" prefix=" " category="inline-code"></block>. Il s'agit d'une option au niveau du nœud.</block>
  <block id="0ba7c8a7759adb519c715ac93fdee2a6" category="paragraph">Par exemple, si vous avez fréquemment besoin d'effectuer des basculements LIF, et que vous devez réduire le délai de grâce, vous changiez .<block ref="b1280b7c6d986647dff33b87ce276327" prefix=" " category="inline-code"></block> Si vous souhaitez améliorer le temps de reprise des E/S pendant le basculement du contrôleur, vous devez le modifier<block ref="d75aeb1a8759ea7475fe0ddcd2058ca1" prefix=" " category="inline-code"></block>.</block>
  <block id="3f3edac1c3ed7bfad53f9d42b9a0c5a7" category="paragraph">Ne modifiez ces valeurs qu'avec prudence et après avoir parfaitement compris les risques et les conséquences. Les pauses E/S liées aux opérations de basculement et de migration avec NFSv4.X ne peuvent pas être entièrement évitées. Les périodes de verrouillage, de bail et de grâce font partie de la RFC NFS. Pour de nombreux clients, NFSv3 est préférable, car les délais de basculement sont plus courts.</block>
  <block id="167503c08e9285f5c4a4a61a0123897b" category="paragraph">Le délai de grâce et la période de location sont connectés. Comme mentionné ci-dessus, le délai de bail par défaut est de 30 secondes, ce qui signifie que les clients NFSv4 doivent s'enregistrer auprès du serveur au moins toutes les 30 secondes, sinon ils perdent leur bail et, à leur tour, leurs verrous. Le délai de grâce existe pour permettre à un serveur NFS de reconstruire les données de bail/verrouillage, et il prend par défaut 45 secondes. Le délai de grâce doit être plus long que la période de location. Cela permet de s'assurer qu'un environnement client NFS conçu pour renouveler les contrats de location au moins toutes les 30 secondes aura la possibilité d'archiver avec le serveur après un redémarrage. Un délai de grâce de 45 secondes garantit que tous les clients qui s'attendent à renouveler leur contrat de location au moins toutes les 30 secondes ont certainement l'occasion de le faire.</block>
  <block id="6be050126f2df5ae7cd944ce446241c2" category="paragraph">Si un délai de 30 secondes n'est pas acceptable, vous pouvez choisir de prolonger la période de location.</block>
  <block id="38d530634a8d32e8775a37109fc08542" category="paragraph">Si vous souhaitez augmenter le délai de bail à 60 secondes pour résister à une panne réseau de 60 secondes, vous devrez également augmenter le délai de grâce. Une pause d'E/S plus longue sera donc nécessaire lors du basculement du contrôleur.</block>
  <block id="ac76821692fdb2dae1d98babe804fb8f" category="paragraph">Ce ne devrait normalement pas être un problème. En général, les utilisateurs ne mettent à jour les contrôleurs ONTAP qu'une ou deux fois par an. En outre, les basculements non planifiés en raison de défaillances matérielles sont extrêmement rares. En outre, si vous aviez un réseau où une panne réseau de 60 secondes était possible, et que le délai de bail était de 60 secondes, vous n'auriez probablement pas à vous opposer à un basculement rare du système de stockage, ce qui aurait entraîné une pause de 61 secondes non plus. Vous avez déjà reconnu que vous disposez d'un réseau qui s'arrête pendant plus de 60 secondes plutôt fréquemment.</block>
  <block id="3a80e1e29c96d0837b12aef65785a41a" category="doc">Paramètres de configuration</block>
  <block id="4bb9f72180425717a416a5037a100cca" category="searchtitle">Structure des fichiers MySQL et InnoDB</block>
  <block id="9a41c04f55c43c1bfac6d1e3fb0992de" category="doc">Tables d'emplacements NFSv3</block>
  <block id="dce12836eeccf070f53590dc5d86633d" category="doc">Tailles de bloc</block>
  <block id="b4aa7c0127688b4c623685cfeed4ab97" category="searchtitle">Oracle Real application clusters expire</block>
  <block id="6fae8d228f324e0e0a9c817b746b9bd0" category="doc">Délais d'expiration du RAC</block>
  <block id="b64e3a0dc81f710f886a442e1a397bb9" category="doc">Outils d'automatisation et de gestion de la base de données</block>
  <block id="87921e5ee2cf87589874871f0d361694" category="doc">Disponibilité de la base de données</block>
  <block id="accd3900cbd3e4d55a38c8518052015c" category="doc">Checksums et intégrité des données</block>
  <block id="5611150a7a2a706d09d267b466f083d6" category="paragraph">Avec une baie de stockage réelle, l'intégrité des données est protégée par des checksums à plusieurs niveaux. Si les données sont corrompues dans un réseau IP, la couche TCP (transmission Control Protocol) rejette les données de paquets et demande la retransmission. Le protocole FC inclut des checksums, tout comme les données SCSI encapsulées. Une fois sur la matrice, ONTAP dispose d'une protection RAID et checksum. Une corruption peut se produire, mais, comme dans la plupart des baies d'entreprise, elle est détectée et corrigée. En général, un disque entier tombe en panne, ce qui invite à une reconstruction RAID et l'intégrité de la base de données n'est pas affectée. Il est toujours possible que des octets individuels sur un disque soient endommagés par le rayonnement cosmique ou par des cellules flash défectueuses. Si cela se produit, la vérification de parité échoue, le disque est mis hors service et la reconstruction RAID démarre. Là encore, l'intégrité des données n'est pas affectée. La dernière ligne de défense est l'utilisation de checksums. Si, par exemple, une erreur de micrologiciel catastrophique sur un disque a corrompu des données d'une manière qui n'a pas été détectée par un contrôle de parité RAID, le checksum ne correspond pas et ONTAP empêche le transfert d'un bloc corrompu avant que la base de données Oracle puisse le recevoir.</block>
  <block id="cd985f59320d95026288fa5ff6dcf58a" category="doc">Sauvegardes en ligne</block>
  <block id="9c030078e0f444e80ad1c24e215220a4" category="doc">Protection des données avec ONTAP</block>
  <block id="6bb9a5aec98309d1414b32f7e0751415" category="doc">Planification de la protection des données</block>
  <block id="06db8225d3ec2b43755ddc9358302450" category="doc">Planification des objectifs de durée de restauration, de point de récupération et des SLA</block>
  <block id="5d827e5d4c92779310224878dc408813" category="summary">Reprise après incident des bases de données Oracle avec MetroCluster</block>
  <block id="f0b223afb696335287bc2ed9501b5b33" category="doc">Reprise d'activité avec MetroCluster</block>
  <block id="67be2475945283126e261087dcc833b7" category="doc">MetroCluster et NVFAIL</block>
  <block id="13262509535baae73d0cc7ab06de1fc6" category="searchtitle">Oracle Extended RAC sur MetroCluster</block>
  <block id="7993038617c805a663d50702c4494b68" category="doc">RAC étendu Oracle</block>
  <block id="75b233b87417347976ef489e09961c77" category="doc">Instance unique Oracle</block>
  <block id="aa51324dbf5137dc80d29f127e7265f1" category="doc">Instance unique Oracle</block>
  <block id="254742fbeffe659f98f802792b541c45" category="doc">Disjoncteur d'attache RAC</block>
  <block id="aeee9c92b22d6f18b8670c9f330ea7c9" category="doc">Échec total de l'interconnectivité réseau</block>
  <block id="0ef819e6ae8a74f9c8ac0158a24b1627" category="doc">Restauration du service</block>
  <block id="8367f9ef79397d7d8f1367cb4392c602" category="summary">Synchronisation active Oracle et SnapMirror - défaillance du site</block>
  <block id="5c8784e46ac32f6b1c9b78f954c1a473" category="summary">Synchronisation active SnapMirror - échec de communication SnapMirror</block>
  <block id="7ed82538ab967cd6e2949aa971158dc9" category="searchtitle">Oracle, la synchronisation active SnapMirror et le médiateur ONTAP</block>
  <block id="db2170f38b52c13c31e0572c709b6f8a" category="searchtitle">Présentation de la synchronisation active Oracle et SnapMirror</block>
  <block id="e9a673980d8df30ed4173e4b7c4ecd2c" category="searchtitle">Site privilégié de synchronisation active Oracle et SnapMirror</block>
  <block id="45d97b0c2ca342ad882153a1245f9897" category="doc">Site préféré de la synchronisation active SnapMirror</block>
  <block id="0bb4536e921f4d96dd701c1afe746457" category="doc">ASMLib/AFD (pilote de filtre ASM)</block>
  <block id="3ee9e6a595247d1965be0d0c6cd0f22e" category="doc">Migration des fichiers de données</block>
  <block id="a9761df551af398a0fc2974288502d8a" category="doc">Copie de données hôte</block>
  <block id="d437e7d8b6513f91bbd58e0b1e08c90b" category="doc">Planification des migrations</block>
  <block id="4c7e0d612a5f0e09f272083633991979" category="doc">Configuration TCP/IP et ethernet</block>
  <block id="9f2dc5f476d250d879dc58a583f93fd1" category="searchtitle">Configuration FC SAN pour les bases de données Oracle</block>
  <block id="08f606415b4ad7fb864651eac04fcd8e" category="searchtitle">Optimisation et évaluation des performances des bases de données Oracle</block>
  <block id="b30e3ef968d39d109aea4a92750c9792" category="doc">Les verrous NFSv3 obsolètes</block>
  <block id="1d19e21de0f93b11f5ceb8b535a3afc2" category="doc">Gestion de la capacité</block>
  <block id="8d409dbefa8e76403d7adf4cbd315d3d" category="doc">Basculement/basculement ONTAP</block>
  <block id="0f03a4e25b68a1a67d3be8f0d989ef8b" category="doc">Gestion des performances grâce à la QoS de ONTAP</block>
  <block id="555472a0fed2f80e0848845e538a08af" category="doc">Oracle Direct NFS (dNFS)</block>
  <block id="92d0288d9e0c6ed5ffd8dcd2e0900101" category="paragraph">Au moment de la rédaction de ce rapport, les chemins d'accès multiples dNFS ne fonctionnent pas avec NFSv4.1 avec les versions récentes d'Oracle Database. Un fichier oranfstab qui spécifie NFSv4.1 comme protocole ne peut utiliser qu'une instruction de chemin unique pour une exportation donnée. La raison en est que ONTAP ne prend pas en charge l'agrégation ClientID. Les correctifs de bases de données Oracle permettant de résoudre cette limitation seront peut-être disponibles à l'avenir.</block>
  <block id="3fdf18c0210b51691df97c8be74021a3" category="doc">Utilitaire de récupération ASM (ASMRU)</block>
  <block id="d63f66214ae30c5b9b10653f1e503492" category="doc">Alignement de LUN</block>
  <block id="38baeef7dc11ad9438aa5b211745d9f6" category="searchtitle">Redimensionnement des LUN de la base de données Oracle et du LVM</block>
  <block id="f447f8c9180e11bc4219ace93e7431fb" category="doc">Redimensionnement des LUN et LVM</block>
  <block id="c8d869d733bd5299001f9d90b9f00d90" category="doc">Dimensionnement des LUN et nombre de LUN</block>
  <block id="4ee97146242ed12473141d7ecad00ee1" category="doc">Tiering de sauvegarde</block>
  <block id="e7cba09a05ca3e6ccdd30a1aa0a7d3af" category="doc">Tiering des journaux d'archivage</block>
  <block id="c1affdf2bd2e606557f2bf12c69af8f8" category="doc">Tiering partiel des fichiers</block>
  <block id="3bf6f5a455b1889775d79713ad4e19ed" category="doc">Stratégies de récupération</block>
  <block id="636d94f9e0fb52c5d7560661b059b203" category="doc">Tiering Snapshot</block>
  <block id="bf5f70c9080724ef27b09203705b1abc" category="doc">Tiering complet de fichiers</block>
  <block id="acf5662e9defb6f8df644e0d8b4caa28" category="doc">Paramètres d'initialisation</block>
  <block id="03095e209912bbf8e40f883c88befe49" category="searchtitle">Protection des données PostgreSQL native</block>
  <block id="300e5ea4a0c7d02b8a4efeba5a1f6faf" category="doc">Protection Ddta native</block>
  <block id="1c3ee6977dcad0709502549dd7b111f3" category="sidebar">Reprise après incident Oracle avec MetroCluster</block>
  <block id="662637dadb14be675de52ed993629bcd" category="paragraph">Pour connaître la profondeur de la file d'attente du système d'exploitation du serveur, utilisez au moins huit LUN (une LUN par volume) pour une base de données. Augmentez le nombre de LUN en fonction du nombre de nœuds dans le cluster ONTAP. Par exemple, ajoutez 4 LUN si vous utilisez un cluster à 4 nœuds (2 paires HA). Pour les environnements de plus grande taille, davantage de LUN peuvent être nécessaires ; utilisez le même nombre de volumes (huit au total, distribués sur un nœud de stockage) et ajoutez des LUN par multiples de deux entre les nœuds et les volumes du cluster. Cette approche vous permet de faire évoluer facilement votre environnement Epic.</block>
  <block id="f73f987e4ea887ccfd1bf297bad46e22" category="paragraph">*Exemple 1 : cluster ONTAP à 2 nœuds*</block>
  <block id="f08ea6531fe21723a28ec9f89ea3e451" category="paragraph">2 nœuds, 1 paire HA 8 volumes, 4 volumes par nœud 8 LUN, une LUN par volume Ajout de 2 LUN supplémentaires, une LUN sur le nœud 01 dans le volume 01, une LUN sur le nœud 02 dans le volume 02.</block>
  <block id="fd52d4fb0b6e3cfb46cae3e012d26c20" category="paragraph">*Exemple 2 : cluster ONTAP à 4 nœuds*</block>
  <block id="489d5412107ca7c901de568b7c7dcce3" category="paragraph">4 nœuds, 2 paires HA 8 volumes, 2 volumes par nœud 8 LUN, une LUN par volume Ajout de 4 LUN supplémentaires, une LUN sur le nœud 01 dans le volume01, une LUN sur le nœud 02 dans le volume02, une LUN sur le nœud 03 dans le volume03, une LUN sur le nœud 04 dans le volume04.</block>
  <block id="2feec0f4e37d9566d4cf292116430adb" category="paragraph">Si le serveur requiert plus de stockage, l'option la plus simple est d'augmenter les LUN contenant des volumes. La seconde option consiste à ajouter des LUN aux groupes de volumes par multiples de deux à la fois (un par volume par nœud).</block>
  <block id="c338b7a4eb0c6f0bb88b444f6c195b01" category="admonition">Si dans un grand environnement nécessitant plus de 4 nœuds ou 8 LUN, consultez notre équipe Epic pour confirmer les conceptions de LUN. L'équipe peut être rejointe sur Epic@NetApp.com.</block>
  <block id="e9afc81d3b8e2990f966bb247fa75a6b" category="list-text">Utilisez 8 LUN dans 8 volumes pour démarrer, en ajoutant 2 LUN à la fois, sur tous les nœuds du cluster.</block>
  <block id="eb75aeb3b4b2b9734ba3e52f5483f0b2" category="inline-link-macro">Documentation de l'ONTAP</block>
  <block id="c5432110ad66f4e2e624118b88a48126" category="list-text">Créez des LUN dont la taille est prévue pour 3 ans de croissance. (Pour connaître la taille maximale de LUN, consultez la<block ref="2a57767dbf71d600f009b2fefab6360d" category="inline-link-macro-rx"></block>.)</block>
  <block id="4631d10aa7c8cd31e9dcf52425c327ee" category="paragraph">Six protocoles sont utilisés pour connecter VMware vSphere aux datastores d'un système exécutant ONTAP :</block>
  <block id="4dc791031dce7528180b933655b6f73e" category="paragraph">FCP, NVMe/FC, NVMe/TCP et iSCSI sont des protocoles en mode bloc qui utilisent VMFS (Virtual machine File System) vSphere pour stocker des machines virtuelles dans des LUN ONTAP ou des namespaces NVMe contenus dans un ONTAP FlexVol volume. NFS est un protocole de fichier qui place les machines virtuelles dans des datastores (qui sont simplement des volumes ONTAP) sans avoir besoin de VMFS. SMB (CIFS), iSCSI, NVMe/TCP ou NFS peuvent également être utilisés directement d'un système d'exploitation invité à ONTAP.</block>
  <block id="6b8f0029ce30f9b4d5fe0def33875511" category="cell">FC</block>
  <block id="81761811d0f769f1e8ab81834167af5c" category="cell">Logiciel de sauvegarde compatible VADP (VMware vStorage APIs for Data protection)</block>
  <block id="50f09c99cf03d7efc83cfdc33047b54f" category="cell">Oui ^1^</block>
  <block id="bb3e0b0b29c5930728585f775194c32b" category="cell">Non ^2^</block>
  <block id="b42c555e5ddbb6a4354369bbdd6b4513" category="cell">V3 uniquement ^2^</block>
  <block id="5543e0c19ec8cfcca651874f8d3b3ff7" category="list-text">*NetApp recommande* l'utilisation de volumes FlexVol pour la plupart des datastores NFS. À partir de ONTAP 9.8, les volumes FlexGroup sont également pris en charge en tant que datastores et sont généralement recommandés pour certaines utilisations. Les autres conteneurs de stockage ONTAP, tels que les qtrees, ne sont généralement pas recommandés, car ils ne sont actuellement pas pris en charge par les outils ONTAP pour VMware vSphere ou par le plug-in NetApp SnapCenter pour VMware vSphere. Cela étant, le déploiement de datastores sous forme de plusieurs qtrees dans un seul volume peut s'avérer utile dans les environnements hautement automatisés qui peuvent bénéficier de quotas au niveau du datastore ou de clones de fichiers de machine virtuelle.</block>
  <block id="c411a2d2bb7111e695dcd16998c5bf03" category="list-text">Les datastores VMFS peuvent également être configurés avec des LUN accessibles via FC et iSCSI. VMFS permet à chaque serveur ESX d'un cluster d'accéder simultanément aux LUN. Les datastores VMFS peuvent être jusqu'à 64 To et comprennent jusqu'à 32 LUN de 2 To (VMFS 3) ou un seul LUN de 64 To (VMFS 5). La taille de LUN maximale de la baie ONTAP est de 128 To sur les systèmes AFF, ASA et FAS. NetApp recommande généralement d'utiliser un LUN unique et volumineux pour chaque datastore. Comme pour NFS, envisagez l'utilisation de plusieurs datastores (volumes) pour optimiser les performances d'un seul contrôleur ONTAP.</block>
  <block id="cb928308729506b7eff5e7791a0ce0ba" category="list-text">Les anciens systèmes d'exploitation invités (OS) devaient s'aligner sur le système de stockage pour obtenir des performances et une efficacité du stockage optimales. Cependant, les systèmes d'exploitation actuels pris en charge par les fournisseurs de Microsoft et de distributeurs Linux tels que Red Hat ne nécessitent plus d'ajustements pour aligner la partition du système de fichiers sur les blocs du système de stockage sous-jacent dans un environnement virtuel. Si vous utilisez un ancien système d'exploitation qui peut nécessiter un alignement, recherchez dans la base de connaissances du support NetApp des articles « alignement des machines virtuelles » ou demandez une copie de l'article TR-3747 à un contact partenaire ou commercial NetApp.</block>
  <block id="2d95becf2e726f81e5f2c0c9447ec2ad" category="paragraph">En général, *NetApp recommande* d'utiliser les outils ONTAP pour l'interface VMware vSphere dans vCenter pour provisionner les datastores traditionnels et vVols afin de s'assurer du respect des bonnes pratiques.</block>
  <block id="3405fd91ec611e14ca0464a159e87d21" category="list-text">Lorsque les baies de stockage VMware ESXi et ONTAP sont connectées aux réseaux de stockage Ethernet, *NetApp recommande* de configurer les ports Ethernet auxquels ces systèmes se connectent en tant que ports de périphérie RSTP (Rapid Spanning Tree Protocol) ou en utilisant la fonction PortFast de Cisco. *NetApp recommande* d'activer la fonctionnalité Spanning-Tree PortFast trunk dans les environnements qui utilisent la fonctionnalité Cisco PortFast et dont l'agrégation VLAN 802.1Q est activée sur le serveur VMware ESXi ou sur les baies de stockage ONTAP.</block>
  <block id="96d48caf96811ccfa373aaf5fbe6f862" category="list-text">*NetApp recommande* les meilleures pratiques suivantes pour l'agrégation de liens :</block>
  <block id="022cc03b844340886b4e892084430269" category="cell">Non ^4^</block>
  <block id="57749a8572dd2708f63cdf198026e062" category="cell">Non ^3^</block>
  <block id="03cba371c1878a590431cec079c6f4c2" category="paragraph">^3^ les LIF du SVM se connectent aux ports, groupes d'interface ou interfaces VLAN disposant de VLAN, MTU et d'autres paramètres. Cependant, les paramètres ne sont pas gérés au niveau de la SVM.</block>
  <block id="7b9dbbe3099a486a2a81a7e43267d3af" category="paragraph">^4^ ces périphériques ont leurs propres adresses IP pour la gestion, mais ces adresses ne sont pas utilisées dans le contexte du réseau de stockage ESXi.</block>
  <block id="d4b27e1b61577e2e3dfeebd3b8129da5" category="list-text">Évitez de partager des volumes entre des hôtes. Par exemple, s'il est possible de créer 2 LUN dans un seul volume et de partager chaque LUN avec un autre hôte, cela peut être évité, car la gestion peut en compliquer la tâche. Dans le cas d'une exécution de plusieurs instances SQL Server sur le même hôte, sauf si vous êtes proche de la limite de volume sur un nœud, évitez le partage de volume et disposez à la place d'un volume distinct par instance et par hôte pour faciliter la gestion des données.</block>
  <block id="e3ea9105e22caf8aa06aee0279a968bb" category="list-text">Le cas échéant, configurez une règle de dimensionnement automatique de volume pour éviter les conditions de manque d'espace.</block>
  <block id="72a9733bd5929d30a93ea680e0c3fad1" category="list-text">Le placement de fichiers secondaires de base de données (dans le cadre d'un groupe de fichiers) sur des volumes distincts améliore les performances de la base de données SQL Server. Cette séparation est valide uniquement si le fichier de la base de données<block ref="937f38432beb92fdba3d47780720bdf7" prefix=" " category="inline-code"></block> ne partage pas son LUN avec d'autres<block ref="937f38432beb92fdba3d47780720bdf7" prefix=" " category="inline-code"></block> fichiers.</block>
  <block id="82d9655a27436534991360ea4c0dc680" category="paragraph">La base de données tempdb peut être largement utilisée. Outre le placement optimal des fichiers de base de données utilisateur sur ONTAP, le placement des fichiers de données tempdb est également essentiel pour réduire les conflits d'allocation. Tempdb doit être placé sur un disque distinct et non partagé avec les fichiers de données utilisateur.</block>
  <block id="5c4a7832da0e9f8799089fdc985bb9b3" category="list-text">Le fichier de données tempdb doit être créé avec la même taille</block>
  <block id="20453a1c8627ad0bc536be210636fa41" category="paragraph">L'exemple de script suivant modifie tempdb en créant huit fichiers tempdb de taille égale et en déplaçant tempdb vers le point de montage<block ref="ae6fbe62f3ddc46fa9a9885244d23675" prefix=" " category="inline-code"></block> pour SQL Server 2012 et versions ultérieures.</block>
  <block id="3f808654ebfed6aae875b71a402ac91b" category="inline-link-macro">Avis pour ONTAP 9.16.1</block>
  <block id="afb530fcc81b2978f808bd5327a32c87" category="inline-link-macro">Avis pour ONTAP 9.16.0</block>
  <block id="d804afb237a517c556722013a1b8ec73" category="inline-link-macro">Avis pour ONTAP 9.15.1</block>
  <block id="5f016d328522d91c512269e0786e144d" category="inline-link-macro">Avis pour ONTAP 9.15.0</block>
  <block id="98ea16e049d26c017c083e3896766015" category="inline-link-macro">Avis pour ONTAP 9.14.1</block>
  <block id="2a0d0e639657d07a66d55606242f8863" category="inline-link-macro">Avis pour ONTAP 9.14.0</block>
  <block id="d13ca0508189923e4791d61e82518903" category="paragraph"><block ref="ee254fc53b05f67f41ce3314151253c2" category="inline-link-macro-rx"></block> <block ref="83cffbd8d99e434b2f5f3940f69ff8e4" category="inline-link-macro-rx"></block> <block ref="23ce2232a13ec581d8a1f356c5cc2645" category="inline-link-macro-rx"></block> <block ref="4d4f1ffb0dbcd5627ca696d020c34dce" category="inline-link-macro-rx"></block> <block ref="d16c9b11843460f788b4709fb5f6f9c0" category="inline-link-macro-rx"></block> <block ref="5032e7169b10b3f96d6c299a82923a0e" category="inline-link-macro-rx"></block> <block ref="f7a2b1db149ed9886af0ce846dbc3e14" category="inline-link-macro-rx"></block> <block ref="b349c509ad858348b30db7e73307e3aa" category="inline-link-macro-rx"></block> <block ref="0dce234dfded58bd461541473b86e42a" category="inline-link-macro-rx"></block> <block ref="9760ec4df13f0afbdfec88ae16c871ae" category="inline-link-macro-rx"></block> <block ref="b6dab2933dfb92cf0c1355707a4aec7c" category="inline-link-macro-rx"></block> <block ref="1b7c80b26162b03bd0addd587f70df55" category="inline-link-macro-rx"></block> <block ref="14faf912aa42102a6628af4551e02583" category="inline-link-macro-rx"></block> <block ref="a90f36d649d3be5d386cc3563ab044fb" category="inline-link-macro-rx"></block> <block ref="2cd65b4a044075cfd9ad4a91f42fdff4" category="inline-link-macro-rx"></block> <block ref="5e764cc3fdcc19ff667796e414159bdc" category="inline-link-macro-rx"></block> <block ref="561451f09c7bca700ea0d7833cd9e92e" category="inline-link-macro-rx"></block> <block ref="d23d341a344216fbf99a91152429d49c" category="inline-link-macro-rx"></block> <block ref="b35e8fbd7b0369b23734510994911ec4" category="inline-link-macro-rx"></block> <block ref="41d4305cf7a6acb595086f123121a781" category="inline-link-macro-rx"></block> <block ref="ea685649fabe77da53e843fec56f72b8" category="inline-link-macro-rx"></block></block>
  <block id="c9e7f99d53af8a795853cdf25af30b41" category="section-title">ONTAP Mediator pour les configurations IP MetroCluster</block>
  <block id="f6cab8e78e70dc1f9720a3ef038776e0" category="inline-link-macro">9.9.1 Avis concernant le médiateur ONTAP pour les configurations IP MetroCluster</block>
  <block id="ebe991cfd03b446bbf8687699ccbd660" category="inline-link-macro">9.8 Avis concernant le médiateur ONTAP pour les configurations IP MetroCluster</block>
  <block id="2db41096b15f25232cba7341c2140448" category="inline-link-macro">9.7 Avis concernant le médiateur ONTAP pour les configurations IP MetroCluster</block>
  <block id="f81cc577527b8b7cad4405edd62a83d4" category="paragraph"><block ref="3e82164cf34143fb60c8ff9df8c41c0a" category="inline-link-macro-rx"></block> <block ref="d53517b81c95b1c10115cf953ff553c1" category="inline-link-macro-rx"></block> <block ref="b1bde49b948d4004f51f0cd5e9a9e990" category="inline-link-macro-rx"></block></block>
  <block id="89a8982c5b7248833ca5b092a530069e" category="admonition">Bien que les systèmes ONTAP vous permettent de coupler des SVM au sein du même cluster pour la réplication SnapMirror, ce scénario n'est pas testé et certifié avec SRM. Par conséquent, il est recommandé d'utiliser uniquement des SVM provenant de différents clusters lors de l'utilisation de SRM.</block>
  <block id="7d90174e2cb3f5e3051541506c8587b4" category="list-text">Utilisez les outils ONTAP pour VMware vSphere pour provisionner les datastores, car ils simplifient automatiquement la gestion des règles d'exportation.</block>
  <block id="4ac7ffa40244bc8345591768f8411745" category="list-text">Utilisez la fonction de montage du plug-in pour appliquer les datastores existants aux nouveaux serveurs.</block>
  <block id="adf5380025d4004543deef73a471bbd5" category="inline-link-macro">Fonctionnalité NFSv3 nconnect avec NetApp et VMware</block>
  <block id="f9f508df0fe89d92476e598965812f69" category="list-text">Toutes les versions de VMware vSphere actuellement prises en charge peuvent utiliser NFS v3 et v4.1. Le support officiel de nconnect a été ajouté à vSphere 8.0 mise à jour 2 pour NFS v3 et mise à jour 3 pour NFS v4.1. Pour NFS v4.1, vSphere continue à prendre en charge l'agrégation de sessions, l'authentification Kerberos et l'authentification Kerberos avec intégrité. Il est important de noter que l'agrégation de session nécessite ONTAP 9.14.1 ou une version ultérieure. Vous pouvez en savoir plus sur la fonction nconnect et sur la manière dont elle améliore les performances à <block ref="8bbf9cc2e5403eec56b8cc2f4bd74d68" category="inline-link-macro-rx"></block>.</block>
  <block id="81439479f2f4c0fa8c28668334fa82bd" category="list-text">La valeur maximale de nconnect dans vSphere 8 est 4 et la valeur par défaut est 1. La limite de valeur maximale dans vSphere peut être augmentée par hôte grâce à des paramètres avancés, mais elle n'est généralement pas nécessaire.</block>
  <block id="b279126f58fd7f43a55f5efc8596bcea" category="list-text">Une valeur de 4 est recommandée pour les environnements nécessitant des performances supérieures à celles d'une seule connexion TCP.</block>
  <block id="9d676095b7ff8ea1b1779bc58fb32a92" category="list-text">Sachez que ESXi a une limite de 256 connexions NFS et que chaque connexion nconnect compte pour ce total. Par exemple, deux datastores avec nconnect=4 compteraient comme huit connexions au total.</block>
  <block id="efdc45c7bd15d84f5bcb4df0560d6d3a" category="list-text">Il est important de tester l'impact de nconnect sur les performances de votre environnement avant d'implémenter des modifications à grande échelle dans les environnements de production.</block>
  <block id="d1801a2d87a0325c6c691a74f5d1ffef" category="list-text">Notez que NFS v3 et NFS v4.1 utilisent différents mécanismes de verrouillage. NFS v3 utilise un verrouillage côté client, tandis que NFS v4.1 utilise un verrouillage côté serveur. Bien qu'un volume ONTAP puisse être exporté via les deux protocoles, ESXi ne peut monter qu'un datastore via un protocole. Cependant, cela ne signifie pas que d'autres hôtes ESXi ne peuvent pas monter le même datastore via une version différente. Pour éviter tout problème, il est essentiel de spécifier la version du protocole à utiliser lors du montage, en veillant à ce que tous les hôtes utilisent la même version et, par conséquent, le même style de verrouillage. Il est essentiel d'éviter de mélanger les versions NFS entre les hôtes. Si possible, utilisez les profils hôtes pour vérifier la conformité.</block>
  <block id="c17658fd7af3bb19a0f047cb1e006186" category="list-text">Les règles d'export NFS permettent de contrôler l'accès des hôtes vSphere. Vous pouvez utiliser une seule règle avec plusieurs volumes (datastores). Avec NFS, ESXi utilise le style de sécurité sys (UNIX) et requiert l'option de montage racine pour exécuter les VM. Dans ONTAP, cette option est appelée superutilisateur et, lorsque l'option superutilisateur est utilisée, il n'est pas nécessaire de spécifier l'ID utilisateur anonyme. Notez que les règles d'export-policy avec des valeurs différentes pour<block ref="ea72d12ecaa06afdb0c8a3b15e485e95" prefix=" " category="inline-code"></block> et<block ref="df809a941c1287d18c08bb5927b639dc" prefix=" " category="inline-code"></block> peuvent causer des problèmes de découverte de SVM avec les outils ONTAP. Les adresses IP doivent être séparées par des virgules, sans espaces dans les adresses de port vmkernel qui montés dans les datastores. Voici un exemple de règle de stratégie :</block>
  <block id="a001b05a0a70d03d708c133c88072a2b" category="list-text">Liste des noms d'hôte, adresses IP, groupes réseau ou domaines correspondant au client : 192.168.42.21,192.168.42.22</block>
  <block id="0106a8755025c8789c58f6ca3db3cd93" category="list-text">Règle d'accès RO : tous</block>
  <block id="1c66db8bac919c3f29211badf0369156" category="list-text">Règle d'accès RW : tous</block>
  <block id="193fc1ecf90841d52215e705d60caa7b" category="list-text">ID utilisateur auquel les utilisateurs anonymes sont mappés : 65534</block>
  <block id="f913a13d0c2cb8f8dd45dc1479901025" category="list-text">Types de sécurité superutilisateur : tous</block>
  <block id="e44d8f7f976db169814f15c0e3c91250" category="list-text">Honorez les bits setuid dans SETATTR : TRUE</block>
  <block id="c154c7fcb68e62b069047ccff2521dc0" category="list-text">Autoriser la création de périphériques : vrai</block>
  <block id="71168bd99a960bfb425e723f5750b3fc" category="list-text">Si le plug-in NetApp NFS pour VMware VAAI est utilisé, le protocole doit être défini comme<block ref="2521ef5d58fc027d3121662b7d8f9ac2" prefix=" " category="inline-code"></block> lors de la création ou de la modification de la règle d'export policy. Le protocole NFSv4 est requis pour que le déchargement des copies VAAI fonctionne, et la spécification du protocole comme<block ref="2521ef5d58fc027d3121662b7d8f9ac2" prefix=" " category="inline-code"></block> inclut automatiquement les versions NFSv3 et NFSv4. Cette opération est requise même si le type de datastore est créé en tant que NFS v3.</block>
  <block id="dd68c690edda5e0630944465c5950d11" category="list-text">Protocole d'accès : nfs</block>
  <block id="4d6306be791d29381011bb901e0351d5" category="list-text">Comparaison avec le client : 192.168.42.21,192.168.42.22</block>
  <block id="62297138e048f9159339e4709b23cd2f" category="list-text">En tant que LUN connectée iSCSI ou espace de noms connecté à NVMe/TCP, accessible et contrôlé par un initiateur logiciel à partir d'un système d'exploitation invité de machine virtuelle</block>
  <block id="6bc78ccffdd069cded655f73dc33debc" category="paragraph">ESXi 6 a également pris en charge jusqu'à 256 LUN et jusqu'à 1,024 chemins d'accès au total aux LUN. ESXi ne voit pas de LUN ni de chemins au-delà de ces limites. En supposant un nombre maximum de LUN, la limite de chemin autorise quatre chemins par LUN. Dans un cluster ONTAP plus grand, il est possible d'atteindre la limite de chemin avant la limite de LUN. Pour résoudre cette limitation, ONTAP prend en charge le mappage de LUN sélectif (SLM) dans la version 8.3 et les versions ultérieures.</block>
  <block id="7eae63bf83e6298ab64a2dd5e2544df9" category="inline-link-macro">Outil VMware Configuration Maximums</block>
  <block id="ee1c3928454779ec08bd2d50271b6621" category="admonition">Reportez-vous au <block ref="ca32979bcc653e1966d3624ee8d76604" category="inline-link-macro-rx"></block>pour connaître les limites les plus récentes prises en charge dans ESXi.</block>
  <block id="387b349695476180bf90cc1891288318" category="list-text">Vérifiez <block ref="1f38ac07598dbb4b06912539aafa4211" category="inline-link-macro-rx"></block> les paramètres recommandés par NetApp en collaboration avec VMware.</block>
  <block id="9c4a21e654649a6a5201381ce4ba6cbd" category="paragraph">Les tableaux suivants présentent les fonctionnalités de datastore traditionnel prises en charge par vSphere avec ONTAP. Ces informations ne s'appliquent pas aux datastores vvols, mais elles s'appliquent généralement aux versions vSphere 6.x et ultérieures utilisant des versions ONTAP prises en charge. Vous pouvez également consulter le <block ref="ca32979bcc653e1966d3624ee8d76604" category="inline-link-macro-rx"></block> pour connaître les versions de vSphere spécifiques afin de confirmer les limites spécifiques.</block>
  <block id="d325729822747316770c21019ec914ac" category="paragraph">^1^ *NetApp recommande* d'utiliser iSCSI dans l'invité pour les clusters Microsoft plutôt que des VMDK compatibles avec les enregistreurs multiples dans un datastore VMFS. Cette approche est entièrement prise en charge par Microsoft et VMware. Elle offre une grande flexibilité avec ONTAP (SnapMirror vers les systèmes ONTAP sur site ou dans le cloud), est facile à configurer et à automatiser, et peut être protégée avec SnapCenter. VSphere 7 ajoute une nouvelle option VMDK en cluster. Cette approche est différente des VMDK compatibles avec plusieurs enregistreurs, qui requièrent un datastore présenté via le protocole FC pour lequel la prise en charge de VMDK en cluster est activée. D'autres restrictions s'appliquent. Consultez la documentation de VMware <block ref="46658ede14d15d79e2a20c75a7b15bb2" category="inline-link-macro-rx"></block>pour obtenir des instructions de configuration.</block>
  <block id="27071f484b59aa9ce5f5cffcefefd481" category="paragraph">Les datastores ^2^ utilisant NVMe-of et NFS v4.1 requièrent une réplication vSphere. La réplication basée sur les baies pour NFS v4.1 n'est pas actuellement prise en charge par SRM. La réplication basée sur la baie avec NVMe-of n'est actuellement pas prise en charge par l'outil ONTAP pour VMware vSphere Storage Replication adapter (SRA).</block>
  <block id="f992800e6b8aa5ca675e5d1c9fd9950c" category="summary">SnapCenter vous permet de créer des règles de sauvegarde qui peuvent être appliquées à plusieurs tâches. Ces règles peuvent définir des fonctionnalités de planification, de conservation, de réplication et autres. Ils continuent d'autoriser une sélection facultative de snapshots cohérents avec les machines virtuelles, ce qui exploite la capacité de l'hyperviseur à suspendre les E/S avant de prendre un snapshot VMware.</block>
  <block id="0a99e5aa10081a6cc2cd756764a791f5" category="inline-link-macro">Limites des snapshots</block>
  <block id="aa5047ea08cd6ab5089b7e97962beef9" category="paragraph">SnapCenter vous permet de créer des règles de sauvegarde qui peuvent être appliquées à plusieurs tâches. Ces règles peuvent définir des fonctionnalités de planification, de conservation, de réplication et autres. Ils continuent d'autoriser une sélection facultative de snapshots cohérents avec les machines virtuelles, ce qui exploite la capacité de l'hyperviseur à suspendre les E/S avant de prendre un snapshot VMware. Cependant, en raison de l'impact des snapshots VMware sur les performances, ils ne sont généralement pas recommandés sauf si vous devez suspendre le système de fichiers invité. Utilisez plutôt les snapshots pour une protection générale et des outils applicatifs tels que les plug-ins SnapCenter pour protéger les données transactionnelles comme SQL Server ou Oracle. Ces snapshots sont différents des snapshots VMware (cohérence) et conviennent à une protection à long terme. Les snapshots VMware sont uniquement recommandés pour une utilisation à court terme en raison des performances et d'autres effets. Voir <block ref="edb84c63886608dd2a747873a2732130" category="inline-link-macro-rx"></block>pour plus de détails.</block>
  <block id="029b7a5fa374f35f7d7eb7c6b5c66f41" category="paragraph">Ces plug-ins offrent des fonctionnalités étendues pour protéger les bases de données dans les environnements physiques et virtuels. VSphere permet de protéger les bases de données SQL Server ou Oracle dans lesquelles les données sont stockées sur des LUN RDM, des LUN iSCSI directement connectées au système d'exploitation invité ou des fichiers VMDK dans des datastores VMFS ou NFS. Les plug-ins permettent de spécifier différents types de sauvegardes de bases de données, de prendre en charge la sauvegarde en ligne ou hors ligne et de protéger les fichiers de base de données ainsi que les fichiers journaux. Outre la sauvegarde et la restauration, les plug-ins prennent également en charge le clonage des bases de données à des fins de développement ou de test.</block>
  <block id="aa4e326f7359bc14116e671e7002dd80" category="paragraph">ONTAP propose un stockage bloc haute performance pour VMware vSphere à l'aide d'iSCSI classiques et du protocole FCP (Fibre Channel Protocol). Il prend également en charge NVMe/FC et NVMe/TCP, le protocole bloc nouvelle génération hautement efficace et performant, NVMe over Fabrics (NVMe-of).</block>
  <block id="69ed4612751aa53c36bfb06723b9ac3c" category="inline-link-macro">Datastores et protocoles - SAN</block>
  <block id="6ed827bb740ef6ae13ba33875f09bd4d" category="paragraph">Pour connaître les meilleures pratiques détaillées en matière d'implémentation de protocoles par blocs pour le stockage de machines virtuelles avec vSphere et ONTAP, reportez-vous à la section <block ref="851570383af5746336da824a0a2590e1" category="inline-link-macro-rx"></block></block>
  <block id="080533926d0a5f93ded730459d8fe38e" category="paragraph">VSphere permet aux clients d'utiliser des baies NFS de classe entreprise pour fournir un accès simultané aux datastores à tous les nœuds d'un cluster ESXi. Comme mentionné dans cette <block ref="72b655a9973dbed02099f5e63762d591" category="inline-link-macro-rx"></block> section, NFS avec vSphere offre des avantages en termes de visibilité sur la facilité d'utilisation et l'efficacité du stockage.</block>
  <block id="d9243800afbb4af685507413cda85fb3" category="inline-link-macro">Datastores et protocoles - NFS</block>
  <block id="5b17d236da497a1c9e5d89b42dfc8264" category="paragraph">Pour connaître les meilleures pratiques recommandées, reportez-vous à la section <block ref="75fda850433b3639ed71701079d043be" category="inline-link-macro-rx"></block></block>
  <block id="d240aead1fe438e9f66d54e3cebb7e47" category="paragraph">Voici les paramètres d'hôte recommandés pour toutes les versions de ONTAP actuellement prises en charge.</block>
  <block id="11d0e9e8442c67c812829427e008eb11" category="inline-link-macro">Récupération d'espace pour les machines virtuelles VMFS5</block>
  <block id="fef769c2e7ba3ba16273c3c81c47ed9e" category="cell">Conserver la valeur par défaut (0), mais peut être modifiée si nécessaire. Pour plus d'informations, voir <block ref="9b26e5c0136d6a9ffe3ef541d9621427" category="inline-link-macro-rx"></block></block>
  <block id="c99694bb5336dd37a10341183ec8a950" category="inline-link-macro">VMware KB 2069356</block>
  <block id="e6c0dd75e5461550c4a0e5988151488a" category="list-text">Dans les environnements hautes performances ou lors des tests de performances avec un seul datastore LUN, envisagez de modifier le paramètre d'équilibrage de charge de la règle de sélection de chemin Round-Robin (VMW_PSP_RR) entre la valeur de 1000 IOPS par défaut et la valeur de 1. Voir <block ref="1687988694c35db61b845d7b15620672" category="inline-link-macro-rx"></block> pour plus d'informations.</block>
  <block id="2f5a0569065e71943058f8fb26e3e8da" category="inline-link">Modifier les paramètres par défaut pour le tour de latence</block>
  <block id="18aa403816c42116dbae93c18dc9ce38" category="list-text">Dans vSphere 6.7 mise à jour 1, VMware a introduit un nouveau mécanisme d'équilibrage de la charge de latence pour la PSP Round Robin. La nouvelle option prend en compte la bande passante d'E/S et la latence de chemin lors de la sélection du chemin optimal pour les E/S. Il peut être utile de l'utiliser dans des environnements avec une connectivité de chemin non équivalente, par exemple dans des cas où plusieurs sauts réseau sont sur un chemin plus grand que sur un autre, ou lors de l'utilisation d'un système NetApp All SAN Array (ASA). Voir<block ref="d244127cef9364538ba1012ad8871adc" category="inline-link-rx"></block> pour plus d'informations.</block>
  <block id="da151950bd7f77d4d82f31a151e48d86" category="paragraph">Pour FCP et iSCSI avec vSphere 7, des informations supplémentaires sont disponibles à l'adresse <block ref="ad69e690a8561a2cf3328cde094252f4" category="inline-link-macro-rx"></block> pour FCP et iSCSI avec vSphere 8. Vous trouverez plus de détails à l'adresse <block ref="0b6ab7c7c874850b69a7bdde572cc0ce" category="inline-link-macro-rx"></block> concernant NVMe-of avec vSphere 7. Des informations plus détaillées sont disponibles à l'adresse <block ref="72dcc917faa9346f108bcba624c6b54f" category="inline-link-macro-rx"></block> concernant NVMe-of avec vSphere 8. Des informations plus détaillées sont disponibles à l'adresse <block ref="6388c35b35c0c848de96298937e342cf" category="inline-link-macro-rx"></block></block>
  <block id="b565c40b717c5d84ecaff52fbb94903d" category="paragraph">Annoncé pour la première fois en 2012, NetApp a été l'un des premiers partenaires de conception avec VMware dans le développement de VMware vSphere APIs for Storage Awareness (VASA), la base de la gestion basée sur des règles de stockage (SPBM) avec des baies de stockage d'entreprise. Avec cette approche, la gestion du stockage granulaire des ordinateurs virtuels était limitée au stockage VMFS et NFS.</block>
  <block id="e01da3b454da14823394d0b9b3fac1d6" category="section-title">Volumes virtuels (vVols)</block>
  <block id="b077cca6e6fd5e690157294fd7f87e08" category="paragraph">Les vVols sont une architecture de stockage révolutionnaire qui permet la gestion granulaire du stockage des machines virtuelles. Le stockage peut ainsi être géré non seulement par machine virtuelle (y compris les métadonnées des machines virtuelles), mais également par VMDK. Les vVols sont un composant clé de la stratégie Software Defined Data Center (SDDC) qui constitue la base de VMware Cloud Foundation (VCF), fournissant ainsi une architecture de stockage plus efficace et évolutive pour les environnements virtualisés.</block>
  <block id="7dba0dd24357e8a19109bbbf7f689fb2" category="paragraph">Les vVols permettent aux machines virtuelles de consommer du stockage par machine virtuelle, car chaque objet de stockage de machine virtuelle est une entité unique dans NetApp ONTAP. Avec les systèmes ASA r2 qui ne nécessitent plus de gestion de volume, chaque objet de stockage VM est une unité de stockage unique sur la baie et peut être contrôlé de manière indépendante. Cela permet de créer des règles de stockage qui peuvent être appliquées aux machines virtuelles individuelles ou aux VMDK (et ainsi aux unités d'exploitation doubles), fournissant un contrôle granulaire sur les services de stockage tels que les performances, la disponibilité et la protection des données.</block>
  <block id="f467f22eb6ec5b3e0694963b3f16ebc2" category="section-title">Gestion du stockage basée sur des règles (SBPM)</block>
  <block id="05ba8cf72b56cd6a89d699c0a922d186" category="paragraph">Grâce à la gestion du stockage basée sur des règles, une structure sert de couche d'abstraction entre les services de stockage disponibles pour votre environnement de virtualisation et les éléments de stockage provisionnés via des règles. Cette approche permet aux architectes du stockage de concevoir des pools de stockage avec des fonctionnalités différentes. Ces pools peuvent être facilement consommés par les administrateurs des VM. Les administrateurs peuvent ensuite faire correspondre les besoins des charges de travail des machines virtuelles aux pools de stockage provisionnés. Cette approche simplifie la gestion du stockage et permet une utilisation plus efficace des ressources de stockage.</block>
  <block id="4e1ae190f1f93f025754e7944927b697" category="paragraph">Le SBPM est un composant clé des vVols qui fournit un framework basé sur des règles pour la gestion des services de stockage. Les règles sont créées par les administrateurs vSphere à l'aide de règles et de fonctionnalités exposées par le VASA Provider(VP) du fournisseur. Il est possible de créer des règles pour différents services de stockage, tels que les performances, la disponibilité et la protection des données. Il est possible d'attribuer des règles à des machines virtuelles ou des VMDK individuels pour assurer un contrôle granulaire des services de stockage.</block>
  <block id="ac0bb89f2c9215fb6f1280fb1d88d213" category="section-title">NetApp ONTAP et vVols</block>
  <block id="1402ced4d3888a58c5af1059e38ea6b4" category="paragraph">NetApp ONTAP est leader du secteur du stockage en vVols à l'échelle du cluster, prenant en charge des centaines de milliers de vVols* par cluster unique. En revanche, les fournisseurs de baies d'entreprise et de baies Flash plus petites prennent en charge jusqu'à plusieurs milliers de vVols par baie. ONTAP offre une solution de stockage évolutive et efficace pour les environnements VMware vSphere, prenant en charge les vVols avec un ensemble complet de services de stockage, dont la déduplication, la compression, le provisionnement fin et la protection des données. La gestion du stockage basée sur des règles facilite l'intégration transparente aux environnements VMware vSphere.</block>
  <block id="6070863553bff7655694da4be22f793e" category="paragraph">Nous avons mentionné précédemment que les administrateurs des ordinateurs virtuels peuvent consommer de la capacité sous forme de pools de stockage. Pour ce faire, nous utilisons des conteneurs de stockage représentés dans vSphere en tant que datastores logiques.</block>
  <block id="67fd8c9c20e6ac877f87b28741218bf1" category="paragraph">Les conteneurs de stockage sont créés par les administrateurs du stockage et servent à grouper les ressources de stockage consommées par les administrateurs des VM. Les conteneurs de stockage peuvent être créés différemment en fonction du type de système ONTAP que vous utilisez. Avec les clusters ONTAP 9 classiques, un ou plusieurs volumes FlexVol soutiennent ensemble le pool de stockage. Avec les systèmes ASA r2, l'intégralité du cluster correspond au pool de stockage.</block>
  <block id="5db11f8fed5bd72f359ab9469069dffa" category="summary">Liste de contrôle d'installation des outils ONTAP 10</block>
  <block id="a5d727df2ce2d168bae39c78df4b9054" category="doc">Liste de contrôle</block>
  <block id="7aed7b3182cbdda9aceb9c8f8b3c2dbe" category="paragraph">Utilisez cette liste de contrôle d'installation pour garantir un déploiement réussi (mise à jour pour 10.3 et versions ultérieures).</block>
  <block id="06c2cea18679d64399783748fa367bdd" category="inline-image-macro">Une seule</block>
  <block id="1e90f607d380c9ee51b487edec3975fa" category="list-title"><block ref="58f667aaf05f87159670e12bd9bc076b" category="inline-image-macro-rx" type="image"></block> Planification initiale</block>
  <block id="4f04d17639e7b735b12137c9c18a4ab8" category="list-text">Avant de commencer l'installation, vous devez vérifier<block ref="5f4d65abf1f4ea058efeaa8d75e7e1ba" category="inline-link-rx"></block> que votre déploiement a été certifié.</block>
  <block id="5541521d8d465590f0919510f29154b2" category="inline-link">Limites de configuration pour le déploiement des outils ONTAP pour VMware vSphere</block>
  <block id="225d03736b7d93585b216af68e8caa12" category="list-text">Déterminez la taille et le type d'outils ONTAP nécessaires à la configuration de votre environnement. Pour plus d'informations, reportez-vous au<block ref="de0a48be1b1ae6c0ec73a4762c1d7abf" category="inline-link-rx"></block>.</block>
  <block id="e5cd295f99866f601e300eb40641d85c" category="list-text">Déterminez si vous utiliserez des SVM mutualisés ou autorisez l'accès complet au cluster. En cas d'utilisation de SVM mutualisés, vous devrez disposer d'une LIF de gestion de SVM sur chaque SVM à utiliser. Cette LIF doit être accessible via le port 443 par les outils ONTAP.</block>
  <block id="c56feb728c490e11ea8eba91afce9419" category="list-text">Déterminez si vous allez utiliser ONTAP Tools Storage Replication adapter (SRA) pour VMware site Recovery Manager (SRM) ou Live site Recovery (VLSR). Si tel est le cas, vous devrez accéder à l'interface de gestion du serveur SRM/VLSR pour installer SRA.</block>
  <block id="15ee84770ceab89b9fe30ec618843c01" category="inline-link">Créez une relation entre clusters dans ONTAP</block>
  <block id="bfbb5bcd0f88a18adcc2741da1b9063a" category="inline-link">Créer une relation de pairs SVM intercluster dans ONTAP</block>
  <block id="d8a2601707345eab1d4df3e541d61f3c" category="list-text">Si vous utilisez la réplication SnapMirror gérée par les outils ONTAP (y compris, mais sans s'y limiter, la synchronisation active SnapMirror), votre administrateur ONTAP doit<block ref="f4be9e71a34420e69a7db6d0cf97d232" category="inline-link-rx"></block> et<block ref="42356490ef97c026f7c04a9cb9eeee7d" category="inline-link-rx"></block> avant de pouvoir utiliser les outils ONTAP avec SnapMirror.</block>
  <block id="801ab24683a4a8c433c6eb40c48bcd9d" category="inline-link">Télécharger</block>
  <block id="18f5114f4a595ad26525bf20f301ce19" category="list-text"><block ref="20462cf0cb6f4e0f9c91cc66c831d98e" category="inline-link-rx"></block> Les outils ONTAP OVA et, si nécessaire, le fichier SRA tar.gz.</block>
  <block id="aada29daee1d64ed0fe907043855cb7e" category="inline-image-macro">Deux</block>
  <block id="770c8023395525bc05b5a8fc2e6efa8b" category="list-title"><block ref="54f425ce8d89f4ed6b8a546561af5d60" category="inline-image-macro-rx" type="image"></block> Provisionnez les adresses IP et les enregistrements DNS</block>
  <block id="08b0c7e27d2f1780fce59893f12e7642" category="list-text">Adresse de l'application des outils ONTAP \_____\_____ . \_____\_____ . \_____\_____ . \_____\____</block>
  <block id="6bb090d29a0e3de8cc001d02c1e8a7b3" category="list-text">Adresse des services internes \_____\_____ . \_____\_____ . \_____\_____ . \_____\____</block>
  <block id="e32a9122e97bf17560b53c6993301629" category="list-text">Nom d'hôte DNS du nœud 1 \_____\_____\________\_______\________\________\_________</block>
  <block id="1cb7943b8cf41289c8d5ae2c9f9ec310" category="list-text">Adresse IP du nœud 1 \_____\_____ . \_____\_____ . \_____\_____ . \_____\____</block>
  <block id="2b5f3d5d41f4d2986a55a91aa934205c" category="list-text">Masque de sous-réseau \_____\____ . \_____\_____ . \_____\_____ . \_____\____</block>
  <block id="ed7c49acbcb0724e63d695ba272bcd1d" category="list-text">Passerelle par défaut \_____\_____ . \_____\_____ . \_____\_____ . \_____\____</block>
  <block id="a637d19158a083f61d5e6d9df66998cb" category="list-text">Serveur DNS 1 \_____\_____ . \_____\_____ . \_____\_____ . \_____\____</block>
  <block id="b7eed84956833fb9e8cbb126fb30803f" category="list-text">Serveur DNS 2 \_____\_____ . \_____\_____ . \_____\_____ . \_____\____</block>
  <block id="7f7df9c7f87bea4d47136da35a80f4a9" category="list-text">Domaine de recherche DNS \_____\__________\_____\_______\_________\_________\_______</block>
  <block id="59cd965988b8905f3416029cd3a1facf" category="list-text">Nom d'hôte DNS du nœud deux (facultatif) \_____\_____\_____\____\_______\_______\________\_________</block>
  <block id="242e264b9e179f0ea25123089a967467" category="list-text">Adresse IP du nœud deux (facultative) \_____\_____ . \_____\_____ . \_____\_____ . \_____\____</block>
  <block id="4115e1d934066b360d5cdd8013198fff" category="list-text">Nom d'hôte DNS du nœud 3 (facultatif) \____\_____\______\____\_______\_______________\_________</block>
  <block id="8043aaa26cf3f85d9ab4df441ceb6ef3" category="list-text">Adresse IP du nœud 3 (facultative) \_____\_____ . \_____\_____ . \_____\_____ . \_____\____</block>
  <block id="305c44d3641b44153a7487e28382fffb" category="list-text">Créez des enregistrements DNS pour toutes les adresses IP ci-dessus.</block>
  <block id="ca8a2087e5557e317599344687a57391" category="inline-image-macro">Trois</block>
  <block id="543a0cfd4f6527c92c513911b3079c22" category="list-title"><block ref="05b2444faffd66d76e88602ea7dd353f" category="inline-image-macro-rx" type="image"></block> Configuration du pare-feu réseau</block>
  <block id="76841410d8f9a6881e0b96f150e9cedf" category="inline-link">Configuration requise pour les ports</block>
  <block id="1cb44e38b7d534b49fb7ce15d6726cb0" category="list-text">Ouvrez les ports requis pour les adresses IP ci-dessus dans votre pare-feu réseau. Reportez-vous<block ref="d75d54fbd8f18143d683ed6f5389e615" category="inline-link-rx"></block> à pour connaître la dernière mise à jour.</block>
  <block id="981b8fcee42e1e726a67a2b9a98ea6e9" category="inline-image-macro">Quatre</block>
  <block id="640e990f06389e4b49f54086ba1aba46" category="inline-link">Modifiez les paramètres de l'appliance et activez le service VASA</block>
  <block id="49b964c1f288e8e75650b3e86683914d" category="list-text">Pour utiliser vVols, vous devez d'abord<block ref="c9f7d482e0b51df808dc044e3e43f591" category="inline-link-rx"></block>. En même temps, passez en revue les deux éléments suivants.</block>
  <block id="8ba46a1826b102cd1b8b0fb75a241176" category="inline-link">haute disponibilité</block>
  <block id="acc64c77b8528b3513e0bab18372f0d3" category="list-text">Si vous prévoyez d'utiliser vVols en production,<block ref="b5eaf1d61c4c1246e4e215774dc53776" category="inline-link-rx"></block> avec les deux adresses IP facultatives ci-dessus.</block>
  <block id="fddd8f455515e6a6de8e8d876641e0c5" category="inline-link">Activation des services SRA</block>
  <block id="777b715f4e7db3295048bd9409cb3a0f" category="list-text">Si vous prévoyez d'utiliser ONTAP Tools Storage Replication adapter (SRA) pour VMware site Recovery Manager ou Live site Recovery,<block ref="9eb793199b56cb94f5df0c657a62ea9e" category="inline-link-rx"></block>.</block>
  <block id="e5d9de39f7ca1ba2637e5640af3ae8aa" category="inline-image-macro">Cinq</block>
  <block id="e03ec7d1e46f44c47e1547f8c19fdbb5" category="list-text">Selon VMware, les certificats signés par une autorité de certification sont requis en cas d'utilisation de vVols avec plusieurs vCenters.</block>
  <block id="777f90dea67a6de19d7e4287d6d65525" category="list-text">Services Vasa \_____\______\_____\____\_____\_______\___________\___________</block>
  <block id="50261e7dc97594e1ef47d1913fadd642" category="list-text">Services administratifs \_____\__________\_______\__________________________________</block>
  <block id="e6fbc0b9673f8c86726688d7607fc8f5" category="inline-image-macro">Six</block>
  <block id="96c44f7328270a7b9e72a07f78739ecf" category="list-text">Un datastore sur un périphérique de stockage partagé est requis. Vous pouvez également utiliser une bibliothèque de contenu sur le même datastore que le nœud un pour faciliter le clonage rapide du modèle avec VAAI.</block>
  <block id="656b82abf6edc190097506cd4d1d585b" category="list-text">Bibliothèque de contenu (requise uniquement pour HA) \_____\______\_______\___________________________\_______</block>
  <block id="99325facb7679dc357733bd909532cfc" category="list-text">Nœud un magasin de données \_____\__________\_____\________\_______________________</block>
  <block id="f669e2c7e65edea7adca0c4006b6cf36" category="list-text">Nœud deux datastore (facultatif, mais recommandé pour la haute disponibilité) \_____\________\_______\_______\_______\__________\________</block>
  <block id="5ba1096fffa0ecfd4695651916c48133" category="list-text">Datastore du troisième nœud (facultatif, mais recommandé pour la haute disponibilité) \_____\________\______\_______\________\__________\_____</block>
  <block id="12e67aac3e7f9227cc35f8f047d7dc74" category="inline-image-macro">Sept</block>
  <block id="db5321854b38ff4107ff88c3d3fb2602" category="inline-link">Déployez l'OVA</block>
  <block id="62386ee2b40ea01fd147eb04a3da8b17" category="list-text"><block ref="2b093a8e786abd40836246bfb87e05bd" category="inline-link-rx"></block> À l'aide du client vSphere.</block>
  <block id="baca0ca6729684fd54206793ae4b5bd5" category="inline-image-macro">Huit</block>
  <block id="d40a477cc61e319a78ef1bb36d8ea566" category="list-text">Créez des règles d'affinité pour les machines virtuelles dans un déploiement haute disponibilité.</block>
  <block id="4695b076293ddedd5434ae5a73b57ae2" category="list-text">Si vous utilisez la haute disponibilité, Storage vMotion nœuds deux et trois vers des datastores séparés (facultatif, mais recommandé).</block>
  <block id="fde3f7a850bbaaac2a3706bf8c7df54c" category="inline-link">Configurer les rôles et privilèges des utilisateurs ONTAP</block>
  <block id="064719d8b0308f2a4bc89590c3becdab" category="inline-link">utilisez gérer les certificats</block>
  <block id="d59a2f6a46dd460183ac2d0c23cf6f75" category="list-text"><block ref="53fb9f19112a80479a138e84ac0182c6" category="inline-link-rx"></block> Dans le gestionnaire d'outils ONTAP pour installer les certificats signés par l'autorité de certification requis.</block>
  <block id="6245e46af5a3bdaf57696763c4214c70" category="inline-link">Ajouter des instances vCenter Server</block>
  <block id="427d083edfb4d6df118817492fea1fea" category="list-text"><block ref="9271e724c67dd3dffeb4e3ddaf43b80d" category="inline-link-rx"></block> Dans le Gestionnaire d'outils ONTAP.</block>
  <block id="75299228e38c6c56354b3fbc53bd01db" category="inline-link">clusters intégrés</block>
  <block id="0583aea4353aeb5998071022ebbb79ae" category="inline-link">Ports SVM intégrés</block>
  <block id="4d5a9665c20fe0f045d612f3d7c14c3a" category="inline-link">Configurez SRA sur l'appliance VMware Live site Recovery</block>
  <block id="74d3c40ee5d2741e75390e90d13a881a" category="list-text">Si vous avez activé SRA pour SRM/VLSR pour protéger les datastores traditionnels,<block ref="ae14a63430307f4358dbb1aa0a6215ef" category="inline-link-rx"></block>.</block>
  <block id="56b3d744b9b4be462a3690ae4544597f" category="inline-link">RPO proche de zéro</block>
  <block id="f2866fe05fc7b275f3e2c504b39a3676" category="list-text">Configurer les sauvegardes natives pour<block ref="f915d15018e6084f8326718037772bc7" category="inline-link-rx"></block>.</block>
  <block id="c6a161ea3b473fa2cdc98e5283764902" category="list-text">Configurer des sauvegardes régulières sur d'autres supports de stockage.</block>
  <block id="ed0748e15540f55b7e9e13424330165e" category="paragraph">Suivez ces bonnes pratiques pour créer du stockage vVols pour vos machines virtuelles.</block>
  <block id="e747ebae9f47585b050b0fe47b1807b4" category="paragraph">Le provisionnement des datastores vVols implique plusieurs étapes. Les systèmes ASA r2 de NetApp sont conçus pour les charges de travail VMware et offrent une expérience utilisateur différente des systèmes ONTAP classiques. Lors de l'utilisation de systèmes ASA r2, les outils ONTAP version 10.3 ou ultérieure nécessitent moins d'étapes de configuration et incluent les extensions d'interface utilisateur et la prise en charge de l'API REST optimisées pour la mise à jour de l'architecture de stockage.</block>
  <block id="071d555e17e95fc548b89eaa2c3d9abf" category="section-title">Préparation à la création de datastores vVols avec les outils ONTAP</block>
  <block id="96a0f754354a16524c8672aacf5ba9a6" category="paragraph">Vous pouvez ignorer les deux premières étapes du processus de déploiement si vous utilisez déjà les outils ONTAP pour gérer, automatiser et générer des rapports sur votre stockage VMFS ou NFS classique existant.</block>
  <block id="6a78342dc1cffdf32c956e733c832cee" category="list-text">Créer la machine virtuelle de stockage (SVM) et sa configuration de protocole. Notez que cela n'est pas forcément nécessaire pour les systèmes ASA r2, car ils disposent généralement d'un SVM unique pour les services de données. Vous sélectionnerez NVMe/FC (outils ONTAP 9.13 uniquement), NFS v3, NFS v4.1, iSCSI, FCP ou un mélange de ces options. Les protocoles NVMe/TCP et NVMe/FC peuvent également être utilisés pour les datastores VMFS classiques avec les outils ONTAP 10.3. Vous pouvez utiliser les assistants ONTAP System Manager ou la ligne de commande du cluster shell.</block>
  <block id="ed0b328de155f4d64394b3fa01aa3eda" category="inline-link">Attribuez des tiers locaux (agrégats) aux SVM</block>
  <block id="835f14a0eb02625831ec957a0e6d8a57" category="list-text"><block ref="62ee77b15c683e37c03a082cde78e3a1" category="inline-link-rx"></block> Pour tous les systèmes non ASA r2.</block>
  <block id="975336c37f4c9eec8db7574a1acdfc20" category="inline-link">Configurer la présentation des LIFs</block>
  <block id="a51cd3bd8dc9efabd4808d4faa54cb85" category="inline-link">Combinaison de ports physiques pour créer des groupes d'interfaces</block>
  <block id="02da2876df386437299938fff21fad98" category="list-text">Au moins une LIF par nœud pour chaque connexion switch/fabric. Il est recommandé de créer au moins deux par nœud pour les protocoles FCP, iSCSI ou NVMe. Une LIF par nœud est suffisante pour les vVols basés sur NFS, mais cette LIF doit être protégée par un ifgroup LACP. Reportez-vous aux sections<block ref="f0614b67c9ad440bb8aa968adbd6137a" category="inline-link-rx"></block> et<block ref="a5ffd5460ffa788a3fba4a7f91132efb" category="inline-link-rx"></block> pour plus de détails.</block>
  <block id="1e410bafe9c5869016fc8d733372d354" category="list-text">Si vous avez l'intention d'utiliser les identifiants SVM scoped pour vos vCenters locataires, au moins une LIF de gestion par SVM.</block>
  <block id="88ad52445ad4b758c30b8d41e4898479" category="inline-link">Les clusters ONTAP et les SVM sont peering</block>
  <block id="9e972a46542b8d916a3d602fa7d61635" category="list-text">Si vous prévoyez d'utiliser SnapMirror, assurez-vous que votre source et votre cible<block ref="03354afe01dc1f53e5b25fc0bc002ae0" category="inline-link-rx"></block>.</block>
  <block id="dd441f913b3f6f72bcf4499b88815e03" category="list-text">Les volumes peuvent être créés à ce stade, mais il est recommandé de laisser l'assistant de _provisionnement de datastore_ dans les outils ONTAP les créer. La seule exception à cette règle est que vous prévoyez d'utiliser la réplication vVols avec VMware site Recovery Manager et les outils ONTAP 9. Cette configuration est plus simple avec des volumes FlexVol préexistants avec des relations SnapMirror existantes. N'oubliez pas d'activer la QoS sur les volumes à utiliser pour les vVols, car ceux-ci doivent être gérés par les outils SPBM et ONTAP.</block>
  <block id="2a03ee5b0887b8a6bf23fd52456544db" category="inline-link">Déployez les outils ONTAP pour VMware vSphere</block>
  <block id="23f58455f809e6f8a8a2cac1db0e49cf" category="list-text"><block ref="17b63a5e90adbe276a8874700041ac19" category="inline-link-rx"></block> Utilisation du fichier OVA téléchargé depuis le site de support NetApp.</block>
  <block id="1bcb0e86c49aae8128bbabb5d9d3d585" category="list-text">Les outils ONTAP 10.0 et versions ultérieures prennent en charge plusieurs serveurs vCenter par appliance. Il n'est plus nécessaire de déployer une appliance d'outils ONTAP par serveur vCenter.</block>
  <block id="951d3fc54a28f9f46798897467d96a5b" category="inline-link">Gérer les certificats</block>
  <block id="6d8aae47de809b9e77fb4f1ee0ed7730" category="list-text">Si vous prévoyez de connecter plusieurs vCenters à une seule instance d'outils ONTAP, vous devez créer et installer des certificats signés par une autorité de certification. Reportez-vous<block ref="32dbc6ca4c4a8bcb0695dd873f46e9e4" category="inline-link-rx"></block> à pour les étapes.</block>
  <block id="31be7f8c3c1f560d4cfdde9947673161" category="list-text">Depuis 10.3, les outils ONTAP se déploient désormais en tant qu'appliance petit type à nœud unique, adaptée à la plupart des workloads non vVols.</block>
  <block id="485a78e60d40cdf87a9864e840ed44a8" category="inline-link">Outils ONTAP scale-out</block>
  <block id="a614ddc55c86c92e39a1e167189a59f3" category="list-text">Il est recommandé de<block ref="ef398e4ee19e56a537bbd5564e5f4512" category="inline-link-rx"></block> passer de la configuration 10.3 à la configuration haute disponibilité (HA) à 3 nœuds pour toutes les charges de travail de production. Dans les laboratoires ou à des fins de test, il est possible d'utiliser un déploiement à un seul nœud.</block>
  <block id="0112f904af205a304a0144318d92a88f" category="inline-link">Utilisation des règles d'affinité sans vSphere DRS</block>
  <block id="7ff088db1b9b2e6077b66b3e834c022c" category="inline-link">Créez une règle d'affinité VM-VM</block>
  <block id="1d7299ee36dd01581c03d394e21875e9" category="inline-link">utilisez l'utilitaire de sauvegarde de configuration intégré</block>
  <block id="aaccfa1f911c7ed3afac8a1c9005cf08" category="list-text">La meilleure pratique recommandée pour l'utilisation des vVols de production est d'éliminer tout point de défaillance unique. Créez des règles d'anti-affinité pour empêcher les machines virtuelles des outils ONTAP de s'exécuter ensemble sur le même hôte. Après le déploiement initial, il est également recommandé d'utiliser Storage vMotion pour placer les machines virtuelles des outils ONTAP dans différents datastores. En savoir plus sur<block ref="9d1413939148e981fa32923e1c0a740d" category="inline-link-rx"></block> ou<block ref="33bad2ad715296cb3b9df2aa8e0bbe93" category="inline-link-rx"></block>. Vous devez également planifier des sauvegardes fréquentes, et/ou<block ref="835137bc934138d6c89439748022267d" category="inline-link-rx"></block>.</block>
  <block id="97075bcba23b351ceb599f8167247f82" category="list-text">Configurez les outils ONTAP 10.3 en fonction de votre environnement.</block>
  <block id="46efd89ca4d682d645c74916f2c8e8f4" category="list-text"><block ref="9271e724c67dd3dffeb4e3ddaf43b80d" category="inline-link-rx"></block> Dans l'interface utilisateur du gestionnaire d'outils ONTAP.</block>
  <block id="6eaf552fe4b827d87d969ecf00791fab" category="inline-link">Ajoutez vos clusters ONTAP</block>
  <block id="e4c64ea440c0954a75e29bee53f58731" category="list-text">Les outils ONTAP 10.3 prennent en charge la colocation sécurisée. Si vous n'avez pas besoin d'une colocation sécurisée, il vous suffit d'<block ref="c70dc775815ebe034e3eb8a346ef862b" category="inline-link-rx"></block>accéder au menu des outils ONTAP dans vCenter, de cliquer sur _systèmes back-end_ et de cliquer sur le bouton _ajouter_.</block>
  <block id="b7e859c0d3a2db9fa17e5b88bf5ca641" category="list-text">Dans un environnement mutualisé sécurisé où vous souhaitez déléguer des SVM spécifiques à des vCenters spécifiques, vous devez procéder comme suit.</block>
  <block id="2fdde12c870630cac6cf925e7762e8b7" category="list-text">Connectez-vous à l'interface du gestionnaire d'outils ONTAP</block>
  <block id="bfae79cf17053457fef781bcd20e0f14" category="inline-link">Intégration du cluster de stockage</block>
  <block id="b7d3b83b5327fbad54ed641ffe056c7b" category="list-text"><block ref="b7d3b83b5327fbad54ed641ffe056c7b" category="inline-link-rx"></block></block>
  <block id="a5ff3af9e80b6313b32053dd07f43a23" category="inline-link">Associer un back-end de stockage à une instance vCenter Server</block>
  <block id="b60bfa6652bfe8b1d4f8779e792ac95c" category="list-text"><block ref="b60bfa6652bfe8b1d4f8779e792ac95c" category="inline-link-rx"></block></block>
  <block id="e3efa7d6ee6a48514d6cd7ff7795498f" category="list-text">Fournir les informations d'identification de SVM spécifiques à l'administrateur vCenter qui ajoutera ensuite la SVM en tant que back-end de stockage dans le menu ONTAP Tools Storage backend de vCenter.</block>
  <block id="0abec471b6c51c227aee6d0b1708d228" category="list-text">Il est recommandé de créer des rôles RBAC pour vos comptes de stockage.</block>
  <block id="e235f10d1a7bf30f3198a59ac049dc9c" category="list-text">Les outils ONTAP incluent un fichier JSON contenant les autorisations de rôle requises par les comptes d'accès au stockage des outils ONTAP. Vous pouvez télécharger le fichier JSON vers ONTAP System Manager pour simplifier la création des rôles et utilisateurs RBAC.</block>
  <block id="8ca4b3b11e162a34da542a63661edf9a" category="list-text">Pour en savoir plus sur les rôles RBAC de ONTAP, rendez-vous sur<block ref="34ad13b9bdc1ec3d2d017144f37b1766" category="inline-link-rx"></block>.</block>
  <block id="e4f0d44befb2f792ce908178a949f26d" category="admonition">Parce que de nombreuses API utilisées pour les vVols ne sont disponibles qu'au niveau du cluster, l'intégralité du cluster doit être intégrée dans l'interface utilisateur du gestionnaire des outils ONTAP.</block>
  <block id="90aa53fd267c0c35741d35381ad7a054" category="section-title">Création de datastores vVols avec les outils ONTAP</block>
  <block id="2899926e592e956d9ee50e9ac1a3fcc5" category="paragraph">Cliquez avec le bouton droit de la souris sur l'hôte, le cluster ou le data Center sur lequel vous souhaitez créer le datastore vVols, puis sélectionnez _ONTAP Tools_ &gt; _Provision datastore_.</block>
  <block id="893534fd72b00ed504664763cdcfc0a5" category="inline-image-macro">Role=« pouce » « Assistant de provisionnement de datastore », 300</block>
  <block id="4a68f477edf1ea24da48b805acb7318c" category="paragraph"><block ref="4a68f477edf1ea24da48b805acb7318c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="20474b1a0c7edf7bd0809f2cb13dfe99" category="list-text">Choisissez vVols, indiquez un nom significatif et sélectionnez le protocole souhaité. Vous pouvez également fournir une description du datastore.</block>
  <block id="f4f44261c4e217310cb4f0bb2cc389f5" category="list-text">Outils ONTAP 10.3 avec ASA r2.</block>
  <block id="39a5735e417853a21c6d8ed53aa5cb1f" category="paragraph"><block ref="39a5735e417853a21c6d8ed53aa5cb1f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e332ae811243a2074f58eb5d5efdcc21" category="list-text">Sélectionner le SVM du système ASA r2 et cliquer sur _Next_.</block>
  <block id="dac9a06ae28c99c2bc00c2f1ca94c7ed" category="paragraph"><block ref="dac9a06ae28c99c2bc00c2f1ca94c7ed" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2b3dd72cbd7ce4cf79b8fe46700d45d5" category="list-text">Cliquez sur _Finish_</block>
  <block id="278f04f3dff2f303eed4edfbc836f534" category="paragraph"><block ref="278f04f3dff2f303eed4edfbc836f534" category="inline-image-macro-rx" type="image"></block></block>
  <block id="78195be4e07f2cf980cf70b78cfd4a62" category="list-text">C'est aussi simple que cela !</block>
  <block id="ca8e7cc39790460719db057ff38e167d" category="list-text">Outils ONTAP 10.3 avec ONTAP FAS, AFF et ASA antérieurs à ASA r2.</block>
  <block id="7f016940a12444f321c6a4251eb495cf" category="list-text">Sélectionnez le protocole</block>
  <block id="c3646108adeb4be26557fcbb99f62dc2" category="paragraph"><block ref="c3646108adeb4be26557fcbb99f62dc2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b0ec44dc6f9561dfdf58606f8e389753" category="list-text">Sélectionner le SVM et cliquer sur _Next_.</block>
  <block id="444c0ec9fa985ffe1e7a13b90ec73f1b" category="paragraph"><block ref="444c0ec9fa985ffe1e7a13b90ec73f1b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="75403559d3b552e859c244a233ae00ac" category="list-text">Cliquez sur _add New volumes_ ou _use existing volume_ et spécifiez les attributs. Notez que dans les outils ONTAP 10.3 vous pouvez demander la création simultanée de plusieurs volumes. Vous pouvez également ajouter manuellement plusieurs volumes pour les équilibrer dans le cluster ONTAP. Cliquez sur _Next_</block>
  <block id="9a7e72607a6faad27d7fbe6e5f295675" category="paragraph"><block ref="9a7e72607a6faad27d7fbe6e5f295675" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4e1a38b50f0db11d407ccb112de6a782" category="paragraph"><block ref="4e1a38b50f0db11d407ccb112de6a782" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2037e6ffbfee1dde5dddbbca50cda2de" category="paragraph"><block ref="2037e6ffbfee1dde5dddbbca50cda2de" category="inline-image-macro-rx" type="image"></block></block>
  <block id="775c4cf447196b1d2af4bc4eb340eab0" category="list-text">Les volumes affectés s'affichent dans le menu Outils ONTAP de l'onglet configurer du datastore.</block>
  <block id="f16d549f88c459ef96e6cb1cfd5e5ad6" category="paragraph"><block ref="f16d549f88c459ef96e6cb1cfd5e5ad6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="66ded2ce50d43c22f8e56efe6053a76d" category="list-text">Vous pouvez désormais créer des stratégies de stockage de machine virtuelle à partir du menu _Policies and Profiles_ de l'interface utilisateur vCenter.</block>
  <block id="fc7ec2dfcc40e5c7c47dca5758e10523" category="paragraph">La migration des machines virtuelles des datastores traditionnels vers un datastore vVols est aussi simple que le déplacement de machines virtuelles entre des datastores traditionnels. Il vous suffit de sélectionner la ou les machines virtuelles, puis de sélectionner migrer dans la liste actions et de sélectionner un type de migration de _modifier le stockage uniquement_. Lorsque vous y êtes invité, sélectionnez une règle de stockage de machine virtuelle correspondant à votre datastore vVols. Les opérations de copie de migration peuvent être déchargées à l'aide de vSphere 6.0 et versions ultérieures pour les migrations de SAN VMFS vers des vVols, mais pas des VMDK NAS vers des vVols.</block>
  <block id="26fcc57b7c0de02dc9e8360d6f4b3493" category="paragraph">Pour automatiser le provisionnement du stockage avec la gestion basée sur des règles, vous devez créer des règles de stockage de machines virtuelles mappées sur les capacités de stockage souhaitées.</block>
  <block id="8b8944ec0cef6dd0777b2144561987fe" category="admonition">Les outils ONTAP 10.0 et versions ultérieures n'utilisent plus les profils de capacité de stockage comme les versions précédentes. Au contraire, les fonctionnalités de stockage sont directement définies dans la stratégie de stockage de la machine virtuelle.</block>
  <block id="cdca3b3c5fbefb00afe4df9de69ab75b" category="paragraph">Les règles de stockage des machines virtuelles sont utilisées dans vSphere pour gérer les fonctionnalités facultatives telles que le contrôle des E/S du stockage ou le chiffrement vSphere. Ils sont également utilisés avec les vVols pour appliquer des fonctionnalités de stockage spécifiques à la machine virtuelle. Utilisez le type de stockage « NetApp.clustered.Data.ONTAP.VP.vvol ». Voir le lien:vmware-vvols-ontap.html#Best Practices[exemple de configuration réseau avec vVols sur NFS v3] pour un exemple de ceci avec les outils ONTAP VASA Provider. Les règles pour le stockage « NetApp.clustered.Data.ONTAP.VP.VASA10 » doivent être utilisées avec les datastores non basés sur vVols.</block>
  <block id="0774b1717ce18129cd8e3ec0094e8640" category="paragraph">Une fois la règle de stockage créée, elle peut être utilisée lors du provisionnement de nouvelles machines virtuelles.</block>
  <block id="473e84e674f60e2fe619202a460efdfb" category="inline-image-macro">Role=« pouce » « création de la stratégie de stockage VM avec les outils ONTAP VASA Provider 9.10 », 300</block>
  <block id="e2f8ccc321215682fc34ae142633f3ff" category="paragraph"><block ref="b8f36bdf242d29fb6768827d6130494d" category="inline-image-macro-rx" type="image"></block> <block ref="e2501bb4f16d0f74914f04323d8e5e58" category="inline-image-macro-rx" type="image"></block> <block ref="166606e94a626af27852e00771133222" category="inline-image-macro-rx" type="image"></block> <block ref="8a14d5d27355a6630c7d65d859977eb8" category="inline-image-macro-rx" type="image"></block> <block ref="50b6bc69b9e417ba7f80bbcc0baaf57d" category="inline-image-macro-rx" type="image"></block> <block ref="8ec6614ba8e8947129dafaaede18ec39" category="inline-image-macro-rx" type="image"></block> <block ref="7bf707d7de5e0a048094c66368c89e52" category="inline-image-macro-rx" type="image"></block></block>
  <block id="71ea2d7b6b501372ec2ecc7846b5bd74" category="section-title">Gestion des performances avec les outils ONTAP</block>
  <block id="4357d652f2cfe6e15b6e8c54aacec10b" category="paragraph">Les outils ONTAP utilisent leur propre algorithme de placement équilibré pour placer un nouveau VVol dans le meilleur FlexVol volume avec des systèmes ASA unifiés ou classiques, ou dans une zone de disponibilité du stockage (SAZ) avec des systèmes ASA r2, dans un datastore vVols. Le placement est basé sur la correspondance entre le stockage de sauvegarde et la règle de stockage des machines virtuelles. Cela permet de s'assurer que le datastore et le stockage de sauvegarde peuvent répondre aux exigences de performances spécifiées.</block>
  <block id="97c380438d77f28866d8fca75c697d78" category="list-text">*Les valeurs min et Max IOPS* peuvent être spécifiées dans une stratégie VM.</block>
  <block id="f980d0e57da48ae0fc9f45625e32cf7d" category="list-text">La modification des IOPS de la règle ne modifiera pas la QoS sur les vVols tant que la règle de machine virtuelle ne sera pas réappliquée aux machines virtuelles qui l'utilisent. Vous pouvez également créer une nouvelle règle avec les IOPS souhaitées et l'appliquer aux machines virtuelles cibles. Il est généralement recommandé de définir simplement des règles de stockage VM distinctes pour les différents niveaux de service et de modifier simplement la règle de stockage VM sur la VM.</block>
  <block id="6c47cd98201c31f6165c0239e8fa84b8" category="list-text">Les personnalités ASA, ASA r2, AFF et FAS ont des paramètres d'IOPS différents. Les valeurs min et Max sont disponibles sur tous les systèmes Flash. Toutefois, les systèmes non AFF peuvent uniquement utiliser les paramètres Max IOPS.</block>
  <block id="6c2d6091dcb0d9df928f0dc687f86383" category="inline-image-macro">Role=« pouce » « réapplication de la règle de stockage VM », 300</block>
  <block id="8551dcdff381e3430606b1ff98a1e369" category="paragraph"><block ref="8551dcdff381e3430606b1ff98a1e369" category="inline-image-macro-rx" type="image"></block></block>
  <block id="def8fabb3f167c5ac05ad7f416c77a5c" category="paragraph">La clé de l'utilisation de vVols avec NetApp est l'outil ONTAP pour VMware vSphere, qui fait office d'interface VASA (vSphere API for Storage Awareness) Provider pour les systèmes ONTAP 9 de NetApp.</block>
  <block id="e1688cfcbc1a78418422879cc779caf5" category="paragraph">Les outils ONTAP incluent également les extensions d'interface utilisateur vCenter, les services d'API REST, les adaptateurs de réplication du stockage pour VMware site Recovery Manager / Live site Recovery, les outils de surveillance et de configuration d'hôte, ainsi qu'une série de rapports qui vous aident à mieux gérer votre environnement VMware.</block>
  <block id="d943156d32e8da8030f35b3bdc46f06e" category="paragraph">La licence ONTAP One inclut toutes les licences nécessaires pour utiliser les vVols avec les systèmes ONTAP. La seule autre exigence est les outils ONTAP gratuits OVA, qui agit en tant que fournisseur VASA. Dans un environnement vVols, le logiciel VASA Provider traduit les fonctionnalités des baies en attributs basés sur des règles qui peuvent être exploitées via les API VASA sans que l'administrateur vSphere n'ait à savoir comment les fonctionnalités sont gérées en arrière-plan. Cela permet une consommation dynamique de la capacité de stockage allouée sur la base de règles, ce qui évite de créer manuellement des datastores classiques et de gérer leurs taux de consommation de stockage individuels. En bref, les vVols simplifient la gestion du stockage d'entreprise et l'affranchit de l'administrateur vSphere pour qu'il puisse se concentrer sur la couche de virtualisation.</block>
  <block id="3122b363be1cca4e9b79843907db549f" category="paragraph">Pour les clients qui utilisent VMware Cloud Foundation avec VSAN, les vVols peuvent être ajoutés à n'importe quel domaine de gestion ou de workload en tant que stockage supplémentaire. VVols s'intègre de façon transparente avec VSAN via un framework de gestion commun basé sur des règles de stockage.</block>
  <block id="adcd94c2ec3aa54fc9fbaa77544ccc10" category="paragraph">La gamme d'outils ONTAP 10 nouvelle génération modernise les fonctionnalités précédentes grâce à une architecture évolutive, conteneurisée et basée sur des microservices qui peut être déployée via une simple appliance de format OVA sur ESXi. Les outils ONTAP 10 combinent toutes les fonctionnalités de trois anciens dispositifs et produits dans un déploiement unique. Pour la gestion des vVols, vous utiliserez les extensions intuitives de l'interface utilisateur vCenter ou les API REST pour les outils ONTAP VASA Provider. Notez que le composant SRA est destiné aux datastores classiques ; VMware site Recovery Manager n'utilise pas SRA pour les vVols.</block>
  <block id="b87ac5af4acce876c9cb950c7c5a1891" category="section-title">ONTAP Tools VASA Provider architecture lors de l'utilisation d'iSCSI ou FCP avec des systèmes unifiés</block>
  <block id="b566b0372bb84d18bc26fdc4c0fbd397" category="paragraph">Pour les nouvelles installations, déployez l'appliance virtuelle dans votre environnement vSphere. Une fois déployé, vous pouvez vous connecter à l'interface utilisateur du gestionnaire ou utiliser les API REST pour faire évoluer votre déploiement verticalement ou horizontalement, intégrer les vCenters (qui enregistrent le plug-in avec vCenter), intégrer les systèmes de stockage et associer les systèmes de stockage à vos vCenters. L'intégration de systèmes de stockage dans l'interface du gestionnaire d'outils ONTAP et l'association de clusters à des vCenters sont uniquement nécessaires si vous prévoyez d'utiliser la colocation sécurisée avec des SVM dédiés. Sinon, vous pouvez simplement intégrer le ou les clusters de stockage souhaités dans les extensions de l'interface utilisateur vCenter des outils ONTAP ou à l'aide des API REST.</block>
  <block id="26ffc687a7267f96a389530199971cd1" category="inline-link">Documentation sur les outils ONTAP pour VMware vSphere</block>
  <block id="e8d49fe128837c5d33383898126449d6" category="paragraph">Reportez-vous à <block ref="d7e84668ac8db4130d4662ae6bde9c89" category="inline-link-macro-rx"></block> dans ce document, ou<block ref="b9c3640cd3dcc39d23d49bf169dd367b" category="inline-link-rx"></block>.</block>
  <block id="2e2b8d8692ea57a5a089be51e49a3104" category="paragraph">Il est recommandé de stocker vos outils ONTAP et appliances vCenter sur des datastores NFS ou VMFS classiques afin d'éviter tout conflit d'interdépendance. Étant donné que les outils vCenter et ONTAP doivent communiquer entre eux lors des opérations vVols, n'installez pas et ne déplacez pas les appliances ONTAP Tools ou vCenter Server (VCSA) vers le stockage vVols qu'ils gèrent. Dans ce cas, le redémarrage de l'appliance vCenter ou des outils ONTAP peut entraîner une interruption de l'accès au plan de contrôle et une incapacité de l'appliance à démarrer.</block>
  <block id="d6776ddc59d905e2967855a8949b8ff0" category="inline-link">Outils ONTAP pour VMware vSphere 10 - Téléchargements</block>
  <block id="e085c3225ffce6bb698ac8cf50cc0dc4" category="inline-link">Mise à niveau des outils ONTAP pour VMware vSphere 10.x vers la version 10.3</block>
  <block id="e43b5fd407b2bc9fda1a39851a48f9bb" category="inline-link">Migrez des outils ONTAP pour VMware vSphere 9.x vers la version 10.3</block>
  <block id="a3a288ec9e5f16d7de8c63fbc6934c97" category="paragraph">Les mises à niveau des outils ONTAP sans déplacement des données sont prises en charge grâce au fichier ISO de mise à niveau disponible au téléchargement<block ref="b5b3717cb556fa4a89daf005a0a23ea8" category="inline-link-rx"></block> sur le site du support NetApp (identifiant NSS requis). Suivez les<block ref="f4c1005a920344cdec43558687897506" category="inline-link-rx"></block> instructions du guide pour mettre à niveau l'appareil. Il est également possible d'effectuer une mise à niveau côte à côte des outils ONTAP 9.13 à 10.3. Reportez-vous<block ref="f6676f6d529f1f81f9da02084f545f3c" category="inline-link-rx"></block> à la pour plus d'informations sur ce sujet.</block>
  <block id="8374c9fea191c7d2f4430555aa250de3" category="paragraph">Pour le dimensionnement de votre appliance virtuelle et la compréhension des limites de configuration, reportez-vous à la section<block ref="d602e3cdd9623c66a90a3f53a55d967f" category="inline-link-rx"></block></block>
  <block id="eddf7820ea4e2a78603e1bff3aa3bbb6" category="paragraph"><block ref="eddf7820ea4e2a78603e1bff3aa3bbb6" category="inline-link-rx"></block></block>
  <block id="a4552c6e2a6c6188a04ffaf366c67ea5" category="list-text"><block ref="a4552c6e2a6c6188a04ffaf366c67ea5" category="inline-link-rx"></block></block>
  <block id="2bd2f3ded095498e9ee97f7cc9074dc0" category="inline-link">Présentation des outils ONTAP pour VMware vSphere</block>
  <block id="0e8f3f9d7644f28839e4eb573b4c2589" category="list-text"><block ref="0e8f3f9d7644f28839e4eb573b4c2589" category="inline-link-rx"></block></block>
  <block id="b832e56b13b2026b9c4d50d0f3f07904" category="list-text"><block ref="b832e56b13b2026b9c4d50d0f3f07904" category="inline-link-rx"></block></block>
  <block id="f0bc076dbe95da208c42e642105b0125" category="list-text"><block ref="f0bc076dbe95da208c42e642105b0125" category="inline-link-rx"></block></block>
  <block id="5245dc6f2a790bb421c841d2dfa17c0d" category="inline-link">Provisionner les datastores</block>
  <block id="8faeb8c24af8fea505d7e93e49a7faa9" category="list-text"><block ref="8faeb8c24af8fea505d7e93e49a7faa9" category="inline-link-rx"></block></block>
  <block id="607bc4263c4e2c484eb0fbbfdc21b438" category="list-text"><block ref="607bc4263c4e2c484eb0fbbfdc21b438" category="inline-link-rx"></block></block>
  <block id="f5f3c80e03e60f2a58399685adcf6610" category="list-text"><block ref="f5f3c80e03e60f2a58399685adcf6610" category="inline-link-rx"></block></block>
  <block id="1608a10fc8319b14c6c50a77edab9e7c" category="inline-link">Modifier les paramètres de l'hôte VMware ESXi</block>
  <block id="1f4b95b02061cf146ca813dd68f240b5" category="list-text"><block ref="1f4b95b02061cf146ca813dd68f240b5" category="inline-link-rx"></block></block>
  <block id="952be4c4311cd0b3b105435f5c484336" category="inline-link">Configurez vSphere Metro Storage Cluster (vMSC) à l'aide des outils ONTAP et de la synchronisation active SnapMirror</block>
  <block id="4e22d6ab0229a29e7c9f041b1f4263a0" category="list-text"><block ref="4e22d6ab0229a29e7c9f041b1f4263a0" category="inline-link-rx"></block></block>
  <block id="c724784c65896d8b16350f4b0580dfd4" category="inline-link">Protection des machines virtuelles</block>
  <block id="19ffdbf6d480a0097bf46b6fe379b412" category="list-text"><block ref="7970b8a3df0aeb298f96944db6f19225" category="inline-link-rx"></block> Avec SRM</block>
  <block id="cb2b70161843498e22e97eb5f155009c" category="inline-link">Surveillez les clusters, les datastores et les machines virtuelles</block>
  <block id="1f901bed9e91faa77a039d895d167c4b" category="list-text"><block ref="1f901bed9e91faa77a039d895d167c4b" category="inline-link-rx"></block></block>
  <block id="90d45c9fcbbcfdfcff766c447a16f73a" category="paragraph">Le fournisseur VASA inclut un tableau de bord contenant des informations sur les performances et la capacité des VM vVols individuelles. Ces informations proviennent directement de ONTAP pour les fichiers et les LUN VVol, notamment la latence, les IOPS, le débit, etc. Il est activé par défaut lors de l'utilisation de toutes les versions de ONTAP 9 actuellement prises en charge. Notez qu'après la configuration initiale, le tableau de bord peut contenir jusqu'à 30 minutes de données.</block>
  <block id="6861075c55e048882e2c055171a337b2" category="section-title">Autres pratiques exemplaires</block>
  <block id="ce76fed6b9276669c61e2b0b85e8e767" category="paragraph">En général, ONTAP supporte les limites vVols définies par VMware (voir publié<block ref="a6efdd9b1a19df6105024b4869e0582b" category="inline-link-rx"></block>). Vérifiez toujours les limites mises à jour du<block ref="bb9c67b5a4c15a85b5e6aa6c9afd0285" category="inline-link-rx"></block> nombre et de la taille des LUN, des espaces de noms et des fichiers.</block>
  <block id="0441498a23e55973b6e2d5843b427613" category="paragraph">Même s'il est possible de créer des datastores vVols avec l'interface vSphere générale, l'utilisation des outils ONTAP crée automatiquement des terminaux de protocole selon les besoins et crée des volumes FlexVol (non requis avec ASA r2) en utilisant les bonnes pratiques ONTAP. Il vous suffit de cliquer avec le bouton droit sur l'hôte/le cluster/le data Center, puis de sélectionner _ONTAP Tools_ et _provisioning datastore_. Ensuite, il vous suffit de choisir les options vVols souhaitées dans l'assistant.</block>
  <block id="3729a48b517da427fd2d9807ebc0fed5" category="paragraph">*Zone votre fabric Fibre Channel avant d'utiliser FCP pour vVols.*</block>
  <block id="f156d8db1f2ed380f0199266e583aa1b" category="paragraph">Pour les systèmes non ASA r2, il peut être souhaitable d'ajouter plusieurs volumes de sauvegarde à votre datastore vVols pour répartir la charge de travail sur le cluster ONTAP, pour prendre en charge différentes options de règles ou pour augmenter le nombre de LUN ou de fichiers autorisés. Toutefois, si vous avez besoin d'une efficacité de stockage maximale, placez l'ensemble de vos volumes en arrière-forme sur un seul agrégat. Si des performances de clonage maximales sont requises, envisagez d'utiliser un seul volume FlexVol et de conserver vos modèles ou votre bibliothèque de contenu dans le même volume. Le fournisseur VASA délègue de nombreuses opérations de stockage vVols à ONTAP, notamment la migration, le clonage et les copies Snapshot. Cette opération est réalisée au sein d'un seul volume FlexVol, ce qui permet d'utiliser des clones de fichiers peu encombrants et de les mettre presque instantanément à disposition. Sur des volumes FlexVol, les copies sont rapidement disponibles et utilisent la déduplication et la compression à la volée. Toutefois, l'efficacité du stockage maximale ne peut pas être restaurée tant que des tâches en arrière-plan ne sont pas exécutées sur des volumes utilisant la déduplication et la compression en arrière-plan. Selon la source et la destination, une certaine efficacité peut être dégradée.</block>
  <block id="256a688cc49c759f4698b8d5d1dd7b6a" category="paragraph">Avec les systèmes ASA r2, cette complexité n'est plus liée à l'abstraction du concept de volume ou d'agrégat par rapport à l'utilisateur. Le placement dynamique est géré automatiquement et des terminaux de protocole sont créés en fonction des besoins. Des terminaux supplémentaires peuvent être créés automatiquement à la volée si une évolutivité supplémentaire est nécessaire.</block>
  <block id="66a77b29a2cc0bdf1aa1bf8f6d4dac96" category="paragraph">*Assurez-vous d'avoir suffisamment de LIFs de données.* Reportez-vous à la <block ref="d7e84668ac8db4130d4662ae6bde9c89" category="inline-link-macro-rx"></block>.</block>
  <block id="3518579aa5aedcfb4f4b83a6ccbe9cb6" category="admonition">Ce document a été mis à jour pour inclure les nouvelles fonctionnalités vVols de vSphere 8.0 mise à jour 3 et de ONTAP Tools version 10.3.</block>
  <block id="b2dd36bd4918e00f8b2e15e6d62a4b94" category="section-title">Vasa Provider</block>
  <block id="0a4ba68e118d83e29ea66516a02f1b48" category="section-title">Terminal PE (Protocol Endpoint)</block>
  <block id="974863a1395a284a680d09e18cf6c9cc" category="section-title">Terminal virtuel de protocole (VPE)</block>
  <block id="8f13bfaaa8ba18765f4525a280f647cf" category="section-title">Datastore du volume virtuel</block>
  <block id="80c64f568dcf805b418e425957b8c975" category="paragraph">| le datastore de volume virtuel est une représentation de datastore logique d'un conteneur vVols créée et gérée par un fournisseur VASA. Le conteneur représente un pool de capacité de stockage provisionné à partir des systèmes de stockage gérés par le fournisseur VASA. Les outils ONTAP prennent en charge l'allocation de plusieurs volumes FlexVol (appelés « volumes de sauvegarde ») à un datastore vVols unique. Ces datastores vVols peuvent couvrir plusieurs nœuds dans un cluster ONTAP, combinant des systèmes Flash et hybrides ayant des fonctionnalités différentes. L'administrateur peut créer de nouveaux volumes FlexVol à l'aide de l'assistant de provisionnement ou de l'API REST, ou sélectionner des volumes FlexVol précréés pour la sauvegarde du stockage, le cas échéant.</block>
  <block id="3d947d83ddfd03d217cdfcc09be70c32" category="paragraph">Avec VMware vSphere APIs for Storage Awareness (VASA), un administrateur de serveurs virtuels peut facilement utiliser les fonctionnalités de stockage nécessaires pour provisionner des serveurs virtuels sans avoir à interagir avec son équipe de stockage. Avant VASA, les administrateurs de VM pouvaient définir des règles de stockage de VM, mais devaient travailler avec leurs administrateurs de stockage pour identifier les datastores appropriés, souvent à l'aide de la documentation ou des conventions de nommage. Dans VASA, les administrateurs de vCenter disposant des autorisations appropriées peuvent définir une gamme de fonctionnalités de stockage que les utilisateurs de vCenter peuvent ensuite utiliser pour provisionner des VM. Le mappage entre la règle de stockage de la machine virtuelle et les fonctionnalités du datastore permet à vCenter d'afficher une liste de datastores compatibles à sélectionner, ainsi que d'activer d'autres technologies telles que Aria (anciennement vRealize) Automation ou Tanzu Kubernetes Grid pour sélectionner automatiquement le stockage dans une règle attribuée. Cette approche est appelée gestion basée sur des règles de stockage. Si les règles VASA Provider et les politiques de stockage de VM peuvent également être utilisées avec les datastores traditionnels, notre attention se concentre sur les datastores vVols.</block>
  <block id="9f1893d8db5ceaf62726d1a0aa228224" category="section-title">Règles de stockage de VM</block>
  <block id="0aa8052a92097a4f8ec3114e7249a0e1" category="paragraph">Les règles de stockage de serveur virtuel sont créées dans vCenter sous stratégies et profils. Pour les vVols, créez un jeu de règles à l'aide de règles provenant du fournisseur de type de stockage NetApp vVols. Les outils ONTAP 10.X offrent désormais une approche plus simple que les outils ONTAP 9.X en vous permettant de spécifier directement les attributs de stockage dans la stratégie de stockage des machines virtuelles.</block>
  <block id="2efad47a2579a212fb659be8b8101b3c" category="paragraph">Une fois qu'une machine virtuelle est provisionnée, le fournisseur VASA continue à vérifier la conformité et alerte l'administrateur de la machine virtuelle en cas d'alarme dans vCenter lorsque le volume de sauvegarde n'est plus conforme à la règle.</block>
  <block id="ede8e2fa9dea87dd87a82bda2b2cf090" category="paragraph">Les instructions de configuration de NetApp MetroCluster (appelées « configuration MCC ») sont disponibles à l'adresse<block ref="2c736bccede87dae47dcf61108f083c4" category="inline-link-rx"></block>. Les instructions relatives à la synchronisation active SnapMirror (SMAs) sont également disponibles à l'adresse<block ref="14203840309dd1b6e13f73373477bb9d" category="inline-link-rx"></block>.</block>
  <block id="ea27eb943310e6748735c2b98c65f5fd" category="paragraph">Si vous n'utilisez pas MetroCluster, vous pouvez utiliser la synchronisation active SnapMirror qui offre une protection granulaire du datastore et un accès actif-actif sur plusieurs clusters ONTAP dans différents domaines de défaillance. Les directeurs de groupe utilisent des groupes de cohérence (CGS) pour assurer la cohérence de l'ordre d'écriture dans un ou plusieurs datastores. Vous pouvez également créer plusieurs groupes de cohérence selon les besoins de votre application et de votre datastore. Les groupes de cohérence sont particulièrement utiles pour les applications qui nécessitent une synchronisation des données entre plusieurs datastores. Les SMAs prennent également en charge les mappages de périphériques Raw Device (RDM) et le stockage connecté par l'invité avec les initiateurs iSCSI invités. Pour en savoir plus sur les groupes de cohérence, rendez-vous sur<block ref="8bba9b5b97dba092834d7a48a07f102d" category="inline-link-rx"></block>.</block>
  <block id="1bf63b567c68de7fcd78fcc89f42f93c" category="inline-link">Protégez à l'aide de la protection de cluster hôte</block>
  <block id="1809bb507d1d8b8c1fbe71452026a52e" category="paragraph">Les outils ONTAP offrent désormais un moyen simple de configurer la synchronisation active SnapMirror pour vMSC. Vous pouvez utiliser le plug-in vCenter des outils ONTAP pour créer et gérer des relations de synchronisation active SnapMirror entre deux clusters ONTAP. Le plug-in offre une interface simple et intuitive qui permet de créer et de gérer des relations de synchronisation active SnapMirror entre deux clusters ONTAP. Pour en savoir plus sur le plug-in vCenter des outils ONTAP, rendez-vous sur<block ref="238135431b1a2d25dda1f29146112b60" category="inline-link-rx"></block> ou accédez directement à<block ref="50b45f063e0080035a4876db2aa395bd" category="inline-link-rx"></block>.</block>
  <block id="0ed4664c1cb15021c67bd0d4753c18f0" category="paragraph">La gestion d'une configuration vMSC avec SnapMirror Active Sync est différente de celle d'un MetroCluster. Tout d'abord, les SMAs sont une configuration SAN uniquement, aucun datastore NFS ne peut être protégé avec la synchronisation active SnapMirror. Ensuite, vous devez mapper les deux copies des LUN sur vos hôtes ESXi afin qu'elles puissent accéder aux datastores répliqués dans les deux domaines de défaillance.</block>
  <block id="b6930b017bd126db888766f9750b206b" category="section-title">Configuration de VMware vSphere</block>
  <block id="2587ca69fa38fdcf84be76d7302e4e48" category="admonition">Rien dans ce document ne remplace<block ref="0802e50581eb79c07178f36fed073afc" category="inline-link-rx"></block>. Ce contenu est fourni pour faciliter les références et ne remplace pas la documentation officielle de VMware.</block>
  <block id="7fb958c31516ee34a32cd425ce9f6084" category="list-text">Vous pouvez créer une alarme basée sur des événements qui est déclenchée lorsqu'une machine virtuelle viole une règle d'affinité VM-Host. Dans le client vSphere, ajoutez une nouvelle alarme pour la machine virtuelle et sélectionnez « VM viole VM-Host Affinity Rule » comme déclencheur d'événement. Pour plus d'informations sur la création et la modification d'alarmes, reportez-vous à la <block ref="68398319bb6b2bfb9f64390479799795" category="inline-link-macro-rx"></block> documentation.</block>
  <block id="0daafa8f38daf57ac774520f73c6131b" category="section-title">Créez des clusters de datastores si nécessaire</block>
  <block id="5888812a5e670c1dc41279a5d93cc502" category="paragraph">*Lors de l'utilisation du stockage ONTAP, il est recommandé de désactiver Storage DRS.</block>
  <block id="f58d6a99824e61e497bca94714a3efef" category="list-text">Storage DRS n'est généralement pas nécessaire ou recommandé pour une utilisation avec les systèmes de stockage ONTAP.</block>
  <block id="8525b77695e58a3254731f53ce2b2162" category="list-text">ONTAP offre ses propres fonctionnalités d'efficacité du stockage, telles que la déduplication, la compression et la compaction, qui peuvent être affectées par Storage DRS.</block>
  <block id="c9a841ce409cdc722c7bdd080f0f88de" category="list-text">Si vous utilisez des snapshots ONTAP, Storage vMotion laisse derrière lui la copie de la machine virtuelle dans le snapshot, ce qui augmente potentiellement l'utilisation du stockage et peut avoir un impact sur les applications de sauvegarde telles que NetApp SnapCenter qui suivent les machines virtuelles et leurs snapshots ONTAP.</block>
  <block id="e5239709587bb3ebb34629be6c41ac7b" category="paragraph">Les solutions VMSC sont prises en charge avec NetApp® MetroCluster™ et la synchronisation active SnapMirror (anciennement appelée SnapMirror Business Continuity ou SMBC) et assurent une continuité de l'activité avancée si un ou plusieurs domaines à défaillance subissent une panne totale. La résilience aux différents modes de défaillance dépend des options de configuration que vous choisissez.</block>
  <block id="5c6034b4452ec29d83cf38ddf5f9e2f6" category="paragraph">L'architecture ONTAP est une plateforme de stockage flexible et évolutive qui fournit des services SAN (FCP, iSCSI et NVMe-of) et NAS (NFS v3 et v4.1) pour les datastores. Les systèmes de stockage NetApp AFF, ASA et FAS utilisent le système d'exploitation ONTAP pour offrir des protocoles supplémentaires pour l'accès au stockage invité comme S3 et SMB/CIFS.</block>
  <block id="e495475024bf1186bfbf671683e828e6" category="paragraph">La synchronisation active NetApp SnapMirror offre une protection granulaire des datastores avec les protocoles SAN FCP et iSCSI, ce qui vous permet de protéger de manière sélective uniquement les workloads prioritaires. Il offre un accès actif/actif aux sites locaux et distants, contrairement à NetApp MetroCluster, qui est une solution de secours actif. Depuis la version ONTAP 9.15.1, la synchronisation active SnapMirror prend en charge une fonctionnalité actif-actif symétrique. Elle permet d'effectuer des opérations de lecture et d'écriture d'E/S à partir des deux copies d'un LUN protégé grâce à une réplication synchrone bidirectionnelle, ce qui permet aux deux copies de LUN de traiter les opérations d'E/S localement. Avant ONTAP 9.15.1, la synchronisation active SnapMirror prend uniquement en charge les configurations actif-actif asymétriques, dans lesquelles les données du site secondaire sont proxys vers un LUN.</block>
  <block id="f1d3123c01306b368942c0739b049d98" category="paragraph">VSphere Metro Storage Cluster (vMSC) est une configuration certifiée qui protège les machines virtuelles et les conteneurs contre les défaillances. Pour y parvenir, les concepts de stockage étendus ainsi que les clusters d'hôtes ESXi sont répartis sur différents domaines à défaillance, tels que les racks, les bâtiments, les campus ou même les villes. Les technologies de stockage avec synchronisation active NetApp MetroCluster et SnapMirror assurent respectivement une protection RPO=0 ou RPO=0 aux clusters hôtes. La configuration vMSC est conçue pour assurer la disponibilité continue des données, même en cas de défaillance d’un « site » physique ou logique complet. Un périphérique de stockage faisant partie de la configuration vMSC doit être certifié après avoir suivi un processus de certification vMSC réussi. Tous les périphériques de stockage pris en charge se trouvent dans le<block ref="293ceee3268d7991d7fe245e02c1c5c9" category="inline-link-rx"></block>.</block>
  <block id="1e1566860cb6afbc338f9fba32c4e5e5" category="list-text">Synchronisation active symétrique (ONTAP 9.15.1)</block>
  <block id="9354dd74ac44e8083ef676403653cf41" category="image-alt">Schéma VMSC avec MSAS et médiateur</block>
  <block id="b9ca5ba97cf75d3dafb51f78e073770a" category="inline-link">Documents NetApp</block>
  <block id="1c71125ba0668792e46d93c17dc6c428" category="paragraph">Reportez-vous<block ref="9ace5d3ebe2fe57037322de54ac9a869" category="inline-link-rx"></block> à la pour obtenir des informations spécifiques sur la conception et le déploiement de la synchronisation active SnapMirror.</block>
  <block id="c50c3de11b39aab15ac6b3b860691105" category="paragraph">La fonctionnalité VMware Storage DRS permet l'agrégation de datastores dans une seule unité et équilibre les disques de machines virtuelles lorsque les seuils de contrôle des E/S du stockage (SIOC) sont dépassés.</block>
  <block id="a6389705a0010980a83767268763aa53" category="sidebar">Volumes virtuels (vVols) avec les outils ONTAP 10</block>
  <block id="d858ab232a556e2be473d51d09bc0c3d" category="sidebar">Checklist d'installation des outils ONTAP</block>
  <block id="2e0a1393be1d4f990f277513b8384831" category="cell">Conserver la valeur par défaut (1) pour plus d'informations, voir <block ref="3b98534d1167689d42f2d1a533484036" category="inline-link-macro-rx"></block></block>
  <block id="79a22fb066bcc86a371f557f30051d43" category="inline-link">configurer le zoning</block>
  <block id="b5d661217ddfecce129a41707ffa9fa9" category="list-text">Déterminez si vous allez utiliser Fibre Channel (FC) pour la connectivité de stockage. Si c'est le cas, vous devez<block ref="1ce5ae0107fd362eacaa4ef5b56c5d82" category="inline-link-rx"></block> sur vos commutateurs FC pour activer la connectivité entre les hôtes ESXi et les LIF FC du SVM.</block>
  <block id="49e1b0dac188727de519431ac2068825" category="list-text">Demandez les informations IP suivantes à votre équipe réseau. Les trois premières adresses IP sont requises ; les nœuds deux et trois sont utilisés pour les déploiements scale-out de haute disponibilité (HA). Les enregistrements d'hôte DNS sont requis et tous les noms de nœud et toutes les adresses doivent se trouver sur le même VLAN et sous-réseau.</block>
  <block id="7be8dd6dbcd142349f300df69f6a63d2" category="list-title"><block ref="beadfa85a2fdca06b91edc1131c603e6" category="inline-image-macro-rx" type="image"></block> Stockage</block>
  <block id="829d9899725b36358387edfa5df0e486" category="list-title"><block ref="99e8b2f00e172bfcff96afdce69907bc" category="inline-image-macro-rx" type="image"></block> Déployez l'OVA</block>
  <block id="2c63315a0e6899fa3f810f1b06553689" category="list-title"><block ref="ef78558f80439832e0f51cc22cee8b8c" category="inline-image-macro-rx" type="image"></block> Ajouter des vCenters aux outils ONTAP</block>
  <block id="0547f403694814dca82327ab77f95205" category="list-title"><block ref="36915574c413876eaa75cbd48f69fd00" category="inline-image-macro-rx" type="image"></block> Ajout de systèmes back-end de stockage aux outils ONTAP</block>
  <block id="3317c36267d6f484693b29dbd86b1e79" category="list-text">En cas d'utilisation en cas d'utilisation de la colocation du stockage avec les SVM</block>
  <block id="5abf46747a299bb4d24d81d3a3f343aa" category="list-text"><block ref="40ea307f91b1c1591600230b15a0b728" category="inline-link-rx"></block> Dans le Gestionnaire d'outils ONTAP et les associer à des vCenters.</block>
  <block id="e69b3c58a2b1480f291387c690bf92b4" category="list-text"><block ref="9f5477aac946ec407262cd052d80864d" category="inline-link-rx"></block> Dans l'interface utilisateur vCenter des outils ONTAP.</block>
  <block id="1ca4d08fe4d0cced2e4ebb5629b6613c" category="list-text">Si *NOT* utilise des SVM mutualisées</block>
  <block id="9e80f1d38a7781fc49c6800d20337ec2" category="list-text"><block ref="40ea307f91b1c1591600230b15a0b728" category="inline-link-rx"></block> Directement dans l'interface utilisateur vCenter des outils ONTAP. Dans ce scénario, il est également possible d'ajouter directement des SVM lorsque vous n'utilisez pas les vVols.</block>
  <block id="421bdf5be659af6d75aab31df92b7907" category="list-title"><block ref="430057c670c01688e904ed2ba129a0b5" category="inline-image-macro-rx" type="image"></block> Configuration des services de l'appliance (en option)</block>
  <block id="24db11216549ee55172c33cf3def2f3f" category="inline-image-macro">Neuf</block>
  <block id="8a339db13a88428ad39d370cfdd1129a" category="list-title"><block ref="b37b448eff4f65237cf47b29bdd2817c" category="inline-image-macro-rx" type="image"></block> Certificats (facultatif)</block>
  <block id="a185c3c138dca5ef46afc33288a67d1f" category="inline-image-macro">Dix</block>
  <block id="71fc21799db94f8cae72c8732659492c" category="list-title"><block ref="6097494f0af631df68e3dcb7a6da8d2a" category="inline-image-macro-rx" type="image"></block> Autres tâches post-déploiement</block>
  <block id="93da9d9a3842b9e17ab9de43211bf697" category="paragraph">Pour plus d'informations, reportez-vous à la section<block ref="0802e50581eb79c07178f36fed073afc" category="inline-link-rx"></block>_.__</block>
  <block id="275507174f3ab21b1a65c1d5e8446001" category="paragraph">Vous devez également vous reporter<block ref="0802e50581eb79c07178f36fed073afc" category="inline-link-rx"></block> à .</block>
  <block id="c44625cf01f743c720301c28e8461709" category="list-text">Notez que cette étape peut prendre jusqu'à 45 minutes</block>
  <block id="7747c50f7bb3ac05c39d999f8d5ce43e" category="list-text">À l'étape 3 du déploiement d'OVA, sélectionnez l'option « personnaliser le matériel de cette machine virtuelle » et définissez les paramètres suivants à l'étape 10 :</block>
  <block id="a7510781f5c52d40e5706471809518f0" category="list-text">« Activer l'ajout à chaud du processeur »</block>
  <block id="5b1ae3ca31ee580e9664ebf0949a302c" category="list-text">« Mémoire enfichable à chaud »</block>
  <block id="2cd9adcb9e8de7c58834011ca647797d" category="list-text"><block ref="4ccf4d83bac775854f5f0cfb549c6d86" category="inline-link-rx"></block> Utilisation du fichier JSON inclus si vous n'utilisez pas admin.</block>
  <block id="067561a3b92d67321174249eb7de567d" category="paragraph">En 2012, NetApp a commencé à travailler avec VMware pour prendre en charge les API vSphere pour Storage Awareness (VASA) pour vSphere 5. Ce premier VASA Provider a autorisé la définition des fonctionnalités de stockage dans un profil qui pouvait être utilisé pour filtrer les datastores lors du provisionnement et pour vérifier par la suite la conformité avec la règle. Cette évolution a vu le jour, de nouvelles fonctionnalités permettant d'automatiser davantage le provisionnement, ainsi que l'ajout de volumes virtuels ou de vVols où des objets de stockage individuels sont utilisés pour les fichiers de machines virtuelles et les disques virtuels. Il peut s'agir de LUN, de fichiers et désormais d'espaces de noms vSphere 8 NVMe (utilisés avec les outils ONTAP 9.13P2). NetApp a travaillé en étroite collaboration avec VMware en tant que partenaire de référence pour les vVols publiés avec vSphere 6 en 2015, et à nouveau en tant que partenaire de conception pour les vVols utilisant NVMe over Fabrics dans vSphere 8. NetApp continue d'améliorer les vVols pour tirer parti des dernières fonctionnalités d'ONTAP.</block>
  <block id="e867f73e9a09d015c82be5c45264cda9" category="paragraph">VVols sont les fichiers et disques de machines virtuelles réellement stockés dans le datastore vVols. L'utilisation du terme vVol (singulier) fait référence à un fichier, une LUN ou un espace de nom spécifique unique. ONTAP crée des namespaces NVMe, des LUN ou des fichiers en fonction du protocole utilisé par le datastore. Il existe plusieurs types distincts de vVols : les plus courants sont Config (le seul avec VMFS, il contient des fichiers de métadonnées tels que le fichier VMX de la machine virtuelle), Data (disque virtuel ou VMDK) et Swap (créé lorsque la machine virtuelle est mise sous tension). Les vVols protégés par le chiffrement VMware VM seront de type autre. Le chiffrement des machines virtuelles VMware ne doit pas être confondu avec le chiffrement du volume ou de l'agrégat ONTAP.</block>
  <block id="f615a85ee8b4ffd3bdd64ab72c2cf934" category="paragraph">Comme mentionné ci-dessus, l'utilisation de règles peut aider à rationaliser la tâche de provisionnement d'une machine virtuelle ou d'un VMDK. Il vous suffit de sélectionner une règle appropriée, et le fournisseur VASA affiche les datastores vVols qui prennent en charge cette règle et place le vVol dans un FlexVol volume individuel conforme.</block>
  <block id="d5938f26039c87ff0b18251b9b89e0ec" category="list-text">La création de clones est rapide au sein d'un seul volume ou sur plusieurs volumes d'un cluster ONTAP. C'est un avantage par rapport aux clones classiques compatibles VAAI. Ils sont également efficaces en termes de stockage. Les clones d'un volume utilisent un clone de fichier ONTAP, qui ressemble aux volumes FlexClone et ne stockent que les modifications du fichier vVol source, de la LUN ou de l'espace de noms. Ainsi, les machines virtuelles à long terme pour la production ou d'autres applications sont créées rapidement, prennent un minimum d'espace et peuvent bénéficier de la protection au niveau des machines virtuelles (à l'aide du plug-in NetApp SnapCenter pour VMware vSphere, des snapshots gérés par VMware ou de la sauvegarde VADP) et de la gestion des performances (avec ONTAP QoS). Les clones intervolumes sont bien plus rapides avec les vVols qu'avec VAAI becuase avec VASA, nous pouvons créer le clone et y autoriser l'accès au niveau de la destination avant la fin de la copie. Les blocs de données sont copiés en arrière-plan pour remplir le vVol de destination. Cette approche est similaire à la méthode de déplacement de LUN sans interruption de ONTAP pour les LUN classiques.</block>
  <block id="5c2620ed6abb266a7824246fc409e405" category="admonition">Si un volume est configuré en mode « Thick provisioning », veillez à désactiver complètement toutes les fonctions d'efficacité de ce volume, y compris la décompression et la suppression de la déduplication à l'aide de la<block ref="3cfeff511a11b8c5f54ce9749a719a58" prefix=" " category="inline-code"></block> commande. Le volume ne doit pas apparaître en<block ref="df899f2d908ec33afe1d01ee26b3dd47" prefix=" " category="inline-code"></block> sortie. Si c'est le cas, le volume est encore partiellement configuré pour les fonctions d'efficacité. Par conséquent, les garanties de remplacement fonctionnent différemment, ce qui augmente le risque que les dépassements de configuration entraînent un manque inattendu d'espace du volume, ce qui entraîne des erreurs d'E/S de la base de données.</block>
  <block id="d276d666f03c049a59433c8727efaa6e" category="paragraph">Dans les environnements Linux, créez des groupes de volumes logiques sur l'ensemble de l'unité de disque. Lorsqu'une partition est requise, vérifiez l'alignement en exécutant et en<block ref="ab425294b9ef9f9c8acbc3f08f92b37d" prefix=" " category="inline-code"></block> vérifiant que le début de chaque partition est un multiple de huit. Cela signifie que la partition démarre à un multiple de huit secteurs de 512 octets, soit 4 Ko.</block>
  <block id="e23f5b5639a79ab22ace94b51b47872d" category="paragraph"><block ref="e23f5b5639a79ab22ace94b51b47872d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="39e45e79eb595c951cff8267572302f1" category="inline-image-macro">Configuration SyncMirror</block>
  <block id="8c91b2538377a2c3400ec4694ba15e2e" category="paragraph"><block ref="8c91b2538377a2c3400ec4694ba15e2e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="073b52a996437eabf93f7783b02e2fe9" category="paragraph"><block ref="fe3ee14511b9b1e5dfd5af1f82ac3216" category="inline-link-macro-rx"></block>Exécuté sur un troisième site, le logiciel peut contrôler l'état de santé de l'environnement MetroCluster, envoyer des notifications et forcer un basculement en cas d'incident. Une description complète du Tiebreaker se trouve sur le <block ref="2acc94a061be1196588f7f734d193bf6" category="inline-link-macro-rx"></block>, mais le but principal du Tiebreaker MetroCluster est de détecter la perte du site. Il doit également faire la distinction entre la perte du site et une perte de connectivité. Par exemple, le basculement ne doit pas se produire car le disjoncteur d'attache n'a pas pu atteindre le site principal. C'est pourquoi le disjoncteur d'attache surveille également la capacité du site distant à contacter le site principal.</block>
  <block id="007bfe897ab1dfc6713daff4c13130e2" category="admonition">Le logiciel MCTB ne vérifie pas que NVRAM était et/ou que les plexes sont synchronisés lorsqu'un basculement est forcé. Le basculement automatique, s'il est configuré, doit être désactivé pendant les opérations de maintenance qui entraînent une perte de synchronisation des plexes NVRAM ou SyncMirror.</block>
  <block id="d5e917df8e0b7f1db3996ead2cbeb2ac" category="paragraph">Le médiateur ONTAP est utilisé avec MetroCluster IP et certaines autres solutions ONTAP. Il fonctionne comme un service disjoncteur d'attache classique, tout comme le logiciel disjoncteur d'attache MetroCluster mentionné ci-dessus, mais comprend également une fonctionnalité essentielle, qui effectue un basculement automatique sans surveillance.</block>
  <block id="bf74d7de09985a8ef553e5122b5d0f7c" category="inline-image-macro">Diagramme ClusterLion</block>
  <block id="0354d54d7a567ab0e86cd8a04f4919a1" category="paragraph"><block ref="0354d54d7a567ab0e86cd8a04f4919a1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0db380344593268d0331dffbd0e53491" category="inline-image-macro">Architecture IP de MetroCluster</block>
  <block id="207f169ffa50efdada53e61e95be500f" category="paragraph"><block ref="207f169ffa50efdada53e61e95be500f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d012707a79628e35e35aa78aae04ba03" category="inline-image-macro">MetroCluster à quatre nœuds</block>
  <block id="d2d10d2707ff9930a55b8735ba28ca8b" category="paragraph"><block ref="d2d10d2707ff9930a55b8735ba28ca8b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f76fa4fd08c3d58e5591281c16d5c61b" category="inline-image-macro">MetroCluster à deux nœuds</block>
  <block id="4cc7f7e2eae466068330e3136b2e786f" category="paragraph"><block ref="4cc7f7e2eae466068330e3136b2e786f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="57d3154f4afcd986d4f30b4e06c1c434" category="paragraph">Un volume flexible ONTAP, ou plus simplement, un volume n'est pas synonyme de LUN. Les volumes sont des conteneurs de gestion pour des données telles que des fichiers ou des LUN. Par exemple, une base de données peut être placée sur un jeu de bandes de 8 LUN, toutes les LUN étant contenues dans un seul volume.</block>
  <block id="05ef9b22209f0e35efc9b6f875ad3c55" category="inline-link-macro">Documentation ONTAP.</block>
  <block id="a9f5ed6c3fb24e75b9bbfde2801f43c5" category="paragraph">Pour plus d'informations sur les instantanés, reportez-vous au <block ref="8f47a9b0ccec19c7f5d940ab138ea0b4" category="inline-link-macro-rx"></block></block>
  <block id="7509bd2cfd7821f433d962315cc50a57" category="paragraph">Depuis ONTAP 9.12.1, les snapshots ne sont pas uniquement en lecture seule et peuvent également être protégés contre la suppression accidentelle ou intentionnelle. Cette fonctionnalité s'appelle des snapshots inviolables. Une période de conservation peut être définie et appliquée via une règle Snapshot. Les snapshots obtenus ne peuvent pas être supprimés tant qu'ils n'ont pas atteint leur date d'expiration. Il n'y a pas de substitution administrative ou de centre de support.</block>
  <block id="287130f9ebd13d6ed68dd04d8d2a295e" category="admonition">Les snapshots inviolables ne peuvent pas être hiérarchisés à l'aide du pool de fabric.</block>
  <block id="c2f55c662895ff4fac4100a2a0852e43" category="paragraph">Pour plus d'informations sur les instantanés inviolables, consultez le <block ref="fd5bfd16d2f3d4d67a500529a5ee8cad" category="inline-link-macro-rx"></block></block>
  <block id="be7dc70d98bcb6099a5c94c0eb263502" category="paragraph">Les snapshots peuvent également être répliqués sur un système distant. Cela inclut des snapshots inviolables, où la période de conservation est appliquée et appliquée sur le système distant. Il en résulte les mêmes avantages en matière de protection des données que les snapshots locaux, mais les données se trouvent sur une seconde baie de stockage. Cela permet de s'assurer que la destruction de la baie d'origine ne compromet pas les sauvegardes.</block>
  <block id="170814cc5599dd2691018c487b6c756b" category="paragraph">Pour plus d'informations sur SnapMirror, reportez-vous au <block ref="3a921b7bc4d1ecfb45f8d64003b59241" category="inline-link-macro-rx"></block></block>
  <block id="f1e054edf08e67911f64f3d6bc85055c" category="paragraph">Un système de stockage ONTAP nouvellement configuré est similaire à un serveur VMware ESX nouvellement provisionné, car aucun utilisateur ne peut prendre en charge avant la création d'une machine virtuelle. Avec ONTAP, vous créez une machine virtuelle de stockage (SVM) qui devient l'unité de gestion du stockage la plus élémentaire. Chaque SVM dispose de ses propres ressources de stockage, configurations de protocoles, adresses IP et WWN FCP. Il s'agit de la base de la colocation ONTAP.</block>
  <block id="9f531561663c2d70601e59d0a2a97e22" category="paragraph">Pour plus d'informations sur les SVM, reportez-vous au <block ref="49f63552efbf93d6a834173c0aa523ad" category="inline-link-macro-rx"></block></block>
  <block id="7995495e3afeef685b0a0bcf51360d6c" category="paragraph">Pour plus d'informations sur le contrôle d'accès administratif, reportez-vous au <block ref="a0740fbcbe9ba6690a7ab99ab89cd2c9" category="inline-link-macro-rx"></block></block>
  <block id="19fd31cbf45473230fbcebf8392cc91e" category="section-title">Authentification multifacteur (MFA)</block>
  <block id="96654aef2c50a23153b1537b5229776f" category="paragraph">Pour plus d'informations sur l'authentification multifacteur (MFA), consultez le <block ref="1786169af27633b737f29186948225e1" category="inline-link-macro-rx"></block></block>
  <block id="e888b1b74bec5238c3c604159ac1d53a" category="paragraph">Pour plus d'informations sur API RBAC, reportez-vous au <block ref="e61ba9faf8dbe169378ea875c9b479b4" category="inline-link-macro-rx"></block></block>
  <block id="6e09a67fb21def2cb508cbfe0d7c0794" category="paragraph">Pour plus d'informations sur la vérification multiadministrateur (MAV), reportez-vous au <block ref="88147b7c4319c7463e1de20879284ceb" category="inline-link-macro-rx"></block></block>
  <block id="d682e5055f8368ad42d44e0de5e75ed3" category="inline-image-macro">Synchronisation active SnapMirror en fonctionnement normal</block>
  <block id="a61d348ee21d7fdf1a9da822a79df846" category="paragraph"><block ref="a61d348ee21d7fdf1a9da822a79df846" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3fe281f607d85b52408e82cb2d7aef71" category="inline-image-macro">Échec de la synchronisation active SnapMirror</block>
  <block id="c5ff28a15762db1ce9589bc45fe42a83" category="paragraph"><block ref="c5ff28a15762db1ce9589bc45fe42a83" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a98433bfbc9755650778888be2e155c8" category="inline-image-macro">Basculement de la synchronisation active SnapMirror</block>
  <block id="5fe2be834f0686a9a02a2872ecb20f91" category="paragraph"><block ref="5fe2be834f0686a9a02a2872ecb20f91" category="inline-image-macro-rx" type="image"></block></block>
  <block id="40685542fb725d5516910c5721538340" category="inline-image-macro">Réparation de la synchronisation active SnapMirror</block>
  <block id="67e60a13c39559320bab1f6f456824d0" category="paragraph"><block ref="67e60a13c39559320bab1f6f456824d0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="217536ed57b639cdf05f688cf8ddaca1" category="inline-image-macro">Rétablissement de la synchronisation active SnapMirror</block>
  <block id="362b862a6b72622be34b2904dcbf413b" category="paragraph"><block ref="362b862a6b72622be34b2904dcbf413b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f060f17ec7a3fc2a182a4759545d4cb3" category="paragraph"><block ref="f060f17ec7a3fc2a182a4759545d4cb3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3d25a1eebebf538e68ea79a21fdeb31c" category="paragraph"><block ref="3d25a1eebebf538e68ea79a21fdeb31c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1cf9d22584fea5a10f4ed164a871a45f" category="paragraph"><block ref="1cf9d22584fea5a10f4ed164a871a45f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4be3d396256a7548ce446a9a03183122" category="paragraph"><block ref="4be3d396256a7548ce446a9a03183122" category="inline-image-macro-rx" type="image"></block></block>
  <block id="05933557921f3e80d9d78fff7d9532d6" category="paragraph"><block ref="05933557921f3e80d9d78fff7d9532d6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2a5e066e529edd11b35f46c161170620" category="paragraph">En revanche, une application en cluster telle qu'Oracle RAC peut fournir un service qui est disponible simultanément sur deux sites différents. La perte d'un site ne signifie pas la perte du service d'application dans son ensemble. Les instances restent disponibles et s'exécutent sur le site survivant.</block>
  <block id="d629eadf33041c24ee81c3752a895f8d" category="paragraph"><block ref="d629eadf33041c24ee81c3752a895f8d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="267017761cb9de7ce4e0ea9f0e078628" category="paragraph"><block ref="267017761cb9de7ce4e0ea9f0e078628" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fd994146b555ce2a39038a16098a6e3e" category="list-text"><block ref="9df22f196a33acd0b372fe502de51211" prefix="" category="inline-code"></block>- récupérer uniquement les données lues de façon aléatoire</block>
  <block id="0c65a737281c49235c3058020e81f7b9" category="list-text"><block ref="8805d416ce540c5f2df34af5b18d742b" prefix="" category="inline-code"></block>- récupérer toutes les données lues de manière séquentielle ou aléatoire</block>
  <block id="deea309eeb62f907bfa37ca436857255" category="list-text"><block ref="334c4a4c42fdb79d7ebc3e73b517e6f8" prefix="" category="inline-code"></block>- récupérer toutes les données lues de manière séquentielle ou aléatoire</block>
  <block id="c4216ce97dadec9cf3de76609a5a07de" category="list-text"><block ref="a181a603769c1f98ad927e7367c7aa51" prefix="" category="inline-code"></block>- ne pas récupérer les données du niveau de capacité</block>
  <block id="47f64097ec44c9f18f4025941f2e4436" category="inline-image-macro">Hiérarchisation FabricPool</block>
  <block id="0a5778c8b17c5df28190c8f022c4e11a" category="paragraph"><block ref="0a5778c8b17c5df28190c8f022c4e11a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e6edcd80dc55ce70fb5c4fa1c13c9bc6" category="section-title">Hyper-Threading</block>
  <block id="7e4c522ec8e0c58e24f493765888ed54" category="paragraph">L'Hyper-threading fait référence à la mise en œuvre simultanée de plusieurs threads (SMT), qui améliore la parallélisation des calculs réalisés sur les processeurs x86. La colocation sécurisée est disponible sur les processeurs Intel et AMD.</block>
  <block id="4114d233d42e1381db8a36ed5a76930b" category="paragraph">L'Hyper-threading entraîne des CPU logiques qui apparaissent sous forme de CPU physiques au système d'exploitation. SQL Server voit ensuite ces CPU supplémentaires et les utilise comme s'il y avait plus de cœurs que physiquement présents. Cela peut considérablement améliorer les performances en augmentant la parallélisation.</block>
  <block id="fbb6d18b081bfa69df40139eb4b0213b" category="inline-image-macro">Message du journal SQL Server</block>
  <block id="d78202a5fb91002bb31924c80636beee" category="paragraph"><block ref="d78202a5fb91002bb31924c80636beee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8f2b07811863589142fb500958a93aef" category="paragraph">Bien que cela soit utile pour les requêtes volumineuses, il peut causer des problèmes de performances et limiter la simultanéité. Une meilleure approche consiste à limiter le parallélisme au nombre de cœurs physiques dans un seul socket de processeur. Par exemple, sur un serveur doté de deux sockets CPU physiques avec 12 cœurs par socket, quel que soit l'hyper-threading,<block ref="1abedc5f6ab369ab9fcd16d6b7990638" prefix=" " category="inline-code"></block> doit être défini sur 12.<block ref="1abedc5f6ab369ab9fcd16d6b7990638" prefix=" " category="inline-code"></block> Impossible de restreindre ou de dicter le CPU à utiliser. Elle limite le nombre de processeurs pouvant être utilisés par une seule requête de lot.</block>
  <block id="2bcdfd16d227f0659d58f9c368f92311" category="inline-link-macro">Configurez l'option de configuration du serveur de threads de travail max</block>
  <block id="784d03ae991a0cc4ef7f8b5318d0643e" category="paragraph">Quand devez-vous configurer SQL Server pour utiliser davantage de threads de travail ? Si la longueur moyenne de la file d'attente de travail de chaque planificateur est supérieure à 1, vous pouvez bénéficier de l'ajout de threads supplémentaires au système, mais uniquement si la charge n'est pas liée au processeur ou si d'autres files d'attente importantes sont en cours. Si l'une ou l'autre de ces opérations se produit, l'ajout de threads n'est pas utile, car ils finissent par attendre les autres goulets d'étranglement du système. Pour plus d'informations sur le nombre maximal de threads de travail, reportez-vous à la section <block ref="516f4431a9f331f442450f80b5638a9d" category="inline-link-macro-rx"></block>.</block>
  <block id="a5ee78f6f06a355d893076bd00799f33" category="inline-image-macro">Nombre MAX. De threads de travail</block>
  <block id="06a7934dd21e03f634b6cd9fc8dfafd5" category="paragraph"><block ref="06a7934dd21e03f634b6cd9fc8dfafd5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c7acc2cdcff9c9156a99e4f37871f0b3" category="searchtitle">Protection des bases de données Microsoft SQL Server sur ONTAP avec les commandes SnapCenter et T-SQL</block>
  <block id="d56a13248537a908d7fb7730827a3ea8" category="paragraph">La sécurisation d'un environnement de base de données SQL Server est un effort multidimensionnel qui va au-delà de la gestion de la base de données elle-même. ONTAP propose plusieurs fonctionnalités uniques conçues pour sécuriser l'aspect stockage de votre infrastructure de base de données.</block>
  <block id="1fdd8a4c4832d13ddabbb02c424cf87d" category="paragraph">Si les volumes, les systèmes de fichiers et les datastores hébergeant des bases de données virtualisées ne sont pas utilisés sur le site de reprise d'activité avant le basculement, il n'est pas nécessaire de les définir<block ref="a2626552f293b2377efe829e69d14daa" prefix=" " category="inline-code"></block> sur les volumes associés.</block>
  <block id="358f73eb3e0830400b47b849dd1ff244" category="summary">Microsoft SQL Server et le médiateur ONTAP</block>
  <block id="d7b47db08dce16a62f9ea97613e8f704" category="paragraph">Le Mediator est requis pour automatiser le basculement en toute sécurité. Dans l'idéal, elle serait placée sur un site tiers indépendant, mais elle peut toujours fonctionner pour la plupart des besoins si elle est en colocation avec l'un des clusters participant à la réplication.</block>
  <block id="f9619e52c7cdde4c0b1a97530a47dd35" category="section-title">Architecture de la synchronisation active SnapMirror avec actif-actif symétrique</block>
  <block id="19faeb7ab81d5f28227fc1778d55ff90" category="inline-image-macro">Architecture de synchronisation active SnapMirror</block>
  <block id="133eca4b24d6c05606859c2288c8ac7f" category="paragraph"><block ref="133eca4b24d6c05606859c2288c8ac7f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="441756ba9f536a754940c70c53cb3b13" category="paragraph">**Médiateur ONTAP**</block>
  <block id="b41efcb6893de373f77e07be9a8e0d32" category="paragraph"><block ref="b41efcb6893de373f77e07be9a8e0d32" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f830e7995cd120ac203db751bdb1174b" category="paragraph">NetApp propose Astra Trident pour fournir des fonctionnalités de gestion avancées du stockage. Par exemple, Astra Trident permet à un conteneur créé dans Kubernetes de provisionner automatiquement son stockage sur le Tier approprié, d'appliquer des règles d'exportation, de définir des règles Snapshot et même de cloner un conteneur vers un autre. Pour plus d'informations, reportez-vous à la <block ref="d243cca937364184efa824b0525b876a" category="inline-link-macro-rx"></block>.</block>
  <block id="e5f3f995b3e054f0d6bfdd13c3597e2c" category="paragraph"><block ref="e5f3f995b3e054f0d6bfdd13c3597e2c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9b87cb3e85b59ad2d04537560673f94b" category="inline-image-macro">Types d'E/S.</block>
  <block id="977d1017b39374152ac0d18ac3267ca2" category="paragraph"><block ref="977d1017b39374152ac0d18ac3267ca2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="77ea00d93c10244a077ab55be57f5c28" category="admonition">Vous pouvez sérieusement nuire aux performances en définissant ce paramètre ou le paramètre innodb_io_Capacity_max trop élevé et gaspillé</block>
</blocks>