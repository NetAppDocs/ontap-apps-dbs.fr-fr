<?xml version="1.0" encoding="UTF-8"?>
<blocks>
  <block id="d41d8cd98f00b204e9800998ecf8427e" category="summary"></block>
  <block id="30d965eef5ba25c6b9998ae38270b43e" category="doc">Mentions légales</block>
  <block id="e9c44bbfd795a5d63d74c6a77afee70d" category="paragraph">Les mentions légales donnent accès aux déclarations de copyright, aux marques, aux brevets, etc.</block>
  <block id="6016a2b341113bf496b719905398ecd2" category="section-title">Droits d'auteur</block>
  <block id="52009bb7ee17227f566cd26a02caee56" category="inline-link-macro"><block ref="52009bb7ee17227f566cd26a02caee56" category="inline-link-rx"></block></block>
  <block id="a1a9afcf552a769c282769271829889a" category="paragraph"><block ref="a1a9afcf552a769c282769271829889a" category="inline-link-macro-rx"></block></block>
  <block id="126a02652da6de02962cf1b654fd6376" category="section-title">Marques déposées</block>
  <block id="c4ce4761e466527d26b3e3d5ed1006fd" category="paragraph">NetApp, le logo NETAPP et les marques mentionnées sur la page des marques commerciales NetApp sont des marques commerciales de NetApp, Inc. Les autres noms de sociétés et de produits peuvent être des marques commerciales de leurs propriétaires respectifs.</block>
  <block id="f99aa604031e5049799e73b5c3748a98" category="inline-link-macro"><block ref="f99aa604031e5049799e73b5c3748a98" category="inline-link-rx"></block></block>
  <block id="5d545fe5152641e2ebe654e336e520e5" category="paragraph"><block ref="5d545fe5152641e2ebe654e336e520e5" category="inline-link-macro-rx"></block></block>
  <block id="be89498d2f8a22ce47c02ba9795fe2af" category="section-title">Brevets</block>
  <block id="d0b19d36be2c5f16e9aef46c8a452d3d" category="paragraph">Vous trouverez une liste actuelle des brevets appartenant à NetApp à l'adresse suivante :</block>
  <block id="88e5eabd3917048b6927c42496b98f86" category="inline-link-macro"><block ref="88e5eabd3917048b6927c42496b98f86" category="inline-link-rx"></block></block>
  <block id="dd38f906b37d412de7d1c1dcf4cbf31c" category="paragraph"><block ref="dd38f906b37d412de7d1c1dcf4cbf31c" category="inline-link-macro-rx"></block></block>
  <block id="56c34c6410dd45c5cec44149ad0ce037" category="section-title">Politique de confidentialité</block>
  <block id="8acb58cbd50ef1b468a020ee0bd351d3" category="inline-link-macro"><block ref="8acb58cbd50ef1b468a020ee0bd351d3" category="inline-link-rx"></block></block>
  <block id="2352c4e1f4d0024ade0869e00e6243f4" category="paragraph"><block ref="2352c4e1f4d0024ade0869e00e6243f4" category="inline-link-macro-rx"></block></block>
  <block id="c0227cef6f07a8cd2ac72f2945b031aa" category="section-title">Source ouverte</block>
  <block id="9b73989307c1975dfa4d5e1581e4afe8" category="paragraph">Les fichiers de notification fournissent des informations sur les droits d'auteur et les licences de tiers utilisés dans le logiciel NetApp.</block>
  <block id="253b40ae359ba25b56231803430c4873" category="section-title">ONTAP</block>
  <block id="856c8958afd787f748a4a025f649154a" category="inline-link-macro">Avis pour ONTAP 9.13.1</block>
  <block id="b22b3b2970d843f99e7e6904bea05207" category="inline-link-macro">Notification relative à ONTAP 9.12.1</block>
  <block id="0358f41254df2d512849db5a04b7e3d4" category="inline-link-macro">Notification relative à ONTAP 9.12.0</block>
  <block id="28f1290102a277ef2fd452d558c74219" category="inline-link-macro">Notification relative à ONTAP 9.11.1</block>
  <block id="57b07f14c8eb4660f94a86d29d53362d" category="inline-link-macro">Notification relative à ONTAP 9.10.1</block>
  <block id="396712eb9c1644241047ac30619b2b3e" category="inline-link-macro">Avis pour ONTAP 9.10.0</block>
  <block id="1e6000d4849ef9f3e08d1d9908e9f163" category="inline-link-macro">Notification relative à ONTAP 9.9.1</block>
  <block id="6f408b9c999245c7aa32bc9cb1a020f6" category="inline-link-macro">Notification relative à ONTAP 9.8</block>
  <block id="04b0bd5b1b4d414fdde93f809162d36d" category="inline-link-macro">Avis pour ONTAP 9.7</block>
  <block id="0c1d7dffcba488555d5eb39b8991e822" category="inline-link-macro">Avis pour ONTAP 9.6</block>
  <block id="a11ac6880e72412c0f54ae19bea3d191" category="inline-link-macro">Avis pour ONTAP 9.5</block>
  <block id="e49c3c01b15761b5f011d0bd2a0661a3" category="inline-link-macro">Avis pour ONTAP 9.4</block>
  <block id="bf7dcf6467a8a03b05b2d37d31d6eccd" category="inline-link-macro">Avis pour ONTAP 9.3</block>
  <block id="0328352fdfda84af6968462d1a67d3a6" category="inline-link-macro">Avis pour ONTAP 9.2</block>
  <block id="83904100c7d6fe0102e8b2b5bd8ec4bb" category="inline-link-macro">Avis pour ONTAP 9.1</block>
  <block id="5672f5979be77bb31dd559817c9e1e76" category="paragraph"><block ref="f7a2b1db149ed9886af0ce846dbc3e14" category="inline-link-macro-rx"></block>
<block ref="b349c509ad858348b30db7e73307e3aa" category="inline-link-macro-rx"></block>
<block ref="0dce234dfded58bd461541473b86e42a" category="inline-link-macro-rx"></block>
<block ref="9760ec4df13f0afbdfec88ae16c871ae" category="inline-link-macro-rx"></block>
<block ref="b6dab2933dfb92cf0c1355707a4aec7c" category="inline-link-macro-rx"></block>
<block ref="1b7c80b26162b03bd0addd587f70df55" category="inline-link-macro-rx"></block>
<block ref="14faf912aa42102a6628af4551e02583" category="inline-link-macro-rx"></block>
<block ref="a90f36d649d3be5d386cc3563ab044fb" category="inline-link-macro-rx"></block>
<block ref="2cd65b4a044075cfd9ad4a91f42fdff4" category="inline-link-macro-rx"></block>
<block ref="5e764cc3fdcc19ff667796e414159bdc" category="inline-link-macro-rx"></block>
<block ref="561451f09c7bca700ea0d7833cd9e92e" category="inline-link-macro-rx"></block>
<block ref="d23d341a344216fbf99a91152429d49c" category="inline-link-macro-rx"></block>
<block ref="b35e8fbd7b0369b23734510994911ec4" category="inline-link-macro-rx"></block>
<block ref="41d4305cf7a6acb595086f123121a781" category="inline-link-macro-rx"></block>
<block ref="ea685649fabe77da53e843fec56f72b8" category="inline-link-macro-rx"></block></block>
  <block id="07ee2fe6f236deffba69a7cf80a680fd" category="section-title">Mediator ONTAP pour MCC IP</block>
  <block id="f089ab2b9f25f609795bdd46ae636f18" category="inline-link-macro">9.9.1 Avis pour le médiateur ONTAP pour MCC IP</block>
  <block id="239794a299abe62705440f2dab3114cb" category="inline-link-macro">9.8 Avis pour le médiateur ONTAP pour MCC IP</block>
  <block id="51fcca20d278d2d03192c01120f17442" category="inline-link-macro">9.7 Avis pour le médiateur ONTAP pour MCC IP</block>
  <block id="3ba2aeb22339424d5f5b15dafd2c3eca" category="paragraph"><block ref="c8696a7854fcd089ea112145e4968b10" category="inline-link-macro-rx"></block>
<block ref="4d19e06382f392d0f1a50df789d77c13" category="inline-link-macro-rx"></block>
<block ref="fe4ac88b6b3f1cb9f1dc6d5d4b5086ee" category="inline-link-macro-rx"></block></block>
  <block id="9e476387322a5c250893cf9c5c4ce78c" category="doc">Stratégies</block>
  <block id="b9e18a3460bc17eb9ea65b03f0167453" category="paragraph">Ceci est courant avec les bases de données. Les bases de données qui contiennent des blocs inactifs sont également candidates au Tiering FabricPool. Par exemple, une base de données de gestion de la chaîne logistique peut contenir des informations historiques qui doivent être disponibles si nécessaire, mais qui ne sont pas accessibles pendant les opérations normales. FabricPool peut être utilisé pour déplacer de manière sélective les blocs inactifs.</block>
  <block id="95e955bbbe5dd9520a6bf45b0d8a9d4c" category="paragraph">Par exemple, les fichiers de données s'exécutant sur un volume FabricPool avec un<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> la période de 90 jours permet de conserver les blocs auxquels le tier de performance accède au cours des 90 jours précédents. Toutefois, tout élément non utilisé pendant 90 jours est transféré vers le niveau de capacité. Dans d'autres cas, l'activité normale de l'application préserve les blocs corrects du niveau approprié. Par exemple, si une base de données est normalement utilisée pour traiter les 60 jours précédents de données sur une base régulière, c'est beaucoup moins<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> la période peut être définie car l'activité naturelle de l'application s'assure que les blocs ne sont pas déplacés prématurément.</block>
  <block id="c33af7c93d461803ceaf8531e861017d" category="paragraph">Le<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> la politique doit être utilisée avec soin pour les bases de données. De nombreuses bases de données ont des activités périodiques, comme le processus de fin de trimestre ou les opérations de réindexation. Si la période de ces opérations est supérieure à<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> des problèmes de performances peuvent se produire. Par exemple, si le traitement de fin de trimestre nécessite 1 To de données qui n'étaient pas modifiées, ces données peuvent maintenant être présentes sur le niveau de capacité. Les lectures à partir du niveau de capacité sont souvent extrêmement rapides et ne provoquent pas de problèmes de performance, mais les résultats exacts dépendent de la configuration du magasin d'objets.</block>
  <block id="03431a55183cb73a12c1bbc3e1927678" category="paragraph">Le<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> la règle doit être définie de manière suffisamment élevée pour conserver les fichiers qui peuvent être requis sur le niveau de performance. Par exemple, une base de données dans laquelle les 60 derniers jours de données peuvent être requis avec des performances optimales justifierait de définir le<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> période à 60 jours. Des résultats similaires pourraient également être obtenus en fonction des modèles d'accès aux fichiers. Par exemple, si les 90 derniers jours de données sont requis et que l'application accède à cette période de 90 jours, les données restent sur le Tier de performance. Réglage du<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> une période de 2 jours permettrait de hiérarchiser les données rapidement lorsque celles-ci deviennent moins actives.</block>
  <block id="25d9496e96e698b08c4fc713bfc9a5ca" category="paragraph">Le<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> la règle est requise pour la hiérarchisation de ces blocs, car uniquement le système<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> la règle affecte les blocs qui se trouvent dans le système de fichiers actif.</block>
  <block id="55fad400d892fb6062e67904fa9be485" category="admonition">Tout type d'accès aux données réinitialise les données de la carte thermique. Par conséquent, les analyses de la table complète des bases de données, et même les opérations de sauvegarde qui lisent les fichiers source, empêchent le Tiering, car nécessaire<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> le seuil n'est jamais atteint.</block>
  <block id="117c4b6bad0236ab23e0fe29aead8aef" category="paragraph">Bien que le redimensionnement des LUN soit une option d'augmentation de la capacité, il est généralement préférable d'utiliser un LVM, y compris Oracle ASM. L'une des principales raisons pour lesquelles les LVM existent est d'éviter la nécessité d'un redimensionnement des LUN. Avec une LVM, plusieurs LUN sont reliées entre elles dans un pool de stockage virtuel. Les volumes logiques extraits de ce pool sont gérés par le LVM et peuvent être facilement redimensionnés. Il est également possible d'éviter les points sensibles sur un disque en distribuant un volume logique donné à tous les LUN disponibles. Une migration transparente peut généralement être effectuée à l'aide du gestionnaire de volumes pour déplacer les extensions sous-jacentes d'un volume logique vers de nouvelles LUN.</block>
  <block id="4d4855a15e1f9d6fd8f8bdf1668c537e" category="doc">NVFAIL forcé manuellement</block>
  <block id="8772c1c8bed97f5c942657feeb8bfb6f" category="admonition">Cette section décrit en détail les fonctionnalités de base de ONTAP NVFAIL et aborde également les sujets spécifiques à MetroCluster.</block>
  <block id="14d74316044293d1ebd8c5a01ff90055" category="paragraph">Avec MetroCluster, une écriture n'est pas confirmée tant qu'elle n'a pas été connectée à la NVRAM et à la NVRAM locales sur au moins un autre contrôleur. Cette approche évite toute panne matérielle ou de courant qui entraîne une perte des E/S à la volée En cas de panne de la mémoire NVRAM locale ou de la connectivité aux autres nœuds, les données ne seront plus mises en miroir.</block>
  <block id="d820d86d09ea05a0de19c3aacbfb72b2" category="paragraph">Si la mémoire NVRAM locale signale une erreur, le nœud s'arrête. Cet arrêt entraîne le basculement vers un contrôleur partenaire lorsque des paires haute disponibilité sont utilisées. Avec MetroCluster, le comportement dépend de la configuration globale choisie, mais il peut entraîner un basculement automatique vers la note distante. Dans tous les cas, aucune donnée n'est perdue parce que le contrôleur qui connaît la défaillance n'a pas acquitté l'opération d'écriture.</block>
  <block id="886174de078cee4595eb8a8d07f81703" category="paragraph">Une défaillance de connectivité site à site qui bloque la réplication NVRAM sur des nœuds distants est une situation plus compliquée. Les écritures ne sont plus répliquées sur les nœuds distants, ce qui crée un risque de perte de données en cas d'erreur catastrophique sur un contrôleur. Plus important encore, une tentative de basculement vers un autre nœud dans ces conditions entraîne une perte de données.</block>
  <block id="790ec042c9b89dac2390ea81b9c29a51" category="paragraph">Le facteur de contrôle est de savoir si la NVRAM est synchronisée. Si la mémoire NVRAM est synchronisée, le basculement nœud à nœud peut se poursuivre sans risque de perte de données. Dans une configuration MetroCluster, si la mémoire NVRAM et les plexes d'agrégats sous-jacents sont synchronisés, vous pouvez effectuer le basculement sans risque de perte de données.</block>
  <block id="3d936bb059b98a2fc7c177d20eb755c9" category="paragraph">ONTAP n'autorise pas le basculement ou le basculement lorsque les données ne sont pas synchronisées, sauf si le basculement ou le basculement est forcé. Le fait de forcer une modification des conditions de cette manière reconnaît que les données peuvent être laissées pour compte dans le contrôleur d'origine et que la perte de données est acceptable.</block>
  <block id="3d37a3a8ed77bebc986238aedccecbc9" category="paragraph">Les bases de données sont particulièrement vulnérables à la corruption si un basculement ou un basculement est forcé, car les bases de données conservent des caches internes de données plus volumineux sur disque. En cas de basculement forcé ou de basculement forcé, les modifications précédemment reconnues sont effectivement supprimées. Le contenu de la baie de stockage recule dans le temps et l'état du cache de la base de données ne reflète plus l'état des données sur le disque.</block>
  <block id="7ad23b7fa394c8666b132d78a58b1987" category="paragraph">Afin de protéger les applications de cette situation, ONTAP permet de configurer les volumes pour une protection spéciale contre les défaillances de mémoire NVRAM. Lorsqu'il est déclenché, ce mécanisme de protection entraîne l'entrée d'un volume dans un état appelé NVFAIL. Cet état entraîne des erreurs d'E/S qui entraînent l'arrêt d'une application et n'utilisent donc pas de données obsolètes. Les données ne doivent pas être perdues car des écritures reconnues sont toujours présentes sur le système de stockage et, avec les bases de données, toutes les données de transaction validées doivent être présentes dans les journaux.</block>
  <block id="99259586124503e22927506a7ed3738d" category="paragraph">Les étapes suivantes habituelles sont qu'un administrateur arrête complètement les hôtes avant de remettre manuellement en ligne les LUN et les volumes. Bien que ces étapes puissent impliquer un certain travail, cette approche est le moyen le plus sûr d'assurer l'intégrité des données. Toutes les données n'ont pas besoin de cette protection. C'est pourquoi NVFAIL peut être configuré volume par volume.</block>
  <block id="13fbc5a220fe8007dcaea69217bba134" category="paragraph">Pour forcer un basculement avec un cluster d'applications (y compris VMware, Oracle RAC et autres) distribué sur plusieurs sites, il faut spécifier la méthode la plus sûre<block ref="71e644310ff0f1164d905d6e80174023" prefix=" " category="inline-code"></block> en ligne de commande. Cette option est disponible en tant que mesure d'urgence pour s'assurer que toutes les données mises en cache sont vidées. Si un hôte utilise des ressources de stockage initialement situées sur le site sinistré, il reçoit des erreurs d'E/S ou un descripteur de fichier obsolète <block ref="a3c6541ac12f1f06a81cc9b03e6bd094" prefix="(" category="inline-code"></block>) erreur. Les bases de données Oracle planent et les systèmes de fichiers passent entièrement hors ligne ou en mode lecture seule.</block>
  <block id="dc6683d37e50abd82911fa91c036fbb2" category="paragraph">Une fois le basculement terminé, le<block ref="6b0a5ec5ecf08db5d4b32d860214d098" prefix=" " category="inline-code"></block> L'indicateur doit être effacé et les LUN doivent être mis en ligne. Une fois cette activité terminée, la base de données peut être redémarrée. Ces tâches peuvent être automatisées afin de réduire le RTO.</block>
  <block id="a2626552f293b2377efe829e69d14daa" category="section-title">dr-force-nvfail</block>
  <block id="f0cc4bbe3d196251009dbe9f0ac42ffc" category="paragraph">En tant que mesure de sécurité générale, réglez le<block ref="a2626552f293b2377efe829e69d14daa" prefix=" " category="inline-code"></block> drapeau sur tous les volumes accessibles depuis un site distant pendant les opérations normales, ce qui signifie qu'il s'agit d'activités utilisées avant le basculement. Le résultat de ce paramètre est que les volumes distants sélectionnés deviennent indisponibles lorsqu'ils entrent<block ref="6b0a5ec5ecf08db5d4b32d860214d098" prefix=" " category="inline-code"></block> lors d'un basculement. Une fois le basculement terminé, le<block ref="6b0a5ec5ecf08db5d4b32d860214d098" prefix=" " category="inline-code"></block> L'indicateur doit être effacé et les LUN doivent être mis en ligne. Une fois ces activités terminées, les applications peuvent être redémarrées. Ces tâches peuvent être automatisées afin de réduire le RTO.</block>
  <block id="5f6aa76cc0fe886c07f242f921486ef7" category="paragraph">Le résultat est similaire à l'utilisation du<block ref="71e644310ff0f1164d905d6e80174023" prefix=" " category="inline-code"></block> indicateur pour commutateurs manuels. Toutefois, le nombre de volumes affectés peut être limité aux volumes qui doivent être protégés contre les applications ou les systèmes d'exploitation dotés de caches obsolètes.</block>
  <block id="4df566a29b44806612369c0c1f67521b" category="paragraph">Il existe deux exigences critiques pour un environnement qui n'utilise pas<block ref="a2626552f293b2377efe829e69d14daa" prefix=" " category="inline-code"></block> sur les volumes d'application :</block>
  <block id="aaf1cc67bd88c39a71e691d413ded49f" category="list-text">Un basculement forcé ne doit pas se produire plus de 30 secondes après la perte du site principal.</block>
  <block id="7f9cc623e2a11875714cf4bc64f148fd" category="list-text">Le basculement ne doit pas avoir lieu pendant les tâches de maintenance ou tout autre mode dans lequel les plexes SyncMirror ou la réplication NVRAM sont désynchronisés. Le premier critère peut être atteint à l'aide d'un logiciel disjoncteur d'attache configuré pour effectuer un basculement dans les 30 secondes qui suivent la défaillance d'un site. Cela ne signifie pas que le basculement doit être effectué dans les 30 secondes qui suivent la détection d'une défaillance de site. Cela signifie qu'il n'est plus sûr de forcer un basculement si 30 secondes se sont écoulées depuis qu'un site a été confirmé opérationnel.</block>
  <block id="0929cc8043c21dcf0163f06424677ede" category="paragraph">Le deuxième critère peut être partiellement respecté en désactivant toutes les fonctionnalités de basculement automatisé lorsque la configuration MetroCluster est désynchronisée. Il est préférable d'opter pour une solution disjoncteur d'attache capable de surveiller l'état de santé de la réplication NVRAM et des plexes SyncMirror. Si le cluster n'est pas entièrement synchronisé, le disjoncteur d'attache ne doit pas déclencher de basculement.</block>
  <block id="a168430c68d0310385371eabe149a118" category="paragraph">Le logiciel MCTB de NetApp ne peut pas contrôler l'état de la synchronisation. Il doit donc être désactivé lorsque MetroCluster n'est pas synchronisé pour quelque raison que ce soit. ClusterLion inclut des fonctionnalités de surveillance NVRAM et plex et peut être configuré pour ne pas déclencher le basculement à moins que le système MetroCluster ne soit entièrement synchronisé.</block>
  <block id="baba038803e218b2ac3b2688bc2fd5db" category="doc">Nombre de LUN</block>
  <block id="b0e4db975ae00108abe9f47db9be5668" category="paragraph">Une LUN est un objet virtualisé sur ONTAP qui existe sur tous les disques de l'agrégat d'hébergement. Par conséquent, les performances de la LUN ne sont pas affectées par sa taille, car la LUN exploite tout le potentiel de performance de l'agrégat, quelle que soit sa taille.</block>
  <block id="7235d4b71fadc2fe03d09d863c7cdd66" category="paragraph">À titre de commodité, les clients peuvent souhaiter utiliser un LUN de taille spécifique. Par exemple, si une base de données est construite sur un groupe de disques LVM ou Oracle ASM composé de deux LUN de 1 To chacune, ce groupe de disques doit être développé par incréments de 1 To. Il peut être préférable de créer le groupe de disques à partir de huit LUN de 500 Go chacune, de sorte que le groupe de disques puisse être augmenté par incréments plus petits.</block>
  <block id="4b1ffe65479a23391a2c7f9caf467a35" category="paragraph">Il n'est pas recommandé d'établir une taille de LUN standard universelle, car cela peut compliquer la gestion. Par exemple, une taille de LUN standard de 100 Go peut fonctionner correctement lorsqu'une base de données ou un datastore se situe entre 1 et 2 To, mais qu'une base de données ou un datastore de 20 To nécessite 200 LUN. Cela signifie que les délais de redémarrage du serveur sont plus longs, que les différents utilisateurs doivent gérer davantage d'objets et que des produits tels que SnapCenter doivent effectuer des recherches sur de nombreux objets. L'utilisation d'un nombre inférieur de LUN de plus grande taille permet d'éviter de tels problèmes.</block>
  <block id="4afa3de974c36a09c2055d30989bb405" category="list-text">Le nombre de LUN est plus important que la taille de LUN.</block>
  <block id="691c70133d96d57796a9299359666f80" category="list-text">La taille de LUN est principalement contrôlée par les exigences liées au nombre de LUN.</block>
  <block id="8af9e525c143179b948a11fc382a331e" category="list-text">Évitez de créer plus de LUN que nécessaire.</block>
  <block id="407b2218ad77513a7e3964f169d07e66" category="paragraph">Contrairement à la taille de LUN, le nombre de LUN affecte les performances. La performance des applications dépend souvent de la capacité à réaliser des E/S parallèles via la couche SCSI. Ainsi, deux LUN offrent de meilleures performances qu'une seule LUN. L'utilisation d'un LVM tel que Veritas VxVM, Linux LVM2 ou Oracle ASM est la méthode la plus simple pour augmenter le parallélisme.</block>
  <block id="39143fe6204f383e4ce3bb3b77926455" category="paragraph">Les clients NetApp n'ont généralement pas eu l'avantage d'augmenter le nombre de LUN au-delà de seize. Toutefois, le test d'environnements 100 % SSD avec des E/S aléatoires très lourdes a permis d'améliorer encore jusqu'à 64 LUN.</block>
  <block id="9875f7503e59521e91e519abd87f5c9e" category="paragraph">*NetApp recommande* ce qui suit :</block>
  <block id="57153ab478a4958250d76ac6bf4e3ac0" category="paragraph">En général, de quatre à seize LUN suffisent pour prendre en charge les besoins en E/S d'une charge de travail de base de données donnée. Moins de quatre LUN peuvent créer des limites de performances en raison de limites dans les implémentations SCSI hôte.</block>
  <block id="de932976b195d4755fcbea64295fc7cb" category="doc">Paramètres du système d'exploitation hôte</block>
  <block id="f62cb371f65c322cd9e17a5c2cecd1c8" category="paragraph">La plupart des documents des fournisseurs d'applications incluent des paramètres TCP et ethernet spécifiques destinés à garantir le fonctionnement optimal de l'application. Ces mêmes paramètres suffisent généralement pour assurer des performances de stockage IP optimales.</block>
  <block id="ae7a0bb210cbd1edb935128116a21c55" category="section-title">Contrôle de flux Ethernet</block>
  <block id="a3c15fb208efc85bdfe72c57d56c92b8" category="paragraph">Cette technologie permet à un client de demander à un expéditeur d'arrêter temporairement la transmission de données. Cela est généralement fait parce que le récepteur est incapable de traiter les données entrantes assez rapidement. À un moment donné, demander à un expéditeur de cesser la transmission était moins perturbant que d'avoir un récepteur de paquets de rejet parce que les tampons étaient pleins. Ce n'est plus le cas avec les piles TCP utilisées dans les systèmes d'exploitation d'aujourd'hui. En fait, le contrôle de flux cause plus de problèmes qu'il ne résout.</block>
  <block id="950d31923e253d170d6c994801ce7cec" category="paragraph">Les problèmes de performances causés par le contrôle de flux Ethernet ont augmenté ces dernières années. En effet, le contrôle de flux Ethernet fonctionne au niveau de la couche physique. Si une configuration réseau permet à un système d'exploitation hôte d'envoyer une demande de contrôle de flux Ethernet à un système de stockage, il en résulte une pause des E/S pour tous les clients connectés. Étant donné qu'un nombre croissant de clients sont servis par un seul contrôleur de stockage, la probabilité qu'un ou plusieurs de ces clients envoient des demandes de contrôle de flux augmente. Le problème a été fréquemment rencontré sur les sites des clients qui possèdent une virtualisation étendue du système d'exploitation.</block>
  <block id="6bfd8563627c68f73c30581843441a74" category="paragraph">Une carte réseau sur un système NetApp ne doit pas recevoir de demandes de contrôle de flux. La méthode utilisée pour obtenir ce résultat varie en fonction du fabricant du commutateur réseau. Dans la plupart des cas, le contrôle de flux sur un commutateur Ethernet peut être réglé sur<block ref="a67b5ddb674c9ca32d9c9e1ca81578ee" prefix=" " category="inline-code"></block> ou<block ref="f4eb0bfa09695eb47ff4f3bd3ca4449d" prefix=" " category="inline-code"></block>, ce qui signifie qu'une demande de contrôle de flux n'est pas transmise au contrôleur de stockage. Dans d'autres cas, la connexion réseau sur le contrôleur de stockage risque de ne pas permettre la désactivation du contrôle de flux. Dans ce cas, les clients doivent être configurés pour ne jamais envoyer de demandes de contrôle de flux, soit en changeant la configuration NIC sur le serveur hôte lui-même, soit en changeant les ports de commutateur auxquels le serveur hôte est connecté.</block>
  <block id="7496f3ff64e30d4732c2c64880faf186" category="admonition">*NetApp recommande* de s'assurer que les contrôleurs de stockage NetApp ne reçoivent pas de paquets de contrôle de flux Ethernet. Pour ce faire, il est généralement possible de définir les ports de commutateur auxquels le contrôleur est connecté, mais certains matériels de commutateur ont des limites qui peuvent nécessiter des modifications côté client.</block>
  <block id="ae6d0fc57efaf02ad7dfdacd3575e315" category="section-title">Tailles du MTU</block>
  <block id="ff13ea04765cd9c9aed7b839f15eb2b4" category="paragraph">L'utilisation de trames Jumbo a été démontrée afin d'améliorer les performances des réseaux 1 Gbit en réduisant la surcharge du processeur et du réseau, mais l'avantage n'est généralement pas significatif.</block>
  <block id="ee3f364287a30ef10dfdce2f37d94ed2" category="admonition">*NetApp recommande* d'implémenter des trames Jumbo lorsque cela est possible, à la fois pour réaliser des avantages potentiels en termes de performances et pour pérenniser la solution.</block>
  <block id="2c6ba27b7ed602a9089da6ad9f762c9a" category="paragraph">L'utilisation de trames Jumbo dans un réseau de 10 Gb est presque obligatoire. En effet, la plupart des implémentations de 10 Gbits atteignent une limite de paquets par seconde sans trames Jumbo avant d'atteindre le seuil de 10 Gbits. L'utilisation de trames jumbo améliore l'efficacité du traitement TCP/IP car elle permet au système d'exploitation, au serveur, aux cartes réseau et au système de stockage de traiter moins de paquets, mais des paquets plus volumineux. L'amélioration des performances varie d'une carte réseau à l'autre, mais elle est significative.</block>
  <block id="a44be1bbfde97e4a64b50282325165e7" category="paragraph">Dans le cas des implémentations de trames Jumbo, il est courant, mais incorrect, que tous les périphériques connectés doivent prendre en charge les trames Jumbo et que la taille MTU doit correspondre de bout en bout Au lieu de cela, les deux extrémités du réseau négocient la taille de trame la plus élevée mutuellement acceptable lors de l'établissement d'une connexion. Dans un environnement standard, un commutateur réseau est défini sur une taille MTU de 9 9216, le contrôleur NetApp est défini sur 9000 et les clients sont configurés sur une combinaison de 9000 et 1514. Les clients qui prennent en charge un MTU de 9 9000 peuvent utiliser des trames jumbo, et les clients qui ne peuvent prendre en charge que 1514 peuvent négocier une valeur inférieure.</block>
  <block id="a31484167f31e1c3f36f7cea821bc581" category="paragraph">Les problèmes avec cet arrangement sont rares dans un environnement complètement commuté. Cependant, dans un environnement routé, veillez à ce qu'aucun routeur intermédiaire ne soit forcé de fragmenter des trames jumbo.</block>
  <block id="c805e9846e6fca449dbe3233cc5dbdf5" category="paragraph">*NetApp recommande* de configurer les éléments suivants :</block>
  <block id="b4446b5ca60d915111af271495bd4c17" category="list-text">Les trames Jumbo sont souhaitables, mais non requises avec Ethernet 1 Gb (GbE).</block>
  <block id="5b1ea13ac12a9c8be0d09303f637dba4" category="list-text">Les trames Jumbo sont requises pour des performances maximales avec 10GbE et plus rapides.</block>
  <block id="08a8dce78637f5dd14ed052163feb9da" category="section-title">Paramètres TCP</block>
  <block id="1a999618685598bee637262fe589de70" category="paragraph">Trois paramètres sont souvent mal configurés : les horodatages TCP, l'acquittement sélectif (SACK) et la mise à l'échelle de la fenêtre TCP. De nombreux documents obsolètes sur Internet recommandent de désactiver un ou plusieurs de ces paramètres pour améliorer les performances. Cette recommandation a été très utile il y a de nombreuses années, lorsque les capacités du processeur étaient beaucoup plus faibles et qu'il y avait un avantage à réduire la surcharge sur le traitement TCP chaque fois que cela était possible.</block>
  <block id="6a594ec6f0bb742c1d2b0f631cf65ba1" category="paragraph">Cependant, avec les systèmes d'exploitation modernes, la désactivation de l'une de ces fonctionnalités TCP n'entraîne généralement aucun avantage détectable, tout en pouvant nuire aux performances. Dans les environnements réseau virtualisés, les performances peuvent être endommagées, car ces fonctionnalités sont nécessaires pour gérer efficacement la perte de paquets et les modifications de la qualité du réseau.</block>
  <block id="cdc44d05b1633e8a8c7835010c423dd6" category="admonition">*NetApp recommande* d'activer les horodatages TCP, le SACK et la mise à l'échelle des fenêtres TCP sur l'hôte, et ces trois paramètres doivent être activés par défaut dans tout système d'exploitation actuel.</block>
  <block id="72a921ac9177188a9be32ec711fc15d8" category="doc">Accès au chemin</block>
  <block id="544c599da087dba677a820c3df344503" category="paragraph">SnapMirror Business Continuity (SM-BC) est une fonctionnalité améliorée de SnapMirror pour SAN qui permet aux hôtes d'accéder à une LUN à partir du système hébergeant la LUN, ainsi que du système hébergeant sa réplique.</block>
  <block id="6139cdabb39d5ceac18a60642497c6a7" category="paragraph">SM-BC et SnapMirror Sync (SM-S) partagent un moteur de réplication. Toutefois, SM-BC inclut des fonctionnalités supplémentaires, telles que le basculement et la restauration transparents des applications pour les applications d'entreprise.</block>
  <block id="a73743f15de974052b0640c60f489d90" category="paragraph">En pratique, il fonctionne comme une version granulaire de MetroCluster grâce à une réplication synchrone avec RPO=0 sélective et granulaire pour des workloads individuels. Le comportement du chemin de bas niveau est très différent de MetroCluster, mais le résultat final du point de vue de l'hôte est similaire.</block>
  <block id="b3bf85c7b0a17286752c110f404a7035" category="paragraph">SM-BC rend les périphériques de stockage visibles pour les systèmes d'exploitation hôtes à partir des baies de stockage principale et distante. Les chemins sont gérés via le protocole ALUA (Asymmetric Logical Unit Access), qui est un protocole standard de l'industrie pour identifier les chemins optimisés entre un système de stockage et un hôte.</block>
  <block id="cbf0bd4f4096570f567049c984f8c9d3" category="paragraph">Le chemin de périphérique le plus court pour accéder aux E/S est considéré comme des chemins actifs/optimisés et le reste des chemins sont considérés comme des chemins actifs/non optimisés.</block>
  <block id="350b9208772a185e0d0943b105765d89" category="paragraph">La relation SM-BC se situe entre une paire de SVM située sur différents clusters. Les deux SVM sont capables de transmettre des données, mais le protocole ALUA utilisera de préférence le SVM qui est actuellement propriétaire des disques sur lesquels résident les LUN. Les E/S vers le SVM distant seront proxys via l'interconnexion SM-BC.</block>
  <block id="341d84aa26cb4521474864e04ea2a63b" category="inline-image-macro">Erreur : image graphique manquante</block>
  <block id="532db5273379dd6149d97b7ab6e420b6" category="paragraph"><block ref="532db5273379dd6149d97b7ab6e420b6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b56265ceb6311e42003e668438136a59" category="section-title">Réplication synchrone</block>
  <block id="8159c40a86db91b72e00c2eb5cf751fe" category="paragraph">En fonctionnement normal, la copie distante est une réplique synchrone RPO=0 à tout moment, à une exception près. Si les données ne peuvent pas être répliquées, SM-BC impose de répliquer les données et de reprendre le service d'E/S. Cette option est privilégiée par les clients qui considèrent la perte de la liaison de réplication comme un quasi-incident ou qui ne souhaitent pas que les opérations de l'entreprise s'interrompent lorsque les données ne peuvent pas être répliquées.</block>
  <block id="0cf4a786acebd750bbfdfc4416c89406" category="section-title">Matériel de stockage</block>
  <block id="f0fd4c8ee2422af8e335cc85c485ccbf" category="paragraph">Contrairement à d'autres solutions de reprise après incident de stockage, SM-BC offre une flexibilité de plateforme asymétrique. Le matériel de chaque site n'a pas besoin d'être identique. Cette fonctionnalité vous permet d'adapter la taille du matériel utilisé pour la prise en charge de SM-BC. Le système de stockage distant peut être identique au site principal s'il doit prendre en charge une charge de travail de production complète, mais si un incident entraîne une réduction des E/S, un système plus petit sur le site distant peut être plus économique.</block>
  <block id="ea9f3de5dd21190fbc6bca180b2040f1" category="section-title">ONTAP Médiateur</block>
  <block id="b378eb5f2b386494f24a3f09afd8ae1f" category="paragraph">Le Mediator ONTAP est une application logicielle téléchargée à partir du support NetApp. Le médiateur automatise les opérations de basculement à la fois pour le cluster de stockage du site principal et pour le cluster de stockage du site distant. Il peut être déployé sur une petite machine virtuelle hébergée sur site ou dans le cloud. Une fois configuré, il fait office de troisième site pour surveiller les scénarios de basculement des deux sites.</block>
  <block id="0f54fb931dbdeea735f18a8e73f9eab5" category="doc">Protection des données avec SyncMirror</block>
  <block id="d7023f86951b6c3c009891a468c3effd" category="paragraph">Au niveau le plus simple, la réplication synchrone implique que toute modification doit être apportée des deux côtés du stockage en miroir avant d'être reconnue. Par exemple, si une base de données écrit un journal ou si un invité VMware est en cours de correction, une écriture ne doit jamais être perdue. Au niveau du protocole, le système de stockage ne doit pas accuser réception de l'écriture tant qu'il n'a pas été validé sur un support non volatile des deux sites. Ce n'est qu'à cette condition qu'il est possible de continuer sans risque de perte de données.</block>
  <block id="eee4f7a4e0ed3a8646a97bcf3e118fb9" category="paragraph">L'utilisation d'une technologie de réplication synchrone est la première étape de la conception et de la gestion d'une solution de réplication synchrone. Il est important de comprendre ce qui pourrait se passer lors de divers scénarios de défaillance planifiés ou non. Les solutions de réplication synchrone offrent toutes des fonctionnalités différentes. Si vous avez besoin d'une solution avec un objectif de point de récupération de zéro, c'est-à-dire sans perte de données, tous les scénarios de défaillance doivent être pris en compte. En particulier, quel est le résultat escompté lorsque la réplication est impossible en raison d'une perte de connectivité entre les sites ?</block>
  <block id="71554672a088c43ab21c759ddd161928" category="section-title">Disponibilité des données SyncMirror</block>
  <block id="bec293a9cf8e49ec40e6a4fdc02b9146" category="paragraph">La réplication MetroCluster repose sur la technologie NetApp SyncMirror, conçue pour basculer efficacement en mode synchrone et en sortir. Cette fonctionnalité répond aux exigences des clients qui demandent une réplication synchrone, mais qui ont également besoin d'une haute disponibilité pour leurs services de données. Par exemple, si la connectivité à un site distant est coupée, il est généralement préférable que le système de stockage continue de fonctionner dans un état non répliqué.</block>
  <block id="9a9ce41f4b23474045b6c6e0ac7752af" category="paragraph">De nombreuses solutions de réplication synchrone ne peuvent fonctionner qu'en mode synchrone. Ce type de réplication « tout ou rien » est parfois appelé mode domino. Ces systèmes de stockage cessent d'accéder aux données au lieu d'interrompre la synchronisation des copies locales et distantes des données. Si la réplication est forcée, la resynchronisation peut prendre beaucoup de temps et laisser un client exposé à des pertes de données complètes pendant la période de rétablissement de la mise en miroir.</block>
  <block id="8646bb558f8f18a200cce2f70602627a" category="paragraph">Non seulement SyncMirror peut basculer en mode synchrone sans interruption si le site distant est inaccessible, mais il peut également rapidement resynchroniser vers un état RPO = 0 une fois la connectivité restaurée. La copie obsolète des données sur le site distant peut également être conservée dans un état utilisable lors de la resynchronisation, garantissant la présence à tout moment de copies locales et distantes des données.</block>
  <block id="995f5151d2d1c0a4e8371b2b3c9b6e5b" category="paragraph">Si le mode domino est requis, NetApp propose SnapMirror synchrone (SM-S). Des options au niveau de l'application existent également, telles qu'Oracle DataGuard ou des délais d'expiration étendus pour la mise en miroir des disques côté hôte. Pour plus d'informations et d'options, consultez votre équipe de compte NetApp ou partenaire.</block>
  <block id="1d12d7a206d9b5337ae6fa442f23d377" category="doc">Copies Snapshot uniquement</block>
  <block id="64c29f2f2feedeb607ff588b13d9758b" category="paragraph">Le<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block><block ref="964193481f440d73ce3474a7a09bc3ac" prefix=" " category="inline-code"></block> s'applique uniquement aux blocs qui ne sont pas partagés avec le système de fichiers actif. Elle entraîne essentiellement une hiérarchisation des sauvegardes de bases de données. Les blocs deviennent candidats au Tiering après la création d'une copie Snapshot et l'écrasement du bloc, ce qui entraîne l'affichage d'un bloc uniquement dans la copie Snapshot. Le délai avant un<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> le bloc est considéré comme froid est contrôlé par le<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> réglage du volume. La plage à partir de ONTAP 9.8 est de 2 à 183 jours.</block>
  <block id="ebd9889c847a7a3ddeccd2717ead46f2" category="paragraph">De nombreux jeux de données ont des taux de modification faibles, ce qui permet de réduire au minimum les économies réalisées grâce à cette règle. Par exemple, un taux de modification hebdomadaire d'une base de données type observée sur ONTAP est inférieur à 5 %. Les journaux d'archivage de base de données peuvent occuper un espace important, mais ils continuent généralement d'exister dans le système de fichiers actif et ne sont donc pas candidats à la hiérarchisation dans le cadre de cette règle.</block>
  <block id="06b9281e396db002010bde1de57262eb" category="section-title">Auto</block>
  <block id="ecf602bd5abbd6a605debedbb6c3d4e0" category="paragraph">Le<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> la règle de tiering étend le tiering aux blocs spécifiques de snapshot et aux blocs dans le système de fichiers actif. Le délai avant qu'un bloc soit considéré comme froid est contrôlé par le<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> réglage du volume. La plage à partir de ONTAP 9.8 est de 2 à 183 jours.</block>
  <block id="6256ce48698ff0bde6f818679cdfb382" category="paragraph">Cette approche permet d'activer des options de hiérarchisation qui ne sont pas disponibles avec le<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> politique. Par exemple, une règle de protection des données peut nécessiter la conservation de 90 jours de certains fichiers journaux. Si vous définissez une période de refroidissement de 3 jours, tous les fichiers journaux de plus de 3 jours doivent être placés hors de la couche de performances. Cela libère un espace considérable sur le Tier de performance tout en vous permettant de consulter et de gérer l'ensemble des 90 jours de données.</block>
  <block id="6adf97f83acf6453d4a6a4b1070f3754" category="section-title">Aucune</block>
  <block id="7026ff5c5d4ab3946ff2d86f0e2cca6f" category="paragraph">Le<block ref="334c4a4c42fdb79d7ebc3e73b517e6f8" prefix=" " category="inline-code"></block> la règle de tiering empêche tout bloc supplémentaire d'être hiérarchisé de la couche de stockage, mais toutes les données qui se trouvent toujours dans le tier de capacité restent dans le tier de capacité jusqu'à ce qu'elles soient lues. Si le bloc est ensuite lu, il est retiré et placé sur le Tier de performance.</block>
  <block id="d152c7b0939fb6d35fdb0433de0d6369" category="paragraph">La principale raison d'utiliser le<block ref="334c4a4c42fdb79d7ebc3e73b517e6f8" prefix=" " category="inline-code"></block> la règle de tiering consiste à empêcher les blocs d'être hiérarchisés, mais elle peut s'avérer utile pour modifier les règles au fil du temps. Par exemple, imaginons qu'un dataset spécifique soit beaucoup hiérarchisé vers la couche de capacité, mais qu'un besoin inattendu de fonctionnalités de performance complètes se produit. La règle peut être modifiée pour éviter tout Tiering supplémentaire et confirmer que tous les blocs lus en cas d'augmentation des E/S restent dans le Tier de performance.</block>
  <block id="b1c94ca2fbc3e78fc30069c8d0f01680" category="section-title">Tout</block>
  <block id="84826d7e23dfac7549819d5115fdcedd" category="paragraph">Le<block ref="a181a603769c1f98ad927e7367c7aa51" prefix=" " category="inline-code"></block> la règle de tiering remplace la<block ref="402051f4be0cc3aad33bcf3ac3d6532b" prefix=" " category="inline-code"></block> Politique à partir de ONTAP 9.6. Le<block ref="402051f4be0cc3aad33bcf3ac3d6532b" prefix=" " category="inline-code"></block> Règle appliquée uniquement aux volumes de protection des données, c'est-à-dire une destination SnapMirror ou NetApp SnapVault. Le<block ref="a181a603769c1f98ad927e7367c7aa51" prefix=" " category="inline-code"></block> les règles fonctionnent de même, mais ne se limitent pas aux volumes de protection des données.</block>
  <block id="10d8500e282e8bbacd668af6f773f412" category="paragraph">Avec cette règle, les blocs sont immédiatement considérés comme « cool » et peuvent être immédiatement hiérarchisés jusqu'à la couche de capacité.</block>
  <block id="ec583de0216b95bc673c84e4ec9356e6" category="paragraph">Cette règle est particulièrement appropriée pour les sauvegardes à long terme. Il peut également être utilisé comme une forme de gestion hiérarchique du stockage (HSM). Auparavant, HSM était couramment utilisé pour classer les blocs de données d'un fichier sur bande tout en gardant le fichier lui-même visible sur le système de fichiers. Un volume FabricPool avec<block ref="a181a603769c1f98ad927e7367c7aa51" prefix=" " category="inline-code"></block> cette stratégie vous permet de stocker des fichiers dans un espace visible et gérable, tout en ne consommant quasiment aucun espace sur le niveau de stockage local.</block>
  <block id="79768a069a539d4f130e672a660bf45f" category="doc">Segmentation</block>
  <block id="79da1502ddfac887bfdf0d92f2428fe6" category="paragraph">Il s'agit notamment de mesures de planification courantes, telles que l'assurance d'une bande passante suffisante sur le SAN entre l'hôte et le système de stockage, la vérification de l'existence de tous les chemins SAN entre tous les périphériques requis, l'utilisation des paramètres de port FC requis par le fournisseur du commutateur FC, l'utilisation des conflits ISL et à l'utilisation d'un système de surveillance de la structure SAN approprié.</block>
  <block id="a0bdb98e8b9da585816478d24278e42f" category="paragraph">Une zone FC ne doit jamais contenir plusieurs initiateurs. Un tel arrangement peut sembler fonctionner au départ, mais la diaphonie entre les initiateurs finit par interférer avec la performance et la stabilité.</block>
  <block id="8ef958d9e25538841b306960ab117626" category="paragraph">Les zones à cibles multiples sont généralement considérées comme sûres, bien que dans de rares circonstances le comportement des ports cibles FC de fournisseurs différents ait causé des problèmes. Par exemple, évitez d'inclure les ports cibles d'une baie de stockage NetApp et non NetApp dans la même zone. En outre, le fait de placer un système de stockage NetApp et un dispositif de bande dans la même zone est encore plus susceptible de causer des problèmes.</block>
  <block id="642223473862db290604321fe2ebe763" category="doc">SVM</block>
  <block id="47ea917cf14ad91c68c407f90a7a189d" category="paragraph">Un SVM, connu sous le nom de vserver sur l'interface de ligne de commandes ONTAP, est une unité fonctionnelle de base du stockage. Il est utile de comparer un SVM à un invité sur un serveur VMware ESX.</block>
  <block id="9efbaa34de852e33319ca8ceb1861832" category="paragraph">Lors de l'installation initiale, ESX ne dispose pas de fonctionnalités préconfigurées, telles que l'hébergement d'un système d'exploitation invité ou la prise en charge d'une application utilisateur. Il s'agit d'un conteneur vide jusqu'à ce qu'une machine virtuelle (VM) soit définie. ONTAP fonctionne de manière similaire : Lors de la première installation de ONTAP, aucune fonctionnalité de service des données n'est disponible tant qu'un SVM n'est pas créé. Pour configurer les services de données.</block>
  <block id="13ce2622b2cc2118c44d3aae7df8167d" category="paragraph">À l'instar des autres aspects de l'architecture de stockage, les meilleures options pour la conception des SVM et de l'interface logique (LIF) dépendent largement des exigences d'évolutivité et des besoins de l'entreprise.</block>
  <block id="8fb41a27984f0beba2e12fb920a486aa" category="paragraph">Il n'existe aucune bonne pratique officielle de provisionnement des SVM pour ONTAP. La bonne approche dépend des exigences en matière de gestion et de sécurité.</block>
  <block id="f4d8541bb6d07f7533a6b5aa6cfb2455" category="paragraph">La plupart des clients utilisent un SVM principal pour la plupart de leurs besoins quotidiens, mais ils en créent un petit pour des besoins particuliers. Par exemple, vous pouvez créer :</block>
  <block id="259908e9e431c0fbb9d425249ceb7930" category="list-text">SVM d'une base de données stratégique gérée par une équipe de spécialistes</block>
  <block id="0e10f2715884f3538282397d69b2cd00" category="list-text">SVM pour un groupe de développement auquel un contrôle administratif complet a été attribué afin de pouvoir gérer leur propre stockage indépendamment</block>
  <block id="7624156e307247e4ea1ec8bf574136a1" category="list-text">SVM pour les données sensibles de l'entreprise, telles que les données de rapports financiers ou de ressources humaines, pour lesquelles l'équipe administrative doit être limitée</block>
  <block id="e5e09031843479ef9ef8cbbd4c2f404c" category="inline-link-macro">NetApp Hardware Universe</block>
  <block id="bd32656670155eb09690047819fc0971" category="paragraph">Dans un environnement mutualisé, chaque locataire peut se voir attribuer une SVM dédiée. La limite du nombre de SVM et de LIF par cluster, paire HA et nœud dépend du protocole utilisé, du modèle de nœud et de la version de ONTAP.  Consulter le <block ref="41f66f34b3a905f864500c9319fdff8f" category="inline-link-macro-rx"></block> pour ces limites.</block>
  <block id="fb012f1e7970d8285bd5d6c5a7f7d523" category="doc">Des agrégats SSD, y compris les systèmes AFF</block>
  <block id="cb8e4651c457f71d5788f38eac01471f" category="paragraph">L'espace libre est défini comme tout espace qui n'est pas utilisé pour les données réelles et inclut l'espace non alloué sur l'agrégat lui-même et l'espace inutilisé au sein des volumes constitutifs. Le provisionnement fin doit également être envisagé. Par exemple, un volume peut contenir une LUN de 1 To, dont seulement 50 % sont utilisés par des données réelles. Dans un environnement à provisionnement fin, cet espace semble être consommé de 500 Go. Toutefois, dans un environnement entièrement provisionné, la capacité totale de 1 To semble être utilisée. Les 500 Go d'espace non alloué sont masqués. Cet espace n'est pas utilisé par les données réelles et doit donc être inclus dans le calcul de l'espace libre total.</block>
  <block id="d3487661d9a0702bd5915d49070f62dc" category="paragraph">Les recommandations de NetApp pour les systèmes de stockage utilisés pour les applications d'entreprise sont les suivantes :</block>
  <block id="678e476783bceae80094bcb4c1f32969" category="admonition">*NetApp recommande* un minimum de 10% d'espace libre. Cela inclut tout l'espace inutilisé, y compris l'espace libre au sein de l'agrégat ou d'un volume, ainsi que tout espace libre alloué en raison de l'utilisation du provisionnement complet, mais qui n'est pas utilisé par les données réelles. L'espace logique n'est pas important, la question est de savoir quelle quantité d'espace physique réellement disponible pour le stockage des données.</block>
  <block id="2171d172d184f1202a686849c85dce91" category="paragraph">La recommandation de 10 % d'espace libre est très prudente. Les agrégats SSD peuvent prendre en charge des charges de travail à des niveaux d'utilisation encore plus élevés, sans affecter les performances. Cependant, à mesure que l'utilisation de l'agrégat augmente, le risque de manquer d'espace augmente également si l'utilisation n'est pas surveillée de près. De plus, même si vous utilisez un système à 99 % de capacité, les performances risquent d'être moins élevées, mais vous devrez probablement interrompre la gestion pour l'empêcher de se remplir complètement lors de la commande de matériel supplémentaire. L'acquisition et l'installation de disques supplémentaires peuvent prendre un certain temps.</block>
  <block id="789243e17acb0b134f435d6c4c1350f2" category="section-title">Les agrégats HDD, y compris les agrégats Flash Pool</block>
  <block id="7302e9f16fb8c5bc30f6035fe4098b52" category="admonition">*NetApp recommande* un minimum de 15 % d'espace libre lorsque des disques rotatifs sont utilisés. Cela inclut tout l'espace inutilisé, y compris l'espace libre au sein de l'agrégat ou d'un volume, ainsi que tout espace libre alloué en raison de l'utilisation du provisionnement complet, mais qui n'est pas utilisé par les données réelles. Les performances seront affectées aux approches de la liberté d'expression de 10 %.</block>
  <block id="0b0a68e2dedde9c0b9a3ea4276f4b85c" category="paragraph">Le<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> la règle est la règle la plus appropriée pour les données de sauvegarde. Cela garantit une hiérarchisation rapide lorsque le seuil de refroidissement a été atteint, que les fichiers aient été supprimés ou qu'ils continuent d'exister dans le système de fichiers principal. Le stockage de tous les fichiers potentiellement requis dans un emplacement unique du système de fichiers actif simplifie également la gestion. Il n'y a aucune raison de rechercher un fichier à restaurer à l'aide de snapshots.</block>
  <block id="11a75a1257cc68a4a46bc553dabe0c0d" category="paragraph">Le<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> la stratégie peut être mise en œuvre, mais elle s'applique uniquement aux blocs qui ne sont plus dans le système de fichiers actif. Par conséquent, les fichiers d'un partage NFS ou SMB doivent d'abord être supprimés avant de pouvoir placer les données dans un Tier.</block>
  <block id="b4af96e8cea99b56592db816cab30fce" category="paragraph">Cette règle serait encore moins efficace avec une configuration de LUN, car la suppression d'un fichier d'une LUN supprime uniquement les références de fichier des métadonnées du système de fichiers. Les blocs réels des LUN restent en place jusqu'à ce qu'ils soient remplacés. Cette situation peut entraîner un délai long entre la suppression d'un fichier et l'écrasement des blocs et leur candidature à la hiérarchisation. Il est avantageux de déplacer le<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> Bloque le niveau de capacité, mais, dans l'ensemble, la gestion FabricPool des données de sauvegarde fonctionne mieux avec le<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> politique.</block>
  <block id="1c237d1ebcdeff13ae0145c741d9401d" category="admonition">Cette approche permet aux utilisateurs de gérer plus efficacement l'espace requis pour les sauvegardes, mais FabricPool lui-même n'est pas une technologie de sauvegarde. Le Tiering des fichiers de sauvegarde vers un magasin d'objets simplifie la gestion, car les fichiers restent visibles sur le système de stockage d'origine. Cependant, les blocs de données de destination du magasin d'objets dépendent du système de stockage d'origine. En cas de perte du volume source, les données du magasin d'objets ne sont plus utilisables.</block>
  <block id="a19665c8f7c0210f96ad2934ad0ee361" category="paragraph">Sur un système ONTAP, le stockage est organisé en unités de 4 Ko. Un bloc de 8 Ko de base de données ou de système de fichiers doit être mappé à exactement deux blocs de 4 Ko. Si une erreur de configuration de LUN déplace l'alignement de 1 Ko dans les deux sens, chaque bloc de 8 Ko existerait sur trois blocs de stockage de 4 Ko différents au lieu de deux. Cette configuration entraîne une augmentation de la latence et des E/S supplémentaires au sein du système de stockage.</block>
  <block id="211a9fe299057fe8665b591dddbac56d" category="paragraph">L'alignement affecte également les architectures LVM. Si un volume physique au sein d'un groupe de volumes logiques est défini sur l'unité entière (aucune partition n'est créée), le premier bloc de 4 Ko de la LUN s'aligne sur le premier bloc de 4 Ko du système de stockage. Il s'agit d'un alignement correct. Des problèmes surviennent avec les partitions car elles déplacent l'emplacement de départ où le système d'exploitation utilise le LUN. Tant que le décalage est décalé en unités entières de 4 Ko, la LUN est alignée.</block>
  <block id="7c8a0aad1f59988f8160921a07203bb4" category="paragraph">Dans les environnements Linux, créez des groupes de volumes logiques sur l'ensemble de l'unité de disque. Lorsqu'une partition est requise, vérifiez l'alignement en exécutant<block ref="16ae8c2dc7757a3180ce37bad780251a" prefix=" " category="inline-code"></block> et vérifier que le début de chaque partition est un multiple de huit. Cela signifie que la partition démarre à un multiple de huit secteurs de 512 octets, soit 4 Ko.</block>
  <block id="e98a692d783d8d778aab49ed4c55e214" category="doc">Protection contre les défaillances de site : NVRAM et MetroCluster</block>
  <block id="186577daf29184ed8a55cf899ba2979c" category="paragraph">MetroCluster étend la protection des données NVRAM de plusieurs manières :</block>
  <block id="679f5a5873d7d3378cf4b3035fd5cb13" category="list-text">Dans une configuration à deux nœuds, les données NVRAM sont répliquées au partenaire distant à l'aide des liens ISL (Inter-Switch Links).</block>
  <block id="00bec98f52b9151dd2e0c760becd4ca8" category="list-text">Dans une configuration de paire haute disponibilité, les données NVRAM sont répliquées à la fois vers le partenaire local et vers un partenaire distant.</block>
  <block id="94deccfbf8f798c1661000b27a568b18" category="list-text">Une écriture n'est pas validée tant qu'elle n'est pas répliquée à tous les partenaires. Cette architecture protège les E/S à la volée contre les défaillances de site en répliquant les données NVRAM sur un partenaire distant. Ce processus n'est pas impliqué dans la réplication des données au niveau des disques. Le contrôleur propriétaire des agrégats est responsable de la réplication des données en écrivant dans les deux plexes de l'agrégat. Cependant, il doit toujours assurer une protection contre les pertes d'E/S à la volée en cas de perte du site. Les données NVRAM répliquées sont uniquement utilisées si un contrôleur partenaire doit prendre le relais en cas de défaillance d'un contrôleur.</block>
  <block id="996aa1ed8a906e55c7f157a1643021b7" category="section-title">Protection contre les pannes de site et de tiroir : SyncMirror et plexes</block>
  <block id="1c114a932963683e04dc7dece97c15c9" category="paragraph">SyncMirror est une technologie de mise en miroir qui améliore, mais ne remplace pas, RAID DP ou RAID-TEC. Il met en miroir le contenu de deux groupes RAID indépendants. La configuration logique est la suivante :</block>
  <block id="b4b4f1d65cb5f1370402220b00584e79" category="list-text">Les disques sont configurés en deux pools en fonction de leur emplacement. Un pool est composé de tous les disques du site A et le second est composé de tous les disques du site B.</block>
  <block id="418f0763b76bff8e324f1afdd5456b49" category="list-text">Un pool de stockage commun, appelé agrégat, est ensuite créé à partir de jeux en miroir de groupes RAID. Un nombre égal de lecteurs est tiré de chaque site. Par exemple, un agrégat SyncMirror de 20 disques se compose de 10 disques du site A et de 10 disques du site B.</block>
  <block id="51bf74357f742acfa0a7cd11ce52ed7f" category="list-text">Chaque jeu de disques d'un site donné est automatiquement configuré comme un ou plusieurs groupes RAID DP ou RAID-TEC entièrement redondants, indépendamment de l'utilisation de la mise en miroir. Cette utilisation de la mise en miroir RAID assure la protection des données même après la perte d'un site.</block>
  <block id="8a35ad1e53533c7a3a8ff427bda0deb2" category="paragraph"><block ref="8a35ad1e53533c7a3a8ff427bda0deb2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="abf64dbc3ac20af1b4a30150a016ca58" category="paragraph">La figure ci-dessus illustre un exemple de configuration SyncMirror. Un agrégat de 24 disques a été créé sur le contrôleur avec 12 disques à partir d'un tiroir alloué sur le site A et 12 disques à partir d'un tiroir alloué sur le site B. Les disques ont été regroupés en deux groupes RAID en miroir. Le groupe RAID 0 comprend un plex de 6 disques sur le site A mis en miroir sur un plex de 6 disques sur le site B. De même, le groupe RAID 1 comprend un plex de 6 disques sur le site A mis en miroir sur un plex de 6 disques sur le site B.</block>
  <block id="d9945e1dbadc87ba8e52a5e69376005c" category="paragraph">SyncMirror est généralement utilisé pour assurer la mise en miroir à distance avec les systèmes MetroCluster, avec une copie des données sur chaque site. Il a parfois été utilisé pour fournir un niveau supplémentaire de redondance dans un seul système. Il assure en particulier la redondance au niveau du tiroir. Un tiroir disque contient déjà deux blocs d'alimentation et contrôleurs. Dans l'ensemble, il ne s'agit pas d'une simple tôlerie, mais dans certains cas, une protection supplémentaire peut être garantie. Par exemple, un client NetApp a déployé SyncMirror sur une plateforme mobile d'analytique en temps réel utilisée lors des tests automobiles. Le système a été séparé en deux racks physiques fournis avec des alimentations indépendantes et des systèmes UPS indépendants.</block>
  <block id="f3495a1e6cf563a617c71164f3b11ca3" category="section-title">Échec de la redondance : NVFAIL</block>
  <block id="c7474a3ed1a224804e4741a256bdd953" category="paragraph">Comme nous l'avons vu précédemment, une écriture n'est pas validée tant qu'elle n'a pas été connectée à la NVRAM et à la NVRAM locales sur au moins un autre contrôleur. Cette approche évite toute panne matérielle ou de courant qui entraîne une perte des E/S à la volée En cas de panne de la mémoire NVRAM locale ou de la connectivité aux autres nœuds, les données ne seront plus mises en miroir.</block>
  <block id="4774101e81ea03c43fe20e0d7f2d21d1" category="paragraph">Le facteur de contrôle est de savoir si la NVRAM est synchronisée. Si la mémoire NVRAM est synchronisée, le basculement nœud à nœud peut se poursuivre sans risque de perte de données. Dans une configuration MetroCluster, si la mémoire NVRAM et les plexes d'agrégats sous-jacents sont synchronisés, vous pouvez procéder au basculement sans risque de perte de données.</block>
  <block id="03e97c023521445cd70307afabdcf0d5" category="paragraph">Les bases de données et autres applications sont particulièrement vulnérables à la corruption en cas de basculement ou de basculement forcé, car elles conservent des caches internes de données plus volumineux sur disque. En cas de basculement forcé ou de basculement forcé, les modifications précédemment reconnues sont effectivement supprimées. Le contenu de la baie de stockage recule dans le temps et l'état du cache ne reflète plus l'état des données sur le disque.</block>
  <block id="ff7a32ed70b7df57dd29a3ed75e8c787" category="paragraph">Afin d'éviter ce genre de situation, ONTAP permet de configurer les volumes pour une protection spéciale contre les défaillances de mémoire NVRAM. Lorsqu'il est déclenché, ce mécanisme de protection entraîne l'entrée d'un volume dans un état appelé NVFAIL. Cet état entraîne des erreurs d'E/S qui provoquent une panne de l'application. Cette panne provoque l'arrêt des applications, qui n'utilisent donc pas de données obsolètes. Les données ne doivent pas être perdues car des données de transaction validées doivent être présentes dans les journaux. Les étapes suivantes habituelles sont qu'un administrateur arrête complètement les hôtes avant de remettre manuellement en ligne les LUN et les volumes. Bien que ces étapes puissent impliquer un certain travail, cette approche est le moyen le plus sûr d'assurer l'intégrité des données. Toutes les données n'ont pas besoin de cette protection. C'est pourquoi NVFAIL peut être configuré volume par volume.</block>
  <block id="637d4b37868fb7825461df6edd674158" category="section-title">Paires HAUTE DISPONIBILITÉ et MetroCluster</block>
  <block id="9d8738f531e6c6a809ba66315beaa2f4" category="paragraph">MetroCluster est disponible dans deux configurations : deux nœuds et paire haute disponibilité. La configuration à deux nœuds se comporte de la même manière qu'une paire haute disponibilité par rapport à la mémoire NVRAM. En cas de défaillance soudaine, le nœud partenaire peut relire les données NVRAM pour assurer la cohérence des disques et garantir la perte d'aucune écriture reconnue.</block>
  <block id="936f4311b16ee4dc74a5564892f8976d" category="paragraph">La configuration HA-pair réplique également la mémoire NVRAM sur le nœud partenaire local. Une simple défaillance de contrôleur entraîne une relecture NVRAM sur le nœud partenaire, comme c'est le cas avec une paire haute disponibilité autonome sans MetroCluster. En cas de perte complète soudaine d'un site, le site distant dispose également de la mémoire NVRAM requise pour assurer la cohérence des disques et commencer à transmettre les données.</block>
  <block id="83b6c3c3018b913ecf1aca67e0daa35e" category="paragraph">Un aspect important de MetroCluster est que les nœuds distants ne peuvent pas accéder aux données des partenaires dans des conditions de fonctionnement normales. Chaque site fonctionne essentiellement comme un système indépendant qui peut assumer la personnalité du site opposé. Ce processus est connu sous le nom de basculement et inclut un basculement planifié dans lequel les opérations sur site sont migrées sans interruption vers le site opposé. Il comprend également les situations non planifiées où un site est perdu et un basculement manuel ou automatique est nécessaire dans le cadre de la reprise d'activité.</block>
  <block id="58504b36cfdfd10d5f2802d7b943a379" category="section-title">Basculement et rétablissement</block>
  <block id="d505751d1708fb5d57b0e23d089507a9" category="paragraph">Les termes « switchover and switchoback » font référence au processus de transition des volumes entre des contrôleurs distants dans une configuration MetroCluster. Ce processus s'applique uniquement aux nœuds distants. Lorsque MetroCluster est utilisé dans une configuration à quatre volumes, le basculement de nœud local est le même processus de basculement et de rétablissement que celui décrit précédemment.</block>
  <block id="1127608e73df5ede22b149c8f19fc860" category="section-title">Basculement et rétablissement planifiés</block>
  <block id="a6733335678588619c977608e891e54e" category="paragraph">Un basculement ou rétablissement planifié est similaire à un basculement ou un rétablissement entre les nœuds. Ce processus comporte plusieurs étapes et peut sembler prendre plusieurs minutes, mais il s'agit d'une transition progressive et progressive des ressources de stockage et de réseau. Le moment où les transferts de contrôle se produisent beaucoup plus rapidement que le temps nécessaire à l'exécution de la commande complète.</block>
  <block id="4bb5647dcff332f0b53819ecd631303c" category="paragraph">La principale différence entre le basculement/rétablissement et le basculement/rétablissement réside dans l'effet sur la connectivité FC SAN. Avec le Takeover/Giveback local, un hôte subit la perte de tous les chemins FC vers le nœud local et s'appuie sur son MPIO natif pour le basculer vers des chemins alternatifs disponibles. Les ports ne sont pas déplacés. Avec le basculement et le rétablissement, les ports cibles FC virtuels des contrôleurs passent à l'autre site. Ils cessent d'exister sur le SAN pendant un instant, puis réapparaissent sur un autre contrôleur.</block>
  <block id="0ba902ec3f6ce91c2e801715bb8b96fa" category="section-title">SyncMirror expire</block>
  <block id="9c8a1814b60b84d1aa68fa7bba69138b" category="paragraph">SyncMirror est une technologie de mise en miroir ONTAP qui offre une protection contre les défaillances de tiroirs. Lorsque les tiroirs sont séparés sur une distance, les données sont protégées à distance.</block>
  <block id="68cf36f65a7e56ff3b6c0894be3ed9e8" category="paragraph">SyncMirror ne fournit pas de mise en miroir synchrone universelle. Le résultat est une meilleure disponibilité. Certains systèmes de stockage utilisent une mise en miroir totale ou nulle constante, parfois appelée mode domino. Cette forme de mise en miroir est limitée dans l'application car toutes les activités d'écriture doivent cesser en cas de perte de la connexion au site distant. Sinon, une écriture existerait sur un site, mais pas sur l'autre. Généralement, ces environnements sont configurés pour mettre les LUN hors ligne en cas de perte de la connectivité site à site pendant plus d'une courte période (par exemple, 30 secondes).</block>
  <block id="84ad4c21def9c355e80ef250d910bfa2" category="paragraph">Ce comportement est souhaitable pour un petit sous-ensemble d'environnements. Cependant, la plupart des applications nécessitent une solution capable de garantir une réplication synchrone dans des conditions normales de fonctionnement, mais avec la possibilité de suspendre la réplication. Une perte complète de la connectivité site à site est souvent considérée comme une situation proche d'une catastrophe. Généralement, ces environnements sont maintenus en ligne et donnent accès aux données jusqu'à ce que la connectivité soit réparée ou qu'une décision officielle soit prise de fermer l'environnement pour protéger les données. Il n'est pas rare d'avoir besoin d'arrêter automatiquement l'application uniquement en raison d'une défaillance de réplication à distance.</block>
  <block id="e3bd381a7bbaee6c741aee230972acf4" category="paragraph">SyncMirror prend en charge les exigences de mise en miroir synchrone avec la flexibilité d'un délai d'expiration. Si la connectivité à la télécommande et/ou au plex est perdue, une minuterie de 30 secondes commence à s'arrêter. Lorsque le compteur atteint 0, le traitement des E/S d'écriture reprend en utilisant les données locales. La copie distante des données est utilisable, mais elle est figée à temps jusqu'à ce que la connectivité soit rétablie. La resynchronisation exploite des snapshots au niveau de l'agrégat pour rétablir le système en mode synchrone aussi rapidement que possible.</block>
  <block id="0c919cd6511df6d83b811234b0448374" category="paragraph">Notamment, dans de nombreux cas, ce type de réplication universelle en mode domino tout ou rien est mieux implémenté au niveau de la couche applicative. Par exemple, Oracle DataGuard inclut le mode de protection maximum, ce qui garantit la réplication à long terme en toutes circonstances. Si la liaison de réplication échoue pendant une période dépassant un délai configurable, les bases de données s'arrêtent.</block>
  <block id="ba92cbe464cfee8aa12c41e6aecd1071" category="section-title">Basculement automatique sans surveillance avec Fabric Attached MetroCluster</block>
  <block id="515094655d10031595da776c94b3d710" category="paragraph">Le basculement automatique sans surveillance (AUSO) est une fonctionnalité MetroCluster intégrée au fabric qui offre une forme de haute disponibilité intersite. Comme évoqué précédemment, MetroCluster est disponible en deux types : un contrôleur unique sur chaque site ou une paire haute disponibilité sur chaque site. L'avantage principal de l'option haute disponibilité est que l'arrêt planifié ou non planifié du contrôleur permet toujours une E/S locale. L'avantage de l'option à nœud unique est de réduire les coûts, la complexité et l'infrastructure.</block>
  <block id="29d4da26af76b66db3a172a39edf8367" category="paragraph">La principale valeur d'AUSO est d'améliorer les fonctionnalités haute disponibilité des systèmes MetroCluster connectés à la structure. Chaque site surveille l'état de santé du site opposé et, si aucun nœud n'est encore utilisé pour transmettre des données, l'AUSO assure un basculement rapide. Cette approche est particulièrement utile dans les configurations MetroCluster avec un seul nœud par site, car elle rapproche la configuration d'une paire haute disponibilité en termes de disponibilité.</block>
  <block id="6b3a5f7923b2d803fd3b28c255fef420" category="paragraph">AUSO ne peut pas offrir de surveillance complète au niveau d'une paire HA. Une paire haute disponibilité peut offrir une haute disponibilité, car elle inclut deux câbles physiques redondants pour une communication nœud à nœud directe. En outre, les deux nœuds d'une paire haute disponibilité ont accès au même ensemble de disques sur des boucles redondantes, ce qui permet à un nœud de suivre l'état d'un autre nœud sur une autre route.</block>
  <block id="da87dad268507a3523bc38275b1d3fbc" category="paragraph">Il existe des clusters MetroCluster sur plusieurs sites pour lesquels la communication nœud à nœud et l'accès au disque reposent sur la connectivité réseau site à site. La capacité à surveiller le pouls du reste du cluster est limitée. AUSO doit faire la distinction entre une situation où l'autre site est en fait hors service plutôt qu'indisponible en raison d'un problème de réseau.</block>
  <block id="e8e4f55c4203e7fb24d4543a7a0f65da" category="paragraph">Par conséquent, un contrôleur d'une paire haute disponibilité peut demander un basculement s'il détecte une panne de contrôleur qui s'est produite pour une raison spécifique, par exemple une situation critique du système. Elle peut également déclencher un basculement en cas de perte complète de la connectivité, parfois appelée « perte de pulsation ».</block>
  <block id="91aa4ce36cb243281f3777d66c8f89e0" category="paragraph">Un système MetroCluster ne peut effectuer un basculement automatique en toute sécurité que lorsqu'une panne spécifique est détectée sur le site d'origine. En outre, le contrôleur qui devient propriétaire du système de stockage doit être en mesure de garantir la synchronisation des données du disque et de la NVRAM. Le contrôleur ne peut pas garantir la sécurité d'un basculement simplement parce qu'il a perdu le contact avec le site source, qui pourrait toujours être opérationnel. Pour plus d'informations sur les options d'automatisation d'un basculement, reportez-vous aux informations sur la solution MetroCluster Tiebreaker (MCTB) dans la section suivante.</block>
  <block id="8e7705fe4aea384d7f6a99ab6dc0f408" category="section-title">Disjoncteur d'attache MetroCluster avec MetroCluster FAS</block>
  <block id="897b7698cb343dbc3452e845705ab0f3" category="inline-link">NetApp MetroCluster Tiebreaker</block>
  <block id="9c093f14319e8253b8c9b37290597239" category="inline-link">Site de support NetApp</block>
  <block id="a1d9fc4fb49119a9fe9b39abec0a769b" category="paragraph">Le<block ref="9332969062716487f0feefe076babf99" category="inline-link-rx"></block> Le logiciel peut s'exécuter sur un troisième site afin de contrôler l'état de santé de votre environnement MetroCluster, d'envoyer des notifications et de forcer un basculement en cas d'incident. Une description complète du disjoncteur d'attache se trouve sur le<block ref="c21658567f794984b03c21186a56713d" category="inline-link-rx"></block>, Mais le but principal du Tiebreaker de MetroCluster est de détecter la perte de site. Il doit également faire la distinction entre la perte du site et une perte de connectivité. Par exemple, le basculement ne doit pas se produire car le disjoncteur d'attache n'a pas pu atteindre le site principal. C'est pourquoi le disjoncteur d'attache surveille également la capacité du site distant à contacter le site principal.</block>
  <block id="6f29b1849750ceee5eb7f6f02d100e6b" category="paragraph">Le basculement automatique avec AUSO est également compatible avec le MCTB. AUSO réagit très rapidement car il est conçu pour détecter des événements de défaillance spécifiques, puis n'invoque le basculement que lorsque les plexes NVRAM et SyncMirror sont synchronisés.</block>
  <block id="6f5c7ae76595eca2ca83c5dd30cd8e9f" category="paragraph">En revanche, le disjoncteur principal est situé à distance et doit donc attendre qu'une minuterie s'écoule avant de déclarer un site mort. Le disjoncteur d'attache détecte finalement le type de défaillance de contrôleur couverte par l'AUSO, mais en général, l'AUSO a déjà commencé le basculement et éventuellement terminé le basculement avant que le disjoncteur d'attache n'agisse. La deuxième commande de basculement qui en résulte provient du Tiebreaker serait rejetée.</block>
  <block id="842547e1622bb12d9201167b0c39cf6d" category="paragraph">*Attention : *le logiciel MCTB ne vérifie pas que la mémoire NVRAM était et/ou que les plexes sont synchronisés lorsque vous forcez un basculement. Le basculement automatique, s'il est configuré, doit être désactivé pendant les opérations de maintenance qui entraînent une perte de synchronisation des plexes NVRAM ou SyncMirror.</block>
  <block id="7110edd59c3d0f25a584723f6fea26a0" category="paragraph">En outre, le MCTB peut ne pas traiter un désastre roulant qui conduit à la séquence d'événements suivante :</block>
  <block id="93d732b784eaf1a323f191e75c10f233" category="list-text">La connectivité entre les sites est interrompue pendant plus de 30 secondes.</block>
  <block id="81d4275cc3534a9fa8cfdcdb5172eb94" category="list-text">La réplication SyncMirror est obsolète et les opérations se poursuivent sur le site principal, ce qui ne permet pas au réplica distant d'être obsolète.</block>
  <block id="44441f68631008a941ce92e985131ff9" category="list-text">Le site primaire est perdu. Le résultat est la présence de modifications non répliquées sur le site primaire. Un basculement peut alors se révéler indésirable pour plusieurs raisons, notamment :</block>
  <block id="499527dd40fad77b119b8b33c99cd614" category="list-text">Certaines données critiques peuvent être présentes sur le site primaire et peuvent être récupérées à terme. Un basculement qui a permis à l'application de continuer à fonctionner aurait pour effet de supprimer ces données stratégiques.</block>
  <block id="86de4e3737e3d871dacf8ffef353fc31" category="list-text">Des données peuvent être mises en cache pour une application sur le site survivant qui utilisait des ressources de stockage sur le site principal au moment de la perte du site. Le basculement introduit une version obsolète des données qui ne correspond pas au cache.</block>
  <block id="dbb2a01afe28c8310daf781bb80b795f" category="list-text">Des données peuvent être mises en cache sur un système d'exploitation du site survivant qui utilisait des ressources de stockage sur le site principal au moment de la perte du site. Le basculement introduit une version obsolète des données qui ne correspond pas au cache. L'option la plus sûre est de configurer le Tiebreaker pour envoyer une alerte s'il détecte une défaillance du site et demander à une personne de décider si elle doit forcer un basculement. Il peut être nécessaire d'abord d'arrêter les applications et/ou les systèmes d'exploitation pour effacer les données en cache. En outre, les paramètres NVFAIL peuvent être utilisés pour renforcer la protection et rationaliser le processus de basculement.</block>
  <block id="ec6b0ea9c511479c118aa0f028f6519d" category="section-title">Mediator ONTAP avec MetroCluster IP</block>
  <block id="8ada6a626a475d631df231bbb3a88ac9" category="paragraph">Le médiateur ONTAP est utilisé avec MetroCluster IP et certaines autres solutions ONTAP. Il fonctionne comme un service disjoncteur d'attache classique, tout comme le logiciel disjoncteur d'attache MetroCluster mentionné ci-dessus, mais comprend également une fonctionnalité essentielle, qui effectue un basculement automatique sans surveillance.</block>
  <block id="991d7d7d7388ccdd87c65ca09aa804f2" category="paragraph">Un MetroCluster FAS dispose d'un accès direct aux dispositifs de stockage sur le site opposé. Cela permet à un contrôleur MetroCluster de surveiller l'intégrité des autres contrôleurs en lisant les données de pulsation à partir des disques. Cela permet à un contrôleur de reconnaître la défaillance d'un autre contrôleur et d'effectuer un basculement.</block>
  <block id="db2e932a11478bcf14c75d38e8b9a170" category="paragraph">En revanche, l'architecture IP MetroCluster achemine toutes les E/S exclusivement via la connexion contrôleur-contrôleur ; il n'y a pas d'accès direct aux dispositifs de stockage sur le site distant. Cela limite la capacité d'un contrôleur à détecter les défaillances et à effectuer un basculement. Le Mediator ONTAP est donc requis comme dispositif Tiebreaker pour détecter la perte du site et effectuer automatiquement un basculement.</block>
  <block id="8004e6d63f487a456290225b74768a6c" category="section-title">Troisième site virtuel avec ClusterLion</block>
  <block id="f1d5a7305654a402a719675fbec810e7" category="paragraph">ClusterLion est un dispositif de surveillance MetroCluster avancé qui fonctionne comme un troisième site virtuel. Cette approche permet de déployer MetroCluster en toute sécurité dans une configuration à deux sites avec une fonctionnalité de basculement entièrement automatisée. De plus, ClusterLion peut effectuer un moniteur de niveau réseau supplémentaire et exécuter des opérations de post-basculement. La documentation complète est disponible auprès de ProLion.</block>
  <block id="a60b8f728a13371898fea9947ef1e0dc" category="paragraph"><block ref="a60b8f728a13371898fea9947ef1e0dc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f8aae92ec17ec82868ef9ffc767dbd03" category="list-text">Les appliances ClusterLion contrôlent l'état des contrôleurs à l'aide de câbles série et Ethernet directement connectés.</block>
  <block id="c5f8963a91e3d8e7ac0abda2eab9f17d" category="list-text">Les deux appareils sont connectés l'un à l'autre à l'aide de connexions 3G sans fil redondantes.</block>
  <block id="24de16a13a1b584832d19117982cbfa6" category="list-text">L'alimentation vers le contrôleur ONTAP est acheminée via des relais internes. En cas de panne de site, ClusterLion, qui contient un système UPS interne, coupe les connexions d'alimentation avant d'appeler un basculement. Ce processus permet de s'assurer qu'aucune condition de split-brain ne se produit.</block>
  <block id="b2bcd3c3c555e2e4f27d453de4e0f06d" category="list-text">ClusterLion effectue un basculement dans le délai d'attente SyncMirror de 30 secondes ou pas du tout.</block>
  <block id="390fb5f827a3fbcdc7d05e6e7db03223" category="list-text">ClusterLion n'effectue pas de basculement à moins que les États des plexes NVRAM et SyncMirror ne soient synchronisés.</block>
  <block id="f322f850d55e87946f9660e4ccb1bbb6" category="list-text">Étant donné que ClusterLion effectue un basculement uniquement si MetroCluster est entièrement synchronisé, NVFAIL n'est pas nécessaire. Cette configuration permet aux environnements couvrant l'ensemble des sites, tels qu'un RAC Oracle étendu, de rester en ligne, même pendant un basculement non planifié.</block>
  <block id="5c132e05fb0e306f56955603619de359" category="list-text">Il inclut les protocoles Fabric-Attached MetroCluster et MetroCluster IP</block>
  <block id="86bcf99dbc3944da56f06b48074d09f6" category="doc">Fonctionnement normal</block>
  <block id="16dd4928055f2caf6f6fb8119ef69bcc" category="paragraph">SM-BC prend en charge deux types d'opérations de basculement du stockage, planifiées et non planifiées, qui fonctionnent de manières légèrement différentes. Un basculement planifié est initié manuellement par l'administrateur pour permettre un basculement rapide vers un site distant, tandis que le basculement non planifié est automatiquement initié par le médiateur sur le troisième site. L'objectif principal d'un basculement planifié est d'effectuer des correctifs et des mises à niveau incrémentiels, d'effectuer des tests de reprise après incident ou d'adopter une politique formelle de basculement des opérations entre les sites tout au long de l'année afin de prouver la continuité complète de l'activité.</block>
  <block id="63d4f976530f4faffa1ecd40fe8843f4" category="paragraph">Les diagrammes présentent ce qui se produit pendant les opérations normales, de basculement et de restauration. Pour plus de clarté, ils représentent un LUN répliqué. Dans une configuration SM-BC réelle, la réplication est basée sur des volumes, où chaque volume contient une ou plusieurs LUN, mais pour simplifier l'image, la couche de volume a été supprimée.</block>
  <block id="e48472f7daf781b63506f9e296443027" category="paragraph">En fonctionnement normal, une LUN est accessible à partir du réplica local ou distant. La ligne rouge indique le chemin optimisé annoncé par ALUA, qui doit s'assurer que les E/S sont préférablement envoyées sur ce chemin.</block>
  <block id="ef1d805ecb3b65664c42a1d32d8120d5" category="paragraph">La ligne verte est un chemin actif, mais elle subirait plus de latence, car les E/S sur ce chemin devront être transmises sur le chemin SM-BC. La latence supplémentaire dépend de la vitesse de l'interconnexion entre les sites utilisés pour SM-BC.</block>
  <block id="e139a585510a502bbf1841cf589f5086" category="section-title">Panne</block>
  <block id="7ed516552b652790c92df0bf237264b2" category="paragraph">Si la copie miroir active devient indisponible, en raison d'un basculement planifié ou non planifié, elle ne sera évidemment plus utilisable. Cependant, le système distant possède une réplique synchrone et des chemins SAN vers le site distant existent déjà. Le système distant peut traiter les E/S pour cette LUN.</block>
  <block id="89a4933a199f7b0e286c8bcb1606905a" category="paragraph">L'utilisation immédiate de la copie distante dépend du mode synchrone ou synchrone de SM-BC.</block>
  <block id="af43c542f512c4f7dc1b137d5de49d40" category="paragraph"><block ref="af43c542f512c4f7dc1b137d5de49d40" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7388404ef116c3ff812bfd290b094d9e" category="section-title">Basculement</block>
  <block id="997dfe060d2107e84407cfb41e692c54" category="paragraph">Le basculement entraîne la copie distante en tant que copie active. Les chemins passent de actif à actif/optimisé et les E/S continuent d'être traitées sans perte de données.</block>
  <block id="52da4ea35ba60090f331eefab5d6c612" category="paragraph"><block ref="52da4ea35ba60090f331eefab5d6c612" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0493d27e20d11e356e53e0a730b0ad08" category="section-title">Réparation</block>
  <block id="4f125c91283d9dc1751ad99a7a171420" category="paragraph">Une fois le système source remis en service, SM-BC peut resynchroniser la réplication tout en exécutant l'autre direction. La configuration est maintenant essentiellement la même que le point de départ, sauf que les sites actifs-miroirs ont été inversés.</block>
  <block id="5c647f57a104a05d7d8b55d089efefbe" category="paragraph"><block ref="5c647f57a104a05d7d8b55d089efefbe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6d80a3efb80520f47b63dc279e1bea3d" category="section-title">Du rétablissement</block>
  <block id="d47f47372b9b94d274cceb3638b28845" category="paragraph">Si vous le souhaitez, un administrateur peut effectuer un retour arrière et déplacer la copie active de la ou des LUN vers les contrôleurs d'origine.</block>
  <block id="0c99cedb6f39d8ac16d5b4c01c162c23" category="paragraph">La journalisation des opérations de reprise et des transactions de la base de données génère normalement des E/S non alignées qui peuvent entraîner des avertissements erronés concernant les LUN mal alignées sur ONTAP.</block>
  <block id="b2f7bb8e75b21ee3e883141c6ac1defe" category="paragraph">La journalisation effectue une écriture séquentielle du fichier journal avec des écritures de taille variable. Une opération d'écriture de journal qui ne s'aligne pas sur les limites de 4 Ko ne provoque généralement pas de problèmes de performances, car l'opération d'écriture de journal suivante termine le bloc. ONTAP est ainsi en mesure de traiter la quasi-totalité des écritures sous forme de blocs complets de 4 Ko, même si les données de blocs de 4 Ko ont été écrites dans deux opérations distinctes.</block>
  <block id="0e635e1f8ffad809203304cf41ed45c4" category="inline-link-macro">Vérification de l'alignement WAFL</block>
  <block id="bf837d24f10c904e697e3c0092da43b9" category="paragraph">Vérifiez l'alignement à l'aide d'utilitaires tels que<block ref="40883add63f1fbabc7fe6158f93c1246" prefix=" " category="inline-code"></block> ou<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block> Qui peuvent générer des E/S à une taille de bloc définie. Les statistiques d'alignement des E/S sur le système de stockage peuvent être affichées à l'aide du<block ref="446501053769c06c565094b26d26e8ef" prefix=" " category="inline-code"></block> commande. Voir <block ref="ebccec7997af507c87f985ec4ccec634" category="inline-link-macro-rx"></block> pour en savoir plus.</block>
  <block id="b5ffbfb0c082804ad41d0f61c87525ed" category="paragraph">De nombreux jeux de données d'applications sont organisés par date, et ces données sont généralement moins susceptibles d'être accessibles au fur et à mesure du vieillissement. Par exemple, une banque peut disposer d'un référentiel de fichiers PDF contenant cinq années de relevés clients, mais seuls les derniers mois sont actifs. FabricPool peut être utilisé pour déplacer d'anciens fichiers de données vers le Tier de capacité. Une période de refroidissement de 14 jours permettrait de conserver les fichiers PDF de 14 jours les plus récents sur le niveau de performance. En outre, les fichiers lus au moins tous les 14 jours resteraient fortement sollicités et resteraient donc sur le Tier de performance.</block>
  <block id="ed7e2cc7ff107d4b2032fe65cf4e756a" category="paragraph">Pour mettre en œuvre une approche de hiérarchisation basée sur des fichiers, vous devez avoir des fichiers écrits et non modifiés par la suite. Le<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> la règle doit être définie suffisamment haut pour que les fichiers dont vous avez besoin restent sur le tier de performance. Par exemple, un jeu de données pour lequel les 60 derniers jours de données sont requis avec des performances optimales garantit le paramétrage du<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> période jusqu'en 60. Des résultats similaires peuvent également être obtenus en fonction des modèles d'accès aux fichiers. Par exemple, si les 90 derniers jours de données sont requis et que l'application accède à cette période de 90 jours, les données restent sur le Tier de performance. En réglant le<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> sur 2, le tiering s'affiche rapidement une fois les données moins actives.</block>
  <block id="8a467b35326e4738b1bd39865c3b21a0" category="admonition">Tout type d'accès aux données réinitialise les données de la carte thermique. L'analyse antivirus, l'indexation et même l'activité de sauvegarde qui lit les fichiers source empêchent le Tiering, car les besoins sont importants<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> le seuil n'est jamais atteint.</block>
  <block id="7a1920d61156abc05a60135aefe8bc67" category="doc">Valeur par défaut</block>
  <block id="5ba46d288640832c345e169b04a7458a" category="paragraph">Tous les volumes FabricPool sont initialement définis sur<block ref="c21f969b5f03d33d43e04f8f136e7682" prefix=" " category="inline-code"></block>, ce qui signifie que le comportement est contrôlé par la `cloud-retrieval-policy. `le comportement exact dépend de la règle de hiérarchisation utilisée.</block>
  <block id="5ec354970d7934d92ba67ccaa0de0121" category="list-text"><block ref="9df22f196a33acd0b372fe502de51211" prefix="" category="inline-code"></block>– ne récupérer que les données lues de façon aléatoire</block>
  <block id="74092cfa5efab8e6ddc5c2991ee2cfc9" category="list-text"><block ref="8805d416ce540c5f2df34af5b18d742b" prefix="" category="inline-code"></block>– récupérer toutes les données lues de manière séquentielle ou aléatoire</block>
  <block id="2de036541477f953c6fd33d14a8db0e8" category="list-text"><block ref="334c4a4c42fdb79d7ebc3e73b517e6f8" prefix="" category="inline-code"></block>– récupérer toutes les données lues de manière séquentielle ou aléatoire</block>
  <block id="b6ffdb7ccf86e99ecf73899ec23bdd46" category="list-text"><block ref="a181a603769c1f98ad927e7367c7aa51" prefix="" category="inline-code"></block>– ne récupérez pas les données du niveau de capacité</block>
  <block id="d556a0d2cad80695d1d803ebb49de9cd" category="section-title">En lecture</block>
  <block id="7c39eb141ca855e5a211b468bd67636c" category="paragraph">Réglage<block ref="d253e682212338dd6cbe577947f0511e" prefix=" " category="inline-code"></block> la lecture remplace le comportement par défaut, de sorte qu'une lecture de toutes les données hiérarchisées entraîne le renvoi de ces données vers le niveau de performance.</block>
  <block id="e07df43ea07fecb178484ef278644eb2" category="paragraph">Par exemple, un volume peut avoir été légèrement utilisé pendant une longue période sous le<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> la règle de tiering et la plupart des blocs sont désormais hiérarchisés.</block>
  <block id="98c8614a9e0467f220df33a02cf7550a" category="paragraph">Si une modification inattendue des besoins de l'entreprise nécessitait l'analyse répétée de certaines données pour préparer un rapport spécifique, il peut être souhaitable de modifier le<block ref="d253e682212338dd6cbe577947f0511e" prefix=" " category="inline-code"></block> à<block ref="0ba0dc933ac714a0bef4467360437336" prefix=" " category="inline-code"></block> pour garantir que toutes les données lues sont renvoyées au niveau de performances, y compris les données lues de manière séquentielle et aléatoire. Cela améliorerait les performances des E/S séquentielles par rapport au volume.</block>
  <block id="3ea4ba4aadef21fbda74c9b242c99efa" category="section-title">Promouvoir</block>
  <block id="cb674c0cbcbaa23bdd3c8e4f6182f865" category="paragraph">Le comportement de la règle de promotion dépend de la règle de hiérarchisation. Si la règle de hiérarchisation est<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block>, puis réglage du<block ref="723c2b1883eb9949dd821267c2d1b5c7" prefix=" " category="inline-code"></block> ramène tous les blocs du tier de capacité à l'analyse de tiering suivante.</block>
  <block id="452d85cc34fd3a4cf55ac61e732239f4" category="paragraph">Si la règle de hiérarchisation est<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block>, les seuls blocs renvoyés sont les blocs associés au système de fichiers actif. Normalement, cela n'aurait aucun effet car les seuls blocs placés sous le sont<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> la règle serait les blocs associés exclusivement aux snapshots. Il n'y aurait pas de blocs hiérarchisés dans le système de fichiers actif.</block>
  <block id="d6269fb1a970b6c261fedbc79464b3dc" category="paragraph">Toutefois, si une SnapRestore de volume ou une opération de clonage de fichiers a été effectuée pour restaurer les données d'un volume à partir d'un snapshot, le système de fichiers actif peut désormais avoir besoin de certains blocs qui ont été hiérarchisés, car ils n'étaient associés qu'à des snapshots. Il peut être souhaitable de modifier temporairement le<block ref="d253e682212338dd6cbe577947f0511e" prefix=" " category="inline-code"></block> règle à<block ref="eeefc0add5ccd6e20ac4214923d27fbc" prefix=" " category="inline-code"></block> pour récupérer rapidement tous les blocs localement requis.</block>
  <block id="6e7b34fa59e1bd229b207892956dc41c" category="section-title">Jamais</block>
  <block id="c45e30a0f86af155e2feb17dd7ba6e44" category="paragraph">Ne récupérez pas les blocs du niveau de capacité.</block>
  <block id="2d242bb36ec91b32005f9296ff03a912" category="doc">Architecture</block>
  <block id="ac30d4a74ecef302adab70e9669a4bf2" category="paragraph">FabricPool est une technologie de hiérarchisation qui classe les blocs « actifs » ou « froids » et les place dans le Tier de stockage le plus approprié. Le Tier de performance se trouve le plus souvent sur un stockage SSD et héberge les blocs de données fortement sollicités. Le Tier de capacité se trouve dans un magasin d'objets et héberge les blocs de données utiles. Elle prend en charge le stockage objet, notamment NetApp StorageGRID, ONTAP S3, Microsoft Azure Blob Storage, le service de stockage objet Alibaba Cloud, IBM Cloud Object Storage, Google Cloud Storage et Amazon AWS S3.</block>
  <block id="f9f5fe2f7456d37c955f3291744c93b6" category="paragraph">Plusieurs règles de Tiering sont disponibles pour contrôler la façon dont les blocs sont classés comme actifs ou froids. Il est également possible de définir des règles par volume et de les modifier selon les besoins. Seuls les blocs de données sont déplacés entre les tiers de performance et de capacité. Les métadonnées qui définissent la structure des LUN et du système de fichiers restent toujours sur le Tier de performance. La gestion est ainsi centralisée sous ONTAP. Les fichiers et les LUN n'apparaissent pas différents des données stockées dans une autre configuration ONTAP. Le contrôleur NetApp AFF ou FAS applique les règles définies pour déplacer les données vers le Tier approprié.</block>
  <block id="156a1cf692c4ba9a4f9574fb16428b01" category="paragraph"><block ref="156a1cf692c4ba9a4f9574fb16428b01" category="inline-image-macro-rx" type="image"></block></block>
  <block id="616ce0475334fe37834d13972a168ca5" category="section-title">Fournisseurs de magasins d'objets</block>
  <block id="71e79501cc067e6b35ac3d3e97c940a4" category="paragraph">Les protocoles de stockage objet utilisent de simples requêtes HTTP ou HTTPS pour stocker un grand nombre d'objets de données. L'accès au stockage objet doit être fiable, car l'accès aux données depuis ONTAP dépend du traitement rapide des demandes. Notamment Amazon S3 Standard et Infrequent Access, Microsoft Azure Hot Blob Storage, IBM Cloud et Google Cloud. Les options d'archivage telles qu'Amazon Glacier et Amazon Archive ne sont pas prises en charge, car le temps nécessaire à la récupération des données peut dépasser les tolérances des systèmes d'exploitation et des applications hôtes.</block>
  <block id="e114e830308285cd9085063fad91662c" category="paragraph">NetApp StorageGRID est également pris en charge et constitue une solution optimale. C'est un système de stockage objet haute performance, évolutif et hautement sécurisé qui assure une redondance géographique pour les données FabricPool ainsi que pour les autres applications de magasin d'objets qui font de plus en plus partie des environnements applicatifs d'entreprise.</block>
  <block id="fb318c5cd9ed18c79e1f7a298dd96665" category="paragraph">StorageGRID peut également réduire les coûts en évitant les frais de sortie imposés par de nombreux fournisseurs de cloud public pour la lecture des données de leurs services.</block>
  <block id="119d8a1213b5b7cae4bb567153b028cf" category="section-title">Données et métadonnées</block>
  <block id="b59d6123a3191bd85fe14e57b7a01e11" category="paragraph">Notez que le terme « données » s'applique ici aux blocs de données réels, et non aux métadonnées. Seuls les blocs de données sont hiérarchisés, tandis que les métadonnées restent dans le Tier de performance. En outre, l'état d'un bloc en tant que bloc chaud ou froid n'est affecté que par la lecture du bloc de données réel. La simple lecture du nom, de l'horodatage ou des métadonnées de propriété d'un fichier n'affecte pas l'emplacement des blocs de données sous-jacents.</block>
  <block id="1414cdc093d39dd56d0b0d20049e17fc" category="section-title">Sauvegardes</block>
  <block id="e0b766a7a0a7633679ecddd0f78a7390" category="paragraph">Même si FabricPool permet de réduire considérablement l'encombrement du stockage, il ne s'agit pas à lui seul d'une solution de sauvegarde. Les métadonnées NetApp WAFL restent toujours sur le Tier de performance. Si un incident catastrophique détruit le Tier de performance, il est impossible de créer un nouvel environnement à l'aide des données du Tier de capacité, car il ne contient pas de métadonnées WAFL.</block>
  <block id="7a25ce12890e524732cb71784b5915ab" category="paragraph">FabricPool peut cependant faire partie d'une stratégie de sauvegarde. Par exemple, FabricPool peut être configuré avec la technologie de réplication NetApp SnapMirror. Chaque moitié du miroir peut avoir sa propre connexion à une cible de stockage objet. Vous obtenez ainsi deux copies indépendantes des données. La copie principale se compose des blocs du niveau de performance et des blocs associés du niveau de capacité, tandis que la réplique constitue un second ensemble de blocs de performance et de capacité.</block>
  <block id="82af841589057aa8922b1ac3bb4a28a4" category="doc">Compression</block>
  <block id="e242ff0701d9ed7d8317b32fd762a100" category="paragraph">Les fonctionnalités d'optimisation de l'espace, telles que la compression, la compaction et la déduplication, sont conçues pour augmenter la quantité de données logiques correspondant à un volume de stockage physique donné. Vous réduisez ainsi vos coûts et vos frais de gestion.</block>
  <block id="13b992c3d358d786db03341886472c4f" category="paragraph">À un niveau élevé, la compression est un processus mathématique qui permet de détecter et d'encoder des modèles de données de manière à réduire les besoins en espace. En revanche, la déduplication détecte les blocs de données répétés et supprime les copies parasites. La compaction permet à plusieurs blocs logiques de données de partager le même bloc physique sur le support.</block>
  <block id="786d7cc1b18aa3d9c3e8d3e30865240e" category="paragraph">Avant la disponibilité des systèmes de stockage 100 % Flash, la compression basée sur les baies était d'une valeur limitée, car la plupart des charges de travail exigeantes en E/S nécessitaient un très grand nombre de piles pour obtenir une performance acceptable. Les systèmes de stockage contenaient invariablement beaucoup plus de capacité que nécessaire, ce qui a pour effet d'augmenter le nombre de disques. La situation a changé avec la montée du stockage Solid-State. Il n'est plus nécessaire de surprovisionner des disques uniquement pour obtenir de bonnes performances. L'espace disque d'un système de stockage peut être adapté aux besoins réels en termes de capacité.</block>
  <block id="b207c460d31fea9e1cfab71057e8152c" category="paragraph">La capacité accrue des disques SSD en termes d'IOPS permet presque toujours de réaliser des économies par rapport aux disques rotatifs. Toutefois, la compression peut réaliser davantage d'économies en augmentant la capacité effective des supports SSD.</block>
  <block id="bd6c983943da8bf0ead08c643f0e75f3" category="paragraph">Il existe plusieurs façons de compresser les données. De nombreuses bases de données incluent leurs propres fonctionnalités de compression, mais ce phénomène est rarement observé dans les environnements clients. La raison en est généralement la pénalité de performance pour un *changement* de données compressées, plus il y a souvent des coûts de licence élevés. Enfin, il y a les conséquences globales sur les performances des opérations des bases de données. Il est peu judicieux de payer un coût de licence par processeur élevé pour un processeur qui effectue la compression et la décompression des données plutôt que le véritable travail de base de données. Une meilleure option consiste à décharger la tâche de compression sur le système de stockage.</block>
  <block id="6296c8b7406b90d37edf269f1ea6f6ee" category="section-title">Compression adaptative</block>
  <block id="1245fef302b5da2c27766d9a98ad358c" category="paragraph">La compression adaptative a été testée en profondeur avec des charges de travail exigeantes sans effet sur les performances, même dans un environnement 100 % Flash où la latence se mesure en microsecondes. Certains clients ont même signalé une augmentation des performances due à l'utilisation de la compression, car les données restent compressées dans le cache, augmentant ainsi la quantité de cache disponible dans un contrôleur.</block>
  <block id="93e0a644c8f1b7f7f378bc071d15d1e9" category="paragraph">ONTAP gère les blocs physiques dans des unités de 4 Ko. La compression adaptative utilise une taille de bloc de compression par défaut de 8 Ko, ce qui signifie que les données sont compressées dans des unités de 8 Ko. La taille de bloc de 8 Ko la plus utilisée par les bases de données relationnelles est donc identique. Les algorithmes de compression deviennent plus efficaces avec la compression d'un volume croissant de données. Une taille de bloc de compression de 32 Ko serait plus compacte qu'une unité de bloc de compression de 8 Ko. Cela signifie que la compression adaptative utilisant une taille de bloc de 8 Ko par défaut entraîne des taux d'efficacité légèrement inférieurs, mais qu'une taille de bloc de compression inférieure présente également des avantages considérables. Les charges de travail de la base de données incluent une grande quantité d'activités de remplacement. Le remplacement d'un bloc de données de 32 Ko compressé de 8 Ko nécessite la lecture de l'intégralité des 32 Ko de données logiques, leur décompression, la mise à jour de la région de 8 Ko requise, la recompression, puis l'écriture de la totalité des 32 Ko sur les disques. Cette opération est très coûteuse pour un système de stockage. En effet, certaines baies de stockage concurrentes, basées sur des blocs de compression plus volumineux, affectent également considérablement les performances des charges de travail de la base de données.</block>
  <block id="096cc7f8e7e1861c3ee0269a90fc27e3" category="admonition">La taille de bloc utilisée par la compression adaptative peut être augmentée jusqu'à 32 Ko. Cela peut améliorer l'efficacité du stockage et doit être envisagé pour les fichiers de repos tels que les journaux d'archivage et les fichiers de sauvegarde lorsqu'une quantité importante de ces données est stockée sur la baie. Dans certains cas, les bases de données actives qui utilisent une taille de bloc de 16 ou 32 Ko peuvent également tirer parti de l'augmentation de la taille de bloc de la compression adaptative pour qu'elle corresponde. Consultez un représentant NetApp ou partenaire pour savoir si cette solution convient à votre charge de travail.</block>
  <block id="f291779c724993ded5e79421d88f3e55" category="admonition">Les tailles de bloc de compression supérieures à 8 Ko ne doivent pas être utilisées avec la déduplication sur les destinations de sauvegarde en streaming. Les petites modifications apportées aux données sauvegardées affectent la fenêtre de compression de 32 Ko. Si la fenêtre change, les données compressées obtenues diffèrent dans l'ensemble du fichier. La déduplication a lieu après la compression, ce qui signifie que le moteur de déduplication voit chaque sauvegarde compressée différemment. Si la déduplication des sauvegardes en continu (comme Oracle RMAN) est requise, seule une compression adaptative de bloc de 8 Ko doit être utilisée. Il est préférable d'utiliser la compression adaptative, car elle fonctionne à des blocs de taille réduite sans perturber l'efficacité de la déduplication. Pour des raisons similaires, la compression côté hôte interfère également avec l'efficacité de la déduplication.</block>
  <block id="1f9367b7afff301ee24188d35050ae0a" category="section-title">Efficacité du stockage sensible à la température</block>
  <block id="78aa8c12abb3bf9f61a08df0f9b403de" category="paragraph">L'efficacité du stockage sensible à la température (TSSE) est disponible dans ONTAP 9.8 et versions ultérieures. Elle repose sur des cartes thermiques d'accès aux blocs pour identifier les blocs peu utilisés et les compresser avec une efficacité accrue.</block>
  <block id="02e44d620def629a6c145ccd0d9a0fd3" category="section-title">Alignement de compression</block>
  <block id="3b6e6c232a02ab9c64199eb9efae012c" category="paragraph">La compression adaptative dans un environnement de base de données nécessite un certain respect de l'alignement des blocs de compression. Cela ne préoccupe que les données soumises à des écrasements aléatoires de blocs très spécifiques. Cette approche est similaire à l'alignement global du système de fichiers, où le début d'un système de fichiers doit être aligné sur une limite de périphérique de 4 Ko et la taille de bloc d'un système de fichiers doit être un multiple de 4 Ko.</block>
  <block id="327a36f7ca539411197c2f867b501719" category="paragraph">Par exemple, une écriture de 8 Ko dans un fichier est compressée uniquement si elle s'aligne sur une limite de 8 Ko dans le système de fichiers lui-même. Ce point signifie qu'il doit figurer sur le premier 8 Ko du fichier, le deuxième 8 Ko du fichier, etc. Les données telles que les sauvegardes RMAN ou les journaux d'archivage sont des opérations écrites de manière séquentielle couvrant plusieurs blocs, qui sont toutes compressées. Par conséquent, il n'est pas nécessaire de considérer l'alignement. Le seul modèle d'E/S préoccupant est l'écrasement aléatoire des fichiers.</block>
  <block id="1d1a594959ec615f56516f5d0f5e8ddb" category="section-title">NFS</block>
  <block id="8dae8f7054353dae17cd9da8deb0e091" category="paragraph">NFS permet d'aligner les E/S de fichiers. Chaque bloc d'un fichier est aligné par rapport au début du fichier.</block>
  <block id="62a0282d39568be094470486eaf70c4f" category="section-title">SAN</block>
  <block id="b0762e9957c8485f911e57bfd027eddb" category="paragraph">Les environnements SAN nécessitent que les données soient alignées sur une limite de 8 Ko pour une compression optimale. Il existe deux aspects de l'alignement pour SAN : le LUN et le système de fichiers. La LUN doit être configurée en tant que périphérique de disque entier (pas de partition) ou avec une partition alignée sur une limite de 8 Ko.</block>
  <block id="ad16b6d5634739ef4ceb795c5beea659" category="admonition">Reportez-vous aux sections sur le provisionnement fin pour une explication de l'interaction entre la compression et la réservation fractionnaire.</block>
  <block id="14c3c56ff2a98d1a9c47b63a917f67a3" category="section-title">Compaction</block>
  <block id="546168bb7b68da66be7b6c0e60a23460" category="paragraph">La compaction est une technologie intégrée à ONTAP qui améliore l'efficacité de la compression. Comme indiqué précédemment, la compression adaptative à elle seule permet d'économiser 2:1 au maximum, car elle se limite au stockage d'une E/S de 8 Ko dans un bloc WAFL de 4 Ko. Les méthodes de compression avec des blocs de taille supérieure améliorent l'efficacité. Cependant, elles ne conviennent pas aux données soumises à des remplacements de blocs de petite taille. La décompression d'unités de données de 32 Ko, la mise à jour d'une partie de 8 Ko, la recompression et l'écriture sur les disques entraînent une surcharge.</block>
  <block id="0b01f66d49b9df153ee76048de44f6eb" category="paragraph">La compaction des données permet de stocker plusieurs blocs logiques dans des blocs physiques. Par exemple, une base de données avec des données fortement compressibles comme des blocs texte ou partiellement pleins peut être compressée de 8 Ko à 1 Ko. Sans compaction, 1 Ko de données occuperaient toujours un bloc complet de 4 Ko. La compaction des données à la volée permet de stocker 1 Ko de données compressées dans un espace physique de seulement 1 Ko, parallèlement à d'autres données compressées. Il ne s'agit pas d'une technologie de compression. Il s'agit simplement d'un moyen plus efficace d'allouer de l'espace sur les disques et, par conséquent, il ne doit pas créer d'effet détectable sur les performances.</block>
  <block id="07b153ed9b6a6f9f334f2ad1fe94651e" category="paragraph">Le degré d'économie obtenu varie. En général, les données déjà compressées ou chiffrées ne peuvent pas être compressées davantage et, par conséquent, la compaction de ces datasets ne peut pas être bénéfique. Les fichiers de données Oracle nouvellement initialisés qui ne contiennent que des métadonnées de bloc et des zéros compressent jusqu'à 80:1. Cela crée un très large éventail de possibilités.</block>
  <block id="83f45cad5e6f535ff10e564a526baad0" category="section-title">Déduplication</block>
  <block id="f591ef30da06841378ee7f595e63a93c" category="paragraph">La déduplication permet de supprimer les tailles de bloc dupliquées d'un dataset. Par exemple, si le même bloc de 4 Ko existe dans 10 fichiers différents, la déduplication redirige ce bloc de 4 Ko au sein des 10 fichiers vers le même bloc physique de 4 Ko. Résultat : une amélioration de l'efficacité de ces données de 10:1.</block>
  <block id="699c85c5df1985b2af588f9e6c1ad353" category="paragraph">Les données, telles que les LUN de démarrage invité VMware, se dédupliquent extrêmement bien, car elles sont constituées de plusieurs copies des mêmes fichiers du système d'exploitation. L'efficacité de 100:1 et plus ont été observées.</block>
  <block id="c3ed34b88ac0b8efff210a99f19a4b9b" category="paragraph">Certaines données ne contiennent pas de données dupliquées. Par exemple, un bloc Oracle contient un en-tête globalement unique à la base de données et une bande-annonce presque unique. Par conséquent, la déduplication d'une base de données Oracle permet rarement de réaliser plus de 1 % d'économies.</block>
  <block id="9653a3d4907877aae00bb7d39eeec66d" category="paragraph">Dans quelques cas, des économies d'espace allant jusqu'à 15 % ont été observées pour les bases de données de 16 Ko et les blocs volumineux. La bande de 4 Ko initiale de chaque bloc contient l'en-tête unique dans le monde, et le bloc de 4 Ko final contient la remorque presque unique. Les blocs internes sont candidats à la déduplication, bien que dans la pratique cela soit presque entièrement attribué à la déduplication des données mises à zéro.</block>
  <block id="89d6ec0df0a54d3cdcc8f0573a6b37c5" category="paragraph">De nombreuses baies concurrentes prétendent être capables de dédupliquer des bases de données Oracle en présumant qu'une base de données est copiée à plusieurs reprises. Il est également possible d'utiliser la déduplication NetApp, mais ONTAP offre une meilleure option : la technologie FlexClone de NetApp. Le résultat final est le même : plusieurs copies d'une base de données Oracle qui partagent la plupart des blocs physiques sous-jacents sont créées. L'utilisation de FlexClone est bien plus efficace que de prendre le temps de copier les fichiers de données, puis de les dédupliquer. Il s'agit en effet de la non-duplication plutôt que de la déduplication, car un doublon n'est jamais créé à la première place.</block>
  <block id="32aeb47267cb2045610b468115f3ae0e" category="section-title">Efficacité et provisionnement fin</block>
  <block id="3381946611f34fb44ad8a38a0c44e0a8" category="paragraph">Les fonctions d'efficacité sont des formes de provisionnement fin. Par exemple, une LUN de 100 Go occupant un volume de 100 Go peut compresser à 50 Go. Aucune économie réelle n'est encore réalisée, car le volume est toujours de 100 Go. Le volume doit d'abord être réduit afin que l'espace économisé puisse être utilisé ailleurs sur le système. Si des modifications ultérieures de la LUN de 100 Go réduisent la taille des données compressibles, la LUN augmente et le volume pourrait se remplir.</block>
  <block id="20132d08f816a6401f40a29feb68df8d" category="paragraph">Le provisionnement fin est fortement recommandé car il simplifie la gestion tout en améliorant la capacité exploitable avec les économies associées. La raison en est simple : les environnements Oracle incluent souvent beaucoup d'espace vide, un grand nombre de volumes et de LUN, ainsi que des données compressibles. Le provisionnement fin entraîne la réservation d'espace sur le stockage pour les volumes et les LUN au cas où un jour ils se traduirait par une saturation de 100 % et contiendraient des données non compressibles à 100 %. Il est peu probable que cela se produise. Le provisionnement fin permet de récupérer et d'utiliser cet espace ailleurs. Il permet également de gérer la capacité en fonction du système de stockage lui-même, plutôt que de nombreux volumes et LUN plus petits.</block>
  <block id="38ef8b6f2fc332958c293d93c61d7756" category="paragraph">Certains clients préfèrent utiliser le provisionnement lourd, soit pour des charges de travail spécifiques, soit généralement en fonction de pratiques opérationnelles et d'approvisionnement établies.</block>
  <block id="f8ea8eaa5ca0e58c6a43ec0117b7bd8d" category="paragraph">*Attention :* si un volume est configuré en mode lourd, il faut veiller à désactiver complètement toutes les fonctions d'efficacité de ce volume, y compris la décompression et la suppression de la déduplication à l'aide du<block ref="3cfeff511a11b8c5f54ce9749a719a58" prefix=" " category="inline-code"></block> commande. Le volume ne doit pas apparaître dans<block ref="df899f2d908ec33afe1d01ee26b3dd47" prefix=" " category="inline-code"></block> sortie. Si c'est le cas, le volume est encore partiellement configuré pour les fonctions d'efficacité. Par conséquent, les garanties de remplacement fonctionnent différemment, ce qui augmente le risque que les dépassements de configuration entraînent un manque inattendu d'espace du volume, ce qui entraîne des erreurs d'E/S de la base de données.</block>
  <block id="0e7c78164adb6d4650ea685a79d8e99e" category="section-title">Meilleures pratiques en matière d'efficacité</block>
  <block id="d67dd6ae62908b7781805cf297fa8d87" category="paragraph">NetApp fournit les recommandations suivantes pour ONTAP 9 et versions ultérieures. Pour les versions ONTAP antérieures à ONTAP 9, veuillez contacter votre représentant NetApp.</block>
  <block id="ec499ad25fa5a765ba43ec2c87819623" category="section-title">AFF par défaut</block>
  <block id="38b7d52fb2d518d07c1c857b20ebbbd2" category="paragraph">Les volumes créés sur ONTAP et exécutés sur un système AFF 100 % Flash sont à allocation dynamique, avec l'activation de toutes les fonctionnalités d'efficacité à la volée. Bien que les bases de données Oracle ne bénéficient généralement pas de la déduplication et puissent inclure des données non compressibles, les paramètres par défaut conviennent néanmoins à la plupart des charges de travail. ONTAP est conçu pour traiter efficacement tous les types de données et de modèles d'E/S, qu'ils entraînent ou non des économies. Les valeurs par défaut ne doivent être modifiées que si les raisons sont parfaitement comprises et si un écart est bénéfique.</block>
  <block id="9f7127e69d50bf7b844ff3723b86fbd1" category="section-title">Recommandations générales</block>
  <block id="2c24e4751310e03f119a4df187a3bc08" category="list-text">Si les volumes et/ou les LUN ne sont pas à provisionnement fin, vous devez désactiver tous les paramètres d'efficacité car l'utilisation de ces fonctionnalités n'offre aucune économie et la combinaison du provisionnement lourd et de l'optimisation de l'espace peut provoquer des comportements inattendus, notamment des erreurs de manque d'espace.</block>
  <block id="4922fe547c351d6a121465da036d478e" category="list-text">Si les données ne sont pas sujettes à des écrasements, par exemple avec des sauvegardes ou des journaux de transactions de base de données, vous pouvez atteindre une meilleure efficacité en activant TSSE avec une période de refroidissement faible.</block>
  <block id="e75fd383e4106eb78482b18896975daf" category="list-text">Certains fichiers peuvent contenir une quantité importante de données non compressibles, par exemple lorsque la compression est déjà activée au niveau de l'application, les fichiers sont cryptés. Si l'un de ces scénarios est vrai, envisagez de désactiver la compression pour permettre un fonctionnement plus efficace sur d'autres volumes contenant des données compressibles.</block>
  <block id="11845fef1d21077d7b23ce880868b556" category="list-text">N'utilisez pas la compression et la déduplication de 32 Ko pour les sauvegardes de bases de données. Voir la section « »<block ref="57ee2712afc5e59236f86db0537b05dc" category="inline-xref-macro-rx"></block>« » pour plus de détails.</block>
  <block id="64d5def835c194cac8afe4fafded756e" category="doc">Règles - snapshots locaux</block>
  <block id="baa596d0db91317fa83739a95649752e" category="paragraph">La version initiale de FabricPool a ciblé le cas d'utilisation de la sauvegarde. Les seuls types de blocs qui ont pu être hiérarchisés sont les blocs qui n'étaient plus associés aux données dans le système de fichiers actif. Par conséquent, seuls les blocs de données des snapshots peuvent être déplacés vers le niveau de capacité. Il s'agit là de l'une des options de hiérarchisation les plus sécurisées lorsque vous devez vous assurer que les performances ne sont jamais affectées.</block>
  <block id="b21eb7f0b67c3e27e915183638bf92cf" category="paragraph">Deux options sont disponibles pour le Tiering des blocs de snapshots inactifs vers le niveau de capacité. Tout d'abord, le<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> la règle cible uniquement les blocs de snapshot. Bien que le<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> la politique inclut le<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> et tiering des blocs à partir du système de fichiers actif. Ce n'est peut-être pas souhaitable.</block>
  <block id="eeba990304f236b36a9fec2434c77470" category="paragraph">Le<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> value doit être défini sur une période qui met à disposition les données éventuellement requises lors d'une restauration sur le tier de performance. Par exemple, la plupart des scénarios de restauration d'une base de données de production stratégique incluent un point de restauration à un moment donné au cours des jours précédents. Réglage a<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> la valeur 3 garantit que toute restauration du fichier entraîne un fichier qui offre immédiatement des performances maximales. Tous les blocs des fichiers actifs sont toujours présents sur un système de stockage rapide sans avoir à les restaurer à partir du niveau de capacité.</block>
  <block id="baf531ed01ad56f5614e1a68e8a2e7aa" category="section-title">Règles - snapshots répliqués</block>
  <block id="27e5121a4c75181022e7be2b738339d0" category="paragraph">Les snapshots répliqués avec SnapMirror ou SnapVault, uniquement utilisés pour la restauration, doivent généralement utiliser FabricPool<block ref="a181a603769c1f98ad927e7367c7aa51" prefix=" " category="inline-code"></block> politique. Avec cette règle, les métadonnées sont répliquées, mais tous les blocs de données sont immédiatement envoyés au niveau de capacité pour des performances maximales. La plupart des processus de restauration impliquent des E/S séquentielles, ce qui est intrinsèquement efficace. Le délai de restauration à partir de la destination du magasin d'objets doit être évalué, mais dans une architecture bien conçue, ce processus de restauration ne doit pas nécessairement être beaucoup plus lent que la restauration à partir de données locales.</block>
  <block id="639e481de0ffe002bd83251b26a2540a" category="paragraph">Si les données répliquées sont également destinées à être utilisées pour le clonage, le<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> la politique est plus appropriée, avec un<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> valeur qui englobe les données qui doivent être utilisées régulièrement dans un environnement de clonage. Par exemple, le jeu de travail actif d'une base de données peut inclure des données lues ou écrites au cours des trois jours précédents, mais il peut également inclure 6 mois de données historiques supplémentaires. Si oui, alors le<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> La règle appliquée à la destination SnapMirror met à disposition le jeu de travail sur le Tier de performance.</block>
  <block id="ace0bd0c1be3a9e17d9736d93e7a1da2" category="doc">QoS des IOPS</block>
  <block id="786ee59e0cdaa09335e12fea3a168653" category="paragraph">Plus précisément, l'adoption croissante des systèmes de stockage 100 % Flash a permis de consolider les charges de travail. Les baies de stockage qui reposent sur des supports rotatifs ne prennent généralement en charge qu'un nombre limité de charges de travail exigeantes en E/S, car leurs capacités IOPS sont limitées par rapport aux anciens disques rotatifs. Une ou deux bases de données fortement actives saturaient les disques sous-jacents bien avant que les contrôleurs de stockage n'atteignent leurs limites. Cela a changé. Il est possible de saturer les contrôleurs de stockage les plus puissants, car le nombre de disques SSD requis est relativement faible. Cela signifie que vous pouvez exploiter pleinement les capacités des contrôleurs sans craindre un effondrement soudain des performances lors de pics de latence des supports rotatifs.</block>
  <block id="270d79669200ef485add1ecc1833cc94" category="paragraph">À titre d'exemple de référence, un simple système AFF A800 HA à deux nœuds est capable de traiter jusqu'à un million d'IOPS aléatoires avant que la latence ne dépasse la milliseconde. On pourrait s'attendre à ce que très peu de charges de travail atteignent de tels niveaux. L'utilisation optimale de cette baie AFF A800 implique l'hébergement de plusieurs workloads. Pour ce faire, la sécurité et la prévisibilité exigent des contrôles de QoS.</block>
  <block id="4dca0c3547523a2e5bd1b8d0e2ff8de5" category="paragraph">Il existe deux types de qualité de service (QoS) dans ONTAP : les IOPS et la bande passante. Les contrôles de QoS peuvent être appliqués aux SVM, volumes, LUN et fichiers.</block>
  <block id="3ea539ed2021ba46a3658039e8af419f" category="paragraph">Un contrôle de la QoS pour les IOPS est évidemment basé sur l'ensemble des IOPS d'une ressource donnée, mais il existe un certain nombre d'aspects de la QoS pour les IOPS qui peuvent ne pas être intuitifs. Au départ, quelques clients ont été surpris par l'augmentation apparente de la latence lorsqu'un seuil d'IOPS est atteint. L'augmentation de la latence est la conséquence naturelle de la limitation des IOPS. Logiquement, il fonctionne de la même manière qu'un système de jetons. Par exemple, si un volume donné contenant des fichiers de données dispose d'une limite de 10 000 IOPS, chaque E/S arrivant doit d'abord recevoir un jeton pour poursuivre le traitement. Tant que plus de 10 000 jetons n'ont pas été consommés en une seconde donnée, aucun retard n'est présent. Si les opérations d'E/S doivent attendre la réception de leur jeton, cet attente apparaît comme une latence supplémentaire. Plus une charge de travail est élevée, plus les E/S sont longues à attendre dans la file d'attente pour le traitement de son tour, ce qui apparaît comme une latence plus élevée.</block>
  <block id="34a96885dd7f4501920b13026e7f2cab" category="admonition">Soyez prudent lorsque vous appliquez des contrôles QoS aux données des transactions de base de données/journaux de reprise. Alors que les demandes de performances liées à la journalisation de reprise sont généralement très élevées, bien inférieures à celles des fichiers de données, l'activité du journal de reprise est en rafales. L'E/S se produit en de brèves impulsions et une limite de QoS qui semble appropriée pour les niveaux d'E/S de reprise moyens peut être trop basse pour les exigences réelles. Cela peut entraîner de strictes limitations de performance en cas d'engagement de la QoS avec chaque pic de journal de reprise. En général, la journalisation des opérations de reprise et d'archivage ne doit pas être limitée par la QoS.</block>
  <block id="c79dc76371299e08f4b4ebd609314ca4" category="section-title">QoS de la bande passante</block>
  <block id="b9d5c520039715de9b997c5a69f4aeaa" category="paragraph">Toutes les tailles d'E/S ne sont pas identiques. Par exemple, une base de données peut effectuer de nombreuses lectures de blocs de petite taille, ce qui entraînerait l'atteinte du seuil d'IOPS, mais il est également possible que les bases de données effectuent une analyse de table complète comprenant un très petit nombre de lectures de blocs volumineux, qui consomment une très grande quantité de bande passante, mais relativement peu d'IOPS.</block>
  <block id="4930ae83bb8dd5e539dc9f7e73c6d74c" category="paragraph">De même, un environnement VMware peut générer un nombre très élevé d'IOPS aléatoires au démarrage, mais exécuter moins d'E/S, mais plus importantes, lors d'une sauvegarde externe.</block>
  <block id="eabb5a523a77d4521c12622ee9388aa6" category="paragraph">Pour gérer efficacement les performances, les IOPS ou la bande passante doivent parfois être limitées, voire les deux.</block>
  <block id="13dac55a5f26cefab26368ea5a67e29f" category="section-title">QoS minimale/garantie</block>
  <block id="68559688130772c84bb39b2a9ca2c2af" category="paragraph">De nombreux clients recherchent une solution incluant une QoS garantie, qui semble plus difficile à atteindre qu'elle ne le paraît et qui risque d'être très gaspillée. Par exemple, pour placer 10 bases de données avec une garantie de 10 000 IOPS, il est nécessaire de dimensionner un système dans le cas où les 10 bases de données s'exécutent simultanément à 10 000 IOPS, pour un total de 100 000.</block>
  <block id="c0938f706c890ea85c86388391ffad22" category="paragraph">La meilleure utilisation pour les contrôles QoS minimaux est de protéger les charges de travail stratégiques. Prenons l'exemple d'un contrôleur ONTAP avec un maximum de 500 000 IOPS et un mélange de charges de travail de production et de développement. Vous devez appliquer des règles de QoS maximales aux workloads de développement pour empêcher toute base de données de monopoliser le contrôleur. Vous appliqueriez ensuite des règles de QoS minimales aux charges de travail de production afin de vous assurer que les IOPS requises sont toujours disponibles, le cas échéant.</block>
  <block id="acdda1c20fb3985ce840929f7525c803" category="section-title">La QoS adaptative</block>
  <block id="dd5bc58ed6ab031b170a409470d9a763" category="paragraph">La QoS adaptative fait référence à la fonctionnalité ONTAP où la limite de QoS repose sur la capacité de l'objet de stockage. Elle est rarement utilisée avec les bases de données, car il n'existe généralement aucun lien entre la taille d'une base de données et ses exigences de performances. Les grandes bases de données peuvent être quasiment inertes, tandis que les bases de données plus petites peuvent être celles qui nécessitent le plus d'IOPS.</block>
  <block id="eb595833577352045f92d14ac4315ad2" category="paragraph">La QoS adaptative peut s'avérer très utile avec les datastores de virtualisation, car les exigences en IOPS de ces jeux de données ont tendance à être corrélées à la taille totale de la base de données. Un datastore plus récent contenant 1 To de fichiers VMDK devrait avoir besoin d'environ la moitié des performances pour un datastore de 2 To. La QoS adaptative vous permet d'augmenter automatiquement les limites de qualité de service lorsque le datastore est rempli de données.</block>
  <block id="23f3d415bb4fe6f99165df604b24da0e" category="paragraph">Le Tiering d'un dataset avec FabricPool entraîne une dépendance entre la baie de stockage primaire et le Tier de magasin d'objets. De nombreuses options de stockage objet offrent différents niveaux de disponibilité. Il est important de comprendre l'impact d'une éventuelle perte de connectivité entre la baie de stockage primaire et le niveau de stockage objet.</block>
  <block id="7e856c11a853d276fd5d6274bf60fafd" category="paragraph">Si une E/S émise par ONTAP nécessite des données du niveau de capacité et que les ONTAP ne peuvent pas atteindre le niveau de capacité pour récupérer des blocs, les E/S finissent par être sorties. L'effet de ce délai dépend du protocole utilisé. Dans un environnement NFS, ONTAP répond par une réponse EJUKEBOX ou EDELAY, selon le protocole. Certains systèmes d'exploitation plus anciens peuvent interpréter cela comme une erreur, mais les systèmes d'exploitation actuels et les niveaux de correctifs actuels du client Oracle Direct NFS traitent cette erreur comme une nouvelle tentative et continuent d'attendre la fin des E/S.</block>
  <block id="207d9fe0f57910936bfa043248f3afca" category="paragraph">Un délai plus court s'applique aux environnements SAN. Si un bloc de l'environnement de magasin d'objets est requis et reste inaccessible pendant deux minutes, une erreur de lecture est renvoyée à l'hôte. Le volume ONTAP et les LUN restent en ligne, mais le système d'exploitation hôte peut signaler le système de fichiers comme étant dans un état d'erreur.</block>
  <block id="c9251835da8df507ca4f6ce02d4216be" category="paragraph">Les problèmes de connectivité du stockage objet<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> la politique est moins préoccupante, car seules les données de sauvegarde sont hiérarchisées. Les problèmes de communication ralentiraient la récupération des données, mais n'affecteraient pas les données utilisées activement. Le<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> et<block ref="a181a603769c1f98ad927e7367c7aa51" prefix=" " category="inline-code"></block> Les règles permettent le Tiering des données inactives de la LUN active, ce qui signifie qu'une erreur lors de la récupération des données du magasin d'objets peut affecter la disponibilité de la base de données. Un déploiement SAN doté de ces règles doit uniquement être utilisé avec un stockage objet de grande qualité et des connexions réseau conçues pour une haute disponibilité. NetApp StorageGRID est la meilleure option.</block>
  <block id="0f8062f9220efe4f38e7236fe8885379" category="paragraph">La plupart des bases de données relationnelles opèrent en mode d'archivage du journal de transactions pour assurer une restauration instantanée. Les modifications apportées aux bases de données sont validées en enregistrant les modifications dans les journaux de transactions et le journal de transactions est conservé sans être écrasé. Il peut donc s'avérer nécessaire de conserver un énorme volume de journaux de transactions archivés. De nombreux autres workflows applicatifs génèrent des données qui doivent être conservées, mais il est très peu probable qu'elles soient accessibles.</block>
  <block id="229384bbfb1db19c4897d87ba4b9bc2d" category="paragraph">Pour résoudre ces problèmes, FabricPool propose une solution unique avec hiérarchisation intégrée. Les fichiers sont stockés et restent accessibles à leur emplacement habituel, mais ne prennent pratiquement pas d'espace sur la baie principale.</block>
  <block id="f60aec7aaed8420e09f17a8cfd1d7d37" category="paragraph">Utiliser un<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> la règle de quelques jours permet de conserver les blocs dans les fichiers récemment créés (les fichiers les plus susceptibles d'être requis à court terme) sur le niveau de performance. Les blocs de données des anciens fichiers sont ensuite déplacés vers le niveau de capacité.</block>
  <block id="485e24df9e0ebeecf416daa6e5441bba" category="paragraph">Le<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> applique la hiérarchisation des invites lorsque le seuil de refroidissement a été atteint, que les journaux aient été supprimés ou qu'ils continuent d'exister dans le système de fichiers principal. Le stockage de tous les journaux potentiellement requis dans un seul emplacement du système de fichiers actif simplifie également la gestion. Il n'y a aucune raison de rechercher un fichier à restaurer à l'aide de snapshots.</block>
  <block id="bbe0132696bc482e0ba7a1f293d80083" category="paragraph">Certaines applications, telles que Microsoft SQL Server, tronquent les fichiers journaux de transactions pendant les opérations de sauvegarde afin que les journaux ne soient plus dans le système de fichiers actif. Il est possible d'économiser de la capacité à l'aide de<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> la règle de tiering, mais la règle<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> la règle n'est pas utile pour les données de journal car il devrait rarement y avoir des données de journal refroidies dans le système de fichiers actif.</block>
  <block id="0694b4972669f201ca85f9427a230208" category="doc">MetroCluster est disponible dans 3 configurations différentes</block>
  <block id="948676ffa8073153cbe404795950ad85" category="list-text">Paires HAUTE DISPONIBILITÉ avec connectivité IP</block>
  <block id="ef012b81fd45a95681a584a59f8df77e" category="list-text">Paires HAUTE DISPONIBILITÉ avec connectivité FC</block>
  <block id="6ffec869ba36dff4e093b5ed8bac798a" category="list-text">Contrôleur unique avec connectivité FC</block>
  <block id="6fa7041982bed9488213a7bd2ecccfdf" category="paragraph">[REMARQUE]le terme « connectivité » fait référence à la connexion en cluster utilisée pour la réplication entre sites. Il ne fait pas référence aux protocoles hôtes. Tous les protocoles côté hôte sont pris en charge comme d'habitude dans une configuration MetroCluster, quel que soit le type de connexion utilisé pour les communications entre clusters.</block>
  <block id="4767099b22895a8101a1cba45d8cf6e9" category="section-title">IP MetroCluster</block>
  <block id="adc397d87c1a7827f2df9fdd362d5ff7" category="paragraph">La configuration IP MetroCluster à paire haute disponibilité utilise deux ou quatre nœuds par site. Cette option de configuration augmente la complexité et les coûts liés à l'option à deux nœuds, mais elle offre un avantage important : la redondance intrasite. Une simple panne de contrôleur ne nécessite pas l'accès aux données via le WAN. L'accès aux données reste local via l'autre contrôleur local.</block>
  <block id="c15560f2ae5432223c591c5f5d9db5c1" category="paragraph">La plupart des clients choisissent la connectivité IP, car les exigences d'infrastructure sont plus simples. Auparavant, la connectivité inter-sites à haut débit était généralement plus facile à provisionner avec des commutateurs FC et fibre noire. Cependant, les circuits IP à haut débit et à faible latence sont aujourd'hui plus facilement disponibles.</block>
  <block id="b28c5a429800ea9669a191a402a72b49" category="paragraph">L'architecture est également plus simple, car les contrôleurs disposent des seules connexions entre les sites. Dans les MetroCluster FC, un contrôleur écrit directement sur les disques du site opposé et requiert ainsi des connexions SAN, des commutateurs et des ponts supplémentaires. En revanche, un contrôleur dans une configuration IP écrit sur les lecteurs opposés via le contrôleur.</block>
  <block id="457b0075e8f0333975a8e2aaeaceb149" category="inline-link">Architecture et conception de la solution IP de MetroCluster</block>
  <block id="82aa44c8aa5ebe78f1496c8fc80cb954" category="paragraph">Pour plus d'informations, consultez la documentation officielle de ONTAP et<block ref="03a3c76178d2d43147a2756857a0985e" category="inline-link-rx"></block>.</block>
  <block id="68cf128ce140240c63e9a47e2a82a333" category="paragraph"><block ref="68cf128ce140240c63e9a47e2a82a333" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0d2d438a72f6c558744351265fa49a62" category="section-title">MetroCluster FC à connexion SAN HA-pair</block>
  <block id="3e9133ff590581b29a911d9631ab1737" category="paragraph">La configuration MetroCluster FC à paire haute disponibilité utilise deux ou quatre nœuds par site. Cette option de configuration augmente la complexité et les coûts liés à l'option à deux nœuds, mais elle offre un avantage important : la redondance intrasite. Une simple panne de contrôleur ne nécessite pas l'accès aux données via le WAN. L'accès aux données reste local via l'autre contrôleur local.</block>
  <block id="7ea740801794ba8a2ce3f87db010c319" category="paragraph"><block ref="7ea740801794ba8a2ce3f87db010c319" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4bc2926f030255369db3e4435de5c774" category="paragraph">Certaines infrastructures multisites ne sont pas conçues pour les opérations en mode actif-actif. Elles sont plutôt utilisées comme site principal et site de reprise après incident. Dans ce cas, il est généralement préférable d'utiliser une option MetroCluster à paire HA pour les raisons suivantes :</block>
  <block id="5f49f48dd22b405a813e2ef7cc02e9f8" category="list-text">Bien qu'un cluster MetroCluster à deux nœuds soit un système haute disponibilité, toute panne inattendue d'un contrôleur ou une maintenance planifiée implique que les services de données soient en ligne sur le site opposé. Si la connectivité réseau entre les sites ne prend pas en charge la bande passante requise, les performances sont affectées. La seule option serait également de basculer les différents systèmes d'exploitation hôtes et les services associés vers le site secondaire. Le cluster MetroCluster de paire haute disponibilité élimine ce problème, car la perte d'un contrôleur simplifie le basculement au sein du même site.</block>
  <block id="0ce798a4f2e77d6aa1a6e0d718fa8e98" category="list-text">Certaines topologies réseau ne sont pas conçues pour l'accès intersite, mais utilisent des sous-réseaux différents ou des SAN FC isolés. Dans ce cas, le cluster MetroCluster à deux nœuds ne fonctionne plus comme un système haute disponibilité, car le contrôleur secondaire ne peut plus transmettre de données aux serveurs sur le site opposé. L'option MetroCluster de paire haute disponibilité est nécessaire pour assurer une redondance complète.</block>
  <block id="098fa44ef37572e0f8ea717199ac72e6" category="list-text">Si une infrastructure à deux sites est considérée comme une seule infrastructure extrêmement disponible, la configuration MetroCluster à deux nœuds est adaptée. Toutefois, si le système doit fonctionner pendant une période prolongée après une panne sur le site, une paire haute disponibilité est recommandée, car la haute disponibilité continue d'être disponible sur un seul site.</block>
  <block id="ea8bb3e5a357ca97851352f6944342c9" category="section-title">MetroCluster FC à deux nœuds avec connexion SAN</block>
  <block id="b759079fef92c80eca80e7349bf84363" category="paragraph">La configuration MetroCluster à deux nœuds n'utilise qu'un nœud par site. Cette conception est plus simple que l'option de paire haute disponibilité, car le nombre de composants à configurer et à gérer est inférieur. Elle a également réduit les besoins en infrastructure en termes de câblage et de commutation FC. Enfin, il réduit les coûts.</block>
  <block id="5bfcbf762ac959212294cdf71bbec2b5" category="paragraph"><block ref="5bfcbf762ac959212294cdf71bbec2b5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bcf549481eb36a62594e938bca6a10bb" category="paragraph">L'impact évident de cette conception est que la défaillance du contrôleur sur un seul site signifie que les données sont disponibles depuis le site opposé. Cette restriction n'est pas nécessairement un problème. De nombreuses entreprises disposent d'opérations de data Center multisites avec des réseaux étendus, ultra-rapides et à faible latence qui fonctionnent essentiellement comme une infrastructure unique. Dans ce cas, la version à deux nœuds de MetroCluster est la configuration préférée. Plusieurs fournisseurs de services utilisent actuellement des systèmes à deux nœuds de plusieurs pétaoctets.</block>
  <block id="78558542e724655ba80fc4879399f103" category="section-title">Fonctions de résilience MetroCluster</block>
  <block id="5427d2eb91f25a425f13544e56fb12c4" category="paragraph">Une solution MetroCluster ne présente aucun point de défaillance unique :</block>
  <block id="6a988bf07e73bcbf69f62ce9724dd0f3" category="list-text">Chaque contrôleur dispose de deux chemins d'accès indépendants aux tiroirs disques sur le site local.</block>
  <block id="2c98a75e02c6e103b43724f02e99e393" category="list-text">Chaque contrôleur dispose de deux chemins d'accès indépendants aux tiroirs disques du site distant.</block>
  <block id="e18f703538cd1f5af3b9185eed57b49b" category="list-text">Chaque contrôleur dispose de deux chemins d'accès indépendants aux contrôleurs sur le site opposé.</block>
  <block id="800ec0ea85a62c2fb192ac2f79ee1d02" category="list-text">Dans la configuration HA-pair, chaque contrôleur dispose de deux chemins vers son partenaire local.</block>
  <block id="a3d7a569ad6ea771a0ad9b995619251b" category="paragraph">En résumé, n'importe quel composant de la configuration peut être supprimé sans compromettre la capacité de MetroCluster à transmettre des données. La seule différence en termes de résilience entre les deux options est que la version à paire haute disponibilité reste un système de stockage haute disponibilité global après une panne de site.</block>
  <block id="9b4c3976d453e66a3dd22e2793fc3a8e" category="doc">Gestion de l'espace</block>
  <block id="e89d3732a2fbc592923c30e54522dcdb" category="paragraph">Le provisionnement fin, de nombreuses formes, fait partie intégrante de nombreuses fonctionnalités offertes par ONTAP à l'environnement applicatif d'entreprise. Le provisionnement fin est également étroitement lié aux technologies d'efficacité pour la même raison : les fonctionnalités d'efficacité permettent de stocker davantage de données logiques que ce qui existe techniquement sur le système de stockage.</block>
  <block id="537642ed3bfef7f2bb3e580b3b266bd3" category="paragraph">La plupart des snapshots impliquent un provisionnement fin. Par exemple, une base de données classique de 10 To sur un système de stockage NetApp compte environ 30 jours de copies Snapshot. Cet arrangement donne lieu à environ 10 To de données visibles dans le système de fichiers actif et 300 To dédiés aux snapshots. La capacité totale de stockage de 310 To réside généralement dans un espace d'environ 12 To à 15 To. La base de données active consomme 10 To et les 300 To de données restantes ne nécessitent que 2 à 5 To d'espace, car seules les modifications apportées aux données d'origine sont stockées.</block>
  <block id="a19609016ad1cb6b7bae7cac796a26a4" category="paragraph">Le clonage est également un exemple de provisionnement fin. Un client NetApp majeur a créé 40 clones d'une base de données de 80 To à utiliser pour le développement. Si les 40 développeurs qui utilisent ces clones surécrivent chaque bloc dans chaque fichier de données, plus de 3,2 po de stockage seraient nécessaires. En pratique, le chiffre d'affaires est faible et l'espace collectif requis est proche de 40 To, car seules les modifications sont stockées sur les disques.</block>
  <block id="2433af6347e4871be5af0f2af0f6bd6e" category="paragraph">Le provisionnement fin d'un environnement applicatif doit être extrêmement prudent, car les taux de modification des données peuvent augmenter de manière inattendue. Par exemple, la consommation d'espace due aux snapshots peut augmenter rapidement si les tables de base de données sont réindexées ou si des correctifs à grande échelle sont appliqués aux invités VMware. Une sauvegarde mal placée peut écrire une grande quantité de données dans un délai très court. Enfin, il peut être difficile de restaurer certaines applications si un système de fichiers manque d'espace de façon inattendue.</block>
  <block id="5cf4dc4d1ce52ff655ea7f1157a72e2e" category="paragraph">Avec une configuration soigneuse de, ces risques peuvent être maîtrisés<block ref="f9e1f2ea1a2becbaf82dd54e55a12e6b" prefix=" " category="inline-code"></block> et<block ref="24d554277b3513bb6cef3f0a336725a9" prefix=" " category="inline-code"></block> règles. Comme leurs noms l'indiquent, ces options permettent de créer des règles qui effacent automatiquement l'espace consommé par les snapshots ou augmentent un volume pour prendre en charge des données supplémentaires. De nombreuses options sont disponibles et les besoins varient selon les clients.</block>
  <block id="6a28738961e6f6e4b57e4dd70c446600" category="inline-link-macro">documentation sur la gestion du stockage logique</block>
  <block id="01570cb5a3aec2324ab56e318e1de04d" category="paragraph">Voir la <block ref="e69bd75bdb49183ee90588843edb33f4" category="inline-link-macro-rx"></block> pour une discussion complète de ces fonctionnalités.</block>
  <block id="8cf44a7a390ab582c5010ba430143d4b" category="section-title">Provisionnement fin des LUN</block>
  <block id="ba0bdf51bc57bacdd6f3f0bd26b7674c" category="paragraph">L'efficacité du provisionnement fin des LUN actives dans un environnement de système de fichiers peut être perdue au fil du temps suite à la suppression des données. À moins que les données supprimées ne soient remplacées par des zéros ou que l'espace ne soit libéré par la récupération d'espace TRIM/UNMAP, les données « effacées » occupent de plus en plus d'espace non alloué dans le système de fichiers. En outre, l'utilisation du provisionnement fin des LUN actives est limitée dans de nombreux environnements de base de données, car les fichiers de données sont initialisés sur leur taille complète au moment de la création.</block>
  <block id="e10d46632bc86306cf4c22633ee930ab" category="paragraph">Une planification minutieuse de la configuration de LVM peut améliorer l'efficacité et réduire les besoins en provisionnement du stockage et en redimensionnement des LUN. Lorsqu'un LVM tel que Veritas VxVM ou Oracle ASM est utilisé, les LUN sous-jacentes sont divisés en extensions qui ne sont utilisées que lorsque cela est nécessaire. Par exemple, si un dataset commence à 2 To mais peut atteindre 10 To au fil du temps, ce dataset peut être placé sur 10 To de LUN à provisionnement fin organisées dans un groupe de disques LVM. Elle occupant seulement 2 To d'espace au moment de la création et réclarait uniquement de l'espace supplémentaire, dans la mesure où les extensions sont allouées pour prendre en charge la croissance du volume des données. Ce processus est sûr tant que l'espace est surveillé.</block>
  <block id="66a41fd6fc38c454973e91d92cf0e291" category="section-title">Réservations fractionnaires</block>
  <block id="e8a206fe65814e0ea465e32487544751" category="paragraph">La réserve fractionnaire fait référence au comportement d'une LUN dans un volume en ce qui concerne l'efficacité de l'espace. Lorsque l'option<block ref="c1acac5c4332e37ec1f281fcbaf0765a" prefix=" " category="inline-code"></block> est défini sur 100 %. toutes les données du volume peuvent connaître un taux de rotation de 100 % avec n'importe quel modèle de données, sans épuiser l'espace sur le volume.</block>
  <block id="a3cd28aef7d0becd57b60187fdc4a24e" category="paragraph">Par exemple, prenons l'exemple d'une base de données située sur une seule LUN de 250 Go dans un volume de 1 To. La création d'un snapshot entraînerait immédiatement la réservation d'un espace supplémentaire de 250 Go dans le volume, garantissant ainsi que l'espace disponible sur le volume ne serait pas insuffisant pour quelque raison que ce soit. L'utilisation de réserves fractionnaires est généralement inutile car il est très peu probable que chaque octet du volume de base de données ait besoin d'être écrasé. Il n'y a aucune raison de réserver de l'espace pour un événement qui ne se produit jamais. Cependant, si un client ne peut pas surveiller la consommation d'espace dans un système de stockage et doit être certain que l'espace ne sera jamais épuisé, des réservations fractionnaires de 100 % seront nécessaires pour utiliser les snapshots.</block>
  <block id="e30fbe8981929fb070a820a213381bab" category="section-title">Compression et déduplication</block>
  <block id="1b6e4e9a2be031edc6f3da1f559ef884" category="paragraph">La compression et la déduplication sont deux formes de provisionnement fin. Par exemple, une empreinte des données de 50 To peut être compressée jusqu'à 30 To, ce qui permet d'économiser 20 To. Pour que la compression offre tous les avantages, il faut utiliser quelques 20 To pour d'autres données ou acheter le système de stockage avec moins de 50 To. Il en résulte une quantité de données stockées supérieure à ce qui n'est techniquement disponible sur le système de stockage. Du point de vue des données, il y a 50 To de données, même si celles-ci ne occupent que 30 To sur les disques.</block>
  <block id="dbca4bb791f36eac2c11c32f73f2b4ec" category="paragraph">Il est toujours possible que la compressibilité d'un dataset change, ce qui entraîne une consommation accrue de l'espace réel. Cette augmentation de la consommation signifie que la compression doit être gérée comme avec les autres formes de provisionnement fin en termes de surveillance et d'utilisation<block ref="f9e1f2ea1a2becbaf82dd54e55a12e6b" prefix=" " category="inline-code"></block> et<block ref="24d554277b3513bb6cef3f0a336725a9" prefix=" " category="inline-code"></block>.</block>
  <block id="ad241666a88b5414e8c2fe6d1cc1edb0" category="paragraph">La compression et la déduplication sont présentées plus en détail dans la section link:efficiency.html</block>
  <block id="8ecfcadfebb472a089481e8554ebed87" category="section-title">Compression et réservations fractionnaires</block>
  <block id="4f8fcc146d2e8e712dcd8c56b1684fcc" category="paragraph">La compression est une forme d'allocation dynamique. Les réservations fractionnaires affectent l'utilisation de la compression, avec une remarque importante ; l'espace est réservé avant la création du snapshot. Normalement, la réserve fractionnaire n'est importante que si un instantané existe. S'il n'y a pas de snapshot, la réserve fractionnaire n'est pas importante. Ce n'est pas le cas avec la compression. Si une LUN est créée sur un volume avec compression, ONTAP conserve l'espace nécessaire pour prendre en charge un snapshot. Ce comportement peut être déroutant pendant la configuration, mais il est normal.</block>
  <block id="e26f8048b4bf60dad827c5a425271361" category="paragraph">Prenons l'exemple d'un volume de 10 Go avec une LUN de 5 Go compressée à 2,5 Go sans copie Snapshot. Prenez en compte ces deux scénarios :</block>
  <block id="ade18971a2dab7e37335e95d81da0ef1" category="list-text">La réserve fractionnaire = 100 entraîne une utilisation de 7,5 Go</block>
  <block id="1d07b8e7c92488a55301ea201328cf35" category="list-text">La réserve fractionnaire = 0 entraîne une utilisation de 2,5 Go</block>
  <block id="aa410d0e46ec94b6efcf344f0d870c1a" category="paragraph">Le premier scénario comprend 2,5 Go de consommation d'espace pour les données actuelles et 5 Go d'espace pour représenter 100 % de chiffre d'affaires de la source en prévision de l'utilisation des snapshots. Le deuxième scénario ne réserve pas d'espace supplémentaire.</block>
  <block id="e79414ad391b126cc9bd53af1624c8de" category="paragraph">Bien que cette situation puisse sembler confuse, il est peu probable qu'elle soit rencontrée dans la pratique. La compression implique un provisionnement fin et le provisionnement fin dans un environnement LUN nécessite des réservations fractionnaires. Il est toujours possible d'écraser des données compressées par un élément non compressible, ce qui signifie qu'un volume doit être à provisionnement fin pour la compression, pour réaliser des économies.</block>
  <block id="499a10b92cb9ca6b3412d4bf5a91a2b0" category="paragraph">*NetApp recommande* les configurations de réserve suivantes :</block>
  <block id="7f26e875cee50c1b3baf71a014043794" category="list-text">Réglez<block ref="c1acac5c4332e37ec1f281fcbaf0765a" prefix=" " category="inline-code"></block> à 0 lorsque la surveillance de la capacité de base est en place avec<block ref="f9e1f2ea1a2becbaf82dd54e55a12e6b" prefix=" " category="inline-code"></block> et<block ref="24d554277b3513bb6cef3f0a336725a9" prefix=" " category="inline-code"></block>.</block>
  <block id="675996bd34ec0d8c134215f5be73fb3a" category="list-text">Réglez<block ref="c1acac5c4332e37ec1f281fcbaf0765a" prefix=" " category="inline-code"></block> à 100 s'il n'y a pas de capacité de surveillance ou s'il est impossible d'évacuer l'espace en quelque circonstance que ce soit.</block>
  <block id="8ee38535add58992c14b23a6f7cf8d27" category="doc">Types de LIF</block>
  <block id="50d034374ef68094a0f6c8e8d06a77af" category="inline-link-macro">Documentation de gestion de réseau ONTAP</block>
  <block id="fc25025f3f0a2afd42465a55f35c02d0" category="paragraph">Cette section présente les principes clés de conception des LIF. Pour obtenir une documentation plus complète, reportez-vous au <block ref="a3e6361e1a52d384f542a2f2d8bc9bb1" category="inline-link-macro-rx"></block>. Comme pour les autres aspects de l'architecture de la base de données, les meilleures options pour la conception des machines virtuelles de stockage (SVM, appelé SVM au niveau de l'interface de ligne de commande) et de l'interface logique (LIF) dépendent largement des besoins en termes d'évolutivité et des besoins de l'entreprise.</block>
  <block id="be0801f7fb241be642bec73b799d45cb" category="paragraph">Tenez compte des principaux sujets suivants lors de l'élaboration d'une stratégie LIF :</block>
  <block id="362c2978dddcf6988ce266d3d60f5beb" category="list-text">*Performances.* la bande passante du réseau est-elle suffisante ?</block>
  <block id="cfc88efb72b2c7ea83a4a3d68b760d55" category="list-text">*Résilience.* y a-t-il des points de défaillance uniques dans la conception?</block>
  <block id="af02972fd4dc1e949d800731d9518812" category="list-text">*Gérabilité.* le réseau peut-il être mis à l'échelle sans interruption ?</block>
  <block id="fdcbadc80d2dd31527cc91cf81fb725d" category="paragraph">Ces rubriques s'appliquent à la solution de bout en bout, de l'hôte aux commutateurs et au système de stockage.</block>
  <block id="f45fe079103703d0b315ff2e339728fd" category="inline-link-macro">Documentation ONTAP sur les types de LIF</block>
  <block id="cc4583278db25277db9ddcd781cbf992" category="paragraph">Il existe plusieurs types de LIF. <block ref="9d27879d9d2bd4f0f081ffed63159522" category="inline-link-macro-rx"></block> Fournir des informations plus complètes à ce sujet, mais d'un point de vue fonctionnel, les LIF peuvent être divisées en plusieurs groupes :</block>
  <block id="f34a52d788c5a4cf56d7ae8ccb85f8c2" category="list-text">*LIFs de gestion de clusters et de nœuds.* utilisées pour gérer le cluster de stockage.</block>
  <block id="73ac4e00a9ff3caf31e6df13a6df2f78" category="list-text">*LIF de gestion SVM.* interfaces permettant l'accès à une SVM via l'API REST ou ONTAPI (aussi connue sous le nom de ZAPI) pour des fonctions telles que la création de snapshots ou le redimensionnement de volumes. Des produits tels que SnapManager pour Oracle (SMO) doivent avoir accès à une LIF de gestion SVM.</block>
  <block id="b7010e46f4769f638197aa230f448ba0" category="list-text">*Interfaces de données LIF.* pour FC, iSCSI, NVMe/FC, NVMe/TCP, NFS, ou SMB/CIFS.</block>
  <block id="1eb4f53fa8ee8f0954514a1b9858bf6b" category="admonition">Une LIF de données utilisée pour le trafic NFS peut également être utilisée à des fins de gestion en modifiant la politique de pare-feu de<block ref="8d777f385d3dfec8815d20f7496026dc" prefix=" " category="inline-code"></block> à<block ref="d724f231a9a7b89757c4394d6622bc47" prefix=" " category="inline-code"></block> Ou une autre règle autorisant HTTP, HTTPS ou SSH. Ce changement peut simplifier la configuration du réseau en évitant la configuration de chaque hôte pour l'accès à la fois à la LIF de données NFS et à une LIF de gestion distincte. Il n'est pas possible de configurer une interface pour l'iSCSI et le trafic de gestion, bien que les deux utilisent un protocole IP. Une LIF de gestion distincte est requise dans les environnements iSCSI.</block>
  <block id="85d465743ad38be108b50648ab283d78" category="section-title">Conception de SAN LIF</block>
  <block id="8800a54085e1b2987d83537423221cf9" category="paragraph">La conception de LIF dans un environnement SAN est relativement simple pour une raison : les chemins d'accès multiples. Toutes les implémentations SAN modernes permettent à un client d'accéder aux données sur plusieurs chemins réseau indépendants et de sélectionner le ou les chemins d'accès les plus adaptés. Par conséquent, les performances du design LIF sont plus simples à gérer, car les clients SAN équilibrent automatiquement la charge en E/S sur les meilleurs chemins disponibles.</block>
  <block id="e33c923a4d6280bf6f2b2a982ff74ee3" category="paragraph">Si un chemin devient indisponible, le client sélectionne automatiquement un autre chemin. La simplicité de conception qui en résulte rend les LIF SAN généralement plus faciles à gérer. Cela ne signifie pas pour autant qu'un environnement SAN est toujours plus facile à gérer, car de nombreux autres aspects du stockage SAN sont bien plus complexes que NFS. Cela signifie simplement que la conception de la LIF SAN est plus facile.</block>
  <block id="9446a98ad14416153cc4d45ab8b531bf" category="section-title">Performance</block>
  <block id="141614e246b14131ec01a449d61ed657" category="paragraph">La bande passante est l'élément le plus important à prendre en compte dans les performances de LIF dans un environnement SAN. Par exemple, un cluster ONTAP AFF à deux nœuds doté de deux ports FC 16 Gb par nœud permet d'obtenir jusqu'à 32 Go de bande passante vers/depuis chaque nœud.</block>
  <block id="02bc0523497de72834c4c7990e32d155" category="section-title">Résilience</block>
  <block id="01b1d8276ca14813ff4804089a9ac082" category="paragraph">Les LIF SAN ne basculent pas sur un système de stockage AFF. Si une LIF SAN échoue en raison du basculement du contrôleur, le logiciel de chemins d'accès multiples du client détecte la perte d'un chemin et redirige les E/S vers une autre LIF. Avec les systèmes de stockage ASA, les LIF basculent après un court délai, mais cela n'interrompt pas les E/S, car il existe déjà des chemins actifs sur l'autre contrôleur. Le processus de basculement a lieu afin de restaurer l'accès de l'hôte sur tous les ports définis.</block>
  <block id="b7c94ef25c0629a65f8a1f6ce7014d95" category="section-title">Gestion aisée</block>
  <block id="1325935a6fa0e88cfec45038005f18e3" category="paragraph">La migration des LIF est une tâche beaucoup plus courante dans un environnement NFS, car elle est souvent associée au déplacement des volumes au sein du cluster. Il n'est pas nécessaire de migrer une LIF dans un environnement SAN lorsque les volumes sont déplacés au sein de la paire HA. En effet, une fois le déplacement de volume terminé, ONTAP envoie une notification au SAN concernant un changement de chemins et les clients SAN se réoptimisent automatiquement. La migration de LIF avec SAN est principalement associée à des modifications matérielles physiques majeures. Par exemple, si une mise à niveau des contrôleurs sans interruption est requise, une LIF SAN est migrée vers le nouveau matériel. Si un port FC est défectueux, une LIF peut être migrée vers un port non utilisé.</block>
  <block id="dbb887b1373e51dab774976c5a556964" category="section-title">Recommandations de conception</block>
  <block id="076872b2444637e6142c3c6f0f157423" category="paragraph">NetApp fait les recommandations suivantes :</block>
  <block id="d8d6bca7c981c13479781da85883cfef" category="list-text">Ne créez pas plus de chemins que nécessaire. Un nombre excessif de chemins complique la gestion globale et peut entraîner des problèmes de basculement de chemin sur certains hôtes. De plus, certains hôtes ont des limites de chemin inattendues pour les configurations comme le démarrage SAN.</block>
  <block id="bd662d86fcca370cddf188ff5378fb1b" category="list-text">Très peu de configurations doivent nécessiter plus de quatre chemins vers une LUN. L'intérêt d'avoir plus de deux nœuds de chemins publicitaires vers les LUN est limité, car l'agrégat hébergeant une LUN est inaccessible en cas de défaillance du nœud qui détient la LUN et de son partenaire haute disponibilité. Dans ce cas, la création de chemins sur des nœuds autres que la paire haute disponibilité principale n'est pas utile.</block>
  <block id="8873f044ab7c082f16372e4b8bdc6e03" category="list-text">Même si vous pouvez gérer le nombre de chemins de LUN visibles en sélectionnant les ports inclus dans les zones FC, il est généralement plus facile d'inclure tous les points cibles potentiels dans la zone FC et de contrôler la visibilité des LUN au niveau des ONTAP.</block>
  <block id="0ebc6267761306c4daefb9871a470e4b" category="list-text">Dans ONTAP 8.3 et versions ultérieures, la fonction de mappage de LUN sélectif (SLM) est la fonction par défaut. Avec SLM, toute nouvelle LUN est automatiquement annoncée à partir du nœud qui possède l'agrégat sous-jacent et du partenaire HA du nœud. Cet arrangement évite de créer des ensembles de ports ou de configurer le zoning pour limiter l'accessibilité des ports. Chaque LUN est disponible sur le nombre minimal de nœuds requis pour des performances et une résilience optimales.
*Dans le cas où un LUN doit être migré en dehors des deux contrôleurs, les nœuds supplémentaires peuvent être ajoutés avec le<block ref="02d0bbdc14988c85bbd7994723f4dd7f" prefix=" " category="inline-code"></block> De sorte que les LUN soient annoncées sur les nouveaux nœuds. Vous créez ainsi des chemins SAN supplémentaires vers les LUN pour la migration des LUN. Toutefois, l'hôte doit effectuer une opération de découverte pour utiliser les nouveaux chemins.</block>
  <block id="cc4b24f288afae5889c6061466dda472" category="list-text">Ne vous souciez pas trop du trafic indirect. Dans un environnement très exigeant en E/S, il est préférable d'éviter le trafic indirect pour lequel chaque microseconde de latence est critique, mais l'impact visible sur la performance est négligeable pour les charges de travail classiques.</block>
  <block id="f54fccb82abaa995eb9f86264f431505" category="section-title">Conception de LIF NFS</block>
  <block id="e68dee93f11ae71aebd7a1e4c2abfc5a" category="paragraph">Contrairement aux protocoles SAN, NFS dispose d'une capacité limitée de définir plusieurs chemins d'accès aux données. Les extensions NFS parallèles (pNFS) à NFSv4 répondent à cette limitation, mais l'ajout de chemins d'accès supplémentaires devient rarement intéressant dans la mesure où les vitesses ethernet atteignent 100 Go et au-delà.</block>
  <block id="391dc675ec3d853200129b799ed5923e" category="section-title">Performances et résilience</block>
  <block id="a0bd34f908e3947aa4aba15382354836" category="paragraph">Bien que la mesure des performances d'une LIF SAN consiste principalement à calculer la bande passante totale à partir de tous les chemins principaux, la détermination des performances d'une LIF NFS nécessite d'étudier de plus près la configuration réseau exacte. Par exemple, deux ports 10 Gbit peuvent être configurés comme ports physiques bruts ou en tant que groupe d'interface LACP (Link Aggregation Control Protocol). S'ils sont configurés en tant que groupe d'interface, plusieurs stratégies d'équilibrage de charge sont disponibles et fonctionnent différemment selon que le trafic est commuté ou routé. Enfin, Oracle Direct NFS (dNFS) propose des configurations d'équilibrage de charge qui n'existent pour le moment dans aucun client OS NFS.</block>
  <block id="e500ca27c6b92454c989d80e0445c359" category="paragraph">Contrairement aux protocoles SAN, les systèmes de fichiers NFS nécessitent une résilience au niveau de la couche de protocole. Par exemple, une LUN est toujours configurée avec les chemins d'accès multiples activés, ce qui signifie que plusieurs canaux redondants sont disponibles pour le système de stockage, chacun utilisant le protocole FC. Un système de fichiers NFS, en revanche, dépend de la disponibilité d'un seul canal TCP/IP qui ne peut être protégé qu'au niveau de la couche physique. C'est pourquoi des options telles que le basculement de port et l'agrégation de ports LACP existent.</block>
  <block id="35926e2ada969ad80fd3b16c0cd7d35a" category="paragraph">Dans un environnement NFS, les performances et la résilience sont fournies au niveau de la couche du protocole réseau. En conséquence, ces deux sujets sont étroitement liés et doivent être discutés ensemble.</block>
  <block id="84f4a5dfaa9613a469cd783c353a186c" category="section-title">Lier les LIFs aux groupes de ports</block>
  <block id="44bfb87c11d83c1b91c3589f2081e7ca" category="paragraph">Pour lier une LIF à un port group, associez l'adresse IP de la LIF à un groupe de ports physiques. La méthode principale pour agréger les ports physiques est le LACP. La fonctionnalité de tolérance aux pannes de LACP est assez simple : chaque port d'un groupe LACP est surveillé et supprimé du groupe de ports en cas de dysfonctionnement. Cependant, il existe de nombreuses idées fausses sur le fonctionnement de LACP en matière de performances :</block>
  <block id="19a43026949fb6ef1017a54cf7c94f9b" category="list-text">LACP ne requiert pas que la configuration sur le switch corresponde au terminal. Par exemple, ONTAP peut être configuré avec un équilibrage de charge basé sur IP, tandis qu'un commutateur peut utiliser un équilibrage de charge basé sur MAC.</block>
  <block id="86501252b34395de5303a65f5e9943e3" category="list-text">Chaque noeud final utilisant une connexion LACP peut choisir indépendamment le port de transmission des paquets, mais il ne peut pas choisir le port utilisé pour la réception. Cela signifie que le trafic de ONTAP vers une destination particulière est lié à un port particulier, et que le trafic de retour peut arriver sur une interface différente. Cela ne cause cependant aucun problème.</block>
  <block id="298ca40b99dd3540dcd82ba5537f3f8d" category="list-text">LACP ne distribue pas uniformément le trafic en permanence. Dans un grand environnement comptant de nombreux clients NFS, le résultat est même généralement l'utilisation de tous les ports d'une agrégation LACP. Cependant, tout système de fichiers NFS dans l'environnement est limité à la bande passante d'un seul port, et non à l'agrégation complète.</block>
  <block id="d071b5ccd1569aace97a0b4d6c0a71ac" category="list-text">Bien que les politiques LACP robin-Robin soient disponibles sur ONTAP, ces règles n'abordent pas la connexion entre un switch et un hôte. Par exemple, une configuration avec une jonction LACP à quatre ports sur un hôte et une jonction LACP à quatre ports sur ONTAP ne peut toujours lire un système de fichiers qu'à l'aide d'un seul port. Bien que ONTAP puisse transmettre des données via les quatre ports, aucune technologie de commutation n'est actuellement disponible, qui envoie du commutateur à l'hôte via les quatre ports. Un seul est utilisé.</block>
  <block id="6e9e98dfaea1ca7860606f1fc05e414a" category="paragraph">L'approche la plus courante dans les grands environnements composés de nombreux hôtes de base de données est de créer un agrégat LACP comportant un nombre approprié d'interfaces 10 Gbit (ou plus rapides) en utilisant l'équilibrage de la charge IP. Cette approche permet à ONTAP d'assurer une utilisation uniforme de tous les ports, tant qu'il y a suffisamment de clients. L'équilibrage de la charge est défaillant lorsque la configuration compte moins de clients, car les ressources en ligne LACP ne redistribuent pas la charge de manière dynamique.</block>
  <block id="7815da600ab459d2b05c5792f2271c1a" category="paragraph">Lorsqu'une connexion est établie, le trafic dans une direction particulière est placé sur un seul port. Par exemple, une base de données effectuant une analyse de table complète sur un système de fichiers NFS connecté via une jonction LACP à quatre ports lit les données via une seule carte d'interface réseau (NIC). Si seulement trois serveurs de base de données se trouvent dans un tel environnement, il est possible que les trois derniers lisent à partir du même port, alors que les trois autres ports sont inactifs.</block>
  <block id="153f704ea16440133d51b1877af2a657" category="section-title">Lier les LIF à des ports physiques</block>
  <block id="70e655aa3c03f840747c5272142b3527" category="paragraph">La liaison d'une LIF à un port physique permet un contrôle plus granulaire de la configuration du réseau, car une adresse IP donnée sur un système ONTAP n'est associée qu'à un seul port réseau à la fois. La résilience s'obtient ensuite via la configuration des groupes de basculement et des règles de basculement.</block>
  <block id="218f00463f5281b8ead536582c69ac3a" category="section-title">Stratégies de basculement et groupes de basculement</block>
  <block id="0a53c26a1bc4036c84fc3b4b63542744" category="inline-link-macro">Documentation de gestion de réseau ONTAP pour les groupes et politiques de basculement</block>
  <block id="f29ae31443947c9782482ee9683dbc0e" category="paragraph">Le comportement des LIF durant une interruption du réseau est contrôlé par des règles de basculement et des groupes de basculement. Les options de configuration ont été modifiées avec les différentes versions de ONTAP. Consulter le <block ref="96c8cd47b667604fb9991ace7d2eff29" category="inline-link-macro-rx"></block> Pour plus d'informations sur la version de ONTAP déployée.</block>
  <block id="0f2f345dd1247ae428cee703c1bf1c84" category="paragraph">Les versions ONTAP 8.3 et supérieures permettent la gestion du basculement des LIF sur la base des domaines de diffusion. Par conséquent, un administrateur peut définir tous les ports ayant accès à un sous-réseau donné et autoriser ONTAP à sélectionner une LIF de basculement appropriée. Cette approche peut être utilisée par certains clients, mais elle est limitée dans un environnement de réseau de stockage haut débit en raison du manque de prévisibilité. Par exemple, un environnement peut inclure à la fois des ports 1 Gbit pour l'accès aux systèmes de fichiers de routine et des ports 10 Gbit pour les E/S des fichiers de données Si les deux types de ports existent dans le même broadcast domain, le basculement de LIF peut entraîner le déplacement des E/S des fichiers de données d'un port 10 Gb vers un port 1 Gb.</block>
  <block id="ced0729d57c08312b2b12382f2147d26" category="paragraph">En résumé, tenez compte des pratiques suivantes :</block>
  <block id="57cb6a7ba8acb7faa31cc5219bae83b3" category="list-text">Configurez un groupe de basculement comme défini par l'utilisateur.</block>
  <block id="b444855eccae552d7fb79bf3d31a4f7b" category="list-text">Remplissez le groupe de basculement avec les ports du contrôleur partenaire de basculement de stockage (SFO) de sorte que les LIF suivent les agrégats lors d'un basculement de stockage. Cela évite de créer du trafic indirect.</block>
  <block id="86c48b21d166ed8e440a07e1d4a0b15d" category="list-text">Utilisez les ports de basculement avec des caractéristiques de performance correspondantes à la LIF d'origine. Par exemple, une LIF située sur un seul port physique de 10 Go doit inclure un groupe de basculement doté d'un seul port 10 Go. Une LIF LACP à quatre ports doit basculer vers une autre LIF LACP à quatre ports. Ces ports seraient un sous-ensemble des ports définis dans le domaine de diffusion.</block>
  <block id="3e839a73f7dc1262508f23a89628ca2d" category="list-text">Définissez la politique de basculement sur partenaire SFO uniquement. Veillez donc à ce que la LIF suive l'agrégat lors du failover.</block>
  <block id="85e82ce4c9842f978fa774c4fe96b14c" category="section-title">Restauration automatique</block>
  <block id="3dc8610f78478640e47688101cecbfad" category="paragraph">Réglez le<block ref="9f1b7141f09f19c4e33409646aef43cf" prefix=" " category="inline-code"></block> paramètre selon vos besoins. La plupart des clients préfèrent définir ce paramètre sur<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> Pour que la LIF rerevienne sur son port home. Cependant, dans certains cas, les clients ont défini cette option sur `false `afin qu'un basculement inattendu puisse être recherché avant de renvoyer une LIF à son port de attache.</block>
  <block id="edf6d4c299bc2890ba63c7eb3ef8b4d2" category="section-title">Rapport LIF/volume</block>
  <block id="9c75becef8c432a0152a40c7c037a04c" category="paragraph">On croit souvent, à tort, qu'il doit y avoir une relation 1:1 entre les volumes et les LIFs NFS. Même si cette configuration est requise pour déplacer un volume n'importe où dans un cluster sans jamais créer de trafic d'interconnexion supplémentaire, elle n'est pas obligatoire de manière catégorique. Le trafic intercluster doit être envisagé, mais la simple présence du trafic intercluster ne crée pas de problèmes. Nombre des bancs d'essai publiés pour ONTAP portent sur des E/S principalement indirectes</block>
  <block id="2b4ebcd522b07b80d3fd76b301c506e8" category="paragraph">Par exemple, un projet de base de données contenant un nombre relativement limité de bases de données pour lesquelles seuls 40 volumes nécessitent des performances élevées peut justifier un rapport volume 1:1 vers une stratégie LIF, un arrangement qui nécessiterait 40 adresses IP. N'importe quel volume peut ensuite être déplacé n'importe où dans le cluster avec la LIF associée, et le trafic serait toujours direct, minimisant ainsi chaque source de latence, même à des niveaux d'une microseconde.</block>
  <block id="38bad4911bcdf1117d37eb1195566f8c" category="paragraph">Par exemple, un grand environnement hébergé peut être plus facilement géré avec une relation 1:1 entre les clients et les LIF. Au fil du temps, un volume peut avoir besoin d'être migré vers un autre nœud, ce qui provoque du trafic indirect. Cependant, l'effet sur les performances doit être indétectable à moins que les ports réseau du commutateur d'interconnexion ne soient saturés. En cas de problème, une nouvelle LIF peut être établie sur des nœuds supplémentaires et l'hôte peut être mis à jour dans la fenêtre de maintenance suivante afin de supprimer le trafic indirect de la configuration.</block>
  <block id="d75b0d8f723c3e97eaa4ca39630c7420" category="doc">MetroCluster et plusieurs agrégats</block>
  <block id="df5855269b493a27a5565dfd9f2584f0" category="list-text">Dans des conditions normales, les écritures entrantes sur un contrôleur donné sont mises en miroir de manière synchrone sur son partenaire. Dans un environnement NetApp MetroCluster, les écritures sont également mises en miroir sur un contrôleur distant. Tant qu'une écriture n'est pas stockée sur un support non volatile dans tous les emplacements, elle n'est pas validée par l'application hôte.</block>
  <block id="05b60db315aa45e1524b7a6ffa242fa8" category="list-text">Le support qui stocke les données d'écriture est appelé mémoire non volatile ou NVMEM. Elle est également parfois appelée mémoire NVRAM, et peut être considérée comme un cache d'écriture, même si elle fonctionne comme un journal. En fonctionnement normal, les données de NVMEM ne sont pas lues ; elles sont uniquement utilisées pour protéger les données en cas de défaillance logicielle ou matérielle. Lors de l'écriture des données sur les disques, les données sont transférées de la mémoire RAM du système, et non de NVMEM.</block>
  <block id="e6dd8b559da6e046f2043043a55faafc" category="list-text">Lors d'une opération de basculement, un nœud d'une paire haute disponibilité reprend les opérations de son partenaire. Un basculement est quasiment identique, mais s'applique aux configurations MetroCluster dans lesquelles un nœud distant prend le relais par rapport à un nœud local.</block>
  <block id="33c0c466972aae7427262e3075a2ed07" category="paragraph">Lors des opérations de maintenance de routine, un basculement du stockage ou un basculement doivent être transparents, sauf en cas de brève pause potentielle dans les opérations en cas de changement des chemins réseau. La mise en réseau peut toutefois être complexe et il est facile d'y faire des erreurs. NetApp recommande donc de tester minutieusement les opérations de basculement et de basculement avant de mettre en production un système de stockage. C'est la seule façon de s'assurer que tous les chemins réseau sont correctement configurés. Dans un environnement SAN, vérifiez soigneusement le résultat de la commande<block ref="41dc2c94e82e1c56ba876085acf5a974" prefix=" " category="inline-code"></block> pour vous assurer que tous les chemins principaux et secondaires attendus sont disponibles.</block>
  <block id="d33ea1ad1493de23aafd480e95fea159" category="paragraph">Il convient de faire attention lors d'un basculement forcé ou d'un basculement forcé. Forcer une modification de la configuration du stockage avec ces options signifie que l'état du contrôleur propriétaire des disques est ignoré et que le nœud alternatif prend le contrôle des disques. Une force de basculement incorrecte peut entraîner une perte ou une corruption des données. En effet, un basculement forcé ou un basculement forcé peut rejeter le contenu de la NVMEM. Une fois le basculement ou le basculement effectué, la perte de ces données signifie que les données stockées sur les disques peuvent revenir à un état plus ancien du point de vue de la base de données.</block>
  <block id="c226371d96b605ccff84ad23db0069b8" category="paragraph">Un basculement forcé avec une paire haute disponibilité normale devrait rarement être nécessaire. Dans la plupart des scénarios de défaillance, un nœud s'arrête et informe le partenaire qu'un basculement automatique a lieu. Il existe certains cas à la périphérie, par exemple une panne de déploiement où l'interconnexion entre les nœuds est perdue puis un contrôleur est perdu, dans lequel un basculement forcé est nécessaire. Dans ce cas, la mise en miroir entre les nœuds est perdue avant la panne du contrôleur, ce qui signifie que le contrôleur survivant n'aurait plus de copie des écritures en cours. Le basculement doit ensuite être forcé, ce qui signifie que des données peuvent être perdues.</block>
  <block id="418f81f529a577cb711b44adece1376f" category="paragraph">La même logique s'applique à un basculement MetroCluster. Dans des conditions normales, le basculement est presque transparent. Toutefois, un incident peut entraîner une perte de connectivité entre le site survivant et le site de reprise sur incident. Du point de vue du site survivant, le problème ne pourrait être rien de plus qu'une interruption de la connectivité entre les sites, et le site d'origine pourrait encore traiter les données. Si un nœud ne peut pas vérifier l'état du contrôleur principal, seul un basculement forcé est possible.</block>
  <block id="ae0c16d397348d8f8fd4e56b08b06c7c" category="paragraph">*NetApp recommande* de prendre les précautions suivantes :</block>
  <block id="79fd18cb18befbe5c2113757478be193" category="list-text">Veillez à ne pas forcer accidentellement un basculement ou un basculement. En règle générale, il n'est pas nécessaire de forcer et le fait de forcer la modification peut entraîner la perte de données.</block>
  <block id="26cece11254903c5ba8bfdd8d54ae779" category="list-text">Si un basculement ou un basculement forcé s'avère nécessaire, assurez-vous que les applications sont arrêtées, que tous les systèmes de fichiers sont démontés et que les groupes de volumes LVM (Logical Volume Manager) sont proposés en mode Variyoffed. Les groupes de disques ASM doivent être démontés.</block>
  <block id="0b6986eb1285d28a9987ea13adbca358" category="list-text">En cas de basculement forcé du MetroCluster, vous pouvez isoler le nœud défaillant de toutes les ressources de stockage restantes. Pour plus d'informations, consultez le Guide de gestion et de reprise sur incident de MetroCluster correspondant à la version appropriée de ONTAP.</block>
  <block id="71303adf87737046acd4381c72151278" category="paragraph">MetroCluster est une technologie de réplication synchrone qui passe en mode asynchrone en cas d'interruption de la connectivité. Cette demande est la plus courante de la part des clients, car une réplication synchrone garantie signifie que l'interruption de la connectivité du site entraîne un blocage complet des E/S de la base de données, ce qui la met hors service.</block>
  <block id="cb791a44ee361703eb7594a7932f57de" category="paragraph">Avec MetroCluster, les agrégats sont rapidement resynchronisés une fois la connectivité restaurée. Contrairement à d'autres technologies de stockage, MetroCluster ne devrait jamais nécessiter de mise en miroir complète après une panne de site. Seules les modifications delta doivent être expédiées.</block>
  <block id="c1536091d7c1ca33c9dc4dfa8c0852a2" category="paragraph">Dans les jeux de données qui couvrent les agrégats, le risque est faible de nécessiter des étapes supplémentaires de restauration des données en cas de sinistre en cas de déploiement. En particulier, si (a) la connectivité entre les sites est interrompue, (b) la connectivité est restaurée, (c) les agrégats atteignent un état dans lequel certains sont synchronisés et d'autres ne le sont pas, puis (d) le site primaire est perdu, le site survivant dans lequel les agrégats ne sont pas synchronisés. Dans ce cas, une partie du dataset est synchronisée et il est impossible d'ouvrir des applications, des bases de données ou des datastores sans restauration. Si un dataset compte plusieurs agrégats, NetApp recommande vivement d'utiliser des sauvegardes basées sur des snapshots avec l'un des nombreux outils disponibles pour vérifier la restauration rapide dans ce scénario inhabituel.</block>
  <block id="a42c87064c284490a38efac4bf0b7f7f" category="paragraph">RAID 4, RAID 5, RAID 6, RAID DP et RAID-TEC utilisent tous la parité pour s'assurer qu'une panne de disque n'entraîne pas de perte de données. Ces options RAID offrent une meilleure utilisation du stockage que la mise en miroir, mais la plupart des implémentations RAID présentent des inconvénients pour les opérations d'écriture. La réalisation d'une opération d'écriture sur d'autres implémentations RAID peut nécessiter plusieurs lectures de disque pour régénérer les données de parité, un processus communément appelé la pénalité RAID.</block>
  <block id="3cfcf9a3299db75df9aa0e024ebef965" category="paragraph">Cependant, ONTAP n'entraîne pas cette pénalité RAID. Cela est dû à l'intégration de NetApp WAFL (Write Anywhere File Layout) à la couche RAID. Les opérations d'écriture sont fusionnées dans la mémoire RAM et préparées sous la forme d'une couche RAID complète, y compris la génération de la parité. ONTAP n'a pas besoin d'effectuer de lecture pour effectuer une écriture, ce qui signifie que ONTAP et WAFL évitent la pénalité RAID. Les performances des opérations stratégiques pour la latence, telles que la journalisation de reprise, sont assurées sans aucun obstacle. Les écritures aléatoires des fichiers de données n'entraînent aucune pénalité RAID résultant de la régénération de la parité.</block>
  <block id="5ff9a871332f0f82f38d880b68a9874b" category="paragraph">En ce qui concerne la fiabilité statistique, même RAID DP offre une meilleure protection que la mise en miroir RAID. Le problème principal est la demande sur disques lors de la reconstruction RAID. Avec une configuration RAID en miroir, le risque de perte de données en cas de défaillance d'un disque pendant la reconstruction vers son partenaire dans la configuration RAID est bien plus grand que le risque de défaillance simultanée de trois disques dans une configuration RAID DP.</block>
  <block id="12c3fe87fd5a746ce8a7cbe25dc1c25b" category="paragraph">Avant l'ère des disques Flash, la répartition était utilisée pour surmonter les limites de performances des disques rotatifs. Par exemple, si un système d'exploitation doit effectuer une opération de lecture de 1 Mo, la lecture de ce 1 Mo de données à partir d'un seul disque demande beaucoup de tête de lecture lorsque le transfert des 1 Mo est lent. Si ce 1 Mo de données a été réparti sur 8 LUN, le système d'exploitation pourrait exécuter huit opérations de lecture de 128 K en parallèle et réduire le temps nécessaire au transfert de 1 Mo.</block>
  <block id="e337352c3d57672fd08af8ba709b544f" category="paragraph">Le striping avec des disques rotatifs était plus difficile, car le modèle d'E/S devait être connu à l'avance. Si la répartition n'a pas été correctement réglée pour les véritables modèles d'E/S, les configurations à bandes risquent d'endommager les performances. Avec les bases de données Oracle, et en particulier les configurations 100 % Flash, le striping est beaucoup plus facile à configurer et a fait ses preuves pour améliorer considérablement les performances.</block>
  <block id="7025652291dc6872022b0f79a2b2be21" category="paragraph">Par défaut, les gestionnaires de volumes logiques, tels que la bande Oracle ASM, ne le font pas pour le système d'exploitation natif LVM. Certaines lient plusieurs LUN ensemble en tant que périphérique concaténé. Résultat : des fichiers de données existent sur un seul périphérique LUN. Ceci provoque des points chauds. Les autres implémentations LVM prennent par défaut en charge les extensions distribuées. Cette méthode est similaire à la répartition, mais elle est plus grossière. Les LUN du groupe de volumes sont tranchées en grandes parties, appelées extensions et généralement mesurées en plusieurs mégaoctets. Ensuite, les volumes logiques sont distribués sur ces extensions. Il en résulte des E/S aléatoires sur un fichier qui doit être bien réparti entre les LUN, mais les opérations d'E/S séquentielles ne sont pas aussi efficaces qu'elles pourraient l'être.</block>
  <block id="0c2f3b2ec9d90baa0a0a0b6fb673a113" category="paragraph">Les E/S des applications exigeantes en performances sont presque toujours de (a) en unités de taille de bloc de base ou (b) d'un mégaoctet.</block>
  <block id="804d5b1f06570b4d242be0c2f0c3392c" category="paragraph">L'objectif principal d'une configuration à bandes est de s'assurer que les E/S de fichier unique peuvent être exécutées comme une seule unité, et que les E/S de plusieurs blocs, d'une taille de 1 Mo, peuvent être parallélisées de façon homogène sur toutes les LUN du volume réparti. Cela signifie que la taille de bande ne doit pas être inférieure à la taille du bloc de base de données, et que la taille de bande multipliée par le nombre de LUN doit être de 1 Mo.</block>
  <block id="0598f393baefd05d48b48076cc7df606" category="paragraph">La figure suivante présente trois options possibles pour le réglage de la taille et de la largeur des bandes. Le nombre de LUN est sélectionné pour répondre aux exigences de performances comme décrit ci-dessus, mais dans tous les cas, le total des données dans une seule bande est de 1 Mo.</block>
  <block id="9ca503fae9ccd4d6d8e67806b23adfa0" category="paragraph"><block ref="9ca503fae9ccd4d6d8e67806b23adfa0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0353522b39b87d54d40d3f09ec668851" category="doc">Configuration ONTAP</block>
  <block id="8e52de0d4b03d5fe87dc88da09616c7f" category="inline-link-macro">ici.</block>
  <block id="9fe343788d08130f46e418bb81928479" category="summary">Présentation de FabricPool</block>
  <block id="337c62c6b6eb7319bae58701105e889c" category="doc">Tiering</block>
  <block id="cec4b296aaf93974a98a5d3b3f27ff9e" category="paragraph">Pour comprendre l'impact du Tiering FabricPool sur les applications et les bases de données, il est nécessaire de connaître l'architecture FabricPool de bas niveau.</block>
  <block id="3493794b3ccb587f71a663f51f4484ef" category="summary">Bases de données PostgreSQL sur ONTAP</block>
  <block id="2d3298c651b356a82db5d664ce68e65e" category="doc">Protection native des données</block>
  <block id="31c6611c8e0bd237a3ee51db1728a440" category="paragraph">L'un des principaux aspects de la conception du stockage est l'activation de la protection pour les volumes PostgreSQL. Les clients peuvent protéger leurs bases de données PostgreSQL en utilisant l'approche dump ou en utilisant des sauvegardes de système de fichiers. Cette section décrit les différentes approches de sauvegarde de bases de données individuelles ou de l'ensemble du cluster.</block>
  <block id="9f3265914462c64fd02bc50ab4c9ebe9" category="paragraph">Il existe trois approches de sauvegarde des données PostgreSQL :</block>
  <block id="6b592c7950245a5a9f54d9424e851e97" category="list-text">Dump SQL Server</block>
  <block id="c8b1fc69d12d1da6589e384671c8e82c" category="list-text">Sauvegarde au niveau du système de fichiers</block>
  <block id="3c25062a0babfa1495dd604698707610" category="list-text">Archivage continu</block>
  <block id="58c132e2be12705408a7456c6183b617" category="paragraph">L'idée derrière la méthode de vidage de SQL Server est de générer un fichier avec des commandes SQL Server qui, une fois renvoyées au serveur, peuvent recréer la base de données telle qu'elle était au moment de la sauvegarde. PostgreSQL fournit les programmes utilitaires<block ref="5a5149b2817f30cbb3805307f9cadae4" prefix=" " category="inline-code"></block> et<block ref="0ead269b3d000482b5a44a1ef4e8cd54" prefix=" " category="inline-code"></block> pour la création de sauvegardes individuelles et au niveau du cluster. Ces vidages sont logiques et ne contiennent pas suffisamment d'informations pour être utilisés par la relecture WAL.</block>
  <block id="1d05b80fc6f199681263e063190e8325" category="paragraph">Une autre stratégie de sauvegarde consiste à utiliser une sauvegarde au niveau du système de fichiers, dans laquelle les administrateurs copient directement les fichiers utilisés par PostgreSQL pour stocker les données dans la base de données. Cette méthode s'effectue en mode hors ligne : la base de données ou le cluster doit être arrêté. Une autre alternative est d'utiliser<block ref="35679fc424d9eec0c30f38459fd9b322" prefix=" " category="inline-code"></block> Pour exécuter une sauvegarde de diffusion à chaud de la base de données PostgreSQL.</block>
  <block id="10907e7ac5ab6e5235a23898a2331b31" category="doc">Bases de données PostgreSQL sur ONTAP</block>
  <block id="b5f477e959f26421a80e1eebdadbdd71" category="paragraph">PostgreSQL est fourni avec des variantes incluant PostgreSQL, PostgreSQL plus et EDB Postgres Advanced Server (EPAS). PostgreSQL est généralement déployé en tant que base de données interne pour les applications multiniveaux. Il est pris en charge par les logiciels middleware courants (tels que PHP, Java, Python, Tcl/TK, ODBC, Et JDBC) et a toujours été un choix populaire pour les systèmes de gestion de bases de données open source. NetApp ONTAP constitue un excellent choix pour l'exécution des bases de données PostgreSQL et ses fonctionnalités de gestion des données fiables, performantes et efficaces.</block>
  <block id="841a21e58e7c22a71c07b89a4362d2b6" category="admonition">Cette documentation sur ONTAP et la base de données PostgreSQL remplace la base de données _TR-4770: PostgreSQL sur les meilleures pratiques ONTAP._</block>
  <block id="23dc28a190980aa339329235e8b66434" category="paragraph">Avec la croissance exponentielle des données, la gestion des données devient de plus en plus complexe pour les entreprises. Cette complexité augmente les coûts de licence, d'exploitation, de support et de maintenance. Pour réduire le coût total de possession, envisagez de passer de bases de données commerciales à des bases de données open source grâce à un stockage interne fiable et haute performance. PostgreSQL est une base de données open source avancée largement utilisée dans les universités, le commerce et les grandes entreprises. Il est fourni avec un nouvel ensemble de fonctionnalités qui permettent de combler les lacunes dans d'autres systèmes de gestion de bases de données relationnelles (RDBMS).</block>
  <block id="595e7195ec732ff0042e8b03492176cc" category="admonition">Les clients NetApp qui utilisent des bases de données PostgreSQL dans des environnements physiques ou virtualisés peuvent tirer parti des meilleures pratiques pour réussir le déploiement et la gestion des bases de données PostgreSQL sur ONTAP. Les recommandations sont génériques et ne sont donc pas spécifiques à une configuration. Selon les besoins de votre entreprise, certaines suggestions peuvent nécessiter des modifications. Vous devez évaluer votre environnement par rapport à la documentation officielle pour PostgreSQL, les hyperviseurs, le système d'exploitation et le stockage ONTAP.</block>
  <block id="6c1ea8a6f96c812bdbee4a788f8282dc" category="doc">Annexe A : configuration de l'hôte</block>
  <block id="c3ef6436e8acdba8ced1def7d29a99b8" category="paragraph">Contenu de l'annexe :</block>
  <block id="873bf9c2fc74dd3fc39aa67a16b51d6a" category="list-text">Vérifiez que les adaptateurs de bus hôte (HBA) FC de l'hôte ESX fonctionnent avec les pilotes, le micrologiciel et la version correcte du BIOS.</block>
  <block id="b6d348f60c7c0e3bb221591b67518d1c" category="list-text">Installez les utilitaires d'hôtes NetApp sur l'hôte pour afficher les chemins directs et indirects d'une LUN donnée. Le kit fournit également des informations détaillées sur le SVM LUN.</block>
  <block id="4a1afd4a3d39c7e385017e01816d721f" category="list-text">Utilisez toujours un script de nouvelle analyse de bus SCSI sur l'hôte pour :</block>
  <block id="6d1436a6f6bda3b3ce87df91aaf6fb56" category="list-text">Rechercher de nouvelles LUN</block>
  <block id="897dc659ee2dd9f0dd17af82c47259bd" category="list-text">Mettez les LUN obsolètes au rebut</block>
  <block id="ecef9cf88b8cf100d1a489f3acdd4732" category="list-text">Mettez à jour les nouveaux chemins vers les LUN</block>
  <block id="c7b133bd977e02fc973a2df60786e7a8" category="list-text">Pour établir plusieurs voies vers le stockage en cas de défaillance du chemin, installez et configurez le logiciel de chemins d'accès multiples sur le système d'exploitation hôte.</block>
  <block id="3617da17b3368e5730bf10cdacf54a18" category="list-text">Si vous n'utilisez pas de logiciel de chemins d'accès multiples, vous devez limiter chaque LUN à un chemin unique.</block>
  <block id="6dff2f8361cdca0bbb6cfa1d162de499" category="list-text">Le noyau Linux permet un contrôle de bas niveau sur la planification des E/S pour bloquer les périphériques. Les valeurs par défaut dans les versions Linux peuvent varier considérablement. De manière générale, les clients NetApp et les tests internes montrent de meilleurs résultats avec le planificateur NoOps pour les bases de données. Vous devez réaliser des bancs d'essai pour déterminer quels planificateurs d'E/S sont les mieux adaptés à votre cas d'utilisation.</block>
  <block id="9147e5e61a7b9260dec09f3a6eb3e5be" category="doc">Snapshots</block>
  <block id="0b9d99167191c5d9ad23ca07bc6a9b38" category="paragraph">Les sauvegardes basées sur des copies Snapshot avec PostgreSQL requièrent la configuration de snapshots pour les fichiers de données, les fichiers WAL et les fichiers WAL archivés afin d'assurer une restauration complète ou instantanée.</block>
  <block id="8c6a53edc4449a4cc3983d47ecffa851" category="paragraph">Pour les bases de données PostgreSQL, la durée moyenne de sauvegarde avec des copies Snapshot est comprise entre quelques secondes et quelques minutes. Cette vitesse de sauvegarde est 60 à 100 fois plus rapide que<block ref="35679fc424d9eec0c30f38459fd9b322" prefix=" " category="inline-code"></block> et d'autres approches de sauvegarde basées sur le système de fichiers.</block>
  <block id="c798632224ae09152f66f60e0edc757e" category="paragraph">Les copies Snapshot situées sur un système de stockage NetApp peuvent être à la fois cohérentes après panne et cohérentes au niveau des applications. Un snapshot cohérent après panne est créé sur un système de stockage sans interrompre la base de données, tandis qu'un Snapshot cohérent avec les applications est créé lorsque la base de données est en mode de sauvegarde. NetApp garantit également que les copies Snapshot suivantes sont des sauvegardes incrémentielles à l'infini pour promouvoir les économies de stockage et l'efficacité réseau.</block>
  <block id="d0e369216eeac8de66e915909364970a" category="paragraph">Comme les snapshots sont rapides et n'affectent pas les performances du système, vous pouvez planifier plusieurs copies Snapshot chaque jour au lieu de créer une sauvegarde quotidienne comme avec les autres technologies de sauvegarde en streaming. Lorsqu'une opération de restauration et de restauration est nécessaire, le temps d'interruption du système est réduit grâce à deux fonctionnalités clés :</block>
  <block id="316eb8adba4d16a34c92eaf9db381b9e" category="list-text">Avec la technologie de restauration des données NetApp SnapRestore, la restauration s'exécute en quelques secondes.</block>
  <block id="c128c475c12703e37685edd6db8144bc" category="list-text">Les objectifs de point de restauration (RPO) agressifs signifient qu'il faut moins de journaux de base de données et que la restauration par progression est également accélérée.</block>
  <block id="9b9f26085ff7149d4dbb916b1db0f121" category="paragraph">Pour sauvegarder PostgreSQL, vous devez vous assurer que les volumes de données sont protégés simultanément avec WAL (groupe de cohérence) et les journaux archivés. Lorsque vous utilisez la technologie Snapshot pour copier des fichiers WAL, assurez-vous de les exécuter<block ref="a3b8c8ee15ba60bfb2b999195d2b4e7d" prefix=" " category="inline-code"></block> Pour vider toutes les entrées WAL qui doivent être archivées. Si vous videz les entrées WAL pendant la restauration, il vous suffit d'arrêter la base de données, de démonter ou de supprimer le répertoire de données existant et d'effectuer une opération SnapRestore sur le stockage. Une fois la restauration terminée, vous pouvez monter le système et le ramener à son état actuel. Pour la restauration instantanée, vous pouvez également restaurer les journaux WAL et d'archivage ; PostgreSQL décide alors du point le plus cohérent et le récupère automatiquement.</block>
  <block id="8e8d6187572eace409fee5bf2dbb7cf9" category="paragraph">Les groupes de cohérence sont une fonctionnalité de ONTAP recommandée lorsque plusieurs volumes sont montés sur une seule instance ou une base de données avec plusieurs tablespaces. Une copie Snapshot de groupe de cohérence garantit que tous les volumes sont regroupés et protégés. Pour gérer efficacement un groupe de cohérence, ONTAP vous pouvez même le cloner et créer une copie d'instance d'une base de données à des fins de test ou de développement.</block>
  <block id="55ca4b30c6f7c3ef975a6d1e1fb222a2" category="inline-link-macro">Présentation des groupes de cohérence NetApp</block>
  <block id="69dd5879aee425e37fdd5796a8e06a56" category="paragraph">Pour plus d'informations sur les groupes de cohérence, reportez-vous au <block ref="112c5744a39904facdbc5fab385d9fe1" category="inline-link-macro-rx"></block>.</block>
  <block id="7e7397a7b79323762c61941fc0e6b5f9" category="doc">Protection des données</block>
  <block id="90b0d8da95f7f5935481bc7e648c111e" category="summary">Tablespaces PostgreSQL</block>
  <block id="16a49d0bc0249ef3dd42949589a0ed4e" category="doc">Espaces de stockage</block>
  <block id="d6d544de56c329d9f68bb176c6245e7c" category="paragraph">Deux tablespaces sont créés automatiquement lorsque le cluster de base de données est initialisé.</block>
  <block id="6df924905e21856e4e8b8f936767cdd6" category="paragraph">Le<block ref="bd676cbef0d168a62a062c8709af1824" prefix=" " category="inline-code"></block> l'espace table est utilisé pour les catalogues système partagés. Le<block ref="3224684b8e7208962a73daeb0bb24110" prefix=" " category="inline-code"></block> tablespace est l'espace table par défaut des bases de données templage1 et template0. Si la partition ou le volume sur lequel le cluster a été initialisé est à court d'espace et ne peut pas être étendu, un espace table peut être créé sur une partition différente et utilisé jusqu'à ce que le système puisse être reconfiguré.</block>
  <block id="364c9d7b9593277eee9477befaf9f66b" category="paragraph">Un index très utilisé peut être placé sur un disque rapide et hautement disponible, comme un périphérique SSD. Par ailleurs, une table qui stocke des données archivées rarement utilisées ou non critiques pour les performances peut être stockée sur un système sur disque moins onéreux et plus lent, tel que des disques SAS ou SATA.</block>
  <block id="9bfe8d8e1117bd1d4b8597220e3f166e" category="paragraph">Les tablespaces font partie du cluster de base de données et ne peuvent pas être traités comme un ensemble autonome de fichiers de données. Elles dépendent des métadonnées contenues dans le répertoire de données principal et ne peuvent donc pas être reliées à un autre cluster de base de données ou sauvegardées individuellement. De même, si vous perdez un espace de table (suite à la suppression d'un fichier, à une panne de disque, etc.), le cluster de base de données peut devenir illisible ou ne pas démarrer. Le fait de placer un tablespace sur un système de fichiers temporaire, tel qu'un disque RAM, risque de nuire à la fiabilité de l'ensemble du cluster.</block>
  <block id="7d9573b1ed3543ec6ea42c81830dc27c" category="paragraph">Une fois créé, un espace table peut être utilisé à partir de n'importe quelle base de données si l'utilisateur demandeur dispose de privilèges suffisants. PostgreSQL utilise des liens symboliques pour simplifier l'implémentation des tablespaces. PostgreSQL ajoute une ligne au<block ref="4a926dc6e7549c49a13755513af41e67" prefix=" " category="inline-code"></block> Tableau (table à l'échelle du cluster) et attribue un nouvel identifiant d'objet (OID) à cette ligne. Enfin, le serveur utilise l'OID pour créer un lien symbolique entre votre cluster et le répertoire donné. Le répertoire<block ref="8e3da386e945c59fb1e1cd1d7a47697c" prefix=" " category="inline-code"></block> contient des liens symboliques pointant vers chacun des tablespaces non intégrés définis dans le cluster.</block>
  <block id="249fd7d68098688fab42436eed51be7d" category="doc">Configuration de la base de données</block>
  <block id="8daf26b2c72dd18a89fa89a6b1aa988d" category="paragraph">Il existe plusieurs configurations de réglage PostgreSQL qui peuvent améliorer les performances.</block>
  <block id="abb3dae412afe5c801e9ab90de71675b" category="paragraph">Les paramètres les plus utilisés sont les suivants :</block>
  <block id="bfdf741f4acb3dfee6e87075b535610e" category="list-text"><block ref="39d79378db03fed7c5ba62efba38e327" prefix="" category="inline-code"></block>: Le nombre maximal de connexions de base de données à avoir en même temps. Utilisez ce paramètre pour limiter l'échange sur le disque et l'arrêt des performances. Selon les besoins de votre application, vous pouvez également régler ce paramètre pour les paramètres du pool de connexions.</block>
  <block id="9625e1a6f5d1f695fd1c72401afaa07e" category="list-text"><block ref="904d399f43708a8a5b6d10c1ee3f8356" prefix="" category="inline-code"></block>: La méthode la plus simple pour améliorer les performances de votre serveur de base de données. La valeur par défaut est faible pour la plupart des matériels modernes. Il est défini pendant le déploiement à environ 25 % de la RAM disponible sur le système. Ce paramètre varie en fonction de la façon dont il fonctionne avec des instances de base de données particulières ; vous devrez peut-être augmenter ou diminuer les valeurs par tâtonnement et erreur. Cependant, le réglage haut risque de dégrader les performances.</block>
  <block id="d1960c56572383fc401fec3f0b767cf9" category="list-text"><block ref="5edeed59821790d8bec6d32da26bca4c" prefix="" category="inline-code"></block>: Cette valeur indique à l'optimiseur de PostgreSQL la quantité de mémoire disponible pour la mise en cache des données et aide à déterminer si un index doit être utilisé. Une valeur plus élevée augmente la probabilité d'utiliser un index. Ce paramètre doit être défini sur la quantité de mémoire allouée à<block ref="e15ed0f69e5c2475450b97691d6a2cee" prefix=" " category="inline-code"></block> Plus la quantité de cache du système d'exploitation disponible. Cette valeur représente souvent plus de 50 % de la mémoire système totale.</block>
  <block id="508df54f84fc7abb00f3a92937ca3506" category="list-text"><block ref="1edef4d43b06d4deb28010505df5724d" prefix="" category="inline-code"></block>: Ce paramètre contrôle la quantité de mémoire à utiliser dans les opérations de tri et les tables de hachage. Si vous effectuez un tri important dans votre application, vous devrez peut-être augmenter la quantité de mémoire, mais soyez prudent. Ce n'est pas un paramètre à l'échelle du système, mais un paramètre par opération. Si une requête complexe comporte plusieurs opérations de tri, elle utilise plusieurs unités de mémoire Work_mem et plusieurs back end peuvent le faire simultanément. Cette requête peut souvent amener votre serveur de base de données à échanger si la valeur est trop élevée. Cette option était auparavant appelée sort_mem dans les anciennes versions de PostgreSQL.</block>
  <block id="59d9770060aecba84c7e8ed849b5653d" category="list-text"><block ref="65768448b4f275b95af20a317c7355a9" prefix="" category="inline-code"></block>: Ce paramètre détermine si toutes vos pages WAL doivent être synchronisées sur le disque à l'aide de fsync() avant qu'une transaction ne soit validée. Sa désactivation peut parfois améliorer les performances d'écriture et son activation renforce la protection contre le risque de corruption en cas de panne du système.</block>
  <block id="625a65dd6cef83bac66319bde3894899" category="list-text"><block ref="ff5a06a39dd6824f30a778a51cf7ea69" prefix="" category="inline-code"></block>: Le processus de point de contrôle vide les données validées sur le disque. Cela implique de nombreuses opérations de lecture/écriture sur le disque. La valeur est définie en secondes et les valeurs inférieures réduisent le temps de reprise après incident et l'augmentation des valeurs peut réduire la charge sur les ressources système en réduisant les appels au point de contrôle. En fonction de la criticité de l'application, de l'utilisation et de la disponibilité de la base de données, définissez la valeur de Checkpoint_timeout.</block>
  <block id="309b1036c45e7ad490448925dc4f9597" category="list-text"><block ref="6a5c0586429891e84e05d6ab15088405" prefix="" category="inline-code"></block> et<block ref="9080796d32078fea7d191100eab64f92" prefix=" " category="inline-code"></block>: Ces options sont utilisées ensemble pour aider à améliorer les performances en écrivant plusieurs transactions qui sont exécutées simultanément. Si plusieurs objets commit_frames sont actifs à l'instant où votre transaction est validée, le serveur attend les microsecondes commit_delay pour essayer de valider plusieurs transactions à la fois.</block>
  <block id="8d5137ce002c6328c2b5f4f328662e1d" category="list-text"><block ref="fa4ca2cd95c20a44171f964fb8f5fdb9" prefix="" category="inline-code"></block>: Configurer le nombre optimal de travailleurs pour les processus. Max_Parallel_workers correspond au nombre de CPU disponibles. Selon la conception de l'application, les requêtes peuvent nécessiter un nombre réduit de collaborateurs pour les opérations parallèles. Il est préférable de conserver la même valeur pour les deux paramètres, mais d'ajuster la valeur après le test.</block>
  <block id="c8736e7ca19e9096796c624f3030dae5" category="list-text"><block ref="8dda85a5feb6de66d8f5f9a4cbdb0754" prefix="" category="inline-code"></block>: Cette valeur contrôle la façon dont PostgreSQL affiche les lectures de disque non séquentielles. Une valeur plus élevée signifie que PostgreSQL est plus susceptible d'utiliser une analyse séquentielle au lieu d'une analyse d'index, indiquant que votre serveur a des disques rapides Modifier ce paramètre après avoir évalué d'autres options telles que l'optimisation basée sur un plan, l'aspiration, l'indexation pour modifier les requêtes ou le schéma.</block>
  <block id="17edf3863f12b7d9480b3336a9fca773" category="list-text"><block ref="709989c844c22473cb8406550423d39a" prefix="" category="inline-code"></block>: Ce paramètre définit le nombre d'opérations d'E/S de disque simultanées que PostgreSQL tente d'exécuter simultanément. L'augmentation de cette valeur augmente le nombre d'opérations d'E/S que toute session PostgreSQL individuelle tente d'initier en parallèle. La plage autorisée est comprise entre 1 et 1,000, ou zéro pour désactiver l'émission de demandes d'E/S asynchrones. Actuellement, ce paramètre n'affecte que les analyses de tas bitmap. Les disques SSD et les autres systèmes de stockage basés sur la mémoire (NVMe) peuvent souvent traiter un grand nombre de requêtes simultanées. Le meilleur choix peut donc se situer dans les centaines.</block>
  <block id="82b38edb10ad73f9645c5d65e73a659b" category="paragraph">Consultez la documentation PostgreSQL pour obtenir une liste complète des paramètres de configuration PostgreSQL.</block>
  <block id="402fbc243dbef50cd5c8e57ccbdd92f5" category="section-title">TOASTS</block>
  <block id="0d2b62abb26bd0b4109f5bc967250933" category="paragraph">TOAST est l'acronyme de Oversized-Attribute Storage technique. PostgreSQL utilise une taille de page fixe (généralement 8 Ko) et ne permet pas aux blocs de données de couvrir plusieurs pages. Par conséquent, il n'est pas possible de stocker directement des valeurs de champ importantes. Lorsque vous essayez de stocker une ligne qui dépasse cette taille, TOAST divise les données de grandes colonnes en « morceaux » plus petits et les stocke dans une table de TOASTS.</block>
  <block id="3f11f21bdc22c3c955c3f0fca39e9bc0" category="paragraph">Les grandes valeurs des attributs toastés sont extraites (si elles sont sélectionnées) uniquement au moment où le jeu de résultats est envoyé au client. La table elle-même est beaucoup plus petite et peut contenir plus de lignes dans le cache du tampon partagé qu'elle ne le pouvait sans stockage hors ligne (TOAST).</block>
  <block id="9a311ef6dad816cb7a15c0ab41920ad8" category="section-title">VIDE</block>
  <block id="385e23b8ebe64dfd0005f6846cc8e85e" category="paragraph">En mode PostgreSQL normal, les blocs de données supprimés ou rendus obsolètes par une mise à jour ne sont pas physiquement supprimés de leur table ; ils restent présents jusqu'à ce que LE VIDE soit exécuté. Par conséquent, vous devez faire fonctionner le VIDE régulièrement, en particulier sur les tables fréquemment mises à jour. L'espace qu'il occupe doit ensuite être récupéré pour réutilisation par de nouvelles lignes, afin d'éviter une panne d'espace disque. Cependant, il ne renvoie pas l'espace vers le système d'exploitation.</block>
  <block id="db81319c35b48ed94867775a9a1ce1d7" category="paragraph">L'espace libre dans une page n'est pas fragmenté. VIDE réécrit le bloc entier, en empaquant efficacement les lignes restantes et en laissant un seul bloc contigu d'espace libre dans une page.</block>
  <block id="8a5c17164c9920590fc057ee01f2fcb3" category="paragraph">En revanche, LE VIDE COMPLET composera activement les tables en écrivant une version complètement nouvelle du fichier table sans espace mort. Cette action réduit la taille de la table mais peut prendre un certain temps. Elle nécessite également de l'espace disque supplémentaire pour la nouvelle copie de la table jusqu'à ce que l'opération soit terminée. L'objectif du VIDE DE routine est d'éviter toute activité de VIDE COMPLET. Ce processus permet non seulement de conserver les tables à leur taille minimale, mais également de conserver une utilisation régulière de l'espace disque.</block>
  <block id="d3213224909897cac25fe1359e587293" category="summary">Initialisation PostgreSQL</block>
  <block id="61bcd96a2c1f8026527cbf2019d6e9a4" category="doc">Initialisation</block>
  <block id="f4f9dac58f7c47e819293af5f2dd1177" category="paragraph">Vous créez un nouveau cluster de base de données à l'aide de<block ref="abc91e782cd3950bfa31202aff74ca69" prefix=" " category="inline-code"></block> programme. An<block ref="abc91e782cd3950bfa31202aff74ca69" prefix=" " category="inline-code"></block> script crée les fichiers de données, les tables système et les bases de données modèles (template0 et template1) qui définissent le cluster.</block>
  <block id="b668460552732302350bbb840d57931c" category="paragraph">La base de données de modèles représente une base de données de stock. Il contient des définitions pour les tables système, les vues standard, les fonctions et les types de données.<block ref="3865cf98fe802a965570b4a10a1d894b" prefix=" " category="inline-code"></block> sert d'argument à l'<block ref="abc91e782cd3950bfa31202aff74ca69" prefix=" " category="inline-code"></block> script qui spécifie l'emplacement du cluster de base de données.</block>
  <block id="8fcd14822a5b94d212898fe3e006526e" category="paragraph">Tous les objets de base de données dans PostgreSQL sont gérés en interne par les OID respectives. Les tables et les index sont également gérés par des OID individuelles. Les relations entre les objets de base de données et leurs OID respectives sont stockées dans les tables de catalogue système appropriées, selon le type d'objet. Par exemple, les OID des bases de données et des tables de segment de mémoire sont stockées dans<block ref="d0fcebb608269edbd5d67486884ebed7" prefix=" " category="inline-code"></block> et `pg_class, respectivement. Vous pouvez déterminer les OID en émettant des requêtes sur le client PostgreSQL.</block>
  <block id="d0e97e34fe92edd2facd0f7377b6340b" category="paragraph">Chaque base de données a ses propres tables et fichiers d'index qui sont limités à 1 Go. Chaque table a deux fichiers associés, avec le suffixe respectivement<block ref="7b9b00c45b01f7b7c6d3a3c8ba2e9275" prefix=" " category="inline-code"></block> et<block ref="a1d869a79e2f43693a6a416fcbdc2724" prefix=" " category="inline-code"></block>. Ils sont appelés carte de l'espace libre et carte de visibilité. Ces fichiers stockent les informations relatives à la capacité d'espace libre et ont une visibilité sur chaque page du fichier de table. Les index ne disposent que de cartes d'espace libre individuelles et ne disposent pas de cartes de visibilité.</block>
  <block id="048a7ed79caf84bb5c725efc5f474911" category="paragraph">Le<block ref="c28f4f32219f5ff99fb4b116980b8549" prefix=" " category="inline-code"></block> le répertoire contient les journaux d'écriture anticipée. Des journaux d'écriture anticipée sont utilisés pour améliorer la fiabilité et les performances de la base de données. Chaque fois que vous mettez à jour une ligne dans une table, PostgreSQL écrit d'abord la modification dans le journal d'écriture anticipée, puis écrit les modifications sur les pages de données réelles sur un disque. Le<block ref="f7223cfaa9416056a91e259e326ac5cf" prefix=" " category="inline-code"></block> le répertoire contient généralement plusieurs fichiers, mais initdb ne crée que le premier. Des fichiers supplémentaires sont ajoutés si nécessaire. Chaque fichier xlog fait 16 Mo de long.</block>
  <block id="789a6c7dd865d16eb1df122bcc5c9a3a" category="admonition">*NetApp recommande* d'utiliser NFSv4.1 si les fonctionnalités NFSv4 sont requises. Certaines améliorations fonctionnelles du protocole NFSv4 dans NFSv4.1 améliorent la résilience dans certains cas à la périphérie.</block>
  <block id="8e86e0aee135afb67c6a1d3d6e0f3306" category="inline-link-macro">Tailles de transfert NFS</block>
  <block id="d84b41126744795c4ee82f7b256e7234" category="inline-link-macro">SAN FC</block>
  <block id="2c8c2171fc87c96e58fb40d8714f85cf" category="doc">Architecture PostgreSQL</block>
  <block id="ee62b4420d426c21a46d892ac084872a" category="paragraph">PostgreSQL est un SGBDR basé sur l'architecture client et serveur. Une instance PostgreSQL est appelée cluster de base de données, qui est une collection de bases de données par opposition à une collection de serveurs.</block>
  <block id="89c30c326e106773af32af40255b92a8" category="inline-image-macro">Erreur : graphique introuvable</block>
  <block id="54c2dd41fd1ad3efa25e80bee0bae549" category="paragraph">Il existe trois éléments principaux dans une base de données PostgreSQL : le postmaster, le front end (client) et le back end Le client envoie des demandes au postmaster avec des informations telles que le protocole IP et la base de données à laquelle se connecter. Le postmaster authentifie la connexion et la transmet au processus d'arrière-plan pour une communication plus poussée. Le processus back-end exécute la requête et envoie les résultats directement au frontal (client).</block>
  <block id="9f96e07bbaf7c0237047d6d0f95301a8" category="paragraph">Une instance PostgreSQL est basée sur un modèle multiprocessus au lieu d'un modèle multithread. Il génère plusieurs processus pour différents travaux, et chaque processus possède sa propre fonctionnalité. Les principaux processus incluent le processus client, le processus WAL writer, le processus Background writer et le processus checkpointer :</block>
  <block id="6aebf901bd4be26a765c56e4133b3798" category="list-text">Lorsqu'un processus client (premier plan) envoie des demandes de lecture ou d'écriture à l'instance PostgreSQL, il ne lit pas ou n'écrit pas les données directement sur le disque. Il met d'abord en mémoire tampon les données dans des tampons partagés et des tampons WAL (Write-Ahead Logging).</block>
  <block id="458239ee6c634dc5fef96f9dfab275f0" category="list-text">Un processus WAL writer manipule le contenu des tampons partagés et des tampons WAL pour écrire dans les journaux WAL. Les journaux WAL sont généralement des journaux de transaction de PostgreSQL et sont écrits de manière séquentielle. Par conséquent, pour améliorer le temps de réponse de la base de données, PostgreSQL écrit d'abord dans les journaux de transactions et reconnaît le client.</block>
  <block id="9ec2999256fe568cd596b42e7da2cc39" category="list-text">Pour mettre la base de données dans un état cohérent, le processus de l'enregistreur d'arrière-plan vérifie périodiquement la présence de pages sales dans le tampon partagé. Il purge ensuite les données sur les fichiers de données stockés sur des volumes NetApp ou des LUN.</block>
  <block id="5c852dd8ba7215c01dfde8e98f6c46c6" category="list-text">Le processus CheckPointer s'exécute également périodiquement (moins fréquemment que le processus d'arrière-plan) et empêche toute modification des tampons. Il signale au processus d'écriture WAL d'écrire et de vider l'enregistrement de point de contrôle à la fin des journaux WAL stockés sur le disque NetApp. Il signale également au processus d'écriture d'arrière-plan d'écrire et de vider toutes les pages sales sur le disque.</block>
  <block id="0a7b1215fd0b9621d4d7300f88b2906c" category="doc">Logiciels de protection des données</block>
  <block id="e265011e47d11db43ee112fd2fdc9d5b" category="paragraph">Le plug-in NetApp SnapCenter pour les bases de données PostgreSQL, associé aux technologies Snapshot et NetApp FlexClone, vous offre les avantages suivants :</block>
  <block id="4dcdaba06a92b8fecfdc823643a71723" category="list-text">Sauvegarde et restauration rapides.</block>
  <block id="aee746a577a1baebdc33197fb5f3a279" category="list-text">Clones compacts.</block>
  <block id="b96bb0cd2ebc0389b6670602ac80d983" category="list-text">La possibilité de mettre en place un système de reprise d'activité rapide et efficace.</block>
  <block id="9e060ad00fced94f2616dd71fbc49f76" category="paragraph">Vous pouvez choisir les partenaires de sauvegarde premium de NetApp, tels que Veeam Software et CommVault dans les circonstances suivantes :</block>
  <block id="0ee17b3b55ea2b0af3d90985bc347775" category="list-text">Gestion des workloads dans un environnement hétérogène</block>
  <block id="88fbde7bbe0274fbe9e7ce01c563d03c" category="list-text">Stocker les sauvegardes dans le cloud ou sur bande pour les conserver à long terme</block>
  <block id="445e3e0cce7f959696dde65b3be27843" category="list-text">Prise en charge d'un large éventail de versions et de types de systèmes d'exploitation</block>
  <block id="21c5d67cc22beaf7d7c9c84c8deaabbe" category="paragraph">Le plug-in SnapCenter pour PostgreSQL est un plug-in pris en charge par la communauté et la configuration et la documentation sont disponibles sur le magasin d'automatisation NetApp. Grâce à SnapCenter, l'utilisateur peut sauvegarder la base de données, cloner et restaurer les données à distance.</block>
  <block id="7d334ca369e4a752ec91b1503183f0ed" category="summary">Pour SAP HANA et AnyDB</block>
  <block id="1ac73696f4529e3901b0d4e5430365cb" category="doc">SAP HANA et SAP avec AnyDB</block>
  <block id="2c1b27a986b5e37a810d61f72b23ee4b" category="paragraph">Les bonnes pratiques de configuration, de gestion et d'automatisation des solutions SAP sont disponibles sur la page Solutions SAP de NetApp.</block>
  <block id="6c92285fa6d3e827b198d120ea3ac674" category="inline-link-macro">ici</block>
  <block id="ee1e67308b27672a8f54eace4c615a98" category="paragraph">Veuillez cliquer sur <block ref="c95e4a3e1de9e00fefc4bf8a7ce42893" category="inline-link-macro-rx"></block> pour plus.</block>
  <block id="beb3ca55ed0a53a38a2b97540b05d6e4" category="summary">Microsoft SQL Server sur ONTAP</block>
  <block id="7636ae91f443b605f05bed59d7d57a02" category="doc">Reprise sur incident de Microsoft SQL Server</block>
  <block id="810304d54e0a61663cfc457b0894037b" category="paragraph">NetApp propose différentes approches pour augmenter la disponibilité des données en cas de défaillance matérielle, logicielle ou de site.</block>
  <block id="9c1e9d82d3220658621f72dca978adb0" category="section-title">SnapMirror NetApp</block>
  <block id="46983273062fdc8ce8561a9ce89cdc5b" category="paragraph">La technologie NetApp SnapMirror offre une solution rapide et flexible pour les entreprises qui met en miroir ou répliquent des données sur des réseaux LAN et WAN. La technologie SnapMirror transfère uniquement les blocs de données de 4 Ko modifiés vers la destination après le transfert de base initial, ce qui réduit considérablement les besoins en bande passante réseau. SnapMirror offre une réplication asynchrone au niveau du volume basée sur un intervalle de mise à jour de réplication configuré.
Voici les recommandations pour SnapMirror pour SQL Server :</block>
  <block id="5f3bfe8f92842bdc2f9455d4102f2531" category="list-text">Si CIFS est utilisé, le SVM de destination doit être membre du même domaine Active Directory dont le SVM source est membre, de sorte que les listes de contrôle d'accès (ACL) stockées dans les fichiers NAS ne soient pas interrompues pendant la reprise après un incident.</block>
  <block id="e0fd410ebdc68e7ca628bbca66b63ff4" category="list-text">L'utilisation de noms de volume de destination identiques aux noms de volume source n'est pas requise, mais peut faciliter la gestion du processus de montage des volumes de destination dans la destination. Si CIFS est utilisé, vous devez rendre l'espace de noms NAS de destination identique dans les chemins et la structure de répertoires vers l'espace de noms source.</block>
  <block id="14b01fb6bdbebef1f8a00c7f84926307" category="list-text">À des fins de cohérence, ne planifiez pas la mise à jour de SnapMirror à partir des contrôleurs. Cependant, activez SnapMirror Update depuis SnapCenter pour mettre à jour SnapMirror une fois la sauvegarde complète ou la sauvegarde du journal terminée.</block>
  <block id="18c6a681ea46e1ed394e092461bb53ef" category="list-text">Distribuez les volumes contenant des données SQL Server sur différents nœuds du cluster pour permettre à tous les nœuds de cluster de partager l'activité de réplication SnapMirror. Cette distribution optimise l'utilisation des ressources du nœud.</block>
  <block id="0a01e6837f5c691536f0b6cbdd0232ec" category="inline-link-macro">Tr-4015 : Guide de configuration et des meilleures pratiques de SnapMirror pour ONTAP 9</block>
  <block id="1cca1a3fad8c6dd7e2dadbd2aa08bf07" category="paragraph">Pour plus d'informations sur SnapMirror, reportez-vous à la section <block ref="64b916f792bad525a069a243c092b62e" category="inline-link-macro-rx"></block>.</block>
  <block id="3d4b417d78ff0ef4c84f0c043de24b10" category="doc">Sécurité de la base de données</block>
  <block id="77641f4a3e4406855e878235cbd89b87" category="doc">Configuration du processeur</block>
  <block id="a51adad5719779145ac252822e328611" category="section-title">Hyperthreading</block>
  <block id="fe520b79816bad6a21fbebcb205c7ca9" category="paragraph">L'hyperthreading est la mise en œuvre propriétaire d'Intel pour le multithreading simultané (SMT), qui améliore la parallélisation des calculs (multitâche) réalisés sur des microprocesseurs x86.</block>
  <block id="005f484c2235e04f39d2e69256147281" category="paragraph">Le matériel qui utilise l'hyperthreading permet aux CPU de l'hyperthread logique d'apparaître comme des CPU physiques au système d'exploitation. SQL Server voit ensuite les CPU physiques, que le système d'exploitation présente, et peut donc utiliser les processeurs hyperthreading.</block>
  <block id="673c216e20d1cf8827f347c01dace664" category="paragraph">La mise en garde ici est que chaque version de SQL Server a ses propres limites sur la puissance de calcul qu'il peut utiliser. Pour plus d'informations, voir calcul des limites de capacité par édition de SQL Server.</block>
  <block id="932a9271c08db114962ce3791480f371" category="paragraph">Il existe deux grandes écoles de pensée lors de l'octroi de licences SQL Server. Le premier est connu sous le nom de modèle serveur + licence d'accès client (CAL) ; le second est le modèle par cœur de processeur. Bien que vous puissiez accéder à toutes les fonctionnalités du produit disponibles dans SQL Server avec la stratégie serveur + CAL, il existe une limite matérielle de 20 cœurs de processeur par socket. Même si vous disposez de SQL Server Enterprise Edition + CAL pour un serveur avec plus de 20 cœurs de processeur par socket, l'application ne peut pas utiliser tous ces cœurs à la fois sur cette instance. La figure illustre le message du journal SQL Server après le démarrage, indiquant l'application de la limite de cœur.</block>
  <block id="d06fce44fdcf20791141e7585205a477" category="section-title">Les entrées de journal indiquent le nombre de cœurs utilisés après le démarrage de SQL Server.</block>
  <block id="cf0e2551e639758cc3c4d82df655eccd" category="inline-link-macro">SQL Server 2022 : une plateforme de données moderne</block>
  <block id="809c9e1f6ce0bc82bf42fae361c6f43e" category="paragraph">Par conséquent, pour utiliser tous les CPU, vous devez utiliser la licence par cœur de processeur. Pour plus d'informations sur les licences SQL Server, reportez-vous à la section <block ref="457abfaf1083b1cbfc49f2783069c6cd" category="inline-link-macro-rx"></block>.</block>
  <block id="cb8d56a3511d402b7355db8502a54c5a" category="section-title">Affinité CPU</block>
  <block id="884be48d06a17be095fb51de089dfc89" category="paragraph">Il est peu probable que vous ayez à modifier les valeurs par défaut d'affinité du processeur, sauf si vous rencontrez des problèmes de performances, mais il est toujours utile de comprendre ce qu'elles sont et comment elles fonctionnent.</block>
  <block id="74f896768ee487acfd4c42370c202bed" category="paragraph">SQL Server prend en charge l'affinité de processeur par deux options :</block>
  <block id="cb315fb2b62c836ba51357d46f2e8c3f" category="list-text">Masque d'affinité du processeur</block>
  <block id="cb00a2408ea648cf85edfd7dbb23fbe0" category="list-text">Masque d'E/S d'affinité</block>
  <block id="14ad08466dec6635067b988a82e91a8e" category="paragraph">SQL Server utilise tous les processeurs disponibles dans le système d'exploitation (si la licence par processeur est choisie). Il crée des planificateurs sur toutes les CPU pour optimiser l'utilisation des ressources pour une charge de travail donnée. En mode multitâche, le système d'exploitation ou d'autres applications du serveur peuvent basculer les threads de traitement d'un processeur à un autre. SQL Server est une application qui consomme beaucoup de ressources et qui peut donc affecter les performances dans ce cas. Pour minimiser l'effet, vous pouvez configurer les processeurs de sorte que toute la charge SQL Server soit dirigée vers un groupe de processeurs présélectionné. Pour ce faire, utilisez le masque d'affinité du processeur.</block>
  <block id="28a51b601de21080b76fe2d8b2ec8101" category="paragraph">L'option de masque d'E/S d'affinité lie les E/S de disque SQL Server à un sous-ensemble de processeurs. Dans les environnements OLTP SQL Server, cette extension peut améliorer les performances des threads SQL Server exécutant des opérations d'E/S.</block>
  <block id="49e103832576f4486179df8868372d17" category="section-title">Degré maximal de parallélisme (MAXDOP)</block>
  <block id="f7e9f8e341a301aec4560db108b93020" category="paragraph">Par défaut, SQL Server utilise tous les CPU disponibles pendant l'exécution de la requête (si la licence par processeur est choisie).</block>
  <block id="9bdcdbe52ea41cf96b314b7b7671bd2a" category="paragraph">Bien que cela soit idéal pour les requêtes volumineuses, il peut causer des problèmes de performances et limiter la simultanéité. Une meilleure approche consiste à limiter le parallélisme au nombre de cœurs physiques dans un seul socket de processeur. Par exemple, sur un serveur doté de deux sockets CPU physiques avec 12 cœurs par socket, quel que soit l'hyperthreading, MAXDOP doit être défini sur 12. MAXDOP ne peut pas restreindre ou dicter quelle CPU doit être utilisée. Elle limite le nombre de processeurs pouvant être utilisés par une seule requête de lot.</block>
  <block id="1a6b79859b80796a108bd348f98856f6" category="admonition">*NetApp recommande* pour DSS comme les data warehouses, commencez par ce paramètre à 50 ou ainsi et réglez-le à la hausse ou à la baisse, selon le cas. Assurez-vous de mesurer les requêtes critiques dans votre application et de les ajuster si nécessaire.</block>
  <block id="a99f7ebb3b0f5b0ecea93ed586b2a17d" category="section-title">Nombre max. De threads de travail</block>
  <block id="aff27140f50a549b1331add8d5025f7e" category="paragraph">L'option max worker threads permet d'optimiser les performances lorsqu'un grand nombre de clients sont connectés à SQL Server.</block>
  <block id="aefc7f2ee96effbbbe49e6ece6d2f72a" category="paragraph">Normalement, un thread de système d'exploitation distinct est créé pour chaque requête. Si des centaines de connexions simultanées sont effectuées à SQL Server, un thread par requête consomme de grandes quantités de ressources système. L'option max worker threads permet d'améliorer les performances en permettant à SQL Server de créer un pool de threads de travail pour traiter un plus grand nombre de requêtes.</block>
  <block id="decd79137325e1efbc7b994f946ea24f" category="paragraph">La valeur par défaut est 0, ce qui permet à SQL Server de configurer automatiquement le nombre de threads de travail au démarrage. Cela fonctionne pour la plupart des systèmes. Max worker threads est une option avancée qui ne doit pas être modifiée sans l'aide d'un administrateur de base de données expérimenté (DBA).</block>
  <block id="030a270970f70c1bd91d3689b6f95f3f" category="inline-link-macro">Configurez l'option Configuration du serveur max worker threads</block>
  <block id="2a0c648df721b9bc2643d59c4a3a310a" category="paragraph">Quand devez-vous configurer SQL Server pour utiliser davantage de threads de travail ? Si la longueur moyenne de la file d'attente de travail de chaque planificateur est supérieure à 1, vous pouvez bénéficier de l'ajout de threads supplémentaires au système, mais uniquement si la charge n'est pas liée au processeur ou si d'autres files d'attente importantes sont en cours. Si l'une ou l'autre de ces opérations se produit, l'ajout de threads n'est pas utile, car ils finissent par attendre les autres goulets d'étranglement du système. Pour plus d'informations sur le nombre maximal de threads de travail, reportez-vous à la section <block ref="77c391df5f9f06cdf367c2a7314ce351" category="inline-link-macro-rx"></block>.</block>
  <block id="29d04e616d2293c4c7538dd6226feac5" category="section-title">Configuration du nombre maximal de threads de travail à l'aide de SQL Server Management Studio.</block>
  <block id="5962130d833e0408cf58a87e342bc1f9" category="doc">Fichiers tempdb Microsoft SQL Server</block>
  <block id="625156cc6cef9a3c56b1b535579bd2c9" category="paragraph">NetApp recommande de gonfler de manière proactive les fichiers tempdb à leur pleine taille pour éviter la fragmentation du disque.</block>
  <block id="ca75041d415f4dafabb49b7f06b634ed" category="paragraph">Les conflits de pages peuvent se produire sur les pages GAM (Global allocation map), SGAM (Global allocation map) ou PFS (page Free Space) lorsque SQL Server doit écrire sur des pages système spéciales pour allouer de nouveaux objets. Les loquets protègent (verrouillent) ces pages en mémoire. Sur une instance SQL Server occupée, l'obtention d'un verrou sur une page système dans tempdb peut prendre un certain temps. Cela ralentit les temps d'exécution des requêtes et est appelé conflit de type LATCH. Consultez les meilleures pratiques suivantes pour la création de fichiers de données tempdb :</block>
  <block id="44dbc82801d84781083ed9e23b63be00" category="list-text">Pour &lt; ou = jusqu'à 8 cœurs : fichiers de données tempdb = nombre de cœurs</block>
  <block id="6203fcdbdad10bb603fd00edd2f0fcf5" category="list-text">Pour plus de 8 cœurs : 8 fichiers de données tempdb</block>
  <block id="b9f341e4fb0e6b384aa7ec0b5c33f964" category="paragraph">L'exemple de script suivant modifie tempdb en créant huit fichiers tempdb et en déplaçant tempdb vers le point de montage<block ref="ae6fbe62f3ddc46fa9a9885244d23675" prefix=" " category="inline-code"></block> Pour SQL Server 2012 et versions ultérieures.</block>
  <block id="0424163d6b24f29436021dfd7072863b" category="paragraph">À partir de SQL Server 2016, le nombre de cœurs de CPU visibles par le système d'exploitation est automatiquement détecté lors de l'installation et, en fonction de ce nombre, SQL Server calcule et configure le nombre de fichiers tempdb requis pour des performances optimales.</block>
  <block id="1c5b37437282a3648dde78afd914e452" category="doc">Présentation de Microsoft SQL Server</block>
  <block id="9aa5016539f88d8f1972a16ce9babd34" category="paragraph">SQL Server constitue le socle de la plateforme de données Microsoft. Il apporte les performances stratégiques grâce aux technologies in-memory et permet d'obtenir plus rapidement des informations sur toutes les données, qu'elles soient sur site ou dans le cloud.</block>
  <block id="8133a02d7327679696821fb31b105177" category="paragraph">Microsoft SQL Server s'appuie sur les fonctionnalités stratégiques des versions précédentes pour offrir des performances, une disponibilité et une gestion exceptionnelles pour les applications stratégiques. Le système de stockage joue un rôle clé dans les performances globales d'une base de données SQL Server. NetApp propose plusieurs produits qui permettent à votre base de données SQL Server de fournir des performances d'entreprise tout en fournissant des outils de pointe pour la gestion de votre environnement.</block>
  <block id="0bdfc026961d516d3d473152b4b6a87e" category="section-title">But et portée</block>
  <block id="d0554e23b25bb82082a0cd9eaf810d0f" category="paragraph">Cette section décrit les meilleures pratiques et présente des conseils de conception pour déployer SQL Server sur des systèmes de stockage NetApp exécutant le logiciel NetApp ONTAP. Vous pouvez ainsi déployer le stockage de manière efficace et efficace, ainsi que planifier la protection et la conservation des données de bout en bout. Le périmètre de ce guide se limite aux instructions de conception technique basées sur les principes de conception et les normes privilégiées que NetApp recommande pour l'infrastructure de stockage lors du déploiement de SQL Server. La mise en œuvre de bout en bout ne fait pas partie du champ d'application du présent rapport.</block>
  <block id="cf4cab9c6fd24025b34dfcae06e9b6fc" category="paragraph">Les meilleures pratiques et recommandations décrites dans ce guide permettent aux architectes SQL Server et aux administrateurs de stockage NetApp de planifier un environnement SQL Server hautement disponible et facile à gérer et de répondre à des SLA rigoureux. NetApp suppose que le lecteur a une connaissance pratique des éléments suivants :</block>
  <block id="9801f873fe2232da0de3cbab00483bfb" category="list-text">Logiciel NetApp ONTAP</block>
  <block id="3b5b2ca12603a36517ce602ffe47361c" category="list-text">NetApp SnapCenter en tant que logiciel de sauvegarde, qui inclut :</block>
  <block id="36a92a010308100e1efc10d9eb98c369" category="list-text">Plug-in SnapCenter pour Microsoft Windows</block>
  <block id="ec51578d7d8f930329548bf3d00d7038" category="list-text">Plug-in SnapCenter pour SQL Server</block>
  <block id="a6d698a68f555339f6e91957f636ad69" category="list-text">Architecture et administration de Microsoft SQL Server</block>
  <block id="697ea025ecb303d4f40d1bf3a8b4bde0" category="inline-link-macro">Matrice d'interopérabilité NetApp (IMT)</block>
  <block id="c02eaaaf0eed9e51c3a9e1e9ae8b9147" category="paragraph">Pour connaître la compatibilité de la configuration sur l'ensemble de la pile NetApp, reportez-vous au <block ref="ea0e6fe442c1f7a042a8853ffcc2b382" category="inline-link-macro-rx"></block>.</block>
  <block id="fbd4c4f9516af91c6c3cb5fa35fb5720" category="doc">Considérations relatives au stockage Microsoft SQL Server</block>
  <block id="8c2a9e7195a263b5d79d397f5c6a9f68" category="paragraph">L'association des solutions de stockage NetApp et de Microsoft SQL Server permet de concevoir des systèmes de stockage de base de données d'entreprise capables de répondre aux exigences des applications les plus exigeantes.</block>
  <block id="8136e237a15b0f72e5d7a60392225d17" category="paragraph">Pour optimiser ces deux technologies, il est essentiel de comprendre le modèle et les caractéristiques d'E/S de SQL Server. Une infrastructure de stockage bien conçue pour une base de données SQL Server supporte les performances de SQL Server et la gestion de l'infrastructure SQL Server. Une bonne disposition du stockage permet également de réussir le déploiement initial et d'assurer une croissance progressive de l'environnement à mesure que l'entreprise se développe.</block>
  <block id="3da07c62fca4dd242f7ffcfcf72998be" category="section-title">Conception du stockage des données</block>
  <block id="9e45010900186b3cbbe04f954a6f3562" category="paragraph">Pour les bases de données SQL Server qui n'utilisent pas SnapCenter pour effectuer des sauvegardes, Microsoft recommande de placer les données et les fichiers journaux sur des disques distincts. Pour les applications qui mettent à jour et demandent simultanément des données, le fichier journal est très gourmand en écriture et le fichier de données (selon votre application) consomme beaucoup de ressources en lecture/écriture. Pour la récupération des données, le fichier journal n'est pas nécessaire. Par conséquent, les demandes de données peuvent être satisfaites à partir du fichier de données placé sur son propre disque.</block>
  <block id="df018ea4abdb71f91802ea1d4fb0fb37" category="inline-link-macro">Placez les fichiers de données et les fichiers journaux sur des lecteurs distincts</block>
  <block id="f2f25c68d67c561be1926b4b06e676b0" category="paragraph">Lorsque vous créez une nouvelle base de données, Microsoft recommande de spécifier des disques distincts pour les données et les journaux. Pour déplacer des fichiers après la création de la base de données, la base de données doit être mise hors ligne. Pour plus d'informations sur les recommandations de Microsoft, consultez la section <block ref="04fab8828edf0d2e95eff3c4f124b372" category="inline-link-macro-rx"></block>.</block>
  <block id="d5350d8759b1ec84607e47908809058e" category="section-title">64 bits</block>
  <block id="b8212b86fca1dcaeb0438529a03212c3" category="paragraph">Les agrégats sont les principaux conteneurs de stockage pour les configurations de stockage NetApp. Ils contiennent un ou plusieurs groupes RAID composés à la fois de disques de données et de disques de parité. NetApp a effectué plusieurs tests de caractérisation des charges de travail d'E/S à l'aide d'agrégats partagés et dédiés, avec des fichiers de données et des fichiers journaux de transactions séparés. Les tests montrent qu'un grand agrégat avec un plus grand nombre de piles et de groupes RAID optimise et améliore les performances du stockage et est plus facile à gérer pour les administrateurs pour deux raisons :</block>
  <block id="5f9196be7c85ebe3a38375ace1f3a345" category="list-text">Un grand agrégat rend les capacités d'E/S de toutes les piles de disques disponibles pour tous les fichiers.</block>
  <block id="77f1d6b9cbcaf3663f6bdd19a821e773" category="list-text">Un seul grand agrégat permet d'optimiser l'utilisation de l'espace disque.</block>
  <block id="63d9962fabe500361986d05317bd65a5" category="paragraph">Pour la haute disponibilité (HA), placer la réplique synchrone secondaire SQL Server Always On Availability Group sur une machine virtuelle de stockage (SVM) distincte dans l'agrégat. Pour la reprise sur incident, placez la réplication asynchrone sur un agrégat faisant partie d'un cluster de stockage distinct dans le site de reprise sur incident, le contenu étant répliqué à l'aide de la technologie NetApp SnapMirror. Pour des performances de stockage optimales, NetApp recommande de disposer d'au moins 10 % d'espace libre dans un agrégat.</block>
  <block id="c6f01c78bfe0a0a495cb5d3ed77824a9" category="section-title">Volumes</block>
  <block id="5ec65e803efce0f0779c59e4df9b2a71" category="paragraph">Les volumes NetApp FlexVol sont créés et résident dans des agrégats. De nombreux volumes peuvent être créés dans un seul agrégat, et chaque volume peut être étendu, réduit ou déplacé entre les agrégats sans temps d'indisponibilité pour les utilisateurs.</block>
  <block id="17fce39141e6fa457c789ce2c3239b0c" category="section-title">Considérations relatives à la conception des volumes</block>
  <block id="d1c9fdbcdbb8521971decf35c6d1c0c8" category="paragraph">Avant de créer une conception de volume de base de données, il est important de comprendre comment le modèle et les caractéristiques d'E/S SQL Server varient en fonction de la charge de travail et des exigences de sauvegarde et de restauration. Consultez les recommandations NetApp suivantes pour les volumes flexibles :</block>
  <block id="570f1006846b0d45ff44b4332b9b4d14" category="list-text">Utilisez des volumes flexibles pour stocker des fichiers de base de données SQL Server et éviter de partager des volumes entre des hôtes.</block>
  <block id="674343739e297abb52c536a453ebaad0" category="list-text">Utilisez des points de montage NTFS au lieu de lettres de lecteur pour dépasser la limite de 26 lettres de lecteur dans Windows. Lorsque vous utilisez des points de montage de volume, il est généralement recommandé de donner au libellé de volume le même nom que le point de montage.</block>
  <block id="d5fe4f7f1c47df1ec78c926d21498f73" category="list-text">Le cas échéant, configurez une règle de dimensionnement automatique de volume pour éviter les conditions de manque d'espace. 17 Guide des meilleures pratiques pour Microsoft SQL Server avec ONTAP © 2022 NetApp, Inc Tous droits réservés.</block>
  <block id="fdb3a973962ea77cf56d76e12cff8c7d" category="list-text">Activer la réallocation de lecture sur le volume lorsque le profil d'E/S de la base de données SQL Server comprend principalement des lectures séquentielles volumineuses, telles que les charges de travail du système d'aide à la décision. La fonctionnalité de réallocation de lecture optimise les blocs pour améliorer les performances.</block>
  <block id="3a9320cf27fb328f77ec6153273784d5" category="list-text">Si vous installez SQL Server sur un partage SMB, assurez-vous que Unicode est activé sur les volumes SMB/CIFS pour la création de dossiers.</block>
  <block id="08a6901e4e7b04d6170563bc57864093" category="list-text">Définissez la valeur de la réserve de copie Snapshot NetApp dans le volume sur zéro pour faciliter la surveillance sur le plan opérationnel.</block>
  <block id="156ce9adf6c474183396aa3cfb8f92f1" category="list-text">Désactivez les plannings de copie Snapshot™ de stockage et les stratégies de conservation. Utilisez plutôt SnapCenter pour coordonner les copies Snapshot des volumes de données SQL Server.</block>
  <block id="f2e00c12259a4bb11608f2a12fc8014a" category="list-text">Placez les bases de données système SQL Server sur un volume dédié ou un VMDK.</block>
  <block id="4176288dbc134524f79476ba4e57e3aa" category="list-text">Tempdb est une base de données système utilisée par SQL Server comme espace de travail temporaire, en particulier pour les opérations DBCC CHECKDB exigeantes en E/S. Par conséquent, placez cette base de données sur un volume dédié avec un jeu séparé de piles de disques. Dans les grands environnements dans lesquels le nombre de volumes est un défi, vous pouvez consolider tempdb en un nombre réduit de volumes et le stocker dans le même volume que les autres bases de données système après une planification minutieuse. La protection des données pour tempdb n'est pas une priorité élevée car cette base de données est recréée à chaque redémarrage de SQL Server.</block>
  <block id="57eda1aa66778bf3c77caa0294652ba8" category="list-text">Placez les fichiers de données utilisateur (.mdf) sur des volumes distincts car ils sont des workloads de lecture/écriture aléatoires. Il est courant de créer des sauvegardes du journal de transactions plus fréquemment que les sauvegardes de bases de données. Pour cette raison, placez les fichiers journaux de transactions (.ldf) sur un volume distinct ou un fichier VMDK à partir des fichiers de données afin de pouvoir créer des plannings de sauvegarde indépendants pour chacun d'eux. Cette séparation isole également les E/S d'écriture séquentielle des fichiers journaux des E/S de lecture/écriture aléatoires des fichiers de données et améliore considérablement les performances de SQL Server.</block>
  <block id="b26e74ed6e2892c7e2bb95e414d460c6" category="section-title">LUN</block>
  <block id="b703a2ceaabee81dd9dfcfb3a4b738ee" category="list-text">Assurez-vous que les fichiers de base de données utilisateur et le répertoire des journaux pour stocker la sauvegarde des journaux se trouvent sur des volumes distincts afin d'empêcher la règle de conservation d'écraser les snapshots lorsqu'ils sont utilisés avec la technologie SnapVault.</block>
  <block id="152bb9192ea87919eda3b4f97fd4e1bf" category="list-text">Assurez-vous que les bases de données SQL Server résident sur des LUN distincts des LUN qui ne disposent pas de fichiers de base de données, tels que les fichiers de recherche en texte intégral.</block>
  <block id="e2faf723544ceb1ea01ba41cef2d633a" category="list-text">Le placement de fichiers secondaires de base de données (dans le cadre d'un groupe de fichiers) sur des volumes distincts améliore les performances de la base de données SQL Server. Cette séparation est valide uniquement si le fichier .mdf de la base de données ne partage pas son LUN avec d'autres fichiers .mdf.</block>
  <block id="ae72f885471636cbfd0dbe902ddf24e1" category="list-text">Si vous créez des LUN à l'aide de DiskManager ou d'autres outils, assurez-vous que la taille de l'unité d'allocation est définie sur 64 Ko pour les partitions lors du formatage des LUN.</block>
  <block id="ac4782a9243acaaff52164f9e47417d5" category="inline-link-macro">Microsoft Windows et MPIO natif conformément aux meilleures pratiques ONTAP pour les SAN modernes</block>
  <block id="934e206705ddafc720e4a8f25a4acded" category="list-text">Voir la <block ref="95506eaa4fca841adc20747ae4650d10" category="inline-link-macro-rx"></block> Pour appliquer la prise en charge des chemins d'accès multiples sur Windows aux périphériques iSCSI dans les propriétés MPIO.</block>
  <block id="31a8d85b6a44cffc2c7dfc6387696f31" category="section-title">Répertoire du journal</block>
  <block id="973781a026becacffaae9fd5fd5c2b7b" category="paragraph">Le répertoire des journaux est spécifié dans SQL Server pour stocker les données de sauvegarde du journal de transactions au niveau de l'hôte. Si vous utilisez SnapCenter pour sauvegarder les fichiers journaux, chaque hôte SQL Server utilisé par SnapCenter doit disposer d'un répertoire de journaux hôte configuré pour effectuer des sauvegardes de journaux. SnapCenter dispose d'un référentiel de base de données. Les métadonnées liées aux opérations de sauvegarde, de restauration ou de clonage sont donc stockées dans un référentiel de base de données central.</block>
  <block id="29766ed5967263787fface0a4ad3396f" category="paragraph">La taille du répertoire de journaux hôte est calculée comme suit :
Taille du répertoire des journaux hôtes = ( (taille LDF maximale de la base de données x taux de modification quotidien du journal %) x (rétention des snapshots) ÷ (1 - espace de surcharge de la LUN %)
La formule de dimensionnement du répertoire des journaux hôte suppose un espace supplémentaire de 10 % pour les LUN</block>
  <block id="31333b887781902e13c263570523ddc1" category="paragraph">Placez le répertoire des journaux sur un volume ou une LUN dédié. La quantité de données dans le répertoire du journal hôte dépend de la taille des sauvegardes et du nombre de jours pendant lesquels les sauvegardes sont conservées. SnapCenter n'autorise qu'un seul répertoire de journaux hôte par hôte SQL Server. Vous pouvez configurer les répertoires de journaux hôtes dans SnapCenter --&gt; hôte --&gt; configurer le plug-in.</block>
  <block id="e815059019027c04aa969a50787d5b34" category="paragraph">*NetApp recommande* ce qui suit pour un répertoire de journaux hôte :</block>
  <block id="07ae4edb1ccfbfe1f5da6006c95ee4a9" category="list-text">Assurez-vous que le répertoire du journal de l'hôte n'est partagé par aucun autre type de données pouvant potentiellement corrompre les données du snapshot de sauvegarde.</block>
  <block id="991bd1f492a593453f65c2a23c1f1612" category="list-text">Ne placez pas de bases de données utilisateur ou de bases de données système sur un LUN qui héberge des points de montage.</block>
  <block id="bdfdf6f1492d7a7beac0bce2c4109f95" category="list-text">Créez le répertoire des journaux hôtes sur le volume FlexVol dédié sur lequel SnapCenter copie les journaux de transactions.</block>
  <block id="7b01578e73f5081fecdcc6dedf28aa3c" category="list-text">Utilisez les assistants SnapCenter pour migrer les bases de données vers le stockage NetApp de sorte que les bases de données soient stockées dans des emplacements valides, ce qui permet de réaliser les opérations de sauvegarde et de restauration SnapCenter. N'oubliez pas que le processus de migration est disruptif et peut mettre les bases de données hors ligne pendant la migration.</block>
  <block id="b2d0e2f60ee139155b728ef6933efe7c" category="list-text">Les conditions suivantes doivent être en place pour les instances de cluster de basculement (FCI) de SQL Server :</block>
  <block id="863fda0972208e1e15d0c4a16d6915af" category="list-text">Si vous utilisez une instance de cluster de basculement, la LUN du répertoire de journalisation de l'hôte doit être une ressource de disque de cluster dans le même groupe de cluster que l'instance SQL Server en cours de sauvegarde SnapCenter.</block>
  <block id="ddb1104e1e71caabad3e7639c7675af8" category="list-text">Si vous utilisez une instance de cluster de basculement, les bases de données utilisateur doivent être placées sur des LUN partagées qui sont des ressources de cluster de disques physiques affectées au groupe de clusters associé à l'instance SQL Server.</block>
  <block id="bca5f9a18696e080113088282fe481de" category="doc">Configuration de la mémoire Microsoft SQL Server</block>
  <block id="02578ec0e8ce2fbef37ca792fd20c289" category="section-title">Mémoire maximale du serveur</block>
  <block id="81dbc262a15fc545920141998ddd1c17" category="paragraph">L'option max. De mémoire du serveur définit la quantité maximale de mémoire que l'instance SQL Server peut utiliser.</block>
  <block id="c9fa383209ffc05f20049101298fec96" category="paragraph">Il est généralement utilisé si plusieurs applications s'exécutent sur le même serveur que SQL Server et que vous voulez vous assurer que ces applications disposent de suffisamment de mémoire pour fonctionner correctement.</block>
  <block id="1ceeb5f5f18aefbc39e34d0d3c7b7e1c" category="paragraph">Certaines applications utilisent uniquement la mémoire disponible au démarrage et ne demandent pas plus, même si nécessaire. C'est là que le paramètre de mémoire maximale du serveur entre en jeu.</block>
  <block id="6e345f11e9b2856a7ac40d6cf283606b" category="paragraph">Sur un cluster SQL Server avec plusieurs instances SQL Server, chaque instance peut être en concurrence pour des ressources. La définition d'une limite de mémoire pour chaque instance de SQL Server peut aider à garantir les meilleures performances pour chaque instance.</block>
  <block id="318b34a3511a1be6d179a73303da2077" category="admonition">*NetApp recommande* de laisser au moins 4 Go à 6 Go de RAM pour le système d'exploitation afin d'éviter les problèmes de performances.</block>
  <block id="cd151dbdf946ad6bd27e1d55ea1cd029" category="section-title">Réglage de la mémoire minimale et maximale du serveur à l'aide de SQL Server Management Studio.</block>
  <block id="2e0d4de7d927936246f5537ba48015d2" category="paragraph">L'utilisation de SQL Server Management Studio pour ajuster la mémoire minimale ou maximale du serveur nécessite un redémarrage du service SQL Server. Vous pouvez ajuster la mémoire du serveur à l'aide de Trantransaction SQL (T-SQL) à l'aide du code suivant :</block>
  <block id="998c5e632fa0f987c20c182fc9322f67" category="section-title">Accès à la mémoire non uniforme</block>
  <block id="d92030bf70ac1cf1da30ce4c9ab2bbf6" category="paragraph">L'accès à la mémoire non uniforme (NUMA) est une méthode d'optimisation de l'accès à la mémoire qui permet d'augmenter la vitesse du processeur sans augmenter la charge sur le bus du processeur.</block>
  <block id="6ef102e61df24a50b0119558432f5623" category="paragraph">Si NUMA est configuré sur le serveur sur lequel SQL Server est installé, aucune configuration supplémentaire n'est requise car SQL Server est conscient de NUMA et fonctionne bien sur le matériel NUMA.</block>
  <block id="b3b5cd113ed637ebe6cb28eab322307a" category="section-title">Mémoire de création d'index</block>
  <block id="8e7c0153e4b7aa851a5a62683c378d1c" category="paragraph">L'option index create memory est une autre option avancée que vous ne devez généralement pas modifier.</block>
  <block id="631c6718cc62ad33b6e3b3b48d754569" category="paragraph">Il contrôle la quantité maximale de RAM initialement allouée pour la création d'index. La valeur par défaut de cette option est 0, ce qui signifie qu'elle est gérée automatiquement par SQL Server. Cependant, si vous rencontrez des difficultés à créer des index, envisagez d'augmenter la valeur de cette option.</block>
  <block id="8c91aa3f5264c57bd2d2e66bd70f2ad1" category="section-title">Mémoire min. Par requête</block>
  <block id="027d5a3eabe88aa0ab705b9c4a2fe096" category="paragraph">Lorsqu'une requête est exécutée, SQL Server tente d'allouer la quantité optimale de mémoire pour qu'elle s'exécute efficacement.</block>
  <block id="4c7836a7e63c3ecb3f6860ec19643561" category="paragraph">Par défaut, la mémoire minimale par paramètre de requête alloue &gt; ou = à 1024 Ko pour chaque requête à exécuter. Il est recommandé de laisser ce paramètre à la valeur par défaut 0 pour permettre à SQL Server de gérer dynamiquement la quantité de mémoire allouée aux opérations de création d'index. Cependant, si SQL Server dispose de plus de RAM que nécessaire pour fonctionner efficacement, les performances de certaines requêtes peuvent être améliorées si vous augmentez ce paramètre. Par conséquent, tant que la mémoire est disponible sur le serveur qui n'est pas utilisé par SQL Server, toute autre application ou le système d'exploitation, l'augmentation de ce paramètre peut aider à améliorer les performances globales de SQL Server. Si aucune mémoire disponible n'est disponible, l'augmentation de ce paramètre peut nuire aux performances globales.</block>
  <block id="d2a88da9a0fcc96168f8f051909d5599" category="section-title">Extensions de pool de mémoire tampon</block>
  <block id="11a3fdcfeb0715eaf26e855034f6ab9a" category="paragraph">L'extension du pool de mémoire tampon assure l'intégration transparente d'une extension NVRAM au pool de mémoire tampon du moteur de base de données afin d'améliorer considérablement le débit d'E/S.</block>
  <block id="c722da593d2f37b2c1ffc91a10c03dad" category="paragraph">L'extension de pool de mémoire tampon n'est pas disponible dans chaque édition de SQL Server. Il est disponible uniquement avec les éditions 64 bits SQL Server Standard, Business Intelligence et Enterprise.</block>
  <block id="df07548a7c164cbe93b68c4cbebbdcf8" category="paragraph">La fonctionnalité d'extension du pool de tampons étend le cache du pool de tampons à l'aide d'un stockage non volatile (généralement des disques SSD). L'extension permet au pool de mémoire tampon de prendre en charge un jeu de travail de base de données plus important, ce qui force la pagination des E/S entre la RAM et les disques SSD et décharge efficacement les petites E/S aléatoires des disques mécaniques vers les disques SSD. En raison de la faible latence et de l'amélioration des performances d'E/S aléatoires des disques SSD, l'extension du pool de tampons améliore considérablement le débit d'E/S.</block>
  <block id="54af95ef673718e2f8bf1cc873d8b3ce" category="paragraph">La fonction d'extension de pool de mémoire tampon offre les avantages suivants :</block>
  <block id="2c250b49dc6705e6d219cf2bf8d50bc5" category="list-text">Augmentation du débit d'E/S aléatoires</block>
  <block id="93dce890e8c62b3a651edb9098201e58" category="list-text">Latence d'E/S réduite</block>
  <block id="d7e49f79c1b78c9ead1e9541d2160307" category="list-text">Augmentation du débit de transaction</block>
  <block id="6643befb3c9dc2fbb68fe1107fe24842" category="list-text">Meilleures performances de lecture grâce à un pool de tampons hybride plus important</block>
  <block id="6609220b8670ffd627a3663b3beef46b" category="list-text">Une architecture de mise en cache qui peut tirer parti de la mémoire économique existante et future</block>
  <block id="471bda18bb94c589b421edccb0e402fe" category="paragraph">*NetApp recommande* de configurer les extensions de pool de mémoire tampon pour :</block>
  <block id="12810c53d2afa05bd2a75aa3c0c55592" category="list-text">Assurez-vous qu'une LUN à disques SSD (telle que NetApp AFF) est présentée à l'hôte SQL Server de manière à ce qu'elle puisse être utilisée comme disque cible d'extension de pool tampon.</block>
  <block id="824cfa1576a82f89ee0af13fb9f086dc" category="list-text">Le fichier d'extension doit être de la même taille ou plus grand que le pool de mémoire tampon.</block>
  <block id="c7e0d87e723625072015431887edf349" category="paragraph">L'exemple suivant montre une commande T-SQL pour configurer une extension de pool de mémoire tampon de 32 Go.</block>
  <block id="7ef20d2374bc8b734222e4ec2f0f3643" category="doc">Efficacité du stockage ONTAP avec Microsoft SQL Server</block>
  <block id="e5bc122522e9ae1409590d9944ec4421" category="paragraph">L'efficacité du stockage désigne la capacité de stocker et de gérer des données SQL Server d'une manière qui utilise le moins d'espace de stockage avec peu ou pas d'impact sur les performances globales du système.</block>
  <block id="2d3c9d6f03cd640c224f5daf9c2352b0" category="paragraph">SQL Server dispose également de fonctionnalités permettant de compresser et de gérer efficacement les données. SQL Server prend actuellement en charge deux types de compression de données : la compression de ligne et la compression de page.</block>
  <block id="181341700086c5e2f2259774b2aaa59c" category="inline-link-macro">Mise en œuvre de la compression de page</block>
  <block id="46c6aaf21d639d23d4f297a1f6922d9a" category="paragraph">La compression de ligne modifie le format de stockage des données. Par exemple, il change les entiers et les décimales au format de longueur variable au lieu de leur format natif de longueur fixe. Il remplace également les chaînes de caractères de longueur fixe par le format de longueur variable en éliminant les espaces vides. La compression de page implémente la compression de ligne et deux autres stratégies de compression (compression de préfixe et compression de dictionnaire). Vous trouverez plus de détails sur la compression de page dans <block ref="88eab602b149fe360da37498ad5cdeae" category="inline-link-macro-rx"></block>.</block>
  <block id="0d629ff07f9214182fa91977089ff029" category="paragraph">La compression des données est actuellement prise en charge dans les éditions entreprise, Développeur et évaluation de SQL Server 2008 et versions ultérieures. Bien que la compression puisse être effectuée par la base de données elle-même, elle est rarement observée dans un environnement SQL Server.</block>
  <block id="c6757fbc56df4ba20f0ef165aeb214d0" category="paragraph">Voici les recommandations pour la gestion de l'espace pour les fichiers de données SQL Server</block>
  <block id="46344e63db1ea2128cc47543b10a0f96" category="list-text">Utiliser le provisionnement fin dans les environnements SQL Server pour améliorer l'utilisation de l'espace et réduire les besoins globaux en stockage lorsque la fonctionnalité de garantie d'espace est utilisée.</block>
  <block id="924e1b131d6b3a2846efd1a81de8eac1" category="list-text">Utilisez le croissance automatique dans la plupart des configurations de déploiement courantes, car l'administrateur du stockage ne doit contrôler l'utilisation de l'espace dans l'agrégat.</block>
  <block id="13a233d96ce19e7530391105360d749b" category="list-text">Il est conseillé de ne pas activer la déduplication sur les volumes contenant des fichiers de données SQL Server, sauf si le volume contient plusieurs copies des mêmes données, telles que la restauration de la base de données à partir de sauvegardes sur un seul volume.</block>
  <block id="752d71c042ef775879f6db705ccf6b31" category="section-title">Réclamations d'espace</block>
  <block id="89f8656e4e33094d6011ef9aaa8fa8de" category="paragraph">La récupération d'espace peut être lancée régulièrement pour restaurer l'espace inutilisé d'une LUN. Avec SnapCenter, vous pouvez utiliser la commande PowerShell suivante pour démarrer la récupération d'espace.</block>
  <block id="aa864feb1e600aa376e91ac119da387b" category="paragraph">Si vous devez exécuter la récupération d'espace, ce processus doit être exécuté pendant les périodes de faible activité car il consomme initialement des cycles sur l'hôte.</block>
  <block id="a356c94dff23a233551ff221e74a144d" category="summary">Protection des données Microsoft SQL Server avec ONTAP</block>
  <block id="731c00fe6475fb22aece82ffa9d74ef3" category="paragraph">La protection des bases de données est essentielle pour toute entreprise. Plus la taille et le nombre de bases de données ont augmenté, plus il est essentiel de maintenir l'objectif de délai de restauration (RTO) et l'objectif de point de récupération (RPO).</block>
  <block id="5c014f8939a89da0166a347a0237cf4f" category="section-title">SnapCenter</block>
  <block id="2ddb1872f6c378e74cb7269e9de4c4e5" category="paragraph">SnapCenter est le logiciel NetApp de protection des données pour les applications d'entreprise.les bases de données SQL Server peuvent être rapidement et facilement protégées à l'aide du logiciel NetApp SnapCenter avec le plug-in pour SQL Server et le plug-in pour Microsoft Windows.</block>
  <block id="bdc6c0cf646d837838203c2980eba84a" category="paragraph">Ce produit permet la sauvegarde cohérente avec les applications, le clonage automatisé, ainsi que la restauration et la restauration de bases de données SQL Server, d'instances ou de groupes de disponibilité.</block>
  <block id="2450e19674db2a865555d3c04563e647" category="admonition">*NetApp recommande* d'utiliser SnapCenter pour créer des copies Snapshot.</block>
  <block id="1567bc0803275089d7cbc1ffc468158c" category="inline-link-macro">Tr-4714 : guide des meilleures pratiques pour SQL Server avec NetApp SnapCenter</block>
  <block id="17f58c1b5cb5feb5dcaf49ca87298c00" category="paragraph">Pour plus d'informations sur le plug-in SQL Server pour SnapCenter, reportez-vous à la section <block ref="c94de7812b9bc9ed76b3c4005974958d" category="inline-link-macro-rx"></block>.</block>
  <block id="91a7baba41dc4b5f958101b261cf179b" category="section-title">Protection de la base de données à l'aide de snapshots T-SQL</block>
  <block id="e158e137ead13fd14e064b875e45df20" category="paragraph">Dans SQL Server 2022, Microsoft a introduit les snapshots T-SQL qui offrent un avantage intégré par rapport à la méthode traditionnelle, qui n'a pas été facilement consommée par l'administrateur de base de données. À l'aide des API REST de ONTAP, vous pouvez appeler des commandes vers des volumes Snapshot.</block>
  <block id="02e19b2989ebddca9ad3778807bdc426" category="paragraph">Voici un exemple de flux de travail de sauvegarde :</block>
  <block id="17884d5a1cfc06145e718a49c8d6ac66" category="list-text">Figez une base de données à l'aide de la commande ALTER, afin d'effectuer un snapshot cohérent sur le stockage sous-jacent. Ensuite, vous pouvez dégeler la base de données et enregistrer le snapshot avec la commande BACKUP.</block>
  <block id="bd03301405e4dd8f2460ff1788765ac4" category="list-text">Réalisez des instantanés de plusieurs bases de données sur les volumes de stockage simultanément avec les nouvelles commandes de GROUPE DE SAUVEGARDE et de SERVEUR DE SAUVEGARDE.</block>
  <block id="a3b19be7df3ddff7295558d9934cd9b6" category="list-text">Effectuer des sauvegardes COMPLÈTES ou des sauvegardes COMPLÈTES COPY_ONLY. Ces sauvegardes sont également enregistrées dans msdb.</block>
  <block id="e2d06152222f63515f4b83229cb5444c" category="list-text">Effectuez une restauration instantanée à l'aide de sauvegardes de journaux effectuées avec l'approche de streaming standard après la sauvegarde COMPLÈTE des snapshots. Les sauvegardes différentielles en continu sont également prises en charge si nécessaire.</block>
  <block id="a7a2496066febda8d325e0964e434481" category="inline-link-macro">Documentation Microsoft à connaître sur les snapshots T-SQL</block>
  <block id="bf06f3f95c5b653499bb4ac53ba44c95" category="paragraph">Pour en savoir plus, voir <block ref="2ba8392a398067f6d2e5f6e4167e9d00" category="inline-link-macro-rx"></block>.</block>
  <block id="450eb6d84ec721a20f17b7778b24b457" category="doc">Workloads Microsoft SQL Server</block>
  <block id="764e07fc8f1f5e2d1b9fc63f83b88cbd" category="paragraph">La plate-forme de base de données SQL Server peut prendre en charge de nombreuses applications.</block>
  <block id="25343e3363b414e89943f5a4e46f51ad" category="paragraph">Avant de déployer SQL Server, vous devez comprendre les exigences de charge de travail de la base de données des applications prises en charge par vos instances SQL Server. Chaque application a des exigences variables en termes de capacité, de performance et de disponibilité. Par conséquent, chaque base de données doit être conçue de manière à répondre de manière optimale à ces exigences. De nombreuses entreprises classent les bases de données en plusieurs niveaux de gestion, en utilisant les exigences des applications pour définir des contrats de niveau de service. Les charges de travail SQL Server sont les suivantes :</block>
  <block id="c6a1c5843ff7b078079edf24beeea746" category="list-text">Les bases de données OLTP sont souvent également les bases de données les plus stratégiques d'une entreprise. Ces bases de données prennent généralement en charge les applications orientées client et sont considérées comme essentielles aux opérations stratégiques de l'entreprise. Les bases de données OLTP stratégiques et les applications qu'elles prennent en charge disposent souvent de SLA qui exigent des niveaux de performances élevés et sont sensibles à la dégradation des performances et à la disponibilité. Ils peuvent également être candidats pour toujours sur les clusters de basculement ou pour toujours sur les groupes de disponibilité. La combinaison E/S de ces types de bases de données se caractérise généralement par une lecture aléatoire de 75 à 90 % et une écriture de 25 à 10 %.</block>
  <block id="96d864d235bcd68e1ef22c2c49aef352" category="list-text">Les bases de données du système d'aide à la décision (DSS) peuvent également être appelées data warehouses. Ces bases de données jouent un rôle stratégique dans de nombreuses entreprises qui s'appuient sur l'analytique pour leurs activités. Ces bases de données sont sensibles à l'utilisation du CPU et aux opérations de lecture à partir du disque lors de l'exécution de requêtes. Dans de nombreuses entreprises, les bases de données DSS sont les plus critiques à la fin du mois, du trimestre et de l'année Cette charge de travail présente généralement un mélange d'E/S de lecture à 100 %.</block>
  <block id="da02a82356735ded82f6661108abe7ef" category="section-title">Analyse comparative</block>
  <block id="b9a9b34816c2e5ebaecb45f376b52bc3" category="paragraph">Le transaction Process Council (TPC) est une société à but non lucratif fondée pour définir des points de référence pour le traitement des transactions et les bases de données et pour diffuser des données objectives et vérifiables sur le rendement de PTC à l'industrie. Les tests TPC simulent des environnements informatiques complets dans lesquels un ensemble d'utilisateurs exécute des transactions sur des bases de données.</block>
  <block id="427af860f9733f0c5427a1408195bb2b" category="cell">Type de workload</block>
  <block id="54861efdd06fc309e1c9a420feff98eb" category="cell">Scénario</block>
  <block id="b130fcf8f0704ab887b72883b1eda2fa" category="cell">Rapport de lecture/écriture (pourcentages)</block>
  <block id="3edb9cc3b98f151feb21dbde6323e82a" category="cell">OLTP</block>
  <block id="69e16af975a283d07a422bdbcc70aa33" category="cell">TPC-C</block>
  <block id="b1e04731135df8a16c5318612ec8654e" category="cell">~75/25</block>
  <block id="106ff1baff5c32dc414f262e0a710c54" category="cell">TPC-E</block>
  <block id="48e219d97cf4619f212471bafd4215ec" category="cell">~90/10</block>
  <block id="e71f0182ed04206cb78bd7ceb2d9f4f3" category="cell">DSS</block>
  <block id="5788057170990ecf5e4d921f2853c2ae" category="cell">TPC-H.</block>
  <block id="492d66c3da61bdb9c69261aa1aa6f5f9" category="cell">~100/0</block>
  <block id="0737ef89fbed16c79fadf3568aad6ba0" category="inline-link-macro">HammerDB.com</block>
  <block id="45e5ae4569fb8a91cd5513654f31b764" category="paragraph">Bien que diverses options de génération de charges de travail soient disponibles, nous nous efforçons généralement de mesurer les performances des bases de données SQL Server lors du traitement de charges de travail transactionnelles, et nous utilisons les outils TPC-E de Microsoft ou TPC-H à l'aide de HammerDB (<block ref="af66be8e0834614cdd62ca4f34bc61ec" category="inline-link-macro-rx"></block>^). Les instructions détaillées sur l'utilisation de ces bancs d'essai spécifiques n'entrent pas dans le cadre de ce document.</block>
  <block id="1b1b4c822e9c1b28b845dcc038fec08e" category="doc">Fichiers de base de données et groupes de fichiers Microsoft SQL Server</block>
  <block id="381c0738613a6b6a27d1c14f223e99ba" category="paragraph">Une base de données SQL Server est une collection d'objets qui vous permet de stocker et de manipuler des données.</block>
  <block id="5306de2e4bff067a10c1c9b5aafe5920" category="paragraph">En théorie, SQL Server (64 bits) prend en charge 32,767 bases de données par instance et 524 272 To de taille de base de données, bien que l'installation standard comporte généralement plusieurs bases de données. Cependant, le nombre de bases de données que SQL Server peut gérer dépend de la charge et du matériel. Il n'est pas rare que des instances SQL Server hébergent des dizaines, des centaines, voire des milliers de petites bases de données.</block>
  <block id="9a3f42cec243006996ab4580d3ce5d56" category="paragraph">Chaque base de données se compose d'un ou plusieurs fichiers de données et d'un ou plusieurs fichiers journaux de transactions. Le journal de transactions stocke les informations sur les transactions de base de données et toutes les modifications de données effectuées par chaque session. Chaque fois que les données sont modifiées, SQL Server stocke suffisamment d'informations dans le journal de transactions pour annuler (revenir en arrière) ou rétablir (relire) l'action. Un journal de transactions SQL Server fait partie intégrante de la réputation de SQL Server en matière d'intégrité et de robustesse des données. Le journal de transactions est essentiel aux capacités d'atomicité, de cohérence, d'isolation et de durabilité (ACIDE) de SQL Server. SQL Server écrit dans le journal de transactions dès qu'une modification de la page de données se produit. Chaque instruction Data manipulation Language (DML) (par exemple, Select, INSERT, Update ou DELETE) est une transaction complète, et le journal de transactions s'assure que l'opération basée sur l'ensemble a lieu, en s'assurant de l'atomicité de la transaction.</block>
  <block id="cbe6958e46fbab53cdbdb9deb2d75938" category="paragraph">Chaque base de données possède un fichier de données primaire, qui, par défaut, possède l'extension .mdf. En outre, chaque base de données peut avoir des fichiers de base de données secondaires. Ces fichiers, par défaut, ont des extensions .ndf.</block>
  <block id="811b578b6dfbb4a4ca16ba0c0911e3df" category="paragraph">Tous les fichiers de base de données sont regroupés en groupes de fichiers. Un groupe de fichiers est l'unité logique, qui simplifie l'administration de la base de données. Ils permettent de séparer le placement d'objets logiques des fichiers de base de données physiques. Lorsque vous créez les tables d'objets de base de données, vous spécifiez dans quel groupe de fichiers elles doivent être placées sans vous soucier de la configuration du fichier de données sous-jacent.</block>
  <block id="3717596742d438a1c8e77b0aeb58fcec" category="paragraph">La possibilité de placer plusieurs fichiers de données dans le groupe de fichiers vous permet de répartir la charge entre les différents périphériques de stockage, ce qui contribue à améliorer les performances d'E/S du système. En revanche, le journal de transactions ne bénéficie pas des multiples fichiers car SQL Server écrit dans le journal de transactions de manière séquentielle.</block>
  <block id="c136ffb510a6a465d338ab0affc16641" category="paragraph">La séparation entre le placement d'objets logiques dans les groupes de fichiers et les fichiers de base de données physiques vous permet d'affiner la disposition des fichiers de base de données, en tirant le meilleur parti du sous-système de stockage. Par exemple, les éditeurs de logiciels indépendants qui déploient leurs produits auprès de différents clients peuvent ajuster le nombre de fichiers de base de données en fonction de la configuration d'E/S sous-jacente et de la quantité de données attendue au cours de la phase de déploiement. Ces modifications sont transparentes pour les développeurs d'applications, qui placent les objets de base de données dans les groupes de fichiers plutôt que dans les fichiers de base de données.</block>
  <block id="3ac46c2f04dec9d215efbe44d307a020" category="admonition">*NetApp recommande* d'éviter l'utilisation du groupe de fichiers principal pour tout autre objet que les objets système. La création d'un groupe de fichiers distinct ou d'un ensemble de groupes de fichiers pour les objets utilisateur simplifie l'administration de la base de données et la reprise après incident, en particulier dans le cas de bases de données volumineuses.</block>
  <block id="e3fc56c012a5d0c9f92dff9b49bcc80d" category="paragraph">Vous pouvez spécifier la taille initiale du fichier et les paramètres de croissance automatique au moment de la création de la base de données ou de l'ajout de nouveaux fichiers à une base de données existante. SQL Server utilise un algorithme de remplissage proportionnel lors du choix du fichier de données dans lequel il doit écrire des données. Elle écrit une quantité de données proportionnellement à l'espace libre disponible dans les fichiers. Plus l'espace libre dans le fichier est important, plus il traite d'écritures.</block>
  <block id="91d249de86b62102d6324849de2360fe" category="admonition">*NetApp recommande* que tous les fichiers d'un seul groupe de fichiers aient les mêmes paramètres de taille initiale et de croissance automatique, avec la taille de croissance définie en mégaoctets plutôt qu'en pourcentages. Cela permet à l'algorithme de remplissage proportionnel d'équilibrer uniformément les activités d'écriture entre les fichiers de données.</block>
  <block id="a39d73055b8dbbe112e749e7c3ededb8" category="paragraph">Chaque fois que SQL Server augmente les fichiers, il remplit l'espace nouvellement alloué dans les fichiers avec des zéros. Ce processus bloque toutes les sessions qui doivent écrire dans le fichier correspondant ou, en cas de croissance du journal de transactions, générer des enregistrements de journal de transactions.</block>
  <block id="54db492ee9e4d356cc8722d1f4126f77" category="paragraph">SQL Server met toujours à zéro le journal de transactions et ce comportement ne peut pas être modifié. Toutefois, vous pouvez contrôler si les fichiers de données sont mis à zéro en activant ou en désactivant l'initialisation instantanée des fichiers. L'activation de l'initialisation instantanée des fichiers permet d'accélérer la croissance des fichiers de données et de réduire le temps nécessaire à la création ou à la restauration de la base de données.</block>
  <block id="92208bd4d9c6fec3f7c1dedeca62e135" category="paragraph">Un petit risque de sécurité est associé à l'initialisation instantanée des fichiers. Lorsque cette option est activée, les parties non allouées du fichier de données peuvent contenir des informations provenant de fichiers OS précédemment supprimés. Les administrateurs de base de données peuvent examiner ces données.</block>
  <block id="2b222ad4000e6e966783fd7bc480180e" category="paragraph">Vous pouvez activer l'initialisation instantanée des fichiers en ajoutant l'autorisation sa_MANAGE_VOLUME_NAME, également appelée « effectuer une tâche de maintenance de volume » au compte de démarrage SQL Server. Vous pouvez le faire sous l'application de gestion des stratégies de sécurité locales (secpol.msc), comme indiqué dans la figure suivante. Ouvrez les propriétés de l'autorisation "effectuer une tâche de maintenance de volume" et ajoutez le compte de démarrage SQL Server à la liste des utilisateurs.</block>
  <block id="c622e0142ed854a10f98fcaa8b3487f8" category="paragraph">Pour vérifier si l'autorisation est activée, vous pouvez utiliser le code de l'exemple suivant. Ce code définit deux indicateurs de suivi qui forcent SQL Server à écrire des informations supplémentaires dans le journal d'erreurs, à créer une petite base de données et à lire le contenu du journal.</block>
  <block id="eba8c32bde087b29aaa1fe0d3bb32ef3" category="paragraph">Lorsque l'initialisation instantanée des fichiers n'est pas activée, le journal d'erreurs SQL Server indique que SQL Server met à zéro le fichier de données mdf en plus de mettre à zéro le fichier journal ldf, comme indiqué dans l'exemple suivant. Lorsque l'initialisation instantanée des fichiers est activée, elle affiche uniquement la remise à zéro du fichier journal.</block>
  <block id="cf346325be0652c6b6e9a04b9352bda3" category="paragraph">La tâche de maintenance du volume Perform est simplifiée dans SQL Server 2016 et est fournie ultérieurement en option lors du processus d'installation. Cette figure affiche l'option permettant d'accorder au service du moteur de base de données SQL Server le privilège d'effectuer la tâche de maintenance du volume.</block>
  <block id="638b283700120d26a838f9cb56fca59d" category="paragraph">Une autre option de base de données importante qui contrôle la taille des fichiers de base de données est la fonction de transmission automatique. Lorsque cette option est activée, SQL Server réduit régulièrement les fichiers de base de données, réduit leur taille et libère de l'espace dans le système d'exploitation. Cette opération consomme beaucoup de ressources et est rarement utile car les fichiers de base de données augmentent à nouveau après l'arrivée de nouvelles données dans le système. Autohrink ne doit jamais être activé sur la base de données.</block>
  <block id="3b6c913908f5844ccb31a4d3775cb34e" category="doc">Instance partagée Microsoft SQL Server par rapport à une instance dédiée</block>
  <block id="8b58192b54b5dc25444ace0536a34893" category="paragraph">Si une application possède de nombreux schémas et procédures stockées, elle peut affecter d'autres applications qui partagent une instance SQL Server.</block>
  <block id="0f85d9701e2ca305652e98c4181097e4" category="paragraph">Les ressources d'instance peuvent potentiellement être divisées ou verrouillées, ce qui entraîne des problèmes de performances pour d'autres applications pour lesquelles des bases de données sont hébergées sur l'instance SQL Server partagée.</block>
  <block id="37fbf1be337695452699ab9df948aa25" category="paragraph">La résolution des problèmes de performances peut s'avérer complexe, car vous devez déterminer quelle instance est la cause première. Cette question est comparée aux coûts des licences de systèmes d'exploitation et des licences SQL Server. Si les performances des applications sont primordiales, une instance dédiée est fortement recommandée.</block>
  <block id="c840abede1d1bcf78e7b3e30048c08b1" category="paragraph">Microsoft octroie des licences SQL Server par cœur au niveau du serveur et non par instance. C'est pourquoi les administrateurs de base de données sont tentés d'installer autant d'instances SQL Server que le serveur peut gérer pour réduire les coûts de licence, ce qui peut entraîner des problèmes de performances majeurs par la suite.</block>
  <block id="8a77155b45f0f2313c8ebf3d755463e5" category="admonition">*NetApp recommande* de choisir des instances SQL Server dédiées chaque fois que possible pour obtenir des performances optimales.</block>
  <block id="df7423789cebcf51de121abdae4181c3" category="summary">ONTAP et applications d'entreprise</block>
  <block id="6e1c62c6c9ec560b6b6cf47a8a8c83f8" category="summary">Oracle sur ONTAP à l'aide de Solaris</block>
  <block id="eaf36c98b91893b7f79bd5184a23d377" category="doc">Solaris</block>
  <block id="fb04d97697a77a89d0c3f5c09cd9ba47" category="paragraph">Rubriques de configuration spécifiques au système d'exploitation Solaris.</block>
  <block id="eefc332f1bd0a0aa81d0ce222989294f" category="section-title">Options de montage Solaris NFS</block>
  <block id="3e484486d582145f6d93ca5f8c71e228" category="paragraph">Le tableau suivant répertorie les options de montage Solaris NFS pour une seule instance.</block>
  <block id="6622c14ce91b6b9683505626a5eebdd2" category="cell">Type de fichier</block>
  <block id="f18f8a29d3e2281d374f43c78cf8f0f1" category="cell">Options de montage</block>
  <block id="a45543a64530673135f37ff8f9e95e69" category="cell">Accueil ADR</block>
  <block id="93a02670f814a2df6c830194a7244ea9" category="cell"><block ref="623bbf58c0b2f552d891a1c276bcc3bc" prefix="" category="inline-code"></block></block>
  <block id="80d52d74fd5c383b43f91575d569b42c" category="cell">Fichiers de contrôle
Fichiers de données
Journaux de reprise</block>
  <block id="73cf9d3814b8678439c37316096219b1" category="cell"><block ref="4c899c62e1ffeb12078476828bb54351" prefix="" category="inline-code"></block></block>
  <block id="72d33cb5c8b7ff5f7fd6a894094b0697" category="cell"><block ref="e1f651debac4f720c13ae930ff3ca14a" prefix="" category="inline-code"></block></block>
  <block id="3f490427e0bf55dc5c837e7b0d4c651c" category="cell"><block ref="b9ce73264210e6d0faa4115ce7525610" prefix="" category="inline-code"></block></block>
  <block id="b00b0ab6e8494db1a230bf3da7f42fd6" category="paragraph">L'utilisation de<block ref="545e1db0caafaa47ef37ce893c8fb92c" prefix=" " category="inline-code"></block> il a été prouvé qu'il améliorait considérablement les performances dans les environnements des clients en supprimant la latence associée à l'acquisition et au déblocage du système de stockage. Utilisez cette option avec soin dans les environnements dans lesquels de nombreux serveurs sont configurés pour monter les mêmes systèmes de fichiers et où Oracle est configuré pour monter ces bases de données. Bien qu'il s'agisse d'une configuration très inhabituelle, elle est utilisée par un petit nombre de clients. Si une instance est démarrée une seconde fois par erreur, une corruption des données peut se produire, car Oracle ne peut pas détecter les fichiers de verrouillage sur le serveur étranger. Les verrous NFS n'offrent pas de protection ; comme dans la version NFS 3, ils sont réservés à des conseils.</block>
  <block id="f480015b57b289b7dad1473ee5c55216" category="paragraph">Parce que le<block ref="545e1db0caafaa47ef37ce893c8fb92c" prefix=" " category="inline-code"></block> et<block ref="6698a391ee8befa0ca4646a86a1bbd66" prefix=" " category="inline-code"></block> les paramètres s'excluent mutuellement, il est important que<block ref="b6a2b868e8bebfc19497b406a12a1071" prefix=" " category="inline-code"></block> est présent dans le<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> classez-les de sorte que<block ref="6887bae4cda2d09a283a165c5be3f2b8" prefix=" " category="inline-code"></block> est utilisé. Sans ce paramètre, la mise en cache du tampon du système d'exploitation hôte est utilisée et les performances peuvent être affectées.</block>
  <block id="5171d5dfdc21b0941b921796638c10a9" category="paragraph">Le tableau suivant répertorie les options de montage de Solaris NFS RAC.</block>
  <block id="38e4e10abf410c92cd13e9cb4d54ae35" category="cell"><block ref="41a82b9bd64cb001f8913a34614b00d1" prefix="" category="inline-code"></block></block>
  <block id="e72cc50c204d77a1e47f0dcc8ad28a56" category="cell">Fichiers de contrôle
Fichiers de données
Journaux de reprise</block>
  <block id="98ee9e91a49f27abbd9dc831afa9fae5" category="cell"><block ref="f3a0fd4a197a2eae60d2ef904e5366f1" prefix="" category="inline-code"></block></block>
  <block id="f93eecf9c582d76d4e14292dc34c79f8" category="cell">CRS/vote</block>
  <block id="42c82995de255264e2a8690c3149c16a" category="cell">Ressource dédiée<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block></block>
  <block id="b71e04a676ec52e65edb52c138f2ad98" category="cell"><block ref="ac15a7c050732bc5169b6c17ce30f859" prefix="" category="inline-code"></block></block>
  <block id="273f714e976e2a709a6abe18d34e4b61" category="cell">Partagée<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block></block>
  <block id="2052aa052eee25e077178cd737b68f47" category="cell"><block ref="18f533bce293643d1004086db883dd03" prefix="" category="inline-code"></block></block>
  <block id="e9d3beba8b6a40da6f8074236ca3ddbc" category="paragraph">La principale différence entre les options de montage à instance unique et RAC est l'ajout de<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> et<block ref="6698a391ee8befa0ca4646a86a1bbd66" prefix=" " category="inline-code"></block> aux options de montage. Cet ajout a pour effet de désactiver la mise en cache du système d'exploitation hôte, ce qui permet à toutes les instances du cluster RAC d'avoir une vue cohérente de l'état des données. En utilisant le<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> paramètre<block ref="b6a2b868e8bebfc19497b406a12a1071" prefix=" " category="inline-code"></block> a le même effet que la désactivation de la mise en cache de l'hôte, il est toujours nécessaire de l'utiliser<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> et<block ref="6698a391ee8befa0ca4646a86a1bbd66" prefix=" " category="inline-code"></block>.</block>
  <block id="983c4ff0cb78851d95be06277152653f" category="paragraph">La raison<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block> est requis pour le partage<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block> Les déploiements visent à faciliter la cohérence des fichiers tels que les fichiers de mots de passe Oracle et les fichiers spfiles. Si chaque instance d'un cluster RAC possède un dédié<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block>, ce paramètre n'est pas requis.</block>
  <block id="5a11994cffaa4d0a9c8594d2223e3e96" category="section-title">Options de montage Solaris UFS</block>
  <block id="130c5ffb786e38c2e6648fd53593681a" category="paragraph">NetApp recommande fortement d'utiliser l'option de montage de journalisation afin de préserver l'intégrité des données en cas de panne de l'hôte Solaris ou d'interruption de la connectivité FC. L'option de montage de la journalisation préserve également l'utilisation des sauvegardes Snapshot.</block>
  <block id="516f7006de2e9b1f7f871d961db4a1ca" category="section-title">ZFS Solaris</block>
  <block id="a92c2c52c7360246c6da2b1169e0fa50" category="paragraph">Solaris ZFS doit être installé et configuré avec soin pour offrir des performances optimales.</block>
  <block id="c9208a3ad95d5ce3d9e2ba1839426251" category="section-title">mvector</block>
  <block id="c54b9977f43cf2f9a1aa7cb0de8fec22" category="paragraph">Solaris 11 a inclus un changement dans la façon dont il traite les opérations d'E/S importantes, ce qui peut entraîner de graves problèmes de performances sur les baies de stockage SAN. Le problème est décrit en détail dans le rapport de bogue NetApp 630173, « Solaris 11 ZFS Performance Regression ». " La solution est de changer un paramètre OS appelé<block ref="954f82599f7db0212a28fd448e03bdf3" prefix=" " category="inline-code"></block>.</block>
  <block id="17e692fa261653b11634297d15070637" category="paragraph">Exécutez la commande suivante en tant que root :</block>
  <block id="bc7e9b3c34345bf9ebe88467d6714f1b" category="paragraph">En cas de problème inattendu résultant de cette modification, vous pouvez facilement l'inverser en exécutant la commande suivante en tant que root :</block>
  <block id="6ff9f4444ac481652f4412b5e1623846" category="section-title">Noyau</block>
  <block id="78d06f587305b9e5481c8cf660693a61" category="paragraph">Pour des performances ZFS fiables, un noyau Solaris est nécessaire pour résoudre les problèmes d'alignement des LUN. Le correctif a été introduit avec le correctif 147440-19 dans Solaris 10 et avec SRU 10.5 pour Solaris 11. Utilisez uniquement Solaris 10 et versions ultérieures avec ZFS.</block>
  <block id="db8880d80ab20f2f01a010e5c454f7fb" category="section-title">Configuration du LUN</block>
  <block id="3b296d65c0c37979abe39ac7f6d8e1d8" category="paragraph">Pour configurer une LUN, effectuez les opérations suivantes :</block>
  <block id="3bdc2a5622b76404f8b0ce2fc774e69a" category="list-text">Créer une LUN de type<block ref="7bee0477f82303aa43de5d78f7b9cb05" prefix=" " category="inline-code"></block>.</block>
  <block id="c06f6c6685c06bb821295b3a6d5e580c" category="list-text">Installez le kit d'utilitaire hôte (HUK) approprié spécifié par le <block ref="b5b16f3cdb0eb25a282348ba54f8c677" category="inline-link-macro-rx"></block>.</block>
  <block id="33db73c9b3936cb8eaae825d3101f60c" category="inline-link-macro">documentation la plus récente</block>
  <block id="c8646086dca29c1d978ab285faa93709" category="list-text">Suivez les instructions du HUK exactement comme décrit. Les étapes de base sont décrites ci-dessous, mais reportez-vous au <block ref="33574dfffc2cb6d01be0edb6738c51bb" category="inline-link-macro-rx"></block> pour connaître la procédure adéquate.</block>
  <block id="6c06455cad171d61eac3593147bd71d6" category="list-text">Exécutez le<block ref="3062dc928daa4d85f6e34b6dea110a00" prefix=" " category="inline-code"></block> utilitaire de mise à jour du<block ref="d5416d340f5bec1fcb3addb6ae7d059e" prefix=" " category="inline-code"></block> fichier. Les disques SCSI seront ainsi en mesure de détecter correctement les LUN ONTAP.</block>
  <block id="7ec6668202fa9a677238143b0445102f" category="list-text">Suivez les instructions fournies par le<block ref="3062dc928daa4d85f6e34b6dea110a00" prefix=" " category="inline-code"></block> Utilitaire permettant d'activer les entrées/sorties multivoies (MPIO).</block>
  <block id="b53abe6c0013125abea171427b351ccc" category="list-text">Redémarrez. Cette étape est nécessaire pour que les modifications soient reconnues dans l'ensemble du système.</block>
  <block id="b88caedbe9708683eed783eb534ae5f6" category="list-text">Partitionnez les LUN et vérifiez qu'ils sont correctement alignés. Voir « Annexe B : Vérification de l'alignement WAFL » pour obtenir des instructions sur la façon de tester et de confirmer directement l'alignement.</block>
  <block id="a0c1c26e783204cf713b2e1f0823aab3" category="section-title">zpools</block>
  <block id="c81b8fe4a368c32102406e65fc41a227" category="inline-link-macro">Configuration du LUN</block>
  <block id="869dc3a8daf591c7f33e5bb32a4a63c9" category="paragraph">La valeur de<block ref="81df978a8e3da4bee74b135548f390f3" prefix=" " category="inline-code"></block> la valeur par défaut est 9, ce qui signifie 2^9, ou 512 octets. Pour des performances optimales, le<block ref="81df978a8e3da4bee74b135548f390f3" prefix=" " category="inline-code"></block> La valeur doit être 12 (2^12=4K). Cette valeur est définie au moment de la création du zpool et ne peut pas être modifiée, ce qui signifie que les données dans zpools avec<block ref="81df978a8e3da4bee74b135548f390f3" prefix=" " category="inline-code"></block> une migration autre que 12 doit être effectuée en copiant les données vers un nouveau zpool.</block>
  <block id="6a00a2262e030c2656588743cb031710" category="paragraph">Après avoir créé un zpool, vérifiez la valeur de<block ref="81df978a8e3da4bee74b135548f390f3" prefix=" " category="inline-code"></block> avant de continuer. Si la valeur n'est pas 12, les LUN n'ont pas été détectées correctement. Détruisez le zpool, vérifiez que toutes les étapes indiquées dans la documentation des utilitaires hôtes correspondante ont été effectuées correctement et recréez le zpool.</block>
  <block id="15ec722ce3f6694d12f89aeb5b621941" category="section-title">Zpools et LDOMS Solaris</block>
  <block id="8826ef54a7d108df25ed6921b5129cb6" category="paragraph">Les LDOMS Solaris créent une exigence supplémentaire pour s'assurer que l'alignement des E/S est correct. Bien qu'un LUN soit correctement découvert en tant que périphérique 4K, un périphérique virtuel vdsk sur un LDOM n'hérite pas de la configuration du domaine d'E/S. Le vdsk basé sur cette LUN revient par défaut à un bloc de 512 octets.</block>
  <block id="9a984f24f825e4f0bca1f36e11acbca9" category="paragraph">Un fichier de configuration supplémentaire est requis. Tout d'abord, les LDOM individuels doivent être corrigés pour le bogue Oracle 15824910 afin d'activer les options de configuration supplémentaires. Ce correctif a été porté dans toutes les versions actuellement utilisées de Solaris. Une fois le logiciel LDOM corrigé, il est prêt à configurer les nouveaux LUN correctement alignés comme suit :</block>
  <block id="e0f306ab540315b015db849b1ae9099e" category="list-text">Identifiez la ou les LUN à utiliser dans le nouveau zpool. Dans cet exemple, il s'agit du périphérique c2d1.</block>
  <block id="f469046d419183a7be08ed5a13d2c65e" category="list-text">Récupérez l'instance vdc des systèmes à utiliser pour un pool ZFS :</block>
  <block id="bcaa63dcd5db76bffd8b867e8720a272" category="list-text">Modifier<block ref="ebceeaa7b6ce5abf6c8de7177255fef5" prefix=" " category="inline-code"></block>:</block>
  <block id="ec960a08b4666fe258b6e005064378ab" category="paragraph">Cela signifie que l'instance de périphérique 1 se voit attribuer une taille de bloc de 4096.</block>
  <block id="3df4cdc476a0c3a5a930597e9d8da84c" category="paragraph">Par exemple, supposons que les instances vdsk 1 à 6 doivent être configurées pour une taille de bloc de 4 Ko et<block ref="74a491ed941b00d0c9909d488eee67bf" prefix=" " category="inline-code"></block> se lit comme suit :</block>
  <block id="dfed6d8974f03c5b31f20c9c5c2bbe66" category="list-text">La finale<block ref="3328fba80b08b36663ffae0684f6c578" prefix=" " category="inline-code"></block> le fichier doit contenir les éléments suivants :</block>
  <block id="764a2caff05993fc0d3eff5de7b225e9" category="cell">Avertissement</block>
  <block id="5c442834a7707cc96719e468c87b2ff6" category="cell">Le LDOM doit être redémarré après la configuration de vdc.conf et la création du vdsk. Cette étape ne peut pas être évitée. La modification de la taille de bloc n'est effective qu'après un redémarrage. Procéder à la configuration du pool de zpool et s'assurer que le module de transmission automatique est correctement réglé sur 12 comme décrit précédemment.</block>
  <block id="2138e0b461ac7e557539bb0b33bde81a" category="section-title">Journal des intentions ZFS (ZIL)</block>
  <block id="5477cebfd480a13008afdd16bea2b3f9" category="paragraph">En général, il n'y a aucune raison de localiser le ZFS Intent Log (ZIL) sur un autre périphérique. Le journal peut partager de l'espace avec le pool principal. L'utilisation principale d'une ZIL distincte est l'utilisation de disques physiques qui n'offrent pas les fonctionnalités de mise en cache des écritures dans les baies de stockage modernes.</block>
  <block id="26a004aeb043de19f767bd7daa39cf2f" category="section-title">biais logique</block>
  <block id="07fff183bc4c01bf9bbb21a48b389845" category="paragraph">Réglez le<block ref="26a004aeb043de19f767bd7daa39cf2f" prefix=" " category="inline-code"></block> Paramètre sur les systèmes de fichiers ZFS hébergeant les données Oracle.</block>
  <block id="ac01fbc5e98d6450f3b565d0617f4a55" category="paragraph">Ce paramètre réduit les niveaux d'écriture globaux. Sous les valeurs par défaut, les données écrites sont d'abord validées dans le ZIL, puis dans le pool de stockage principal. Cette approche est adaptée à une configuration utilisant une configuration de disque simple, qui inclut un périphérique ZIL SSD et un support rotatif pour le pool de stockage principal. En effet, elle permet une validation dans une seule transaction d'E/S sur le support à latence la plus faible disponible.</block>
  <block id="c6cc0f147c42f124079d7fc1a0761886" category="paragraph">Lorsque vous utilisez une baie de stockage moderne qui inclut sa propre capacité de mise en cache, cette approche n'est généralement pas nécessaire. Dans de rares cas, il peut être souhaitable d'effectuer une écriture avec une seule transaction dans le journal, par exemple une charge de travail composée d'écritures aléatoires hautement concentrées et sensibles à la latence. L'amplification d'écriture peut avoir des conséquences, car les données consignées sont finalement écrites dans le pool de stockage principal, ce qui double l'activité d'écriture.</block>
  <block id="92b9531657a4ce6a31c623d889a2c55d" category="section-title">E/S directes</block>
  <block id="387f4a4c250ed7a5003f3f6a19abfd1f" category="paragraph">De nombreuses applications, y compris les produits Oracle, peuvent contourner le cache du tampon hôte en activant des E/S directes Cette stratégie ne fonctionne pas comme prévu avec les systèmes de fichiers ZFS. Bien que le cache du tampon hôte soit contourné, ZFS lui-même continue à mettre en cache les données. Cette action peut entraîner des résultats trompeurs lors de l'utilisation d'outils tels que fio ou Sio pour effectuer des tests de performances. En effet, il est difficile de prévoir si les E/S atteignent le système de stockage ou si elles sont mises en cache localement au sein du système d'exploitation. Cette action rend également très difficile l'utilisation de tels tests synthétiques pour comparer les performances ZFS aux autres systèmes de fichiers. D'un point de vue pratique, les performances du système de fichiers varient considérablement, voire nulle, pour les charges de travail réelles des utilisateurs.</block>
  <block id="ec79b30d56e7bae54aa7efedccc47e93" category="section-title">Plusieurs zpools</block>
  <block id="f5aa5b31f0536ddcdb748ae360d91358" category="paragraph">Les sauvegardes, les restaurations, les clones et l'archivage des données ZFS basés sur des snapshots doivent être effectués au niveau du zpool et requièrent généralement plusieurs zpools. Un zpool est similaire à un groupe de disques LVM et doit être configuré à l'aide des mêmes règles. Par exemple, il est probablement préférable de définir au mieux une base de données avec les fichiers de données résidant sur<block ref="f1fb162e58045170396a0ac29d648fa5" prefix=" " category="inline-code"></block> ainsi que les journaux d'archivage, les fichiers de contrôle et les journaux de reprise qui résident sur<block ref="92073f03d18c8eaec3eb5e0908210e1a" prefix=" " category="inline-code"></block>. Cette approche permet une sauvegarde à chaud standard dans laquelle la base de données est placée en mode de sauvegarde à chaud, suivie d'un snapshot de<block ref="f1fb162e58045170396a0ac29d648fa5" prefix=" " category="inline-code"></block>. La base de données est alors supprimée du mode de sauvegarde à chaud, l'archivage des journaux est forcé et un instantané de<block ref="92073f03d18c8eaec3eb5e0908210e1a" prefix=" " category="inline-code"></block> est créé. Une opération de restauration nécessite de démonter les systèmes de fichiers zfs et de mettre hors ligne le zpool dans son intégralité, après une opération de restauration SnapRestore. Le zpool peut alors être remis en ligne et la base de données récupérée.</block>
  <block id="f1110589be196c2310808482067fce1b" category="section-title">filesytemio_options</block>
  <block id="c271ff9f255f2d215054d508448781a3" category="paragraph">Le paramètre Oracle<block ref="f1110589be196c2310808482067fce1b" prefix=" " category="inline-code"></block> Fonctionne différemment avec ZFS. Si<block ref="aef8f91b1e026cc1bb55e8b08c491d35" prefix=" " category="inline-code"></block> ou<block ref="6887bae4cda2d09a283a165c5be3f2b8" prefix=" " category="inline-code"></block> Est utilisé, les opérations d'écriture sont synchrones et contournent le cache du tampon du système d'exploitation, mais les lectures sont mises en tampon par ZFS. Cette action engendre des difficultés dans l'analyse des performances, car les E/S sont parfois interceptées et traitées par le cache ZFS, ce qui rend la latence du stockage et les E/S totales inférieures à ce qu'elles semblent être.</block>
  <block id="22a7d37643562540ddbda52f511fb1fe" category="summary">Oracle sous ONTAP avec HP-UX</block>
  <block id="b1fd823d262032e04291313f72be9452" category="doc">HP-UX</block>
  <block id="5be7e182308e16aee80978c6a5ebe02b" category="paragraph">Rubriques de configuration spécifiques au système d'exploitation HP-UX.</block>
  <block id="8ec258cd0b6ab050fc478a415a20f2e9" category="section-title">Options de montage NFS HP-UX</block>
  <block id="7c5876d5737071c64af78562fe375386" category="paragraph">Le tableau suivant répertorie les options de montage NFS HP-UX pour une seule instance.</block>
  <block id="9c9fb3cc18a83e4e46165b5c3d4ce8ef" category="cell">Fichiers de contrôle
Fichiers de données
Journaux de reprise</block>
  <block id="55b835c747261995c0e1022d234e286d" category="cell"><block ref="fa8766c679857b7d589983df0ab5bcf4" prefix="" category="inline-code"></block></block>
  <block id="189dbd39cabd57c5d2e51714d9a5b85b" category="paragraph">Le tableau suivant répertorie les options de montage NFS HP-UX pour RAC.</block>
  <block id="fa9da3a6a7ef8986a94c7395577c322f" category="cell"><block ref="8b080dc74532d24847a6163dcc34d93f" prefix="" category="inline-code"></block></block>
  <block id="add42ff64fa5b57e5abeab49d154a9d9" category="cell"><block ref="acdef4af05a9f0c43f72b7c600f04d62" prefix="" category="inline-code"></block></block>
  <block id="c88a7b7f83f761f7fc2979815d210140" category="cell"><block ref="d29d7b7ed8c19a99fe17fd7f3d07ea7b" prefix="" category="inline-code"></block></block>
  <block id="af8831a1b8129b099114c3237a61db88" category="paragraph">La principale différence entre les options de montage à instance unique et RAC est l'ajout de<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> et<block ref="6698a391ee8befa0ca4646a86a1bbd66" prefix=" " category="inline-code"></block> aux options de montage. Cet ajout a pour effet de désactiver la mise en cache du système d'exploitation hôte, ce qui permet à toutes les instances du cluster RAC d'avoir une vue cohérente de l'état des données. En utilisant le<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> paramètre<block ref="b6a2b868e8bebfc19497b406a12a1071" prefix=" " category="inline-code"></block> a le même effet que la désactivation de la mise en cache de l'hôte, il est toujours nécessaire de l'utiliser<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> et<block ref="6698a391ee8befa0ca4646a86a1bbd66" prefix=" " category="inline-code"></block>.</block>
  <block id="b865c6aba24c3f61595471aab993d27c" category="paragraph">La raison<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> est requis pour le partage<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block> Les déploiements visent à faciliter la cohérence des fichiers tels que les fichiers de mots de passe Oracle et les fichiers spfiles. Si chaque instance d'un cluster RAC possède un dédié<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block>, ce paramètre n'est pas requis.</block>
  <block id="898311d838a2fa2fa41b4b52a63a7f1d" category="section-title">Options de montage HP-UX VxFS</block>
  <block id="85b4a3d44370909d395ab8af28ff4927" category="paragraph">Utilisez les options de montage suivantes pour les systèmes de fichiers hébergeant les binaires Oracle :</block>
  <block id="6630bbc9a901be0d038b2c39e2faf65d" category="paragraph">Utilisez les options de montage suivantes pour les systèmes de fichiers contenant des fichiers de données, des journaux de reprise, des journaux d'archivage et des fichiers de contrôle dans lesquels la version de HP-UX ne prend pas en charge les E/S simultanées :</block>
  <block id="ed37730e0f28a631768a396e7898e197" category="paragraph">Lorsque des E/S simultanées sont prises en charge (VxFS 5.0.1 et versions ultérieures, ou avec ServiceGuard Storage Management Suite), utilisez ces options de montage pour les systèmes de fichiers contenant des fichiers de données, des journaux de reprise, des journaux d'archivage et des fichiers de contrôle :</block>
  <block id="f51ddb98d92e83609db075add5fba4d8" category="admonition">Le paramètre<block ref="d3cc759510a3aba837fc8efeb2e24b91" prefix=" " category="inline-code"></block> Est particulièrement critique dans les environnements VxFS. Oracle recommande que ce paramètre ne soit pas défini dans Oracle 10g R1 et versions ultérieures, sauf indication contraire. La taille de bloc Oracle de 8 Ko par défaut est 128. Si la valeur de ce paramètre est forcée à 16 ou moins, retirer le<block ref="a6b02283cba560dcfdea44af66ec792c" prefix=" " category="inline-code"></block> Option de montage car elle peut endommager les performances des E/S séquentielles. Cette étape nuit à d'autres aspects de la performance et ne doit être prise que si la valeur de<block ref="d3cc759510a3aba837fc8efeb2e24b91" prefix=" " category="inline-code"></block> doit être modifié par rapport à la valeur par défaut.</block>
  <block id="ca3fa25943498edb0ee62d0ea286bb7a" category="summary">Oracle sur ONTAP à l'aide de Linux et du pilote de filtre ASMlib/ASM</block>
  <block id="d7e9c72be485a5a848f1f7cd15a9a5ba" category="doc">Pilote de filtre ASMlib et ASM</block>
  <block id="5802d9527a43305e9e1c903bc6b5a721" category="paragraph">Rubriques de configuration spécifiques au système d'exploitation Linux utilisant AFD et ASMlib</block>
  <block id="2681013be5b0a9063a7ef0a8fe4d31da" category="section-title">Tailles de bloc ASMlib</block>
  <block id="1943673cc25055e93f0129f2baa8f499" category="paragraph">ASMlib est une bibliothèque de gestion ASM facultative et des utilitaires associés. Sa valeur principale est la capacité de tamponner un LUN ou un fichier NFS en tant que ressource ASM avec une étiquette lisible par l'utilisateur.</block>
  <block id="51713fdb873939c9c333273947776b8e" category="paragraph">Les versions récentes d'ASMlib détectent un paramètre LUN appelé blocs logiques par exposant de bloc physique (LBPPBE). Cette valeur n'a été signalée que récemment par la cible SCSI ONTAP. Elle renvoie désormais une valeur qui indique qu'une taille de bloc de 4 Ko est recommandée. Il ne s'agit pas d'une définition de la taille de bloc, mais il est un indice pour toute application utilisant LBPPBE que les E/S d'une certaine taille peuvent être gérées plus efficacement. Cependant, ASMlib interprète LBPPBE comme une taille de bloc et estampille constamment l'en-tête ASM lors de la création du périphérique ASM.</block>
  <block id="65242d5b49071240043eeef598415104" category="paragraph">Ce processus peut causer des problèmes avec les mises à niveau et les migrations de différentes manières, tous en fonction de l'incapacité à mélanger des périphériques ASMlib avec des tailles de bloc différentes dans le même groupe de disques ASM.</block>
  <block id="ea884eec0628302adc731211dc4e2cc7" category="paragraph">Par exemple, des tableaux plus anciens ont généralement signalé une valeur LBPPBE de 0 ou n'ont pas signalé cette valeur du tout. ASMlib l'interprète comme une taille de bloc de 512 octets. Pour les baies plus récentes, la taille de bloc est de 4 Ko. Il n'est pas possible de mélanger des périphériques de 512 octets et de 4 Ko dans le même groupe de disques ASM. Cela empêche un utilisateur d'augmenter la taille du groupe de disques ASM en utilisant des LUN de deux baies ou en utilisant ASM comme outil de migration. Dans d'autres cas, RMAN pourrait ne pas permettre la copie de fichiers entre un groupe de disques ASM avec une taille de bloc de 512 octets et un groupe de disques ASM avec une taille de bloc de 4 Ko.</block>
  <block id="f17ff15b23b87f35906ece98842a080f" category="paragraph">La solution préférée est de corriger ASMlib. L'ID de bug Oracle est 13999609 et le correctif est présent dans oracleasm-support-2.1.8-1 et versions ultérieures. Ce correctif permet à un utilisateur de définir le paramètre<block ref="442e2026c8afecc4611b52331b5d0d56" prefix=" " category="inline-code"></block> à<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> dans le<block ref="92a59ba9a0643a344be2d72cfd504181" prefix=" " category="inline-code"></block> fichier de configuration. Cela empêche ASMlib d'utiliser le paramètre LBPPBE, ce qui signifie que les LUN de la nouvelle baie sont maintenant reconnues comme des périphériques de bloc de 512 octets.</block>
  <block id="f140ff6b2b71e70e551e39dacb9561ef" category="admonition">L'option ne modifie pas la taille de bloc sur les LUN précédemment estampées par ASMlib. Par exemple, si un groupe de disques ASM avec des blocs de 512 octets doit être migré vers un nouveau système de stockage qui signale un bloc de 4 Ko, l'option<block ref="442e2026c8afecc4611b52331b5d0d56" prefix=" " category="inline-code"></block> Doit être défini avant que les nouvelles LUN soient estampées avec ASMlib.  Si les périphériques ont déjà été estampillés par oracleasm, ils doivent être reformatés avant d'être repoussées avec une nouvelle taille de bloc. Commencez par déconfigurer le périphérique avec<block ref="41bd8c47b8e640da7bdb5c7dc995d435" prefix=" " category="inline-code"></block>, Puis effacez le premier 1 Go du périphérique avec<block ref="85c2e94baaf4d9c084e19d290907596e" prefix=" " category="inline-code"></block>. Enfin, si le périphérique a déjà été partitionné, utilisez le<block ref="9a287d63dabd6fbcbbe1b12344bfe922" prefix=" " category="inline-code"></block> Commande permettant de supprimer les partitions obsolètes ou de simplement redémarrer le système d'exploitation.</block>
  <block id="75ad83418241561186f96dfed5229aaa" category="paragraph">Si ASMlib ne peut pas être corrigé, ASMlib peut être supprimé de la configuration. Ce changement est perturbateur et nécessite le démarquage des disques ASM et s'assurer que le<block ref="0802edf7303a95bdecde832bbbe3a89c" prefix=" " category="inline-code"></block> le paramètre est défini correctement. Toutefois, cette modification ne nécessite pas la migration des données.</block>
  <block id="ad9ac4c6d7ed2e11bdcf8c693658a482" category="section-title">Tailles de bloc d'entraînement de filtre ASM (AFD)</block>
  <block id="de59cd97a61c9f9964a35d2cd8b05c88" category="paragraph">AFD est une bibliothèque de gestion ASM facultative qui remplace ASMlib. Du point de vue du stockage, il est très similaire à ASMlib, mais il inclut des fonctionnalités supplémentaires telles que la capacité de bloquer les E/S non-Oracle afin de réduire les risques d'erreurs d'utilisateur ou d'application susceptibles de corrompre les données.</block>
  <block id="36dc27685773851e52f035f82e3deba2" category="section-title">Tailles des blocs de périphériques</block>
  <block id="1ef92cf7e561e179d6079cc937b2778a" category="paragraph">Comme ASMlib, AFD lit également le paramètre LUN blocs logiques par exposant de bloc physique (LBPPBE) et utilise par défaut la taille de bloc physique, et non la taille de bloc logique.</block>
  <block id="b95ce6c503801cb15f2f9c0773c58f00" category="paragraph">Cela peut créer un problème si l'AFD est ajouté à une configuration existante où les périphériques ASM sont déjà formatés comme des périphériques de bloc de 512 octets. Le pilote AFD reconnaîtrait le LUN comme un périphérique 4K et l'incompatibilité entre l'étiquette ASM et le périphérique physique empêcherait l'accès. De même, les migrations seraient affectées, car il n'est pas possible de combiner des périphériques de 512 octets et de 4 Ko dans le même groupe de disques ASM. Cela empêche un utilisateur d'augmenter la taille du groupe de disques ASM en utilisant des LUN de deux baies ou en utilisant ASM comme outil de migration. Dans d'autres cas, RMAN pourrait ne pas permettre la copie de fichiers entre un groupe de disques ASM avec une taille de bloc de 512 octets et un groupe de disques ASM avec une taille de bloc de 4 Ko.</block>
  <block id="7ef45d3a7c5fff234bf42bdf549b8339" category="paragraph">La solution est simple - AFD inclut un paramètre pour contrôler si elle utilise les tailles de bloc logiques ou physiques. Il s'agit d'un paramètre global affectant tous les périphériques du système. Pour forcer AFD à utiliser la taille de bloc logique, définissez<block ref="722fc896569f3d455bb5ef8f5b8c3703" prefix=" " category="inline-code"></block> dans le<block ref="dcd5fd81543c5e08e927c54e89acdd40" prefix=" " category="inline-code"></block> fichier.</block>
  <block id="47b0d7fc4c27720c4fc326722edad27c" category="section-title">Tailles de transfert multivoie</block>
  <block id="7c329811bcc7bb2f50005da5a3aff250" category="paragraph">Les modifications récentes du noyau linux appliquent des restrictions de taille d'E/S envoyées aux périphériques à chemins d'accès multiples, et AFD ne respecte pas ces restrictions. Les E/S sont ensuite rejetées, ce qui entraîne la mise hors ligne du chemin d'accès à la LUN. Il en résulte une incapacité à installer Oracle Grid, à configurer ASM ou à créer une base de données.</block>
  <block id="926e4b7a2822a39a07f61474b92e9d8c" category="paragraph">La solution consiste à spécifier manuellement la longueur de transfert maximale dans le fichier multipath.conf pour les LUN ONTAP :</block>
  <block id="3d0c741146f1e8e31bc7d07128ca6e0a" category="admonition">Même si aucun problème n'existe actuellement, ce paramètre doit être défini si l'AFD est utilisé pour garantir qu'une future mise à niveau de linux ne provoque pas de problèmes inattendus.</block>
  <block id="72247c591c444399f3d42dffa31b644e" category="summary">Oracle sous ONTAP sous AIX</block>
  <block id="23802d94b756cf69028557bea156ab1a" category="doc">IBM AIX</block>
  <block id="5b8d4d99cdcb494ca636eb065004b165" category="paragraph">Rubriques de configuration spécifiques au système d'exploitation IBM AIX.</block>
  <block id="d99ae60d37a12f766bc2a1f1c228fb4f" category="section-title">E/S simultanées</block>
  <block id="0f3eb508f611e203aeffa91d5753648a" category="paragraph">Pour obtenir des performances optimales sur IBM AIX, il est nécessaire d'utiliser des E/S simultanées Sans E/S simultanées, les limites de performances sont probablement dues au fait qu'AIX exécute des E/S atomiques sérialisées, ce qui entraîne une surcharge importante.</block>
  <block id="ecdc41fc6a2adf7e41e7277e12eeb805" category="paragraph">À l'origine, NetApp a recommandé d'utiliser le<block ref="4482571a249db31b3abed938e4567a15" prefix=" " category="inline-code"></block> Option de montage pour forcer l'utilisation d'E/S simultanées sur le système de fichiers, mais ce processus présente des inconvénients et n'est plus nécessaire. Depuis l'introduction d'AIX 5.2 et d'Oracle 10gR1, Oracle sous AIX peut ouvrir des fichiers individuels pour des E/S simultanées, au lieu de forcer des E/S simultanées sur l'ensemble du système de fichiers.</block>
  <block id="445b433b62b675f0ca0bda7acb56d41b" category="paragraph">La meilleure méthode pour activer les E/S simultanées est de définir le<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> paramètre<block ref="f1110589be196c2310808482067fce1b" prefix=" " category="inline-code"></block> à<block ref="aef8f91b1e026cc1bb55e8b08c491d35" prefix=" " category="inline-code"></block>. Oracle peut ainsi ouvrir des fichiers spécifiques pour une utilisation avec des E/S simultanées</block>
  <block id="6206c23a0282b18352573158f9a8f9b3" category="paragraph">À l'aide de<block ref="4482571a249db31b3abed938e4567a15" prefix=" " category="inline-code"></block> En tant qu'option de montage, force l'utilisation d'E/S simultanées, ce qui peut avoir des conséquences négatives. Par exemple, forcer des E/S simultanées désactive la lecture anticipée sur les systèmes de fichiers, ce qui peut nuire aux performances des E/S se produisant en dehors du logiciel de base de données Oracle, comme la copie de fichiers et les sauvegardes sur bande. En outre, les produits tels qu'Oracle GoldenGate et SAP BR*Tools ne sont pas compatibles avec l'utilisation du<block ref="4482571a249db31b3abed938e4567a15" prefix=" " category="inline-code"></block> Option de montage avec certaines versions d'Oracle.</block>
  <block id="770cb9a1e9321ca3012ecbb9ec65c422" category="list-text">N'utilisez pas le<block ref="4482571a249db31b3abed938e4567a15" prefix=" " category="inline-code"></block> option de montage au niveau du système de fichiers. Activez plutôt les E/S simultanées via l'utilisation de<block ref="b6a2b868e8bebfc19497b406a12a1071" prefix=" " category="inline-code"></block>.</block>
  <block id="872080b7d5ec5585776f1426fb157842" category="list-text">Utilisez uniquement le<block ref="4482571a249db31b3abed938e4567a15" prefix=" " category="inline-code"></block> l'option de montage doit être définie si elle n'est pas possible<block ref="b6a2b868e8bebfc19497b406a12a1071" prefix=" " category="inline-code"></block>.</block>
  <block id="0c5d86482201f32acb30cd2f7de3048f" category="section-title">Options de montage NFS AIX</block>
  <block id="1ce07cafb2507c98c8b96ad5f35fb66a" category="paragraph">Le tableau suivant répertorie les options de montage NFS AIX pour les bases de données Oracle à instance unique.</block>
  <block id="9a8f040dae3f0f15b337fe69a85239c0" category="cell"><block ref="86d38d6e2b36f6557e583e005e23d258" prefix="" category="inline-code"></block></block>
  <block id="d45a1a2afa30c30042b28f028fe75953" category="cell"><block ref="915be14765d6133923d803e1221f1513" prefix="" category="inline-code"></block></block>
  <block id="b74f5956b4bcda2de3c82ee97e192ab6" category="paragraph">Le tableau suivant répertorie les options de montage NFS AIX pour RAC.</block>
  <block id="b547b55ba7f2a20602494777c5426eba" category="cell"><block ref="7e879bda961bd5b7d64d2ef4f5fb7869" prefix="" category="inline-code"></block></block>
  <block id="875abb256654bd3f6da7abcb1bd92f27" category="cell"><block ref="f93eecf9c582d76d4e14292dc34c79f8" prefix="" category="inline-code"></block></block>
  <block id="3ed8fb68917b28af138fb74ccde62e80" category="cell"><block ref="415e8eb8b9fc05cb48e633d31fd04944" prefix="" category="inline-code"></block></block>
  <block id="8102775fe4080f632332ab8d3312311a" category="paragraph">La principale différence entre les options de montage à instance unique et RAC est l'ajout de<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> aux options de montage. Cet ajout a pour effet de désactiver la mise en cache du système d'exploitation hôte qui permet à toutes les instances du cluster RAC d'avoir une vue cohérente de l'état des données.</block>
  <block id="1e3f10dfa324520cb7261c0da5bf6ec7" category="paragraph">En utilisant le<block ref="4482571a249db31b3abed938e4567a15" prefix=" " category="inline-code"></block> option de montage et<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> paramètre<block ref="b6a2b868e8bebfc19497b406a12a1071" prefix=" " category="inline-code"></block> a le même effet que la désactivation de la mise en cache de l'hôte, il est toujours nécessaire de l'utiliser<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block>.<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> est requis pour le partage<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block> Déploiements pour faciliter la cohérence des fichiers tels que les fichiers de mots de passe Oracle et<block ref="1737629d60b511cf45957529a8f046e2" prefix=" " category="inline-code"></block> fichiers de paramètres. Si chaque instance d'un cluster RAC possède un dédié<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block>, ce paramètre n'est pas requis.</block>
  <block id="5365dd1a92461c9e6cf65017c4a11647" category="section-title">Options de montage AIX jfs/jfs2</block>
  <block id="d7a578263480a2003f05c459a8961298" category="paragraph">Le tableau suivant répertorie les options de montage AIX jfs/jfs2.</block>
  <block id="0aabf727ab0a83c5f5d078e8b18445e0" category="cell">Valeurs par défaut</block>
  <block id="e1f651debac4f720c13ae930ff3ca14a" category="cell">ORACLE_HOME</block>
  <block id="27a7ffa293f5a4d2a5bb54354486dece" category="paragraph">Avant d'utiliser AIX<block ref="b7cc91287fc99a8937a55e79376c6f54" prefix=" " category="inline-code"></block> dans tout environnement, y compris les bases de données, vérifiez le paramètre<block ref="9d51746070ef554ad4e93a16de4aed0f" prefix=" " category="inline-code"></block>. Ce paramètre n'est pas la profondeur de la file d'attente HBA ; il se rapporte plutôt à la profondeur de la file d'attente SCSI de l'individu<block ref="66ad66c6ace8456eae4ca6807552e54b" prefix=" " category="inline-code"></block> peut être trop faible pour de bonnes performances. Les tests ont montré que la valeur optimale est de 64.</block>
  <block id="6e1dee25b21d0005970053df9e9384ba" category="summary">Oracle sous ONTAP sous Microsoft Windows</block>
  <block id="bb79f96acbff544ded541446c9c7c894" category="doc">Microsoft Windows</block>
  <block id="44959b8c12de9e1107621ee8c0337463" category="paragraph">Rubriques de configuration spécifiques au système d'exploitation Microsoft Windows.</block>
  <block id="14ce2582c2080a7f08fe9249f6565f40" category="paragraph">Oracle prend en charge l'utilisation de Microsoft Windows avec le client NFS direct. Cette fonctionnalité offre les avantages de NFS en termes de gestion, notamment la possibilité d'afficher les fichiers dans les différents environnements, de redimensionner les volumes de façon dynamique et d'exploiter un protocole IP moins onéreux. Pour plus d'informations sur l'installation et la configuration d'une base de données sous Microsoft Windows à l'aide de dNFS, reportez-vous à la documentation officielle d'Oracle. Il n'existe pas de meilleures pratiques spéciales.</block>
  <block id="f854b764258138b512f30be71e1c7908" category="paragraph">Pour une efficacité de compression optimale, assurez-vous que le système de fichiers NTFS utilise une unité d'allocation de 8 Ko ou plus. L'utilisation d'une unité d'allocation 4K, qui est généralement la valeur par défaut, a un impact négatif sur l'efficacité de la compression.</block>
  <block id="140def8362bd2cf6a999328e25572cfd" category="summary">Oracle sous ONTAP sous Linux</block>
  <block id="edc9f0a5a5d57797bf68e37364743831" category="doc">Linux</block>
  <block id="dfc95ed5e895617bbd0d4b1a8bfba8ca" category="paragraph">Rubriques de configuration spécifiques au système d'exploitation Linux.</block>
  <block id="5ecd4a6f4aedfdd45cce80a18b1a7942" category="section-title">Tables de rainures</block>
  <block id="2518e65e64213437c921c39a097db167" category="section-title">Options de montage NFS Linux</block>
  <block id="29cd2e6d4fc96e749c4a0e622cad7f50" category="paragraph">Le tableau suivant répertorie les options de montage NFS Linux pour une seule instance.</block>
  <block id="9fafd031075cede0e8a5a796ec45fbff" category="paragraph">Le tableau suivant répertorie les options de montage NFS Linux pour RAC.</block>
  <block id="f16135915fe2ca5c3b0d660acc0325d3" category="cell"><block ref="4c927b3193f1cd00c7cfd3ac2e7ba8ea" prefix="" category="inline-code"></block></block>
  <block id="fc1ea13514277ff14dc705f62c31c0fc" category="cell"><block ref="4d0511346ac74044d79c9bc297d59b09" prefix="" category="inline-code"></block></block>
  <block id="13c64659680c0bc3603209997cc22225" category="cell">CRS/vote</block>
  <block id="672c5eef2603018159295408f761324b" category="cell"><block ref="26b20bdf0b0e7d3ddef3749a70c17932" prefix="" category="inline-code"></block></block>
  <block id="f7085c7dc406f5b44813ac43c18b80c0" category="paragraph">La principale différence entre les options de montage à instance unique et RAC est l'ajout de<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block> aux options de montage. Cet ajout a pour effet de désactiver la mise en cache du système d'exploitation hôte, ce qui permet à toutes les instances du cluster RAC d'avoir une vue cohérente de l'état des données. En utilisant le<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> paramètre<block ref="b6a2b868e8bebfc19497b406a12a1071" prefix=" " category="inline-code"></block> a le même effet que la désactivation de la mise en cache de l'hôte, il est toujours nécessaire de l'utiliser<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block>.</block>
  <block id="d2537738f34705bc9d100925252c0102" category="paragraph">La raison<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block> est requis pour le partage<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block> Les déploiements visent à faciliter la cohérence des fichiers tels que les fichiers de mots de passe Oracle et les fichiers spfiles. Si chaque instance d'un cluster RAC possède un dédié<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block>, ce paramètre n'est pas requis.</block>
  <block id="5084019c1051a9937b5ff77568ce579b" category="paragraph">En règle générale, les fichiers ne provenant pas de bases de données doivent être montés avec les mêmes options que celles utilisées pour les fichiers de données à instance unique. Toutefois, certaines applications peuvent avoir des exigences différentes. Évitez les options de montage<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> et<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block> si possible parce que ces options désactivent la lecture et la mise en mémoire tampon au niveau du système de fichiers. Cela peut entraîner de graves problèmes de performances pour les processus tels que l'extraction, la translation et le chargement.</block>
  <block id="243de27c01fea05cc58186d2e5ad1ce5" category="section-title">ACCESS et GETATTR</block>
  <block id="59dcf78e97c197a0f240067da57a248f" category="paragraph">Certains clients ont remarqué qu'un niveau extrêmement élevé d'autres IOPS, comme L'ACCÈS et GETATTR, peut dominer leurs charges de travail. Dans des cas extrêmes, les opérations telles que les lectures et les écritures peuvent représenter jusqu'à 10 % du total. Il s'agit d'un comportement normal avec toute base de données qui inclut l'utilisation de<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block> et/ou<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> Sous Linux car ces options font que le système d'exploitation Linux recharge en permanence les métadonnées de fichiers à partir du système de stockage. Les opérations telles que ACCESS et GETATTR sont des opérations à faible impact qui sont traitées à partir du cache ONTAP dans un environnement de base de données. Elles ne doivent pas être considérées comme des IOPS authentiques, comme les lectures et les écritures, qui génèrent une véritable demande pour les systèmes de stockage. Cependant, ces autres IOPS créent une certaine charge, en particulier dans les environnements RAC. Pour résoudre ce problème, activez dNFS, qui contourne le cache du tampon du système d'exploitation et évite ces opérations de métadonnées inutiles.</block>
  <block id="041f371e212c70407e145ae9f752a8b4" category="section-title">NFS direct Linux</block>
  <block id="dd2f3f344f14ae5daf12cb0a817a72e0" category="paragraph">Une option de montage supplémentaire, appelée<block ref="4740c034d97ca90a96b8050082816605" prefix=" " category="inline-code"></block>, Est requis lorsque (a) dNFS est activé et (b) qu'un volume source est monté plusieurs fois sur un seul serveur (c) avec un montage NFS imbriqué. Cette configuration est principalement utilisée dans les environnements prenant en charge les applications SAP. Par exemple, un seul volume sur un système NetApp peut avoir un répertoire situé sur<block ref="9f9f4ccb1fc3afcbfe0cc3f5eac4332c" prefix=" " category="inline-code"></block> et une seconde à<block ref="ac2f9bbcd397d8f6b39e6713658051ea" prefix=" " category="inline-code"></block>. Si<block ref="9f9f4ccb1fc3afcbfe0cc3f5eac4332c" prefix=" " category="inline-code"></block> est monté à<block ref="9ad16912cc0ba54a259b1a15d233c264" prefix=" " category="inline-code"></block> et<block ref="ac2f9bbcd397d8f6b39e6713658051ea" prefix=" " category="inline-code"></block> est monté à<block ref="1da707b60c3b55bd01cb7df7c171a368" prefix=" " category="inline-code"></block>, Le résultat est des montages NFS imbriqués qui proviennent de la même source.</block>
  <block id="b06ff38483faff2d17d8de1fc966848e" category="paragraph">Le système d'exploitation peut détecter cela<block ref="9ad16912cc0ba54a259b1a15d233c264" prefix=" " category="inline-code"></block> et<block ref="1da707b60c3b55bd01cb7df7c171a368" prefix=" " category="inline-code"></block> résident sur le même volume, qui est le même système de fichiers source. Le système d'exploitation utilise ensuite le même descripteur de périphérique pour accéder aux données. Cela améliore l'utilisation de la mise en cache du système d'exploitation et de certaines autres opérations, mais interfère avec dNFS. Si dNFS doit accéder à un fichier, tel que le<block ref="1737629d60b511cf45957529a8f046e2" prefix=" " category="inline-code"></block>, activé<block ref="1da707b60c3b55bd01cb7df7c171a368" prefix=" " category="inline-code"></block>, il peut tenter par erreur d'utiliser le mauvais chemin d'accès aux données. Le résultat est une opération d'E/S défaillante. Dans ces configurations, ajoutez le<block ref="4740c034d97ca90a96b8050082816605" prefix=" " category="inline-code"></block> Option de montage sur tout système de fichiers NFS qui partage un volume FlexVol source avec un autre système de fichiers NFS sur cet hôte. Cela force le système d'exploitation Linux à allouer un descripteur de périphérique indépendant pour ce système de fichiers.</block>
  <block id="14dd7af30f62ec838445a1e167d2aff6" category="section-title">Linux Direct NFS et Oracle RAC</block>
  <block id="c6a209e4ad702c6424efb7d63d76feca" category="paragraph">DNFS présente des avantages spéciaux en matière de performances pour Oracle RAC sur le système d'exploitation Linux. En effet, Linux ne dispose pas d'une méthode permettant de forcer les E/S directes, qui est requise avec RAC pour assurer la cohérence entre les nœuds. Pour contourner ce problème, Linux nécessite l'utilisation du<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block> Mount option, qui entraîne l'expiration immédiate des données de fichier à partir du cache du système d'exploitation. Cette option force à son tour le client Linux NFS à relire en permanence les données d'attributs, ce qui endommage la latence et augmente la charge sur le contrôleur de stockage.</block>
  <block id="3070cb366c38db327b0cf057d63792c1" category="paragraph">L'activation de dNFS contourne le client NFS hôte et évite ces dommages. Plusieurs clients ont signalé une amélioration significative des performances sur les clusters RAC et une baisse significative de la charge ONTAP (en particulier par rapport aux autres IOPS) lors de l'activation de dNFS.</block>
  <block id="e97ab7f94d503bbec4b013b5b77118c6" category="section-title">Linux Direct NFS et fichier orangfstab</block>
  <block id="f63255b70940d25581e0cf5f81dd6cd6" category="paragraph">Si vous utilisez dNFS sur Linux avec l'option de chemins d'accès multiples, vous devez utiliser plusieurs sous-réseaux. Sur d'autres systèmes d'exploitation, vous pouvez établir plusieurs canaux dNFS à l'aide du<block ref="54b4c4075463b2e02cd69f5cd139b5b2" prefix=" " category="inline-code"></block> et<block ref="bbf52a1a57a4eaa83512cab68fd52b70" prefix=" " category="inline-code"></block> Options de configuration de plusieurs canaux dNFS sur un même sous-réseau. Cependant, cela ne fonctionne pas correctement sur Linux et des problèmes de performances inattendus peuvent survenir. Sous Linux, chaque carte réseau utilisée pour le trafic dNFS doit se trouver sur un sous-réseau différent.</block>
  <block id="6c5cf31ca1af553b1f4a9b99e3cb054c" category="section-title">Planificateur d'E/S.</block>
  <block id="49bb1f5f4810e5f3d32dac84bd96005d" category="paragraph">Le noyau Linux permet un contrôle de bas niveau sur la façon dont les E/S sont planifiées pour bloquer les périphériques. Les valeurs par défaut sur les différentes distributions de Linux varient considérablement. Les tests montrent que la date limite offre habituellement les meilleurs résultats, mais il arrive que le NOOP ait été légèrement meilleur. La différence de performance est minime, mais testez les deux options s'il est nécessaire d'extraire les performances maximales d'une configuration de base de données. Dans de nombreuses configurations, le paramètre CFQ est le paramètre par défaut. Il a démontré des problèmes de performances significatifs avec les charges de travail de la base de données.</block>
  <block id="38f25b8840d56fc601af1024115764b2" category="paragraph">Pour plus d'informations sur la configuration du planificateur d'E/S, reportez-vous à la documentation du fournisseur Linux correspondant.</block>
  <block id="4150162ad42bffea7bb903b4c7a4ffd9" category="section-title">Chemins d'accès multiples</block>
  <block id="305482bf1c318f0a9a04f94987db06b2" category="paragraph">Certains clients ont rencontré des pannes durant une interruption du réseau, car le démon multivoie ne s'exécutait pas sur leur système. Sur les versions récentes de Linux, le processus d'installation du système d'exploitation et le démon de chemins d'accès multiples peuvent exposer ces systèmes d'exploitation à ce problème. Les packages sont installés correctement, mais ils ne sont pas configurés pour un démarrage automatique après un redémarrage.</block>
  <block id="6fb0bf499bef576f56e0fd6360eba0a6" category="paragraph">Par exemple, la valeur par défaut du démon multiacheminement sur RHEL5.5 peut apparaître comme suit :</block>
  <block id="31026ba0b77cbe4c9d44ed6afc859ed6" category="paragraph">Ceci peut être corrigé à l'aide des commandes suivantes :</block>
  <block id="c759a9b7e4db09da8a25fb73d256f6b7" category="section-title">Mise en miroir ASM</block>
  <block id="f2f41836b42c08199948378b4a4a6e26" category="paragraph">La mise en miroir ASM peut nécessiter des modifications des paramètres de chemins d'accès multiples Linux pour permettre à ASM de reconnaître un problème et de basculer vers un autre groupe de pannes. La plupart des configurations ASM sur ONTAP reposent sur une redondance externe. La protection des données est assurée par la baie externe et ASM ne met pas en miroir les données. Certains sites utilisent ASM avec redondance normale pour fournir une mise en miroir bidirectionnelle, généralement entre différents sites.</block>
  <block id="25f47751ccd5df99e3c25a8eb2a21fc5" category="inline-link-macro">Documentation des utilitaires hôtes NetApp</block>
  <block id="066a79b72a430b074cdc0476b67bbde3" category="paragraph">Les paramètres Linux indiqués dans le <block ref="210658f6fe0d0061c73c19a9a6b263d1" category="inline-link-macro-rx"></block> Incluez les paramètres de chemins d'accès multiples qui entraînent une mise en file d'attente illimitée des E/S. Cela signifie qu'une E/S sur un périphérique LUN sans chemin d'accès actif attend tant que les E/S sont terminées. Cette opération est généralement souhaitable, car les hôtes Linux attendent tant que nécessaire la fin des modifications du chemin SAN, le redémarrage des commutateurs FC ou le basculement d'un système de stockage.</block>
  <block id="184ea23c04f24d03fc0123bc6eb30de2" category="paragraph">Ce comportement de mise en file d'attente illimité cause un problème de mise en miroir ASM car ASM doit recevoir une erreur d'E/S pour qu'il puisse réessayer d'E/S sur une autre LUN.</block>
  <block id="5616945ee545765b51d3fe1871cff4ec" category="paragraph">Définissez les paramètres suivants dans Linux<block ref="9ac80d53ede05256c28cf9e043eb423c" prefix=" " category="inline-code"></block> Fichier pour les LUN ASM utilisés avec la mise en miroir ASM :</block>
  <block id="49af3bbe0c557480960d217b217502ff" category="paragraph">Ces paramètres créent une temporisation de 120 secondes pour les périphériques ASM. Le délai d'attente est calculé comme étant le<block ref="e2f0125c5971e1ce714f86f145386ee3" prefix=" " category="inline-code"></block> *<block ref="9434de34302b4f40887a7277cf35a8fc" prefix=" " category="inline-code"></block> en secondes. Il peut être nécessaire d'ajuster la valeur exacte dans certaines circonstances, mais un délai de 120 secondes doit être suffisant pour la plupart des utilisations. En particulier, 120 secondes doivent permettre un basculement ou un retour du contrôleur sans générer d'erreur d'E/S susceptible de mettre le groupe défaillant hors ligne.</block>
  <block id="dbff1dc161f3f1d61258259b3a0b549c" category="paragraph">Un plus bas<block ref="9434de34302b4f40887a7277cf35a8fc" prefix=" " category="inline-code"></block> La valeur peut réduire le temps nécessaire à ASM pour passer à un autre groupe de pannes, mais augmente également le risque de basculement indésirable lors des activités de maintenance, telles qu'une prise de contrôle. Le risque peut être atténué par une surveillance attentive de l'état de mise en miroir ASM. Si un basculement indésirable se produit, les miroirs peuvent être rapidement resynchronisés si la resynchronisation est effectuée relativement rapidement. Pour plus d'informations, consultez la documentation Oracle sur ASM Fast Mirror Resync pour la version du logiciel Oracle utilisé.</block>
  <block id="ec0b68df6b5a0fdd6d73ac710b9684da" category="section-title">Options de montage Linux xfs, ext3 et ext4</block>
  <block id="278230e4238d02fcb49850454e7d79e0" category="admonition">*NetApp recommande* d'utiliser les options de montage par défaut.</block>
  <block id="17361a1d111a3ff3a45b20c3a1efa11b" category="summary">Configuration Oracle et TCP/IP et ethernet.</block>
  <block id="fe586387f0871fa578f77ac2e26e624a" category="doc">Configuration TCP/IP et Ethernet pour Oracle Database</block>
  <block id="02a5a4d50c5112bb31ff9c94f5b47ce9" category="paragraph">De nombreux clients d'Oracle sur ONTAP utilisent ethernet, le protocole réseau de NFS, iSCSI, NVMe/TCP, en particulier le cloud.</block>
  <block id="8a1870adbe8a237106c32d72660a9c42" category="summary">Conception d'interface logique pour les bases de données Oracle</block>
  <block id="f46a94d438563c03413adfec27c6bfda" category="paragraph">Les bases de données Oracle doivent accéder au stockage. Les interfaces logiques (LIF) correspondent à la tuyauterie réseau qui connecte une machine virtuelle de stockage (SVM) au réseau et, par conséquent, à la base de données. Une conception correcte des LIF est requise pour s'assurer qu'il y a suffisamment de bande passante pour chaque charge de travail de la base de données, et le basculement ne provoque pas de perte des services de stockage.</block>
  <block id="f445528d334d486a14570735705e2223" category="summary">Configuration réseau FC pour les bases de données Oracle</block>
  <block id="ee955933387c00b282dcfda69005517f" category="doc">Configuration FC pour Oracle</block>
  <block id="92cdde4ecc529b9f9379ed2bdb6aae34" category="paragraph">La configuration de FC SAN pour les bases de données Oracle consiste principalement à suivre les meilleures pratiques quotidiennes en matière de SAN.</block>
  <block id="953369199e3a71ad1ad58bc7d5ad2d9f" category="summary">NetApp ONTAP est une puissante plateforme de gestion des données dotée de fonctionnalités natives qui incluent des fonctionnalités de sauvegarde instantanée, de restauration et de clonage, des fonctions d'efficacité telles que la compression à la volée, des mises à niveau matérielles sans interruption et l'importation d'une LUN à partir d'une baie de stockage étrangère.</block>
  <block id="9eaca569c6f5ca3388f5613da3aa008c" category="doc">Bases de données Oracle sur ONTAP</block>
  <block id="528b35962f1679204260ddef6800eece" category="paragraph">ONTAP est conçu pour les bases de données Oracle. Pendant des décennies, ONTAP a été optimisé pour les demandes uniques d'E/S de bases de données relationnelles. Plusieurs fonctionnalités ONTAP ont été créées spécifiquement pour répondre aux besoins des bases de données Oracle, et même à la demande d'Oracle Inc. Elle-même.</block>
  <block id="c9f8ef2db64ce19b15d2cc98fbd3d24c" category="admonition">Cette documentation remplace les rapports techniques publiés précédemment _TR-3633 : bases de données Oracle sur ONTAP ; TR-4591 : protection des données Oracle : sauvegarde, restauration, réplication ; TR-4592 : Oracle sur MetroCluster ; et TR-4534 : migration de bases de données Oracle vers des systèmes de stockage NetApp_</block>
  <block id="b42ad0517ef7394f97178fb9e1de8d78" category="paragraph">Outre les nombreuses possibilités offertes par ONTAP pour valoriser votre environnement de base de données, les besoins des utilisateurs sont très variés, notamment en termes de taille de la base de données, de performances et de protection des données. Les déploiements de systèmes de stockage NetApp prennent des formes diverses, qu'il s'agisse d'un environnement virtualisé incluant environ 6,000 bases de données fonctionnant sous VMware ESX ou d'un data warehouse à instance unique dont la taille de 996 To ne cesse de croître. Par conséquent, il existe peu de bonnes pratiques claires pour la configuration d'une base de données Oracle sur un système de stockage NetApp.</block>
  <block id="7bf0493f27e81fe4c3740e773e137a48" category="paragraph">Les exigences relatives à l'exploitation d'une base de données Oracle sur un stockage NetApp sont traitées de deux manières. Tout d'abord, lorsqu'il existe une bonne pratique claire, elle sera appelée spécifiquement. D'une manière générale, de nombreuses considérations de conception à prendre en compte par les architectes de solutions de stockage Oracle en fonction de leurs besoins spécifiques seront expliquées.</block>
  <block id="633d94718c25247da5772ed6f2b244c9" category="summary">Introduction à la migration du stockage Oracle</block>
  <block id="6ca08c212e9ec987ce485fd9c7705eff" category="doc">Migration des bases de données Oracle vers les systèmes de stockage NetApp</block>
  <block id="9e099143017b5d9ff9c117de4ac659d7" category="paragraph">L'exploitation des capacités d'une nouvelle plateforme de stockage implique une seule nécessité : les données doivent être placées sur le nouveau système de stockage.</block>
  <block id="08beeb11d62fd51ef2742eae3ee3719f" category="admonition">Cette documentation remplace le rapport technique _TR-4534 : migration des bases de données Oracle vers des systèmes de stockage NetApp_</block>
  <block id="5f2a4190824fd64be3c8cabeb7dc62ff" category="paragraph">Dans le cas d'un nouveau projet de base de données, cela ne pose pas de problème car les environnements de base de données et d'application sont construits en place. Cependant, la migration pose des défis particuliers en ce qui concerne les interruptions d'activité, le temps nécessaire à la réalisation de la migration, les compétences requises et la réduction des risques.</block>
  <block id="a83f1ca5ad00b39773d9e6a26b0e70b2" category="section-title">Scripts</block>
  <block id="08293bec81c296b61f4a751175d9caa7" category="paragraph">Des exemples de scripts sont fournis dans cette documentation. Ces scripts fournissent des exemples de méthodes d'automatisation de divers aspects de la migration afin de réduire le risque d'erreurs des utilisateurs. Les scripts réduisent les demandes globales de l'équipe INFORMATIQUE responsable de la migration et accélèrent le processus global. Ces scripts sont issus de projets de migration réalisés par les services professionnels de NetApp et les partenaires NetApp. Des exemples de leur utilisation sont présentés dans cette documentation.</block>
  <block id="b3978e376e381abd116a2ae7938d8a9c" category="summary">Coupure FLI - Oracle</block>
  <block id="c28b52826242c7cdffe5f3ae1e917f61" category="paragraph">Certaines perturbations lors de l'importation d'une LUN étrangère sont inévitables en raison de la nécessité de modifier la configuration du réseau FC. Cependant, l'interruption ne doit pas durer beaucoup plus longtemps que le temps nécessaire pour redémarrer l'environnement de base de données et mettre à jour la segmentation FC pour basculer la connectivité FC de l'hôte de la LUN étrangère vers ONTAP.</block>
  <block id="a2248459756ffc1877beb9b39c77668b" category="paragraph">Ce processus peut être résumé comme suit :</block>
  <block id="c9f77905e39abbada6c73a7a3d5f51f8" category="list-text">Mettez toutes les activités de LUN au repos sur les LUN étrangères.</block>
  <block id="cff6e7c6c4f8dd7e57a0286f28712c58" category="list-text">Rediriger les connexions FC de l'hôte vers le nouveau système ONTAP.</block>
  <block id="9fea842823b73e1eb32307ab325f170e" category="list-text">Déclencher le processus d'importation.</block>
  <block id="df814ea2bf92d4f18e72a648e93103a2" category="list-text">Redécouvrez les LUN.</block>
  <block id="030a5009bbe6fb141ca5863ab6c59464" category="list-text">Redémarrez la base de données.</block>
  <block id="f3bb22d18791c042e889671ad1963239" category="paragraph">Inutile d'attendre la fin du processus de migration. Dès que la migration d'une LUN donnée commence, celle-ci est disponible sur ONTAP et peut assurer le service des données pendant que le processus de copie des données se poursuit. Toutes les lectures sont transmises au LUN étranger et toutes les écritures sont écrites de manière synchrone sur les deux baies. L'opération de copie est très rapide et la surcharge liée à la redirection du trafic FC est minimale. Par conséquent, tout impact sur les performances doit être transitoire et minimal. En cas de problème, vous pouvez retarder le redémarrage de l'environnement jusqu'à ce que le processus de migration soit terminé et que les relations d'importation aient été supprimées.</block>
  <block id="b19e17ab765f91aa0bc0e7152f13779f" category="section-title">Arrêtez la base de données</block>
  <block id="2869cd69e0fec20ba28a42e74afef158" category="paragraph">Dans cet exemple, la première étape de la mise en veille de l'environnement consiste à arrêter la base de données.</block>
  <block id="e20dab0880a91f5da2ea05170177576d" category="section-title">Fermez les services de grille</block>
  <block id="89c458e5176d6caf0690f1e61ecb0620" category="paragraph">L'un des systèmes de fichiers SAN en cours de migration inclut également les services Oracle ASM. La mise en veille des LUN sous-jacentes nécessite la suspension des systèmes de fichiers, ce qui signifie l'arrêt des processus avec des fichiers ouverts sur ce système de fichiers.</block>
  <block id="49f05bf7da4eacfa4c80bb987443eb5a" category="section-title">Démonter les systèmes de fichiers</block>
  <block id="c5a09ac3ff0bb25c97951c7b7f815cd0" category="paragraph">Si tous les processus sont arrêtés, l'opération de montage a réussi. Si l'autorisation est refusée, il doit y avoir un processus avec un verrou sur le système de fichiers. Le<block ref="ace112f9725b6fa0b702e6b3970b2102" prefix=" " category="inline-code"></block> permet d'identifier ces processus.</block>
  <block id="765e13ffc3361a9fd6c6088b2603ffbf" category="section-title">Désactiver les groupes de volumes</block>
  <block id="907e5f35f70dc2f5e4b67da56381bdf4" category="paragraph">Une fois tous les systèmes de fichiers d'un groupe de volumes donné démontés, le groupe de volumes peut être désactivé.</block>
  <block id="ad80f935ccd133a802189e3c2f4421d7" category="section-title">Modifications du réseau FC</block>
  <block id="a497da6790d9ab4bb5cce3d04b0efd2e" category="paragraph">Les zones FC peuvent maintenant être mises à jour pour supprimer tout accès de l'hôte à la baie étrangère et établir l'accès à ONTAP.</block>
  <block id="3ef31115a10790468ad841ec2cdf566f" category="section-title">Démarrer le processus d'importation</block>
  <block id="5bc309ef1913ddc70534a0a7135ba938" category="paragraph">Pour démarrer les processus d'importation de LUN, exécutez<block ref="76ffc50817aa4cd6214aa0061339fdf6" prefix=" " category="inline-code"></block> commande.</block>
  <block id="0a10f1ad4a0b45d384c5771ec0906c4c" category="section-title">Surveiller la progression de l'importation</block>
  <block id="9a3a7545f4a7407ec022c4b2271e0c34" category="paragraph">L'opération d'importation peut être surveillée avec<block ref="1ab15ef2c245a4434fcea3cc3149f4f4" prefix=" " category="inline-code"></block> commande. Comme indiqué ci-dessous, l'importation des 20 LUN est en cours, ce qui signifie que les données sont désormais accessibles via ONTAP, même si la copie des données progresse.</block>
  <block id="d36f98c8a305e33483232e7b5cd90c49" category="inline-link-macro">Importation de LUN étrangères—fin</block>
  <block id="24a74765303a8fc0e4b1e7afbb8e2205" category="paragraph">Si vous avez besoin d'un processus hors ligne, retardez la redécouverte ou le redémarrage des services jusqu'au<block ref="1ab15ef2c245a4434fcea3cc3149f4f4" prefix=" " category="inline-code"></block> indique que la migration a réussi et s'est terminée. Vous pouvez ensuite terminer le processus de migration comme décrit à la section <block ref="5b0017122426f8734e0358273adc6802" category="inline-link-macro-rx"></block>.</block>
  <block id="a9c97f84ee4958d39ed989b3da7ed0ba" category="paragraph">Si vous avez besoin d'une migration en ligne, redécouvrez les LUN de leur nouveau domicile et accédez aux services.</block>
  <block id="d0369936c6fe8c292874e3bc647893b8" category="section-title">Recherchez les modifications de périphérique SCSI</block>
  <block id="6d338faddede649cab4c5b498e8e4379" category="paragraph">Dans la plupart des cas, l'option la plus simple pour redécouvrir de nouvelles LUN consiste à redémarrer l'hôte. Cela supprime automatiquement les anciens périphériques obsolètes, détecte correctement toutes les nouvelles LUN et construit les périphériques associés, tels que les périphériques multivoies. L'exemple ci-dessous montre un processus entièrement en ligne à des fins de démonstration.</block>
  <block id="3b493a859f19779c1f7db7d1951785ee" category="paragraph">Attention : avant de redémarrer un hôte, assurez-vous que toutes les entrées dans<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block> Les ressources SAN migrées de cette référence sont commentées. Si ce n'est pas le cas et si des problèmes surviennent lors de l'accès aux LUN, le système d'exploitation risque de ne pas démarrer. Cette situation n'endommage pas les données. Cependant, il peut être très peu commode de démarrer en mode de secours ou un mode similaire et de corriger le<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block> Afin que le système d'exploitation puisse être démarré pour permettre le dépannage.</block>
  <block id="9d7b16568eb7edb80492b49cb02d7663" category="paragraph">Les LUN de la version de Linux utilisée dans cet exemple peuvent être renumérisées avec<block ref="b6f75508bf2af141e9de6f862662661e" prefix=" " category="inline-code"></block> commande. Si la commande réussit, chaque chemin de LUN doit apparaître dans le résultat de la commande. Le résultat de cette commande peut être difficile à interpréter, mais si la configuration de zoning et d'igroup était correcte, de nombreuses LUN doivent apparaître et inclure un<block ref="971c047750d8e3b03c71d24020b3816f" prefix=" " category="inline-code"></block> chaîne du fournisseur.</block>
  <block id="3384aa7c090758ad18028832967b143f" category="section-title">Vérifiez la présence de périphériques multivoies</block>
  <block id="07a39d42e6d8cc61e0a880e43b83e2a3" category="paragraph">Le processus de découverte des LUN déclenche également la recréation des périphériques multivoies, mais il est connu que le pilote de chemins d'accès multiples Linux présente des problèmes occasionnels. La sortie de<block ref="eeb30d005cab1d8c69785a3cd5818f55" prefix=" " category="inline-code"></block> doit être vérifié pour vérifier que la sortie semble correcte. Par exemple, le résultat ci-dessous affiche les périphériques à chemins d'accès multiples associés à un<block ref="971c047750d8e3b03c71d24020b3816f" prefix=" " category="inline-code"></block> chaîne du fournisseur. Chaque périphérique a quatre chemins, dont deux avec une priorité de 50 et deux avec une priorité de 10. Bien que le résultat exact puisse varier selon les versions de Linux, ce résultat semble normal.</block>
  <block id="efd921479c3d57448954050760c568ca" category="admonition">Reportez-vous à la documentation des utilitaires hôtes pour connaître la version de Linux que vous utilisez pour vérifier que l'<block ref="dd5ff67ba72768d33f75e645aa2b8e56" prefix=" " category="inline-code"></block> les paramètres sont corrects.</block>
  <block id="28751dc1e914a778d11ca0e69613690b" category="section-title">Réactiver le groupe de volumes LVM</block>
  <block id="a66a38e4056f28a310ef6d1fa8bbcc77" category="paragraph">Si les LUN LVM ont été correctement découvertes, le système<block ref="5239f542d8edbc4b528b1f362153c0c7" prefix=" " category="inline-code"></block> la commande doit réussir. C'est un bon exemple de la valeur d'un gestionnaire de volumes logiques. Une modification du WWN d'une LUN ou même d'un numéro de série n'est pas importante, car les métadonnées du groupe de volumes sont écrites sur la LUN elle-même.</block>
  <block id="1d374f8de5ba1b82ab4407b8c6efbd0d" category="paragraph">Le système d'exploitation a analysé les LUN et découvert une petite quantité de données écrites sur la LUN qui l'identifie comme un volume physique appartenant au système<block ref="83b7788c8e4de444d6cd4c69978eaf32" prefix=" " category="inline-code"></block>. Il a ensuite construit tous les périphériques requis. Il suffit de réactiver le groupe de volumes.</block>
  <block id="1f0285a57b2357507c3b77ce5130b548" category="section-title">Remonter les systèmes de fichiers</block>
  <block id="a9047d68dc7e99f553b71590cff301d6" category="paragraph">Une fois le groupe de volumes réactivé, les systèmes de fichiers peuvent être montés avec toutes les données d'origine intactes. Comme nous l'avons vu précédemment, les systèmes de fichiers sont pleinement opérationnels, même si la réplication des données est toujours active dans le groupe en arrière-plan.</block>
  <block id="a787d65e2525ac6bc3a6328efe383b5c" category="section-title">Rechercher à nouveau les périphériques ASM</block>
  <block id="a25bb20f07ed95a633f623678855e8dc" category="paragraph">Les périphériques ASMlib auraient dû être redécouverts lorsque les périphériques SCSI ont été renumérisés. La redécouverte peut être vérifiée en ligne en redémarrant ASMlib puis en analysant les disques.</block>
  <block id="37fb12a52b4a5371c12209e89e09b04f" category="admonition">Cette étape concerne uniquement les configurations ASM où ASMlib est utilisé.</block>
  <block id="6de48f39063d81d53fd0ff3e9938af13" category="paragraph">Attention : lorsque ASMlib n'est pas utilisé, le<block ref="9c9f766701f811ef6f170c7a3453c53f" prefix=" " category="inline-code"></block> les périphériques doivent avoir été recréés automatiquement. Cependant, les autorisations peuvent ne pas être correctes. Vous devez définir des autorisations spéciales sur les périphériques sous-jacents pour ASM en l'absence d'ASMlib. Cette opération est généralement réalisée par des entrées spéciales dans l'un ou l'autre des<block ref="dd5ff67ba72768d33f75e645aa2b8e56" prefix=" " category="inline-code"></block> ou<block ref="ab775c875d5f89d991a670444dd32ad2" prefix=" " category="inline-code"></block> ou éventuellement dans les deux jeux de règles. Ces fichiers peuvent avoir besoin d'être mis à jour pour refléter les modifications de l'environnement en termes de WWN ou de numéros de série afin de s'assurer que les périphériques ASM disposent toujours des autorisations appropriées.</block>
  <block id="08b33d6af4ec78f99dbbc3533589aafc" category="paragraph">Dans cet exemple, le redémarrage d'ASMlib et l'analyse des disques affichent les 10 mêmes LUN ASM que l'environnement d'origine.</block>
  <block id="17c4ae76000d9a79a56195071665af32" category="section-title">Redémarrez les services de grille</block>
  <block id="e8c3dc00e15826e3b77a2d41d7fde92a" category="paragraph">Maintenant que les périphériques LVM et ASM sont en ligne et disponibles, les services de grille peuvent être redémarrés.</block>
  <block id="934317e45581988a01f54761705ca58a" category="section-title">Redémarrez la base de données</block>
  <block id="41475a737e947d73c674b90e78e246a0" category="paragraph">Une fois les services de grille redémarrés, la base de données peut être ouverte. Il peut être nécessaire d'attendre quelques minutes que les services ASM soient entièrement disponibles avant d'essayer de démarrer la base de données.</block>
  <block id="0b986cf2a434b03b097578ad444e72f0" category="summary">Finalisation d'une mise en service FLI - Oracle</block>
  <block id="24bd7d2a01571aa270c81d8d9f8370e9" category="doc">Achèvement FLI - Oracle</block>
  <block id="b171714b39ad4102aced4daceef8c678" category="paragraph">Du point de vue de l'hôte, la migration est terminée, mais les E/S sont toujours servies depuis la baie étrangère jusqu'à ce que les relations d'importation soient supprimées.</block>
  <block id="f708d001227724fa0a8a3d57aacedb1a" category="paragraph">Avant de supprimer les relations, vous devez confirmer que le processus de migration est terminé pour toutes les LUN.</block>
  <block id="85cf20229bc9008553794abdaed507f5" category="section-title">Supprimer les relations d'importation</block>
  <block id="b23ec325eb9c6278cb36e4c45c2c3499" category="paragraph">Une fois le processus de migration terminé, supprimez la relation de migration. Une fois que vous avez terminé, les E/S sont servies exclusivement à partir des disques sur ONTAP.</block>
  <block id="40b98b0023a7eea7c432c29e3c44ba7d" category="section-title">Désenregistrer des LUN étrangères</block>
  <block id="5ccc14ae93ba94bd4183439a9f80f6c8" category="paragraph">Enfin, modifiez le disque pour retirer le<block ref="96ea0e5f46787e93e2970a086b47fdb6" prefix=" " category="inline-code"></block> désignation.</block>
  <block id="875bb561ba851d301052704e0ffb70f4" category="summary">Migration Oracle via l'envoi de journaux</block>
  <block id="e0f9c3b73fe5700df95f30eb98ca4034" category="doc">Envoi de journaux Oracle</block>
  <block id="8e42b5809657e127c7e2d24f30bc493e" category="paragraph">L'objectif d'une migration à l'aide de l'envoi de journaux est de créer une copie des fichiers de données d'origine à un nouvel emplacement, puis d'établir une méthode d'expédition des modifications dans le nouvel environnement.</block>
  <block id="599df5f564506c95624dd78b0b75eeac" category="paragraph">Une fois établie, l'envoi et la relecture des journaux peuvent être automatisés afin de maintenir la base de données de réplica largement synchronisée avec la source. Par exemple, une tâche cron peut être planifiée pour (a) copier les journaux les plus récents vers le nouvel emplacement et (b) les relire toutes les 15 minutes. L'interruption au moment de la mise en service est ainsi minimale, car la lecture des journaux d'archivage ne doit pas dépasser 15 minutes.</block>
  <block id="41bec1b4ddc17b3367c68a025c0ddfb9" category="paragraph">La procédure présentée ci-dessous est également essentiellement une opération de clonage de base de données. La logique illustrée est similaire au moteur de NetApp SnapManager pour Oracle (SMO) et du plug-in Oracle NetApp SnapCenter. Certains clients ont utilisé la procédure présentée dans des scripts ou des workflows WFA pour des opérations de clonage personnalisé. Bien que cette procédure soit plus manuelle qu'avec SMO ou SnapCenter, elle reste facilement scriptée, et les API de gestion des données de ONTAP simplifient davantage le processus.</block>
  <block id="f0616883a5ca70aa97676de436a7fb9e" category="section-title">Envoi de journaux - système de fichiers vers le système de fichiers</block>
  <block id="8f922b64f0bc64f6bba1d555a61ee3bb" category="paragraph">Cet exemple illustre la migration d'une base de données appelée WAFFLE d'un système de fichiers ordinaire vers un autre système de fichiers ordinaire situé sur un serveur différent. Il illustre également l'utilisation de SnapMirror pour effectuer une copie rapide des fichiers de données, mais cela ne fait pas partie intégrante de la procédure globale.</block>
  <block id="60100e1b826a4b972fc113c391f932e7" category="section-title">Créer une sauvegarde de base de données</block>
  <block id="80cf34e10dcfbc5e76c6b2f845f2708d" category="paragraph">La première étape consiste à créer une sauvegarde de base de données. Plus précisément, cette procédure nécessite un ensemble de fichiers de données pouvant être utilisés pour la relecture des journaux d'archivage.</block>
  <block id="0ba29c6a1afacf586b03a26162c72274" category="section-title">De production</block>
  <block id="82f9b672d88793b2ca5716b2a5427056" category="paragraph">Dans cet exemple, la base de données source se trouve sur un système ONTAP. La méthode la plus simple pour créer une sauvegarde d'une base de données consiste à utiliser une copie Snapshot. La base de données est placée en mode de sauvegarde à chaud pendant quelques secondes<block ref="252ce13e6c150af4d3e7eea5fca266bc" prefix=" " category="inline-code"></block> l'opération est exécutée sur le volume hébergeant les fichiers de données.</block>
  <block id="1fd3a22cf15d1e18a6507f539346c40d" category="paragraph">Le résultat est une copie Snapshot sur disque appelée<block ref="a8b3bc9f12cd194b80d404c30e9015ee" prefix=" " category="inline-code"></block> qui contient une image des fichiers de données en mode de sauvegarde à chaud. Lorsqu'elles sont combinées aux journaux d'archivage appropriés pour assurer la cohérence des fichiers de données, les données de cette copie Snapshot peuvent servir de base à une restauration ou à un clone. Dans ce cas, il est répliqué sur le nouveau serveur.</block>
  <block id="744a73803cdac4a5067725ca5814a2cf" category="section-title">Restaurer dans un nouvel environnement</block>
  <block id="46228bb2ce31b0d397faad2b805e8a37" category="paragraph">La sauvegarde doit maintenant être restaurée dans le nouvel environnement. Cette opération peut être effectuée de plusieurs façons, notamment Oracle RMAN, la restauration à partir d'une application de sauvegarde comme NetBackup ou une simple opération de copie des fichiers de données placés en mode de sauvegarde à chaud.</block>
  <block id="ca7da361ad92f677545e12dd462c6e39" category="paragraph">Dans cet exemple, SnapMirror est utilisé pour répliquer la copie Snapshot appelée sauvegarde à chaud vers un nouvel emplacement.</block>
  <block id="1f255556546f1fdfb53692e41f35eb6c" category="list-text">Créez un volume pour recevoir les données de snapshot. Initialiser la mise en miroir à partir de<block ref="937e9fa808ccfe9a4f6b004a2a7caada" prefix=" " category="inline-code"></block> à<block ref="96f9dacb3cb1b1f6f9b4ad02992a1a0e" prefix=" " category="inline-code"></block>.</block>
  <block id="5b1944ec8c0ed933e5b2ea2e3e5fa76e" category="list-text">Une fois l'état défini par SnapMirror, indiquant que la synchronisation est terminée, mettre à jour le miroir en fonction du snapshot souhaité.</block>
  <block id="f4d90c6c29b1f76ab9c87a9996c9751e" category="list-text">La synchronisation peut être vérifiée en affichant le<block ref="31952c255e722053d4cc3f82921e95db" prefix=" " category="inline-code"></block> champ sur le volume miroir.</block>
  <block id="0934c3fcad3065c2a479125e4a80b259" category="list-text">Le miroir peut alors être cassé.</block>
  <block id="fcf1f505b94151a36eba8e1563e7176f" category="list-text">Montez le nouveau système de fichiers.avec les systèmes de fichiers en mode bloc, les procédures précises varient en fonction du LVM utilisé. Le zoning FC ou les connexions iSCSI doivent être configurés. Une fois la connectivité aux LUN établie, des commandes telles que Linux<block ref="302c49bbd5bcda5463eb5130804effc1" prefix=" " category="inline-code"></block> Il peut être nécessaire de déterminer quels groupes de volumes ou LUN doivent être configurés correctement pour être détectables par ASM.</block>
  <block id="20c4d1d4163c2463cf15ff7df6424459" category="paragraph">Dans cet exemple, un simple système de fichiers NFS est utilisé. Ce système de fichiers peut être monté directement.</block>
  <block id="b2dd88a1f03a5fb4c2e3c0d46f425161" category="section-title">Créer un modèle de création de fichier de contrôle</block>
  <block id="1c30e11140f1d0a1093bedee34eef1e4" category="paragraph">Vous devez ensuite créer un modèle de fichier de contrôle. Le<block ref="3177841b2335a6640ea3054199830f1c" prefix=" " category="inline-code"></block> commande crée des commandes texte pour recréer un fichier de contrôle. Dans certaines circonstances, cette fonction peut être utile pour restaurer une base de données à partir d'une sauvegarde, et elle est souvent utilisée avec des scripts qui effectuent des tâches telles que le clonage de base de données.</block>
  <block id="3f51d58ec72b9d36cb5e0636525130b5" category="list-text">Le résultat de la commande suivante est utilisé pour recréer les fichiers de contrôle pour la base de données migrée.</block>
  <block id="cb395c3bf18fd427287caecc9b28058a" category="list-text">Une fois les fichiers de contrôle créés, copiez-les sur le nouveau serveur.</block>
  <block id="cf5c9046a3617a19c0ccc24e4cf54a33" category="section-title">Sauvegarde du fichier de paramètres</block>
  <block id="0d1d1a7db58f3f93ec977733f4909f5d" category="paragraph">Un fichier de paramètres est également requis dans le nouvel environnement. La méthode la plus simple consiste à créer un fichier pfile à partir du fichier spfile ou pfile actuel. Dans cet exemple, la base de données source utilise un fichier spfile.</block>
  <block id="051a634cb1e9a53dbf139214e1d24001" category="section-title">Créer une entrée oratab</block>
  <block id="2dabc26c8b55d44e25a184ba2624eed0" category="paragraph">La création d'une entrée oratab est requise pour le bon fonctionnement des utilitaires tels que oraenv. Pour créer une entrée oratab, procédez comme suit.</block>
  <block id="87ef75141d237e3b44e8310aad8fcf19" category="section-title">Préparer la structure du répertoire</block>
  <block id="12f833c44c11e6bbd970cc126bce2bcb" category="paragraph">Si les répertoires requis n'étaient pas déjà présents, vous devez les créer ou la procédure de démarrage de la base de données échoue. Pour préparer la structure de répertoires, remplissez les conditions minimales suivantes.</block>
  <block id="60225c364a012796a6d886e8cf4ec486" category="section-title">Mises à jour du fichier de paramètres</block>
  <block id="e36ee2d9a95a6b672917862d714af383" category="list-text">Pour copier le fichier de paramètres sur le nouveau serveur, exécutez les commandes suivantes. L'emplacement par défaut est le<block ref="45c7302d9c2e8745b3a2bff0f992b6df" prefix=" " category="inline-code"></block> répertoire. Dans ce cas, le fichier pfile peut être placé n'importe où. Il est utilisé uniquement comme étape intermédiaire dans le processus de migration.</block>
  <block id="d437a40a59905247cfb39cf9dc9da256" category="list-text">Modifiez le fichier selon vos besoins. Par exemple, si l'emplacement du journal d'archive a changé, le fichier pfile doit être modifié pour refléter le nouvel emplacement. Dans cet exemple, seuls les fichiers de contrôle sont déplacés, en partie pour les distribuer entre les systèmes de fichiers journaux et de données.</block>
  <block id="55cc35656c3d28c1b3267c246b397521" category="list-text">Une fois les modifications terminées, créez un fichier spfile basé sur ce fichier pfile.</block>
  <block id="a833a03e6af0b969524dcccb8f296f1c" category="section-title">Recréer les fichiers de contrôle</block>
  <block id="74a636ee3a009f08cd5623dc8066dd09" category="paragraph">Dans une étape précédente, la sortie de<block ref="3177841b2335a6640ea3054199830f1c" prefix=" " category="inline-code"></block> a été copié sur le nouveau serveur. La partie spécifique de la sortie requise est le<block ref="0ca1fba455d799b9a1cc2440b9ba7043" prefix=" " category="inline-code"></block> commande. Ces informations se trouvent dans le fichier sous la section marquée<block ref="9fb76d62be749cec8bdd06f46c77bf5b" prefix=" " category="inline-code"></block>. Il commence par la ligne<block ref="13ac20c4a96b2ecfd703e831ad722907" prefix=" " category="inline-code"></block> et doit inclure le mot<block ref="c3c62948f78a7ccaabb9ef2eea80a895" prefix=" " category="inline-code"></block>. Il se termine par le caractère point-virgule (; ).</block>
  <block id="bf4b2a006646a8e77166a2a596425074" category="list-text">Dans cet exemple de procédure, le fichier se lit comme suit.</block>
  <block id="a9a27c002ec883341220e267712250a7" category="list-text">Modifiez ce script comme vous le souhaitez pour refléter le nouvel emplacement des différents fichiers. Par exemple, certains fichiers de données connus pour prendre en charge des E/S élevées peuvent être redirigés vers un système de fichiers sur un niveau de stockage hautes performances. Dans d'autres cas, les modifications peuvent être uniquement pour des raisons d'administrateur, telles que l'isolation des fichiers de données d'un PDB donné dans des volumes dédiés.</block>
  <block id="2540fb1670d4f9ee8a704a7eb8d748fe" category="list-text">Dans cet exemple, le<block ref="b86df74c6982de8dec7509d039294d7a" prefix=" " category="inline-code"></block> la strophe reste inchangée, mais les journaux de reprise sont déplacés vers un nouvel emplacement dans<block ref="96bb85ed0fe822778c4e5a821e991ad8" prefix=" " category="inline-code"></block> plutôt que de partager de l'espace avec les journaux d'archivage<block ref="0e62afc91abe157ef67895cca0a7f912" prefix=" " category="inline-code"></block>.</block>
  <block id="8d47ad079859f2976fdc7ebf742f768d" category="paragraph">Si des fichiers sont mal placés ou si des paramètres sont mal configurés, des erreurs sont générées et indiquent ce qui doit être corrigé. La base de données est montée, mais elle n'est pas encore ouverte et ne peut pas être ouverte car les fichiers de données utilisés sont toujours marqués comme étant en mode de sauvegarde à chaud. Les journaux d'archivage doivent d'abord être appliqués pour rendre la base de données cohérente.</block>
  <block id="6b7c2d588ac708b58f7ac889090608f6" category="section-title">Réplication initiale du journal</block>
  <block id="2db2d3d6001a06d1a027904fa66bc78c" category="paragraph">Au moins une opération de réponse de journal est nécessaire pour rendre les fichiers de données cohérents. De nombreuses options sont disponibles pour relire les journaux. Dans certains cas, l'emplacement du journal d'archivage d'origine sur le serveur d'origine peut être partagé via NFS et la réponse du journal peut être effectuée directement. Dans d'autres cas, les journaux d'archivage doivent être copiés.</block>
  <block id="5c394e6951584d114c6706d0768e30d7" category="paragraph">Par exemple, un simple<block ref="8a444a43bdf534c0c6338bb7809659b3" prefix=" " category="inline-code"></block> l'opération peut copier tous les journaux en cours du serveur source vers le serveur de migration :</block>
  <block id="5fdb3158ed28dd3aa90b94556476b781" category="section-title">Relecture initiale du journal</block>
  <block id="c2f93ef52583f81f0eba05a39483e2d8" category="paragraph">Une fois les fichiers à l'emplacement du journal d'archivage, ils peuvent être relus en exécutant la commande<block ref="5fea768eb2d353716ca623ae58ce382c" prefix=" " category="inline-code"></block> suivi de la réponse<block ref="e1f2d5134ed2543d38a0de9751cf75d9" prefix=" " category="inline-code"></block> pour relire automatiquement tous les journaux disponibles.</block>
  <block id="f30a45a22256018185c5d235292e4d5e" category="paragraph">La réponse finale au journal d'archivage signale une erreur, mais c'est normal. Le journal l'indique<block ref="a84f4f3da79386c29ab6dfa560af786e" prefix=" " category="inline-code"></block> a cherché un fichier journal particulier et ne l'a pas trouvé. La raison est, très probablement, que le fichier journal n'existe pas encore.</block>
  <block id="80bea8a60412cace54760b223b2d799e" category="paragraph">Si la base de données source peut être arrêtée avant de copier les journaux d'archivage, cette étape ne doit être effectuée qu'une seule fois. Les journaux d'archivage sont copiés et relus. Le processus peut ensuite se poursuivre directement vers le processus de mise en service qui réplique les journaux de reprise critiques.</block>
  <block id="1e334141582a9dcb581c9b34ef2df071" category="section-title">Réplication et relecture incrémentielles du journal</block>
  <block id="5fd2b0bf662c2b1ebdc677ea888536ce" category="paragraph">Dans la plupart des cas, la migration n'est pas effectuée immédiatement. La fin du processus de migration peut prendre plusieurs jours, voire plusieurs semaines, ce qui signifie que les journaux doivent être envoyés en continu à la base de données de réplica et relus. Par conséquent, lors de la mise en service, un nombre minimal de données doit être transféré et relu.</block>
  <block id="0c56d82ec6857bcef5475899b9f7b5cc" category="paragraph">Cela peut être scripté de plusieurs manières, mais l'une des méthodes les plus courantes est l'utilisation de rsync, un utilitaire commun de réplication de fichiers. La façon la plus sûre d'utiliser cet utilitaire est de le configurer en tant que démon. Par exemple, le<block ref="b31375af035ed8a698a803a491084f61" prefix=" " category="inline-code"></block> le fichier suivant montre comment créer une ressource appelée<block ref="260e23541ff372b9bc53b4bd3c0c38ba" prefix=" " category="inline-code"></block> Accessible avec les informations d'identification d'utilisateur Oracle et mappé sur<block ref="488a4921a81e36fca411e6f13cefbbf2" prefix=" " category="inline-code"></block>. Plus important encore, la ressource est définie en lecture seule, ce qui permet de lire les données de production sans les modifier.</block>
  <block id="eabf1b424989b2c7113ba3a538079afa" category="paragraph">La commande suivante synchronise la destination du journal d'archive du nouveau serveur avec la ressource rsync<block ref="260e23541ff372b9bc53b4bd3c0c38ba" prefix=" " category="inline-code"></block> sur le serveur d'origine. Le<block ref="e358efa489f58062f10dd7316b65649e" prefix=" " category="inline-code"></block> argument dans<block ref="293e33723231f0504effabb52b054a31" prefix=" " category="inline-code"></block> permet de comparer la liste de fichiers en fonction de l'horodatage et de copier uniquement les nouveaux fichiers. Ce processus fournit une mise à jour incrémentielle du nouveau serveur. Cette commande peut également être planifiée en cron pour s'exécuter de façon régulière.</block>
  <block id="c775c44069da13c8f7ee5c5116e76e36" category="inline-link-macro">Relire les journaux sur la base de données</block>
  <block id="c3bf9b2ef3e3ae2ae6a02f7f77cfcbc6" category="paragraph">Une fois les journaux reçus, ils doivent être relus. Les exemples précédents montrent l'utilisation de sqlplus pour une exécution manuelle<block ref="5fea768eb2d353716ca623ae58ce382c" prefix=" " category="inline-code"></block>, un processus qui peut être facilement automatisé. L'exemple illustré ici utilise le script décrit dans <block ref="3e57a2099043fa40c58f1e0d4eed995d" category="inline-link-macro-rx"></block>. Les scripts acceptent un argument qui spécifie la base de données nécessitant une opération de relecture. Cela permet d'utiliser le même script dans un effort de migration multibase de données.</block>
  <block id="4ea2a6c39b10b3e3076f976f58a861d1" category="section-title">Mise en service</block>
  <block id="5de3f1ba0bbef459baa93f04f63b9ea1" category="paragraph">Lorsque vous êtes prêt à passer au nouvel environnement, vous devez effectuer une synchronisation finale qui inclut à la fois les journaux d'archivage et les journaux de reprise. Si l'emplacement original du journal de reprise n'est pas déjà connu, il peut être identifié comme suit :</block>
  <block id="677f005cc0f8be0f891df5af72fb5688" category="list-text">Arrêtez la base de données source.</block>
  <block id="41b182875e12de118d17b3432cca93fa" category="list-text">Effectuez une synchronisation finale des journaux d'archivage sur le nouveau serveur avec la méthode souhaitée.</block>
  <block id="37d6d9420cef8230249e7691315f0e13" category="list-text">Les fichiers redo log source doivent être copiés sur le nouveau serveur. Dans cet exemple, les journaux de reprise ont été déplacés vers un nouveau répertoire à<block ref="96bb85ed0fe822778c4e5a821e991ad8" prefix=" " category="inline-code"></block>.</block>
  <block id="d0a5f1380bd67b0d0fd3bc72f22d88f2" category="list-text">À ce stade, le nouvel environnement de base de données contient tous les fichiers nécessaires pour le ramener au même état que la source. Les journaux d'archivage doivent être relus une dernière fois.</block>
  <block id="c2721157205b2d2e96c656c45ca72992" category="list-text">Une fois l'opération terminée, les journaux de reprise doivent être relus. Si le message s'affiche<block ref="975df7a5099101ffbe47981cd1d37c2c" prefix=" " category="inline-code"></block> est renvoyé, le processus a réussi et les bases de données sont synchronisées et peuvent être ouvertes.</block>
  <block id="6acab27c5f334c66f06f3f74bc62d6d8" category="section-title">Envoi de journaux - ASM vers le système de fichiers</block>
  <block id="a67ffcc8b155bb909a6f8c5d5ba2f334" category="paragraph">Cet exemple illustre l'utilisation d'Oracle RMAN pour migrer une base de données. Il est très similaire à l'exemple précédent de système de fichiers pour l'envoi de journaux de système de fichiers, mais les fichiers sur ASM ne sont pas visibles par l'hôte. Les seules options de migration des données situées sur les périphériques ASM sont soit le déplacement du LUN ASM, soit l'utilisation d'Oracle RMAN pour effectuer les opérations de copie.</block>
  <block id="1c51600a778919f7f3abb5b25175220a" category="paragraph">Bien que RMAN soit obligatoire pour la copie de fichiers à partir d'Oracle ASM, l'utilisation de RMAN ne se limite pas à ASM. RMAN peut être utilisé pour migrer de tout type de stockage vers tout autre type.</block>
  <block id="2cb6a5bfc4a76f651d496cddc685e078" category="paragraph">Cet exemple montre le déplacement d'une base de données appelée PANCAKE depuis le stockage ASM vers un système de fichiers standard situé sur un serveur différent au niveau des chemins<block ref="f006bf17b06c884c47190c4225d3215a" prefix=" " category="inline-code"></block> et<block ref="0e62afc91abe157ef67895cca0a7f912" prefix=" " category="inline-code"></block>.</block>
  <block id="d1d789c37f1c96d0a5de07798c14fcc5" category="paragraph">La première étape consiste à créer une sauvegarde de la base de données à migrer vers un autre serveur. Comme la source utilise Oracle ASM, RMAN doit être utilisé. Une simple sauvegarde RMAN peut être effectuée comme suit. Cette méthode crée une sauvegarde balisée qui peut être facilement identifiée par RMAN plus tard dans la procédure.</block>
  <block id="ed927706d8abc2bbf3a5a8bc55e1e562" category="paragraph">La première commande définit le type de destination de la sauvegarde et l'emplacement à utiliser. La seconde lance la sauvegarde des fichiers de données uniquement.</block>
  <block id="db85d05166dd65559ae5f426b51198e6" category="section-title">Fichier de contrôle de sauvegarde</block>
  <block id="a0b95d36955723a82dde7bbe40b6ccb9" category="paragraph">Un fichier de contrôle de sauvegarde est requis plus tard dans la procédure pour<block ref="08de2bfcc2d52d5bc4f3f2dcb97558ad" prefix=" " category="inline-code"></block> fonctionnement.</block>
  <block id="76ff543de72e62217293a1d0ceade0aa" category="paragraph">Un fichier de paramètres est également requis dans le nouvel environnement. La méthode la plus simple consiste à créer un fichier pfile à partir du fichier spfile ou pfile actuel. Dans cet exemple, la base de données source utilise un fichier spfile.</block>
  <block id="d28f3a5b77909b45c50e6c711bef8b60" category="section-title">Script de renommage de fichier ASM</block>
  <block id="c242730c760d895368557f78141ff8b1" category="paragraph">Plusieurs emplacements de fichiers actuellement définis dans les fichiers de contrôle changent lorsque la base de données est déplacée. Le script suivant crée un script RMAN pour faciliter le processus. Cet exemple illustre une base de données comportant un très petit nombre de fichiers de données, mais en général, les bases de données contiennent des centaines, voire des milliers de fichiers de données.</block>
  <block id="359b84bcf7447a77b212e844aeaa9d89" category="inline-link-macro">Conversion de noms de système de fichiers ASM en système de fichiers</block>
  <block id="374a1a0facd7c604ac09ed0dca6efb3e" category="paragraph">Ce script est disponible dans <block ref="288325982fd7bee6cf9eb66ad33f6f7a" category="inline-link-macro-rx"></block> et il fait deux choses.</block>
  <block id="42787fdca1cf792241ce03151ec7dbd3" category="paragraph">Tout d'abord, il crée un paramètre pour redéfinir les emplacements du journal de reprise appelés<block ref="0f2d7ef9b967c2d9fb1ad5aa5e9eb688" prefix=" " category="inline-code"></block>. Il s'agit essentiellement d'une liste de champs alternatifs. Le premier champ est l'emplacement d'un journal de reprise en cours et le second est l'emplacement sur le nouveau serveur. Le schéma est alors répété.</block>
  <block id="cf444fd96c87609516f0ad8212f41b01" category="paragraph">La deuxième fonction consiste à fournir un modèle pour renommer le fichier de données. Le script passe en boucle dans les fichiers de données, extrait les informations relatives au nom et au numéro de fichier et les formate en tant que script RMAN. Il fait ensuite la même chose avec les fichiers temporaires. Le résultat est un script rman simple qui peut être modifié comme vous le souhaitez pour vous assurer que les fichiers sont restaurés à l'emplacement souhaité.</block>
  <block id="50614366822786a4f2ee3a5065543634" category="paragraph">Capturer la sortie de cet écran. Le<block ref="0f2d7ef9b967c2d9fb1ad5aa5e9eb688" prefix=" " category="inline-code"></block> le paramètre est placé dans le fichier pfile comme décrit ci-dessous. Le script de renommage et de duplication du fichier de données RMAN doit être modifié en conséquence pour placer les fichiers de données aux emplacements souhaités. Dans cet exemple, ils sont tous placés dans<block ref="36c3572e381980ee1f1343988ae4a955" prefix=" " category="inline-code"></block>.</block>
  <block id="e60cd818b9f7ae02a73d8b3a6ea0a809" category="paragraph">Les scripts sont presque prêts à être exécutés, mais d'abord la structure de répertoire doit être en place. Si les répertoires requis ne sont pas déjà présents, ils doivent être créés ou la procédure de démarrage de la base de données échoue. L'exemple ci-dessous reflète les exigences minimales.</block>
  <block id="2f2eed2ed14ba876a017aa9ea9515724" category="paragraph">La commande suivante est requise pour que des utilitaires tels que oraenv fonctionnent correctement.</block>
  <block id="f34a9f7c077457a54f8838b55b9fc025" category="section-title">Mises à jour des paramètres</block>
  <block id="fd5c3a935e7374f8b1577e73e85ef375" category="paragraph">Le fichier pfile enregistré doit être mis à jour pour refléter toute modification de chemin sur le nouveau serveur. Les modifications du chemin d'accès au fichier de données sont modifiées par le script de duplication RMAN, et presque toutes les bases de données nécessitent des modifications<block ref="d98137bd230dac4372cf20a2e7839463" prefix=" " category="inline-code"></block> et<block ref="2d205df7ae2efff1576140524b40b93c" prefix=" " category="inline-code"></block> paramètres. Il peut également y avoir des emplacements de fichiers d'audit qui doivent être modifiés, ainsi que des paramètres tels que<block ref="40f8833ae28ec69bcc89eb0eba090fe4" prefix=" " category="inline-code"></block> Peut ne pas être pertinent en dehors d'ASM. Un administrateur de base de données expérimenté doit examiner attentivement les modifications proposées avant de poursuivre.</block>
  <block id="b581dd429e9b4c24127b8940ca8e4346" category="paragraph">Dans cet exemple, les changements de clé sont les emplacements des fichiers de contrôle, la destination de l'archive de journal et l'ajout du<block ref="0f2d7ef9b967c2d9fb1ad5aa5e9eb688" prefix=" " category="inline-code"></block> paramètre.</block>
  <block id="bbba1f65801697ba3abd94d90c83ba71" category="paragraph">Une fois les nouveaux paramètres confirmés, les paramètres doivent être mis en vigueur. Plusieurs options existent, mais la plupart des clients créent un fichier spfile basé sur le fichier pfile texte.</block>
  <block id="3a17a12678d74dabb1032aaf373166d8" category="section-title">Nom de démarrage</block>
  <block id="a9dc570a0b3161e69edc31f3545cbf22" category="paragraph">La dernière étape avant la réplication de la base de données consiste à afficher les processus de la base de données, mais pas à monter les fichiers. Dans cette étape, des problèmes avec le fichier spfile peuvent devenir évidents. Si le<block ref="357eedab214bb515c5622e275bc19cdb" prefix=" " category="inline-code"></block> la commande échoue en raison d'une erreur de paramètre, il est simple de s'arrêter, de corriger le modèle pfile, de le recharger en tant que fichier spfile et de réessayer.</block>
  <block id="0257eff4bf9bf0cb483f2544fd42f109" category="section-title">Dupliquez la base de données</block>
  <block id="4632b675c558eda129fe6da4fbbae2b2" category="paragraph">La restauration de la sauvegarde RMAN précédente vers le nouvel emplacement prend plus de temps que les autres étapes de ce processus. La base de données doit être dupliquée sans modification de l'ID de base de données (DBID) ou réinitialisation des journaux. Cela empêche l'application des journaux, ce qui est une étape nécessaire pour synchroniser complètement les copies.</block>
  <block id="06206ea0cdea741420d9f7619503db89" category="paragraph">Connectez-vous à la base de données avec RMAN en tant qu'aux et exécutez la commande duplicate database en utilisant le script créé lors d'une étape précédente.</block>
  <block id="5ae45dfed3c4aff7fe4fd6a7e3606cb0" category="paragraph">Vous devez maintenant envoyer les modifications de la base de données source vers un nouvel emplacement. Cela peut nécessiter une combinaison d'étapes. La méthode la plus simple serait que RMAN sur la base de données source écrive des journaux d'archive sur une connexion réseau partagée. Si aucun emplacement partagé n'est disponible, une autre méthode consiste à utiliser RMAN pour écrire dans un système de fichiers local, puis à utiliser rcp ou rsync pour copier les fichiers.</block>
  <block id="e355807335e5f05930a748afe1c3b23d" category="paragraph">Dans cet exemple, le<block ref="45987b06d5eae35fc3e3487749a9ba27" prefix=" " category="inline-code"></block> Directory est un partage NFS disponible pour la base de données d'origine et migrée.</block>
  <block id="49fffa356bcd041918ce24ef714f3f72" category="paragraph">L'une des questions importantes est la<block ref="6761e3b36547cd115b3966fcbc7192b2" prefix=" " category="inline-code"></block> clause. Le format de disque de la sauvegarde est<block ref="9ae0f22d9fa2eac270499e74092af364" prefix=" " category="inline-code"></block>, Ce qui signifie que vous devez utiliser le format du numéro de thread, du numéro de séquence et de l'ID d'activation de la base de données. Bien que les lettres soient différentes, cela correspond à<block ref="03e92f2c3a8cae5315f0e42bf6acf436" prefix=" " category="inline-code"></block> dans le fichier pfile. Ce paramètre spécifie également les journaux d'archivage au format de numéro de thread, de numéro de séquence et d'ID d'activation. Le résultat final est que les sauvegardes du fichier journal sur la source utilisent une convention de dénomination attendue par la base de données. Cela permet de réaliser des opérations telles que<block ref="81168dbef15af03d02c51a7447378e76" prefix=" " category="inline-code"></block> beaucoup plus simple parce que sqlplus anticipe correctement les noms des journaux d'archive à lire.</block>
  <block id="76d77393c7ffc6b0a0edd47ad09afe4d" category="paragraph">Une fois les fichiers à l'emplacement du journal d'archivage, ils peuvent être relus en exécutant la commande<block ref="5fea768eb2d353716ca623ae58ce382c" prefix=" " category="inline-code"></block> suivi de la réponse<block ref="e1f2d5134ed2543d38a0de9751cf75d9" prefix=" " category="inline-code"></block> pour relire automatiquement tous les journaux disponibles. Le fichier de paramètres dirige actuellement les journaux d'archivage vers<block ref="e421a42fc6f604fcc78707336ed222b9" prefix=" " category="inline-code"></block>, Mais cela ne correspond pas à l'emplacement où RMAN a été utilisé pour enregistrer les journaux. L'emplacement peut être redirigé temporairement comme suit avant de récupérer la base de données.</block>
  <block id="0a96a4559ad3ab8c616a12a207e8daca" category="paragraph">La réponse finale au journal d'archivage signale une erreur, mais c'est normal. L'erreur indique que sqlplus recherchait un fichier journal particulier et qu'il ne l'a pas trouvé. La raison est la plus probable que le fichier journal n'existe pas encore.</block>
  <block id="e2a234d3299b9e66f0756db00c9ee8c7" category="paragraph">Dans la plupart des cas, la migration n'est pas effectuée immédiatement. La fin du processus de migration peut prendre plusieurs jours, voire plusieurs semaines, ce qui signifie que les journaux doivent être envoyés en continu à la base de données de réplica et relus. Ainsi, le transfert et la lecture de données minimales doivent être assurés à l'arrivée de la mise en service.</block>
  <block id="247e1695519da78866726a4dcb2c5252" category="paragraph">Ce processus peut facilement être scripté. Par exemple, la commande suivante peut être planifiée sur la base de données d'origine pour s'assurer que l'emplacement utilisé pour l'envoi des journaux est mis à jour en permanence.</block>
  <block id="3ce19ecb7c874f75b9a46e29abe2012e" category="inline-link-macro">Relire les journaux sur la base de données de secours</block>
  <block id="469d3082a0f3ad08223ba8fe69bf9311" category="paragraph">Une fois les journaux reçus, ils doivent être relus. Des exemples précédents ont montré l'utilisation de sqlplus pour une exécution manuelle<block ref="5fea768eb2d353716ca623ae58ce382c" prefix=" " category="inline-code"></block>, qui peut être facilement automatisé. L'exemple illustré ici utilise le script décrit dans <block ref="7c7730292e0135c86626e1771f7f02ec" category="inline-link-macro-rx"></block>. Le script accepte un argument qui spécifie la base de données nécessitant une opération de relecture. Ce processus permet d'utiliser le même script dans un effort de migration multibase de données.</block>
  <block id="15d3442f7626bb62f4b255c7ed5c5098" category="paragraph">Lorsque vous êtes prêt à passer au nouvel environnement, vous devez effectuer une synchronisation finale. Lorsque vous travaillez avec des systèmes de fichiers réguliers, il est facile de s'assurer que la base de données migrée est synchronisée à 100 % par rapport à l'original car les journaux de reprise d'origine sont copiés et relus. Il n'y a pas de bonne façon de le faire avec ASM. Seuls les journaux d'archivage peuvent être facilement recopiés. Pour s'assurer qu'aucune donnée n'est perdue, l'arrêt final de la base de données d'origine doit être effectué avec précaution.</block>
  <block id="f9952f2469fbec5fc9dca180322ff9ee" category="list-text">Tout d'abord, la base de données doit être mise en veille, en veillant à ce qu'aucune modification ne soit apportée. Cette mise en veille peut inclure la désactivation des opérations planifiées, l'arrêt des auditeurs et/ou l'arrêt des applications.</block>
  <block id="58fd1c52efcde7151ac264a8f67b14ff" category="list-text">Une fois cette étape effectuée, la plupart des administrateurs de bases de données créent une table fictive qui sert de marqueur de l'arrêt.</block>
  <block id="442da9ab2cced82a6cbdd112be285bcf" category="list-text">Forcer l'archivage des journaux pour s'assurer que la création de la table fictive est enregistrée dans les journaux d'archivage. Pour ce faire, exécutez les commandes suivantes :</block>
  <block id="83fce8a41250d6af49205f9659468351" category="list-text">Pour copier le dernier des journaux d'archivage, exécutez les commandes suivantes. La base de données doit être disponible mais pas ouverte.</block>
  <block id="1b0e887c1394d4617c2a5243da19e44e" category="list-text">Pour copier les journaux d'archivage, exécutez les commandes suivantes :</block>
  <block id="86a7e05acb17098c514dd570b9220302" category="list-text">Enfin, rejouez les journaux d'archive restants sur le nouveau serveur.</block>
  <block id="a430882deb5403e7b4b8061dec17cc80" category="list-text">À ce stade, répliquez toutes les données. La base de données est prête à être convertie à partir d'une base de données de secours vers une base de données opérationnelle active, puis ouverte.</block>
  <block id="077c7bcbf9a94bb62aecadc85045886e" category="list-text">Confirmer la présence de la table factice, puis la déposer.</block>
  <block id="6130a27b8ec8ccf18e06bb3389b0fbbd" category="section-title">Migration des journaux de reprise sans interruption</block>
  <block id="26c294f993888218237d5f9306bfcfc4" category="paragraph">Il arrive qu'une base de données soit correctement organisée de manière globale, à l'exception des journaux de reprise. Cela peut se produire pour de nombreuses raisons, dont la plus courante est liée aux snapshots. Des produits tels que SnapManager pour Oracle, SnapCenter et la structure de gestion du stockage NetApp Snap Creator permettent une restauration quasi instantanée d'une base de données, mais uniquement si vous restaurez l'état des volumes de fichiers de données. Si les journaux de reprise partagent l'espace avec les fichiers de données, la restauration ne peut pas être effectuée en toute sécurité, car elle entraînerait la destruction des journaux de reprise, ce qui entraînerait probablement une perte des données. Les journaux de reprise doivent donc être déplacés.</block>
  <block id="2c56f5081b94b926c93c40f4c935a44a" category="paragraph">Cette procédure est simple et peut être effectuée sans interruption.</block>
  <block id="2986f9fe7ed4aab5aaa64c2ee9fe4841" category="section-title">Configuration actuelle du journal de reprise</block>
  <block id="dd786d22c88a5f1fe0c10cfec58c1b44" category="list-text">Identifiez le nombre de groupes de fichiers redo log et leurs numéros de groupe respectifs.</block>
  <block id="3cd0f7a32a4f5ee026702f8125f3dda7" category="list-text">Indiquez la taille des journaux de reprise.</block>
  <block id="7c2f6ada37d59f2be0bc1a3ead80f77c" category="section-title">Créer de nouveaux journaux</block>
  <block id="106b215e5d87fb1256e47932f2ebf9cf" category="list-text">Pour chaque journal de reprise, créez un nouveau groupe avec la taille et le nombre de membres correspondants.</block>
  <block id="0851b65f20b98420968e488fc3c0085e" category="list-text">Vérifiez la nouvelle configuration.</block>
  <block id="cbccec9e0905e0b7f5cd630a3fa12f64" category="section-title">Supprimez les anciens journaux</block>
  <block id="00f63618719701ddae7fc2ff1d406ec2" category="list-text">Supprimez les anciens journaux (groupes 1, 2 et 3).</block>
  <block id="f00c8361a8acc818247282bb6420a8c1" category="list-text">Si vous rencontrez une erreur qui vous empêche de supprimer un journal actif, forcez un commutateur au journal suivant pour libérer le verrouillage et forcer un point de contrôle global. Reportez-vous à l'exemple suivant de ce processus. La tentative de suppression du groupe de fichiers journaux 2, qui se trouvait sur l'ancien emplacement, a été refusée parce qu'il y avait encore des données actives dans ce fichier journal.</block>
  <block id="5d49a93437a42d2926c8be7eb3c7a56f" category="list-text">Un archivage de journaux suivi d'un point de contrôle vous permet de supprimer le fichier journal.</block>
  <block id="e3898c187d7edf64fc8e4d4e409fd244" category="list-text">Supprimez ensuite les journaux du système de fichiers. Vous devez effectuer ce processus avec une extrême prudence.</block>
  <block id="eb290dfcb2d35cffcb49a22fd05168b5" category="summary">Planification de la migration Oracle</block>
  <block id="4e0761b3f22b38640f0d2291420d26f6" category="doc">Planification de la migration d'Iracle</block>
  <block id="dacc2a633e9981c9f91e43ac6b59e889" category="paragraph">La migration des données Oracle peut se faire à l'un des trois niveaux suivants : la base de données, l'hôte ou la baie de stockage.</block>
  <block id="5153193d50d4c628312db2d5bc0132ed" category="paragraph">Les différences résident dans la capacité du composant de la solution globale à déplacer les données : la base de données, le système d'exploitation hôte ou le système de stockage.</block>
  <block id="cc3e73ae592a355b9beb405232d08fe2" category="paragraph">La figure ci-dessous présente un exemple des niveaux de migration et du flux de données. Dans le cas d'une migration au niveau de la base de données, les données sont déplacées du système de stockage d'origine vers le nouvel environnement via les couches hôte et base de données. La migration au niveau de l'hôte est similaire, mais les données ne passent pas par la couche applicative et sont écrites au nouvel emplacement à l'aide de processus hôtes. Enfin, avec la migration au niveau du stockage, une baie telle qu'un système NetApp FAS est responsable du déplacement des données.</block>
  <block id="204415652114bfb773b51cd76c8c692e" category="paragraph"><block ref="204415652114bfb773b51cd76c8c692e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b059e0e23ffaa8fbd97f681942ce0018" category="paragraph">Une migration au niveau de la base de données fait généralement référence à l'utilisation de l'envoi de journaux Oracle via une base de données de secours pour effectuer une migration au niveau de la couche Oracle. Les migrations au niveau de l'hôte s'effectuent à l'aide de la fonctionnalité native de la configuration du système d'exploitation hôte. Cette configuration inclut des opérations de copie de fichiers à l'aide de commandes telles que cp, tar et Oracle Recovery Manager (RMAN) ou à l'aide d'un gestionnaire de volumes logiques (LVM) pour déplacer les octets sous-jacents d'un système de fichiers. Oracle Automatic Storage Management (ASM) est classé comme une fonctionnalité de niveau hôte car elle s'exécute en dessous du niveau de l'application de base de données. ASM remplace le gestionnaire de volumes logiques habituel sur un hôte. Enfin, les données peuvent être migrées au niveau de la baie de stockage, ce qui signifie en dessous du niveau du système d'exploitation.</block>
  <block id="228d9e0418aa12bae73676a5743558db" category="section-title">Planification</block>
  <block id="ce7eea640cd6ee20e55cbe868f4026e9" category="paragraph">La meilleure option de migration dépend de plusieurs facteurs, notamment de l'étendue de l'environnement à migrer, de la nécessité d'éviter les temps d'indisponibilité et des efforts globaux requis pour effectuer la migration. Les bases de données volumineuses nécessitent évidemment plus de temps et d'efforts pour la migration, mais la complexité de cette migration est minimale. Les petites bases de données peuvent être migrées rapidement. Toutefois, si des milliers d'entre elles doivent être migrées, l'ampleur des efforts peut engendrer des complications. Enfin, plus la base de données est volumineuse, plus elle est susceptible d'être stratégique, ce qui entraîne la nécessité de minimiser les temps d'indisponibilité tout en préservant un chemin « back-out ».</block>
  <block id="d4b9b19593598d98059aae44d6a7bbe1" category="paragraph">Voici quelques-uns des éléments à prendre en compte lors de la planification d'une stratégie de migration.</block>
  <block id="931c6f2c99380fbd899e3eaa31e97d98" category="section-title">Taille des données</block>
  <block id="64e4d570abeebacf6bdcb19dfb73fcae" category="paragraph">La taille des bases de données à migrer a de toute évidence un impact sur la planification de la migration, bien que la taille n'ait pas nécessairement un impact sur le délai de mise en service. Lorsqu'une grande quantité de données doit être migrée, la principale considération est la bande passante. Les opérations de copie s'effectuent généralement via des E/S séquentielles efficaces En guise d'estimation prudente, on suppose une utilisation de 50 % de la bande passante réseau disponible pour les opérations de copie. Par exemple, un port FC de 8 Go peut en théorie transférer environ 800 Mbit/s. Si l'on suppose une utilisation de 50 %, une base de données peut être copiée à un taux d'environ 400 Mbit/s. Ainsi, une base de données de 10 To peut être copiée en sept heures environ à ce rythme.</block>
  <block id="84a80a048e7abc027dd6bdce55fda9d2" category="inline-link-macro">Déplacement du fichier de données en ligne</block>
  <block id="1c169b76761527b28040655a783e50a2" category="section-title">Nombre de bases de données</block>
  <block id="da3770c5d6d1215e9f2524b9d7b7c3c5" category="paragraph">Dans de nombreux cas, le problème du déplacement d'une grande quantité de données n'est pas la taille des données, mais plutôt la complexité de la configuration qui prend en charge la base de données. Savoir qu'il faut migrer 50 To de bases de données n'est pas suffisant. Il peut s'agir d'une seule base de données stratégique de 50 To, d'un ensemble de 4 000 bases de données héritées ou d'un mélange de données de production et de données hors production. Dans certains cas, une grande partie des données est constituée de clones d'une base de données source. Il n'est pas nécessaire de migrer ces clones car ils peuvent être recréés facilement, notamment lorsque la nouvelle architecture est conçue pour exploiter les volumes NetApp FlexClone.</block>
  <block id="a1739e745a7544d2432b2b990a715817" category="paragraph">Pour la planification de la migration, vous devez connaître le nombre de bases de données concernées et leur priorité. À mesure que le nombre de bases de données augmente, l'option de migration privilégiée tend à être plus faible et plus faible dans la pile. Par exemple, la copie d'une seule base de données peut s'effectuer facilement avec RMAN et en cas de courte panne. Il s'agit de la réplication au niveau de l'hôte.</block>
  <block id="284723d6a05b50ace5e5b96c761d03ac" category="paragraph">S'il existe 50 bases de données, il peut être plus facile d'éviter de configurer une nouvelle structure de système de fichiers pour recevoir une copie RMAN et de déplacer les données à la place. Ce processus peut être effectué en tirant parti de la migration LVM basée sur l'hôte pour déplacer les données des anciennes LUN vers les nouvelles LUN. L'équipe chargée de l'administration de la base de données (DBA) est alors détransférée vers l'équipe chargée du système d'exploitation pour que les données soient migrées de manière transparente par rapport à la base de données. La configuration du système de fichiers n'est pas modifiée.</block>
  <block id="8e734da04d394519001f47f723341e9d" category="paragraph">Enfin, si 500 bases de données réparties sur 200 serveurs doivent être migrées, des options basées sur le stockage, telles que la fonctionnalité ONTAP Foreign LUN Import (FLI), peuvent être utilisées pour effectuer une migration directe des LUN.</block>
  <block id="39f43935349622951e0f392c83b6e736" category="section-title">Exigences en matière d'architecture</block>
  <block id="50f1558a3f9d47464b5d57f9d9d0f9d1" category="paragraph">En général, l'organisation d'un fichier de base de données doit être modifiée pour exploiter les fonctionnalités de la nouvelle baie de stockage. Toutefois, ce n'est pas toujours le cas. Par exemple, les fonctionnalités des baies 100 % Flash EF-Series se concentrent sur les performances SAN et la fiabilité SAN. Dans la plupart des cas, les bases de données peuvent être migrées vers une baie EF-Series sans tenir compte particulière de la disposition des données. Les seules exigences sont un nombre élevé d'IOPS, une faible latence et une fiabilité robuste. Bien que certaines pratiques d'excellence soient liées à des facteurs tels que la configuration RAID ou les pools de disques dynamiques, les projets EF-Series nécessitent rarement des modifications importantes de l'architecture de stockage globale pour exploiter ces fonctionnalités.</block>
  <block id="0e2c78f7e9948e19ccb1bf2e1b7f0faf" category="paragraph">En revanche, la migration vers ONTAP nécessite généralement une plus grande considération de la disposition de la base de données pour s'assurer que la configuration finale offre une valeur maximale. À elle seule, ONTAP offre de nombreuses fonctionnalités pour un environnement de base de données, même sans effort d'architecture spécifique. Plus important encore, il permet de migrer vers un nouveau matériel sans interruption lorsque le matériel actuel arrive en fin de vie. De manière générale, une migration vers ONTAP est la dernière migration que vous auriez à effectuer. Ensuite, le matériel est mis à niveau et les données sont migrées sans interruption vers de nouveaux supports.</block>
  <block id="ad93bd21d59f2286385dc519fd7e39fb" category="paragraph">Avec une certaine planification, davantage d'avantages sont disponibles. Les considérations les plus importantes concernent l'utilisation des snapshots. Les copies Snapshot sont la base des sauvegardes, des restaurations et des opérations de clonage quasi-instantanées. Comme exemple de la puissance des snapshots, l'utilisation la plus répandue concerne une base de données unique de 996 To qui s'exécute sur environ 250 LUN sur 6 contrôleurs. Cette base de données peut être sauvegardée en 2 minutes, restaurée en 2 minutes et clonée en 15 minutes. Les autres avantages sont la capacité à déplacer les données au sein du cluster en réponse aux modifications des charges de travail et les contrôles de qualité de service (QoS) appliqués pour fournir de bonnes performances cohérentes dans un environnement à plusieurs bases de données.</block>
  <block id="6b48ce64da84423ce167ffb72f5f9a8b" category="inline-link-macro">Présentation des procédures de migration Oracle</block>
  <block id="1311d3b592e4da5950e91965dac1d593" category="paragraph">Les technologies comme les contrôles de qualité de service, la relocalisation des données, la copie Snapshot et le clonage fonctionnent dans presque toutes les configurations. Cependant, certains pensent généralement être nécessaires pour maximiser les avantages. Dans certains cas, les dispositions du stockage de la base de données peuvent nécessiter des modifications de conception afin d'optimiser l'investissement dans la nouvelle baie de stockage. De telles modifications de conception peuvent avoir un impact sur la stratégie de migration, car les migrations basées sur les hôtes ou sur le stockage répliquent la disposition des données d'origine. Des étapes supplémentaires peuvent être nécessaires pour mener à bien la migration et assurer une disposition des données optimisée pour ONTAP. Les procédures indiquées à la <block ref="d4d5600aaaced44e203002ec1910822d" category="inline-link-macro-rx"></block> vous pouvez par la suite présenter certaines méthodes qui vous permettent non seulement de migrer une base de données, mais aussi de la migrer vers la configuration finale optimale en un minimum d'efforts.</block>
  <block id="1fd9b0a8321228b5b8ad4be85e71cf64" category="section-title">Délai de mise en service</block>
  <block id="95b9194d9f06f6f70febc87c071f3050" category="paragraph">Vous devez déterminer la durée maximale autorisée de l'interruption de service pendant la mise en service. C'est une erreur courante de supposer que l'ensemble du processus de migration provoque des perturbations. De nombreuses tâches peuvent être effectuées avant le début d'une interruption de service, et de nombreuses options permettent d'effectuer la migration sans interruption ni panne. Même si une interruption est inévitable, vous devez toujours définir le temps d'interruption de service maximal autorisé, car la durée de la mise en service varie d'une procédure à l'autre.</block>
  <block id="9cfeaf56d2fc41c2695a69adf260c3f8" category="section-title">Chemin de retour arrière</block>
  <block id="f493e16f7e2caba820eba88a1c5f82d8" category="paragraph">Aucune migration n'est totalement sans risque. Même si la technologie fonctionne parfaitement, il y a toujours une possibilité d'erreur de l'utilisateur. Le risque associé au chemin de migration choisi doit être pris en compte parallèlement aux conséquences d'un échec de la migration. Par exemple, la fonctionnalité de migration transparente du stockage en ligne d'Oracle ASM est l'une de ses principales fonctionnalités, et cette méthode est l'une des plus fiables connues. Cependant, les données sont copiées de manière irréversible avec cette méthode. Dans le cas peu probable où un problème se produit avec ASM, il n'y a pas de chemin de sortie simple. La seule option consiste à restaurer l'environnement d'origine ou à utiliser ASM pour restaurer la migration vers les LUN d'origine. Le risque peut être réduit, mais pas éliminé, en effectuant une sauvegarde de type Snapshot sur le système de stockage d'origine, à condition que le système soit capable d'effectuer une telle opération.</block>
  <block id="1886f1ab01daa4511ce537d1af675427" category="section-title">Répétition</block>
  <block id="dd5dac65febd7071311b1ae3be1eca90" category="paragraph">Certaines procédures de migration doivent être entièrement vérifiées avant leur exécution. La nécessité d'une migration et d'une répétition du processus de mise en service est courante dans les bases de données stratégiques pour lesquelles la migration doit réussir et où les temps d'indisponibilité doivent être minimisés. En outre, les tests d'acceptation par l'utilisateur sont fréquemment inclus dans le travail de post-migration et le système global ne peut être remis en production qu'une fois ces tests terminés.</block>
  <block id="7d06b32cdd06d27f7c62fb110d831e60" category="paragraph">S'il est nécessaire de répéter, plusieurs fonctionnalités ONTAP peuvent faciliter le processus. En particulier, les snapshots peuvent réinitialiser un environnement de test et créer rapidement plusieurs copies compactes d'un environnement de base de données.</block>
  <block id="440a667261bd94f099ef4dde5caf024f" category="summary">Migration des fichiers de données Oracle individuels</block>
  <block id="727bb4db430517995ca651c4f57b0c9f" category="doc">Déplacement du fichier de données</block>
  <block id="fade70b277397e039e100bf0faa98d8e" category="paragraph">Vous pouvez déplacer individuellement les fichiers de données Oracle via une seule commande.</block>
  <block id="50c3d56e93d52f122bab9de1f2b35780" category="paragraph">Par exemple, la commande suivante déplace le fichier de données IOPST.dbf du système de fichiers<block ref="87941c54be03c9785752ea54ac9a2dd4" prefix=" " category="inline-code"></block> vers le système de fichiers<block ref="eff8b2f7c4da1cf002bdea257a43fd10" prefix=" " category="inline-code"></block>.</block>
  <block id="53784088a62519d581c3dac4640c41b5" category="paragraph">Le déplacement d'un fichier de données avec cette méthode peut être lent, mais il ne doit normalement pas produire suffisamment d'E/S pour interférer avec les charges de travail quotidiennes des bases de données. En revanche, la migration via le rééquilibrage d'ASM peut s'exécuter beaucoup plus rapidement, mais au détriment du ralentissement de la base de données globale pendant le déplacement des données.</block>
  <block id="f92065612dfd409585ca08d95cc7a4dc" category="paragraph">Le temps nécessaire à la migration des fichiers de données peut être mesuré en créant un fichier de données de test et en le déplaçant. Le temps écoulé pour l'opération est enregistré dans les données v$session :</block>
  <block id="78fb69ccdf01155db62828d0bc182b84" category="paragraph">Dans cet exemple, le fichier déplacé était le fichier de données 8, dont la taille était de 21 Go et dont la migration nécessitait environ 6 minutes. Le temps nécessaire dépend évidemment des capacités du système de stockage, du réseau de stockage et de l'activité globale de la base de données au moment de la migration.</block>
  <block id="593b763e01de37a327966ee1abb3f8a2" category="summary">Migration Oracle à l'aide de la pile de stockage côté hôte</block>
  <block id="174f3246d5f9cdf330404cb6158e67e2" category="doc">Copie des données hôte Oracle</block>
  <block id="3dc2d5f8d7209bb75e8d67aed68bc5ed" category="paragraph">À l'instar de la migration au niveau des bases de données, la migration au niveau de la couche hôte offre une approche indépendante du fournisseur de stockage.</block>
  <block id="1686ceaaa0d8fb4f9a8adb5e717b029c" category="paragraph">En d'autres termes, parfois "juste copier les fichiers" est la meilleure option.</block>
  <block id="d5732a4ab4c633ceb871cebdbf9ae34f" category="paragraph">Bien que cette approche peu technologique puisse sembler trop basique, elle offre des avantages significatifs, car aucun logiciel spécial n'est requis et les données d'origine ne sont pas modifiées en toute sécurité pendant le processus. La principale limitation est le fait qu'une migration de données de copie de fichier est un processus perturbateur, car la base de données doit être arrêtée avant le début de l'opération de copie. Il n'y a pas de bonne façon de synchroniser les modifications dans un fichier, de sorte que les fichiers doivent être complètement suspendus avant le début de la copie.</block>
  <block id="706e7514bb30a289d7ce786a1a5c2ca0" category="paragraph">Si l'arrêt requis par une opération de copie n'est pas souhaitable, la meilleure option basée sur l'hôte suivante consiste à exploiter un gestionnaire de volumes logiques (LVM). De nombreuses options LVM existent, y compris Oracle ASM, toutes avec des capacités similaires, mais avec certaines limitations qui doivent être prises en compte. Dans la plupart des cas, la migration peut s'effectuer sans interruption ni perturbation.</block>
  <block id="f58e97ac8406ca3e8f0bb7a019a81985" category="section-title">Copie du système de fichiers vers le système de fichiers</block>
  <block id="a08ab728e75c63a41ce7571cb781cda2" category="paragraph">L'utilité d'une simple opération de copie ne doit pas être sous-estimée. Cette opération requiert un temps d'indisponibilité lors de la copie, mais le processus est extrêmement fiable et ne requiert aucune expertise particulière en matière de systèmes d'exploitation, de bases de données ou de systèmes de stockage. De plus, elle est très sûre car elle n'affecte pas les données d'origine. Généralement, un administrateur système modifie les systèmes de fichiers source pour qu'ils soient montés en lecture seule, puis redémarre un serveur pour garantir que rien ne risque d'endommager les données actuelles. Le processus de copie peut être scripté pour s'assurer qu'il s'exécute aussi rapidement que possible sans risque d'erreur de l'utilisateur. Comme le type d'E/S est un simple transfert séquentiel de données, il est très peu gourmand en bande passante.</block>
  <block id="ba0bd93801872993ce832352dd03b56a" category="paragraph">L'exemple suivant illustre une option pour une migration sûre et rapide.</block>
  <block id="d8cb8bcd239bbe7a2a488c1d68dbe420" category="paragraph">L'environnement à migrer est le suivant :</block>
  <block id="3ffbdefc66ad1d1e707c1d6820afbdc0" category="list-text">Systèmes de fichiers actuels</block>
  <block id="bdc9e98c6b17bb14a7bce916054413ba" category="list-text">Nouveaux systèmes de fichiers</block>
  <block id="3b878279a04dc47d60932cb294d96259" category="section-title">Présentation</block>
  <block id="e76912cd513cc8cbcabc2735b524e814" category="paragraph">Il suffit à l'administrateur de bases de données de fermer la base de données et de copier les fichiers pour migrer la base de données. Toutefois, ce processus peut être facilement scripté si de nombreuses bases de données doivent être migrées ou si la réduction des temps d'indisponibilité est essentielle. L'utilisation de scripts réduit également les risques d'erreur de l'utilisateur.</block>
  <block id="d21aae9692f3b1d4e53fd73131414b93" category="paragraph">Les exemples de scripts présentés automatisent les opérations suivantes :</block>
  <block id="66909ae9d06bad444f5a059b8ee2cd41" category="list-text">Arrêt de la base de données</block>
  <block id="ae737f3f8c04ccbefa99b2bbf87dccc2" category="list-text">Conversion des systèmes de fichiers existants en état de lecture seule</block>
  <block id="1dd90b7b28cbd03687df6538c66ff494" category="list-text">Copie de toutes les données de la source vers les systèmes de fichiers cibles, ce qui préserve toutes les autorisations de fichier</block>
  <block id="741341be7809d7f5765b2352e6ab0aab" category="list-text">Démontage de l'ancien et du nouveau système de fichiers</block>
  <block id="7465bc030ca3fe236bcf3ecdf8aaebe4" category="list-text">Remontage des nouveaux systèmes de fichiers aux mêmes chemins que les systèmes de fichiers précédents</block>
  <block id="8c4271e6faf2cea4cfc8e5b7108d8ee9" category="section-title">Procédure</block>
  <block id="b273f8d4284bd1f58cfbafe8065af9fa" category="list-text">Arrêtez la base de données.</block>
  <block id="67eadd4b70772835f318e6d3027e4308" category="inline-link-macro">Convertir le système de fichiers en lecture seule</block>
  <block id="474aae6515223cc3ba71074c9d5abcae" category="list-text">Convertissez les systèmes de fichiers en lecture seule. Ceci peut être effectué plus rapidement en utilisant un script, comme indiqué dans la <block ref="2d6e37849c641071fe1cf71ac348d28c" category="inline-link-macro-rx"></block>.</block>
  <block id="4879ec77723fce4974f8ae2a7f87121a" category="list-text">Vérifiez que les systèmes de fichiers sont maintenant en lecture seule.</block>
  <block id="c91e7f5dba3c873d0978f4892bf8b3f2" category="list-text">Synchroniser le contenu du système de fichiers avec le<block ref="89a4551b0f29c1a652648b1cb8747021" prefix=" " category="inline-code"></block> commande.</block>
  <block id="91e702884985853b8a7091ed5f2beceb" category="inline-link-macro">Remplacer le système de fichiers</block>
  <block id="ea27cab9fe7b891870e0ce59aa34e853" category="list-text">Démontez les anciens systèmes de fichiers et déplacez les données copiées. Ceci peut être effectué plus rapidement en utilisant un script, comme indiqué dans la <block ref="fa3b775593af4f3de8972aced258710d" category="inline-link-macro-rx"></block>.</block>
  <block id="5fe2431acb45422c46eadf66a93851af" category="list-text">Vérifiez que les nouveaux systèmes de fichiers sont en place.</block>
  <block id="2d53403ab873059f92ad884eb271e8dc" category="list-text">Démarrez la base de données.</block>
  <block id="40351c33ab81b8b374a20fd292057481" category="section-title">Mise en service entièrement automatisée</block>
  <block id="3f70361470a11fb351c83257cd7aa63e" category="paragraph">Cet exemple de script accepte les arguments du SID de la base de données suivis de paires de systèmes de fichiers délimitées par des points communs. Pour l'exemple ci-dessus, la commande est émise comme suit :</block>
  <block id="5cddd7b314b7ae819e2cfcac85021426" category="paragraph">Lorsqu'il est exécuté, l'exemple de script tente d'exécuter la séquence suivante. Il se termine s'il rencontre une erreur dans une étape :</block>
  <block id="43d4fce7952ee09c0c8df60a17f5ea56" category="list-text">Convertissez les systèmes de fichiers actuels en mode lecture seule.</block>
  <block id="9d53d62d1e6dc69460f47c83e6c1919d" category="list-text">Utilisez chaque paire d'arguments de système de fichiers délimités par des virgules et synchronisez le premier système de fichiers avec le second.</block>
  <block id="39ff0e6dfa9915344ec96f9e78a27267" category="list-text">Démonter les systèmes de fichiers précédents.</block>
  <block id="e220fa2a2806386a64e9860f27372e43" category="list-text">Mettez à jour le<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block> classer comme suit :</block>
  <block id="232c2c4ddd45fc028ae13b58251c5f7e" category="list-text">Créez une sauvegarde à<block ref="9eb56e72a6bb8350a1453c2762d14178" prefix=" " category="inline-code"></block>.</block>
  <block id="d5082ae73767550813688202df21bc4d" category="list-text">Commenter les entrées précédentes pour les systèmes de fichiers antérieurs et nouveaux.</block>
  <block id="b8793b424d1738f1e00e545379867b0d" category="list-text">Créez une nouvelle entrée pour le nouveau système de fichiers qui utilise l'ancien point de montage.</block>
  <block id="29478980f354caa483bc0cfb827c7251" category="list-text">Montez les systèmes de fichiers.</block>
  <block id="a0ec0d8bede7d9d58172084de7d5ce53" category="paragraph">Le texte suivant fournit un exemple d'exécution pour ce script :</block>
  <block id="350265a378d2cb1183cd51d56f0e5843" category="section-title">Migration Oracle ASM spfile et passwd</block>
  <block id="f37bc722651f2fd86ba4da87f947c4db" category="paragraph">Le fichier spfile spécifique à ASM et le fichier de mots de passe constituent une difficulté pour terminer la migration impliquant ASM. Par défaut, ces fichiers de métadonnées critiques sont créés sur le premier groupe de disques ASM défini. Si un groupe de disques ASM particulier doit être évacué et supprimé, le fichier spfile et le fichier de mot de passe qui régissent cette instance ASM doivent être déplacés.</block>
  <block id="88e2a97e52f9854b59ce63e74c4b0cac" category="paragraph">Un autre cas d'utilisation où il peut être nécessaire de déplacer ces fichiers est le cas lors du déploiement d'un logiciel de gestion de base de données, tel que SnapManager pour Oracle ou le plug-in SnapCenter pour Oracle. L'une des fonctionnalités de ces produits consiste à restaurer rapidement une base de données en rétablissant l'état des LUN ASM qui hébergent les fichiers de données. Pour ce faire, vous devez mettre le groupe de disques ASM hors ligne avant d'effectuer une restauration. Ce n'est pas un problème tant que les fichiers de données d'une base de données donnée sont isolés dans un groupe de disques ASM dédié.</block>
  <block id="24de04443b6bdae76336fcab04ae946c" category="paragraph">Lorsque ce groupe de disques contient également le fichier ASM spfile/passwd, la seule façon de mettre le groupe de disques hors ligne est d'arrêter l'instance ASM entière. Il s'agit d'un processus perturbateur, ce qui signifie que le fichier spfile/passwd doit être déplacé.</block>
  <block id="a6221bf4332cc966c69066295a843480" category="list-text">SID de base de données = TOAST</block>
  <block id="0af0da2831407b8130e7f2fabdfab87d" category="list-text">Fichiers de données actuels sur<block ref="c097579d8cb34b312d396304e0b8f487" prefix=" " category="inline-code"></block></block>
  <block id="24aa2824a0b52b46b301afdb3af9336f" category="list-text">Fichiers journaux et fichiers de contrôle actuels sur<block ref="ad6062251d172504e3b3bed3a8256a5a" prefix=" " category="inline-code"></block></block>
  <block id="bb6de9ea84381f7d01fdd038f104e4ae" category="list-text">Nouveaux groupes de disques ASM définis en tant que<block ref="cb2eb5386826561ac7895f1c878e4252" prefix=" " category="inline-code"></block> et<block ref="5e20ccf28224fc0cc564f9825c208dbd" prefix=" " category="inline-code"></block></block>
  <block id="8b14bd9d310bf8b211c19645576201e3" category="section-title">Emplacements des fichiers spfile/passwd ASM</block>
  <block id="7c7d8dd5d09a73f06678562b66dcdc68" category="paragraph">La migration de ces fichiers peut s'effectuer sans interruption. Cependant, pour des raisons de sécurité, NetApp recommande de fermer l'environnement de base de données afin de vous assurer que les fichiers ont été déplacés et que la configuration est correctement mise à jour. Cette procédure doit être répétée si plusieurs instances ASM sont présentes sur un serveur.</block>
  <block id="3666b74ddcf77306328ac5d6db94fecd" category="section-title">Identifier les instances ASM</block>
  <block id="9d19a85576af8e1b3dbd78e343a2b022" category="paragraph">Identifier les instances ASM en fonction des données enregistrées dans le<block ref="9da4474b569071bcb2ece1d0bdfe7560" prefix=" " category="inline-code"></block> fichier. Les instances ASM sont signalées par un symbole +.</block>
  <block id="3fe2dd8cf6f82ac15544fd96f9b59b28" category="paragraph">Il existe une instance ASM appelée +ASM sur ce serveur.</block>
  <block id="35a557b0490d5a93931025eaaf712cac" category="section-title">Assurez-vous que toutes les bases de données sont arrêtées</block>
  <block id="e6b0819ae1eca7d408a097efc2fbf2cf" category="paragraph">Le seul processus smon visible doit être le smon de l'instance ASM utilisée. La présence d'un autre processus smon indique qu'une base de données est toujours en cours d'exécution.</block>
  <block id="97639c779a60f010af01997e2363f4eb" category="paragraph">Le seul processus smon est l'instance ASM elle-même. Cela signifie qu'aucune autre base de données n'est en cours d'exécution et que vous pouvez continuer en toute sécurité sans risque d'interruption des opérations de la base de données.</block>
  <block id="a8d157790e55d19378ddbbdfeb675ef8" category="section-title">Localisez les fichiers</block>
  <block id="12d8c982eb4072e31ac4bfe375193160" category="paragraph">Identifiez l'emplacement actuel du fichier spfile et du fichier de mots de passe ASM à l'aide du<block ref="e258dbf5114b4df07f0d9e72deb386f2" prefix=" " category="inline-code"></block> et<block ref="bb41cdf6c9bb75ee17856f938070f23d" prefix=" " category="inline-code"></block> commandes.</block>
  <block id="bebe64e9d0d4ae3d44b4dfb3583e0109" category="paragraph">Les fichiers se trouvent tous deux à la base du<block ref="c097579d8cb34b312d396304e0b8f487" prefix=" " category="inline-code"></block> groupe de disques.</block>
  <block id="558f28628ba8ab4cb8420949524832d3" category="section-title">Copier des fichiers</block>
  <block id="c0c2c850cb11c5bb52abbd55a9578e54" category="paragraph">Copiez les fichiers dans le nouveau groupe de disques ASM avec le<block ref="c0baea639672c84505e661b9e369c68a" prefix=" " category="inline-code"></block> et<block ref="c7adee97d05083a7b65e4b6953045177" prefix=" " category="inline-code"></block> commandes. Si le nouveau groupe de disques a été créé récemment et est actuellement vide, il peut être nécessaire de le monter en premier.</block>
  <block id="3ed2faf3e1299edd7d92d6c4064f1579" category="paragraph">Les fichiers ont été copiés depuis<block ref="c097579d8cb34b312d396304e0b8f487" prefix=" " category="inline-code"></block> à<block ref="cb2eb5386826561ac7895f1c878e4252" prefix=" " category="inline-code"></block>.</block>
  <block id="1dba5fc559232a8dae45d9f88ed36030" category="section-title">Mettre à jour l'instance ASM</block>
  <block id="1fe2cc6cf436a4bcc6bdc41f947a416a" category="paragraph">L'instance ASM doit maintenant être mise à jour pour refléter le changement d'emplacement. Le<block ref="c8b1affa9ec15d0c0e79347905e75d3e" prefix=" " category="inline-code"></block> et<block ref="73fb08020d8535b4123a8968c596038c" prefix=" " category="inline-code"></block> Les commandes mettent à jour les métadonnées ASM requises pour démarrer le groupe de disques ASM.</block>
  <block id="626759f91a0458b0c068cce8a05a6468" category="section-title">Activez ASM à l'aide de fichiers mis à jour</block>
  <block id="69f08287c6faa04381e5a05f4087abe1" category="paragraph">À ce stade, l'instance ASM utilise toujours les emplacements précédents de ces fichiers. L'instance doit être redémarrée pour forcer une relecture des fichiers à partir de leurs nouveaux emplacements et pour libérer les verrous sur les fichiers précédents.</block>
  <block id="5505cf0c514193b89221f1cef3004c58" category="section-title">Supprimez les anciens fichiers spfile et les anciens fichiers de mots de passe</block>
  <block id="8f2d3ac58be7a91f51d7ce9ffa04e397" category="paragraph">Si la procédure a été effectuée avec succès, les fichiers précédents ne sont plus verrouillés et peuvent maintenant être supprimés.</block>
  <block id="cfca2b2eb0d694e70904ec82f5d1c34e" category="section-title">Copie d'Oracle ASM vers ASM</block>
  <block id="12632d520b8d9518b5622ac00dc764a8" category="paragraph">Oracle ASM est essentiellement un gestionnaire de volumes combiné léger et un système de fichiers. Comme le système de fichiers n'est pas facilement visible, RMAN doit être utilisé pour effectuer des opérations de copie. Même si un processus de migration basé sur la copie est sûr et simple, il provoque certaines perturbations. Les interruptions peuvent être minimisées, mais pas totalement éliminées.</block>
  <block id="152106ebb2aaa94cc87657d353331189" category="paragraph">Si vous souhaitez effectuer une migration sans interruption d'une base de données ASM, il est préférable d'exploiter la capacité d'ASM à rééquilibrer les extensions ASM vers de nouveaux LUN lors de la suppression des anciennes LUN. Cette opération est généralement sûre et non disruptive, mais elle n'offre pas de chemin « back-out ». En cas de problèmes fonctionnels ou de performances, la seule option consiste à migrer les données vers la source.</block>
  <block id="81fe23a1ac3b2bb348e579b2c5b0f5d5" category="paragraph">Ce risque peut être évité en copiant la base de données vers le nouvel emplacement plutôt que de déplacer les données, afin que les données d'origine ne soient pas modifiées. La base de données peut être entièrement testée à son nouvel emplacement avant la mise en service, et la base de données d'origine est disponible comme option de retour en arrière si des problèmes sont détectés.</block>
  <block id="3028182db088e823770b3d02aa0eac9e" category="paragraph">Cette procédure est l'une des nombreuses options impliquant RMAN. Il est conçu pour permettre un processus en deux étapes dans lequel la sauvegarde initiale est créée, puis synchronisée par la suite via la relecture du journal. Ce processus est recommandé pour réduire les temps d'indisponibilité, car il permet à la base de données de rester opérationnelle et d'assurer l'accès aux données pendant la copie de base initiale.</block>
  <block id="634f50a6c6f112c46150a301d749dbcb" category="section-title">Copier la base de données</block>
  <block id="5f0bd85dd65afab1472713e8e034fff7" category="paragraph">Oracle RMAN crée une copie de niveau 0 (complète) de la base de données source actuellement située sur le groupe de disques ASM<block ref="c097579d8cb34b312d396304e0b8f487" prefix=" " category="inline-code"></block> vers le nouvel emplacement sur<block ref="cb2eb5386826561ac7895f1c878e4252" prefix=" " category="inline-code"></block>.</block>
  <block id="b51dc519efad4b151a05682b68f4b182" category="section-title">Forcer le changement de journal d'archivage</block>
  <block id="10793485747151dfa2eaddb0854c84b2" category="paragraph">Vous devez forcer un commutateur de journal d'archivage pour vous assurer que les journaux d'archivage contiennent toutes les données nécessaires pour que la copie soit totalement cohérente. Sans cette commande, les données clés peuvent toujours être présentes dans les journaux de reprise.</block>
  <block id="c55a88a6b8fdc5972d4e2a4924f93dbf" category="section-title">Arrêtez la base de données source</block>
  <block id="9ec82bff06c706f42a8170befdd6cf39" category="paragraph">L'interruption commence à cette étape car la base de données est arrêtée et placée en mode lecture seule à accès limité. Pour arrêter la base de données source, exécutez les commandes suivantes :</block>
  <block id="6ecf02e1343e82cf0cd95d7303346ff1" category="section-title">Sauvegarde Controlfile</block>
  <block id="e7bc82f6d1381df55ace121dc02368e6" category="paragraph">Vous devez sauvegarder le fichier de contrôle si vous devez abandonner la migration et revenir à l'emplacement de stockage d'origine. Une copie du fichier de contrôle de sauvegarde n'est pas nécessaire à 100 %, mais elle facilite le processus de réinitialisation des emplacements des fichiers de base de données vers leur emplacement d'origine.</block>
  <block id="4e7a51f2c1ee60c69cd719d415f5e87a" category="paragraph">Le fichier spfile actuel contient des références aux fichiers de contrôle sur leurs emplacements actuels dans l'ancien groupe de disques ASM. Il doit être édité, ce qui est facile à faire en éditant une version intermédiaire de pfile.</block>
  <block id="253e30479f86461bc79f2fca58ee4cb1" category="section-title">Mettre à jour le fichier pfile</block>
  <block id="35db8a54b9c7581f0f77b059233cc61b" category="paragraph">Mettez à jour tous les paramètres faisant référence aux anciens groupes de disques ASM pour refléter les nouveaux noms de groupes de disques ASM. Enregistrez ensuite le fichier pfile mis à jour. Assurez-vous que le<block ref="5fa1d01559c04dcdb3ba05775712b1ab" prefix=" " category="inline-code"></block> des paramètres sont présents.</block>
  <block id="bb607fbd46f48c3a4080ecda83288b69" category="paragraph">Dans l'exemple ci-dessous, les références à<block ref="c097579d8cb34b312d396304e0b8f487" prefix=" " category="inline-code"></block> ils ont été remplacés par<block ref="cb2eb5386826561ac7895f1c878e4252" prefix=" " category="inline-code"></block> sont surlignés en jaune. Deux paramètres clés sont le<block ref="5fa1d01559c04dcdb3ba05775712b1ab" prefix=" " category="inline-code"></block> paramètres qui créent de nouveaux fichiers à l'emplacement correct.</block>
  <block id="5275e85db4d606621d8f074e44b95748" category="section-title">Mettre à jour le fichier init.ora</block>
  <block id="17a2b5d1af48f7f8d1511d5372896f7a" category="paragraph">La plupart des bases de données ASM utilisent un<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> fichier situé dans le<block ref="45c7302d9c2e8745b3a2bff0f992b6df" prefix=" " category="inline-code"></block> Répertoire, qui est un point vers le fichier spfile sur le groupe de disques ASM. Ce fichier doit être redirigé vers un emplacement du nouveau groupe de disques ASM.</block>
  <block id="6ad274256421918b584abff3b9446b09" category="paragraph">Modifiez ce fichier comme suit :</block>
  <block id="b6638505615764c377e2cf2585993fd0" category="section-title">Récréation du fichier de paramètres</block>
  <block id="52b21c2e6103a3b8d888a4185e21a787" category="paragraph">Le fichier spfile est maintenant prêt à être rempli par les données du fichier pfile modifié.</block>
  <block id="37f4738eddd35e77d15af55a40e1ab1c" category="section-title">Démarrez la base de données pour commencer à utiliser le nouveau fichier spfile</block>
  <block id="79f8a930424fe3b21dc30a72791171d4" category="paragraph">Démarrez la base de données pour vous assurer qu'elle utilise maintenant le fichier spfile nouvellement créé et que toute autre modification des paramètres système est correctement enregistrée.</block>
  <block id="231ef0ea12d142611eeea2fdfad67114" category="section-title">Restaurer le fichier de contrôle</block>
  <block id="33cdbbeabc7f2c647f20b3f8b924307f" category="paragraph">Le fichier de contrôle de sauvegarde créé par RMAN peut également être restauré directement par RMAN à l'emplacement spécifié dans le nouveau fichier spfile.</block>
  <block id="ce656b7f351ebdc7c599aff6a99e0f2a" category="paragraph">Montez la base de données et vérifiez l'utilisation du nouveau fichier de contrôle.</block>
  <block id="fda1e79fe400519496075b7e2871092a" category="section-title">Relecture du journal</block>
  <block id="daaec4441f16b5bac11476d4582a296c" category="paragraph">La base de données utilise actuellement les fichiers de données dans l'ancien emplacement. Avant de pouvoir utiliser la copie, elles doivent être synchronisées. Le temps s'est écoulé pendant le processus de copie initial et les modifications ont été enregistrées principalement dans les journaux d'archivage. Ces modifications sont répliquées comme suit :</block>
  <block id="fca6726270a94f51cab3142509d32919" category="list-text">Effectuez une sauvegarde incrémentielle RMAN contenant les journaux d'archivage.</block>
  <block id="8b8a5667b011b5f37163ff4da1004343" category="list-text">Relire le journal.</block>
  <block id="a9a62e70841c4d06dd16306a85700d36" category="section-title">Activation</block>
  <block id="8fecb0145484a35b1d9d5926c945ca30" category="paragraph">Le fichier de contrôle restauré fait toujours référence aux fichiers de données à l'emplacement d'origine et contient également les informations de chemin des fichiers de données copiés.</block>
  <block id="f590db5fdc10f6942f7cd173c0bb578b" category="list-text">Pour modifier les fichiers de données actifs, exécutez<block ref="7705ebb59373d0b1dfc71d86ef726f93" prefix=" " category="inline-code"></block> commande.</block>
  <block id="2c5c2b5174eafe321358329636e80f5e" category="paragraph">Les fichiers de données actifs sont désormais les fichiers de données copiés, mais des modifications peuvent encore être contenues dans les journaux de reprise finaux.</block>
  <block id="fe83c5826bec1aa20e26802fa94a4a0f" category="list-text">Pour relire tous les journaux restants, exécutez le<block ref="81168dbef15af03d02c51a7447378e76" prefix=" " category="inline-code"></block> commande. Si le message s'affiche<block ref="cef3519da39a73834e89a18ca91951f1" prefix=" " category="inline-code"></block> apparaît, le processus a réussi.</block>
  <block id="15434ad90ad32205a804fe96f265b91d" category="paragraph">Ce processus a uniquement modifié l'emplacement des fichiers de données normaux. Les fichiers de données temporaires doivent être renommés, mais ils n'ont pas besoin d'être copiés car ils sont temporaires uniquement. La base de données est actuellement inactive, il n'y a donc pas de données actives dans les fichiers de données temporaires.</block>
  <block id="2a7c5560f8e4ad220c853666c46eb051" category="list-text">Pour déplacer les fichiers de données temporaires, identifiez d'abord leur emplacement.</block>
  <block id="10b2632cf9c3bf6568b36f6a37e627c2" category="list-text">Déplacez les fichiers de données temporaires à l'aide d'une commande RMAN qui définit le nouveau nom de chaque fichier de données. Avec Oracle Managed Files (OMF), le nom complet n'est pas nécessaire ; le groupe de disques ASM est suffisant. Lorsque la base de données est ouverte, OMF est lié à l'emplacement approprié sur le groupe de disques ASM. Pour déplacer des fichiers, exécutez les commandes suivantes :</block>
  <block id="2c592b1e2841899b280deafe27eeefbf" category="section-title">Migration du journal de reprise</block>
  <block id="3f53598059c3bf11ff505ad9dc0d6776" category="paragraph">Le processus de migration est presque terminé, mais les journaux de reprise se trouvent toujours sur le groupe de disques ASM d'origine. Les journaux de reprise ne peuvent pas être transférés directement. Un nouvel ensemble de journaux de reprise est créé et ajouté à la configuration, suivi d'un DROP des anciens journaux.</block>
  <block id="d54f1c98a924385411a8488657b21dad" category="list-text">Pour chaque journal de reprise, créez un groupe avec une configuration correspondante. Si vous n'utilisez pas OMF, vous devez spécifier le chemin complet. C'est également un exemple qui utilise le<block ref="c9655c773db3ebd5871fbe76c0e38a52" prefix=" " category="inline-code"></block> paramètres. Comme indiqué précédemment, ce paramètre a été défini sur +NEWLOGS. Cette configuration vous permet d'utiliser les commandes suivantes pour créer de nouveaux journaux en ligne sans avoir à spécifier un emplacement de fichier ou même un groupe de disques ASM spécifique.</block>
  <block id="3e0c7c8ee841e9919343fe45e3e04f2d" category="list-text">Ouvrez la base de données.</block>
  <block id="7e4b38db083a404d0d628bdb1ad83311" category="list-text">Supprimez les anciens journaux.</block>
  <block id="37e48dd687a01e58ed329feebebf3198" category="list-text">Si vous rencontrez une erreur qui vous empêche de supprimer un journal actif, forcez un commutateur au journal suivant pour libérer le verrouillage et forcer un point de contrôle global. Un exemple est illustré ci-dessous. La tentative de suppression du groupe de fichiers journaux 3, qui se trouvait sur l'ancien emplacement, a été refusée parce qu'il y avait encore des données actives dans ce fichier journal. Un archivage de journaux après un point de contrôle vous permet de supprimer le fichier journal.</block>
  <block id="79d08abfbe5fd73dc85c55cd20ad4974" category="list-text">Vérifiez l'environnement pour vous assurer que tous les paramètres basés sur l'emplacement sont mis à jour.</block>
  <block id="799f5ce04f1d9cad4455676b2fd908d9" category="list-text">Le script suivant explique comment simplifier ce processus :</block>
  <block id="9867dfc0eee2725f24f86d8114c356a0" category="list-text">Si les groupes de disques ASM ont été complètement évacués, ils peuvent maintenant être démontés avec<block ref="ae709dc3414219bf2c9c8abc9ff6c67a" prefix=" " category="inline-code"></block>. Cependant, dans de nombreux cas, les fichiers appartenant à d'autres bases de données ou au fichier ASM spfile/passwd peuvent toujours être présents.</block>
  <block id="49f8dc5754bd205ea0da17521cb89a1f" category="section-title">Copie d'Oracle ASM vers le système de fichiers</block>
  <block id="0f5b1767a58e43cb548226e94441dc07" category="paragraph">La procédure de copie d'Oracle ASM vers un système de fichiers est très similaire à la procédure de copie d'ASM vers ASM, avec des avantages et des restrictions similaires. La différence principale est la syntaxe des différentes commandes et paramètres de configuration lors de l'utilisation d'un système de fichiers visible par opposition à un groupe de disques ASM.</block>
  <block id="b533404c568b600f9fceddeac9253964" category="paragraph">Oracle RMAN permet de créer une copie de niveau 0 (complète) de la base de données source actuellement située sur le groupe de disques ASM<block ref="c097579d8cb34b312d396304e0b8f487" prefix=" " category="inline-code"></block> vers le nouvel emplacement sur<block ref="f006bf17b06c884c47190c4225d3215a" prefix=" " category="inline-code"></block>.</block>
  <block id="f78b0ab71e2863c28dbe331056451135" category="paragraph">Forcer le commutateur de journal d'archivage est nécessaire pour s'assurer que les journaux d'archivage contiennent toutes les données requises pour rendre la copie entièrement cohérente. Sans cette commande, les données clés peuvent toujours être présentes dans les journaux de reprise. Pour forcer un commutateur de journal d'archivage, exécutez la commande suivante :</block>
  <block id="c37c761fc28428b9ead4533aba9ee148" category="paragraph">L'interruption commence à cette étape car la base de données est arrêtée et placée en mode lecture seule à accès limité. Pour arrêter la base de données source, exécutez les commandes suivantes :</block>
  <block id="3abd8870d8a333edcaec6a1082520c67" category="paragraph">Sauvegarder les fichiers de contrôle si vous devez abandonner la migration et revenir à l'emplacement de stockage d'origine. Une copie du fichier de contrôle de sauvegarde n'est pas nécessaire à 100 %, mais elle facilite le processus de réinitialisation des emplacements des fichiers de base de données vers leur emplacement d'origine.</block>
  <block id="38825215f02e25ca63ff64387b01c1c2" category="paragraph">Tous les paramètres faisant référence aux anciens groupes de disques ASM doivent être mis à jour et, dans certains cas, supprimés lorsqu'ils ne sont plus pertinents. Mettez-les à jour pour refléter les nouveaux chemins du système de fichiers et enregistrez le fichier pfile mis à jour. Assurez-vous que le chemin cible complet est répertorié. Pour mettre à jour ces paramètres, exécutez les commandes suivantes :</block>
  <block id="9d0dce3e570fa0ec18269ca508809401" category="section-title">Désactivez le fichier init.ora d'origine</block>
  <block id="03dda6526778417460fd0bbb7716b373" category="paragraph">Ce fichier se trouve dans le<block ref="45c7302d9c2e8745b3a2bff0f992b6df" prefix=" " category="inline-code"></block> Et se trouve généralement dans un fichier pfile qui sert de pointeur vers le fichier spfile sur le groupe de disques ASM. Pour vous assurer que le fichier spfile d'origine n'est plus utilisé, renommez-le. Ne le supprimez pas, cependant, car ce fichier est nécessaire si la migration doit être abandonnée.</block>
  <block id="6087f741090627369fd114fbc794abc4" category="paragraph">Il s'agit de la dernière étape de la relocalisation de fichier spfile. Le fichier spfile d'origine n'est plus utilisé et la base de données est actuellement démarrée (mais pas montée) à l'aide du fichier intermédiaire. Le contenu de ce fichier peut être écrit dans le nouvel emplacement spfile comme suit :</block>
  <block id="3f62847435205b7b2af1bd5aaf1d3277" category="paragraph">Vous devez démarrer la base de données pour libérer les verrous sur le fichier intermédiaire et démarrer la base de données en utilisant uniquement le nouveau fichier spfile. Le démarrage de la base de données prouve également que le nouvel emplacement spfile est correct et que ses données sont valides.</block>
  <block id="ea164abfd83078cd71a2f3ba5d237900" category="paragraph">Un fichier de contrôle de sauvegarde a été créé au niveau du chemin<block ref="7a1a1280501cff0194d8ce6e351f2a2c" prefix=" " category="inline-code"></block> plus tôt dans la procédure. Le nouveau fichier spfile définit les emplacements des fichiers de contrôle comme <block ref="b4d54c88ccade13a82dcaf8f7c07cac5" prefix="/" category="inline-code"></block> et<block ref="cd300fb0386526438b368e7a6d1b8ace" prefix=" " category="inline-code"></block>. Cependant, ces fichiers n'existent pas encore.</block>
  <block id="f7ed72e578ca8d23dd45bfa2c0a61ed8" category="list-text">Cette commande restaure les données du fichier de contrôle dans les chemins définis dans le fichier spfile.</block>
  <block id="c947c89cb4c7a595782d0be73bbe8cfa" category="list-text">Exécutez la commande mount pour que les fichiers de contrôle soient correctement découverts et contiennent des données valides.</block>
  <block id="da4ae71a31a1286600968f8a340fddb2" category="paragraph">Pour valider le<block ref="d98137bd230dac4372cf20a2e7839463" prefix=" " category="inline-code"></block> paramètre, exécutez la commande suivante :</block>
  <block id="c25a81770c591c46d6909aae84bf5814" category="paragraph">La base de données utilise actuellement les fichiers de données dans l'ancien emplacement. Avant de pouvoir utiliser la copie, les fichiers de données doivent être synchronisés. Le temps s'est écoulé pendant le processus de copie initial et les modifications ont été enregistrées principalement dans les journaux d'archivage. Ces modifications sont répliquées dans les deux étapes suivantes.</block>
  <block id="95ea23a5654037c0ab2a5418478d9da2" category="list-text">Relire les journaux.</block>
  <block id="e726fdb8508ef59abc6d8ef533186382" category="list-text">Pour modifier les fichiers de données actifs, exécutez<block ref="7705ebb59373d0b1dfc71d86ef726f93" prefix=" " category="inline-code"></block> commande :</block>
  <block id="7fdba4cfea0e0d298cda23e7f46e40c4" category="list-text">Bien que les fichiers de données soient parfaitement cohérents, une dernière étape est nécessaire pour relire les modifications restantes enregistrées dans les journaux de reprise en ligne. Utilisez le<block ref="81168dbef15af03d02c51a7447378e76" prefix=" " category="inline-code"></block> pour relire ces modifications et rendre la copie identique à 100 % à l'original. Toutefois, la copie n'est pas encore ouverte.</block>
  <block id="8eb94d53286760da56ca9c892a49cd8b" category="section-title">Déplacer les fichiers de données temporaires</block>
  <block id="a1e7f15bee0eaa976661307aa884fd99" category="list-text">Identifiez l'emplacement des fichiers de données temporaires toujours en cours d'utilisation sur le groupe de disques d'origine.</block>
  <block id="89b79c94ceba42d5bc646c1b4b1acd24" category="list-text">Pour déplacer les fichiers de données, exécutez les commandes suivantes. S'il existe de nombreux fichiers tempfiles, utilisez un éditeur de texte pour créer la commande RMAN, puis coupez-la et collez-la.</block>
  <block id="81aa65cb154a5f125bbf3ede064d4b3f" category="paragraph">Le processus de migration est presque terminé, mais les journaux de reprise se trouvent toujours sur le groupe de disques ASM d'origine. Les journaux de reprise ne peuvent pas être transférés directement. Un nouvel ensemble de journaux de reprise est créé et ajouté à la configuration, suivant un DROP des anciens journaux.</block>
  <block id="6e46687c6cc5deabe53fa42932683c4d" category="list-text">Pour chaque fichier redo log, créez un groupe en utilisant la même taille que le groupe de fichiers redo log actuel à l'aide du nouvel emplacement du système de fichiers.</block>
  <block id="22fd48a866ce4d04edb57c15b2fad5da" category="list-text">Supprimez les anciens groupes de fichiers journaux qui se trouvent toujours sur le stockage précédent.</block>
  <block id="94158400e59555bf69ecd550887bd9f6" category="list-text">Si une erreur bloque la suppression d'un journal actif, forcez un commutateur au journal suivant pour libérer le verrouillage et forcer un point de contrôle global. Un exemple est illustré ci-dessous. La tentative de suppression du groupe de fichiers journaux 3, qui se trouvait sur l'ancien emplacement, a été refusée parce qu'il y avait encore des données actives dans ce fichier journal. L'archivage des journaux suivi d'un point de contrôle permet la suppression des fichiers journaux.</block>
  <block id="326770a786c5933416b6a167c854e7b8" category="list-text">Le script suivant explique comment faciliter ce processus.</block>
  <block id="ffdcdc8ee9653232a906773fa11358fd" category="list-text">Si les groupes de disques ASM ont été complètement évacués, ils peuvent maintenant être démontés avec<block ref="ae709dc3414219bf2c9c8abc9ff6c67a" prefix=" " category="inline-code"></block>. Dans de nombreux cas, les fichiers appartenant à d'autres bases de données ou au fichier ASM spfile/passwd peuvent toujours être présents.</block>
  <block id="3d8b8f4734039817e35d5fb6993c8d08" category="section-title">Procédure de nettoyage du fichier de données</block>
  <block id="637607e2203ac522fc9dbc88deb6c36f" category="inline-link-macro">Nettoyage de migration ASM</block>
  <block id="18325b8b206963bc1ae6cca25406f942" category="paragraph">Le processus de migration peut donner lieu à des fichiers de données avec une syntaxe longue ou chiffrée, selon la façon dont Oracle RMAN a été utilisé. Dans l'exemple illustré ici, la sauvegarde a été effectuée avec le format de fichier de<block ref="1da91ad80bcfeb818066022a42cde773" prefix=" " category="inline-code"></block>.<block ref="432459869b7d0085e120ec9454032267" prefix=" " category="inline-code"></block> Indique que RMAN doit créer un nom unique par défaut pour chaque fichier de données. Le résultat est similaire à ce qui est affiché dans le texte suivant. Les noms traditionnels des fichiers de données sont incorporés dans les noms. Pour ce faire, utilisez l'approche par script illustrée à la <block ref="bf0c2c579af181f7d1e4d0267c1385fe" category="inline-link-macro-rx"></block>.</block>
  <block id="5e8488a95f83d2789417a1f3298f2f31" category="section-title">Rééquilibrage d'Oracle ASM</block>
  <block id="2768938325db3a71a6713959a0f309d9" category="paragraph">Comme nous l'avons vu précédemment, un groupe de disques Oracle ASM peut être migré en toute transparence vers un nouveau système de stockage en utilisant le processus de rééquilibrage. En résumé, le processus de rééquilibrage nécessite l'ajout de LUN de taille égale au groupe existant de LUN, suivi d'une opération de DROP de la LUN précédente. Oracle ASM déplace automatiquement les données sous-jacentes vers un nouveau stockage selon une disposition optimale, puis libère les anciens LUN une fois l'opération terminée.</block>
  <block id="24a638b29b3c55f26c731aa4b9943a52" category="paragraph">Le processus de migration utilise des E/S séquentielles efficaces et ne provoque généralement aucune interruption des performances. En revanche, le taux de migration peut être ralenti lorsque cela est nécessaire.</block>
  <block id="25d06b03dd002ad791b19500c58e9f72" category="section-title">Identifiez les données à migrer</block>
  <block id="3709d4034873467e8e6ae138da54a443" category="section-title">Créer des LUN</block>
  <block id="32176bd565539329eafb96db9447e517" category="paragraph">Créez de nouvelles LUN de la même taille et définissez l'appartenance des utilisateurs et des groupes selon les besoins. Les LUN doivent s'afficher comme<block ref="bea4821516973214973a70aea8337c38" prefix=" " category="inline-code"></block> disques.</block>
  <block id="6e59535a7b8dd239c67b8d015618f5e1" category="section-title">Ajouter de nouvelles LUN</block>
  <block id="71f7e1ff1a6e075f8364d083f145b655" category="paragraph">Même si les opérations d'ajout et de suppression peuvent être effectuées ensemble, il est généralement plus facile d'ajouter de nouvelles LUN en deux étapes. Commencez par ajouter les nouvelles LUN au groupe de disques. Cette étape entraîne la migration de la moitié des extensions des LUN ASM actuelles vers les nouvelles LUN.</block>
  <block id="7989dfdf722e8bee00001dac817e4833" category="paragraph">La puissance de rééquilibrage indique la vitesse à laquelle les données sont transférées. Plus le nombre est élevé, plus le parallélisme du transfert de données est élevé. La migration s'effectue au moyen d'opérations d'E/S séquentielles efficaces, peu susceptibles d'entraîner des problèmes de performances. Toutefois, si nécessaire, le pouvoir de rééquilibrage d'une migration en cours peut être ajusté avec le<block ref="e20ea7dfbbe351f6a5275d7adc71efbd" prefix=" " category="inline-code"></block> commande. Les migrations types utilisent une valeur de 5.</block>
  <block id="2b69f08c262a142b3fb0868f4d31ab4f" category="section-title">Surveiller le fonctionnement</block>
  <block id="a5097a0967c777285f74d63bf0cc26a1" category="paragraph">Une opération de rééquilibrage peut être contrôlée et gérée de plusieurs manières. Nous avons utilisé la commande suivante dans cet exemple.</block>
  <block id="5d68829c11bdb5ae7a50b847bb126d44" category="paragraph">Une fois la migration terminée, aucune opération de rééquilibrage n'est signalée.</block>
  <block id="957310262614cddc1992368d2d0b14b3" category="section-title">Supprimez les anciennes LUN</block>
  <block id="260c16583c8eb689202ed5b4a44708b1" category="paragraph">La migration est maintenant terminée à mi-chemin. Il peut être souhaitable d'effectuer quelques tests de performances de base pour s'assurer que l'environnement est sain. Après confirmation, les données restantes peuvent être déplacées en déposant les anciennes LUN. Notez que cela ne provoque pas la publication immédiate des LUN. L'opération de DROP indique à Oracle ASM de déplacer d'abord les extensions, puis de libérer la LUN.</block>
  <block id="90423249814011b02ba06afd9fb2d617" category="paragraph">L'opération de rééquilibrage peut être contrôlée et gérée de plusieurs manières. Nous avons utilisé la commande suivante dans cet exemple :</block>
  <block id="1544b3a52519b3856f1f7d1e704cb56f" category="section-title">Supprimer les anciens LUN</block>
  <block id="983d704730b30910fc03d3ed444278f0" category="paragraph">Avant de supprimer les anciennes LUN du groupe de disques, vous devez effectuer une dernière vérification de l'état de l'en-tête. Une fois qu'une LUN est libérée d'ASM, son nom n'est plus répertorié et son état est répertorié comme<block ref="e2ffc99cf675f5f0f1a3456438551a9a" prefix=" " category="inline-code"></block>. Cela signifie que ces LUN peuvent être supprimées du système en toute sécurité.</block>
  <block id="22a67c375eff91d37f2363ea69b0c41f" category="section-title">Migration LVM</block>
  <block id="d52f83c78118c243801797ba9b795b72" category="paragraph">La procédure présentée ici présente les principes d'une migration basée sur LVM d'un groupe de volumes appelé<block ref="ec2db4422261eae02091227fb9e53c88" prefix=" " category="inline-code"></block>. Les exemples sont tirés du LVM Linux, mais les principes s'appliquent également à AIX, HP-UX et VxVM. Les commandes précises peuvent varier.</block>
  <block id="64a375907ede7a86c9e8a1b4b142f22e" category="list-text">Identifiez les LUN actuellement dans le<block ref="ec2db4422261eae02091227fb9e53c88" prefix=" " category="inline-code"></block> groupe de volumes.</block>
  <block id="0ae75856dd12545cdd98b8cad5c12ad8" category="list-text">Créez de nouvelles LUN de taille physique identique ou légèrement supérieure et définissez-les comme volumes physiques.</block>
  <block id="2426fa707e9d362c711977b79acd65bb" category="list-text">Ajoutez les nouveaux volumes au groupe de volumes.</block>
  <block id="02443ebd7f86c3a688a1e3466d3f106a" category="list-text">Émettez le<block ref="8167c9a6bd495f7ed235364201039099" prefix=" " category="inline-code"></block> Commande permettant de déplacer les extensions de chaque LUN actuelle vers la nouvelle LUN. Le<block ref="1b464374742cfda0167b82bc6f9462f1" prefix=" " category="inline-code"></block> l'argument surveille la progression de l'opération.</block>
  <block id="ce4a174d56245f6ba5b8808527919921" category="list-text">Une fois ce processus terminé, supprimez les anciennes LUN du groupe de volumes à l'aide du<block ref="3a4d1e7b0af1cf3d80e419c09d238535" prefix=" " category="inline-code"></block> commande. En cas de réussite, la LUN peut être supprimée en toute sécurité du système.</block>
  <block id="599a80136f745b38f35077e1c7eb020e" category="summary">Procédures de migration Oracle</block>
  <block id="329ffa7a9038afa62748f87628b749d5" category="paragraph">De nombreuses procédures sont disponibles pour la migration d'une base de données Oracle. Le bon dépend des besoins de votre entreprise.</block>
  <block id="48a2d08de8943e7ca4718c02e6b791b6" category="paragraph">Dans de nombreux cas, les administrateurs système et les administrateurs de bases de données utilisent leurs propres méthodes de déplacement des données de volume physique, de mise en miroir et de déréplication, ou d'utilisation d'Oracle RMAN pour la copie des données.</block>
  <block id="79d01f6e7efcfef7db530c0b3c5ea516" category="paragraph">Ces procédures sont fournies principalement à titre de conseils pour le personnel INFORMATIQUE qui connaît moins bien certaines des options disponibles. En outre, ces procédures illustrent les tâches, les exigences en termes de temps et les besoins en compétences de chaque approche de migration. Ainsi, d'autres parties, telles que NetApp et les services professionnels partenaires ou la direction INFORMATIQUE, peuvent mieux apprécier les exigences de chaque procédure.</block>
  <block id="5604c71a7d9ae37df511cc85052c1894" category="paragraph">Il n'existe pas de meilleure pratique unique pour créer une stratégie de migration. Pour créer un plan, il faut d'abord comprendre les options de disponibilité, puis sélectionner la méthode la mieux adaptée aux besoins de l'entreprise. La figure ci-dessous illustre les considérations de base et les conclusions types des clients, mais elle n'est pas universellement applicable à toutes les situations.</block>
  <block id="fa2e72668f7d48694bef3ba5474e3967" category="paragraph">Par exemple, une étape soulève le problème de la taille totale de la base de données. L'étape suivante dépend si la base de données est supérieure ou inférieure à 1 To. Les étapes recommandées sont précisément des recommandations basées sur les pratiques standard des clients. La plupart des clients n'utiliseraient pas DataGuard pour copier une petite base de données, mais d'autres pourraient le faire. La plupart des clients ne tenteraient pas de copier une base de données de 50 To en raison du temps nécessaire, mais certaines peuvent disposer d'une fenêtre de maintenance suffisamment longue pour permettre une telle opération.</block>
  <block id="82f59f5f005a6ea06f0466a4ffc18b6c" category="paragraph">Vous trouverez un organigramme des différents types de considérations sur le meilleur chemin de migration <block ref="d197151b12289ca0258c12e9b0e8fb1c" category="inline-link-macro-rx"></block>.</block>
  <block id="e38af1623479eee6cfe1782df43819d3" category="paragraph">Oracle 12cR1 et versions supérieures incluent la possibilité de déplacer un fichier de données pendant que la base de données reste en ligne. Il fonctionne en outre entre différents types de systèmes de fichiers. Par exemple, un fichier de données peut être déplacé d'un système de fichiers xfs vers ASM. Cette méthode n'est généralement pas utilisée à grande échelle en raison du nombre d'opérations de déplacement de fichiers de données individuelles qui seraient requises. Toutefois, il est important de tenir compte de cette méthode avec des bases de données plus petites et moins de fichiers de données.</block>
  <block id="5972a038819f045814401b2baea9ee09" category="paragraph">En outre, le simple déplacement d'un fichier de données est une bonne option pour migrer des parties de bases de données existantes. Par exemple, les fichiers de données moins actifs peuvent être transférés vers un stockage plus économique, tel qu'un volume FabricPool qui peut stocker les blocs inactifs dans le magasin d'objets.</block>
  <block id="fcdd0d9eae6df775f1bdc52f950a0160" category="section-title">Migration au niveau de la base de données</block>
  <block id="2b619622b2b8505c335acc8be3a2c3fd" category="paragraph">La migration au niveau de la base de données signifie que la base de données peut déplacer des données. Plus précisément, cela signifie l'envoi de journaux. Des technologies telles que RMAN et ASM sont des produits Oracle, mais pour la migration, elles fonctionnent au niveau de l'hôte où elles copient les fichiers et gèrent les volumes.</block>
  <block id="1048000638cc5357b8b2b36ab55cbc5a" category="section-title">Envoi de journaux</block>
  <block id="36f7294e33f88b462199b92362434684" category="paragraph">La base de la migration au niveau de la base de données est le journal d'archivage Oracle, qui contient un journal des modifications apportées à la base de données. La plupart du temps, un journal d'archivage fait partie d'une stratégie de sauvegarde et de restauration. Le processus de restauration commence par la restauration d'une base de données, puis la relecture d'un ou plusieurs journaux d'archivage pour ramener la base de données à l'état souhaité. Cette même technologie de base peut être utilisée pour effectuer une migration avec une interruption des opérations nulle ou minime. Plus important encore, cette technologie permet la migration tout en conservant la base de données d'origine intacte, ce qui permet de conserver un chemin de retour.</block>
  <block id="d43de5ded302797939b76670bc488b51" category="paragraph">Le processus de migration commence par la restauration d'une sauvegarde de base de données sur un serveur secondaire. Vous pouvez le faire de différentes manières, mais la plupart des clients utilisent leur application de sauvegarde normale pour restaurer les fichiers de données. Une fois les fichiers de données restaurés, les utilisateurs établissent une méthode d'envoi des journaux. L'objectif est de créer un flux constant de journaux d'archivage générés par la base de données primaire et de les relire sur la base de données restaurée afin de les conserver dans un état similaire. Lorsque le délai de mise en service arrive, la base de données source est complètement arrêtée et les journaux d'archivage finaux, et dans certains cas les journaux de reprise, sont copiés et relus. Il est essentiel que les journaux de reprise soient également pris en compte, car ils peuvent contenir certaines des transactions finales validées.</block>
  <block id="f6fc42763ddbd981d5803ee6676dc7c3" category="paragraph">Une fois ces journaux transférés et relus, les deux bases de données sont cohérentes l'une avec l'autre. À ce stade, la plupart des clients effectuent des tests de base. Si des erreurs sont commises pendant le processus de migration, la relecture du journal doit signaler les erreurs et échouer. Il est toujours conseillé d'effectuer des tests rapides basés sur des requêtes connues ou des activités applicatives pour vérifier que la configuration est optimale. Il est également courant de créer une table de test finale avant d'arrêter la base de données d'origine pour vérifier qu'elle est présente dans la base de données migrée. Cette étape permet de s'assurer qu'aucune erreur n'a été effectuée lors de la synchronisation finale du journal.</block>
  <block id="d8e9d23b4beb4db3da15d77542782747" category="paragraph">Une simple migration d'envoi de journaux peut être configurée hors bande par rapport à la base de données d'origine, ce qui la rend particulièrement utile pour les bases de données stratégiques. Il n'est pas nécessaire de modifier la configuration de la base de données source, car la restauration et la configuration initiale de l'environnement de migration n'affectent pas les opérations de production. Une fois l'envoi de journaux configuré, il impose des demandes d'E/S sur les serveurs de production. Cependant, l'envoi de journaux se compose de simples lectures séquentielles des journaux d'archivage, qui n'ont probablement aucun impact sur les performances des bases de données de production.</block>
  <block id="2c31403002a9f424c6ef56460c6b3715" category="paragraph">L'expédition de journaux s'est avérée particulièrement utile pour les projets de migration longue distance à taux de changement élevé. Dans un cas, une seule base de données de 220 To a été migrée vers un nouvel emplacement situé à environ 500 kilomètres. Le taux de modification était extrêmement élevé et les restrictions de sécurité empêchaient l'utilisation d'une connexion réseau. L'expédition des journaux a été effectuée à l'aide de bandes et de coursiers. Une copie de la base de données source a d'abord été restaurée à l'aide des procédures décrites ci-dessous. Les journaux ont ensuite été expédiés chaque semaine par messagerie jusqu'au moment de la mise en service, lorsque le jeu final de bandes a été livré et que les journaux ont été appliqués à la base de données de réplica.</block>
  <block id="b8efa655c4deb7af8a24fc241f8b53ff" category="section-title">Oracle DataGuard</block>
  <block id="d3165c4060fc6d19c0a6364e7c4580ee" category="paragraph">Dans certains cas, un environnement DataGuard complet est garanti. Il est incorrect d'utiliser le terme DataGuard pour faire référence à toute configuration d'envoi de journaux ou de base de données de secours. Oracle DataGuard est un framework complet de gestion de la réplication de base de données, mais il ne s'agit pas d'une technologie de réplication. Le principal avantage d'un environnement DataGuard complet dans un effort de migration est le basculement transparent d'une base de données à une autre. DataGuard permet également un basculement transparent vers la base de données d'origine en cas de problème, tel qu'un problème de performances ou de connectivité réseau avec le nouvel environnement. Un environnement DataGuard entièrement configuré nécessite la configuration non seulement de la couche de base de données, mais aussi des applications pour que les applications puissent détecter un changement dans l'emplacement de la base de données primaire. En général, il n'est pas nécessaire d'utiliser DataGuard pour effectuer une migration, mais certains clients possèdent une expertise DataGuard étendue en interne et en dépendent déjà pour le travail de migration.</block>
  <block id="f17c0a1ce359c1a6665412f89234bf41" category="section-title">Architecture</block>
  <block id="ece8d784e248d63091fc0d248cdeebc3" category="paragraph">Comme évoqué précédemment, l'exploitation des fonctionnalités avancées des baies de stockage nécessite parfois de modifier l'organisation de la base de données. De plus, une modification du protocole de stockage, telle que le passage d'ASM à un système de fichiers NFS, modifie nécessairement la disposition du système de fichiers.</block>
  <block id="71843fb61639ed5fe216bfebc85af16f" category="paragraph">L'un des principaux avantages des méthodes d'envoi de journaux, y compris DataGuard, est que la destination de réplication ne doit pas correspondre à la source. Il n'y a pas de problème avec l'utilisation d'une approche d'envoi de journaux pour migrer d'ASM vers un système de fichiers standard, et inversement. La disposition précise des fichiers de données peut être modifiée à la destination pour optimiser l'utilisation de la technologie de base de données enfichable (PDB) ou pour définir des contrôles QoS de manière sélective sur certains fichiers. En d'autres termes, un processus de migration basé sur l'envoi de journaux vous permet d'optimiser facilement et en toute sécurité l'organisation du stockage de la base de données.</block>
  <block id="f00ec1b23f539163f4c748a85e49e2dd" category="section-title">Ressources du serveur</block>
  <block id="76c5d43a72d856a95b0eed94694ae696" category="paragraph">La migration au niveau de la base de données est limitée par le besoin d'un second serveur. Ce second serveur peut être utilisé de deux manières :</block>
  <block id="6cb133f8b5045ef30c17e96ab281749e" category="list-text">Vous pouvez utiliser le second serveur comme nouveau domicile permanent pour la base de données.</block>
  <block id="f5133929790fe62dbc76a73db4c88544" category="list-text">Vous pouvez utiliser le second serveur comme serveur temporaire de transfert. Une fois la migration des données vers la nouvelle baie de stockage terminée et testée, les systèmes de fichiers LUN ou NFS sont déconnectés du serveur intermédiaire et reconnectés au serveur d'origine.</block>
  <block id="48a00ba9881b62c610201cd833ee9c88" category="paragraph">La première option est la plus simple, mais son utilisation peut ne pas être possible dans les environnements très vastes nécessitant des serveurs très puissants. La deuxième option nécessite un travail supplémentaire pour replacer les systèmes de fichiers à leur emplacement d'origine. Il peut s'agir d'une opération simple dans laquelle NFS est utilisé comme protocole de stockage car les systèmes de fichiers peuvent être démontés du serveur de transfert et remontés sur le serveur d'origine.</block>
  <block id="c223252c2d577984b75caddbd1dff9dc" category="paragraph">Les systèmes de fichiers basés sur les blocs nécessitent un travail supplémentaire pour mettre à jour le zoning FC ou les initiateurs iSCSI. Avec la plupart des gestionnaires de volumes logiques (y compris ASM), les LUN sont automatiquement détectées et mises en ligne après leur mise à disposition sur le serveur d'origine. Cependant, certaines implémentations de système de fichiers et de LVM peuvent nécessiter davantage de travail pour exporter et importer les données. La procédure précise peut varier, mais il est généralement facile d'établir une procédure simple et reproductible pour terminer la migration et réexécuter les données sur le serveur d'origine.</block>
  <block id="2d22ab8be3661ce5dfd8c9910d1cc003" category="paragraph">Bien qu'il soit possible de configurer l'envoi de journaux et de répliquer une base de données dans un environnement de serveur unique, la nouvelle instance doit avoir un SID de processus différent pour pouvoir relire les journaux. Il est possible d'afficher temporairement la base de données sous un autre ensemble d'ID de processus avec un SID différent et de la modifier ultérieurement. Toutefois, cela peut entraîner de nombreuses activités de gestion complexes et mettre l'environnement de base de données en danger d'erreur de la part des utilisateurs.</block>
  <block id="2660e825d3a58f68aeec49e1c749f477" category="section-title">Migration au niveau de l'hôte</block>
  <block id="fae5bb68519bf78c1b3711566283f4ef" category="paragraph">La migration des données au niveau de l'hôte implique l'utilisation du système d'exploitation hôte et des utilitaires associés pour terminer la migration. Ce processus inclut tout utilitaire qui copie les données, y compris Oracle RMAN et Oracle ASM.</block>
  <block id="01070e0746a412afd171ccf162d3a170" category="section-title">Copie de données</block>
  <block id="180e717e34d5e4bd2991c47960d00f51" category="paragraph">La valeur d'une opération de copie simple ne doit pas être sous-estimée. Les infrastructures réseau modernes peuvent déplacer des données à un taux de gigaoctets par seconde. Les opérations de copie de fichiers reposent sur des E/S efficaces en lecture et écriture séquentielles Si une opération de copie de l'hôte est plus perturbant que l'envoi de journaux, la migration ne se limite pas au déplacement des données. Elle inclut généralement les modifications apportées au réseau, au délai de redémarrage de la base de données et aux tests de post-migration.</block>
  <block id="750e04d167938f35054d1c30fd06af58" category="paragraph">Le temps réel nécessaire à la copie des données peut ne pas être important. En outre, une opération de copie préserve un chemin de retour garanti, car les données d'origine ne sont pas modifiées. En cas de problème pendant le processus de migration, les systèmes de fichiers d'origine avec les données d'origine peuvent être réactivés.</block>
  <block id="5a3572c65171e06d99a4e055f9d35d32" category="section-title">Changement de plate-forme</block>
  <block id="d123cc133e4de7ab3a4b1a5af3bf37a7" category="paragraph">Le changement de plate-forme fait référence à un changement de type de CPU. Lorsqu'une base de données est migrée d'une plate-forme Solaris, AIX ou HP-UX traditionnelle vers Linux x86, les données doivent être reformatées en raison de modifications de l'architecture CPU. Les processeurs SPARC, IA64 et POWER sont connus sous le nom de processeurs big endian, tandis que les architectures x86 et x86_64 sont connues sous le nom de Little endian. Par conséquent, certaines données des fichiers de données Oracle sont triées différemment selon le processeur utilisé.</block>
  <block id="6a03806f9c4b1f0048478bab7863fd2c" category="paragraph">Jusqu'ici, les clients ont généralement utilisé DataPump pour répliquer des données sur plusieurs plateformes. DataPump est un utilitaire qui crée un type spécial d'exportation de données logiques qui peut être importé plus rapidement dans la base de données de destination. Comme il crée une copie logique des données, DataPump laisse derrière lui les dépendances de l'endianness du processeur. DataPump est encore utilisé par certains clients pour le changement de plateforme, mais une option plus rapide est désormais disponible avec Oracle 11g : les tablespaces interplateformes transportables. Cette avance permet de convertir un espace de table en un format endian différent. Il s'agit d'une transformation physique qui offre de meilleures performances qu'une exportation DataPump, qui doit convertir les octets physiques en données logiques, puis les convertir en octets physiques.</block>
  <block id="713bf8ff4ea4c4ece861f3345e15e3ea" category="paragraph">Une discussion complète sur DataPump et les tablespaces transportables va au-delà de la documentation NetApp portée, mais NetApp propose quelques recommandations basées sur notre expérience d'assistance aux clients lors de la migration vers une nouvelle baie de stockage dans le cadre d'une nouvelle architecture de processeur :</block>
  <block id="86b0ebca28354c7f55b4cc2fe79bee0e" category="list-text">Si DataPump est utilisé, le temps nécessaire à la migration doit être mesuré dans un environnement de test. Les clients sont parfois surpris du temps nécessaire à la réalisation de la migration. Cette interruption supplémentaire imprévue peut provoquer des interruptions.</block>
  <block id="8a592f25a72fd6f3718b1b01869ade30" category="list-text">De nombreux clients pensent à tort que les tablespaces transportables multi plates-formes ne nécessitent pas de conversion de données. Lorsqu'une CPU avec un autre endian est utilisée, un RMAN<block ref="31168275dcaac634489082b54c4c66d0" prefix=" " category="inline-code"></block> l'opération doit être effectuée au préalable sur les fichiers de données. Cette opération n'est pas instantanée. Dans certains cas, le processus de conversion peut être accéléré en ayant plusieurs threads fonctionnant sur différents fichiers de données, mais le processus de conversion ne peut pas être évité.</block>
  <block id="db7b3f86f4c9a2a6a76adac81614c03b" category="section-title">Migration basée sur le gestionnaire de volumes logiques</block>
  <block id="86586aa50b0df80a7c68bcd3e86c8606" category="paragraph">Les LVM fonctionnent en déregroupant un groupe d'une ou de plusieurs LUN en petites unités généralement appelées extensions. Le pool d'extensions est ensuite utilisé comme source pour créer des volumes logiques qui sont essentiellement virtualisés. Cette couche de virtualisation apporte de la valeur de plusieurs manières :</block>
  <block id="68d083c44669b8b20f0421b0389c6ded" category="list-text">Les volumes logiques peuvent utiliser des extensions tirées de plusieurs LUN. Lorsqu'un système de fichiers est créé sur un volume logique, il peut exploiter les performances maximales de toutes les LUN. Il favorise également le chargement homogène de toutes les LUN du groupe de volumes, pour des performances plus prévisibles.</block>
  <block id="10d1e748082641ce33e82f457cabcbe7" category="list-text">Les volumes logiques peuvent être redimensionnés en ajoutant et, dans certains cas, en supprimant des extensions. Le redimensionnement d'un système de fichiers sur un volume logique s'effectue généralement sans interruption.</block>
  <block id="5efed6e7bf2fda8321882aff35768721" category="list-text">Le déplacement des extensions sous-jacentes permet de migrer les volumes logiques sans interruption.</block>
  <block id="96371ba57b3d2f331cc9bd7b5e34708b" category="paragraph">La migration à l'aide d'un LVM fonctionne de deux manières : déplacer une extension ou mettre en miroir/démirroring une extension. La migration des LVM utilise des E/S séquentielles de blocs de grande taille efficaces et pose rarement des problèmes de performances. Si ce problème survient, il existe généralement des options pour limiter le taux d'E/S. Cela augmente le temps nécessaire à la migration, tout en réduisant la charge d'E/S sur l'hôte et les systèmes de stockage.</block>
  <block id="28084a93e6570f55c3923991e269816e" category="section-title">Miroir et démiroir</block>
  <block id="f5b05967100f74bb14ae26d5021ef4e3" category="paragraph">Certains gestionnaires de volumes, tels que AIX LVM, permettent à l'utilisateur de spécifier le nombre de copies pour chaque extension et de contrôler les périphériques qui hébergent chaque copie. La migration s'effectue par la mise en miroir d'un volume logique existant sur les extensions sous-jacentes des nouveaux volumes, l'attente de la synchronisation des copies, puis l'abandon de l'ancienne copie. Si un chemin de retour arrière est souhaité, un instantané des données d'origine peut être créé avant le point de suppression de la copie miroir. Il est également possible d'arrêter brièvement le serveur pour masquer les LUN d'origine avant de forcer la suppression des copies miroir contenues. Cela permet de conserver une copie récupérable des données à leur emplacement d'origine.</block>
  <block id="7151373ff69a9fafa4a579b40282beeb" category="section-title">Migration d'extension</block>
  <block id="682ba6adb168511d03877bdbf940a0b7" category="paragraph">La plupart des gestionnaires de volumes permettent la migration des extensions, et il arrive parfois que plusieurs options existent. Par exemple, certains gestionnaires de volumes permettent à un administrateur de déplacer les extensions individuelles d'un volume logique spécifique de l'ancien vers le nouveau stockage. Les gestionnaires de volumes tels que Linux LVM2 offrent le<block ref="8167c9a6bd495f7ed235364201039099" prefix=" " category="inline-code"></block> Qui déplace toutes les extensions du périphérique LUN spécifié vers une nouvelle LUN. Une fois l'ancien LUN évacué, il est possible de le retirer.</block>
  <block id="8c232bd157fb78062260d11e1ec3fc2c" category="admonition">Le risque principal pour les opérations est la suppression des anciennes LUN inutilisées de la configuration. Une attention toute particulière doit être portée au changement de segmentation FC et au retrait des périphériques LUN obsolètes.</block>
  <block id="41175a8b2053bedbf868e340edf92f55" category="section-title">Gestion automatique du stockage par Oracle</block>
  <block id="dce3f0c1b1c85aaee6448197054602d1" category="paragraph">Oracle ASM est un gestionnaire de volumes logiques et un système de fichiers combinés. À un niveau élevé, Oracle ASM prend un ensemble de LUN, les répartit en petites unités d'allocation et les présente comme un seul volume appelé groupe de disques ASM. ASM permet également de mettre en miroir le groupe de disques en définissant le niveau de redondance. Un volume peut être sans miroir (redondance externe), en miroir (redondance normale) ou en miroir tridirectionnel (redondance élevée). La configuration du niveau de redondance doit être effectuée avec précaution car il ne peut pas être modifié après sa création.</block>
  <block id="d0ac5c14a6207835f733f4366345089d" category="paragraph">ASM fournit également des fonctionnalités de système de fichiers. Bien que le système de fichiers ne soit pas visible directement depuis l'hôte, la base de données Oracle peut créer, déplacer et supprimer des fichiers et des répertoires sur un groupe de disques ASM. Vous pouvez également naviguer dans la structure à l'aide de l'utilitaire asmcmd.</block>
  <block id="e72c9da30cbec4daedddc9b6e6fdf03b" category="paragraph">Comme pour les autres implémentations LVM, Oracle ASM optimise les performances d'E/S en segmentant et en équilibrant les E/S de chaque fichier sur l'ensemble des LUN disponibles. Deuxièmement, les extensions sous-jacentes peuvent être déplacées pour permettre le redimensionnement du groupe de disques ASM ainsi que la migration. Oracle ASM automatise le processus tout au long de l'opération de rééquilibrage. Les nouvelles LUN sont ajoutées à un groupe de disques ASM et les anciennes LUN sont abandonnées, ce qui déclenche le déplacement d'extension et le DROP suivant de la LUN évacuée du groupe de disques. Ce processus est l'une des méthodes de migration les plus éprouvées, et la fiabilité d'ASM pour assurer une migration transparente est probablement sa fonctionnalité la plus importante.</block>
  <block id="d4ad443888b51ec4e13912c45da68f76" category="admonition">Comme le niveau de mise en miroir d'Oracle ASM est fixe, il ne peut pas être utilisé avec la méthode de migration miroir et démiroir.</block>
  <block id="048429277e643e20907317612c1f3318" category="section-title">Migration au niveau du stockage</block>
  <block id="623bb7ffbb3730716ea39b5086d26f18" category="paragraph">La migration au niveau du stockage implique d'effectuer la migration au-dessous des niveaux des applications et du système d'exploitation. Auparavant, il fallait parfois utiliser des périphériques spécialisés qui copiaient les LUN au niveau du réseau, mais ces fonctionnalités sont désormais natives dans ONTAP.</block>
  <block id="794cb725c5631ad99b5b7c000307f0df" category="section-title">SnapMirror</block>
  <block id="963ce762febea70d619f1fd5c114d85c" category="paragraph">La migration de bases de données entre des systèmes NetApp est presque effectuée de manière universelle avec le logiciel de réplication des données NetApp SnapMirror. Ce processus implique la configuration d'une relation de miroir pour les volumes à migrer, leur permettant ainsi de se synchroniser, puis d'attendre la fenêtre de mise en service. Lorsqu'elle arrive, la base de données source est arrêtée, une dernière mise à jour miroir est effectuée et le miroir est cassé. Les volumes de réplica sont alors prêts à l'emploi, soit en montant un répertoire de système de fichiers NFS contenu, soit en découvrant les LUN contenues et en démarrant la base de données.</block>
  <block id="1871452e5ea7e53152b5c874a12a890b" category="paragraph">La relocalisation des volumes dans un seul cluster ONTAP n'est pas considérée comme une migration, mais plutôt comme une routine<block ref="0fc2ecb8aa71bddc595fbc39f593496a" prefix=" " category="inline-code"></block> fonctionnement. SnapMirror est utilisé en tant que moteur de réplication des données au sein du cluster. Ce processus est entièrement automatisé. Il n'y a pas d'étape de migration supplémentaire à effectuer lorsque les attributs du volume, tels que le mappage de LUN ou les autorisations d'exportation NFS, sont déplacés avec le volume lui-même. La relocalisation ne prend pas en charge l'hôte. Dans certains cas, il convient de mettre à jour l'accès au réseau pour s'assurer que les données nouvellement déplacées sont accessibles de la manière la plus efficace possible, mais sans interruption.</block>
  <block id="19fee3ea4b7f4472b5c1853122e8f47b" category="section-title">Importation de LUN étrangères (FLI)</block>
  <block id="a73cf458eed5aeff5c15aa5d70298cce" category="paragraph">La FLI est une fonctionnalité qui permet à un système Data ONTAP exécutant la version 8.3 ou supérieure de migrer un LUN existant à partir d'une autre baie de stockage. La procédure est simple : le système ONTAP est zoné sur la baie de stockage existante comme s'il s'agissait d'un autre hôte SAN. Data ONTAP prend alors le contrôle des LUN héritées souhaitées et migre les données sous-jacentes. De plus, le processus d'importation utilise les paramètres d'efficacité du nouveau volume lors de la migration des données. Ainsi, les données peuvent être compressées et dédupliquées en ligne pendant le processus de migration.</block>
  <block id="0ee4b09881406835f151f103412a2f1e" category="paragraph">La première implémentation de FLI dans Data ONTAP 8.3 a permis uniquement la migration hors ligne. Ce transfert était extrêmement rapide, mais cela signifiait que les données de LUN étaient indisponibles jusqu'à la fin de la migration. La migration en ligne a été introduite dans Data ONTAP 8.3.1. Ce type de migration minimise les interruptions en permettant à ONTAP de transmettre des données LUN lors du processus de transfert. Il y a une brève interruption lors de la remise en place de l'hôte pour l'utilisation des LUN via ONTAP. Cependant, dès que ces modifications sont apportées, les données sont de nouveau accessibles et restent accessibles tout au long du processus de migration.</block>
  <block id="19d95ee75467fc2f9a06d150cc99d944" category="paragraph">Les E/S de lecture sont proxées via ONTAP jusqu'à la fin de l'opération de copie, tandis que les E/S d'écriture sont écrites de manière synchrone sur les LUN étrangères et ONTAP. Les deux copies LUN sont ainsi synchronisées jusqu'à ce que l'administrateur exécute une mise en service complète qui libère le LUN étranger et ne réplique plus les écritures.</block>
  <block id="5caad387757ca99ada41709ce30a31a5" category="paragraph">FLI est conçu pour fonctionner avec FC. Toutefois, si vous souhaitez passer à iSCSI, le LUN migré peut facilement être remappé en tant que LUN iSCSI une fois la migration terminée.</block>
  <block id="7fa6cfc683e0f5f9e3a79f6be14e23f4" category="paragraph">Parmi les caractéristiques de FLI figurent la détection et le réglage automatiques de l'alignement. Dans ce contexte, le terme alignement fait référence à une partition sur un périphérique LUN. Pour des performances optimales, les E/S doivent être alignées sur des blocs de 4 Ko. Si une partition est placée à un décalage qui n'est pas un multiple de 4K, les performances en pâtissent.</block>
  <block id="7b4ef266729f1ddfbc724cad17af4efc" category="paragraph">Il existe un deuxième aspect de l'alignement qui ne peut pas être corrigé en réglant un décalage de partition, c'est-à-dire la taille du bloc du système de fichiers. Par exemple, un système de fichiers ZFS prend généralement par défaut une taille de bloc interne de 512 octets. D'autres clients utilisant AIX ont parfois créé des systèmes de fichiers jfs2 avec une taille de bloc de 512 ou 1, 024 octets. Bien que le système de fichiers puisse être aligné sur une limite de 4 Ko, les fichiers créés dans ce système de fichiers ne le sont pas et les performances en pâtissent.</block>
  <block id="1d6b28ed67b1d554df806b0b5a020711" category="paragraph">FLI ne doit pas être utilisé dans ces circonstances. Bien que les données soient accessibles après la migration, vous obtenez des systèmes de fichiers avec de graves limitations de performances. En principe, tout système de fichiers prenant en charge une charge de travail de remplacement aléatoire sur ONTAP doit utiliser une taille de bloc de 4 Ko. Cela s'applique principalement aux charges de travail telles que les fichiers de données de base de données et les déploiements VDI. La taille de bloc peut être identifiée à l'aide des commandes appropriées du système d'exploitation hôte.</block>
  <block id="4941562ef813562e0d6aaef673158b99" category="paragraph">Par exemple, sous AIX, la taille de bloc peut être affichée avec<block ref="10c9a985c983a826424b496a708263ec" prefix=" " category="inline-code"></block>. Avec Linux,<block ref="ba5265473f00b27178098cc38d3aef24" prefix=" " category="inline-code"></block> et<block ref="1f8a87190704df357c64a49aee936874" prefix=" " category="inline-code"></block> peut être utilisé pour<block ref="310201b6353c5f38bc039e0e51b079d3" prefix=" " category="inline-code"></block> et<block ref="5382133ffbecb9bce9d47f2e44327b16" prefix=" " category="inline-code"></block>, respectivement. Avec<block ref="8cbc6ba7c8bba133ce2bc44780d88742" prefix=" " category="inline-code"></block>, la commande est<block ref="1615297782a0dff59b20451e2ca97ea7" prefix=" " category="inline-code"></block>.</block>
  <block id="033a4cb04b5225e2b7cf966f2ce16598" category="paragraph">Le paramètre qui contrôle la taille du bloc est<block ref="81df978a8e3da4bee74b135548f390f3" prefix=" " category="inline-code"></block> et la valeur par défaut est généralement 9, soit 2^9, ou 512 octets. Pour des performances optimales, le<block ref="81df978a8e3da4bee74b135548f390f3" prefix=" " category="inline-code"></block> La valeur doit être 12 (2^12=4K). Cette valeur est définie au moment de la création du zpool et ne peut pas être modifiée, ce qui signifie que les zpools de données avec un<block ref="81df978a8e3da4bee74b135548f390f3" prefix=" " category="inline-code"></block> une migration autre que 12 doit être effectuée en copiant les données vers un nouveau zpool.</block>
  <block id="8bd9661d8c8eb9924c62b8242191af4e" category="paragraph">Oracle ASM n'a pas de taille de bloc fondamentale. La seule exigence est que la partition sur laquelle le disque ASM est construit doit être correctement alignée.</block>
  <block id="ea7f7e1e8119ee64585b6173afe720e8" category="section-title">Outil de transition 7-mode</block>
  <block id="75df51cc2f43b8dde951695f97b838c0" category="paragraph">L'outil 7-mode transition Tool (7MTT) est un utilitaire d'automatisation utilisé pour migrer de grandes configurations 7-mode vers ONTAP. La plupart des clients de bases de données trouvent d'autres méthodes plus faciles, notamment parce qu'ils migrent généralement leurs environnements de bases de données par base de données plutôt que de déplacer l'intégralité de l'empreinte du stockage. De plus, les bases de données ne font souvent partie que d'un environnement de stockage plus important. Les bases de données sont donc souvent migrées individuellement, puis le reste de l'environnement peut être déplacé avec 7MTT.</block>
  <block id="85fd7dcbc2206c27059ae7f88712154d" category="paragraph">Les clients sont de petite taille, mais nombreux. Ils disposent de systèmes de stockage dédiés à des environnements de base de données complexes. Ces environnements peuvent contenir de nombreux volumes, snapshots et de nombreuses informations de configuration telles que les autorisations d'exportation, les groupes initiateurs de LUN, les autorisations utilisateur et la configuration du protocole d'accès aux répertoires légers. Dans de tels cas, les fonctionnalités d'automatisation de l'outil 7MTT simplifient considérablement la migration.</block>
  <block id="2c87fbdecbf0dfe299f9f89958d61085" category="paragraph">7MTT peut fonctionner dans deux modes :</block>
  <block id="dc818e71a5519d1b99c7e996cf21fd74" category="list-text">*Transition basée sur les copies (CBT).* dans le nouvel environnement, l'outil 7MTT avec CBT configure les volumes SnapMirror à partir d'un système 7- mode existant. Une fois les données synchronisées, l'outil 7MTT orchestre le processus de mise en service.</block>
  <block id="453bbc96e365e25cc2d091dced3565a6" category="list-text">*Transition sans copie.* 7MTT avec la transition sans copie repose sur la conversion des tiroirs disques 7-mode existants sans déplacement des données. Aucune donnée n'est copiée et les tiroirs disques existants peuvent être réutilisés. La protection des données et la configuration de l'efficacité du stockage existantes sont préservées.</block>
  <block id="16262236c3981cb3310b9320b5a67fd0" category="paragraph">La différence principale entre ces deux options est que la transition sans copie constitue une approche globale où tous les tiroirs disques rattachés à la paire HA 7-mode d'origine doivent être transférés vers le nouvel environnement. Il n'existe aucune option pour déplacer un sous-ensemble de tiroirs. L'approche basée sur les copies permet de déplacer des volumes sélectionnés. Par ailleurs, une fenêtre de mise en service peut être plus longue et la transition sans copie est liée à l'alignement des tiroirs disques et à la conversion des métadonnées. En fonction de son expérience sur le terrain, NetApp recommande de consacrer 1 heure au déplacement et à la réinstallation des tiroirs disques, et entre 15 minutes et 2 heures à la conversion des métadonnées.</block>
  <block id="c8365c28332d425fd91f2de2e2c22dfb" category="summary">Préparation de ONTAP pour une migration FLI</block>
  <block id="25c18537e56595b3e7f3ce78905917ba" category="doc">Planification FLI - Oracle</block>
  <block id="f1033948d9d2d14612d27f1808720f12" category="inline-link">Tr-4380 : migration SAN à l'aide de Foreign LUN Import</block>
  <block id="58fc59a248fefa86003ac1867e5bd279" category="paragraph">Les procédures de migration des ressources SAN à l'aide de FLI sont décrites dans NetApp<block ref="5abd855dd5d8332b78fa966ac34c0f22" category="inline-link-rx"></block>.</block>
  <block id="795bbfbd054829fad905065087ba2d5a" category="paragraph">Du point de vue de la base de données et de l'hôte, aucune étape particulière n'est requise. Une fois les zones FC mises à jour et les LUN disponibles sur ONTAP, LVM doit pouvoir lire les métadonnées LVM des LUN. De plus, les groupes de volumes sont prêts à être utilisés sans étape de configuration supplémentaire. Dans de rares cas, les environnements peuvent inclure des fichiers de configuration codés en dur avec des références à la baie de stockage précédente. Par exemple, un système Linux inclus<block ref="dd5ff67ba72768d33f75e645aa2b8e56" prefix=" " category="inline-code"></block> Les règles qui référençaient un WWN d'un périphérique donné doivent être mises à jour pour refléter les modifications introduites par FLI.</block>
  <block id="9e7ddc2ddefcd6f202fb11a82a80bc7e" category="admonition">Reportez-vous à la matrice de compatibilité NetApp pour plus d'informations sur les configurations prises en charge. Si votre environnement n'est pas inclus, contactez votre représentant NetApp pour obtenir de l'aide.</block>
  <block id="0f5b3758229b3e28c8605b6c42398115" category="paragraph">Cet exemple montre la migration des LUN ASM et LVM hébergées sur un serveur Linux. FLI est pris en charge par d'autres systèmes d'exploitation. Bien que les commandes côté hôte puissent différer, les principes sont les mêmes et les procédures ONTAP sont identiques.</block>
  <block id="f1036cd97e461d07351c9df32fc5948d" category="section-title">Identifier les LUN LVM</block>
  <block id="88f7413f9621a816ee3d370703168647" category="paragraph">La première étape de la préparation consiste à identifier les LUN à migrer. Dans l'exemple illustré ici, deux systèmes de fichiers SAN sont montés sur<block ref="572f241ef88fdb17d16eba97133d861f" prefix=" " category="inline-code"></block> et<block ref="d14bc7787c7396144583e99a7df52f67" prefix=" " category="inline-code"></block>.</block>
  <block id="ecad615a52fda392a9b7c1075d2cb2c5" category="paragraph">Le nom du groupe de volumes peut être extrait du nom du périphérique, qui utilise le format (nom du groupe de volumes)-(nom du volume logique). Dans ce cas, le groupe de volumes est appelé<block ref="bb97320b8c517da828eae4ec543113db" prefix=" " category="inline-code"></block>.</block>
  <block id="b08986bb1757d5ae8de06d523c71803d" category="paragraph">Le<block ref="f1e2c495108b111c930735e3a0f9a04e" prefix=" " category="inline-code"></block> Vous pouvez utiliser la commande suivante pour identifier les LUN qui prennent en charge ce groupe de volumes. Dans ce cas, 10 LUN constituent le<block ref="bb97320b8c517da828eae4ec543113db" prefix=" " category="inline-code"></block> groupe de volumes.</block>
  <block id="8b47fac6803dfff2e8d2cdad6f297cfa" category="section-title">Identifier les LUN ASM</block>
  <block id="a23d0124954ecdbfe9d0f3aceb9e17a2" category="paragraph">Les LUN ASM doivent également être migrés. Pour obtenir le nombre de LUN et de chemins de LUN depuis sqlplus en tant qu'utilisateur sysasm, exécutez la commande suivante :</block>
  <block id="918841992da84786f00de7c4c7d83dbf" category="paragraph">L'environnement actuel contient 20 LUN à migrer. Mettez à jour le SAN actuel de sorte que ONTAP puisse accéder aux LUN actuelles. Les données n'ont pas encore été migrées, mais ONTAP doit lire les informations de configuration des LUN actuelles pour créer le nouveau home pour ces données.</block>
  <block id="5816768a5d83977f34ffa5025c14f430" category="paragraph">Au moins un port HBA sur le système AFF/FAS doit être configuré en tant que port initiateur. En outre, les zones FC doivent être mises à jour de sorte que ONTAP puisse accéder aux LUN de la baie de stockage étrangère. Certaines baies de stockage ont configuré le masquage des LUN, ce qui limite les WWN pouvant accéder à une LUN donnée. Dans ce cas, le masquage de LUN doit également être mis à jour pour autoriser l'accès aux WWN de ONTAP.</block>
  <block id="030a992b1340f67584d67ef6230e9adf" category="paragraph">Une fois cette étape terminée, ONTAP doit être en mesure d'afficher la baie de stockage étrangère avec le<block ref="d90ba20b63acab53952d68665c50ec47" prefix=" " category="inline-code"></block> commande. Le champ de clé renvoyé est le préfixe utilisé pour identifier la LUN étrangère sur le système. Dans l'exemple ci-dessous, les LUN de la baie étrangère<block ref="25103eba8d70e82b5bd837be0d2f63c4" prefix=" " category="inline-code"></block> Apparaissent dans ONTAP en utilisant le préfixe de<block ref="6b35470d99880c4630ed3ca7b4c842e7" prefix=" " category="inline-code"></block>.</block>
  <block id="c1a0f5174323df40a8b659eb65ac5155" category="section-title">Identifiez le tableau étranger</block>
  <block id="6c1b8919e2e706972b3ec48cb7f014ba" category="section-title">Identifiez les LUN étrangères</block>
  <block id="63841e312d3a8531331e35bd826268d1" category="paragraph">Vous pouvez lister les LUN en transmettant le<block ref="907702f5103a7823393b8dd296a75c26" prefix=" " category="inline-code"></block> à la<block ref="242f4ce1948273386f8bb487bdd3732f" prefix=" " category="inline-code"></block> commande. Les données renvoyées sont référencées plusieurs fois pendant la procédure de migration.</block>
  <block id="e5e94f7e2098883f0d621e064b1104f4" category="section-title">Enregistrer des LUN de baies étrangères en tant que candidats à l'importation</block>
  <block id="c968ec41c1c0c449b0263962966d8293" category="paragraph">Les LUN étrangères sont initialement classées comme tout type de LUN particulier. Avant de pouvoir importer des données, les LUN doivent être marquées comme étrangères et par conséquent comme candidates au processus d'importation. Cette étape est terminée en transmettant le numéro de série au<block ref="93c633f7fa188f1b27df574c0e5e929a" prefix=" " category="inline-code"></block> comme indiqué dans l'exemple suivant. Notez que ce processus balise uniquement la LUN comme étant étrangère dans ONTAP. Aucune donnée n'est écrite sur la LUN étrangère elle-même.</block>
  <block id="33380a523841f23815f2f83c9de1a628" category="section-title">Création de volumes pour héberger les LUN migrés</block>
  <block id="2c2ba8ca6bdd77da1da981b91a3fae4a" category="paragraph">Un volume est nécessaire pour héberger les LUN migrées. La configuration exacte du volume dépend du plan global d'exploitation des fonctionnalités ONTAP. Dans cet exemple, les LUN ASM sont placées dans un volume et les LUN LVM sont placées dans un second volume. Vous pouvez ainsi gérer les LUN en tant que groupes indépendants à des fins telles que la hiérarchisation, la création de snapshots ou la définition de contrôles de QoS.</block>
  <block id="8bc7d64e68e4be8f4908effd57293a2a" category="paragraph">Réglez le<block ref="fb983ebeedc63d8723c0d4aa558a4c02" prefix=" " category="inline-code"></block>. Le processus de migration peut inclure une grande partie du transfert des données. Par conséquent, si des snapshots sont créés par accident, la consommation d'espace peut augmenter de façon importante, car des données indésirables sont capturées dans les snapshots.</block>
  <block id="8c0675d07e44f55f1f5aa6d45abe0cdb" category="section-title">Créer des LUN ONTAP</block>
  <block id="0b799020dac78a5e12a3d1a6400fd0c8" category="paragraph">Une fois les volumes créés, les nouvelles LUN doivent être créées. Normalement, la création d'une LUN nécessite que l'utilisateur indique des informations telles que la taille de LUN, mais dans ce cas, l'argument disque étranger est transmis à la commande. Par conséquent, ONTAP réplique les données de configuration actuelle du LUN à partir du numéro de série spécifié. Il utilise également la géométrie des LUN et les données de la table de partition pour ajuster l'alignement des LUN et établir des performances optimales.</block>
  <block id="5272a1dc3854f1eddc353c8073234e03" category="paragraph">Dans cette étape, les numéros de série doivent être référencés avec le tableau étranger pour s'assurer que le LUN étranger correct est associé au nouveau LUN correct.</block>
  <block id="f6ee70ec9fce7bd34fa5a33d8969fb5e" category="section-title">Créer des relations d'importation</block>
  <block id="94700a911b95416221efe4064acbc2ba" category="paragraph">Les LUN ont été créées, mais ne sont pas configurées en tant que destination de réplication. Avant de pouvoir réaliser cette étape, les LUN doivent d'abord être mises hors ligne. Cette étape supplémentaire est conçue pour protéger les données contre les erreurs de l'utilisateur. Si ONTAP permettait l'exécution d'une migration sur une LUN en ligne, une erreur typographique risquerait d'écraser les données actives. L'étape supplémentaire consistant à forcer l'utilisateur à mettre d'abord une LUN hors ligne permet de vérifier que la LUN cible correcte est utilisée comme destination de migration.</block>
  <block id="85255e52054af9c6ffd3c4e79c723a34" category="paragraph">Une fois les LUN hors ligne, vous pouvez établir la relation d'importation en transmettant le numéro de série de la LUN étrangère à<block ref="04c2f87857699971f5aedd525e65690a" prefix=" " category="inline-code"></block> commande.</block>
  <block id="8e3c921431d2b7f66fa0cc85f3ae5c9d" category="paragraph">Une fois toutes les relations d'importation établies, les LUN peuvent être remis en ligne.</block>
  <block id="ea382cbfdb353cee0cf25eaae9bba150" category="section-title">Créer le groupe initiateur</block>
  <block id="152c4728a5fb152525a639439b9d7cb9" category="inline-link-macro">Conversion de protocoles</block>
  <block id="298a1c3c736859f2cfa3cb8eb1f3fdcc" category="paragraph">Dans cet exemple, un groupe initiateur est créé et contient deux WWN correspondant aux deux ports disponibles sur l'adaptateur HBA de l'hôte.</block>
  <block id="4f6f03762bfcdc7174cdd30240ce45b3" category="section-title">Mappez les nouvelles LUN sur l'hôte</block>
  <block id="c22fee2d07a149be91ae1ae2ada1cb57" category="paragraph">Après la création du groupe initiateur, les LUN sont ensuite mappées sur le groupe initiateur défini. Ces LUN sont uniquement disponibles pour les WWN inclus dans ce groupe initiateur. NetApp suppose, à ce stade du processus de migration, que l'hôte n'a pas été segmenté vers ONTAP. Cela est important, car si l'hôte est segmenté simultanément sur la baie étrangère et le nouveau système ONTAP, il est possible de détecter sur chaque baie des LUN portant le même numéro de série. Cette situation peut entraîner des dysfonctionnements des chemins d'accès multiples ou endommager les données.</block>
  <block id="ecca392290c36269e0489c0b1cf36f50" category="summary">Exemples de scripts pour l'automatisation des opérations de migration Oracle</block>
  <block id="fc53c036602508ed6c2afc18e2fbdf51" category="doc">Exemples de scripts</block>
  <block id="6f78af00b87bcad5d08c95c7b6066ad0" category="paragraph">Les scripts présentés sont fournis sous forme d'exemples de script de diverses tâches du système d'exploitation et de la base de données. Ils sont fournis en l'état. Si une assistance est requise pour une procédure particulière, contactez NetApp ou un revendeur NetApp.</block>
  <block id="3146889e40b3ca2b78c56a19178bff84" category="section-title">Arrêt de la base de données</block>
  <block id="5b98b9877c0c74dc3a3daf46cf943d3f" category="paragraph">Le script Perl suivant prend un seul argument du SID Oracle et arrête une base de données. Il peut être exécuté en tant qu'utilisateur Oracle ou en tant que root.</block>
  <block id="7df41a3619af59182fb5df6d1920d11a" category="section-title">Démarrage de la base de données</block>
  <block id="57249fb9cdac8ddc9ea8843636c4e088" category="section-title">Convertir le système de fichiers en lecture seule</block>
  <block id="f2977a22ba44544ca8921e2d75bce435" category="paragraph">Le script suivant prend un argument de système de fichiers et tente de le démonter et de le remonter en lecture seule. Cette opération est utile lors des processus de migration au cours desquels un système de fichiers doit être mis à disposition pour répliquer des données, tout en étant protégé contre les dommages accidentels.</block>
  <block id="4eac395595a8d266839db0b88fae31e4" category="section-title">Remplacer le système de fichiers</block>
  <block id="988d7030a130298e1641007b5b0aae20" category="paragraph">L'exemple de script suivant est utilisé pour remplacer un système de fichiers par un autre. Comme il modifie le fichier `/etc/fstab `file, il doit être exécuté en tant que root. Il accepte un seul argument délimité par des virgules pour les anciens et les nouveaux systèmes de fichiers.</block>
  <block id="149c75d086adf78a50a16bcb5e349158" category="list-text">Pour remplacer le système de fichiers, exécutez le script suivant :</block>
  <block id="67a4c588434c781febb12c165c3e860a" category="paragraph">Comme exemple d'utilisation de ce script, supposons que les données dans<block ref="f006bf17b06c884c47190c4225d3215a" prefix=" " category="inline-code"></block> est migré vers<block ref="27df80f143a5812bda1553d09c712efc" prefix=" " category="inline-code"></block> et<block ref="0e62afc91abe157ef67895cca0a7f912" prefix=" " category="inline-code"></block> est migré vers<block ref="1c988fc7a325635f00f9b55992128a08" prefix=" " category="inline-code"></block>. L'une des méthodes les plus simples pour effectuer cette tâche consiste à utiliser une simple opération de copie de fichier pour replacer le nouveau périphérique sur le point de montage d'origine.</block>
  <block id="4a3d90c30a5e921650fe8ad0decf4827" category="list-text">Supposons que l'ancien et le nouveau système de fichiers sont présents dans le<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block> classer comme suit :</block>
  <block id="4588a4e3d2f8d0f7c036f59c1be2163f" category="list-text">Lors de son exécution, ce script démonte le système de fichiers actuel et le remplace par le nouveau :</block>
  <block id="2d808cb44231d0a80164567e7220fc44" category="list-text">Le script met également à jour le<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block> classez-les en conséquence. Dans l'exemple illustré ici, il inclut les modifications suivantes :</block>
  <block id="840967a448e36b9efeaacf7673f825aa" category="section-title">Migration automatisée des bases de données</block>
  <block id="1107dd36fe8ba0c18ea8abc8734986e2" category="paragraph">Cet exemple illustre l'utilisation de scripts d'arrêt, de démarrage et de remplacement de système de fichiers pour automatiser complètement la migration.</block>
  <block id="36881541e7d9c7bced65fcac337ac327" category="section-title">Afficher les emplacements des fichiers</block>
  <block id="1e9a1acc40d4943a73e6865cdebaf560" category="paragraph">Ce script collecte un certain nombre de paramètres de base de données critiques et les imprime dans un format facile à lire. Ce script peut être utile lors de la révision des dispositions de données. En outre, le script peut être modifié pour d'autres utilisations.</block>
  <block id="6172b49b7fdf806b59af0aeef8de71e3" category="section-title">Nettoyage de la migration ASM</block>
  <block id="dd8d75d6766af495b5442e67eb27d387" category="section-title">Conversion du nom ASM en nom de système de fichiers</block>
  <block id="abc3fc91423668bb4bd49e6e837fa3e4" category="section-title">Relire les journaux sur la base de données</block>
  <block id="cc7b9a518bb2532f61662a9893248133" category="paragraph">Ce script accepte un seul argument d'un SID Oracle pour une base de données en mode montage et tente de relire tous les journaux d'archives actuellement disponibles.</block>
  <block id="2a5bd3a209a1ed33b81c5306780227ce" category="section-title">Relire les journaux sur la base de données de secours</block>
  <block id="ea7bebed0b4151a9b28acbde55fc0eb3" category="paragraph">Ce script est identique au script précédent, sauf qu'il est conçu pour une base de données de secours.</block>
  <block id="109be8945d38cda6c034a22373bdbd3b" category="summary">Modification du protocole SAN après migration FLI</block>
  <block id="b5e65fbdff41aa940dad918d9f7c0b9e" category="doc">Conversion du protocole FLI : Oracle</block>
  <block id="2adcfd589637337984e39e94dd14ae33" category="paragraph">La modification du protocole utilisé pour accéder à une LUN est une exigence courante.</block>
  <block id="38fe6838f11a6023172d11d806adbfcf" category="paragraph">Dans certains cas, cela fait partie d'une stratégie globale de migration des données vers le cloud. Le protocole TCP/IP est le protocole du cloud. En passant de FC à iSCSI, vous simplifiez la migration vers divers environnements cloud. Dans d'autres cas, il peut être souhaitable de tirer parti de la réduction des coûts d'un SAN IP. Il arrive qu'une migration utilise un protocole différent comme mesure temporaire. Par exemple, si une baie étrangère et des LUN ONTAP ne peuvent pas coexister sur les mêmes HBA, vous pouvez utiliser des LUN iSCSI suffisamment longues pour copier les données de l'ancienne baie. Vous pouvez ensuite reconvertir en FC après le retrait des anciennes LUN du système.</block>
  <block id="832c81bd0db3ad98a3804ff5ce996a58" category="paragraph">La procédure suivante illustre la conversion de FC en iSCSI, mais les principes généraux s'appliquent à une conversion iSCSI inverse en FC.</block>
  <block id="e21180783b17ea695cf9275fce8a0bc7" category="section-title">Installez l'initiateur iSCSI</block>
  <block id="0e1ddcc32a3ef636c9ca084a3d7706f5" category="paragraph">La plupart des systèmes d'exploitation incluent par défaut un initiateur iSCSI logiciel, mais si celui-ci n'est pas inclus, il peut être facilement installé.</block>
  <block id="289fe013df899f5f74fb362d4efcdd5d" category="section-title">Identifiez le nom de l'initiateur iSCSI</block>
  <block id="8242e97b190184a6c7b8ec96c5662886" category="paragraph">Un nom d'initiateur iSCSI unique est généré lors du processus d'installation. Sous Linux, il se trouve dans le<block ref="22565a44e8f73044eb2029acbb069639" prefix=" " category="inline-code"></block> fichier. Ce nom permet d'identifier l'hôte sur le SAN IP.</block>
  <block id="721a96eb0b922b337fa815839839b328" category="section-title">Créer un nouveau groupe initiateur</block>
  <block id="cda1311d977b7b77ad3aebe4a813b3bd" category="paragraph">Un groupe initiateur (igroup) fait partie de l'architecture de masquage des LUN ONTAP. L'accès à une LUN nouvellement créée n'est pas accessible à moins qu'un hôte ne bénéficie au préalable d'un accès. Cette étape est effectuée en créant un groupe initiateur qui répertorie les WWN FC ou les noms d'initiateurs iSCSI nécessitant un accès.</block>
  <block id="6548788f050643897f7354b6df4488db" category="paragraph">Dans cet exemple, un groupe initiateur contenant l'initiateur iSCSI de l'hôte Linux est créé.</block>
  <block id="da8490d81c1ef6b559b09c2ab94631d2" category="section-title">Arrêtez l'environnement</block>
  <block id="0bf211160ad57fedca3499176f213b11" category="paragraph">Avant de modifier le protocole LUN, les LUN doivent être complètement suspendues. Toute base de données de l'une des LUN en cours de conversion doit être arrêtée, les systèmes de fichiers doivent être démontés et les groupes de volumes doivent être désactivés. Si ASM est utilisé, assurez-vous que le groupe de disques ASM est démonté et arrêtez tous les services de grille.</block>
  <block id="2ba1c509ee5f5e31f05b24aed2d23054" category="section-title">Annulez le mappage des LUN à partir du réseau FC</block>
  <block id="2f9e42c479a76dd54d7946c181049dd4" category="paragraph">Une fois les LUN entièrement suspendues, supprimez les mappages du groupe initiateur FC d'origine.</block>
  <block id="5f889f52ef85be290c3e5c0211bbb8fa" category="section-title">Remappez les LUN sur le réseau IP</block>
  <block id="4ac84701530b31d8d33d9aa742715d25" category="paragraph">Accordez l'accès à chaque LUN au nouveau groupe initiateur iSCSI.</block>
  <block id="3d59eaa280c8b75d8e997eac2cf5b3e6" category="section-title">Découvrez les cibles iSCSI</block>
  <block id="981b782c3eacf8b87d8231b887873f03" category="paragraph">La découverte iSCSI se déroule en deux phases. Le premier consiste à découvrir les cibles, qui n'équivaut pas à détecter une LUN. Le<block ref="f88921f58beaaae5bcb9dffac54bf5ad" prefix=" " category="inline-code"></block> la commande illustrée ci-dessous sonde le groupe de portails spécifié par le<block ref="24e12535882a30ad33a21d76d76bd0ff" prefix=" " category="inline-code"></block> Et stocke une liste de toutes les adresses IP et de tous les ports qui offrent des services iSCSI. Dans ce cas, quatre adresses IP disposent de services iSCSI sur le port par défaut 3260.</block>
  <block id="0ab5dd035c7f92f4dce1026744c01604" category="admonition">Cette commande peut prendre plusieurs minutes si l'une des adresses IP cibles ne peut pas être atteinte.</block>
  <block id="1dba8f39914c5f44e3cb635e7ac7563e" category="section-title">Découverte des LUN iSCSI</block>
  <block id="68307bef4b9dc4071d875a0c2aadd321" category="paragraph">Une fois les cibles iSCSI détectées, redémarrez le service iSCSI pour découvrir les LUN iSCSI disponibles et construire les périphériques associés tels que les périphériques multivoies ou ASMlib.</block>
  <block id="25d811252f87ae85dda97f2ab9dd1f3a" category="section-title">Redémarrez l'environnement</block>
  <block id="8a9aae851d31dae8baf96171f114955e" category="paragraph">Redémarrez l'environnement en réactivant les groupes de volumes, en remontant les systèmes de fichiers, en redémarrant les services RAC, etc. Par mesure de précaution, NetApp vous recommande de redémarrer le serveur une fois le processus de conversion terminé afin de vous assurer que tous les fichiers de configuration sont corrects et que tous les périphériques obsolètes sont supprimés.</block>
  <block id="00f4c8378b0bf837cee4b0aed8886f31" category="paragraph">Attention : avant de redémarrer un hôte, assurez-vous que toutes les entrées dans<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block> Les ressources SAN migrées de cette référence sont commentées. Si cette étape n'est pas effectuée et qu'il y a des problèmes avec l'accès aux LUN, le système d'exploitation ne s'amorce pas. Ce problème n'endommage pas les données. Cependant, il peut être très peu commode de démarrer en mode de secours ou un mode similaire et correct<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block> Afin que le système d'exploitation puisse être démarré pour permettre aux efforts de dépannage de commencer.</block>
  <block id="7e712b6bec5dd0821f1822121da9f0c6" category="summary">Gestion des performances Oracle avec QoS</block>
  <block id="ff8b87ff7571fb54e71c9589f1b886a3" category="doc">Qualité de service avec les bases de données Oracle</block>
  <block id="08e3cfb3c3dfa08d34bcbbfe07fe5f28" category="paragraph">Pour gérer efficacement et en toute sécurité plusieurs bases de données Oracle, il est nécessaire de disposer d'une stratégie de qualité de service efficace. C'est pourquoi les systèmes de stockage modernes offrent des performances toujours plus élevées.</block>
  <block id="3408fe4b6e4b2ed9366356f08e3b9ab0" category="summary">Efficacité du stockage et des bases de données Oracle</block>
  <block id="151654fbc652cca26707bd7a060073d3" category="doc">Bases de données Oracle et fonctionnalités d'efficacité ONTAP</block>
  <block id="4564218d346b0ef8263512ebe659337d" category="paragraph">Les fonctionnalités ONTAP d'optimisation de l'espace sont optimisées pour les bases de données Oracle. Dans la plupart des cas, la meilleure approche consiste à conserver les valeurs par défaut avec toutes les fonctionnalités d'efficacité activées.</block>
  <block id="794c6d3bb54da92d9a4a4022bc5c4e94" category="summary">RAID et les bases de données Oracle</block>
  <block id="ead1ce56c368cc12c4f8932e01c92f65" category="doc">Configuration Oracle RAID requise</block>
  <block id="e959fe6bb794f67f31a0d4e6bc5d5bf4" category="paragraph">RAID désigne l'utilisation de la redondance pour protéger les données contre la perte d'un disque.</block>
  <block id="b60b0e7c75501fe2f322675f2e6da6d7" category="paragraph">Des questions se posent parfois au sujet des niveaux RAID dans la configuration du stockage NetApp utilisé pour les bases de données Oracle et d'autres applications d'entreprise. De nombreuses meilleures pratiques Oracle en matière de configuration de baie de stockage contiennent des avertissements concernant l'utilisation de la mise en miroir RAID et/ou l'évitement de certains types de RAID. Bien qu'elles soulèvent des points valides, ces sources ne s'appliquent pas au RAID 4 et aux technologies NetApp RAID DP et RAID-TEC utilisées dans ONTAP.</block>
  <block id="6de6bcceac7c1a53ecb774d42b8d5c9a" category="summary">Provisionnement fin Oracle et ONTAP</block>
  <block id="e04c5c8668870edf8392b07169f96644" category="doc">Provisionnement fin avec Oracle</block>
  <block id="26c71bfc140fc9f2d56f83f7aedffd53" category="paragraph">Le provisionnement fin pour une base de données Oracle nécessite une planification minutieuse, car il en résulte une configuration d'espace sur un système de stockage qui n'est pas nécessairement physiquement disponible. Cela vaut vraiment le coup, car une fois correctement effectué, il en résulte des économies considérables et des améliorations en termes de gestion.</block>
  <block id="c9a6446e7a1a2aa2d3d06c76b3dd02ae" category="summary">Provisionnement SVM pour les bases de données Oracle</block>
  <block id="eaa6380760494a867d1be23523aaba3e" category="doc">Bases de données Oracle et machines virtuelles de stockage</block>
  <block id="ffa2dec61afa63c15c9906328e62e2e8" category="paragraph">La gestion du stockage des bases de données Oracle est centralisée sur un SVM (Storage Virtual machine)</block>
  <block id="ba0fd7b6bfa61ad7f7ad5326a0934d01" category="summary">Il est nécessaire de bien comprendre les fonctions de basculement et de basculement du stockage pour s'assurer que les opérations de la base de données Oracle ne sont pas interrompues par ces opérations. En outre, les arguments utilisés par les opérations de basculement et de basculement peuvent affecter l'intégrité des données en cas d'utilisation incorrecte.</block>
  <block id="75f921b4326183319e82bc907e80cc42" category="doc">Basculement/basculement du contrôleur Oracle et ONTAP</block>
  <block id="999548558d2844d78a3b5f9186c231a4" category="summary">Capacité de stockage et espace libre pour les bases de données et ONTAP</block>
  <block id="3736e7d9912dca1541f3d86788010d1d" category="doc">Oracle et la gestion de la capacité de stockage</block>
  <block id="360612d74cdd78953036946ec943f795" category="paragraph">La gestion d'une base de données ou d'une autre application d'entreprise avec un stockage d'entreprise prévisible, gérable et haute performance requiert de l'espace libre sur les disques pour la gestion des données et des métadonnées. La quantité d'espace libre requise dépend du type de disque utilisé et des processus métier.</block>
  <block id="655dc175973dc3d055e6e798ce1399a6" category="summary">Paramètre de lecture Oracle multibloc</block>
  <block id="d3cc759510a3aba837fc8efeb2e24b91" category="doc">db_file_multibloc_read_count</block>
  <block id="32faf0a922da10425f2be9f86a5f5e18" category="paragraph">Le<block ref="d3cc759510a3aba837fc8efeb2e24b91" prefix=" " category="inline-code"></block> Paramètre contrôle le nombre maximal de blocs de base de données Oracle lus par Oracle au cours d'une opération, pendant les E/S séquentielles</block>
  <block id="36cb03af3dc688208e0e94fda31ca7a4" category="paragraph">Toutefois, ce paramètre n'affecte pas le nombre de blocs lus par Oracle au cours des opérations de lecture, ni le nombre d'E/S aléatoires Seule la taille de bloc des E/S séquentielles est affectée.</block>
  <block id="2565c992b3732464484104f4c846d9b4" category="paragraph">Oracle recommande à l'utilisateur de ne pas définir ce paramètre. Cela permet au logiciel de base de données de définir automatiquement la valeur optimale. Cela signifie généralement que ce paramètre est défini sur une valeur qui produit une taille d'E/S de 1 Mo. Par exemple, une lecture de 1 Mo de blocs de 8 Ko nécessite la lecture de 128 blocs. La valeur par défaut de ce paramètre est donc 128.</block>
  <block id="0fd26e725a6c1a81508e013094776e2c" category="paragraph">La plupart des problèmes de performance de base de données observés par NetApp sur les sites des clients provenaient de paramètres incorrects. Des raisons valides ont été données pour modifier cette valeur avec les versions 8 et 9 d'Oracle. Par conséquent, le paramètre peut être présent sans le savoir dans<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> Fichiers car la base de données a été mise à niveau vers Oracle 10 et versions ultérieures. La configuration héritée de 8 ou 16, par rapport à la valeur par défaut 128, nuit de manière significative aux performances d'E/S séquentielles.</block>
  <block id="3f594bb922365c7a9f095f44822fa22e" category="admonition">*NetApp recommande* de régler le<block ref="d3cc759510a3aba837fc8efeb2e24b91" prefix=" " category="inline-code"></block> le paramètre ne doit pas être présent dans le<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> fichier. NetApp n'a jamais observé d'amélioration des performances suite à la modification de ce paramètre, mais le débit d'E/S séquentielles subit une importante dégradation dans de nombreux cas.</block>
  <block id="669ebbf33c0b19005e2ccaf02ba69e5f" category="summary">Paramètres Oracle RAC avec stockage en réseau</block>
  <block id="5c87e825763ec1e41a459f6baa4b2a44" category="doc">Oracle Real application clusters (RAC)</block>
  <block id="0eec903bb9d87349e379892ca99ef9ec" category="paragraph">Oracle RAC est un produit clusterware qui comporte plusieurs types de processus de pulsation internes qui contrôlent l'intégrité du cluster.</block>
  <block id="7c13d022c9fda6e792c4349a043a6c74" category="inline-link-macro">misscount</block>
  <block id="bab4ae46619fcbbb84e3375ef205e61c" category="admonition">Les informations dans le <block ref="9cd17d807316d35ef47b12cbecab4ec8" category="inline-link-macro-rx"></block> La section contient des informations essentielles pour les environnements RAC Oracle utilisant un stockage en réseau. Dans la plupart des cas, les paramètres RAC Oracle par défaut devront être modifiés pour garantir que le cluster RAC résiste aux modifications de chemin réseau et aux opérations de basculement/basculement du stockage.</block>
  <block id="0494651671c3dc7f1ccdf99a4368a2cf" category="section-title">disktimeout</block>
  <block id="1973cfff3b7c6d828ede9d420b8481b5" category="paragraph">Le paramètre RAC principal lié au stockage est<block ref="0494651671c3dc7f1ccdf99a4368a2cf" prefix=" " category="inline-code"></block>. Ce paramètre contrôle le seuil au sein duquel les E/S du fichier de vote doivent être terminées. Si le<block ref="0494651671c3dc7f1ccdf99a4368a2cf" prefix=" " category="inline-code"></block> Le paramètre est dépassé, puis le nœud RAC est supprimé du cluster. La valeur par défaut de ce paramètre est 200. Cette valeur doit être suffisante pour les procédures standard de Takeover et and Giveback du stockage.</block>
  <block id="4aa33fc988e36b9531d36da80d35ec2f" category="paragraph">NetApp recommande fortement de tester soigneusement les configurations RAC avant de les mettre en production, car de nombreux facteurs affectent un basculement ou un rétablissement. Outre le temps nécessaire au basculement du stockage, la propagation des modifications du protocole LACP (Link Aggregation Control Protocol) nécessite également du temps supplémentaire. En outre, le logiciel de chemins d'accès multiples SAN doit détecter un délai d'expiration d'E/S et réessayer sur un autre chemin. Si une base de données est extrêmement active, une grande quantité d'E/S doit être mise en file d'attente et relancée avant le traitement des E/S du disque de vote.</block>
  <block id="655a10764a0781d26dca3bfb939457b7" category="paragraph">En l'absence d'un basculement ou d'un retour de stockage réel, l'effet peut être simulé à l'aide de tests de câble Pull sur le serveur de base de données.</block>
  <block id="b2a9e8dd67b2d9a7333cb2c2495c2aa5" category="list-text">En quittant le<block ref="0494651671c3dc7f1ccdf99a4368a2cf" prefix=" " category="inline-code"></block> paramètre à la valeur par défaut de 200.</block>
  <block id="971a52f4b805c654dd133cf142457c53" category="list-text">Testez toujours soigneusement une configuration RAC.</block>
  <block id="cd7a91511dbfbe5c79de12fa7d394dc0" category="paragraph">Le<block ref="7c13d022c9fda6e792c4349a043a6c74" prefix=" " category="inline-code"></block> Le paramètre affecte normalement uniquement la pulsation réseau entre les nœuds RAC. La valeur par défaut est 30 secondes. Si les binaires de la grille se trouvent sur une matrice de stockage ou si le disque d'amorçage du système d'exploitation n'est pas local, ce paramètre peut devenir important. Cela inclut les hôtes avec des lecteurs de démarrage situés sur un SAN FC, les systèmes d'exploitation démarrés par NFS et les lecteurs de démarrage situés sur les datastores de virtualisation, tels qu'un fichier VMDK.</block>
  <block id="9c1fd24d7d8e04847dadb944a6643121" category="paragraph">Si l'accès à un disque de démarrage est interrompu par un basculement ou un rétablissement du stockage, il est possible que l'emplacement binaire de la grille ou l'ensemble du système d'exploitation soit temporairement bloqué. Le temps nécessaire à ONTAP pour terminer l'opération de stockage et au système d'exploitation pour changer les chemins et reprendre les E/S peut être supérieur à<block ref="7c13d022c9fda6e792c4349a043a6c74" prefix=" " category="inline-code"></block> seuil. Par conséquent, un nœud est immédiatement supprimé une fois la connectivité à la LUN de démarrage ou aux binaires de la grille restaurée. Dans la plupart des cas, l'exclusion et le redémarrage qui s'ensuit se produisent sans message de journalisation indiquant la raison du redémarrage. Toutes les configurations ne sont pas affectées. Testez donc tout hôte de démarrage SAN, de démarrage NFS ou basé sur un datastore dans un environnement RAC afin que RAC reste stable si la communication avec le lecteur de démarrage est interrompue.</block>
  <block id="2b875dbca82565f3d7e2fa51633bc2c9" category="paragraph">Dans le cas de lecteurs de démarrage non locaux ou d'un système de fichiers non local hébergeant<block ref="ff4a008470319a22d9cf3d14af485977" prefix=" " category="inline-code"></block> binaires, le<block ref="7c13d022c9fda6e792c4349a043a6c74" prefix=" " category="inline-code"></block> devra être modifié pour correspondre<block ref="0494651671c3dc7f1ccdf99a4368a2cf" prefix=" " category="inline-code"></block>. Si ce paramètre est modifié, effectuez des tests supplémentaires pour identifier également les effets sur le comportement du RAC, tels que le temps de basculement du nœud.</block>
  <block id="08d7a86ed9292993deaa28bee18d5ce5" category="list-text">Quittez le<block ref="7c13d022c9fda6e792c4349a043a6c74" prefix=" " category="inline-code"></block> paramètre à la valeur par défaut de 30, sauf si l'une des conditions suivantes s'applique :</block>
  <block id="5b46e861366ffd98cd94c26abf2bf550" category="list-text"><block ref="ff4a008470319a22d9cf3d14af485977" prefix="" category="inline-code"></block> Les fichiers binaires sont situés sur un disque connecté au réseau, y compris les disques basés sur NFS, iSCSI, FC et les datastores.</block>
  <block id="7ace6d79e63cb29c86093526fbddf845" category="list-text">Le système d'exploitation est démarré sur un SAN.</block>
  <block id="985511d6258bbf659d35bd76e0b0cea1" category="list-text">Dans de tels cas, évaluez l'effet des interruptions de réseau qui affectent l'accès au système d'exploitation ou<block ref="9599929f8663b5e2093f7bc5cb20b0c2" prefix=" " category="inline-code"></block> systèmes de fichiers. Dans certains cas, de telles interruptions provoquent le blocage des démons RAC Oracle, ce qui peut conduire à un<block ref="7c13d022c9fda6e792c4349a043a6c74" prefix=" " category="inline-code"></block>délai d'expiration et suppression basés sur. Le délai par défaut est de 27 secondes, soit la valeur de<block ref="7c13d022c9fda6e792c4349a043a6c74" prefix=" " category="inline-code"></block> moins<block ref="c9333b0a26b9f9e9fd808e6238d613b0" prefix=" " category="inline-code"></block>. Dans de tels cas, augmenter<block ref="7c13d022c9fda6e792c4349a043a6c74" prefix=" " category="inline-code"></block> à 200 pour correspondre<block ref="0494651671c3dc7f1ccdf99a4368a2cf" prefix=" " category="inline-code"></block>.</block>
  <block id="6cde0106c3eb71034259ac34de5e6a2c" category="summary">Options_de_fichiers_Oracle</block>
  <block id="a3f7c31b8d967e0ac9f9dd30fc81c061" category="paragraph">Le paramètre d'initialisation Oracle<block ref="f1110589be196c2310808482067fce1b" prefix=" " category="inline-code"></block> Contrôle l'utilisation des E/S asynchrones et directes</block>
  <block id="d1fa3441fd96418a75a509ac2907d644" category="paragraph">Contrairement à une idée reçue, ces deux types d'E/S ne s'excluent pas mutuellement. NetApp a observé que ce paramètre est souvent mal configuré dans les environnements des clients. Cette configuration incorrecte est la cause directe de nombreux problèmes de performances.</block>
  <block id="0775b72ddf51e2a16e466ee2df8f75ab" category="paragraph">Les E/S asynchrones offrent la possibilité de paralléliser les opérations Oracle d'E/S. Avant la disponibilité des E/S asynchrones sur différents systèmes d'exploitation, les utilisateurs ont configuré de nombreux processus dbwriter et modifié la configuration du processus serveur. Avec les E/S asynchrones, le système d'exploitation lui-même exécute les E/S en parallèle pour le compte du logiciel de base de données. Ce processus ne présente aucun risque pour les données et les opérations critiques, telles que la journalisation de reprise Oracle, sont toujours exécutées de manière synchrone.</block>
  <block id="6b72950206966c1983e559eb6886ec69" category="paragraph">Les E/S directes contournent le cache du tampon du système d'exploitation. Sur un système UNIX, les E/S transitent normalement par le cache du tampon du système d'exploitation. Ceci est utile pour les applications qui ne maintiennent pas de cache interne, mais Oracle dispose de son propre cache de tampon dans la SGA. Dans la plupart des cas, il est préférable d'activer les E/S directes et d'allouer la RAM du serveur à la mémoire SGA plutôt que d'utiliser le cache du tampon du système d'exploitation. La SGA exploite la mémoire plus efficacement. En outre, lors de leur transit via le tampon du se, les E/S sont soumises à un traitement supplémentaire, ce qui augmente les latences. Cette augmentation est particulièrement visible lors des E/S intenses en écriture, pour lesquelles la faible latence est primordiale.</block>
  <block id="d8590a940a5bb30d8a845f4359f3c779" category="paragraph">Les options pour<block ref="f1110589be196c2310808482067fce1b" prefix=" " category="inline-code"></block> sont :</block>
  <block id="0aea10c6719256027228a859db38f291" category="list-text">*Async.* Oracle soumet des demandes d'E/S au système d'exploitation pour traitement. Ce qui lui permet d'effectuer d'autres tâches plutôt que d'attendre la fin des E/S et d'augmenter ainsi la parallélisation des E/S.</block>
  <block id="00cb0cc309682c42b3b936a19a042434" category="list-text">*Directio.* Oracle effectue des E/S directement par rapport aux fichiers physiques plutôt que de router les E/S via le cache du système d'exploitation hôte.</block>
  <block id="f9941e1b6cc84711e95db0e757efc36a" category="list-text">*None.* Oracle utilise des E/S synchrones et mises en tampon Dans cette configuration, le choix entre les processus serveur partagés et dédiés et le nombre de dbwriter est plus important.</block>
  <block id="f0939ff6231565c83c5c8c9ce1eddc9d" category="list-text">*Setall.* Oracle utilise des E/S asynchrones et directes Dans presque tous les cas, l'utilisation de<block ref="aef8f91b1e026cc1bb55e8b08c491d35" prefix=" " category="inline-code"></block> est optimale.</block>
  <block id="8647b2eaf101a9425f69e6f2e67aeb9d" category="admonition">Le<block ref="f1110589be196c2310808482067fce1b" prefix=" " category="inline-code"></block> Ce paramètre n'a aucun effet dans les environnements dNFS et ASM. Dans ces environnements, les E/S asynchrones et directes sont automatiquement utilisées</block>
  <block id="6dd5604aa0be2956f8b1b41c74fa648e" category="paragraph">Certains clients ont déjà rencontré des problèmes d'E/S asynchrones, notamment avec les versions précédentes de Red Hat Enterprise Linux 4 (RHEL4). Certains conseils obsolètes sur Internet suggèrent toujours d'éviter les E/S asynchrones en raison d'informations obsolètes. Les E/S asynchrones sont stables sur tous les systèmes d'exploitation actuels. Il n'y a aucune raison de le désactiver, en l'absence d'un bug connu avec le système d'exploitation.</block>
  <block id="1ea377466376b194b2d1bfc3ab2fa4c4" category="paragraph">Si une base de données utilise des E/S mises en tampon, un switch vers des E/S directes peut également justifier une modification de la taille de la mémoire SGA. La désactivation des E/S mises en tampon élimine le gain de performance fourni par le cache du se hôte pour la base de données. L'ajout de RAM à la SGA résout ce problème. Et devrait améliorer les performances nettes d'E/S.</block>
  <block id="787b3d8b62af05ac3efd1c9ca7a8fc7e" category="paragraph">Bien qu'il soit presque toujours préférable d'utiliser la RAM pour la SGA d'Oracle plutôt que pour le cache du tampon du système d'exploitation, il peut s'avérer impossible de déterminer ce qui est le plus avantageux. Par exemple, il est parfois préférable d'utiliser des E/S mises en tampon avec une mémoire SGA de très petite taille sur un serveur de base de données comportant de nombreuses instances Oracle actives par intermittence. Cette configuration permet à toutes les instances de base de données en cours d'exécution d'utiliser de manière flexible la RAM restante sur le système d'exploitation. Cette situation est très inhabituelle, mais elle a été observée sur certains sites clients.</block>
  <block id="d4157ab77eb31459bd406aa0f873e20c" category="admonition">*NetApp recommande* le réglage<block ref="f1110589be196c2310808482067fce1b" prefix=" " category="inline-code"></block> à<block ref="aef8f91b1e026cc1bb55e8b08c491d35" prefix=" " category="inline-code"></block>, Mais notez que dans certains cas, la perte du cache du tampon hôte peut nécessiter une augmentation de la SGA d'Oracle.</block>
  <block id="caa6d47f2f011d5d1b5fb830e85a37f0" category="summary">Taille de bloc Oracle</block>
  <block id="6db776dab2989df63d245511a4dccf08" category="doc">Tailles de bloc Oracle</block>
  <block id="f8b42f9efd1a05ede10b0e0c11dfa8b0" category="paragraph">ONTAP utilise en interne une taille de bloc variable, ce qui signifie que les bases de données Oracle peuvent être configurées avec n'importe quelle taille de bloc. Cependant, la taille des blocs du système de fichiers peut affecter les performances et, dans certains cas, une taille de bloc de reprise supérieure peut améliorer les performances.</block>
  <block id="0944aedb4703c4a5e94fb90de9d7a22f" category="section-title">Tailles des blocs de fichiers de données</block>
  <block id="cc4662c047050e0082701ce6f052dcb7" category="paragraph">Certains systèmes d'exploitation offrent un choix de tailles de blocs de système de fichiers. Pour les systèmes de fichiers prenant en charge les fichiers de données Oracle, la taille de bloc doit être de 8 Ko lorsque la compression est utilisée. Lorsque la compression n'est pas requise, vous pouvez utiliser une taille de bloc de 8 Ko ou 4 Ko.</block>
  <block id="e1a001cf8c7e2072c7a44ee65e8fee11" category="paragraph">Si un fichier de données est placé sur un système de fichiers avec un bloc de 512 octets, des fichiers mal alignés sont possibles. Il est possible que le LUN et le système de fichiers soient correctement alignés en fonction des recommandations de NetApp, mais les E/S de fichier sont mal alignées. Un tel mauvais alignement entraînerait de graves problèmes de performances.</block>
  <block id="9514c8638f798f68108498dd218ec793" category="paragraph">Les systèmes de fichiers prenant en charge les journaux de reprise doivent utiliser une taille de bloc qui représente un multiple de la taille de bloc de reprise. Cela nécessite généralement que le système de fichiers redo log et le fichier redo log lui-même utilisent une taille de bloc de 512 octets.</block>
  <block id="cac7d87a1164763b666ca7d02109d153" category="section-title">Rétablir les tailles des blocs</block>
  <block id="fa06b9584ea36af182742c07894220f0" category="paragraph">Avec des taux de reprise très élevés, il est possible que des tailles de bloc de 4 Ko soient plus performantes, car les taux de reprise élevés permettent d'exécuter les E/S en moins d'opérations et de manière plus efficace. Si les taux de reprise sont supérieurs à 50 Mbit/s, envisagez de tester une taille de bloc de 4 Ko.</block>
  <block id="781000593b4913b5625dd5ed9eebe87e" category="paragraph">Quelques problèmes clients ont été identifiés avec les bases de données à l'aide de journaux de reprise avec une taille de bloc de 512 octets sur un système de fichiers d'une taille de bloc de 4 Ko et de nombreuses transactions très petites. La surcharge liée à l'application de plusieurs modifications de 512 octets à un seul bloc du système de fichiers de 4 Ko a entraîné des problèmes de performances qui ont été résolus en changeant le système de fichiers pour qu'il utilise une taille de bloc de 512 octets.</block>
  <block id="a02416fde36b174cf1196213fcf1bef6" category="admonition">*NetApp vous recommande* de ne pas modifier la taille du bloc de reprise, sauf si un service client ou un service professionnel vous en informe ou si le changement est basé sur la documentation officielle du produit.</block>
  <block id="00783c075f877e6e69c64079296967ed" category="summary">Reprise après incident Oracle avec ONTAP</block>
  <block id="6a87f84ba62b57e5643d5bfa5967c7a8" category="doc">Reprise après incident avec ONTAP</block>
  <block id="65a6ece62f52a5e2ff74baaae821ae86" category="paragraph">La reprise d'activité consiste à restaurer les services de données après une catastrophe, par exemple un incendie qui détruit un système de stockage, voire un site entier.</block>
  <block id="e168b3b0b2f075f39012df52c5ea3c0a" category="admonition">Cette documentation remplace les rapports techniques _TR-4591 : Oracle Data protection_ et _TR-4592 : Oracle on MetroCluster._</block>
  <block id="a91982f09e6a0341a90dae002865ea11" category="paragraph">La reprise après incident peut être effectuée par une simple réplication des données à l'aide de SnapMirror, bien sûr, lorsque de nombreux clients mettent à jour les réplicas en miroir toutes les heures.</block>
  <block id="0f1b72a875a2bcb3d0e844ca2dcee233" category="paragraph">Pour la plupart des clients, la reprise après incident ne suffit pas à posséder une copie distante des données. Il est donc nécessaire de pouvoir les exploiter rapidement. NetApp propose deux technologies pour répondre à ce besoin : MetroCluster et SnapMirror Business Continuity (SM-BC)</block>
  <block id="ad2c5e9521f13e89cd84fdd65ec96c7d" category="paragraph">MetroCluster fait référence à ONTAP dans une configuration matérielle qui inclut un stockage en miroir synchrone de faible niveau et de nombreuses fonctionnalités supplémentaires. Les solutions intégrées telles que MetroCluster simplifient les bases de données, les applications et les infrastructures de virtualisation complexes et évolutives. Elle remplace plusieurs produits et stratégies externes de protection des données par une seule baie de stockage centrale simple. Elle offre également des fonctionnalités intégrées de sauvegarde, de restauration, de reprise après incident et de haute disponibilité au sein d'un seul système de stockage en cluster.</block>
  <block id="05be1e741eba1ac3f0b7c924f261403b" category="paragraph">La continuité de l'activité SnapMirror (SM-BC) est basée sur la technologie SnapMirror synchrone. Avec MetroCluster, chaque contrôleur ONTAP est responsable de la réplication des données de son disque vers un emplacement distant. Avec SM-BC, vous disposez essentiellement de deux systèmes ONTAP différents qui conservent des copies indépendantes de vos données LUN, mais qui coopèrent pour présenter une seule instance de ce LUN. Du point de vue de l'hôte, il s'agit d'une entité LUN unique.</block>
  <block id="70f47db03a0843fec433c8cc41a54635" category="paragraph">Bien que SM-BC et MetroCluster fonctionnent très différemment en interne, le résultat est très similaire pour un hôte. La principale différence est la granularité. Si vous n'avez besoin que de workloads spécifiques pour la réplication synchrone, la solution SM-BC est la mieux adaptée. Si vous devez répliquer des environnements entiers, voire des data centers, MetroCluster est la meilleure option. Par ailleurs, SM-BC est actuellement réservé aux environnements SAN, tandis que MetroCluster est multiprotocole, y compris SAN, NFS et SMB.</block>
  <block id="7389dc8e47495ffdde7fd2e0fc19df20" category="summary">Basculement Oracle avec SM-BC</block>
  <block id="0a54809bbd5dc721967217b79aa04429" category="paragraph">La raison principale de l'hébergement d'une base de données Oracle sur SM-BC est d'assurer un basculement transparent lors d'événements de stockage planifiés ou non.</block>
  <block id="cfb8f86af03363ef2c73933e34108390" category="summary">Instance unique Oracle sur ONTAP avec SM-BC</block>
  <block id="f25228759326d365adf4dca6b7b2cb8b" category="doc">Oracle à instance unique avec SM-BC</block>
  <block id="a38cb04f35bd24313f90398cdc07e149" category="paragraph">Le diagramme ci-dessous présente un modèle de déploiement simple dans lequel des périphériques de stockage sont zonés ou connectés à partir des clusters de stockage principal et distant pour une base de données Oracle.</block>
  <block id="ac38db4f14e512b48d088eedb84cd611" category="paragraph">Oracle est configuré sur le système principal uniquement. Ce modèle assure un basculement transparent du stockage en cas d'incident côté stockage, ce qui évite toute perte de données sans temps d'indisponibilité des applications. Cependant, ce modèle n'assure pas la haute disponibilité de l'environnement de base de données en cas de défaillance sur un site. Ce type d'architecture s'avère utile pour les clients qui recherchent une solution sans perte de données avec une haute disponibilité des services de stockage, mais qui acceptent qu'une perte totale du cluster de base de données nécessite une intervention manuelle.</block>
  <block id="ccc53ca027c7d8fb1e0d647249fd67cd" category="paragraph"><block ref="ccc53ca027c7d8fb1e0d647249fd67cd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4e072ef2eba1c46e59475046cd4fb880" category="paragraph">Cette approche permet également d'économiser de l'argent sur les coûts de licence Oracle. La préconfiguration des nœuds de bases de données Oracle sur le site distant exigerait que tous les cœurs soient sous licence selon la plupart des contrats de licence Oracle. Si le délai d'installation d'un serveur de base de données Oracle et de montage de la copie restante des données est acceptable, cette conception peut s'avérer très rentable.</block>
  <block id="5e2dd7c2fa063e6d7af964efc0e488a0" category="summary">Oracle RAC sur ONTAP avec SM-BC</block>
  <block id="f7d366254f13816be07d3c8dff4ef00c" category="doc">Oracle RAC avec SM-BC</block>
  <block id="67bbc9e19672ee6c9c548cae8a472396" category="paragraph">SM-BC offre un contrôle granulaire de la réplication des datasets à des fins telles que l'équilibrage de la charge ou le basculement d'applications individuelles. L'architecture globale ressemble à un cluster RAC étendu, mais certaines bases de données sont dédiées à des sites spécifiques et la charge globale est distribuée.</block>
  <block id="9331b3ad2bcf259818157930e1c82ad3" category="paragraph">Par exemple, vous pouvez créer un cluster Oracle RAC hébergeant six bases de données individuelles. Le stockage de trois des bases de données serait principalement hébergé sur le site A et le stockage des trois autres bases de données serait hébergé sur le site B. Cette configuration garantit les meilleures performances possibles en minimisant le trafic intersite. En outre, les applications seraient configurées pour utiliser les instances de base de données locales au système de stockage avec les chemins actifs. Cela réduit le trafic d'interconnexion RAC. Enfin, cette conception globale garantit l'utilisation uniforme de toutes les ressources de calcul. À mesure que les workloads changent, les bases de données peuvent faire l'objet d'un échec sélectif entre les sites pour assurer un chargement homogène.</block>
  <block id="4278792a47efb1e599476fe07109dca4" category="inline-link-macro">Oracle RAC sur MetroCluster</block>
  <block id="1c6753ccdcc6629af3e1febabbf271b5" category="paragraph">Outre la granularité, les principes et options de base d'Oracle RAC utilisant SM-BC sont les mêmes que <block ref="f7453402f1e4779ea0ec67d873358932" category="inline-link-macro-rx"></block></block>
  <block id="7e544b57620f5cdeb71865606eab0549" category="summary">Oracle avec continuité de l'activité SnapMirror (SM-BC)</block>
  <block id="33aa8b7a84723347d228956fab2a4de8" category="doc">Continuité de l'activité pour Oracle et SnapMirror</block>
  <block id="41eec95e0dbb542c5cd25248ec5759d5" category="paragraph">SM-BC permet une mise en miroir synchrone avec RPO=0 sélective pour les bases de données Oracle et les environnements applicatifs individuels.</block>
  <block id="563d0bf19fd5d623a031d90c30128dc1" category="summary">Scénarios de défaillance d'Oracle SM-BC</block>
  <block id="3c1ea312a3c6648fc3f94a1ccd12bebc" category="doc">Scénarios de défaillance d'Oracle SM-BC</block>
  <block id="87777c84375810d8b6fd65f604dd2561" category="paragraph">Plusieurs scénarios de défaillance de la continuité de l'activité SnapMirror (SM-BC) ont chacun des résultats différents.</block>
  <block id="8eea62084ca7e541d918e823422bd82e" category="cell">Résultat</block>
  <block id="ee70ac41df7240931fee4110b599c39f" category="cell">Échec du lien de réplication</block>
  <block id="e79e76eca171f3e596eb56ba4bb24743" category="cell">Le médiateur reconnaît ce scénario de cerveau partagé et reprend les E/S sur le nœud qui contient la copie principale. Lorsque la connectivité entre les sites est de nouveau en ligne, le site secondaire effectue une resynchronisation automatique.</block>
  <block id="98a638ba6cee257a8f751bcf8d30e1f2" category="cell">Panne du stockage principal du site</block>
  <block id="b92af6cefecfe68535bbd851b797379f" category="cell">Le basculement automatique non planifié est initié par Mediator.

Sans perturbation des E/S</block>
  <block id="ce9a584219636ca5b159a27f2dd8c445" category="cell">Panne du stockage sur le site distant</block>
  <block id="68a293bd16c4e2589057d43506a5afbd" category="cell">Il n'y a pas de perturbation des E/S. Il y a une pause temporaire due au réseau qui provoque l'abandon de la réplication de synchronisation et au maître qui établit qu'il est le propriétaire légitime de continuer à transmettre les E/S (consensus). Par conséquent, une pause d'E/S de quelques secondes est observée, puis les E/S reprennent.

Il y a une resynchronisation automatique lorsque le site est en ligne.</block>
  <block id="64f4e3573d0b569ef7b5a08476fb9f7d" category="cell">Perte du médiateur ou de la liaison entre le Mediator et les baies de stockage</block>
  <block id="7e7abe23ef8e465ee1b6879b35e6bab3" category="cell">Les E/S se poursuivent et restent synchronisées avec le cluster distant, mais le basculement et le retour arrière automatiques imprévus/planifiés ne sont pas possibles en l'absence de Mediator.</block>
  <block id="96b352ebd03c8c5b7589a527b18f1a2d" category="cell">Perte d'un des contrôleurs de stockage dans le cluster HA</block>
  <block id="426c4468c3cc76191842240593fcfec3" category="cell">Le nœud partenaire dans le cluster HA tente un basculement (NDO). En cas d'échec du basculement, Mediator remarque que le nœud du stockage est en panne et effectue un basculement automatique non planifié vers le cluster distant.</block>
  <block id="0e578c93ab393c3d449d484e9fa4b84e" category="cell">Perte de disques</block>
  <block id="3d5fea5d89ec844fc92c08a585050e4e" category="cell">Les E/S se poursuivent pendant jusqu'à trois pannes de disque consécutives. Cela fait partie de RAID-TEC.</block>
  <block id="bd300f92769c0ee071832cadaff91f04" category="cell">Perte de l'ensemble du site dans un déploiement typique</block>
  <block id="9cfa40a514d333ea10de6fc8a75ac663" category="cell">De toute évidence, les serveurs du site défaillant ne seront plus disponibles. Les applications qui prennent en charge la mise en cluster peuvent être configurées pour s'exécuter sur les deux sites et continuer les opérations sur un autre site. Toutefois, la plupart de ces applications nécessitent un disjoncteur d'attache de troisième site, similaire à celui utilisé par SM-BC, qui requiert un médiateur.

Sans clusters au niveau des applications, les applications doivent être démarrées sur le site survivant. Cela affecterait la disponibilité, mais RPO=0 est conservé. Aucune donnée ne serait perdue.</block>
  <block id="f2762385d394491398659925e75d5d01" category="summary">Architecture physique MetroCluster - Oracle</block>
  <block id="5be41b602a41d06df45e8986ec09a8dc" category="doc">Architecture physique MetroCluster - Oracle</block>
  <block id="d12be40db836559c628e8024f5d6ff56" category="paragraph">Pour comprendre le fonctionnement des bases de données Oracle dans un environnement MetroCluster, il est nécessaire d'expliquer la conception physique d'un système MetroCluster.</block>
  <block id="5e33c0d8a2417ce5fb6e7a211ad063bb" category="admonition">Cette documentation remplace le rapport technique _TR-4592 : Oracle on MetroCluster._</block>
  <block id="bdec122112fe3ad35d588380dc643e48" category="summary">Architecture logique MetroCluster - Oracle</block>
  <block id="141402e8d9fa946970f252a09a01a462" category="doc">Architecture logique MetroCluster - Oracle</block>
  <block id="37fa92fc2662529308c62c84eb1b38ea" category="paragraph">Comprendre le fonctionnement des bases de données Oracle dans un environnement MetroCluster alsop nécessite une explication de la fonctionnalité logique d'un système MetroCluster.</block>
  <block id="2623b589ddbc1cdb6184ba32aa06e83f" category="inline-link-macro">NVFAIL</block>
  <block id="6ddd3d6bc3ad92b983699970b1596e0f" category="summary">Oracle avec MetroCluster</block>
  <block id="c1fac7a72cd91bcd345e567f6d6d93a3" category="doc">Basculement Oracle avec MetroCluster</block>
  <block id="7a60cb119af7ddcdfe38fc872d2027a1" category="paragraph">L'utilisation de MetroCluster n'apporte pas nécessairement de modifications aux meilleures pratiques en matière d'exploitation de bases de données et d'applications d'entreprise.</block>
  <block id="a4feacea8b05d0f24e5a4612a164a055" category="paragraph">Les bonnes pratiques habituelles s'appliquent toujours. Si vos besoins requièrent uniquement une protection des données avec un objectif de point de récupération de 0, MetroCluster répond à ce besoin. Cependant, la plupart des clients utilisent MetroCluster non seulement pour la protection des données avec un objectif de point de récupération de 0, mais aussi pour améliorer l'objectif de délai de restauration en cas d'incident et fournir un basculement transparent dans le cadre des activités de maintenance du site.</block>
  <block id="3ff8bcf18c694581aa25b0a347508e0f" category="section-title">Basculement avec un système d'exploitation préconfiguré</block>
  <block id="9bd9ad7f296a0e8ac3df804b3c6a392f" category="paragraph">SyncMirror livre une copie synchrone des données au niveau du site de reprise d'activité. La mise à disposition des données requiert un système d'exploitation et les applications associées. L'automatisation de base peut considérablement améliorer le délai de basculement de l'environnement global. Les produits Clusterware tels qu'Oracle RAC, Veritas Cluster Server (VCS) ou VMware HA sont souvent utilisés pour créer un cluster sur les sites et, dans la plupart des cas, le processus de basculement peut être piloté avec de simples scripts.</block>
  <block id="c5a2f3b867d990c681a218d29a55fcfa" category="paragraph">En cas de perte des nœuds principaux, le cluster (ou les scripts) est configuré de manière à mettre les applications en ligne sur le site secondaire. Une option consiste à créer des serveurs de secours préconfigurés pour les ressources NFS ou SAN qui constituent l'application. En cas de défaillance du site principal, le logiciel de mise en cluster ou l'alternative scriptée effectue une séquence d'actions similaires à celles décrites ci-dessous :</block>
  <block id="442f34633164f1be348a442b2c62d29d" category="list-text">Forçage du basculement MetroCluster</block>
  <block id="e081e79ea1b1040c51d4a452e46de76d" category="list-text">Découverte de LUN FC (SAN uniquement)</block>
  <block id="6f3fd86521759fc98ed93853eaf8a03a" category="list-text">Montage de systèmes de fichiers</block>
  <block id="9d9ea7a9c532a3cec63305130018a45b" category="list-text">Démarrage de l'application</block>
  <block id="b8eca7b573624230962095fcadb03ddf" category="paragraph">Cette approche doit avant tout se passer d'un système d'exploitation en cours d'exécution sur le site distant. Il doit être préconfiguré avec des binaires d'application, ce qui signifie également que des tâches telles que l'application de correctifs doivent être effectuées sur les sites principal et de secours. Les binaires d'application peuvent également être mis en miroir vers le site distant et montés en cas d'incident.</block>
  <block id="e60946bf73021e18706a6ac33386b376" category="paragraph">La procédure d'activation réelle est simple. Les commandes telles que la découverte de LUN ne nécessitent que quelques commandes par port FC. Le montage du système de fichiers n'est rien de plus qu'un<block ref="19822b1b15d9eefc54c07ab49f87b100" prefix=" " category="inline-code"></block> Et les bases de données et ASM peuvent être démarrés et arrêtés sur l'interface de ligne de commande à l'aide d'une seule commande. Si les volumes et les systèmes de fichiers ne sont pas utilisés sur le site de reprise d'activité avant le basculement, il n'est pas nécessaire de les définir<block ref="3b93661df04b698b1340ff2da3238d16" prefix=" " category="inline-code"></block> sur les volumes.</block>
  <block id="486eed21f55b6fb544db5504294592e6" category="section-title">Basculement avec un système d'exploitation virtualisé</block>
  <block id="bf65e943f86f26b49698bfdac9b95f81" category="paragraph">Le basculement des environnements de base de données peut être étendu pour inclure le système d'exploitation lui-même. En théorie, ce basculement peut être effectué avec des LUN de démarrage, mais le plus souvent avec un système d'exploitation virtualisé. La procédure est similaire aux étapes suivantes :</block>
  <block id="7c37589384e83d2b43bba430c18a45aa" category="list-text">Montage des datastores hébergeant les machines virtuelles du serveur de base de données</block>
  <block id="3d4d04d6cdab90b7ca0deb0344f04eec" category="list-text">Démarrage des machines virtuelles</block>
  <block id="ba2f22f63087151f0a0694be5f35fcf2" category="list-text">Démarrage manuel des bases de données ou configuration des machines virtuelles pour démarrer automatiquement les bases de données</block>
  <block id="810078f3b19b93e24de8638d68f727b5" category="paragraph">Par exemple, un cluster ESX peut couvrir des sites. En cas d'incident, les machines virtuelles peuvent être mises en ligne sur le site de reprise après incident après le basculement. Tant que les datastores hébergeant les serveurs de base de données virtualisés ne sont pas utilisés au moment de l'incident, il n'est pas nécessaire de les définir<block ref="3b93661df04b698b1340ff2da3238d16" prefix=" " category="inline-code"></block> sur les volumes associés.</block>
  <block id="681afe3bdc351138642f233429d64762" category="summary">Oracle et SyncMirror</block>
  <block id="bc8a6c6eac662831d2ddce97adbd4324" category="doc">SyncMirror - Oracle</block>
  <block id="c702c387f07bcb4f18482e68d69a155a" category="paragraph">Le socle de la protection des données Oracle avec un système MetroCluster est SyncMirror, une technologie de mise en miroir synchrone scale-out aux performances maximales.</block>
  <block id="9028b52caaa7bdbfb9be779eeb1fe00e" category="summary">Oracle Extended RAC avec MetroCluster</block>
  <block id="dbcedb2fd86e6012347a3c9ad111f3a8" category="doc">Oracle RAC étendu sur MetroCluster</block>
  <block id="4d4d8a609e5b2ac58e622eb1e90f9e39" category="paragraph">De nombreux clients optimisent leur RTO en étendant un cluster Oracle RAC sur plusieurs sites, offrant une configuration entièrement active/active. La conception globale devient plus complexe car elle doit inclure la gestion du quorum d'Oracle RAC. En outre, l'accès aux données se fait depuis les deux sites, ce qui signifie qu'un basculement forcé peut entraîner l'utilisation d'une copie obsolète des données.</block>
  <block id="89ffaa1a7d089080e9a1ce912bb8c2d3" category="paragraph">Bien qu'une copie des données soit présente sur les deux sites, seul le contrôleur qui possède actuellement un agrégat peut assurer le service des données. Par conséquent, avec les clusters RAC étendus, les nœuds distants doivent effectuer des E/S sur une connexion site à site. Il en résulte une latence d'E/S supplémentaire, mais cette latence n'est généralement pas problématique. Le réseau d'interconnexion RAC doit également être étendu entre les sites, ce qui signifie qu'un réseau haut débit à faible latence est requis de toute façon. Si la latence supplémentaire pose problème, le cluster peut être exploité de manière actif-passif. Les opérations exigeantes en E/S devront ensuite être dirigées vers les nœuds RAC locaux vers le contrôleur propriétaire des agrégats. Les nœuds distants effectuent alors des opérations d'E/S plus légères ou sont utilisés uniquement comme serveurs de secours.</block>
  <block id="375c3caa97162bd0c2c07869d9c5b026" category="paragraph">Si un RAC étendu actif-actif est requis, la mise en miroir ASM doit être prise en compte à la place de MetroCluster. La mise en miroir ASM permet de privilégier une réplique spécifique des données. Par conséquent, un cluster RAC étendu peut être intégré dans lequel toutes les lectures se produisent localement. Les E/S de lecture ne traversent jamais les sites, ce qui assure la latence la plus faible possible. Toute activité d'écriture doit toujours transiter la connexion intersite, mais ce trafic est inévitable avec toute solution de mise en miroir synchrone.</block>
  <block id="f441d5fdc388f3419fb87e071534f3ce" category="inline-link-macro">Oracle RAC avec ONTAP</block>
  <block id="59d934fc4614a6275fef2828bfab30cf" category="admonition">Si des LUN de démarrage, y compris des disques de démarrage virtualisés, sont utilisés avec Oracle RAC, le<block ref="7c13d022c9fda6e792c4349a043a6c74" prefix=" " category="inline-code"></block> il peut être nécessaire de modifier le paramètre. Pour plus d'informations sur les paramètres de délai d'expiration du RAC, reportez-vous à la section <block ref="75080d28a1748f78cf8a666ababf51af" category="inline-link-macro-rx"></block>.</block>
  <block id="58285fb769eb7fb05ab12d9e0efb3e50" category="section-title">Configuration à deux sites</block>
  <block id="af1184f29d838fbfec8d5b5bf5225f66" category="paragraph">Une configuration RAC étendue sur deux sites peut fournir des services de base de données actif-actif qui peuvent survivre à de nombreux scénarios d'incident, mais pas à tous, sans interruption.</block>
  <block id="7544489c7854fcae445508015240a865" category="section-title">Fichiers de vote RAC</block>
  <block id="8b6e46422f88dab6ea82f2dbcadfc76b" category="paragraph">La gestion du quorum doit être prise en compte lors du déploiement du RAC étendu sur MetroCluster. Oracle RAC dispose de deux mécanismes pour gérer le quorum : le battement de cœur du disque et le battement de cœur du réseau. La pulsation du disque surveille l'accès au stockage à l'aide des fichiers de vote. Dans le cas d'une configuration RAC à site unique, une ressource de vote unique suffit tant que le système de stockage sous-jacent offre des fonctionnalités haute disponibilité.</block>
  <block id="fafd618b82d1827eeb8197e1c38722bc" category="paragraph">Dans les versions précédentes d'Oracle, les fichiers de vote étaient placés sur des périphériques de stockage physiques, mais dans les versions actuelles d'Oracle, les fichiers de vote sont stockés dans des groupes de disques ASM.</block>
  <block id="aeab2391a07321ac474989b9c9047226" category="admonition">Oracle RAC est pris en charge par NFS. Pendant le processus d'installation de la grille, un ensemble de processus ASM est créé pour présenter l'emplacement NFS utilisé pour les fichiers de grille en tant que groupe de disques ASM. Le processus est presque transparent pour l'utilisateur final et ne nécessite aucune gestion ASM continue une fois l'installation terminée.</block>
  <block id="42aca4aae768d5ec1cb0c50d41b7b8b7" category="paragraph">Dans une configuration à deux sites, il est tout d'abord nécessaire de s'assurer que chaque site peut toujours accéder à plus de la moitié des fichiers de vote, ce qui garantit un processus de reprise après incident sans interruption. Cette tâche était simple avant que les fichiers de vote ne soient stockés dans des groupes de disques ASM, mais aujourd'hui, les administrateurs doivent comprendre les principes de base de la redondance ASM.</block>
  <block id="60a723853bb2c173648452baf2199e73" category="paragraph">Les groupes de disques ASM disposent de trois options de redondance<block ref="6a21b6995a068148bbb65c8f949b3fb2" prefix=" " category="inline-code"></block>,<block ref="fea087517c26fadd409bd4b9dc642555" prefix=" " category="inline-code"></block>, et<block ref="8d966b2253a917086c8604959e152243" prefix=" " category="inline-code"></block>. En d'autres termes, sans miroir, avec miroir et miroir à 3 voies. Une option plus récente appelée<block ref="09d2bd168181f1e64c2b1651a80a8aa8" prefix=" " category="inline-code"></block> est également disponible, mais rarement utilisé. Le niveau de redondance et le placement des périphériques redondants contrôlent ce qui se passe dans les scénarios de panne. Par exemple :</block>
  <block id="32cdeb2c0245b51a0b590e6054f03c21" category="list-text">Placer les fichiers de vote sur un<block ref="d4f266c5956ee60df748738c483f3dc0" prefix=" " category="inline-code"></block> avec<block ref="6a21b6995a068148bbb65c8f949b3fb2" prefix=" " category="inline-code"></block> la redondance des ressources garantit la suppression d'un site en cas de perte de la connectivité intersite.</block>
  <block id="a549b4f1fc0c2d14bc333c70bbde73dc" category="list-text">Placer les fichiers de vote sur un<block ref="d4f266c5956ee60df748738c483f3dc0" prefix=" " category="inline-code"></block> avec<block ref="fea087517c26fadd409bd4b9dc642555" prefix=" " category="inline-code"></block> La redondance avec un seul disque ASM par site garantit la suppression des nœuds sur les deux sites en cas de perte de la connectivité intersite, car aucun des sites ne possède un quorum majoritaire.</block>
  <block id="c15f1c43a368db0ab3dde90eca52582d" category="list-text">Placer les fichiers de vote sur un<block ref="d4f266c5956ee60df748738c483f3dc0" prefix=" " category="inline-code"></block> avec<block ref="8d966b2253a917086c8604959e152243" prefix=" " category="inline-code"></block> la redondance avec deux disques sur un site et un seul disque sur l'autre site permet des opérations actif-actif lorsque les deux sites sont opérationnels et mutuellement accessibles. Toutefois, si le site à disque unique est isolé du réseau, ce site est supprimé.</block>
  <block id="478ced47a1ea1d6f0db02af749bfdaec" category="section-title">Pulsation du réseau RAC</block>
  <block id="2432333dc52d6150fb3d58051bc8b0c2" category="paragraph">Le signal de présence du réseau RAC Oracle surveille l'accessibilité des nœuds sur l'interconnexion de cluster. Pour rester dans le cluster, un nœud doit pouvoir contacter plus de la moitié des autres nœuds. Dans une architecture à deux sites, cette exigence crée les choix suivants pour le nombre de nœuds RAC :</block>
  <block id="3e36a59c8a51ee9cc2cba0e7051ed35f" category="list-text">Le placement d'un nombre égal de nœuds par site entraîne la suppression sur un site en cas de perte de la connectivité réseau.</block>
  <block id="4955aede919912b3c62fadbc1039671b" category="list-text">Le placement de N nœuds sur un site et de N+1 nœuds sur le site opposé garantit que la perte de la connectivité intersite entraîne le site avec le plus grand nombre de nœuds restants dans le quorum du réseau et le site avec moins de nœuds supprimés.</block>
  <block id="80bd651a66488201c928634689e2e5cc" category="paragraph">Avant Oracle 12cR2, il était impossible de contrôler quel côté devait être expulsé en cas de perte du site. Lorsque chaque site a un nombre égal de nœuds, l'exclusion est contrôlée par le nœud maître, qui est en général le premier nœud RAC à démarrer.</block>
  <block id="d128c05245b2e633856a5061db176b7e" category="paragraph">Oracle 12cR2 introduit la fonctionnalité de pondération des nœuds. L'administrateur peut ainsi mieux contrôler la manière dont Oracle résout les problèmes de partage du cerveau. À titre d'exemple simple, la commande suivante définit les préférences pour un nœud particulier dans un RAC :</block>
  <block id="104c5747f0d9dbb47b0d09953c709a8d" category="paragraph">Après le redémarrage d'Oracle High-Availability Services, la configuration se présente comme suit :</block>
  <block id="693cce334ab6658c73ea67674775156b" category="paragraph">Nœud<block ref="a31853cdea7badfc68b560e70cbbeb02" prefix=" " category="inline-code"></block> est maintenant désigné comme serveur critique. Si les deux nœuds RAC sont isolés,<block ref="a31853cdea7badfc68b560e70cbbeb02" prefix=" " category="inline-code"></block> survit, et<block ref="bf38e7432ba60433c4c8967fc8da0258" prefix=" " category="inline-code"></block> est supprimé.</block>
  <block id="386839b09451962d03e26b7bbfabce74" category="admonition">Pour plus d'informations, consultez le livre blanc Oracle « Oracle Clusterware 12c Release 2 Technical Overview. ”</block>
  <block id="11f65689342acc8f71c8014eeb7945ee" category="paragraph">Pour les versions d'Oracle RAC antérieures à 12cR2, le nœud maître peut être identifié en vérifiant les journaux CRS comme suit :</block>
  <block id="c8b8cd80b31dac17fb85459c341042bd" category="paragraph">Ce journal indique que le nœud maître est<block ref="c81e728d9d4c2f636f067f89cc14862c" prefix=" " category="inline-code"></block> et le nœud<block ref="a31853cdea7badfc68b560e70cbbeb02" prefix=" " category="inline-code"></block> A un ID de<block ref="c4ca4238a0b923820dcc509a6f75849b" prefix=" " category="inline-code"></block>. Ce fait signifie que<block ref="a31853cdea7badfc68b560e70cbbeb02" prefix=" " category="inline-code"></block> n'est pas le nœud maître. L'identité du nœud maître peut être confirmée avec la commande<block ref="08e7c60bbf8289a563b25cc033d431f7" prefix=" " category="inline-code"></block>.</block>
  <block id="fdf6179b59d3f4873b042609a5f09bc4" category="paragraph">Le nœud ayant l'ID de<block ref="c81e728d9d4c2f636f067f89cc14862c" prefix=" " category="inline-code"></block> est<block ref="bf38e7432ba60433c4c8967fc8da0258" prefix=" " category="inline-code"></block>, qui est le nœud maître. Dans une configuration avec un nombre égal de nœuds sur chaque site, le site avec<block ref="bf38e7432ba60433c4c8967fc8da0258" prefix=" " category="inline-code"></block> est le site qui survit si les deux ensembles perdent la connectivité réseau pour quelque raison que ce soit.</block>
  <block id="f2932b43ad604fa01d57212558608ed6" category="paragraph">Il est possible que l'entrée de journal qui identifie le nœud maître puisse sortir du système. Dans ce cas, les horodatages des sauvegardes du registre des clusters Oracle (OCR) peuvent être utilisés.</block>
  <block id="50cd29958db0c1dcb6505d470f553e54" category="paragraph">Cet exemple montre que le nœud maître est<block ref="bf38e7432ba60433c4c8967fc8da0258" prefix=" " category="inline-code"></block>. Il indique également un changement dans le nœud maître de<block ref="a31853cdea7badfc68b560e70cbbeb02" prefix=" " category="inline-code"></block> à<block ref="bf38e7432ba60433c4c8967fc8da0258" prefix=" " category="inline-code"></block> Quelque part entre 2:05 et 21:39 le 4 mai. Cette méthode d'identification du nœud maître n'est sûre que si les journaux CRS ont également été vérifiés car il est possible que le nœud maître ait changé depuis la sauvegarde OCR précédente. Si ce changement s'est produit, il doit être visible dans les journaux OCR.</block>
  <block id="df044a3c3d7f7f244db7c42b347b9a90" category="paragraph">La plupart des clients choisissent un seul groupe de disques de vote qui dessert l'ensemble de l'environnement et un nombre égal de nœuds RAC sur chaque site. Le groupe de disques doit être placé sur le site qui contient la base de données. En conséquence, une perte de connectivité entraîne la suppression du site distant. Le site distant n'aurait plus le quorum, ni l'accès aux fichiers de base de données, mais le site local continue à fonctionner normalement. Une fois la connectivité rétablie, l'instance distante peut être de nouveau mise en ligne.</block>
  <block id="84a24276bfdfbe485b9d961c1a57a830" category="paragraph">En cas d'incident, un basculement est nécessaire pour mettre en ligne les fichiers de base de données et le groupe de disques de vote sur le site survivant. Si l'incident permet à AUSO de déclencher le basculement, NVFAIL n'est pas déclenché, car le cluster est connu pour être synchronisé et les ressources de stockage sont normalement mises en ligne. L'AUSO est une opération très rapide et doit se terminer avant le<block ref="0494651671c3dc7f1ccdf99a4368a2cf" prefix=" " category="inline-code"></block> la période expire.</block>
  <block id="6244ee13e435dcc768edbc9b0b38b73e" category="paragraph">Comme il n'y a que deux sites, il n'est pas possible d'utiliser n'importe quel type de logiciel automatisé externe de rupture de tieBreaking, ce qui signifie que le basculement forcé doit être une opération manuelle.</block>
  <block id="568c8c12fdb7c74f65125732ee717ad3" category="section-title">Configurations à trois sites</block>
  <block id="2c7696fb04f52eb5687d059415066fa7" category="paragraph">Un cluster RAC étendu est beaucoup plus facile à concevoir avec trois sites. Les deux sites hébergeant chaque moitié du système MetroCluster prennent également en charge les workloads de la base de données, tandis que le troisième sert de disjoncteur pour la base de données et le système MetroCluster. La configuration Oracle Tiebreaker peut être aussi simple que le placement d'un membre du groupe de disques ASM utilisé pour le vote sur un troisième site, et peut également inclure une instance opérationnelle sur le troisième site pour s'assurer qu'il y a un nombre impair de nœuds dans le cluster RAC.</block>
  <block id="6265611ca77e9ad52249c5fdd4780da9" category="admonition">Consultez la documentation Oracle sur « quorum failure group » pour obtenir des informations importantes sur l'utilisation de NFS dans une configuration RAC étendue. En résumé, il peut être nécessaire de modifier les options de montage NFS pour inclure l'option logicielle permettant de s'assurer que la perte de connectivité au troisième site hébergeant les ressources quorum n'affecte pas les serveurs Oracle ou les processus RAC Oracle principaux.</block>
  <block id="d84d0eea463e72a6e15018c70a45af46" category="doc">Oracle, MetroCluster et NVFAIL</block>
  <block id="ee6c613c07239c0923d940dfd448493f" category="paragraph">NVFAIL est une fonctionnalité d'intégrité générale des données d'ONTAP, particulièrement importante pour les charges de travail de la base de données.</block>
  <block id="9dc6a9986107298da2a22e7c5a3efb00" category="summary">Instance unique Oracle sur MetroCluster</block>
  <block id="f8b28e31633ae72c2971ee8b815ed4af" category="paragraph">Comme indiqué précédemment, la présence d'un système MetroCluster n'ajoute pas nécessairement aux meilleures pratiques d'exploitation d'une base de données ou ne les modifie pas nécessairement. La majorité des bases de données qui s'exécutent actuellement sur les systèmes MetroCluster client sont à instance unique et suivent les recommandations de la documentation Oracle sur ONTAP.</block>
  <block id="f4872c843923dd8d8731ef66462b5a99" category="paragraph">SyncMirror livre une copie synchrone des données au niveau du site de reprise d'activité. La mise à disposition des données requiert un système d'exploitation et les applications associées. L'automatisation de base peut considérablement améliorer le délai de basculement de l'environnement global. Les produits Clusterware tels que Veritas Cluster Server (VCS) sont souvent utilisés pour créer un cluster sur les sites et, dans la plupart des cas, le processus de basculement peut être piloté par des scripts simples.</block>
  <block id="c50820a41eb4f23d0a3acc1eeddb391b" category="paragraph">En cas de perte des nœuds principaux, le cluster (ou les scripts) est configuré de manière à mettre les bases de données en ligne sur le site secondaire. Une option consiste à créer des serveurs de secours préconfigurés pour les ressources NFS ou SAN qui constituent la base de données. En cas de défaillance du site principal, le logiciel de mise en cluster ou l'alternative scriptée effectue une séquence d'actions similaires à celles décrites ci-dessous :</block>
  <block id="2a6f458321ddf666cb0c876ee39255f3" category="list-text">Montage de systèmes de fichiers et/ou montage de groupes de disques ASM</block>
  <block id="3dee93bd9bc9b8b50dcdd2066a86009f" category="list-text">Démarrage de la base de données</block>
  <block id="620515885465a26daea6cc6441403e34" category="paragraph">Cette approche doit avant tout se passer d'un système d'exploitation en cours d'exécution sur le site distant. Elles doivent être préconfigurées avec des binaires Oracle, ce qui signifie également que des tâches telles que l'application de correctifs Oracle doivent être effectuées sur les sites principal et de secours. Les binaires Oracle peuvent également être mis en miroir vers le site distant et montés en cas d'incident.</block>
  <block id="edb5332feef69c0aa60ea10ed5d31a9f" category="list-text">Démarrage manuel des bases de données ou configuration des machines virtuelles pour démarrer automatiquement les bases de données par exemple, un cluster ESX peut couvrir des sites. En cas d'incident, les machines virtuelles peuvent être mises en ligne sur le site de reprise après incident après le basculement. Tant que les datastores hébergeant les serveurs de base de données virtualisés ne sont pas utilisés au moment de l'incident, il n'est pas nécessaire de les définir<block ref="3b93661df04b698b1340ff2da3238d16" prefix=" " category="inline-code"></block> sur les volumes associés.</block>
  <block id="6c2e01aca4f10a83d34e3f3046435e82" category="summary">SnapMirror et SyncMirror</block>
  <block id="64bba30b717cb45555458da4fed880a1" category="paragraph">Presque toutes les applications nécessitent une réplication des données.</block>
  <block id="25fb1fa02f326334533a22c105ad3e69" category="paragraph">Au niveau le plus élémentaire, la réplication peut signifier une copie sur bande stockée hors site ou une réplication au niveau des applications vers un emplacement de secours. La reprise après incident fait référence à l'utilisation de ces copies de réplica pour mettre un service en ligne en cas de perte catastrophique de service.</block>
  <block id="eab6cb3a1168ef2311865e6155b8272c" category="paragraph">ONTAP propose plusieurs options de réplication pour répondre de nombreuses exigences de manière native à l'intérieur de la baie de stockage et couvrir un large éventail de besoins. Ces options peuvent inclure une simple réplication des sauvegardes vers un site distant jusqu'à une solution synchrone et entièrement automatisée qui assure à la fois la reprise après incident et la haute disponibilité sur la même plateforme.</block>
  <block id="32df0c1cabf839652741a56bdaac7def" category="paragraph">Les principales technologies de réplication ONTAP applicables aux applications sont les technologies NetApp SnapMirror et NetApp SyncMirror. Il ne s'agit pas de produits complémentaires ; ils sont plutôt entièrement intégrés à ONTAP et sont activés par l'ajout simple d'une clé de licence. La réplication au niveau du stockage n'est pas la seule option non plus. La réplication au niveau des applications, comme avec Oracle DataGuard, peut également s'intégrer à une stratégie de protection des données basée sur ONTAP.</block>
  <block id="a2259fa074bae962e46ca7fc7aa31be1" category="paragraph">Le bon choix dépend des exigences spécifiques en matière de réplication, de restauration et de conservation.</block>
  <block id="0d3b37ff5855bf299f3c4a154373c1e2" category="section-title">SnapMirror ONTAP</block>
  <block id="296e89e943f5160d338484b3b705a44e" category="paragraph">SnapMirror est la solution de réplication asynchrone NetApp. Elle est idéale pour protéger des datasets volumineux, complexes et dynamiques, tels que les bases de données et les applications associées. Ses valeurs clés sont les suivantes :</block>
  <block id="d9f36dae2818ace926c4259271530724" category="list-text">*Gérabilité.* SnapMirror est facile à configurer et à gérer car il fait partie intégrante du logiciel de stockage. Aucun produit complémentaire n'est requis. Les relations de réplication peuvent être établies en quelques minutes et gérées directement sur le système de stockage.</block>
  <block id="8f761eff026903aa0140319f597d1fb0" category="list-text">*Simplicité.* la réplication est basée sur des volumes FlexVol, qui sont des conteneurs de LUN ou de fichiers répliqués comme un seul groupe cohérent.</block>
  <block id="8b737d6a9db3de6436966db508cb51d4" category="list-text">*Efficacité.* une fois la relation de réplication initiale établie, seuls les changements sont répliqués. De plus, des fonctionnalités d'efficacité comme la déduplication et la compression sont préservées. De plus, le volume de données à transférer vers un site distant est réduit.</block>
  <block id="0783dadb67ff77ed26bbfc5d80fa0cbd" category="list-text">*Flexibilité.* les miroirs peuvent être temporairement brisés pour permettre le test des procédures de reprise après sinistre, et ensuite la mise en miroir peut être facilement rétablie sans besoin d'une remise en miroir complète. Seules les données modifiées doivent être appliquées pour que les miroirs soient synchronisés. La mise en miroir peut également être inversée pour permettre une resynchronisation rapide après la fin de l'incident et la remise en service du site d'origine. Enfin, les clones en lecture-écriture des données répliquées sont disponibles à des fins de test et de développement.</block>
  <block id="8a00f09d8937e890f2cfb4d7acf72733" category="paragraph">ONTAP propose plusieurs technologies de réplication, mais la plus flexible est SnapMirror, une option de mise en miroir asynchrone volume à volume.</block>
  <block id="80c8fae3d0b5dd100cc984d9ba3eced7" category="paragraph">Comme mentionné précédemment, un volume FlexVol est l'unité de gestion de base des sauvegardes basées sur des copies Snapshot et des restaurations basées sur SnapRestore. Un volume FlexVol est également l'unité de base de la réplication basée sur SnapMirror. La première étape consiste à établir le miroir de base du volume source vers le volume de destination. Une fois cette relation miroir initialisée, toutes les opérations suivantes sont basées uniquement sur la réplication des données modifiées.</block>
  <block id="c1020b1755f65f23643158ce6a4d22cc" category="paragraph">Les valeurs clés de SnapMirror sont les suivantes du point de vue de la restauration :</block>
  <block id="50bde20b37cd4d57fbff2b95f2f8ec97" category="list-text">Les opérations SnapMirror sont simples à comprendre et peuvent être facilement automatisées.</block>
  <block id="66162be45733f65fee4abb22e989eb78" category="list-text">Une simple mise à jour d'un réplica SnapMirror nécessite la réplication de seules les modifications de delta, ce qui réduit les besoins en bande passante et permet des mises à jour plus fréquentes.</block>
  <block id="a3b4fbe416387a4991ccaa8b325a68be" category="list-text">SnapMirror est hautement granulaire. Elle repose sur de simples relations volume à volume, ce qui permet de créer des centaines de répliques gérées de manière indépendante et d'intervalles de réplication. La réplication n'a pas besoin d'être universelle.</block>
  <block id="4e3785883ef3ccad9938d7e35e493057" category="list-text">La direction de symétrie peut être facilement inversée tout en conservant la possibilité de mettre à jour la relation en fonction des modifications seules. Il est ainsi possible de restaurer rapidement le site principal après un incident, comme une panne de courant. Seules les modifications doivent être synchronisées à nouveau vers la source.</block>
  <block id="8b8325381cf528eff12c1e678a3112f9" category="list-text">Les miroirs peuvent être facilement brisés et efficacement resynchés pour permettre la répétition des procédures de reprise après sinistre.</block>
  <block id="b1f45b7d95bfc815351fb649fa94b671" category="list-text">Si SnapMirror fonctionne en mode de réplication complète au niveau des blocs, il réplique non seulement les données d'un volume, mais aussi les copies Snapshot. Cette fonctionnalité permet à la fois de copier les données et d'effectuer un jeu complet de sauvegardes sur le site de reprise après incident.</block>
  <block id="ffafd9ae31dee51209961eb2453ac806" category="paragraph">SnapMirror s'exécutant en mode flexible de la version permet la réplication de snapshots spécifiques, permettant des durées de conservation différentes au niveau des sites principal et secondaire.</block>
  <block id="974658d7ac018cb945e78365b0a760fb" category="section-title">SnapMirror synchrone</block>
  <block id="ffbf9d0ce29a631b6eae8b22c41ec95e" category="paragraph">SnapMirror synchrone (SM-S) est une amélioration apportée à SnapMirror qui fournit une réplication synchrone RPO=0. Elle est le plus souvent utilisée dans les architectures de stockage où seule une partie du volume total de données nécessite une mise en miroir synchrone.</block>
  <block id="e8a45c4c0391895df78421904703c933" category="paragraph">SM-S peut fonctionner dans deux modes légèrement différents, Sync et StrictSync.</block>
  <block id="15a4e16195fb9d30c5df0e11df5c2166" category="paragraph">En mode synchrone, les modifications sont répliquées avant d'être acquittées. Cela garantit un RPO de zéro, tant que la réplication est opérationnelle. Si la modification ne peut pas être répliquée, SM-S peut quitter le mode synchrone et permettre aux opérations de continuer. Cela permet à RPO=0 dans des circonstances normales, mais les processus de données ne s'arrêtent pas complètement si la destination de réplication n'est pas disponible.</block>
  <block id="115455025d4664c0dd6deaaf3c1fc93c" category="paragraph">StrictSync garantit un RPO=0. Si les modifications ne sont pas répliquées, le système génère une erreur d'E/S qui provoque généralement l'arrêt d'une application.</block>
  <block id="1b1ea0d1ad6e5cfb06253a14fcdcfe71" category="inline-link">TR-4733</block>
  <block id="9ccd61d6efc86cc37743fdff385832e8" category="paragraph">Pour une explication complète de SM-S, voir<block ref="4459b84726c651a8047a6486e87e48fb" category="inline-link-rx"></block> Et la documentation officielle de ONTAP. Des fonctionnalités sont ajoutées en permanence avec les nouvelles versions de ONTAP.</block>
  <block id="6165c4352e1504dbaeef34d0cc50c187" category="section-title">Groupes de cohérence</block>
  <block id="0651e813e385dbd62a9bca9baee23c6c" category="paragraph">ONTAP permet de créer des snapshots de groupes de cohérence. Depuis la version 9.13.1, ONTAP peut répliquer des groupes de volumes (n'oubliez pas qu'un volume dans la terminologie ONTAP n'est pas une LUN, il s'agit d'un conteneur de gestion constitué d'un ou plusieurs fichiers ou LUN) en tant que groupe cohérent.</block>
  <block id="80c6d3e933105ad9a2c104ec78444b8c" category="paragraph">La réplication SnapMirror et la relation SnapMirror de rupture au niveau du groupe de cohérence préservent la cohérence entre les volumes. De plus, les technologies SnapMirror synchrone et SnapMirror Business Continuity préservent la cohérence entre les volumes constitutifs.</block>
  <block id="455c7758003d6ebd974e8858f5ef1d7d" category="paragraph">Vous pouvez ainsi répliquer un jeu de données multi-volumes et vous assurer que tous les volumes sont cohérents. Cela permet notamment de réaliser des opérations de reprise après incident « rompez le miroir et Go » sans avoir besoin d'étapes supplémentaires pour la restauration d'applications ou de bases de données.</block>
  <block id="c44a2da164b7b770fce6338a987670ee" category="section-title">MetroCluster et SyncMirror</block>
  <block id="b1a1cfbf3988d8abdfdedaabc1742ae9" category="paragraph">MetroCluster est également une solution de réplication synchrone conçue pour les workloads stratégiques à grande échelle. La réplication est basée sur SyncMirror. Au niveau de la couche la plus simple, SyncMirror crée deux ensembles complets de données protégées par RAID à deux emplacements différents. Elles peuvent se trouver dans des pièces adjacentes au sein d'un data Center ou bien se trouver à plusieurs kilomètres de distance.</block>
  <block id="89b8adf28db7abb0febecafdca5871ad" category="paragraph">SyncMirror est totalement intégré à ONTAP et fonctionne juste au-dessus du niveau RAID. Par conséquent, toutes les fonctionnalités ONTAP habituelles, telles que les copies Snapshot, SnapRestore et NetApp FlexClone, fonctionnent de manière transparente. Il s'agit toujours d'une technologie ONTAP, qui inclut juste une couche supplémentaire de mise en miroir synchrone des données.</block>
  <block id="75c677fa68f5d15c17efbf6fd1fe1765" category="paragraph">Un ensemble de contrôleurs ONTAP gérant les données SyncMirror est appelé configuration NetApp MetroCluster. L'objectif principal de MetroCluster est de fournir un accès haute disponibilité aux données en miroir synchrones dans de nombreux scénarios de défaillance courants et de reprise après incident.</block>
  <block id="af845652f0234e1f71bc37e241ab63dc" category="paragraph">Les valeurs clés de la protection des données avec MetroCluster et SyncMirror sont les suivantes :</block>
  <block id="9ab80c5e33e343c3415c21be433c4447" category="list-text">Dans les opérations normales, SyncMirror fournit une mise en miroir synchrone garantie entre plusieurs sites. Une opération d'écriture n'est pas validée tant qu'elle n'est pas présente sur un support non volatile des deux sites.</block>
  <block id="680ccf94624c9f922ed236c8cc0c1af2" category="list-text">En cas de défaillance de la connectivité entre les sites, SyncMirror passe automatiquement en mode asynchrone pour que le site principal assure le service de données jusqu'à ce que la connectivité soit rétablie. Une fois restaurée, elle permet une resynchronisation rapide en mettant efficacement à jour les modifications qui se sont accumulées sur le site primaire. Une réinitialisation complète n'est pas nécessaire.</block>
  <block id="c18ec55908c635b68abe8c6edbf6476e" category="paragraph">SnapMirror est également entièrement compatible avec les systèmes basés sur SyncMirror. Par exemple, une base de données primaire peut s'exécuter sur un cluster MetroCluster réparti sur deux sites géographiques. Cette base de données peut également répliquer les sauvegardes sur un troisième site en tant qu'archives à long terme ou pour créer des clones dans un environnement DevOps.</block>
  <block id="0660b44d1a6d7e0d905c3fe28eef63ab" category="summary">Procédure de reprise après incident Oracle sur ONTAP avec envoi de journaux</block>
  <block id="54bae719e8fa53582d5b2781b4952c6b" category="doc">Reprise sur incident avec relecture du journal</block>
  <block id="3a8111f0b903472ec78531619bf984f6" category="paragraph">Les procédures de réplication pour une base de données Oracle sont essentiellement les mêmes que pour les procédures de sauvegarde. La principale exigence est que les snapshots qui constituent une sauvegarde récupérable doivent être répliqués sur le système de stockage distant.</block>
  <block id="c62b3abab4fdbaf8f0a84e8c3559b5fd" category="paragraph">Comme indiqué précédemment dans la documentation sur la protection des données locales, une sauvegarde récupérable peut être créée à l'aide du processus de sauvegarde à chaud ou à l'aide de sauvegardes optimisées pour les snapshots.</block>
  <block id="3d8f8c6a5c90bcd85a22fbd17390a864" category="inline-link-macro">Disposition des données</block>
  <block id="30394da99a39ca8264b8f7c0e6f679e0" category="paragraph">Il est donc primordial d'isoler les fichiers de données dans un ou plusieurs volumes dédiés. Ils doivent être non contaminés par tout autre type de fichier. La raison est de s'assurer que la réplication des fichiers de données est totalement indépendante de la réplication d'autres types de données tels que les journaux d'archivage. Pour plus d'informations sur les mises en page de fichiers et pour obtenir des détails importants sur la façon de s'assurer que la disposition du stockage est adaptée aux instantanés, reportez-vous à la section  <block ref="5a4fdf6a1fc411e544cf6d70d47a8289" category="inline-link-macro-rx"></block>.</block>
  <block id="f3f227cc5c07a040d61c36679053a58a" category="paragraph">Si les fichiers de données sont encapsulés dans des volumes dédiés, la question suivante est de savoir comment gérer les journaux de reprise, les journaux d'archivage et les fichiers de contrôle. La méthode la plus simple consiste à placer tous ces types de données dans un seul volume. L'avantage est que les journaux de reprise répliqués, les journaux d'archivage et les fichiers de contrôle sont parfaitement synchronisés. Il n'est pas nécessaire d'effectuer une restauration incomplète ou d'utiliser un fichier de contrôle de sauvegarde, bien qu'il soit également souhaitable de créer un script de fichiers de contrôle de sauvegarde pour d'autres scénarios de récupération potentiels.</block>
  <block id="927992cbeccc8211e382c97e81514ef9" category="section-title">Disposition à deux volumes</block>
  <block id="fe1cf96940a710dc95fd30bbb7533b52" category="paragraph">La disposition la plus simple est illustrée dans la figure suivante.</block>
  <block id="57f1db4bdf2ce49a98f375d8393f02bf" category="paragraph">C'est l'approche la plus courante. Du point de vue de l'administrateur de bases de données, il peut sembler inhabituel de colocaliser toutes les copies des journaux de reprise et d'archivage sur le même volume. Toutefois, la séparation n'offre pas une protection supplémentaire importante si les fichiers et les LUN se trouvent toujours sur le même jeu de disques sous-jacent.</block>
  <block id="bc46e4831ef5654d084e456c4c544a42" category="section-title">Disposition à trois volumes</block>
  <block id="f6e969769d9d166122489505d676769b" category="paragraph">Il peut arriver qu'une séparation des journaux de reprise soit nécessaire en raison de problèmes de protection des données ou de la nécessité de distribuer les E/S des journaux de reprise entre les contrôleurs. Si c'est le cas, la disposition à trois volumes décrite dans la figure ci-dessous est utilisée pour la réplication, tout en évitant toute nécessité d'effectuer une restauration incomplète ou de s'appuyer sur des fichiers de contrôle de sauvegarde.</block>
  <block id="4957c2feaa2cb72d80a0ab65228ad43f" category="paragraph">Cela permet d'entrelacer les journaux de reprise et les fichiers de contrôle sur des ensembles indépendants de piles de disques et de contrôleurs de la source. Toutefois, les journaux d'archivage et un ensemble de fichiers de contrôle et de fichiers de reprise peuvent toujours être répliqués dans un état synchronisé avec les journaux d'archivage.</block>
  <block id="39128da64bc55500b4b11391aa54a011" category="paragraph">Dans ce modèle, le volume Redo Log B n'est pas répliqué.</block>
  <block id="c0ce858e99375deac8274c96b7e5d0ee" category="section-title">Procédure de reprise d'activité : sauvegardes à chaud</block>
  <block id="6993729228512b7e23e3ff3ec9099f33" category="paragraph">Pour effectuer une reprise sur incident à l'aide de sauvegardes à chaud, utilisez la procédure de base suivante :</block>
  <block id="ee68e5b99222bbc29a480fcb0d1d6ee2" category="section-title">Prérequis</block>
  <block id="41bde9c586a860264c425700c48bd375" category="list-text">Les binaires Oracle sont installés sur le serveur de reprise après incident.</block>
  <block id="cebf7cec81152da2cadffd580d81937f" category="list-text">Les instances de base de données sont répertoriées dans le<block ref="2c0b0433aa1c96a2be6f40d9e71bc6af" prefix=" " category="inline-code"></block>.</block>
  <block id="17f8e5eda67237f2ca94c7dcce3e4022" category="list-text">Le<block ref="76a2173be6393254e72ffa4d6df1030a" prefix=" " category="inline-code"></block> et<block ref="6b2f852f7f63f2e5d4be597bbca97bb6" prefix=" " category="inline-code"></block> ou<block ref="1737629d60b511cf45957529a8f046e2" prefix=" " category="inline-code"></block> pour l'instance doit être dans le<block ref="45c7302d9c2e8745b3a2bff0f992b6df" prefix=" " category="inline-code"></block> répertoire. .</block>
  <block id="645a84975202e30700b572b49a5ee29d" category="section-title">Reprise après incident</block>
  <block id="25d18766964d7515e1f5acd893094f6e" category="list-text">Brisez les miroirs des fichiers de données et du volume de journaux commun.</block>
  <block id="8fc655e4752d521563db3bfa138ba62e" category="list-text">Restaurez le ou les volumes de fichiers de données sur le snapshot de sauvegarde à chaud le plus récent des fichiers de données.</block>
  <block id="68a9c75816a16f6d4f7572fe287961bf" category="list-text">Si SAN est utilisé, activez les groupes de volumes et/ou montez les systèmes de fichiers.</block>
  <block id="312007510a0f0dc7878d4ed6a7a01554" category="list-text">Réexécutez les journaux d'archivage au point souhaité.</block>
  <block id="e54b793d8bfa83bbb1bd965992c3474e" category="list-text">Relire les journaux de reprise en cours si vous souhaitez effectuer une restauration complète.</block>
  <block id="72e5734d53581f86093de5c97d8a3a24" category="paragraph">NFS simplifie considérablement la procédure. En effet, les systèmes de fichiers NFS pour les fichiers de données et les fichiers journaux peuvent à tout moment être montés sur le serveur de reprise après incident. Il devient en lecture/écriture lorsque les miroirs sont cassés.</block>
  <block id="de4735bc5bbfdcae3d690313c739ad67" category="section-title">Procédure de reprise après incident : sauvegardes optimisées pour les snapshots</block>
  <block id="6b2b8ef11e5ded8a083372ba49d488d2" category="paragraph">La restauration à partir de sauvegardes optimisées pour les snapshots est presque identique à la procédure de restauration à chaud avec les modifications suivantes :</block>
  <block id="af1e49e7bc2b25ce36bd93df09433fb4" category="list-text">Restaurez le(s) volume(s) de fichiers de données sur un snapshot créé avant le réplica actuel du volume de journaux.</block>
  <block id="5e09669c98226c5d3a748f7e0f0333ad" category="paragraph">Ces différences simplifient la procédure globale de restauration, car il n'est pas nécessaire de s'assurer qu'un snapshot a été correctement créé sur la source pendant que la base de données était en mode de sauvegarde à chaud. La procédure de reprise d'activité est basée sur l'horodatage des snapshots sur le site de reprise d'activité. L'état de la base de données au moment de la création des snapshots n'est pas important.</block>
  <block id="81d6beef7eaf28bbce692d4b59888f3e" category="section-title">Reprise d'activité avec des snapshots de sauvegarde à chaud</block>
  <block id="dc711b77f0d6a9c9ccf88b424509440a" category="paragraph">Voici un exemple de stratégie de reprise d'activité basée sur la réplication de snapshots de sauvegarde à chaud. Il sert également d'exemple de stratégie de sauvegarde locale simple et évolutive.</block>
  <block id="edaef18e1c956b9284405fd664c4ca4a" category="paragraph">La base de données exemple se trouve sur une architecture de base à deux volumes.<block ref="f006bf17b06c884c47190c4225d3215a" prefix=" " category="inline-code"></block> contient les fichiers de données et<block ref="894db1fc1592356880976f1b92c3e6a2" prefix=" " category="inline-code"></block> est utilisé pour les journaux de reprise, les journaux d'archivage et les fichiers de contrôle combinés.</block>
  <block id="fc0e7b6cd7cd15929987b1429d1c3a7e" category="paragraph">Deux calendriers sont requis : un pour les sauvegardes de fichiers de données nocturnes et un pour les sauvegardes de fichiers journaux. Ils sont appelés minuit et 15 minutes, respectivement.</block>
  <block id="44c0956347a70c78d2124c1041321049" category="paragraph">Ces planifications sont ensuite utilisées au sein des politiques de snapshots<block ref="44dc83cda2d6b3ce99cc25803e824061" prefix=" " category="inline-code"></block> et<block ref="9b055600529d69c4ae0d2a9408dc7aa3" prefix=" " category="inline-code"></block>, comme illustré ci-dessous :</block>
  <block id="180e86b8e3c5049779c98c2c1006bb15" category="paragraph">Enfin, ces politiques de snapshots sont appliquées aux volumes.</block>
  <block id="2887f2c14c7efbc97d53ac2f914c5657" category="paragraph">Ceci définit la planification de sauvegarde des volumes. Des snapshots des fichiers de données sont créés à minuit et conservés pendant 60 jours. Le volume du journal contient 72 instantanés créés toutes les 15 minutes, ce qui représente jusqu'à 18 heures de couverture.</block>
  <block id="e1e5ef0e7100311d950b4ffebe040670" category="paragraph">Ensuite, assurez-vous que la base de données est en mode de sauvegarde à chaud lors de la création d'un Snapshot de fichier de données. Ceci s'effectue avec un petit script qui accepte certains arguments de base qui démarrent et arrêtent le mode de sauvegarde sur le SID spécifié.</block>
  <block id="683cdd7abd993faf3ace355cd6870b6f" category="paragraph">Cette étape permet de s'assurer que la base de données est en mode de sauvegarde à chaud pendant une fenêtre de quatre minutes entourant le snapshot de minuit.</block>
  <block id="ccff7eb3ad0059a184886709c87f4889" category="paragraph">La réplication vers le site de reprise sur incident est configurée comme suit :</block>
  <block id="42d3752a745fb0cdae528f6cc425b569" category="paragraph">La destination du volume du journal est mise à jour toutes les 15 minutes. Le RPO est ainsi d'environ 15 minutes. L'intervalle de mise à jour précis varie légèrement en fonction du volume total de données à transférer pendant la mise à jour.</block>
  <block id="e272424001d72919ad498e0e9d3c2cc4" category="paragraph">La destination du volume de fichiers de données est mise à jour toutes les six heures. Cela n'affecte pas le RPO ni le RTO. Si une reprise sur incident est nécessaire, l'une des premières étapes consiste à restaurer le volume du fichier de données vers un Snapshot de sauvegarde à chaud. L'objectif de l'intervalle de mise à jour plus fréquent est de lisser la vitesse de transfert de ce volume. Si la mise à jour est planifiée une fois par jour, toutes les modifications accumulées au cours de la journée doivent être transférées en une seule fois. Avec des mises à jour plus fréquentes, les modifications sont répliquées plus progressivement tout au long de la journée.</block>
  <block id="ce176ff569d716c1fa73d0754aba684b" category="paragraph">En cas d'incident, la première étape consiste à briser les miroirs des deux volumes :</block>
  <block id="4b9cdb6e2096c0828aeccd2ee5eecf42" category="paragraph">Les répliques sont maintenant en lecture-écriture. L'étape suivante consiste à vérifier l'horodatage du volume du journal.</block>
  <block id="b4d461e48f5be5d08f677045d11e8200" category="paragraph">La copie la plus récente du volume de log est le 14 mars à 13:30:00.</block>
  <block id="96f75a4b63f4377efdf64d571d71caec" category="paragraph">Ensuite, identifiez le snapshot de sauvegarde à chaud créé juste avant l'état du volume de journal. Ceci est nécessaire car le processus de relecture des journaux nécessite la création de tous les journaux d'archivage en mode de sauvegarde à chaud. La réplique du volume du journal doit donc être plus ancienne que les images de sauvegarde à chaud ou ne doit pas contenir les journaux requis.</block>
  <block id="d358e4eb10a2f4e0b591e16941d7782c" category="paragraph">Le snapshot le plus récent est<block ref="c001e27abf0e66d13790bb8a7e00da54" prefix=" " category="inline-code"></block>. Il s'agit de l'image de sauvegarde à chaud la plus récente des fichiers de données. Cette image est ensuite restaurée comme suit :</block>
  <block id="d2037035a976c9be71cf6f372300c8c3" category="paragraph">À ce stade, la base de données est prête à être récupérée. S'il s'agissait d'un environnement SAN, l'étape suivante inclurait l'activation des groupes de volumes et le montage de systèmes de fichiers, un processus facilement automatisé. Dans la mesure où cet exemple utilise NFS, les systèmes de fichiers sont déjà montés et sont devenus des opérations de lecture-écriture sans avoir à monter ou activer les miroirs au moment où ils ont été rompus.</block>
  <block id="2edce22eade45b42bc6b2665057fa082" category="paragraph">La base de données peut désormais être restaurée au point dans le temps souhaité ou entièrement récupérée grâce à la copie des journaux de reprise répliqués. Cet exemple illustre la valeur du journal d'archives, du fichier de contrôle et du volume redo log combinés. Le processus de restauration est beaucoup plus simple, car il n'est pas nécessaire de se fier aux fichiers de contrôle de sauvegarde ou de réinitialiser les fichiers journaux.</block>
  <block id="51f74a82c7125b3b288755b6668091b1" category="section-title">Reprise d'activité avec sauvegardes optimisées pour les snapshots</block>
  <block id="3680a4757ddad43934237ab6a0ca955c" category="paragraph">La procédure de reprise sur incident utilisant des sauvegardes optimisées pour les snapshots est presque identique à la procédure de reprise sur incident de sauvegarde à chaud. Comme pour la procédure Snapshot de sauvegarde à chaud, il s'agit essentiellement d'une extension d'architecture de sauvegarde locale dans laquelle les sauvegardes sont répliquées pour être utilisées dans la reprise après incident. L'exemple suivant illustre la configuration détaillée et la procédure de restauration. Cet exemple met également en évidence les principales différences entre les sauvegardes à chaud et les sauvegardes optimisées pour les snapshots.</block>
  <block id="330dadae5e2585726f41ed1f90e88f9f" category="paragraph">La base de données exemple se trouve sur une architecture de base à deux volumes.<block ref="f006bf17b06c884c47190c4225d3215a" prefix=" " category="inline-code"></block> contient les fichiers de données, et<block ref="894db1fc1592356880976f1b92c3e6a2" prefix=" " category="inline-code"></block> est utilisé pour les journaux de reprise, les journaux d'archivage et les fichiers de contrôle combinés.</block>
  <block id="1669f47e046ce7e069e9d143f42e025d" category="paragraph">Deux calendriers sont requis : un pour les sauvegardes de fichiers de données nocturnes et un pour les sauvegardes de fichiers journaux. Ils sont appelés minuit et 15 minutes, respectivement.</block>
  <block id="ef4adcab3e9bd572d0670f9f2073c311" category="paragraph">Ceci contrôle le programme de sauvegarde ultime des volumes. Les snapshots sont créés à minuit et conservés pendant 60 jours. Le volume du journal contient 72 instantanés créés toutes les 15 minutes, ce qui représente jusqu'à 18 heures de couverture.</block>
  <block id="f9d5149b630a43ff5996adc26c6e1f08" category="paragraph">La destination du volume du journal est mise à jour toutes les 15 minutes. Le RPO est ainsi d'environ 15 minutes, l'intervalle de mise à jour précis variant légèrement selon le volume total de données à transférer pendant la mise à jour.</block>
  <block id="992398ebd9e9f825f0aa4415519abdba" category="paragraph">La destination du volume de fichiers de données est mise à jour toutes les 6 heures. Cela n'affecte pas le RPO ni le RTO. Si une reprise sur incident est nécessaire, vous devez d'abord restaurer le volume du fichier de données sur un snapshot de sauvegarde à chaud. L'objectif de l'intervalle de mise à jour plus fréquent est de lisser la vitesse de transfert de ce volume. Si la mise à jour a été planifiée une fois par jour, toutes les modifications accumulées au cours de la journée doivent être transférées en une seule fois. Avec des mises à jour plus fréquentes, les modifications sont répliquées plus progressivement tout au long de la journée.</block>
  <block id="9e85b8590ac2f9ff5ebc8d1def51ae82" category="paragraph">En cas d'incident, la première étape consiste à briser les miroirs de tous les volumes :</block>
  <block id="fd2834dcadb39f00eb897fdcdc07a03d" category="paragraph">La copie la plus récente du volume de log est le 14 mars à 13:30. Ensuite, identifiez le snapshot du fichier de données créé immédiatement avant l'état du volume de journaux. Ceci est nécessaire car le processus de relecture des journaux requiert tous les journaux d'archivage juste avant le snapshot et jusqu'au point de restauration souhaité.</block>
  <block id="810e47566b9cd5aa3b28e6514ec95735" category="paragraph">Le snapshot le plus récent est<block ref="c001e27abf0e66d13790bb8a7e00da54" prefix=" " category="inline-code"></block>. Restaurer cet instantané.</block>
  <block id="87d83a0406ac6622efcdf91c42784ecd" category="paragraph">La base de données est maintenant prête à être récupérée. S'il s'agissait d'un environnement SAN, vous activeriez alors des groupes de volumes et monterait des systèmes de fichiers, ce qui facilite l'automatisation. Cependant, cet exemple utilise NFS, de sorte que les systèmes de fichiers sont déjà montés et sont devenus lecture-écriture sans avoir besoin de monter ou d'activer le moment où les miroirs ont été rompus.</block>
  <block id="7a2e97f17454be76b7e522ce612ff961" category="paragraph">La base de données peut désormais être restaurée au point dans le temps souhaité ou entièrement récupérée grâce à la copie des journaux de reprise répliqués. Cet exemple illustre la valeur du journal d'archives, du fichier de contrôle et du volume redo log combinés. Le processus de restauration est beaucoup plus simple, car il n'est pas nécessaire de se fier aux fichiers de contrôle de sauvegarde ou de réinitialiser les fichiers journaux.</block>
  <block id="d6597945276340ba33115e737eb4b489" category="summary">Réplication de groupe de cohérence pour les bases de données Oracle</block>
  <block id="fc506ae4ea109f50758acc176bcb5341" category="doc">Reprise d'activité par groupe de cohérence</block>
  <block id="5eda890cc07e4b7cd409730d8af8ddc3" category="paragraph">La réplication de groupe de cohérence peut être aussi simple que la planification de la réplication d'un volume unique via SnapMirror. Notamment les fichiers de données, les fichiers de contrôle, les journaux d'archivage et les journaux de reprise. Chaque mise à jour SnapMirror produit une nouvelle copie cohérente de la base de données sur le site de destination, prête pour l'activation en brisant le miroir.</block>
  <block id="89cb1432594ce7c25dadf229401874e7" category="paragraph">Si une base de données doit couvrir plusieurs volumes, un Snapshot de groupe de cohérence (cg-snapshot) est nécessaire.</block>
  <block id="f96b125d1bacc785389957041be148e9" category="paragraph">Autre avantage de cette stratégie lorsqu'elle est utilisée avec SnapMirror en mode de réplication de niveau bloc : la réplication complète de tous les snapshots sur le système de stockage source. La gamme complète de sauvegardes est répliquée en plus de la copie de reprise après incident.</block>
  <block id="77fda44088666155052f9d4224878cbc" category="summary">Tiering des journaux d'archivage Oracle</block>
  <block id="113d9dffdeb8fa14877fc8cf8ca7c9d5" category="doc">Tiering des journaux Oracle</block>
  <block id="8625af69ad0b5f76799d87df777e3c86" category="paragraph">L'utilisation la plus importante pour FabricPool est peut-être l'amélioration de l'efficacité des données inactives connues, telles que les journaux de transactions de base de données.</block>
  <block id="a98d546484d238b37b7e2584ae8d399d" category="summary">Tiering de sauvegarde Oracle</block>
  <block id="9f409a250e4be99904c9e90259cb747d" category="paragraph">Les sauvegardes d'applications traditionnelles incluent des produits tels qu'Oracle Recovery Manager, qui créent des sauvegardes basées sur des fichiers en dehors de l'emplacement de la base de données d'origine.</block>
  <block id="6cddb309df5eb8791dc990f72ef2deb2" category="summary">Règles de Tiering Oracle</block>
  <block id="7ba3322dbc0b3c33a66f1963e80b7a2a" category="doc">Règles de Tiering des bases de données Oracle</block>
  <block id="4627801bdbb24a1991e64f30a2d80cb1" category="paragraph">Quatre règles sont disponibles dans ONTAP, qui contrôlent la façon dont les données Oracle du niveau de performance deviennent candidates à la relocalisation vers le niveau de capacité.</block>
  <block id="47f6817eca23122cc683f7c2759e6ecb" category="summary">Tiering complet avec mosaïque Oracle</block>
  <block id="1def0ac22a738b54cce584e969065918" category="doc">Tiering complet de fichiers Oracle</block>
  <block id="2eea2725f31529888b5e57b36492819f" category="paragraph">Bien que le Tiering FabricPool fonctionne au niveau des blocs, il peut dans certains cas servir à fournir un Tiering au niveau des fichiers.</block>
  <block id="468853d9ed2134af17ede5fd165a8dff" category="summary">Tiering partiel de fichiers avec FabricPool</block>
  <block id="5638b2f30ee966b3ff84bac350092971" category="doc">Tiering partiel de fichiers Oracle</block>
  <block id="f935a501eae76f9c13d430bc3879cd0d" category="paragraph">Comme FabricPool fonctionne au niveau des blocs, les fichiers susceptibles d'être modifiés peuvent être partiellement hiérarchisés vers un stockage objet tout en restant partiellement sur le Tier de performance.</block>
  <block id="dd22ff2cf158f98efbd92f4522b3064b" category="summary">Accès à la base de données pendant les interruptions d'accès au magasin d'objets</block>
  <block id="cc4e17c26faf6b70b383529b6215ba0f" category="doc">Interruptions d'accès au magasin d'objets</block>
  <block id="bbb21240a2cc48eb7a229ec824e70cdf" category="summary">Présentation du Tiering pour Oracle avec FabricPool</block>
  <block id="ec2ffb259f21d115e5481eb0f215aa0d" category="doc">Présentation du Tiering Oracle</block>
  <block id="ec35a176f3e7c086273baee0c7f374d5" category="paragraph">Pour comprendre l'impact du Tiering FabricPool sur Oracle et d'autres bases de données, il est nécessaire de connaître l'architecture FabricPool de bas niveau.</block>
  <block id="cd6b77e4d343896571bc445479f24588" category="summary">Règles de récupération de hiérarchisation du PRacle</block>
  <block id="3bf6f5a455b1889775d79713ad4e19ed" category="doc">Stratégies de récupération</block>
  <block id="6edf1821ddc55278229c2156f42905f0" category="paragraph">Les règles de Tiering contrôlent quels blocs de base de données Oracle sont hiérarchisés du niveau de performance au niveau de capacité. Les règles de récupération contrôlent ce qui se passe lorsqu'un bloc qui a été hiérarchisé est lu.</block>
  <block id="95ab96ac5aaeae15f7b499d0fa0313cf" category="summary">Tiering Snapshot Oracle</block>
  <block id="d01cbb2be77343ccdb1d3372c4b9891e" category="summary">Instructions relatives au dimensionnement des LUN de la base de données Oracle et au nombre de LUN</block>
  <block id="b9e88e2eb3d5eef807fc42db706d866a" category="doc">Dimensionnement des LUN Oracle et nombre de LUN</block>
  <block id="51f96d1f8b50084e3a2ddc21ceef8b2f" category="paragraph">Il est essentiel de sélectionner la taille de LUN optimale et le nombre de LUN à utiliser pour optimiser les performances et la gestion des bases de données Oracle.</block>
  <block id="3d1bd23e74923cdc48fe992d0687809f" category="summary">Bases de données Oracle et locations et verrouillages NFS</block>
  <block id="472f36eb81330c2c27f02245ce8a911e" category="doc">Locations et verrouillages NFS - Oracle</block>
  <block id="cec6f8a988408ba212798e1cc32658c7" category="paragraph">NFSv3 est sans état. Cela signifie que le serveur NFS (ONTAP) ne suit pas les systèmes de fichiers montés, par qui ou quels verrous sont réellement en place.</block>
  <block id="7c96331bd03e63c4eb3505c526b42244" category="paragraph">ONTAP dispose de certaines fonctionnalités qui enregistreront les tentatives de montage. Vous savez donc quels clients accèdent aux données et il se peut que des verrous consultatifs soient présents, mais les informations ne sont pas 100 % complètes. Elle ne peut pas être terminée, car le suivi de l'état du client NFS ne fait pas partie de la norme NFSv3.</block>
  <block id="20733ad7135aa0ede95fd8637fe05cf6" category="section-title">État NFSv4</block>
  <block id="3f7c11f662fc6e07a91179fdf2322ef5" category="paragraph">En revanche, NFSv4 est avec état. Le serveur NFSv4 suit les clients qui utilisent les systèmes de fichiers, les fichiers existants, les fichiers et/ou les régions de fichiers verrouillés, etc Cela signifie qu'une communication régulière entre un serveur NFSv4 doit être établie pour maintenir les données d'état à jour.</block>
  <block id="6f7e4a1e570f45fa3db0b8a0ed80a38f" category="paragraph">Les États les plus importants gérés par le serveur NFS sont les verrous NFSv4 et les locations NFSv4, qui sont très étroitement liés. Vous devez comprendre comment chacun fonctionne par lui-même, et comment ils se rapportent les uns aux autres.</block>
  <block id="0d55fd4062f29237d0fb3b7f666fb8eb" category="section-title">Verrous NFSv4</block>
  <block id="bf4139ff42e411ae5483e062387b3f70" category="paragraph">Avec NFSv3, les verrous sont consultatifs. Un client NFS peut toujours modifier ou supprimer un fichier « verrouillé ». Un verrou NFSv3 n'expire pas de lui-même, il doit être supprimé. Cela crée des problèmes. Par exemple, si une application en cluster crée des verrous NFSv3 et que l'un des nœuds tombe en panne, que faire ? Vous pouvez coder l'application sur les nœuds survivants pour supprimer les verrous, mais comment savoir que c'est sûr ? Le nœud « en panne » est peut-être opérationnel, mais ne communique pas avec le reste du cluster ?</block>
  <block id="11d1c33ac6b190a233c00cdbdd6a355b" category="paragraph">Avec NFSv4, les verrous ont une durée limitée. Tant que le client tenant les Locks continue à s'archiver avec le serveur NFSv4, aucun autre client n'est autorisé à acquérir ces Locks. Si un client ne parvient pas à s'archiver avec NFSv4, les verrous seront éventuellement révoqués par le serveur et d'autres clients pourront demander et obtenir des verrous.</block>
  <block id="c17985911e0182dc5e96c4d60aadf139" category="section-title">Locations NFSv4</block>
  <block id="596bcfef3aaccfe299bb45a969afcaf0" category="paragraph">Les verrous NFSv4 sont associés à un bail NFSv4. Lorsqu'un client NFSv4 établit une connexion avec un serveur NFSv4, il obtient un bail. Si le client obtient un verrou (il existe plusieurs types de verrous), le verrou est associé au bail.</block>
  <block id="b5248856b1835e14738aa32e053e30e0" category="paragraph">Ce bail a un délai défini. Par défaut, ONTAP définit la valeur de temporisation sur 30 secondes :</block>
  <block id="7e2a66190f452806ac1183721a43eaa1" category="paragraph">Cela signifie qu'un client NFSv4 doit vérifier avec le serveur NFSv4 toutes les 30 secondes pour renouveler ses baux.</block>
  <block id="809c552ae0a4d377e87f495b4e3ac62b" category="paragraph">Le bail est automatiquement renouvelé par n'importe quelle activité. Ainsi, si le client effectue des travaux, il n'est pas nécessaire d'effectuer des opérations supplémentaires. Si une application devient silencieuse et ne fait pas de véritable travail, elle devra effectuer une sorte d'opération de maintien en vie (appelée SÉQUENCE). Il s'agit essentiellement de dire « Je suis toujours là, veuillez actualiser mes contrats de location ».</block>
  <block id="70cb78bb7e91dcafab559f9b72e40bb6" category="paragraph">NFSv3 est sans état. Il ne s'attend pas à ce que les clients communiquent. NFSv4 est avec état et une fois la période de location expirée, le bail expire, et les verrous sont révoqués et les fichiers verrouillés sont mis à disposition des autres clients.</block>
  <block id="2ee5d81cfa6306ae71ce534ed9b31431" category="paragraph">Avec NFSv3, vous pouvez déplacer les câbles réseau, redémarrer les switchs réseau, modifier la configuration et être sûr qu'aucun problème ne se produirait. En général, les applications attendront patiemment le bon fonctionnement de la connexion réseau.</block>
  <block id="8900ff182e4197f8eb2acd7d2b7fd902" category="paragraph">Avec NFSv4, vous disposez de 30 secondes (sauf si vous avez augmenté la valeur de ce paramètre dans ONTAP) pour terminer votre travail. Si vous dépassez cette limite, vos contrats de location sont échus. Normalement, cela provoque des pannes d'application.</block>
  <block id="ffa8c7744b3e2d43b18c67aec0fe7743" category="paragraph">Par exemple, si vous disposez d'une base de données Oracle et que vous rencontrez une perte de connectivité réseau (parfois appelée « partition réseau ») qui dépasse le délai d'expiration du bail, vous plantez la base de données.</block>
  <block id="33b9897348039594b4b17bf1e1629c74" category="paragraph">Voici un exemple de ce qui se passe dans le journal des alertes Oracle si cela se produit :</block>
  <block id="85608585bf8e790a579c49ba9af705c6" category="paragraph">Si vous examinez les syslog, vous devriez voir plusieurs de ces erreurs :</block>
  <block id="e19b338de53dada4cf4da3837aaba76d" category="paragraph">Les messages du journal sont généralement le premier signe d'un problème, autre que le blocage de l'application. En général, vous ne voyez rien pendant la panne réseau, car les processus et le système d'exploitation lui-même sont bloqués et tentent d'accéder au système de fichiers NFS.</block>
  <block id="7a3c8c17a9dd10fa565f79e0ebb5bba7" category="paragraph">Les erreurs apparaissent une fois que le réseau est de nouveau opérationnel. Dans l'exemple ci-dessus, une fois la connectivité rétablie, le système d'exploitation a tenté de réacquérir les verrous, mais il était trop tard. Le bail avait expiré et les serrures ont été retirées. Cela entraîne une erreur qui se propage jusqu'à la couche Oracle et provoque le message dans le journal des alertes. Vous pouvez voir des variations sur ces modèles en fonction de la version et de la configuration de la base de données.</block>
  <block id="4bec5e793e34a5819aefb68e4f65db26" category="paragraph">En résumé, NFSv3 tolère l'interruption du réseau, mais NFSv4 est plus sensible et impose une période de location définie.</block>
  <block id="069de2d717910b2677190b9a9b5ed1cf" category="paragraph">Que se passe-t-il si un délai de 30 secondes n'est pas acceptable ? Que se passe-t-il si vous gérez un réseau changeant de façon dynamique où les commutateurs sont redémarrés ou les câbles sont déplacés et que le résultat est une interruption occasionnelle du réseau ? Vous pouvez choisir de prolonger la période de location, mais pour savoir si vous voulez y parvenir, vous devez expliquer les périodes de grâce NFSv4.</block>
  <block id="4b84416146795544deb5c9de89187f91" category="section-title">Périodes de grâce NFSv4</block>
  <block id="7d98e091c5f7be92cd5fb85b985d8d20" category="paragraph">Lorsqu'un serveur NFSv3 est redémarré, il est prêt à transmettre les E/S presque instantanément. Il ne maintenait aucune sorte d'état concernant les clients. Le résultat est qu'une opération de basculement ONTAP semble souvent proche de l'instantané. Dès qu'un contrôleur est prêt à commencer à transmettre des données, il envoie un ARP au réseau qui signale le changement de topologie. En règle générale, les clients le détectent presque instantanément et le flux des données reprend.</block>
  <block id="173d4fd05086441236dbee4710639d10" category="paragraph">NFSv4, cependant, fera une courte pause. Cela fait partie du fonctionnement de NFSv4.</block>
  <block id="21483115213b27583a07dc2ca994671c" category="paragraph">Les serveurs NFSv4 doivent suivre les baux, les verrous et les utilisateurs des données. Si un serveur NFS fonctionne de manière incohérente et redémarre, ou perd de l'alimentation pendant un moment, ou est redémarré pendant l'activité de maintenance, le résultat est le bail/verrouillage et d'autres informations client sont perdues. Le serveur doit déterminer quel client utilise les données avant de reprendre les opérations. C'est là que intervient le délai de grâce.</block>
  <block id="09b6f386094bd895d3c9694f28bfdf65" category="paragraph">Si vous mettez soudainement votre serveur NFSv4 hors/sous tension. Lorsqu'il est rétabli, les clients qui tentent de reprendre l'E/S reçoivent une réponse qui dit essentiellement « J'ai perdu les informations de location/verrouillage. Voulez-vous réenregistrer vos verrous ? » C'est le début de la période de grâce. La valeur par défaut est 45 secondes sur ONTAP :</block>
  <block id="e4f8aa90af36d76254e2f02e56232aed" category="paragraph">Par conséquent, après un redémarrage, un contrôleur met en pause les E/S tandis que tous les clients récupèrent leurs baux et verrous. Une fois le délai de grâce terminé, le serveur reprend les opérations d'E/S.</block>
  <block id="bb2b26fdcb4e947cda6f8e38724ecfc9" category="section-title">Délais de location par rapport aux délais de grâce</block>
  <block id="563494d7f0f6ebcb6698cac7f9705aaa" category="paragraph">Le délai de grâce et la période de location sont connectés. Comme mentionné ci-dessus, le délai de bail par défaut est de 30 secondes, ce qui signifie que les clients NFSv4 doivent s'enregistrer auprès du serveur au moins toutes les 30 secondes, sinon ils perdent leur bail et, à leur tour, leurs verrous. Le délai de grâce existe pour permettre à un serveur NFS de reconstruire les données de bail/verrouillage, et il prend par défaut 45 secondes. ONTAP exige que le délai de grâce soit supérieur de 15 secondes à la période de location. Cela permet de s'assurer qu'un environnement client NFS conçu pour renouveler les contrats de location au moins toutes les 30 secondes aura la possibilité d'archiver avec le serveur après un redémarrage. Un délai de grâce de 45 secondes garantit que tous les clients qui s'attendent à renouveler leur contrat de location au moins toutes les 30 secondes ont certainement l'occasion de le faire.</block>
  <block id="5e6b60906bbbb9a41b140c0749591489" category="paragraph">Si un délai de 30 secondes n'est pas acceptable, vous pouvez choisir de prolonger la période de location. Si vous souhaitez augmenter le délai de bail à 60 secondes pour résister à une panne de réseau de 60 secondes, vous devrez augmenter le délai de grâce à au moins 75 secondes. ONTAP exige qu'il soit supérieur de 15 secondes à la période de location. Une pause d'E/S plus longue sera donc nécessaire lors du basculement du contrôleur.</block>
  <block id="4611c7c931fc15a6feba513fe72e22de" category="paragraph">Ce ne devrait normalement pas être un problème. En général, les utilisateurs ne mettent à jour les contrôleurs ONTAP qu'une ou deux fois par an. En outre, les basculements non planifiés en raison de défaillances matérielles sont extrêmement rares. En outre, si vous aviez un réseau où une panne réseau de 60 secondes était possible, et que le délai de bail était de 60 secondes, vous n'auriez probablement pas à vous opposer à un basculement rare du système de stockage, ce qui aurait entraîné une pause de 75 secondes non plus. Vous avez déjà reconnu que vous disposez d'un réseau qui s'arrête pendant plus de 60 secondes plutôt fréquemment.</block>
  <block id="c4fb6f7d31d205bc07dbff47d0ae4bb3" category="summary">NFS direct Oracle</block>
  <block id="f58bdad9659176e411f064fdb414233f" category="doc">Directement sur Oracle NFS</block>
  <block id="1bd6ec1185ba67395dc6f9cd2b458ec8" category="paragraph">Les bases de données Oracle peuvent utiliser NFS de deux manières.</block>
  <block id="96997ca5c577dd19a3ba5f7ff771f27a" category="paragraph">Tout d'abord, il peut utiliser un système de fichiers monté à l'aide du client NFS natif qui fait partie du système d'exploitation. Il s'agit parfois de kernel NFS ou KNFS. Le système de fichiers NFS est monté et utilisé par la base de données Oracle exactement comme toute autre application utiliserait un système de fichiers NFS.</block>
  <block id="95c17c63df7ceea39a175b1d96955bb7" category="paragraph">La deuxième méthode est Oracle Direct NFS (dNFS). Il s'agit d'une implémentation de la norme NFS dans le logiciel de base de données Oracle. Elle ne modifie pas la façon dont les bases de données Oracle sont configurées ou gérées par l'administrateur de base de données. Tant que les paramètres du système de stockage lui-même sont corrects, l'utilisation de dNFS doit être transparente pour l'équipe DBA et les utilisateurs finaux.</block>
  <block id="43539d2fca21e5b644484efb94614a7b" category="paragraph">Les systèmes de fichiers NFS habituels sont toujours montés sur une base de données avec la fonction dNFS activée. Une fois la base de données ouverte, la base de données Oracle ouvre un ensemble de sessions TCP/IP et effectue directement des opérations NFS.</block>
  <block id="26e7ebad3936387b4b3f7c4f5688ef27" category="section-title">NFS direct</block>
  <block id="6d431a52c8a41a7c2335f98e2ae8c454" category="paragraph">La valeur principale de Direct NFS d'Oracle est de contourner le client NFS hôte et d'effectuer des opérations de fichiers NFS directement sur un serveur NFS. Pour l'activer, il suffit de modifier la bibliothèque Oracle Disk Manager (ODM). Vous trouverez des instructions sur ce processus dans la documentation Oracle.</block>
  <block id="8401d91735209aeccbe56f33b4e2db73" category="paragraph">L'utilisation de dNFS entraîne une amélioration significative des performances d'E/S et réduit la charge sur l'hôte et le système de stockage, car les E/S sont effectuées de la manière la plus efficace possible.</block>
  <block id="b0dedecb00787180a9e0c657cfb278c9" category="paragraph">En outre, Oracle dNFS inclut une *option* pour les chemins d'accès multiples et la tolérance aux pannes de l'interface réseau. Par exemple, il est possible de lier deux interfaces de 10 Gbits pour offrir 20 Go de bande passante. En cas de défaillance d'une interface, les E/S sont relancées sur l'autre interface. L'opération globale est très similaire aux chemins d'accès multiples FC. Les chemins d'accès multiples étaient courants il y a plusieurs années, alors que l'ethernet 1 Gbit était la norme la plus courante. Une carte réseau 10 Go suffit pour la plupart des charges de travail Oracle, mais si un nombre supérieur de cartes réseau 10 Go sont requises, elles peuvent être reliées.</block>
  <block id="11e50b3c816105439151db3a3b4fdda3" category="paragraph">Lorsque dNFS est utilisé, il est essentiel que tous les correctifs décrits dans Oracle Doc 1495104.1 soient installés. Si un correctif ne peut pas être installé, l'environnement doit être évalué pour s'assurer que les bugs décrits dans ce document ne causent pas de problèmes. Dans certains cas, une incapacité à installer les correctifs requis empêche l'utilisation de dNFS.</block>
  <block id="8f98002fee392ad6151679875de1a7cc" category="paragraph">N'utilisez pas dNFS avec tout type de résolution de noms round-Robin, y compris DNS, DDNS, NIS ou toute autre méthode. Cela inclut la fonction d'équilibrage de la charge DNS disponible dans ONTAP. Lorsqu'une base de données Oracle utilisant dNFS résout un nom d'hôte en adresse IP, elle ne doit pas être modifiée lors des recherches ultérieures. Cela peut entraîner des pannes de la base de données Oracle et une corruption potentielle des données.</block>
  <block id="e80ad3efb180dc2d016b27506b7b24ce" category="section-title">Accès direct au NFS et au système de fichiers hôte</block>
  <block id="4c38a8c0a49e721bf2a378d0b4fb2010" category="paragraph">L'utilisation de dNFS peut parfois causer des problèmes pour les applications ou les activités des utilisateurs qui dépendent des systèmes de fichiers visibles montés sur l'hôte car le client dNFS accède au système de fichiers hors bande à partir du système d'exploitation hôte. Le client dNFS peut créer, supprimer et modifier des fichiers sans connaître le système d'exploitation.</block>
  <block id="c03389fdb295f2acb079603123e6d0e3" category="paragraph">Lorsque les options de montage des bases de données à instance unique sont utilisées, elles permettent la mise en cache des attributs de fichiers et de répertoires, ce qui signifie également que le contenu d'un répertoire est mis en cache. Par conséquent, dNFS peut créer un fichier, et il y a un court délai avant que le système d'exploitation ne relise le contenu du répertoire et que le fichier devienne visible pour l'utilisateur. Ce n'est généralement pas un problème, mais, dans de rares cas, des utilitaires tels que SAP BR*Tools peuvent présenter des problèmes. Si cela se produit, modifiez les options de montage pour utiliser les recommandations pour Oracle RAC. Ce changement entraîne la désactivation de l'ensemble de la mise en cache de l'hôte.</block>
  <block id="a370a203383b565c3fb746c1c2e1a64b" category="paragraph">Ne modifiez les options de montage que si (a) dNFS est utilisé et (b) un problème résulte d'un décalage dans la visibilité des fichiers. Si dNFS n'est pas utilisé, les options de montage Oracle RAC sur une base de données à instance unique entraînent une dégradation des performances.</block>
  <block id="b1ced01e4bbcd95ec43a2756131f8f9d" category="admonition">Voir la remarque sur<block ref="4740c034d97ca90a96b8050082816605" prefix=" " category="inline-code"></block> dans <block ref="657185beb26ec14433f7e083717fa98b" category="inline-link-macro-rx"></block> Pour un problème dNFS spécifique à Linux qui peut produire des résultats inhabituels.</block>
  <block id="22a7a03175addfd9aa5b1fa2c351e833" category="summary">Configuration NFS pour les bases de données Oracle</block>
  <block id="6cb2edd2369a17890dce007723d98a6f" category="paragraph">NetApp fournit un stockage NFS haute performance depuis plus de 30 ans et son utilisation se développe avec les infrastructures basées sur le cloud en raison de sa simplicité.</block>
  <block id="95e0ac965f4d3a739263ba13584b6411" category="inline-link-macro">Tr-4067 NFS sur les meilleures pratiques NetApp ONTAP</block>
  <block id="c46e4d65876bc5d9253e8e293f59b613" category="paragraph">Le protocole NFS comprend plusieurs versions aux exigences variables. Pour une description complète de la configuration NFS avec ONTAP, reportez-vous à la section <block ref="e3fa0577f1d5ea8870d93a30eb76667f" category="inline-link-macro-rx"></block>. Les sections suivantes couvrent certaines des exigences les plus critiques et des erreurs utilisateur courantes.</block>
  <block id="0f8a941fcc56687ad8e3914162c19a41" category="section-title">Versions NFS</block>
  <block id="d0972be450ccf257fb73d4878bce204e" category="paragraph">Le client NFS du système d'exploitation doit être pris en charge par NetApp.</block>
  <block id="7722a2ae10cef9bccea115dfdfe78a99" category="list-text">NFSv3 est pris en charge avec des systèmes d'exploitation conformes à la norme NFSv3.</block>
  <block id="a3550edc6962850398d217f78cc4ad0d" category="list-text">NFSv3 est pris en charge avec le client Oracle dNFS.</block>
  <block id="89c45ebba54478419aa679a7ece8593d" category="list-text">NFSv4 est pris en charge avec tous les systèmes d'exploitation conformes à la norme NFSv4.</block>
  <block id="471ff51c89daf6e35e8e2b5111039744" category="inline-link-macro">NetApp IMT</block>
  <block id="8594659e8c4292db778973052a30ab86" category="list-text">NFSv4.1 et NFSv4.2 nécessitent une prise en charge spécifique du système d'exploitation. Consulter le <block ref="d98f827de8e80b3365d5f4160c243cdc" category="inline-link-macro-rx"></block> Pour les systèmes d'exploitation pris en charge.</block>
  <block id="d1eb4c2a4d74705a5aa7945f734eff7c" category="list-text">La prise en charge d'Oracle dNFS pour NFSv4.1 requiert Oracle 12.2.0.2 ou version supérieure.</block>
  <block id="d8bacc1a7a9d6baaeb962e367920593b" category="inline-link-macro">Matrice de prise en charge de NetApp</block>
  <block id="f16dcce07ca44aa38c7ebe3016b981b2" category="admonition">Le <block ref="f1e4f72fb4419d4270270c5ed1e0d9f6" category="inline-link-macro-rx"></block> Pour NFSv3 et NFSv4 n'incluent pas de systèmes d'exploitation spécifiques. Tous les systèmes d'exploitation conformes à la RFC sont généralement pris en charge. Lors d'une recherche dans la prise en charge en ligne de IMT pour NFSv3 ou NFSv4, ne sélectionnez pas de système d'exploitation spécifique, car aucune correspondance ne sera affichée. Tous les systèmes d'exploitation sont implicitement pris en charge par la politique générale.</block>
  <block id="26ed9768d6a659a9768842d903d0025f" category="section-title">Tables d'emplacements TCP Linux NFSv3</block>
  <block id="c56ec9836fbbd9c0a426a40fc71c265c" category="paragraph">Les tables d'emplacements TCP sont l'équivalent NFSv3 de la profondeur de file d'attente de l'adaptateur de bus hôte (HBA). Ces tableaux contrôlent le nombre d'opérations NFS qui peuvent être en attente à la fois. La valeur par défaut est généralement 16, un chiffre bien trop faible pour assurer des performances optimales. Le problème inverse se produit sur les noyaux Linux plus récents : la limite de la table des emplacements TCP augmente automatiquement par envoi de demandes, jusqu'à atteindre le niveau de saturation du serveur NFS.</block>
  <block id="5270700baa50d07af667096293a27564" category="paragraph">Pour des performances optimales et pour éviter les problèmes de performances, ajustez les paramètres du noyau qui contrôlent les tables d'emplacements TCP.</block>
  <block id="5b29db1d99e19013580fa375a5f87fa5" category="paragraph">Exécutez le<block ref="1a1e44f7a3390ed4647a7d5b7e8b08ed" prefix=" " category="inline-code"></block> et observez les paramètres suivants :</block>
  <block id="8821adf56df4952370cfaa57ccaac68d" category="paragraph">Tous les systèmes Linux doivent inclure<block ref="c5f48b899461d4c2b9ddc0b24ea87744" prefix=" " category="inline-code"></block>, mais seulement certains incluent<block ref="6f72acaebcb9a0de6696aaf3508a6144" prefix=" " category="inline-code"></block>. Ils doivent tous deux être réglés sur 128.</block>
  <block id="3a954c4e5e8d5ac3af590651efc5a2cb" category="cell">Si vous ne définissez pas ces paramètres, vous risquez d'avoir des effets importants sur les performances. Dans certains cas, les performances sont limitées car le système d'exploitation linux n'émet pas suffisamment d'E/S. Dans d'autres cas, les latences d'E/S augmentent à mesure que le système d'exploitation linux tente d'émettre plus d'E/S que ce qui peut être traité.</block>
  <block id="837f157b2f309f5415420467f7643e3a" category="section-title">ADR et NFS</block>
  <block id="c0e7bb1383be0bf1268d1d70280bef6d" category="paragraph">Certains clients ont signalé des problèmes de performances liés à une quantité excessive d'E/S dans le<block ref="18ca3ed022c239421418de608ceb49c5" prefix=" " category="inline-code"></block> emplacement. Le problème ne se produit généralement pas tant qu'une grande quantité de données de performances ne s'est pas accumulée. La raison de cet excès d'E/S est inconnue, mais ce problème semble provenir des analyses répétées du répertoire cible par les processus Oracle pour détecter les modifications.</block>
  <block id="99be2ae95d50120a7c33c818afda1834" category="paragraph">Dépose du<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> et/ou<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block> Les options de montage permettent la mise en cache du système d'exploitation hôte et réduisent les niveaux d'E/S du stockage.</block>
  <block id="8950578c587f9503f949dfc6a274b611" category="admonition">*NetApp recommande* de ne pas placer<block ref="18ca3ed022c239421418de608ceb49c5" prefix=" " category="inline-code"></block> données sur un système de fichiers avec<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> ou<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block> parce que des problèmes de performances sont probables. Séparer<block ref="18ca3ed022c239421418de608ceb49c5" prefix=" " category="inline-code"></block> le cas échéant, les données vers un autre point de montage.</block>
  <block id="cdb92b4a73ae99cde4df55c06e20dd3c" category="section-title">nfs-rootonly et mount-rootonly</block>
  <block id="c1f0a21ee026237bef11139a30b07040" category="paragraph">ONTAP inclut une option NFS appelée<block ref="77743dec92afc92eca95c255fd9333d7" prefix=" " category="inline-code"></block> Cela permet de contrôler si le serveur accepte les connexions de trafic NFS à partir des ports élevés. Par mesure de sécurité, seul l'utilisateur root est autorisé à ouvrir des connexions TCP/IP à l'aide d'un port source inférieur à 1024 car ces ports sont normalement réservés à l'utilisation du système d'exploitation, et non aux processus utilisateur. Cette restriction permet de s'assurer que le trafic NFS provient d'un client NFS du système d'exploitation et non d'un processus malveillant émulant un client NFS. Le client Oracle dNFS est un pilote d'espace utilisateur, mais le processus s'exécute en tant que root, il n'est donc généralement pas nécessaire de modifier la valeur de<block ref="77743dec92afc92eca95c255fd9333d7" prefix=" " category="inline-code"></block>. Les connexions sont réalisées à partir de ports bas.</block>
  <block id="832b4524bcec11d28ca777ef9cdb4084" category="paragraph">Le<block ref="eb6c1a5ecd1e17d4cd46fa5c9d415816" prefix=" " category="inline-code"></block> Cette option s'applique uniquement à NFSv3. Il contrôle si l'appel de MONTAGE RPC est accepté à partir de ports supérieurs à 1024. Lorsque dNFS est utilisé, le client est de nouveau exécuté en tant que root, ce qui lui permet d'ouvrir des ports inférieurs à 1024. Ce paramètre n'a aucun effet.</block>
  <block id="57c47a1451485bec1ebb060afdf65cb4" category="paragraph">Les processus ouvrant des connexions avec dNFS sur les versions 4.0 et supérieures de NFS ne s'exécutent pas en tant que root et nécessitent donc des ports supérieurs à 1024. Le<block ref="77743dec92afc92eca95c255fd9333d7" prefix=" " category="inline-code"></block> Le paramètre doit être défini sur Désactivé pour dNFS pour terminer la connexion.</block>
  <block id="4dd73247734d116e5039cc04c4979f2c" category="paragraph">Si<block ref="77743dec92afc92eca95c255fd9333d7" prefix=" " category="inline-code"></block> Est activé, le résultat est un blocage lors de la phase de montage ouvrant les connexions dNFS. La sortie sqlplus ressemble à ceci :</block>
  <block id="f62d72479920ff0f8dc9a3ca6f301b5d" category="paragraph">Le paramètre peut être modifié comme suit :</block>
  <block id="47fc6c6691aed3ba0dbdc66c7896c61b" category="admonition">Dans de rares cas, vous devrez peut-être modifier nfs-rootonly et mount-rootonly sur Désactivé. Si un serveur gère un très grand nombre de connexions TCP, il est possible qu'aucun port inférieur à 1024 n'est disponible et que le système d'exploitation soit forcé d'utiliser des ports supérieurs. Ces deux paramètres ONTAP doivent être modifiés pour permettre la connexion.</block>
  <block id="10b4eb170fe7bd035f21e7d863796683" category="section-title">Règles d'exportation NFS : superutilisateur et setuid</block>
  <block id="98bfec37486e95443730cc3d462022fb" category="paragraph">Si les binaires Oracle se trouvent sur un partage NFS, les règles d'export doivent inclure des autorisations de superutilisateur et de setuid.</block>
  <block id="3c0699ba2c56cb17c145bbda5580ed67" category="paragraph">Les exportations NFS partagées utilisées pour les services de fichiers génériques tels que les répertoires personnels des utilisateurs écraseront généralement l'utilisateur root. Cela signifie qu'une demande de l'utilisateur root sur un hôte qui a monté un système de fichiers est remappée en tant qu'utilisateur différent avec des privilèges inférieurs. Cela permet de sécuriser les données en empêchant un utilisateur root d'un serveur donné d'accéder aux données du serveur partagé. Le bit setuid peut également représenter un risque de sécurité dans un environnement partagé. Le bit setuid permet d'exécuter un processus en tant qu'utilisateur différent de celui qui appelle la commande. Par exemple, un script shell qui était détenu par root avec le bit setuid s'exécute en tant que root. Si ce script shell peut être modifié par d'autres utilisateurs, tout utilisateur non root peut émettre une commande en tant que root en mettant à jour le script.</block>
  <block id="e341736b7d51c23cb7ef95615832e502" category="paragraph">Les binaires Oracle incluent les fichiers appartenant à root et utilisent le bit setuid. Si des binaires Oracle sont installés sur un partage NFS, les règles d'export doivent inclure les autorisations de superutilisateur et de setuid appropriées. Dans l'exemple ci-dessous, la règle inclut les deux<block ref="1efaeada4e3307369aca511f5da0498a" prefix=" " category="inline-code"></block> et permis<block ref="0baea2f0ae20150db78f58cddac442a9" prefix=" " category="inline-code"></block> Accès (root) pour les clients NFS via l'authentification système.</block>
  <block id="f1a0fa258c785ac546835a1a75017faf" category="section-title">Configuration NFSv4/4.1</block>
  <block id="52f9ad2e353a42e61d9bf7dd9f59d0cb" category="paragraph">Pour la plupart des applications, il y a très peu de différence entre NFSv3 et NFSv4. Les E/S applicatives sont généralement des E/S très simples et ne bénéficient pas énormément de certaines des fonctionnalités avancées de NFSv4. Les versions supérieures de NFS ne doivent pas être considérées comme une « mise à niveau » du point de vue du stockage de la base de données, mais plutôt comme des versions de NFS qui incluent des fonctionnalités supplémentaires. Par exemple, si la sécurité de bout en bout du mode de confidentialité kerberos (krb5p) est requise, NFSv4 est requis.</block>
  <block id="5cee42a6ee353ec8d6538898f8e63d2d" category="inline-link">Tr-4067 NFS sur les meilleures pratiques NetApp ONTAP</block>
  <block id="1ca271e9db310f8a7fb925b114fd6811" category="paragraph">Le passage à NFSv4 est plus compliqué que de simplement changer les options de montage de vers=3 en vers=4.1. Pour une explication plus complète de la configuration de NFSv4 avec ONTAP, notamment des conseils sur la configuration du système d'exploitation, voir<block ref="2d2395ce3ab8a9852abebca9822b9553" category="inline-link-rx"></block>. Les sections suivantes de ce TR expliquent certaines des exigences de base relatives à l'utilisation de NFSv4.</block>
  <block id="a1dc4350330c061ae52050f5a3400e25" category="section-title">Domaine NFSv4</block>
  <block id="c30669603c950b31f6093d8beaf8060a" category="paragraph">Une explication complète de la configuration NFSv4/4.1 dépasse le cadre de ce document, mais un problème couramment rencontré est une incohérence dans le mappage de domaine. Du point de vue de sysadmin, les systèmes de fichiers NFS semblent se comporter normalement, mais les applications signalent des erreurs concernant les autorisations et/ou le setuid sur certains fichiers. Dans certains cas, les administrateurs ont conclu à tort que les autorisations des binaires de l'application ont été endommagées et ont exécuté des commandes chown ou chmod lorsque le problème réel était le nom de domaine.</block>
  <block id="f0c6c8a632eeaa954640907ee1da277d" category="paragraph">Le nom de domaine NFSv4 est défini sur le SVM ONTAP :</block>
  <block id="97a98ebe6ac1f4a8eaf69158419dd818" category="paragraph">Le nom de domaine NFSv4 sur l'hôte est défini dans<block ref="60969252b5b8391a3378335ae420d2e8" prefix=" " category="inline-code"></block></block>
  <block id="4ade50e8135e817e75aa3086851eaaa8" category="paragraph">Les noms de domaine doivent correspondre. Si ce n'est pas le cas, des erreurs de mappage similaires à ce qui suit apparaissent dans<block ref="452905a167cf4509fd08acb964fdb20c" prefix=" " category="inline-code"></block>:</block>
  <block id="c0eb73bb35a4c58d87b330cd00f1986a" category="paragraph">Les binaires d'application, tels que les binaires de base de données Oracle, incluent les fichiers appartenant à root avec le bit setuid, ce qui signifie qu'une discordance dans les noms de domaine NFSv4 provoque des échecs avec le démarrage d'Oracle et un avertissement sur la propriété ou les autorisations d'un fichier appelé<block ref="dd440398b298ff16eb1188ba8afca6df" prefix=" " category="inline-code"></block>, qui est situé dans le<block ref="002f94d606ac06f290f33a5fcc67b264" prefix=" " category="inline-code"></block> répertoire. Elle doit apparaître comme suit :</block>
  <block id="21cc6f8790de2a7022b344914915604e" category="paragraph">Si ce fichier apparaît avec la propriété de personne, il peut y avoir un problème de mappage de domaine NFSv4.</block>
  <block id="203f1cdb2421d34e9eb7391e03ffcaf6" category="paragraph">Pour résoudre ce problème, vérifiez le<block ref="60969252b5b8391a3378335ae420d2e8" prefix=" " category="inline-code"></block> Comparez le paramètre v4-ID-domain sur ONTAP et assurez-vous qu'ils sont cohérents. Si ce n'est pas le cas, effectuez les modifications requises, exécutez<block ref="1c7ebfbcaa2681599e41320ed491ca91" prefix=" " category="inline-code"></block>, et attendez un moment pour que les modifications se propagent. La propriété du fichier doit alors être correctement reconnue en tant que racine. Si un utilisateur a tenté de s'exécuter<block ref="05f0da969f2e0e6ecf3ab445e1e665ad" prefix=" " category="inline-code"></block> Sur ce fichier avant que la configuration des domaines NFS ne soit corrigée, il peut être nécessaire de l'exécuter<block ref="05f0da969f2e0e6ecf3ab445e1e665ad" prefix=" " category="inline-code"></block> encore.</block>
  <block id="51fb8677d45bb006235a9f8cbe477f6f" category="summary">Bases de données de mise en cache des attributs NFS</block>
  <block id="4da0a3b9c2e8fc0df8844a41ac133401" category="doc">Mise en cache NFS avec les bases de données</block>
  <block id="748f6387bf49161b9a69b7bfd691dcd2" category="paragraph">La présence de l'une des options de montage suivantes entraîne la désactivation de la mise en cache de l'hôte :</block>
  <block id="9f75df502ef11eaef4292c94110cb673" category="paragraph">Ces paramètres peuvent avoir un effet négatif important sur la vitesse d'installation du logiciel, de correction et des opérations de sauvegarde/restauration. Dans certains cas, en particulier avec les applications en cluster, ces options sont obligatoires car elles doivent inévitablement assurer la cohérence du cache sur tous les nœuds du cluster. Dans d'autres cas, les clients utilisent ces paramètres par erreur, ce qui entraîne des dommages inutiles aux performances.</block>
  <block id="8d23519d53d6611bc42fef8dc4a432df" category="paragraph">De nombreux clients suppriment temporairement ces options de montage lors de l'installation ou de l'application de correctifs binaires. Cette suppression peut être effectuée en toute sécurité si l'utilisateur vérifie qu'aucun autre processus n'utilise activement le répertoire cible pendant le processus d'installation ou de correction.</block>
  <block id="f73bede4039d47664f70de3c2d1f2b46" category="summary">Configuration des bandes LVM pour les bases de données Oracle</block>
  <block id="7844f2cc495a938f3039da5801958506" category="doc">LVM Striping avec les bases de données Oracle</block>
  <block id="1b5681ffc153e25d2a48ae3f3f01b9f5" category="paragraph">La répartition des LVM consiste à distribuer les données entre plusieurs LUN. Les performances de nombreuses bases de données en sont ainsi considérablement améliorées.</block>
  <block id="358b9a846de3e04b423c68bac9bc6d53" category="summary">Alignement des LUN avec les bases de données Oracle</block>
  <block id="c4cb2c6af5d7b6c38cd7e588d846e8b4" category="doc">Alignement des LUN pour les E/S Oracle</block>
  <block id="3e00e4d28b17eedd6f6c2c38233e06a8" category="paragraph">L'alignement des LUN fait référence à l'optimisation des E/S par rapport à la disposition du système de fichiers sous-jacent.</block>
  <block id="a6c7e85d51ae3b98197ceb3eafa3686a" category="inline-link-macro">Efficacité</block>
  <block id="6e2524d5663b2bdc0c7985fa3e57cc55" category="section-title">Avertissements de mauvais alignement</block>
  <block id="79e721357e358d77c4700c25c863fc37" category="inline-link">Configuration de l'hôte SAN ONTAP</block>
  <block id="268b1da3f1ff11d32e385d0223101718" category="paragraph">L'alignement dans les environnements Solaris est plus compliqué. Reportez-vous à la section<block ref="2d33e0364c07dc165b4079892340d4fe" category="inline-link-rx"></block> pour en savoir plus.</block>
  <block id="6d017248f1e4f0ec7e2cd19d967b6bee" category="cell">Dans les environnements Solaris x86, prenez davantage soin de l'alignement approprié car la plupart des configurations comportent plusieurs couches de partitions. Les tranches de partition Solaris x86 existent généralement au-dessus d'une table de partition d'enregistrement d'amorçage maître standard.</block>
  <block id="b1230060a0220caf9d68d64b9dd85e6f" category="summary">Tailles de transfert NFS avec Oracle</block>
  <block id="fabe34ed4a5e432f4d1c4f6584956d8d" category="doc">Tailles de transfert NFS avec les bases de données Oracle</block>
  <block id="1e207db9a7c8127a6c43c771b89254fb" category="paragraph">Par défaut, ONTAP limite la taille des E/S NFS à 64 Ko.</block>
  <block id="72d22e3b9af95e272859e64eb1d82df7" category="paragraph">Les E/S aléatoires utilisent la plupart des applications et bases de données une taille de bloc bien inférieure à la taille maximale de 64 Ko. Les E/S de blocs volumineux sont généralement parallélisées de sorte que le maximum de 64 Ko ne limite pas non plus l'obtention d'une bande passante maximale.</block>
  <block id="ebf61afddb34d070825eb696bea48813" category="paragraph">Dans certains cas, le maximum de 64 000 charges de travail entraîne une limitation. En particulier, les opérations à thread unique, telles que les opérations de sauvegarde ou de restauration, ou encore les analyses de table complète de base de données s'exécutent plus rapidement et plus efficacement si la base de données peut exécuter moins d'E/S, mais plus volumineuses. La taille optimale de gestion des E/S pour ONTAP est de 256 Ko.</block>
  <block id="b0a5b394f3a29e64573049cda19fbacc" category="paragraph">La taille maximale de transfert pour un SVM ONTAP donné peut être modifiée comme suit :</block>
  <block id="b070b82d66be7116d5fd6dfd8172351b" category="cell">Ne réduisez jamais la taille de transfert maximale autorisée sur ONTAP en dessous de la valeur de rsize/wsize des systèmes de fichiers NFS actuellement montés. Cela peut provoquer des blocages ou même une corruption des données avec certains systèmes d'exploitation. Par exemple, si les clients NFS sont actuellement définis sur une taille rsize/wsize de 65536, la taille maximale du transfert ONTAP peut être ajustée entre 65536 et 1048576 sans effet car les clients eux-mêmes sont limités. Réduire la taille de transfert maximale en dessous de 65536 peut endommager la disponibilité ou les données.</block>
  <block id="a5c97d9c3645b9a26e3febeb4bc95e24" category="summary">Utilitaire de récupération ASM avec ONTAP</block>
  <block id="861a5ecc95a8478c750be41bf2ddd6f5" category="doc">Utilitaire de récupération ASM et détection de blocs zéro</block>
  <block id="8eb703f2756cafd21dbac4f23c0d6416" category="paragraph">ONTAP supprime efficacement les blocs nuls écrits sur un fichier ou une LUN lorsque la compression à la volée est activée. Des utilitaires tels que l'utilitaire ASRU (Oracle ASM Reclamation Utility) sont utilisés en écrivant des zéros dans les extensions ASM inutilisées.</block>
  <block id="9de53c14f2bae0c5d4b6e19be495ee94" category="paragraph">Du point de vue de la base de données, le groupe de disques ASM contient des zéros et la lecture de ces régions des LUN entraîne un flux de zéros, mais ONTAP ne stocke pas les zéros sur les disques. Des modifications simples des métadonnées sont effectuées en interne pour marquer les régions mises à zéro de la LUN comme vides de toutes les données.</block>
  <block id="06348c6e795160187e298a91b25a37a3" category="paragraph">Pour des raisons similaires, le test de performance impliquant des données mises à zéro n'est pas valide, car les blocs de zéros ne sont pas réellement traités comme des écritures dans la baie de stockage.</block>
  <block id="cee584f1e6223f6dbb73c0d64d599228" category="admonition">Lorsque vous utilisez ASRU, assurez-vous que tous les correctifs recommandés par Oracle sont installés.</block>
  <block id="17ff263bc6eb701aecb8e79f9ef53efd" category="summary">Redimensionnement des LUN et des LVM avec les bases de données Oracle</block>
  <block id="e0327f97ac271a738dd1ac6b182a4369" category="doc">Redimensionnement des LUN et basé sur LVM</block>
  <block id="ff15e8b125dae74c1231f09380e48886" category="paragraph">Lorsqu'un système de fichiers SAN a atteint sa limite de capacité, il existe deux options pour augmenter l'espace disponible :</block>
  <block id="4182200437c090276a01ad8ca54076b0" category="summary">Configuration de NVFAIL pour protéger les bases de données Oracle</block>
  <block id="60e002164f8988e984cf4a95b240f19d" category="doc">Oracle et NVFAIL</block>
  <block id="370bdf5dd39278264774ea595054e243" category="paragraph">NVFAIL est une fonctionnalité de ONTAP qui assure l'intégrité lors des scénarios de basculement catastrophiques.</block>
  <block id="80250c1f1d70fc693877be6f22cc134e" category="paragraph">En raison de la gestion de caches internes volumineux, les bases de données sont vulnérables à la corruption lors des événements de basculement du stockage. Si un événement catastrophique nécessite de forcer un basculement ONTAP ou de forcer le basculement MetroCluster, quel que soit l'état de santé de la configuration globale, les modifications qui ont été reconnues précédemment peuvent être supprimées. Le contenu de la matrice de stockage recule dans le temps et l'état du cache de la base de données ne reflète plus l'état des données sur le disque. Cette incohérence entraîne une corruption des données.</block>
  <block id="68114defc717054e7e3b02df438cdbe1" category="paragraph">La mise en cache peut avoir lieu au niveau des applications ou des serveurs. Par exemple, une configuration Oracle Real application Cluster (RAC) avec des serveurs actifs sur un site principal et un site distant met en cache les données dans la SGA d'Oracle. Une opération de basculement forcé entraînant des pertes de données risque de corrompre la base de données, car les blocs stockés dans la mémoire SGA peuvent ne pas correspondre aux blocs du disque.</block>
  <block id="162de6d405c04ce8f152f1d246ed9187" category="paragraph">L'utilisation de la mise en cache est moins évidente au niveau du système de fichiers du système d'exploitation. Les blocs d'un système de fichiers NFS monté peuvent être mis en cache dans le système d'exploitation. Un système de fichiers en cluster basé sur des LUN situés sur le site principal peut également être monté sur des serveurs du site distant, et une fois encore, les données peuvent être mises en cache. Une défaillance de la mémoire NVRAM, un basculement forcé ou un basculement forcé dans ces situations peuvent entraîner une corruption du système de fichiers.</block>
  <block id="04ca8d9ad570a3bdf1d76e23bc108ae5" category="paragraph">ONTAP protège les bases de données et les systèmes d'exploitation de ce scénario avec NVFAIL et ses paramètres associés.</block>
  <block id="45293b650c7dacd88d269bebf219b8ef" category="summary">La technologie NetApp SnapRestore assure la restauration rapide des bases de données Oracle dans ONTAP à partir d'une copie Snapshot.</block>
  <block id="82ef718f4ebe0c276814ee3d51e33361" category="doc">SnapRestore</block>
  <block id="863696626734d6591db8be57b41c7eec" category="paragraph">La technologie NetApp SnapRestore assure la restauration rapide des données dans ONTAP à partir d'une copie Snapshot.</block>
  <block id="9099b669f87419bc03914f11f5779c60" category="paragraph">Lorsqu'un dataset stratégique n'est pas disponible, les opérations stratégiques de l'entreprise ne sont pas disponibles. Les bandes peuvent se rompre, et même les restaurations à partir de sauvegardes sur disque peuvent être lentes à transférer sur le réseau. SnapRestore évite ces problèmes en offrant une restauration quasi instantanée des datasets. Même les bases de données de plusieurs pétaoctets peuvent être entièrement restaurées en quelques minutes à peine.</block>
  <block id="b02fb7dec22d0e276ca01cc60b9efb48" category="paragraph">Il existe deux types d'SnapRestore : basés sur les fichiers/LUN et sur les volumes.</block>
  <block id="520e4b70b10aa2755a82b77e438a510f" category="list-text">Il est possible de restaurer des fichiers individuels ou des LUN en quelques secondes, qu'il s'agisse d'un LUN de 2 To ou d'un fichier de 4 Ko.</block>
  <block id="45e8a84fe4ac58c8b30a7bdaf17c0b7f" category="list-text">Le conteneur de fichiers ou de LUN peut être restauré en quelques secondes, qu'il s'agisse de 10 Go ou 100 To de données.</block>
  <block id="4be4677be8cd434956b9b9af515b971a" category="paragraph">Un « conteneur de fichiers ou de LUN » fait généralement référence à un volume FlexVol. Par exemple, vous pouvez avoir 10 LUN qui composent un groupe de disques LVM dans un seul volume, ou un volume peut stocker les home directories NFS de 1000 utilisateurs. Au lieu d'exécuter une opération de restauration pour chaque fichier ou LUN individuel, vous pouvez restaurer le volume entier en une seule opération. Ce processus fonctionne également avec des conteneurs scale-out qui incluent plusieurs volumes, tels qu'un FlexGroup ou un groupe de cohérence ONTAP.</block>
  <block id="a8d6a4d1b7fc6e1f60bb0ab716b4e72f" category="paragraph">La raison pour laquelle SnapRestore fonctionne si rapidement et efficacement est due à la nature d'une copie Snapshot, qui offre essentiellement une vue en lecture seule parallèle du contenu d'un volume à un moment donné. Les blocs actifs sont les blocs réels qui peuvent être modifiés, tandis que le snapshot offre une vue en lecture seule de l'état des blocs qui constituent les fichiers et les LUN au moment de la création du snapshot.</block>
  <block id="55abea92d64d6738f9e0ed48799696e7" category="paragraph">ONTAP permet uniquement un accès en lecture seule aux données instantanées, mais les données peuvent être réactivées avec SnapRestore. L'instantané est réactivé en tant que vue en lecture-écriture des données, renvoyant les données à leur état précédent. SnapRestore peut fonctionner au niveau du volume ou du fichier. La technologie est essentiellement la même avec quelques différences mineures de comportement.</block>
  <block id="f10f2af75e2770a8ed3c2fde594e986d" category="section-title">SnapRestore du volume</block>
  <block id="ca9846346bc3b03cdec10f9fff456866" category="paragraph">La fonction SnapRestore basée sur les volumes renvoie la totalité du volume de données à un état antérieur. Cette opération ne nécessite pas de déplacement de données. Le processus de restauration est donc pratiquement instantané, bien que le traitement des opérations via l'API ou l'interface de ligne de commande puisse prendre quelques secondes. La restauration de 1 Go de données n'est pas plus compliquée et chronophage que la restauration de 1 po de données. Cette fonctionnalité est la principale raison pour laquelle de nombreux clients grands comptes migrent vers des systèmes de stockage ONTAP. Il assure un RTO se mesure en quelques secondes, même pour les datasets les plus volumineux.</block>
  <block id="627436e77bb011a6a312ae87b12f98ea" category="paragraph">L'un des inconvénients des SnapRestore sur volume est le fait que les modifications au sein d'un volume sont cumulées dans le temps. Par conséquent, chaque snapshot et les données de fichier actives dépendent des modifications apportées jusqu'à ce point. Le rétablissement d'un volume à un état antérieur implique la suppression de toutes les modifications ultérieures apportées aux données. Ce qui est moins évident, cependant, c'est qu'il s'agit d'instantanés créés par la suite. Ce n'est pas toujours souhaitable.</block>
  <block id="5c956f2c1cfc5b9e5bac32ad1acba314" category="paragraph">Par exemple, un SLA de conservation des données peut spécifier 30 jours de sauvegardes nocturnes. La restauration d'un dataset sur un snapshot créé il y a cinq jours avec SnapRestore du volume abandonnerait tous les snapshots créés les cinq jours précédents, en violation du SLA.</block>
  <block id="8bf9e697004f47ed6133aef724a8a42c" category="paragraph">Un certain nombre d'options sont disponibles pour résoudre cette limitation :</block>
  <block id="ad3b75456e625de5fe347fb918f59a22" category="list-text">Les données peuvent être copiées à partir d'un instantané précédent, au lieu d'effectuer une SnapRestore du volume entier. Cette méthode fonctionne mieux avec les jeux de données plus petits.</block>
  <block id="90541eb74c7c56cadc2f90ec6fb6f0c0" category="list-text">Un snapshot peut être cloné plutôt que restauré. La limitation à cette approche est que le snapshot source dépend du clone. Par conséquent, elle ne peut pas être supprimée si le clone n'est pas également supprimé ou s'il est divisé en volume indépendant.</block>
  <block id="ab6045d3463c0f68ce2fa405dce9d554" category="list-text">Utilisation d'un SnapRestore basé sur des fichiers.</block>
  <block id="7f7599a8b92846b691484dc91e090164" category="section-title">Fichier SnapRestore</block>
  <block id="f03eebe4f07d362dbfe4c1d4e76c724d" category="paragraph">SnapRestore basé sur les fichiers est un processus de restauration plus granulaire basé sur des snapshots. Au lieu de rétablir l'état d'un volume entier, l'état d'un fichier ou d'une LUN individuel est rétabli. Il n'est pas nécessaire de supprimer des snapshots et cette opération ne crée aucune dépendance vis-à-vis d'un instantané précédent. Le fichier ou la LUN est immédiatement disponible dans le volume actif.</block>
  <block id="e432fdcc277fc74a1b2b94cfeec8a7d2" category="paragraph">Aucun déplacement des données n'est nécessaire lors de la restauration d'un fichier ou d'une LUN par SnapRestore. Cependant, des mises à jour internes des métadonnées sont nécessaires pour refléter le fait que les blocs sous-jacents d'un fichier ou d'une LUN existent désormais à la fois dans un snapshot et dans le volume actif. Les performances ne doivent pas être affectées, mais ce processus bloque la création de snapshots jusqu'à ce qu'elle soit terminée. Le taux de traitement est d'environ 5 Gbit/s (18 To/heure) en fonction de la taille totale des fichiers restaurés.</block>
  <block id="a68b31b502bf7555cda2514354e553c2" category="summary">Stratégies de protection des données ONTAP</block>
  <block id="6bb9a5aec98309d1414b32f7e0751415" category="doc">Planification de la protection des données</block>
  <block id="45c46768a1cb073f0d13245a0dc816f2" category="paragraph">Une architecture de protection des données d'entreprise adaptée dépend des exigences de l'entreprise concernant la conservation des données, la restauration et la tolérance aux perturbations à divers moments.</block>
  <block id="46e1b2893bdb002c0ede448cbfe1cb14" category="paragraph">Prenons l'exemple du nombre d'applications, de bases de données et de datasets importants pris en compte. Il est relativement simple d'élaborer une stratégie de sauvegarde pour un seul dataset afin d'assurer la conformité aux SLA standard, car la gestion ne comporte pas beaucoup d'objets. À mesure que le nombre de jeux de données augmente, la surveillance devient plus complexe et les administrateurs peuvent être obligés de consacrer de plus en plus de temps aux pannes de sauvegarde. Dès qu'un environnement évolue, il faut adopter une approche totalement différente.</block>
  <block id="b70d233428e03d072b1134a97d853ab2" category="paragraph">La taille des datasets affecte également la stratégie. Par exemple, le jeu de données étant si petit, de nombreuses options sont possibles pour la sauvegarde et la restauration avec une base de données de 100 Go. En général, la simple copie des données à partir du support de sauvegarde avec des outils classiques permet d'atteindre un RTO suffisant pour la restauration. Une base de données de 100 To a généralement besoin d'une stratégie totalement différente, sauf si le RTO autorise une panne de plusieurs jours. Dans ce cas, une procédure classique de sauvegarde et de restauration basée sur des copies peut être acceptable.</block>
  <block id="64848fee9c168231f5d0f13322ed0a87" category="paragraph">Enfin, il y a des facteurs en dehors du processus de sauvegarde et de restauration lui-même. Par exemple, existe-t-il des bases de données qui prennent en charge les activités de production stratégiques, faisant de la restauration un événement rare uniquement effectué par des administrateurs de bases de données qualifiés ? Ou bien, les bases de données font-elles partie d'un vaste environnement de développement dans lequel la restauration est fréquente et gérée par une équipe INFORMATIQUE généraliste ?</block>
  <block id="e26b57887de9a65c0316a87d49bf6c44" category="section-title">Un snapshot est-il une sauvegarde ?</block>
  <block id="c3fd105ab426caff0a0ade2e93476543" category="paragraph">L'une des objections les plus fréquentes à l'utilisation des snapshots en tant que stratégie de protection des données est le fait que les « vraies » données et les données de snapshot se trouvent sur les mêmes disques. La perte de ces disques entraînerait la perte des données primaires et de la sauvegarde.</block>
  <block id="12d1adb01d24027626b2a47660fb5b81" category="paragraph">Ce problème est valide. Les snapshots locaux sont utilisés pour les besoins quotidiens de sauvegarde et de restauration, et dans ce sens, le snapshot est une sauvegarde. Dans les environnements NetApp, près de 99 % des scénarios de restauration s'appuient sur des copies Snapshot pour répondre aux exigences de RTO les plus strictes.</block>
  <block id="fc34c9966c8ecb7307468637d9e79933" category="paragraph">Toutefois, les snapshots locaux ne doivent jamais être la seule stratégie de sauvegarde. C'est pourquoi NetApp propose des technologies telles que la réplication SnapMirror pour répliquer rapidement et efficacement des copies Snapshot sur un ensemble indépendant de disques. Dans une solution bien conçue avec des snapshots et une réplication Snapshot, l'utilisation des bandes peut être réduite au minimum, voire même à une archive trimestrielle, ou totalement éliminée.</block>
  <block id="1ea948130a9dbbc02e3a80648a99ff57" category="section-title">Sauvegardes de groupes de cohérence</block>
  <block id="9b234a126e57777ab83807827d4e7078" category="paragraph">La sauvegarde d'un groupe de cohérence implique de capturer l'état d'un jeu de données (ou de plusieurs jeux de données) à un point atomique unique dans le temps. Comme exemple de base de données, cela inclut tous les composants de la base de données, tels que les fichiers de données, les fichiers journaux et les autres fichiers directement associés à la base de données. Cela fonctionne avec presque tous les produits de base de données relationnelle, comme Oracle RDBMS, Microsoft SQL Server, SAP HANA, PostgreSQL, MySQL et MariaDB. La protection d'une configuration VMware avec une sauvegarde de groupe de cohérence serait similaire, en capturant tous les datastores et potentiellement les LUN de démarrage ESX à un seul point atomique dans le temps.</block>
  <block id="5a1f7038c74e54c08669efa6722f1091" category="paragraph">La création d'un Snapshot de groupe de cohérence de ce type simule une panne. C'est pourquoi ces sauvegardes sont souvent appelées sauvegardes cohérentes après panne. La prise en charge des scénarios de restauration pose parfois des problèmes, mais il est important de comprendre qu'aucune procédure de restauration n'est généralement nécessaire. Lorsque l'application démarre après la restauration d'une sauvegarde de groupe de cohérence, elle exécute les processus de restauration de journaux habituels, les relectures du journal du système de fichiers et d'autres tâches pour relire toute E/S en cours au point de la sauvegarde. L'application démarre alors comme d'habitude.</block>
  <block id="aebdbddec25f7eba6434244a989fb659" category="paragraph">Pour l'essentiel, toute application pouvant résister à une panne de courant ou à une panne de serveur sans corruption des données peut être protégée de cette façon. Le fait que cela fonctionne peut également être démontré par le grand nombre d'applications protégées par des produits de mise en miroir synchrone et asynchrone de nombreux fournisseurs différents. Si un incident frappe soudainement le site principal, le site de réplica contient une image cohérente de l'environnement d'origine au moment où l'incident s'est produit. Une fois de plus, aucune procédure de récupération spéciale n'est requise.</block>
  <block id="e085ffefd89f8fb66260a9720e3fb6f8" category="paragraph">Le RPO de cette approche est généralement limité au point de sauvegarde. En règle générale, le RPO minimal pour les copies Snapshot à un seul volume est d'une heure. Par exemple, 48 snapshots par heure et 30 autres snapshots par nuit sont raisonnables et ne nécessitent pas la conservation d'un nombre excessif de snapshots. Il devient plus difficile d'atteindre un objectif de point de récupération inférieur à une heure. Il n'est donc pas recommandé de consulter au préalable les services professionnels NetApp pour comprendre les exigences en matière d'environnement, d'évolutivité et de protection des données.</block>
  <block id="1fe119a790b393b7dd7e79b63f15f52b" category="paragraph">Le RTO se mesure généralement en secondes. A une application est arrêtée, les volumes sont restaurés et l'application redémarrée.</block>
  <block id="444cd304758b7607c8f7a3f627a5bc1f" category="paragraph">La méthode la plus simple consiste à placer tous les fichiers ou LUN dans un groupe de cohérence de volume unique. Ainsi, la création de Snapshot peut être planifiée directement dans ONTAP. Lorsqu'un dataset doit couvrir des volumes, un Snapshot de groupe de cohérence (cg-snapshot) est nécessaire. Vous pouvez les configurer à l'aide de System Manager ou d'appels d'API RESTful. De plus, SnapCenter est capable de créer un snapshot de groupe de cohérence simple sur une liste définie de volumes.</block>
  <block id="689b0155b42a554594a44cddc736eb67" category="section-title">Architecture de réplication et de reprise après incident</block>
  <block id="1749d12df3df2319d3eee218a277ff83" category="inline-link-macro">MetroCluster</block>
  <block id="7b8111b0a2fc76252bbacbbc9de542a4" category="inline-link-macro">Continuité de l'activité SnapMirror</block>
  <block id="96a7c86d5bc52a478876c48dc6dcc9f0" category="paragraph">Cette section traite de la protection des données à distance, pour laquelle les données sont répliquées vers un site distant à des fins de stockage hors site sécurisé et de reprise sur incident. Notez que ces tableaux ne traitent pas de la protection des données de mise en miroir synchrone. Pour cette condition, consultez la documentation de NetApp MetroCluster, y compris <block ref="5c964f26ec7fbbad5ac67aaa5dcf9269" category="inline-link-macro-rx"></block> et <block ref="30831ec866621e18e7521d6c2750acaa" category="inline-link-macro-rx"></block></block>
  <block id="f443592081a2b3ddc55b94abe49ba128" category="paragraph">Le RPO de reprise sur incident est limité par la bande passante réseau disponible et la taille totale des données protégées. Une fois le transfert de base initial créé, les mises à jour sont uniquement basées sur les données modifiées, ce qui représente généralement un faible pourcentage de l'empreinte totale des données, même si des exceptions existent.</block>
  <block id="89e87a831dae60244ba34496d70fd45d" category="paragraph">Par exemple, une base de données de 10 To avec un taux de modification hebdomadaire de 10 % représente en moyenne 6 Go de modifications totales par heure. Avec une connectivité de 10 Gb, ce transfert de base de données prend environ 6 minutes. Le taux de modification varie en fonction des fluctuations du taux de modification de la base de données, mais dans l'ensemble, un intervalle de mise à jour de 15 minutes et un objectif de point de récupération de 15 minutes doivent être atteints. S'il existe 100 bases de données de ce type, 600 minutes sont nécessaires pour transférer les données. Par conséquent, un objectif RPO d'une heure n'est pas possible. De même, une réplique d'une seule base de données de 100 To avec un taux de modification hebdomadaire de 10 % ne peut pas être mise à jour de manière fiable en une heure.</block>
  <block id="3c886a803aef21f5ac9f7bcea7408cbb" category="paragraph">D'autres facteurs peuvent avoir une incidence sur la réplication, comme la surcharge liée à la réplication et la limitation du nombre d'opérations de réplication simultanées. Cependant, la planification globale d'une stratégie de réplication à volume unique peut reposer sur la bande passante disponible et un RPO de réplication d'une heure est généralement réalisable. Un RPO inférieur à une heure devient plus difficile à atteindre et ne doit être réalisé qu'après consultation des services professionnels de NetApp. Dans certains cas, 15 minutes sont possibles avec une très bonne connectivité réseau site à site. Cependant, dans l'ensemble, lorsqu'un objectif RPO inférieur à une heure est requis, l'architecture de relecture des journaux multivolumes produit de meilleurs résultats.</block>
  <block id="5e2cbdd214e7a73bca1af8ed5cc04626" category="paragraph">Dans un scénario de reprise d'activité, le RTO avec réplication de groupe de cohérence est excellent, généralement mesuré en secondes du point de vue du stockage. L'approche la plus simple est de mettre simplement en miroir et la base de données est prête à être démarrée. Le temps de démarrage de la base de données est généralement d'environ 10 secondes, mais les bases de données très volumineuses qui génèrent un grand nombre de transactions consignées peuvent prendre quelques minutes.</block>
  <block id="1c18c939e73ddb1ceee34e8a33079d1a" category="paragraph">Le facteur le plus important pour déterminer l'objectif de durée de restauration n'est pas le système de stockage, mais l'application et le système d'exploitation hôte sur lesquels il s'exécute. Par exemple, les données répliquées peuvent être disponibles en une ou deux secondes, mais elles ne représentent que les données. Il doit également y avoir un système d'exploitation correctement configuré avec des binaires d'application disponibles pour utiliser les données.</block>
  <block id="6fab898feea25b9d7fd4477911b90b31" category="paragraph">Dans certains cas, les clients ont préparé des instances de reprise après incident à l'avance, avec le stockage prédécouvert sur les systèmes d'exploitation. Dans ce cas, l'activation du scénario de reprise d'activité ne peut nécessiter que la rupture d'un miroir et le démarrage de l'application. Dans d'autres cas, le système d'exploitation et les applications associées peuvent être mis en miroir avec la base de données en tant que disque de machine virtuelle ESX (VMDK). Dans ce cas, le RPO est déterminé par la quantité investie par un client dans l'automatisation pour démarrer rapidement le VMDK afin de pouvoir démarrer les applications.</block>
  <block id="c7d5d755b896edf43189fbb020202913" category="paragraph">Le temps de rétention est contrôlé en partie par la limite de snapshot. Par exemple, les volumes dans ONTAP ont une limite de 1024 snapshots. Dans certains cas, les clients disposent d'une réplication multiplexée pour augmenter la limite. Par exemple, si 2000 jours de sauvegardes sont requis, une source peut être répliquée sur deux volumes avec des mises à jour effectuées sur d'autres jours. L'espace initial nécessaire doit être augmenté, mais l'approche reste bien plus efficace qu'un système de sauvegarde traditionnel qui implique plusieurs sauvegardes complètes.</block>
  <block id="7ec0f114b69016879106b5018cdf10b9" category="section-title">Groupe de cohérence à volume unique</block>
  <block id="cd70f3e596e275fe80fbbe5d7858ce1a" category="paragraph">La méthode la plus simple consiste à placer tous les fichiers ou LUN dans un groupe de cohérence de volume unique. Ainsi, les mises à jour SnapMirror et SnapVault peuvent être planifiées directement sur le système de stockage. Aucun logiciel externe n'est requis.</block>
  <block id="909e8df57072d0b3c6d7d64b11acb571" category="section-title">Groupe de cohérence multivolume</block>
  <block id="c7371eded617935ace6c71a33cfbf3fd" category="paragraph">Lorsqu'une base de données doit couvrir plusieurs volumes, un Snapshot de groupe de cohérence (cg-snapshot) est nécessaire. Comme mentionné précédemment, cette configuration peut être effectuée à l'aide de System Manager ou d'appels d'API RESTful. De plus, SnapCenter est capable de créer un snapshot de groupe de cohérence simple sur une liste définie de volumes.</block>
  <block id="9c991b38c054d7bec0632efd6667540c" category="paragraph">Il est également nécessaire de prendre en compte un autre facteur concernant l'utilisation de copies Snapshot cohérentes à plusieurs volumes à des fins de reprise après incident. Lors de la mise à jour de plusieurs volumes, il est possible qu'un incident se produise pendant le transfert. Il en résulte un ensemble de volumes qui ne sont pas cohérents les uns avec les autres. Si c'est le cas, certains volumes doivent être restaurés à un état de snapshot antérieur pour fournir une image de base de données cohérente après panne et prête à être utilisée.</block>
  <block id="fad8a5f46ebd89f74383b461e32dd6b9" category="section-title">Reprise après incident : activation</block>
  <block id="5ac319591298468b0af89c2c469201f8" category="paragraph">Le processus d'activation de la copie de reprise sur incident dépend du type de stockage. Avec NFS, les systèmes de fichiers peuvent être prémontés sur le serveur de reprise après incident. Ils sont en lecture seule et deviennent en lecture-écriture lorsque le miroir est cassé. Le RPO est ainsi extrêmement faible, et le processus global de reprise sur incident est plus fiable, car la gestion comporte moins de pièces.</block>
  <block id="b829fc11ff11b57af8d4632d38d7d7e8" category="paragraph">L'activation des configurations SAN en cas de reprise après incident devient plus complexe. L'option la plus simple consiste généralement à interrompre temporairement les miroirs et à monter les ressources SAN, notamment à découvrir la configuration LVM (y compris les fonctionnalités spécifiques à l'application telles qu'Oracle Automatic Storage Management [ASM]) et à ajouter des entrées à /etc/fstab.</block>
  <block id="335a5796fb106a877544d121062534be" category="paragraph">Le résultat est que les chemins du périphérique LUN, les noms des groupes de volumes et les autres chemins de périphériques sont connus du serveur cible. Ces ressources peuvent ensuite être désactivées, puis les miroirs peuvent être restaurés. Le résultat est un serveur qui est dans un état qui peut rapidement mettre l'application en ligne. Les étapes permettant d'activer des groupes de volumes, de monter des systèmes de fichiers ou de démarrer des bases de données et des applications sont facilement automatisables.</block>
  <block id="b1a175c5f42da29f6c27f4ea29684b63" category="paragraph">Il faut veiller à ce que l'environnement de reprise d'activité soit à jour. Par exemple, de nouvelles LUN sont susceptibles d'être ajoutées au serveur source, ce qui signifie que les nouvelles LUN doivent être prédécouvertes sur la destination pour s'assurer que le plan de reprise sur incident fonctionne comme prévu.</block>
  <block id="90426ba53f908049843b3ea392578d04" category="doc">Reprise sur incident Oracle</block>
  <block id="7fe779a487e8f113f1ffdff0fb80353f" category="summary">Sauvegardes de groupes de cohérence pour Oracle sur ONTAP</block>
  <block id="773f9afa3df0cf82ed853c988183c73f" category="doc">Sauvegarde de groupe de cohérence Oracle</block>
  <block id="5afd3dc3f8d489d47587e10e6663c512" category="paragraph">Pour obtenir la sauvegarde la plus simple possible, il vous suffit de placer l'intégralité de la base de données Oracle dans un seul volume.</block>
  <block id="2a4fa9d9434561574119e3086112023f" category="paragraph">La protection des fichiers de données, des journaux d'archivage, des journaux de reprise et des fichiers de contrôle avec un seul snapshot constitue une méthode valide de sauvegarde, de restauration et de réplication.  Toutefois, le RPO est limité au point de la sauvegarde elle-même. Il convient pour un RPO d'une heure ou plus. Si une base de données s'étend sur plusieurs volumes, vous devez créer des snapshots de groupe de cohérence à l'aide de l'un des outils évoqués précédemment.</block>
  <block id="93310f4cebc752304c164f00d67e0bca" category="paragraph">Par exemple, l'ensemble de la base de données peut se trouver dans un seul volume avec la planification de snapshots suivante :</block>
  <block id="a33821be4b3522d65daed1ec317299f6" category="list-text">72 snapshots par heure</block>
  <block id="0eea0679ac7bf43c19d603cd78e81de9" category="list-text">30 snapshots de nuit</block>
  <block id="c4546c401776d279c5577011584577fa" category="list-text">12 snapshots mensuels</block>
  <block id="b63db1b650d128c342617b377baf928a" category="paragraph">Vous bénéficiez ainsi d'un RPO d'une heure sur la période de roulement des 72 heures précédentes, ainsi que de sauvegardes supplémentaires nocturnes et mensuelles. Il est également possible d'inclure plusieurs bases de données ou fichiers d'application dans le volume unique ou l'ensemble de copies Snapshot de groupe de cohérence afin d'assurer des sauvegardes cohérentes dans un environnement plus vaste.</block>
  <block id="5eb532bcede5a8d57b8fb4429d5cc7ec" category="summary">Optimisation de la disponibilité avec Oracle sur ONTAP</block>
  <block id="b4343a8438e1b9cc9e9486f85831f2a1" category="doc">Disponibilité des données Oracle avec ONTAP</block>
  <block id="686540783626106489734a1990d4930d" category="paragraph">ONTAP est conçu pour offrir une disponibilité maximale des bases de données Oracle. Ce document ne contient pas de description complète des fonctionnalités de haute disponibilité de ONTAP. Cependant, comme pour la protection des données, il est important de bien comprendre cette fonctionnalité lors de la conception d'une infrastructure de base de données.</block>
  <block id="b049fcbe8198301adc6bf87634a02845" category="section-title">Paires HA</block>
  <block id="1a7c11d1e2d03d3d1b57cff284ebd761" category="paragraph">L'unité de base de la haute disponibilité est la paire haute disponibilité. Chaque paire contient des liens redondants pour prendre en charge la réplication des données vers la mémoire NVRAM. La NVRAM n'est pas un cache d'écriture. La RAM à l'intérieur du contrôleur sert de cache d'écriture. L'objectif de la mémoire NVRAM est de journaliser temporairement les données afin de prévenir toute panne système inattendue. À cet égard, il est similaire à un fichier redo log de base de données.</block>
  <block id="cd2e54027dfcfeddd07ddd580db527c0" category="paragraph">La mémoire NVRAM et le journal de reprise de base de données sont utilisés pour stocker des données rapidement, ce qui permet d'y apporter les modifications le plus rapidement possible. La mise à jour des données persistantes sur les disques (ou fichiers de données) n'a lieu qu'une fois plus tard lors d'un processus appelé point de contrôle sur ONTAP et la plupart des plateformes de bases de données. Les données NVRAM et les redo logs de base de données ne sont pas lus pendant les opérations normales.</block>
  <block id="4e044ec0c36e513506c77c0a97d53539" category="paragraph">Si un contrôleur tombe en panne brusquement, des modifications sont susceptibles d'être en attente de stockage dans la mémoire NVRAM qui n'ont pas encore été écrites sur les disques. Le contrôleur partenaire détecte la panne, prend le contrôle des disques et applique les modifications requises qui ont été stockées dans la mémoire NVRAM.</block>
  <block id="310e46747ebab6a43d5a15998f6e2b33" category="section-title">Takeover et Giveback</block>
  <block id="1d739263e44469ad28f77fe7329fa78d" category="paragraph">Le basculement et le rétablissement font référence au processus de transfert de la responsabilité des ressources de stockage entre les nœuds d'une paire HA. Le basculement et le rétablissement sont deux aspects :</block>
  <block id="f2d43d90397aa8140414437eda14febb" category="list-text">Gestion de la connectivité réseau permettant l'accès aux lecteurs</block>
  <block id="6e1c794c81468e3286a23138460bb3fb" category="list-text">Gestion des disques eux-mêmes</block>
  <block id="89d3f6c60c53a11e16a6756bde03ca00" category="paragraph">Les interfaces réseau prenant en charge le trafic CIFS et NFS sont configurées avec un emplacement de home et de basculement. Il inclut le déplacement des interfaces réseau vers leur domicile temporaire sur une interface physique située sur le(s) même(s) sous-réseau que l'emplacement d'origine. Le rétablissement inclut le déplacement des interfaces réseau vers leurs emplacements d'origine. Le comportement exact peut être réglé selon les besoins.</block>
  <block id="108018656caf59cc565f1172047dab38" category="paragraph">Les interfaces réseau prenant en charge les protocoles de bloc SAN, tels que iSCSI et FC, ne sont pas déplacées pendant le basculement et le rétablissement. Les LUN doivent plutôt être provisionnées avec des chemins qui incluent une paire HA complète entraînant un chemin principal et un chemin secondaire.</block>
  <block id="80795d5dd590e432b4f5945aba47caf4" category="admonition">Des chemins d'accès supplémentaires vers des contrôleurs supplémentaires peuvent également être configurés pour prendre en charge le déplacement des données entre les nœuds d'un cluster plus grand, mais cela ne fait pas partie du processus de haute disponibilité.</block>
  <block id="aae63904d16fd1c522dc5ff53eb695b5" category="paragraph">Le deuxième aspect du Takeover et Giveback est le transfert de la propriété de disque. Le processus exact dépend de plusieurs facteurs, notamment la raison du Takeover/Giveback et les options de ligne de commande émises. L'objectif est de réaliser l'opération aussi efficacement que possible. Bien que le processus global puisse sembler durer plusieurs minutes, le moment réel où la propriété du disque est transférée d'un nœud à un autre peut généralement se mesurer en secondes.</block>
  <block id="61775b9e8f759f26eafd6b03448d1f30" category="section-title">Temps de reprise</block>
  <block id="3224b51e62790c4ce988d8c1876fb36e" category="paragraph">Les E/S de l'hôte font l'objet d'une courte pause au niveau des E/S lors des opérations de basculement et de rétablissement. Cependant, la configuration de l'environnement ne doit pas provoquer d'interruption des applications. Le processus de transition réel dans lequel les E/S sont retardées se mesure généralement en secondes, mais l'hôte peut avoir besoin de plus de temps pour reconnaître la modification des chemins de données et renvoyer les opérations d'E/S.</block>
  <block id="40f291752a9848bfecb7264cfd9aa8ee" category="paragraph">La nature de la perturbation dépend du protocole :</block>
  <block id="cb44db7841f8fb68230a260c4c68bfe0" category="list-text">Une interface réseau prenant en charge le trafic NFS et CIFS émet une requête ARP (Address Resolution Protocol) vers le réseau après la transition vers un nouvel emplacement physique. Les commutateurs réseau mettent ainsi à jour leurs tables d'adresses MAC (Media Access Control) et reprennent le traitement des E/S. L'interruption dans le cas d'un basculement et d'un rétablissement planifiés se mesure généralement en secondes et, dans la plupart des cas, elle n'est pas détectable. Certains réseaux peuvent être plus lents à reconnaître pleinement le changement de chemin réseau et certains systèmes d'exploitation peuvent mettre en file d'attente beaucoup d'E/S dans un délai très court qui doit être réessayé. Cela peut prolonger le temps nécessaire pour reprendre les E/S.</block>
  <block id="6a410522094e0b0f874dab5784e81ab8" category="list-text">Une interface réseau prenant en charge les protocoles SAN ne peut pas être mise à niveau vers un nouvel emplacement. Un système d'exploitation hôte doit modifier le ou les chemins utilisés. La pause des E/S observée par l'hôte dépend de plusieurs facteurs. Du point de vue du système de stockage, la période pendant laquelle les E/S ne peuvent pas être servies ne prend que quelques secondes. Cependant, des systèmes d'exploitation hôtes différents peuvent nécessiter plus de temps pour permettre à une E/S de se déconnecter avant de réessayer. Les systèmes d'exploitation les plus récents sont mieux à même de reconnaître un changement de chemin beaucoup plus rapidement, mais les systèmes d'exploitation plus anciens nécessitent généralement jusqu'à 30 secondes pour reconnaître un changement.</block>
  <block id="cabc4f9cda7d4bfb99181166c863a374" category="paragraph">Les délais de basculement attendus lors desquels le système de stockage ne peut pas transmettre de données à un environnement applicatif sont indiqués dans le tableau ci-dessous. Aucun environnement applicatif ne doit contenir d'erreurs ; le basculement doit alors apparaître sous forme de courte pause dans le traitement des E/S.</block>
  <block id="c8984126713ed072b9cb0a44a162be4d" category="cell">AFF</block>
  <block id="b7b46ce5d1a547db89c0bc615ff272a5" category="cell">ASA</block>
  <block id="ed3467fac861f6a32cd66093ac415805" category="cell">Basculement planifié</block>
  <block id="57a915dfa0e8469b25c1b8b947f7ee2c" category="cell">15 s</block>
  <block id="cd5dce62294e9a79e9c2165ee0903f5f" category="cell">6-10 s</block>
  <block id="cbfdbb11fd5eab0d9fdd078ae66a1c69" category="cell">2-3 s</block>
  <block id="1a066f0304c1d3a279466c70359c5103" category="cell">Basculement non planifié</block>
  <block id="0f4a6e109a34d3483995e427b6581130" category="cell">30 s</block>
  <block id="a4985782267828ce03a3d13f37392de1" category="summary">Checksums et protection des données Oracle</block>
  <block id="407941abab873f61b271b481e105eb33" category="doc">Checksums et intégrité des données Oracle</block>
  <block id="b93232347a11497969d0ea20d34cd16e" category="paragraph">Une question couramment adressée à NetApp est de savoir comment sécuriser l'intégrité des données d'une base de données Oracle.</block>
  <block id="dbfb054670bc82c6e08a7e101c0f0ef4" category="paragraph">La protection logique des données dans ONTAP comprend trois exigences clés :</block>
  <block id="b6cc6762545d78ab663e39c37d172bd2" category="list-text">Les données doivent être protégées contre la corruption.</block>
  <block id="e7c7e14f4b6ca1b3ae32b2279243dba6" category="list-text">Les données doivent être protégées contre les pannes disques.</block>
  <block id="1168469b387027a850496f6cac9f3529" category="list-text">Les modifications de données doivent être protégées contre la perte.</block>
  <block id="864a6ca5da4b36656beba11c90f4c4e5" category="paragraph">Ces trois besoins sont abordés dans les sections suivantes.</block>
  <block id="a05b54004946aa523bfe7c1e92a52f52" category="section-title">Corruption du réseau : checksums</block>
  <block id="ed95581a613a4f19be367c10cd063cc2" category="paragraph">Le niveau de protection de données le plus élémentaire est la somme de contrôle, qui est un code spécial de détection d'erreur stocké avec les données. La corruption des données lors de la transmission du réseau est détectée grâce à l'utilisation d'un checksum et, dans certains cas, de multiples checksums.</block>
  <block id="c1343e51090396cf011509389bc0adab" category="paragraph">Par exemple, une trame FC inclut une forme de somme de contrôle appelée contrôle de redondance cyclique (CRC) pour s'assurer que la charge utile n'est pas corrompue en transit. L'émetteur envoie les données et le CRC des données. Le récepteur d'une trame FC recalcule le CRC des données reçues pour s'assurer qu'il correspond au CRC transmis. Si le nouveau CRC calculé ne correspond pas au CRC joint à la trame, les données sont corrompues et la trame FC est supprimée ou rejetée. Une opération d'E/S iSCSI comprend des checksums au niveau des couches TCP/IP et Ethernet. Pour une protection supplémentaire, elle peut également inclure la protection CRC facultative au niveau de la couche SCSI. Toute corruption de bit sur le fil est détectée par la couche TCP ou la couche IP, ce qui entraîne la retransmission du paquet. Comme avec FC, les erreurs dans le CRC SCSI entraînent une suppression ou un rejet de l'opération.</block>
  <block id="1f08639c540e47068c16c3ac48ea7bbe" category="section-title">Corruption de disque : checksums</block>
  <block id="c5d50bc8d916a4b26166bbda091cd6d4" category="paragraph">Des checksums sont également utilisés pour vérifier l'intégrité des données stockées sur les disques. Les blocs de données écrits sur les disques sont stockés avec une fonction de checksum qui génère un nombre imprévisible lié aux données d'origine. Lorsque les données sont lues à partir du lecteur, la somme de contrôle est recalculée et comparée à la somme de contrôle stockée. Si elle ne correspond pas, les données sont corrompues et doivent être restaurées par la couche RAID.</block>
  <block id="8edc44db01815f20f6508db8b5630cfe" category="section-title">Corruption des données : écritures perdues</block>
  <block id="972eab86b2aecd693914feabc5a3b65c" category="paragraph">L'un des types de corruption les plus difficiles à détecter est une écriture perdue ou mal placée. Lorsqu'une écriture est reconnue, elle doit être écrite sur le support à l'emplacement correct. La corruption des données sur place est relativement facile à détecter à l'aide d'une simple somme de contrôle stockée avec les données. Cependant, si l'écriture est simplement perdue, alors la version précédente des données peut toujours exister et le total de contrôle serait correct. Si l'écriture est placée au mauvais emplacement physique, la somme de contrôle associée sera à nouveau valide pour les données stockées, même si l'écriture a détruit d'autres données.</block>
  <block id="53830741c46fbc560962b086f582e79a" category="paragraph">La solution à ce défi est la suivante :</block>
  <block id="656d064400822ca2ffb25f52c9fc95db" category="list-text">Une opération d'écriture doit inclure des métadonnées indiquant l'emplacement où l'écriture est attendue.</block>
  <block id="37a60b1c7392a26270880a361f85db55" category="list-text">Une opération d'écriture doit inclure une sorte d'identifiant de version.</block>
  <block id="4275b2e68761baa23b112833facf4ca1" category="paragraph">Lorsque ONTAP écrit un bloc, il inclut les données à l'emplacement où ce bloc appartient. Si une lecture ultérieure identifie un bloc, mais que les métadonnées indiquent qu'il appartient à l'emplacement 123 lorsqu'il a été trouvé à l'emplacement 456, l'écriture a été déplacée.</block>
  <block id="009b13bf07c7db21c1e4769526e60694" category="paragraph">Il est plus difficile de détecter une écriture entièrement perdue. L'explication est très complexe, mais ONTAP stocke les métadonnées de façon à ce qu'une opération d'écriture entraîne des mises à jour vers deux emplacements différents sur les disques. En cas de perte d'une écriture, une lecture ultérieure des données et des métadonnées associées affiche deux identités de version différentes. Cela indique que l'écriture n'a pas été effectuée par le lecteur.</block>
  <block id="3b04a99c209a31ad69e7865ea94e5c94" category="paragraph">La corruption des écritures perdues ou déplacées est extrêmement rare. Cependant, avec la croissance continue des disques et l'expansion des jeux de données en exaoctets, le risque augmente. La détection des pertes en écriture doit être incluse dans tout système de stockage prenant en charge les charges de travail de la base de données.</block>
  <block id="e978ccc010ec4d37148d52e2fbf439dd" category="section-title">Panne de disque : RAID, RAID DP et RAID-TEC</block>
  <block id="a9fffaaf2b1b518afb56ef273736c0c2" category="paragraph">Si un bloc de données sur un disque est détecté comme étant corrompu, ou si l'ensemble du disque tombe en panne et est totalement indisponible, les données doivent être reconstituées. Cette opération est réalisée dans ONTAP à l'aide de disques de parité. Les données sont réparties sur plusieurs disques, puis des données de parité sont générées. Ces données sont stockées séparément des données d'origine.</block>
  <block id="54abdf00b7122c16619266482eb09f43" category="paragraph">ONTAP utilisait à l'origine RAID 4, qui utilise un seul lecteur de parité pour chaque groupe de lecteurs de données. Le résultat a été qu'un disque du groupe pouvait tomber en panne sans entraîner de perte de données. En cas de panne du disque de parité, aucune donnée n'a été endommagée et un nouveau disque de parité a pu être construit. En cas de panne d'un seul lecteur de données, les lecteurs restants peuvent être utilisés avec le lecteur de parité pour régénérer les données manquantes.</block>
  <block id="6d1ccb512ce2b25e53d90e6d8d459e18" category="paragraph">Lorsque les disques étaient petits, le risque statistique de défaillance simultanée de deux disques était négligeable. Avec l'augmentation des capacités des disques, la reconstruction des données suite à une panne disque s'est également accompagnée d'un temps considérable. Cela a augmenté la fenêtre au cours de laquelle une panne de second disque entraînerait la perte de données. De plus, le processus de reconstruction crée une grande quantité d'E/S supplémentaires sur les disques survivants. Au fur et à mesure du vieillissement des disques, le risque d'une charge supplémentaire entraînant une panne de second disque augmente également. Enfin, même si le risque de perte de données n'augmente pas avec l'utilisation continue de RAID 4, les conséquences de la perte de données deviendront plus graves. Plus la perte de données en cas de panne d'un groupe RAID est importante, plus la restauration des données est longue, ce qui entraîne une interruption de l'activité prolongée.</block>
  <block id="caef9e75bcd55d5a9a4ec855b5a6385c" category="paragraph">Ces problèmes ont conduit NetApp à développer la technologie NetApp RAID DP, une variante de RAID 6. Cette solution comprend deux disques de parité, ce qui signifie que deux disques d'un groupe RAID peuvent tomber en panne sans générer de perte de données. Les disques ont continué de croître en taille, ce qui a conduit NetApp à développer la technologie NetApp RAID-TEC, qui introduit un troisième disque de parité.</block>
  <block id="704c2697ee323569003b7b7ea203ae0f" category="paragraph">Certaines meilleures pratiques en matière de bases de données historiques recommandent l'utilisation de RAID-10, également appelée mise en miroir par bandes. Cela offre une protection des données inférieure à celle de RAID DP, car il existe plusieurs scénarios de défaillance de deux disques, alors que dans RAID DP, il n'en existe aucune.</block>
  <block id="3d0147402d7506d1d3a5227fe447427a" category="paragraph">Par ailleurs, certaines bonnes pratiques en matière d'historique de bases de données indiquent que RAID-10 est préféré aux options RAID-4/5/6 en raison de problèmes de performances. Ces recommandations font parfois référence à une pénalité RAID. Bien que ces recommandations soient généralement correctes, elles ne s'appliquent pas aux implémentations de RAID dans ONTAP. Le problème de performances est lié à la régénération de parité. Dans les implémentations RAID traditionnelles, le traitement des écritures aléatoires de routine effectuées par une base de données nécessite plusieurs lectures de disque pour régénérer les données de parité et terminer l'écriture. La pénalité est définie comme les IOPS de lecture supplémentaires requises pour exécuter les opérations d'écriture.</block>
  <block id="84ff015d2df40fc0ebb34485173f39e4" category="paragraph">ONTAP n'engendre pas de pénalité RAID, car les écritures sont placées dans la mémoire où la parité est générée, puis écrites sur le disque sous la forme d'une seule bande RAID. Aucune lecture n'est requise pour terminer l'opération d'écriture.</block>
  <block id="b7fe11ecbd8b434a231195335b4894ac" category="paragraph">En résumé, par rapport à RAID 10, les systèmes RAID DP et RAID-TEC fournissent une capacité utilisable nettement plus importante, une meilleure protection contre les pannes disque et sans sacrifier les performances.</block>
  <block id="e5e0dc0629a299f8e56ebe7de38f49f9" category="section-title">Protection contre les pannes matérielles : NVRAM</block>
  <block id="1db5fde40e489d805029f9d5be6375e7" category="paragraph">Toute baie de stockage servant de charge de travail de base de données doit traiter les opérations d'écriture le plus rapidement possible. En outre, une opération d'écriture doit être protégée contre la perte d'un événement inattendu tel qu'une coupure de courant. Cela signifie que toute opération d'écriture doit être stockée en toute sécurité dans au moins deux emplacements.</block>
  <block id="ff540b857af868ec85f8f53ddc1f1bd1" category="paragraph">Les systèmes AFF et FAS utilisent la mémoire NVRAM pour répondre à ces exigences. Le processus d'écriture fonctionne comme suit :</block>
  <block id="049f2df0de743a6be8d3ec69864f234a" category="list-text">Les données d'écriture entrantes sont stockées dans la mémoire RAM.</block>
  <block id="976be2293c2f4499d079224003644acf" category="list-text">Les modifications à apporter aux données du disque sont journalisées dans la mémoire NVRAM sur le nœud local et le nœud partenaire. La mémoire NVRAM n'est pas un cache d'écriture. Il s'agit plutôt d'un journal similaire à un redo log de base de données. Dans des conditions normales, il n'est pas lu. Il est utilisé uniquement pour la restauration, par exemple après une coupure de courant pendant le traitement des E/S.</block>
  <block id="8ae87ed4a421bec56e020cd0e83bd748" category="list-text">L'écriture est alors validée par l'hôte.</block>
  <block id="3a7682bcbb490353074b5ee69e18f01c" category="paragraph">À ce stade, le processus d'écriture est complet du point de vue de l'application. Les données sont protégées contre les pertes, car elles sont stockées dans deux emplacements différents. Finalement, les modifications sont écrites sur le disque, mais ce processus est hors bande du point de vue de l'application, car il se produit après l'acquittement de l'écriture et n'affecte donc pas la latence. Ce processus est une fois de plus similaire à la journalisation de la base de données. Une modification de la base de données est enregistrée dans les journaux de reprise aussi rapidement que possible, et la modification est alors reconnue comme validée. Les mises à jour des fichiers de données sont effectuées beaucoup plus tard et n'affectent pas directement la vitesse de traitement.</block>
  <block id="c17f09622da5f1e0064f7b6a65cb8b01" category="paragraph">En cas de panne de contrôleur, le contrôleur partenaire prend possession des disques requis et lit à nouveau les données consignées dans la mémoire NVRAM pour récupérer toutes les opérations d'E/S en cours de fonctionnement au moment de la défaillance.</block>
  <block id="24e6592d53b3bd56ed8827d2f51bb1ab" category="section-title">Protection contre les défaillances matérielles : NVFAIL</block>
  <block id="7965eb54acae120d25d0c77b012b8f90" category="paragraph">Comme nous l'avons vu précédemment, une écriture n'est pas validée tant qu'elle n'a pas été connectée à la NVRAM et à la NVRAM locales sur au moins un autre contrôleur. Cette approche évite toute panne matérielle ou de courant qui entraîne une perte des E/S à la volée En cas de panne de la mémoire NVRAM locale ou de la connectivité au partenaire de haute disponibilité, ces données à la volée ne seront plus mises en miroir.</block>
  <block id="307b6d3e63c12ada7fbcf75cdda0b574" category="paragraph">Si la mémoire NVRAM locale signale une erreur, le nœud s'arrête. Cet arrêt entraîne le basculement vers un contrôleur partenaire de haute disponibilité. Aucune donnée n'est perdue parce que le contrôleur qui connaît la défaillance n'a pas acquitté l'opération d'écriture.</block>
  <block id="6e0c6c8fe69a50581a4ac18acb2c04dd" category="paragraph">ONTAP n'autorise pas le basculement lorsque les données sont désynchronisées, sauf si le basculement est forcé. Le fait de forcer une modification des conditions de cette manière reconnaît que les données peuvent être laissées pour compte dans le contrôleur d'origine et que la perte de données est acceptable.</block>
  <block id="a3961862ed464a06ef6fa4e23935fef2" category="paragraph">Les bases de données sont particulièrement vulnérables à la corruption en cas de basculement forcé, car elles conservent de grands caches internes de données sur disque. En cas de basculement forcé, les modifications précédemment reconnues sont effectivement supprimées. Le contenu de la baie de stockage recule dans le temps et l'état du cache de la base de données ne reflète plus l'état des données sur le disque.</block>
  <block id="b46ce3019d702ee3ece327e5df990be0" category="paragraph">Afin de protéger les données de cette situation, ONTAP permet de configurer les volumes pour une protection spéciale contre les défaillances de mémoire NVRAM. Lorsqu'il est déclenché, ce mécanisme de protection entraîne l'entrée d'un volume dans un état appelé NVFAIL. Cet état entraîne des erreurs d'E/S qui entraînent l'arrêt d'une application et n'utilisent donc pas de données obsolètes. Les données ne doivent pas être perdues car une écriture reconnue doit être présente sur la matrice de stockage.</block>
  <block id="322e1f85910dfc206274f8bd58a54a9d" category="list-text">Chaque jeu de disques d'un site donné est automatiquement configuré comme un ou plusieurs groupes RAID-DP ou RAID-TEC entièrement redondants, indépendamment de l'utilisation de la mise en miroir. Les données sont ainsi protégées en permanence, même après la perte d'un site.</block>
  <block id="dee2dfce5ab0c47301b3c12970a57aa6" category="paragraph">La figure ci-dessus illustre un exemple de configuration SyncMirror. Un agrégat de 24 disques a été créé sur le contrôleur avec 12 disques à partir d'un tiroir alloué sur le site A et 12 disques à partir d'un tiroir alloué sur le site B. Les disques ont été regroupés en deux groupes RAID en miroir. Le groupe RAID 0 comprend un plex de 6 disques sur le site A mis en miroir sur un plex de 6 disques sur le site B. De même, RAID Group 1 inclut un plex de 6 disques sur le site A mis en miroir sur un plex de 6 disques sur le site B.</block>
  <block id="4fbc0abe91c0c1381d0a742f58b4e537" category="paragraph">SyncMirror est généralement utilisé pour assurer la mise en miroir à distance avec les systèmes MetroCluster, avec une copie des données sur chaque site. Il a parfois été utilisé pour fournir un niveau supplémentaire de redondance dans un seul système. Il assure en particulier la redondance au niveau du tiroir. Un tiroir disque contient déjà deux blocs d'alimentation et contrôleurs. Dans l'ensemble, il ne s'agit pas d'une simple tôlerie, mais dans certains cas, une protection supplémentaire peut être garantie. Par exemple, un client NetApp a déployé SyncMirror sur une plateforme mobile d'analytique en temps réel utilisée lors des tests automobiles. Le système a été séparé en deux racks physiques alimentés par des alimentations indépendantes provenant de systèmes UPS indépendants.</block>
  <block id="95a3cc99b05998d49d8e035b994815bc" category="paragraph">==sommes de contrôle</block>
  <block id="0cac56685de94a3ef0e1fd2bfca0c112" category="paragraph">Le thème des checksums est particulièrement intéressant pour les administrateurs de bases de données habitués à l'utilisation de sauvegardes en continu Oracle RMAN qui migrent vers des sauvegardes basées sur des snapshots. RMAN permet notamment de procéder à des contrôles d'intégrité lors des opérations de sauvegarde. Bien que cette fonctionnalité présente un certain intérêt, son principal avantage est une base de données qui n'est pas utilisée sur une baie de stockage moderne. Lorsque des disques physiques sont utilisés pour une base de données Oracle, il est presque certain que la corruption finit par se produire lorsque les disques vieillissent, un problème qui est résolu par les checksums basés sur les baies dans les baies de stockage réelles.</block>
  <block id="58d7088c13cf2013ef373d85e3c27de7" category="paragraph">Avec une baie de stockage réelle, l'intégrité des données est protégée par des checksums à plusieurs niveaux. Si les données sont corrompues dans un réseau IP, la couche TCP (transmission Control Protocol) rejette les données de paquets et demande la retransmission. Le protocole FC inclut des checksums, tout comme les données SCSI encapsulées. Une fois sur la matrice, ONTAP dispose d'une protection RAID et checksum. Une corruption peut se produire, mais, comme dans la plupart des baies d'entreprise, elle est détectée et corrigée. En général, un disque entier tombe en panne, ce qui invite à une reconstruction RAID et l'intégrité de la base de données n'est pas affectée. Moins souvent, ONTAP détecte une erreur de somme de contrôle, ce qui signifie que les données du disque sont endommagées. Le disque est ensuite mis hors service et la reconstruction RAID démarre. Là encore, l'intégrité des données n'est pas affectée.</block>
  <block id="8b7b33533c2b36c157a0a482bdd52a8e" category="paragraph">L'architecture des fichiers de données et des redo log Oracle est également conçue pour offrir le plus haut niveau possible d'intégrité des données, même dans des circonstances extrêmes. Au niveau le plus élémentaire, les blocs Oracle incluent un checksum et des contrôles logiques de base avec presque toutes les E/S. Si Oracle ne s'est pas écrasé ou n'a pas mis un tablespace hors ligne, les données sont intactes. Le degré de vérification de l'intégrité des données est réglable et Oracle peut également être configuré pour confirmer les écritures. Par conséquent, la quasi-totalité des scénarios de panne et de panne peuvent être restaurés, et dans le cas extrêmement rare d'une situation irrécupérable, la corruption est rapidement détectée.</block>
  <block id="4066c36b811913c85aa86346e30cee4d" category="paragraph">La plupart des clients NetApp qui utilisent des bases de données Oracle cessent d'utiliser RMAN et d'autres produits de sauvegarde après la migration vers des sauvegardes snapshot. Il existe encore des options permettant d'utiliser RMAN pour effectuer une restauration au niveau des blocs avec SnapCenter. Toutefois, au quotidien, RMAN, NetBackup et d'autres produits ne sont utilisés qu'occasionnellement pour créer des copies d'archivage mensuelles ou trimestrielles.</block>
  <block id="d0cf0e689669c61d564607d2ef7deb79" category="paragraph">Certains clients choisissent d'exécuter<block ref="d308cbfce7e270e5b41a84d84385645f" prefix=" " category="inline-code"></block> périodiquement pour effectuer des contrôles d'intégrité sur leurs bases de données existantes. NetApp déconseille cette pratique, car elle entraîne une charge d'E/S inutile. Comme indiqué ci-dessus, si la base de données ne rencontrait pas de problèmes auparavant, le risque de<block ref="d308cbfce7e270e5b41a84d84385645f" prefix=" " category="inline-code"></block> La détection d'un problème est proche de zéro et cet utilitaire entraîne une charge d'E/S séquentielles très élevée sur le réseau et le système de stockage. À moins qu'il n'y ait de raison de croire qu'il existe une corruption, comme l'exposition à un bogue connu d'Oracle, il n'y a aucune raison de s'exécuter<block ref="d308cbfce7e270e5b41a84d84385645f" prefix=" " category="inline-code"></block>.</block>
  <block id="db97518eeb3e040b5a78c451efd4b252" category="summary">Sauvegarde optimisée pour les snapshots</block>
  <block id="431bbcf828b8d3513280cb1207824991" category="doc">Sauvegardes optimisées pour Oracle Storage Snapshot</block>
  <block id="52fb042c0d82d8e7bdf9ae239c387729" category="paragraph">Dans Oracle 12c, la sauvegarde et la restauration basées sur des snapshots sont simplifiées, car il n'est pas nécessaire de placer une base de données en mode de sauvegarde à chaud. Il est possible de planifier des sauvegardes Snapshot directement sur un système de stockage et d'effectuer des restaurations complètes ou à un point dans le temps.</block>
  <block id="c9447fe684870cf68e9cb4f23f44db43" category="paragraph">Les administrateurs de bases de données maîtrisent mieux la procédure de restauration à partir d'une sauvegarde à chaud, mais il est depuis longtemps possible d'utiliser des snapshots qui n'ont pas été créés pendant que la base de données était en mode de sauvegarde à chaud. Pour assurer la cohérence de la base de données, des étapes manuelles supplémentaires ont été nécessaires avec Oracle 10g et 11g. Avec Oracle 12c,<block ref="a84f4f3da79386c29ab6dfa560af786e" prefix=" " category="inline-code"></block> et<block ref="075b7d3bd3bbe7767f7ef62f430bc22b" prefix=" " category="inline-code"></block> contiennent la logique supplémentaire permettant de relire les journaux d'archivage sur des sauvegardes de fichiers de données qui n'étaient pas en mode de sauvegarde à chaud.</block>
  <block id="5c7dba68615d3fa5c4c90a36dab57bcb" category="paragraph">Comme nous l'avons vu précédemment, la restauration d'une sauvegarde à chaud basée sur des snapshots nécessite deux jeux de données :</block>
  <block id="50a7086972cada154c8164dc1c6b3539" category="list-text">Un Snapshot des fichiers de données créés en mode de sauvegarde</block>
  <block id="c72d009669a638aab75c21a28a2101de" category="list-text">Les journaux d'archivage générés pendant que les fichiers de données étaient en mode de sauvegarde à chaud</block>
  <block id="b8de4b1201e5595bc3de878f2bf59d9b" category="paragraph">Lors de la restauration, la base de données lit les métadonnées à partir des fichiers de données pour sélectionner les journaux d'archivage requis à des fins de restauration.</block>
  <block id="66ee0a6fd90f3cfab8320e1de1341cbd" category="paragraph">La restauration optimisée pour les snapshots de stockage nécessite des jeux de données légèrement différents pour obtenir les mêmes résultats :</block>
  <block id="6030a1d9761fca3806ef0a0329438071" category="list-text">Un Snapshot des fichiers de données et une méthode d'identification de l'heure de création du Snapshot</block>
  <block id="4e822d4c19600b654f176d335c158829" category="list-text">Archiver les journaux à partir de l'heure du point de contrôle du fichier de données le plus récent jusqu'à l'heure exacte du snapshot</block>
  <block id="604432b50055c69f34df17a8ed5befb5" category="paragraph">Lors de la restauration, la base de données lit les métadonnées à partir des fichiers de données pour identifier le premier journal d'archivage requis. Il est possible d'effectuer une restauration complète ou instantanée. Lors de l'exécution d'une restauration à un point dans le temps, il est essentiel d'connaître l'heure du Snapshot des fichiers de données. Le point de restauration spécifié doit être après l'heure de création des snapshots. NetApp recommande d'ajouter au moins quelques minutes à l'heure du snapshot pour tenir compte des variations d'horloge.</block>
  <block id="08bfe39c49a2dc07b08bd2ccd77d8281" category="paragraph">Pour plus de détails, consultez la documentation d'Oracle sur la rubrique « Restauration à l'aide de l'optimisation des snapshots de stockage » disponible dans les différentes versions de la documentation d'Oracle 12c. Consultez également le document Oracle document ID Doc ID 604683.1 concernant la prise en charge des snapshots tiers par Oracle.</block>
  <block id="d22a890163762fcf7a4cb7605c29b7e6" category="section-title">Disposition des données</block>
  <block id="6a7fc1f74262f6973420f4fc849ba7f7" category="paragraph">La disposition la plus simple consiste à isoler les fichiers de données dans un ou plusieurs volumes dédiés. Ils doivent être non contaminés par tout autre type de fichier. Cela permet de s'assurer que les volumes de fichiers de données peuvent être rapidement restaurés lors d'une opération SnapRestore sans détruire un journal de reprise, un fichier de contrôle ou un journal d'archivage important.</block>
  <block id="ff6fb5d2136ab516e182f4b23f45886d" category="paragraph">LE SYSTÈME SAN présente des exigences similaires en matière d'isolation des fichiers de données dans des volumes dédiés. Avec un système d'exploitation tel que Microsoft Windows, un seul volume peut contenir plusieurs LUN de fichiers de données, chacune avec un système de fichiers NTFS. Avec d'autres systèmes d'exploitation, il existe généralement un gestionnaire de volumes logiques. Par exemple, avec Oracle ASM, l'option la plus simple consiste à limiter les groupes de disques à un volume unique pouvant être sauvegardé et restauré comme une unité. Si des volumes supplémentaires sont nécessaires pour des raisons de performance ou de gestion de la capacité, la création d'un groupe de disques supplémentaire sur le nouveau volume simplifie la gestion.</block>
  <block id="a06956ba6de69aec2dc2b015074e5821" category="paragraph">Si ces instructions sont respectées, les snapshots peuvent être planifiés directement sur ONTAP sans avoir à créer de snapshot de groupe de cohérence. En effet, les sauvegardes optimisées pour les snapshots ne nécessitent pas la sauvegarde simultanée de fichiers de données.</block>
  <block id="9e422c12420f1bd8c73e3c0f63da55e9" category="paragraph">Une complication se produit dans des situations telles qu'un groupe de disques ASM distribué sur des volumes. Dans ce cas, un snapshot de groupe de cohérence doit être réalisé pour s'assurer que les métadonnées ASM sont cohérentes sur tous les volumes constitutifs.</block>
  <block id="7a7969d6a47ed242c25f6a38f2da0e36" category="paragraph">[Remarque]Vérifiez que les fichiers spfile et passwd ASM ne se trouvent pas dans le groupe de disques hébergeant les fichiers de données. Cela interfère avec la capacité à restaurer de manière sélective les fichiers de données et uniquement les fichiers de données.</block>
  <block id="12eb3ceede91a01c74368e0fab03dbe4" category="section-title">Procédure de restauration locale : NFS</block>
  <block id="e1a03fcc478ae212f07b5044b11ff369" category="paragraph">Cette procédure peut être conduite manuellement ou via une application telle que SnapCenter. La procédure de base est la suivante :</block>
  <block id="abb0083d6ab87bbe9d906632fea121ae" category="list-text">Restaurez le ou les volumes de fichiers de données sur l'instantané immédiatement avant le point de restauration souhaité.</block>
  <block id="3450fe1e1eea00fa55cfb5cb835a3d80" category="paragraph">Cette procédure suppose que les journaux d'archive souhaités sont toujours présents dans le système de fichiers actif. Si ce n'est pas le cas, les journaux d'archive doivent être restaurés, ou<block ref="075b7d3bd3bbe7767f7ef62f430bc22b" prefix=" " category="inline-code"></block> ou<block ref="a84f4f3da79386c29ab6dfa560af786e" prefix=" " category="inline-code"></block> peut être dirigé vers les données dans le<block ref="a15da8cecb1f1192c4d913b8ba676121" prefix=" " category="inline-code"></block> répertoire.</block>
  <block id="e43e33171833b26f6b024d28cb8b1afd" category="paragraph">En outre, dans le cas de bases de données plus petites, l'utilisateur peut restaurer les fichiers de données directement à partir du système<block ref="a15da8cecb1f1192c4d913b8ba676121" prefix=" " category="inline-code"></block> Répertoire n'ayant pas besoin des outils d'automatisation ou d'un administrateur du stockage pour exécuter une commande SnapRestore.</block>
  <block id="097230f6ad5345abbe261eabbf533a68" category="section-title">Procédure de restauration locale—SAN</block>
  <block id="4e3110543ebf2a771c16b3b2101f1f88" category="list-text">Arrêter le ou les groupes de disques hébergeant les fichiers de données. La procédure varie en fonction du gestionnaire de volumes logiques choisi. Avec ASM, le processus nécessite de démonter le groupe de disques. Sous Linux, les systèmes de fichiers doivent être démontés et les volumes logiques et les groupes de volumes désactivés. L'objectif est d'arrêter toutes les mises à jour du groupe de volumes cible à restaurer.</block>
  <block id="1d0ecd206531f96737f8e8002be4a047" category="list-text">Restaurez les groupes de disques de fichiers de données sur l'instantané immédiatement avant le point de restauration souhaité.</block>
  <block id="946fe41f610ab658e270a1844c992bcc" category="list-text">Réactivez les groupes de disques récemment restaurés.</block>
  <block id="c21d8f41541fc2a0259e7ea5e51edac3" category="paragraph">Cette procédure suppose que les journaux d'archive souhaités sont toujours présents dans le système de fichiers actif. Si ce n'est pas le cas, les journaux d'archivage doivent être restaurés en mettant les LUN du journal d'archivage hors ligne et en effectuant une restauration. Il s'agit également d'un exemple dans lequel il est utile de diviser les journaux d'archivage en volumes dédiés. Si les journaux d'archivage partagent un groupe de volumes avec les journaux de reprise, les journaux de reprise doivent être copiés ailleurs avant la restauration de l'ensemble global de LUN afin d'éviter de perdre les transactions enregistrées finales.</block>
  <block id="3fd5b2a08b3d7c4db29da8590ef6013f" category="section-title">Exemple de récupération complète</block>
  <block id="31679daa394b7091acfd728d940b7322" category="paragraph">Supposons que les fichiers de données ont été corrompus ou détruits et qu'une restauration complète est requise. La procédure à suivre est la suivante :</block>
  <block id="aa09ca247daac25fc18c2633124ca9b6" category="section-title">Exemple de restauration instantanée</block>
  <block id="935ff627038d1f5001220c8df7f0e1b9" category="paragraph">Toute la procédure de restauration est une commande unique :<block ref="3df448f0a5ec82cac76d91ba14c0fa1d" prefix=" " category="inline-code"></block>.</block>
  <block id="dcd27cf8b8ceae2cd84c898d3c1b9fdb" category="paragraph">Si une restauration à un point dans le temps est requise, l'horodatage des snapshots doit être connu et peut être identifié comme suit :</block>
  <block id="17108ef3ad2e1e613b844beb5f2c6d29" category="paragraph">L'heure de création de l'instantané est répertoriée comme 9 mars et 10:10:06. Pour être sûr, une minute est ajoutée à l'heure du snapshot :</block>
  <block id="904b0a17b003c70e398ea85996f0f9ba" category="paragraph">La restauration est maintenant lancée. Il a spécifié une heure d'instantané de 10:11:00, une minute après l'heure enregistrée pour tenir compte de la variation d'horloge possible, et un temps de récupération cible de 10:44. Ensuite, sqlplus demande les journaux d'archivage requis pour atteindre le délai de restauration souhaité de 10:44.</block>
  <block id="91f99c5ad04365fb4d00e509963e2a0c" category="admonition">Restauration complète d'une base de données à l'aide de snapshots à l'aide de<block ref="3df448f0a5ec82cac76d91ba14c0fa1d" prefix=" " category="inline-code"></block> la commande ne nécessite pas de licence spécifique, mais une restauration à un point dans le temps via<block ref="72104026d9850e8c478c23b2e2e4e8e9" prefix=" " category="inline-code"></block> Requiert la licence Oracle Advanced compression.</block>
  <block id="87161b635cff9308859c719a20929913" category="summary">Outils de sauvegarde Oracle et NetApp</block>
  <block id="9173402b63dc5f55506a692258f185e8" category="doc">SnapCenter et autres outils</block>
  <block id="400937771ac8b3d4e7be82bf39033db5" category="paragraph">La valeur principale de ONTAP dans un environnement applicatif provient des principales technologies ONTAP telles que les copies Snapshot instantanées, la réplication simple de SnapMirror et la création efficace de volumes FlexClone.</block>
  <block id="5459c1727c923baa303ff472498dbe97" category="paragraph">Dans certains cas, une configuration simple de ces fonctionnalités principales directement sur ONTAP répond aux exigences, mais les besoins plus complexes requièrent une couche d'orchestration.</block>
  <block id="aeeb3212c35c26d321183e81d4926e57" category="paragraph">SnapCenter est le produit phare de la protection des données NetApp. À un niveau très bas, il est similaire aux produits SnapManager en termes d'exécution des sauvegardes de base de données, mais il a été conçu dès le départ pour proposer une gestion de la protection des données centralisée sur les systèmes de stockage NetApp.</block>
  <block id="e538db970e1ed1ffe018725fdf223f9e" category="paragraph">SnapCenter inclut les fonctions de base telles que les sauvegardes et restaurations basées sur des copies Snapshot, SnapMirror et la réplication SnapVault, ainsi que d'autres fonctionnalités nécessaires pour fonctionner à grande échelle dans les grandes entreprises. Ces fonctionnalités avancées incluent un contrôle d'accès basé sur des rôles (RBAC) étendu, des API RESTful pour l'intégration de produits d'orchestration tiers, une gestion centralisée et sans interruption des plug-ins SnapCenter sur des hôtes de base de données et une interface utilisateur conçue pour les environnements à l'échelle du cloud.</block>
  <block id="50780f47f6839d47d60bc4555ee00c3f" category="section-title">REPOS</block>
  <block id="a0bac638f30c704da8e03aba136da86d" category="paragraph">ONTAP contient également un jeu d'API RESTful riche. Les fournisseurs tiers peuvent ainsi créer une application de protection des données et de gestion grâce à une intégration étroite avec ONTAP. De plus, l'API RESTful est facile à utiliser par les clients qui souhaitent créer leurs propres workflows et utilitaires d'automatisation.</block>
  <block id="e4cea644160fe9fa4ccd92ab3f079363" category="summary">Sauvegardes et restaurations basées sur des snapshots Oracle</block>
  <block id="9adc36f162691b8ed14a886b6068f368" category="doc">Sauvegardes Oracle en ligne</block>
  <block id="a3b43ae3d4028e3c7ccac3d5720e9fb0" category="paragraph">Deux datasets sont nécessaires pour protéger et restaurer une base de données Oracle en mode de sauvegarde. Notez qu'il ne s'agit pas de la seule option de sauvegarde Oracle, mais qu'elle est la plus courante.</block>
  <block id="8e523970ff7c41dba74e723511d14717" category="list-text">Un Snapshot des fichiers de données en mode de sauvegarde</block>
  <block id="deeddf207b1a29c63ae7c1943f90f3d9" category="list-text">Les journaux d'archivage créés pendant que les fichiers de données étaient en mode de sauvegarde</block>
  <block id="fa1229103a2e02a4ed8790098c98f71f" category="paragraph">Si une récupération complète incluant toutes les transactions validées est requise, un troisième élément est requis :</block>
  <block id="7c11b244c2549a2cc477c134ec4c5635" category="list-text">Les journaux de reprise en cours</block>
  <block id="8522faf14bc9d4ab497945bb48adc870" category="paragraph">Il existe plusieurs façons de restaurer une sauvegarde en ligne. De nombreux clients restaurent les snapshots à l'aide de l'interface de ligne de commande ONTAP, puis à l'aide d'Oracle RMAN ou de sqlplus pour terminer la restauration. Cette approche est particulièrement fréquente dans les environnements de production de grande taille. En effet, la probabilité et la fréquence des restaurations de bases de données sont extrêmement faibles et les restaurations sont gérées par un administrateur de bases de données qualifié. Pour une automatisation totale, des solutions telles que NetApp SnapCenter intègrent un plug-in Oracle avec une ligne de commande et des interfaces graphiques.</block>
  <block id="f88f41d4801183a5d53a4b71f383d144" category="paragraph">Certains grands clients ont adopté une approche plus simple en configurant des scripts de base sur les hôtes afin de placer les bases de données en mode de sauvegarde à un moment spécifique en préparation d'un snapshot planifié. Par exemple, planifiez la commande<block ref="56f72994c4cc84b13a4c20dab49fea35" prefix=" " category="inline-code"></block> à 23:58,<block ref="84c8391d82cbfe300a9615844e0a167f" prefix=" " category="inline-code"></block> à 00:02, puis planifiez les snapshots directement sur le système de stockage à minuit. Résultat : une stratégie de sauvegarde simple et hautement évolutive ne nécessite aucun logiciel ni licence externe.</block>
  <block id="719fbeb74939b8c065321f175de3d222" category="paragraph">La disposition la plus simple consiste à isoler les fichiers de données dans un ou plusieurs volumes dédiés. Ils doivent être non contaminés par tout autre type de fichier. Cela permet de s'assurer que les volumes de fichiers de données peuvent être rapidement restaurés via une opération SnapRestore sans détruire un journal de reprise, un fichier de contrôle ou un journal d'archivage important.</block>
  <block id="19156bdcbf322e8e3189909bbb7a69e8" category="paragraph">LE SYSTÈME SAN présente des exigences similaires en matière d'isolation des fichiers de données dans des volumes dédiés. Avec un système d'exploitation tel que Microsoft Windows, un seul volume peut contenir plusieurs LUN de fichiers de données, chacune avec un système de fichiers NTFS. Avec d'autres systèmes d'exploitation, il existe généralement un gestionnaire de volumes logiques. Par exemple, avec Oracle ASM, l'option la plus simple consiste à limiter les LUN d'un groupe de disques ASM à un seul volume pouvant être sauvegardé et restauré en tant qu'unité. Si des volumes supplémentaires sont nécessaires pour des raisons de performance ou de gestion de la capacité, la création d'un groupe de disques supplémentaire sur le nouveau volume simplifie la gestion.</block>
  <block id="993afa8643b7200c5c9e527c24c1d8b2" category="paragraph">Si ces instructions sont respectées, les snapshots peuvent être planifiés directement sur le système de stockage sans avoir à créer de snapshot de groupe de cohérence. En effet, les sauvegardes Oracle ne nécessitent pas la sauvegarde simultanée de fichiers de données. La procédure de sauvegarde en ligne a été conçue pour assurer la mise à jour des fichiers de données, qui seront ensuite transmis progressivement sur bande en quelques heures.</block>
  <block id="a2ea5ea024e4a68e4d7f4abeca3441a1" category="paragraph">Une complication se produit dans des situations telles que l'utilisation d'un groupe de disques ASM distribué sur des volumes. Dans ce cas, un snapshot de groupe de cohérence doit être réalisé pour s'assurer que les métadonnées ASM sont cohérentes sur tous les volumes constitutifs.</block>
  <block id="0a3ecb97c1b7c97e5075bae0daaa45aa" category="paragraph">*Attention :* Vérifiez que l'ASM<block ref="1737629d60b511cf45957529a8f046e2" prefix=" " category="inline-code"></block> et<block ref="76a2173be6393254e72ffa4d6df1030a" prefix=" " category="inline-code"></block> les fichiers ne se trouvent pas dans le groupe de disques hébergeant les fichiers de données. Cela interfère avec la capacité à restaurer de manière sélective les fichiers de données et uniquement les fichiers de données.</block>
  <block id="2f8a5e254c86a42ebcc8b7d3c84cd22e" category="paragraph">Cette procédure suppose que les journaux d'archive souhaités sont toujours présents dans le système de fichiers actif. Si ce n'est pas le cas, les journaux d'archivage doivent être restaurés ou rman/sqlplus peut être dirigé vers les données du répertoire d'instantanés.</block>
  <block id="a67a69f712a877950e94edd27310b40e" category="paragraph">En outre, dans le cas de bases de données plus petites, l'utilisateur peut restaurer les fichiers de données directement à partir du système<block ref="a15da8cecb1f1192c4d913b8ba676121" prefix=" " category="inline-code"></block> répertoire n'ayant pas besoin des outils d'automatisation ou des administrateurs de stockage pour exécuter une<block ref="a4c0ce4da6fb04943b499690fb3afd6e" prefix=" " category="inline-code"></block> commande.</block>
  <block id="6da8ebf3245e4fbe4654e7f92f0330d7" category="list-text">Arrêter le ou les groupes de disques hébergeant les fichiers de données. La procédure varie en fonction du gestionnaire de volumes logiques choisi. Avec ASM, le processus nécessite de démonter le groupe de disques. Sous Linux, les systèmes de fichiers doivent être démontés et les volumes logiques et les groupes de volumes doivent être désactivés. L'objectif est d'arrêter toutes les mises à jour du groupe de volumes cible à restaurer.</block>
  <block id="931ab211ac6773d20c03a998f9f921ce" category="list-text">Relire tous les journaux de reprise si vous souhaitez procéder à une restauration complète.</block>
  <block id="b6575c3fca5eaaa56eeb8e9ce8867f05" category="paragraph">Cette procédure suppose que les journaux d'archive souhaités sont toujours présents dans le système de fichiers actif. Si ce n'est pas le cas, les journaux d'archivage doivent être restaurés en mettant les LUN du journal d'archivage hors ligne et en effectuant une restauration. Il s'agit également d'un exemple dans lequel il est utile de diviser les journaux d'archivage en volumes dédiés. Si les journaux d'archivage partagent un groupe de volumes avec les journaux de reprise, les journaux de reprise doivent être copiés ailleurs avant la restauration de l'ensemble global des LUN. Cette étape empêche la perte de ces transactions finales enregistrées.</block>
  <block id="1536f0d3e3ee227abdec76f432b89cae" category="summary">SLA de protection des données Oracle</block>
  <block id="e9c8b7044dfae7a21f1a9c4d08628a66" category="doc">Objectif de délai de restauration, objectif de point de récupération et accords de niveau de service</block>
  <block id="020e620c60ad38b75f0ff2a2fe4067b0" category="paragraph">Une stratégie de protection des données doit être définie par les exigences de l'entreprise.</block>
  <block id="65fd6f7f97414140b4d6060b743dc645" category="paragraph">Ces exigences comprennent des facteurs tels que la vitesse de restauration, la perte de données maximale autorisée et les besoins de conservation des sauvegardes. Le plan de protection des données doit également tenir compte de diverses exigences réglementaires en matière de conservation et de restauration des données. Enfin, différents scénarios de restauration des données doivent être pris en compte, allant de la restauration classique et prévisible résultant d'erreurs d'utilisateurs ou d'applications à des scénarios de reprise sur incident incluant la perte complète d'un site.</block>
  <block id="2bd1d35ff88de136066c33905c0fd677" category="paragraph">Les modifications mineures apportées aux règles de protection et de restauration des données peuvent avoir un impact significatif sur l'architecture globale du stockage, de la sauvegarde et de la restauration. Il est essentiel de définir et de documenter des normes avant de commencer le travail de conception afin d'éviter de compliquer une architecture de protection des données. Des fonctions ou des niveaux de protection inutiles entraînent des coûts et des frais de gestion inutiles. Par ailleurs, une exigence initialement négligée peut conduire un projet dans la mauvaise direction ou nécessiter des modifications de conception de dernière minute.</block>
  <block id="a60e6b87ede45aef49d8d095435db22b" category="section-title">Objectif de délai de restauration</block>
  <block id="3d3b341e14c584d1edcea9fe13619ee1" category="paragraph">L'objectif de délai de restauration (RTO) définit le temps maximal autorisé pour la restauration d'un service. Par exemple, une base de données de ressources humaines peut atteindre un objectif de délai de restauration de 24 heures. En effet, même s'il ne serait pas très pratique de perdre l'accès à ces données pendant les jours de travail, l'entreprise peut tout de même fonctionner. En revanche, une base de données prenant en charge le grand livre d'une banque aurait un RTO mesuré en minutes, voire en secondes. Un objectif RTO de zéro n'est pas possible, car il doit y avoir un moyen de faire la différence entre une panne de service réelle et un événement de routine tel qu'un paquet réseau perdu. Toutefois, un objectif RTO quasi nul est généralement requis.</block>
  <block id="5a27873285a0397cc06f9f47280c9426" category="section-title">Objectif de point de récupération</block>
  <block id="f3ae061e139f47d793058ee596a5243f" category="paragraph">L'objectif de point de récupération (RPO) définit la perte de données maximale tolérable. Dans de nombreux cas, l'objectif de point de récupération est uniquement déterminé par la fréquence des copies Snapshot ou des mises à jour snapmirror.</block>
  <block id="2d68fbd3cefeb34bfd64c8f89caba64d" category="paragraph">Dans certains cas, le RPO peut être rendu plus agressif, car il permet de protéger certaines données de manière sélective plus fréquemment. Dans un contexte de base de données, le RPO correspond généralement à la quantité de données perdues dans un journal spécifique. Dans un scénario de restauration typique dans lequel une base de données est endommagée en raison d'un bogue de produit ou d'une erreur utilisateur, le RPO doit être égal à zéro, ce qui signifie qu'il ne doit pas y avoir de perte de données. La procédure de restauration implique la restauration d'une copie antérieure des fichiers de base de données, puis la relecture des fichiers journaux pour ramener l'état de la base de données au point dans le temps souhaité. Les fichiers journaux requis pour cette opération doivent déjà être en place à l'emplacement d'origine.</block>
  <block id="57df8b025934bcd0f7e96bae19cf0688" category="paragraph">Dans des scénarios inhabituels, les données des journaux peuvent être perdues. Par exemple, un accident ou un acte malveillant<block ref="4609acba202877f99742342f4195d95e" prefix=" " category="inline-code"></block> des fichiers de base de données peuvent entraîner la suppression de toutes les données. La seule option serait de restaurer des données à partir de sauvegardes, y compris des fichiers journaux, et certaines seraient inévitablement perdues. Dans un environnement de sauvegarde classique, la seule option permettant d'améliorer le RPO consiste à effectuer des sauvegardes répétées des données du journal. Cela a toutefois ses limites en raison du déplacement constant des données et de la difficulté à maintenir un système de sauvegarde en tant que service en continu. L'un des avantages des systèmes de stockage avancés est la capacité à protéger les données contre les dommages accidentels ou malveillants aux fichiers et à fournir ainsi un meilleur RPO sans déplacement des données.</block>
  <block id="3d08c71e26ac92e34925e02570c4bd22" category="paragraph">La reprise après incident comprend l'architecture INFORMATIQUE, les règles et les procédures requises pour restaurer un service en cas d'incident physique. Cela peut inclure les inondations, les incendies ou les personnes agissant avec une intention malveillante ou négligente.</block>
  <block id="78f4e749ec0c6bb2627abbbc00bce296" category="paragraph">La reprise sur incident est bien plus qu'un ensemble de procédures de restauration. Il s'agit du processus complet d'identification des différents risques, de définition des exigences en matière de restauration des données et de continuité des services, et de mise à disposition de l'architecture appropriée avec les procédures associées.</block>
  <block id="75bcd60b234aba82b5827cd7a5171563" category="paragraph">Lors de l'établissement des exigences de protection des données, il est essentiel de faire la différence entre les objectifs RPO et RTO types et les exigences RPO et RTO requises pour la reprise après incident. Pour les situations de perte de données, allant d'une erreur utilisateur relativement normale à un incendie qui détruit un data Center, certains environnements applicatifs nécessitent un RPO nul et un RTO quasi nul. Cependant, il y a des conséquences administratives et des coûts pour ces niveaux élevés de protection.</block>
  <block id="756651fea87d05811d7a42451d074b60" category="paragraph">En général, les exigences de restauration des données non liées aux incidents doivent être strictes pour deux raisons. Tout d'abord, les bogues d'application et les erreurs d'utilisateur qui endommagent les données sont prévisibles au point qu'ils sont presque inévitables. Deuxièmement, il n'est pas difficile de concevoir une stratégie de sauvegarde capable de fournir un RPO nul et un RTO faible tant que le système de stockage n'est pas détruit. Il n'y a aucune raison de ne pas traiter un risque important facilement résolu. C'est pourquoi les objectifs RPO et RTO pour la reprise locale doivent être agressifs.</block>
  <block id="cb6faee28dd34d25f06bd0b33abe1c2f" category="paragraph">Les exigences en termes de RTO et de RPO pour la reprise d'activité varient plus largement en fonction du risque d'incident et des conséquences de la perte de données ou de l'interruption pour une entreprise. Les exigences en matière de RPO et de RTO doivent être basées sur les besoins réels de l'entreprise et non sur des principes généraux. Ils doivent prendre en compte plusieurs scénarios de catastrophe physique et logique.</block>
  <block id="68f31611fc8a5e6a20793905280a7001" category="section-title">Incidents logiques</block>
  <block id="07f5727077caaf8dedf895542181d26b" category="paragraph">Les incidents logiques incluent la corruption des données provoquée par les utilisateurs, les bogues des applications ou du système d'exploitation et les dysfonctionnements logiciels. Les incidents logiques peuvent également inclure des attaques malveillantes de tiers contenant des virus ou des vers, ou encore en exploitant les vulnérabilités des applications. Dans ces cas, l'infrastructure physique n'est pas endommagée, mais les données sous-jacentes ne sont plus valides.</block>
  <block id="3cb5ee5f24e42f56ba6dac48b7b046d2" category="paragraph">Les ransomwares sont un type de catastrophe logique de plus en plus courant qui sert à chiffrer les données à l'aide d'un vecteur d'attaque. Le chiffrement n'endommage pas les données, mais il les rend indisponibles jusqu'à ce que le paiement soit effectué à un tiers. De plus en plus d'entreprises sont spécifiquement la cible de piratage. Face à cette menace, NetApp propose des snapshots inviolables où même l'administrateur du stockage ne peut pas modifier les données protégées avant la date d'expiration configurée.</block>
  <block id="91c87f53ce0a1f416308a67ce119c623" category="section-title">Incidents physiques</block>
  <block id="79055ca11f54a97d22617a656eab8b9b" category="paragraph">Les incidents physiques incluent la défaillance de composants d'une infrastructure qui dépasse ses capacités de redondance et entraînent une perte de données ou une perte de service prolongée. Par exemple, la protection RAID assure la redondance des disques durs et l'utilisation de HBA assure la redondance des ports FC et des câbles FC. Les pannes matérielles de ces composants sont prévisibles et n'ont pas d'incidence sur la disponibilité.</block>
  <block id="3f7c55fe5f35f94cd2c4bd73b9cbb11b" category="paragraph">Dans un environnement d'entreprise, il est généralement possible de protéger l'infrastructure d'un site entier avec des composants redondants au point où le seul scénario de catastrophe physique prévisible est la perte complète du site. La planification de la reprise d'activité dépend alors de la réplication de site à site.</block>
  <block id="7f3dd7bdd41f7af6853732a383bbd7e2" category="section-title">Protection des données synchrone et asynchrone</block>
  <block id="c5ac17d5693914368f39b40a07af23d4" category="paragraph">Dans l'idéal, toutes les données seraient répliquées de manière synchrone sur des sites dispersés géographiquement. Une telle réplication n'est pas toujours possible, voire possible pour plusieurs raisons :</block>
  <block id="28c59a675d03e1f62a48958bb53ae523" category="list-text">La réplication synchrone entraîne inévitablement une augmentation de la latence d'écriture, car toutes les modifications doivent être répliquées vers les deux emplacements avant que l'application/la base de données ne puisse poursuivre le traitement. L'effet de performance qui en résulte est parfois inacceptable, excluant l'utilisation de la mise en miroir synchrone.</block>
  <block id="50a05ceeb998c4dac7e8b5d706fe2029" category="list-text">En raison de l'adoption accrue de 100 % de stockage SSD, il est plus probable que l'on remarque une latence d'écriture supplémentaire, car les attentes en termes de performances comprennent des centaines de milliers d'IOPS et une latence inférieure à la milliseconde. Pour tirer pleinement parti de l'utilisation de 100 % des SSD, il peut être nécessaire de revoir la stratégie de reprise sur incident.</block>
  <block id="04d90fe6288ce6cceba54a2b71e55727" category="list-text">La croissance des datasets en octets continue, ce qui engendre des défis en garantissant une bande passante suffisante pour soutenir la réplication synchrone.</block>
  <block id="d3aaae220bd5b3d68dd4ccec3bf78197" category="list-text">La croissance des datasets s'accompagne également de défis liés à la gestion de la réplication synchrone à grande échelle.</block>
  <block id="c3a841e0bfc640f91b0a00c4af8c6f5c" category="list-text">Les stratégies basées sur le cloud impliquent souvent des distances de réplication et une latence plus importantes, ce qui exclut davantage l'utilisation de la mise en miroir synchrone.</block>
  <block id="7df1515e247dfa2063c433b9339c2d4a" category="paragraph">NetApp propose des solutions qui incluent à la fois la réplication synchrone pour satisfaire les besoins les plus exigeants en matière de restauration des données et des solutions asynchrones qui assurent des performances et une flexibilité accrues. De plus, la technologie NetApp s'intègre en toute transparence à de nombreuses solutions de réplication tierces, telles qu'Oracle DataGuard</block>
  <block id="4d2c802af835583121763e1a6acc3f9b" category="section-title">Durée de conservation</block>
  <block id="123dbb4c09a5c8fb993a856cf65c9d25" category="paragraph">Le dernier aspect d'une stratégie de protection des données est la durée de conservation des données, qui peut varier considérablement.</block>
  <block id="d3a424909a8559a2d076e5d9a28d834f" category="list-text">Il est généralement nécessaire d'effectuer 14 jours de sauvegardes nocturnes sur le site principal et 90 jours de sauvegardes sur un site secondaire.</block>
  <block id="1d7c2d97c3bfd5ca9489e0ffeb06b150" category="list-text">De nombreux clients créent des archives trimestrielles autonomes stockées sur différents supports.</block>
  <block id="61ae175e4a0c88c4624184a0cb9b04d2" category="list-text">Une base de données constamment mise à jour n'a peut-être pas besoin de données historiques, et les sauvegardes ne doivent être conservées que pendant quelques jours.</block>
  <block id="8bb85c2149e1e808032e7025b0a27b80" category="list-text">Pour des raisons réglementaires, une capacité de restauration peut être nécessaire au point de toute transaction arbitraire dans une fenêtre de 365 jours.</block>
  <block id="a83f7a3ea63946cbdc1977d641e8460c" category="summary">Oracle sur ONTAP et le rôle des snapshots</block>
  <block id="05280349760feacdd6227fb8012e39d7" category="doc">Sauvegardes basées sur des snapshots</block>
  <block id="5e3f0537b2a1927f4a24b28e9157cc0b" category="paragraph">La protection des données Oracle sur ONTAP repose sur la technologie Snapshot de NetApp.</block>
  <block id="a4c2aeedbfeeda21f232cbf45be91693" category="paragraph">Les valeurs clés sont les suivantes :</block>
  <block id="d06c89cff665ecdde6eded3c9d44cd2b" category="list-text">*Simplicité.* Un instantané est une copie en lecture seule du contenu d'un conteneur de données à un moment donné.</block>
  <block id="175888ba89c31a851f719bdd271cae9c" category="list-text">*Efficacité.* les instantanés ne nécessitent pas d'espace au moment de la création. L'espace n'est consommé que lorsque des données sont modifiées.</block>
  <block id="d853e9e275a6e58b3a9a56fa641cbb9f" category="list-text">*Gérabilité.* Une stratégie de sauvegarde basée sur les snapshots est facile à configurer et à gérer car les snapshots font partie intégrante du système d'exploitation du stockage. Si le système de stockage est sous tension, il est prêt à créer des sauvegardes.</block>
  <block id="b564e5fbab71af776ed54a19d09b268c" category="list-text">*Évolutivité.* vous pouvez conserver jusqu'à 1024 sauvegardes d'un seul conteneur de fichiers et de LUN. Dans le cas de jeux de données complexes, plusieurs conteneurs de données peuvent être protégés par un ensemble unique et cohérent de snapshots.</block>
  <block id="7159872a568b97a971b9ea182fb23b7c" category="list-text">Les performances ne sont pas affectées, qu'un volume contienne ou non 1024 snapshots.</block>
  <block id="1a54f7e14e6e652bb32b12df22faf387" category="paragraph">Bien que de nombreux fournisseurs de stockage proposent la technologie Snapshot, la technologie Snapshot de ONTAP est unique et offre des avantages significatifs pour les environnements applicatifs et de bases de données d'entreprise :</block>
  <block id="d77b23e355dc2f65b90fb52ed9a90f9c" category="list-text">Les copies Snapshot font partie de la WAFL (Write-Anywhere File Layout) sous-jacente. Il ne s'agit pas d'une technologie complémentaire ou externe. La gestion est donc simplifiée, car le système de stockage est le système de sauvegarde.</block>
  <block id="8b888e6a2d883c0111428c101532294a" category="list-text">Les copies Snapshot n'affectent pas les performances, sauf dans certains cas en périphérie, par exemple lorsque le volume de données est stocké dans des snapshots que le système de stockage sous-jacent se remplit.</block>
  <block id="2283ea50a243a5d1ad551f7d21f39895" category="list-text">Le terme « groupe de cohérence » fait souvent référence à un regroupement d'objets de stockage gérés comme un ensemble cohérent de données. La copie Snapshot d'un volume ONTAP donné constitue une sauvegarde de groupe de cohérence.</block>
  <block id="ac72c83a8204d600d567261b41c5488c" category="paragraph">Les copies Snapshot ONTAP ont également une meilleure évolutivité que la technologie concurrente. Les clients peuvent stocker 5, 50 ou 500 copies Snapshot sans affecter les performances. Le nombre maximal de snapshots actuellement autorisés dans un volume est de 1024. Si une conservation supplémentaire des snapshots est nécessaire, il existe des options pour les transmettre en cascade à des volumes supplémentaires.</block>
  <block id="3b7ff39ba50f1bc3f56d38c41ba51855" category="paragraph">Par conséquent, la protection d'un dataset hébergé sur ONTAP est simple et hautement évolutive. Les sauvegardes ne nécessitent pas de déplacement de données. Par conséquent, une stratégie de sauvegarde peut être adaptée aux besoins de l'entreprise plutôt qu'aux limites des taux de transfert réseau, du grand nombre de lecteurs de bande ou des zones de transfert de disque.</block>
  <block id="55c5bbb3aad88266600eaa1a526406d4" category="paragraph">La question couramment posée sur l'utilisation des snapshots en tant que stratégie de protection des données est le fait que les données « réelles » et les données de snapshot se trouvent sur les mêmes disques. La perte de ces disques entraînerait la perte des données primaires et de la sauvegarde.</block>
  <block id="68870deb35eeb53373325a314030bd11" category="paragraph">Toutefois, les snapshots locaux ne doivent jamais être la seule stratégie de sauvegarde. C'est pourquoi NetApp propose des technologies telles que la réplication SnapMirror et SnapVault pour répliquer rapidement et efficacement des copies Snapshot sur un ensemble indépendant de disques. Dans une solution bien conçue avec des snapshots et une réplication Snapshot, l'utilisation des bandes peut être réduite au minimum, voire même à une archive trimestrielle, ou totalement éliminée.</block>
  <block id="73d3fd255835ca3dc926f59d50223f91" category="paragraph">Vous pouvez utiliser les copies Snapshot ONTAP pour protéger vos données, et les copies Snapshot sont la base de nombreuses autres fonctionnalités ONTAP, notamment la réplication, la reprise d'activité et le clonage. Une description complète de la technologie Snapshot ne fait pas partie du présent document, mais les sections suivantes offrent un aperçu général.</block>
  <block id="7441577327d1d49b71cc2f6403e17e7b" category="paragraph">Il existe deux approches principales pour créer un snapshot d'un dataset :</block>
  <block id="b38ba43128207852ef5149e6c578ba89" category="list-text">Sauvegardes cohérentes après panne</block>
  <block id="dc64a2f6075820724476e435a1ebd7fa" category="list-text">Sauvegardes cohérentes au niveau des applications</block>
  <block id="7733cc553d118547b64c858cb4281f24" category="paragraph">Une sauvegarde cohérente après panne d'un dataset fait référence à la capture de l'ensemble de la structure du dataset à un point dans le temps. Si le dataset est stocké dans un seul volume NetApp FlexVol, le processus est simple ; il est possible de créer une copie Snapshot à tout moment. Si un dataset s'étend sur plusieurs volumes, un snapshot de groupe de cohérence doit être créé. Plusieurs options sont disponibles pour la création des snapshots de groupe de cohérence, notamment le logiciel NetApp SnapCenter, les fonctionnalités natives de groupe de cohérence ONTAP et les scripts gérés par l'utilisateur.</block>
  <block id="32561979f55bc68c4f028fd26a9975f6" category="paragraph">Les sauvegardes cohérentes après panne sont principalement utilisées lorsque la restauration au point de sauvegarde est suffisante. Lorsqu'une restauration plus granulaire est nécessaire, des sauvegardes cohérentes au niveau des applications sont généralement nécessaires.</block>
  <block id="367735591e5e6e04c17b7930acb29b7d" category="paragraph">Le mot "cohérent" dans "application-cohérente" est souvent un mal nommer. Par exemple, le placement d'une base de données Oracle en mode de sauvegarde est appelé sauvegarde cohérente au niveau des applications, mais les données ne sont en aucun cas rendues cohérentes ou suspendues. Les données continuent de changer tout au long de la sauvegarde. En revanche, la plupart des sauvegardes MySQL et Microsoft SQL Server ont effectivement mis les données au repos avant d'exécuter la sauvegarde. VMware peut rendre certains fichiers cohérents ou non.</block>
  <block id="ebf90723e7659cb5381545104b618612" category="paragraph">Le terme « groupe de cohérence » fait référence à la capacité d'une baie de stockage à gérer plusieurs ressources de stockage comme une seule image. Par exemple, une base de données peut comprendre 10 LUN. La baie doit pouvoir sauvegarder, restaurer et répliquer ces 10 LUN de manière cohérente. La restauration n'est pas possible si les images des LUN n'étaient pas cohérentes au point de sauvegarde. La réplication de ces 10 LUN nécessite que tous les réplicas soient parfaitement synchronisés.</block>
  <block id="3f8a43f1defaa984435092f616876545" category="paragraph">Le terme « groupe de cohérence » n'est pas souvent utilisé lors des discussions sur ONTAP, car la cohérence a toujours été une fonction de base de l'architecture de volumes et d'agrégats au sein de ONTAP. De nombreuses autres baies de stockage gèrent des LUN ou des systèmes de fichiers en tant qu'unités individuelles. Ils peuvent ensuite être configurés en tant que « groupe de cohérence » pour la protection des données, mais cette étape supplémentaire est nécessaire dans la configuration.</block>
  <block id="74e816c3c784f5c30c79dca4590d7f59" category="paragraph">ONTAP a toujours pu capturer des images locales et répliquées cohérentes de données. Bien que les différents volumes d'un système ONTAP ne soient généralement pas officiellement décrits comme des groupes de cohérence, c'est ce qu'ils sont. Une copie Snapshot de ce volume est une image de groupe de cohérence. La restauration de ce Snapshot correspond à une restauration de groupe de cohérence. SnapMirror et SnapVault proposent tous deux une réplication de groupe de cohérence.</block>
  <block id="15cc4389a08c3f4748e98622e630ad3e" category="section-title">Snapshots de groupes de cohérence</block>
  <block id="d286b747757ef3d8d3abac27bfae65f9" category="paragraph">Les copies Snapshot de groupe de cohérence (cg-snapshots) sont une extension de la technologie Snapshot ONTAP de base. Une opération de snapshot standard crée une image cohérente de toutes les données d'un même volume, mais il est parfois nécessaire de créer un ensemble cohérent de snapshots sur plusieurs volumes et même sur plusieurs systèmes de stockage. Il en résulte un ensemble de snapshots qui peuvent être utilisés de la même manière qu'un snapshot d'un seul volume individuel. Elles peuvent être utilisées pour la restauration des données locales, répliquées à des fins de reprise après incident ou clonées sous la forme d'une unité cohérente unique.</block>
  <block id="7c199465bc6344e648e2f73c88131605" category="paragraph">L'utilisation la plus connue des cg-snapshots concerne un environnement de base de données d'environ 1 po de capacité couvrant 12 contrôleurs. Les snapshots de groupe de cohérence créés sur ce système ont été utilisés pour la sauvegarde, la restauration et le clonage.</block>
  <block id="e5c199b4a97409f33d5caae984957744" category="paragraph">La plupart du temps, lorsqu'un dataset s'étend sur des volumes et que l'ordre d'écriture doit être préservé, le logiciel de gestion choisi utilise automatiquement un snapshot de groupe de cohérence. Dans ce cas, il n'est pas nécessaire de comprendre les détails techniques des cg-snapshots. Toutefois, les exigences complexes en matière de protection des données nécessitent un contrôle détaillé du processus de protection et de réplication des données. Certains workflows d'automatisation ou scripts personnalisés permettent d'appeler les API cg-Snapshot. Pour comprendre la meilleure option et le rôle de cg-snapshot, vous devez fournir une explication plus détaillée de la technologie.</block>
  <block id="cf3c30ea5c240a8aef02d240f42cdff7" category="paragraph">La création d'un ensemble de snapshots des groupes de cohérence s'effectue en deux étapes :</block>
  <block id="f30455406a91bd776afbc88e60b9697e" category="list-text">Établir une clôture d'écriture sur tous les volumes cibles.</block>
  <block id="c7afe45d94f2fd172a01e851d7f92a2f" category="list-text">Créez des instantanés de ces volumes à l'état clôturé.</block>
  <block id="c464d4671e489eaad9a8cbf0a8086ea9" category="paragraph">L'escrime d'écriture est établi en série. Cela signifie que lorsque le processus de recel est configuré sur plusieurs volumes, les E/S d'écriture sont bloquées sur le premier volume de la séquence au fur et à mesure qu'elles continuent d'être validées sur les volumes qui apparaissent plus tard. Cela peut sembler initialement contraire à l'exigence de préservation de l'ordre d'écriture, mais cela s'applique uniquement aux E/S émises de manière asynchrone sur l'hôte et ne dépend pas d'autres écritures.</block>
  <block id="688656b1f8644ee299edf7be87a8fc75" category="paragraph">Par exemple, une base de données peut émettre de nombreuses mises à jour asynchrones des fichiers de données et permettre au système d'exploitation de réorganiser les E/S et de les compléter selon sa propre configuration de planificateur. L'ordre de ce type d'E/S ne peut pas être garanti car l'application et le système d'exploitation ont déjà libéré l'obligation de conserver l'ordre d'écriture.</block>
  <block id="599ce07d1bae0fa6169959e2bdb97ada" category="paragraph">Par exemple, la plupart des activités de journalisation de la base de données sont synchrones. La base de données ne procède pas à d'autres écritures de journal tant que les E/S n'ont pas été acquittées et que l'ordre de ces écritures doit être conservé. Si une E/S de journal arrive sur un volume clôturé, elle n'est pas validée et l'application se bloque lors d'écritures ultérieures. De même, les E/S des métadonnées du système de fichiers sont généralement synchrones. Par exemple, une opération de suppression de fichier ne doit pas être perdue. Si un système d'exploitation doté d'un système de fichiers xfs supprime un fichier et que les E/S qui ont mis à jour les métadonnées du système de fichiers xfs pour supprimer la référence à ce fichier ont été reçues sur un volume isolé, l'activité du système de fichiers est alors interrompue. Cela garantit l'intégrité du système de fichiers pendant les opérations cg-Snapshot.</block>
  <block id="0f0c0f05310f9cf257d65bfd936f15c5" category="paragraph">Une fois l'isolation d'écriture configurée sur les volumes cibles, ils sont prêts pour la création d'instantanés. Les snapshots n'ont pas besoin d'être créés précisément en même temps, car l'état des volumes est figé du point de vue de l'écriture dépendant. Pour éviter toute faille dans l'application qui crée les instantanés cg, l'escrime d'écriture initiale inclut un délai configurable dans lequel ONTAP libère automatiquement l'escrime et reprend le traitement d'écriture après un nombre défini de secondes. Si tous les snapshots sont créés avant l'expiration du délai, le jeu de snapshots résultant est un groupe de cohérence valide.</block>
  <block id="df4925d1c6c3f3258e80ff35ce62b17d" category="section-title">Ordre d'écriture dépendant</block>
  <block id="6c78ee478b93fbb573157b85fb1114db" category="paragraph">Du point de vue technique, la préservation de l'ordre d'écriture et, plus particulièrement, de l'ordre d'écriture dépendant constitue la clé d'un groupe de cohérence. Par exemple, une base de données qui écrit 10 LUN écrit simultanément sur toutes ces LUN. De nombreuses écritures sont émises de manière asynchrone, ce qui signifie que l'ordre dans lequel elles sont effectuées n'est pas important et que l'ordre dans lequel elles sont effectuées varie en fonction du système d'exploitation et du comportement du réseau.</block>
  <block id="69d87c00869001f3f06ad4a1494eac21" category="paragraph">Certaines opérations d'écriture doivent être présentes sur le disque avant que la base de données puisse procéder à des écritures supplémentaires. Ces opérations d'écriture critiques sont appelées écritures dépendantes. Les E/S d'écriture suivantes dépendent de la présence de ces écritures sur le disque. Tout snapshot, restauration ou réplication de ces 10 LUN doit garantir l'ordre d'écriture dépendant. Les mises à jour du système de fichiers sont un autre exemple d'écritures dépendantes de l'ordre d'écriture. L'ordre dans lequel les modifications du système de fichiers sont effectuées doit être conservé, sinon l'ensemble du système de fichiers pourrait être corrompu.</block>
  <block id="74fbae5d0b3c16e1774c5f4dce2c1c36" category="section-title">Stratégies</block>
  <block id="53e858edb9bd9ff3f9ead52cebf5731d" category="paragraph">Il existe deux approches principales des sauvegardes basées sur des snapshots :</block>
  <block id="f87f61f625a005bd32c53f808d235eea" category="list-text">Sauvegardes à chaud protégées pour les snapshots</block>
  <block id="c81725eb350a685210d69762bd5d725d" category="paragraph">Une sauvegarde cohérente après panne d'une base de données fait référence à la capture à un moment précis de l'ensemble de la structure de la base de données, y compris les fichiers de données, les journaux de reprise et les fichiers de contrôle. Si la base de données est stockée dans un seul volume NetApp FlexVol, le processus est simple ; il est possible de créer une copie Snapshot à tout moment. Si la base de données s'étend sur plusieurs volumes, un snapshot de groupe de cohérence doit être créé. Plusieurs options sont disponibles pour la création des snapshots de groupe de cohérence, notamment le logiciel NetApp SnapCenter, les fonctionnalités natives de groupe de cohérence ONTAP et les scripts gérés par l'utilisateur.</block>
  <block id="c32eba270db95747b471fd53e203a47b" category="paragraph">Les sauvegardes Snapshot cohérentes après panne sont principalement utilisées lorsque la restauration au point de sauvegarde est suffisante. Les journaux d'archivage peuvent être appliqués dans certains cas, mais lorsqu'une restauration granulaire à un point dans le temps est nécessaire, il est préférable d'effectuer une sauvegarde en ligne.</block>
  <block id="82cc23cd5dc667cc9fb78ff6e76ac15b" category="paragraph">La procédure de base pour une sauvegarde en ligne basée sur un snapshot est la suivante :</block>
  <block id="dbaf4855045e45fbcf678fa4cd1ab2db" category="list-text">Placez la base de données dans<block ref="402051f4be0cc3aad33bcf3ac3d6532b" prefix=" " category="inline-code"></block> mode.</block>
  <block id="c3e07fb8aef84ef3d94e3f9d5376c091" category="list-text">Créez un Snapshot de tous les volumes qui hébergent les fichiers de données.</block>
  <block id="2d0e58ff1a25bd9fd8a85ad8ce6f2665" category="list-text">Quitter<block ref="402051f4be0cc3aad33bcf3ac3d6532b" prefix=" " category="inline-code"></block> mode.</block>
  <block id="4196c5674aaa9e4317b2b4c54f94a905" category="list-text">Lancer la commande<block ref="9d2840394bc37850da4e360dbf60c0dc" prefix=" " category="inline-code"></block> pour forcer l'archivage des journaux.</block>
  <block id="f2736e795871e2fc2d36addb9436f337" category="list-text">Créer des instantanés de tous les volumes hébergeant les journaux d'archivage.</block>
  <block id="f24880a3fe8b242fdd1aba5a2d11196f" category="paragraph">Cette procédure permet d'obtenir un ensemble de snapshots contenant les fichiers de données en mode de sauvegarde et les journaux d'archivage critiques générés en mode de sauvegarde. Il s'agit des deux conditions requises pour restaurer une base de données. Il est également conseillé de protéger les fichiers tels que les fichiers de contrôle, mais la seule condition absolue est la protection des fichiers de données et des journaux d'archivage.</block>
  <block id="0c32649da44277db19fcfa3fe4dac28f" category="paragraph">Même si différents clients peuvent avoir des stratégies très différentes, la quasi-totalité de ces stratégies s'appuient sur les mêmes principes que ceux décrits ci-dessous.</block>
  <block id="88f451afed04f47352987f617f805826" category="section-title">Restauration basée sur des snapshots</block>
  <block id="c092a9763068c8382be82f9c77bb9658" category="paragraph">Lors de la conception d'infrastructures de volumes pour les bases de données Oracle, la première décision est d'utiliser ou non la technologie VBSR (Volume-Based NetApp SnapRestore).</block>
  <block id="15a0b8dc4d1b340d403bf6515f7e61b8" category="paragraph">La fonction SnapRestore basée sur les volumes permet de rétablir quasi instantanément un volume à un point antérieur. Toutes les données du volume étant rétablies, VBSR peut ne pas convenir à toutes les utilisations. Par exemple, si l'intégralité d'une base de données, y compris les fichiers de données, les journaux de reprise et les journaux d'archivage, est stockée sur un seul volume restauré avec VBSR, les données sont perdues, car les nouveaux journaux d'archivage et les données de reprise sont supprimés.</block>
  <block id="e63c0ca12b07a654ccadd92527a95c47" category="paragraph">La technologie VBSR n'est pas requise pour la restauration. De nombreuses bases de données peuvent être restaurées avec SFSR (Single File SnapRestore) ou en copiant simplement les fichiers du snapshot vers le système de fichiers actif.</block>
  <block id="2093e578085fede0f022c4efdb79c336" category="paragraph">La technologie VBSR est recommandée pour les bases de données très volumineuses ou si une restauration doit être effectuée le plus rapidement possible et que l'utilisation de VBSR nécessite l'isolement des fichiers de données. Dans un environnement NFS, les fichiers de données d'une base de données doivent être stockés sur des volumes dédiés non endommagés par d'autres types de fichiers. Dans un environnement SAN, les fichiers de données doivent être stockés sur des LUN dédiés sur des volumes FlexVol dédiés. Si un gestionnaire de volumes est utilisé (y compris Oracle Automatic Storage Management (ASM)), le groupe de disques doit également être dédié aux fichiers de données.</block>
  <block id="b38bd603a952c93872eae2ea858cb15f" category="paragraph">Cette méthode d'isolement des fichiers de données permet de rétablir leur état antérieur sans endommager d'autres systèmes de fichiers.</block>
  <block id="5755a6275c3ecd99e8159efc58a8ff6c" category="section-title">Réserve Snapshot</block>
  <block id="957abb72f2db3a20e0b570a5fa3a1dcc" category="paragraph">Pour chaque volume contenant des données Oracle dans un environnement SAN, le<block ref="9ca25b30dcc119f9115aad6d85fd12ce" prefix=" " category="inline-code"></block> Doit être défini sur zéro car il n'est pas utile de réserver de l'espace pour un snapshot dans un environnement LUN. Si la réserve fractionnaire est définie sur 100, un snapshot d'un volume avec des LUN nécessite suffisamment d'espace libre dans le volume, à l'exception de la réserve Snapshot, pour absorber 100 % de CA de toutes les données. Si la réserve fractionnaire est définie sur une valeur inférieure, une quantité d'espace libre correspondante est nécessaire, mais elle exclut toujours la réserve snapshot. Cela signifie que l'espace de réserve du snapshot dans un environnement de LUN est gaspillé.</block>
  <block id="d5a06adf11e69f265f3ee3277212764e" category="paragraph">Dans un environnement NFS, deux options sont possibles :</block>
  <block id="7631336a8e2e03f6ac500c145445b2d7" category="list-text">Réglez le<block ref="9ca25b30dcc119f9115aad6d85fd12ce" prefix=" " category="inline-code"></block> basé sur la consommation d'espace prévue du snapshot.</block>
  <block id="acc4c5d06fc4a9ac93880c9c2d0a6e76" category="list-text">Réglez le<block ref="9ca25b30dcc119f9115aad6d85fd12ce" prefix=" " category="inline-code"></block> pour zéro et gérer collectivement l'espace utilisé actif et snapshot.</block>
  <block id="44806986c5abfcd6261803f4f75a7b56" category="paragraph">Avec la première option,<block ref="9ca25b30dcc119f9115aad6d85fd12ce" prefix=" " category="inline-code"></block> est défini sur une valeur différente de zéro, généralement autour de 20 %. Cet espace est alors masqué par l'utilisateur. Toutefois, cette valeur ne crée pas de limite d'utilisation. Si une base de données avec une réservation de 20 % connaît un chiffre d'affaires de 30 %, l'espace snapshot peut dépasser les limites de la réserve de 20 % et occuper un espace non réservé.</block>
  <block id="c8910acb0bfa30f82b423ff09a9710ca" category="paragraph">Le principal avantage de la définition d'une réserve sur une valeur telle que 20 % est de vérifier qu'un peu d'espace est toujours disponible pour les snapshots. Par exemple, un volume de 1 To avec une réserve de 20 % permettrait uniquement à un administrateur de base de données (DBA) de stocker 800 Go de données. Cette configuration garantit au moins 200 Go d'espace pour la consommation de snapshots.</block>
  <block id="be233226a8cb890c0a8bbf041c06ac6b" category="paragraph">Quand<block ref="9ca25b30dcc119f9115aad6d85fd12ce" prefix=" " category="inline-code"></block> est défini sur zéro, tout l'espace du volume est disponible pour l'utilisateur final, ce qui offre une meilleure visibilité. L'administrateur de base de données doit comprendre que, s'il constate qu'un volume de 1 To exploite les snapshots, cet espace de 1 To est partagé entre les données actives et le renouvellement du Snapshot.</block>
  <block id="b10efee713968b90d211d08ec8345d20" category="paragraph">Il n'existe pas de préférence claire entre l'option 1 et l'option 2 parmi les utilisateurs finaux.</block>
  <block id="8112d08173571f2d01372cadea3ea76d" category="section-title">ONTAP et snapshots tiers</block>
  <block id="0cc082f7cc7618a904f6cde556295cbd" category="paragraph">Oracle Doc ID 604683.1 décrit les conditions requises pour la prise en charge des snapshots tiers et les nombreuses options disponibles pour les opérations de sauvegarde et de restauration.</block>
  <block id="130a02f8381e6c54b2ea07d2bdaf6f0b" category="paragraph">Les fournisseurs tiers doivent garantir la conformité de leurs snapshots à plusieurs exigences :</block>
  <block id="97eb59a0f249226523b31dd52d557e00" category="list-text">Les snapshots doivent intégrer les opérations de restauration et de reprise recommandées par Oracle.</block>
  <block id="083e9332dc2b6bf064139ac2e670eee9" category="list-text">Les snapshots doivent être cohérents après panne de la base de données au point du Snapshot.</block>
  <block id="9dae8634b638a6949dab0f7eaf7988bd" category="list-text">L'ordre d'écriture est conservé pour chaque fichier d'un snapshot.</block>
  <block id="7bc868657652757ca8505ddcd297456f" category="paragraph">Les produits de gestion Oracle de ONTAP et NetApp sont conformes à ces exigences.</block>
  <block id="9e19caeb431a5e29a1a63e3cee4b36c9" category="doc">Protection des données Oracle avec ONTAP</block>
  <block id="6f1383567177df0041e76e845c3629f2" category="paragraph">Les bases de données constituent les données les plus stratégiques.</block>
  <block id="848aab87f65bfade12f80d4e864ec046" category="paragraph">Une entreprise ne peut pas fonctionner sans accéder à ses données, et parfois l'activité repose sur les données. Ces données doivent être protégées, mais la protection ne se limite pas à garantir une sauvegarde utilisable. Elle consiste également à effectuer des sauvegardes rapidement et de manière fiable en plus de les stocker en toute sécurité.</block>
  <block id="28a0304f97f876b27cf541f4ad9a30d7" category="paragraph">L'autre côté de la protection des données est la restauration des données. Lorsque les données ne sont pas accessibles, l'entreprise est affectée et peut ne pas fonctionner tant qu'elle n'est pas restaurée. Ce processus doit être rapide et fiable. Enfin, la plupart des bases de données doivent être protégées contre les incidents, ce qui signifie maintenir une réplique de la base de données. La réplique doit être suffisamment à jour. Il doit également être rapide et simple de faire de la réplique une base de données entièrement opérationnelle.</block>
  <block id="3d601b26d05eac41fc6a7eba92fdc8b9" category="admonition">Cette documentation remplace le rapport technique _TR-4591 : protection des données Oracle : sauvegarde, restauration et réplication._</block>
  <block id="21d28aa03f67eb242b1c95a6a0594ff5" category="section-title">Planification</block>
  <block id="0bf5784d6c307e4ee0371d46053937c0" category="summary">Tests de performances Oracle</block>
  <block id="3993fbf2fe01237c798f68ece0b84724" category="doc">Optimisation des performances et banc d'essai Oracle</block>
  <block id="355ba59494fea8b20be391a73cc755eb" category="paragraph">Il est extrêmement compliqué de tester précisément les performances du stockage des bases de données. Il faut comprendre les problèmes suivants :</block>
  <block id="b57041cc3b57577b5c21eff44739e3f9" category="list-text">IOPS et débit</block>
  <block id="236e7fd957ada95e8094e302623980d3" category="list-text">Différence entre les opérations d'E/S au premier plan et en arrière-plan</block>
  <block id="902f90cc4ab59808cac5606f767f61c4" category="list-text">Effet de la latence sur la base de données</block>
  <block id="196198dbaa1d1ea17cfc478fbb2f419f" category="list-text">Nombreux paramètres du système d'exploitation et du réseau qui affectent également les performances du stockage</block>
  <block id="5ff18eadb2ef3fc20e13bed3e5b61d79" category="paragraph">En outre, il faut tenir compte des tâches qui ne relèvent pas du domaine du stockage dans les bases de données. L'optimisation de la performance du stockage ne présente plus d'avantages, car la performance du stockage n'est plus un facteur limitant.</block>
  <block id="92d509b1796c0ac8e185dc559cb7e294" category="paragraph">La majorité des clients de base de données choisissent désormais des baies 100 % Flash, ce qui entraîne d'autres considérations. Prenons l'exemple des tests de performances sur un système AFF8080 à deux nœuds :</block>
  <block id="4eb08b8b1c39980bb639a6e5890ec0de" category="list-text">Avec un ratio de lecture/écriture de 75/25, deux nœuds AFF8080 peuvent fournir plus de 300 000 IOPS aléatoires de bases de données, avant même que la latence ne dépasse le millième de seconde. Au-delà des exigences de performance actuelles de la plupart des bases de données, il est difficile de prévoir l'amélioration attendue. Le stockage serait largement effacé comme un goulot d'étranglement.</block>
  <block id="32a993d3f497a6dd4392d3348b05ebc3" category="list-text">La bande passante réseau est une source de plus en plus courante de limites de performances. Par exemple, les solutions sur disque mécanique constituent souvent des goulots d'étranglement pour les performances des bases de données, car la latence d'E/S est très élevée. Lorsque les limites de latence sont éliminées par un système 100 % Flash, le obstacle est fréquemment basculer vers le réseau. Ceci est particulièrement notable dans les environnements virtualisés et les systèmes lames où la véritable connectivité réseau est difficile à visualiser. Les tests de performances peuvent ainsi être plus complexes si le système de stockage lui-même ne peut pas être pleinement utilisé en raison des limitations de bande passante.</block>
  <block id="8caa382fb0f5f7a8279424d306dd003d" category="list-text">Il est généralement impossible de comparer les performances d'une baie 100 % Flash à celles d'une baie contenant des disques rotatifs en raison de la latence considérablement améliorée des baies 100 % Flash. Les résultats des tests ne sont généralement pas significatifs.</block>
  <block id="bc2b8b37bdda467f2ce639ab28bf4646" category="list-text">Généralement, comparer les pics de performance d'IOPS avec un système 100 % Flash n'est pas utile, car les bases de données ne sont pas limitées par les E/S de stockage Supposons par exemple qu'une baie peut supporter 500 000 IOPS aléatoires, tandis qu'une autre peut supporter 300 000. La différence n'est pas pertinente en situation réelle si une base de données consacre 99 % de son temps au traitement du processeur. Ces charges de travail n'exploitent jamais toutes les capacités de la baie de stockage. À l'inverse, les pics d'activité d'E/S par seconde peuvent s'avérer critiques pour une plateforme de consolidation sur laquelle la baie de stockage doit être chargée au maximum de ses capacités.</block>
  <block id="0c2cbb26e6baa58b7d3a3309f95a2786" category="list-text">Lors de tout test de stockage, la latence et les IOPS sont systématiquement prises en compte. De nombreuses baies de stockage sur le marché revendiquant des niveaux extrêmes d'IOPS, mais avec la latence, ces IOPS deviennent inutiles à de tels niveaux. La cible type avec des baies 100 % Flash est le millième de seconde, Une meilleure approche lors de ces tests n'est pas de mesurer les IOPS maximales mais de déterminer le nombre d'IOPS qu'une baie de stockage peut supporter avant que la latence moyenne ne soit supérieure à 1 ms.</block>
  <block id="e6d8362588e550c19912b0f3f0e1a129" category="section-title">Référentiel automatique de workloads Oracle et banc d'essai</block>
  <block id="d035df494751722dd56d4cf4a8d1f795" category="paragraph">Pour les comparaisons de performances Oracle, il est référence dans le rapport Oracle Automatic Workload Repository (AWR).</block>
  <block id="95f7e55383674168e90b01b708bc88db" category="paragraph">Il existe plusieurs types de rapports AWR. Du point de vue du stockage, un rapport généré par l'exécution de<block ref="5053a9940effa118d38161a53f3b80f8" prefix=" " category="inline-code"></block> La commande est la plus complète et la plus utile, car elle cible une instance de base de données spécifique et inclut des histogrammes détaillés qui décomposent les événements d'E/S de stockage en fonction de la latence.</block>
  <block id="7b79802e5668e6e5b990081db481505d" category="paragraph">Dans l'idéal, comparer deux baies de performances implique d'exécuter la même charge de travail sur chaque baie et de produire un rapport AWR qui cible précisément la charge de travail. Dans le cas d'une charge de travail très longue, il est possible d'utiliser un seul rapport AWR avec un temps écoulé couvrant le temps de début et de fin, mais il est préférable de séparer les données AWR sous forme de plusieurs rapports. Par exemple, si une tâche par lots s'est exécutée de minuit à 6 h, créez une série de rapports AWR d'une heure de minuit à 1 h, de 1 h à 2 h, etc.</block>
  <block id="e39ecb86ad7d25413ba8ad2976fd3e4a" category="paragraph">Dans d'autres cas, une requête très courte doit être optimisée. La meilleure option est un rapport AWR basé sur un instantané AWR créé au début de la requête et un deuxième instantané AWR créé à la fin de la requête. Le serveur de base de données doit être silencieux pour réduire au minimum l'activité en arrière-plan qui pourrait masquer l'activité de la requête en cours d'analyse.</block>
  <block id="2fe7152c186ec1b5b0451e13ec8b968b" category="admonition">Lorsque les rapports AWR ne sont pas disponibles, les rapports Oracle statspack constituent une bonne alternative. Ils contiennent la plupart des mêmes statistiques d'E/S qu'un rapport AWR.</block>
  <block id="8b8c73ac7e509a897688356d1d283d75" category="section-title">Oracle AWR et dépannage</block>
  <block id="42a92c79ee82f4343e7d65f2f1cf2dd2" category="paragraph">Un rapport AWR est également l'outil le plus important pour analyser un problème de performances.</block>
  <block id="ad5387afbab7c506c781c8b12b0a4b24" category="paragraph">Comme pour les bancs d'essai, la résolution des problèmes de performances nécessite que vous mesuriez précisément une charge de travail particulière. Dans la mesure du possible, fournissez des données AWR lorsque vous signalez un problème de performance au centre de support NetApp ou lorsque vous travaillez avec une équipe NetApp ou un partenaire responsable de compte concernant une nouvelle solution.</block>
  <block id="6471146c0e33e2a8ec8a5c6635c837bc" category="paragraph">Lorsque vous fournissez des données AWR, tenez compte des exigences suivantes :</block>
  <block id="5c3ba265890805919f93c246b3f8d2d6" category="list-text">Exécutez le<block ref="5053a9940effa118d38161a53f3b80f8" prefix=" " category="inline-code"></block> pour générer le rapport. La sortie peut être texte ou HTML.</block>
  <block id="25db65f9a36910f3e488a8b7407130de" category="list-text">Si Oracle Real application clusters (RAC) est utilisé, générez des rapports AWR pour chaque instance du cluster.</block>
  <block id="96d55341f8208c60720e68b3155f3aa1" category="list-text">Cibler l'heure précise à laquelle le problème a existé. La durée maximale acceptable d'un rapport AWR est généralement d'une heure. Si un problème persiste pendant plusieurs heures ou implique une opération sur plusieurs heures, par exemple un traitement par lots, fournissez plusieurs rapports AWR d'une heure qui couvrent l'ensemble de la période à analyser.</block>
  <block id="4533b15b837909c68a0171d2638494d2" category="list-text">Si possible, réglez l'intervalle d'instantané AWR sur 15 minutes. Ce paramètre permet d'effectuer une analyse plus détaillée. Cela nécessite également des exécutions supplémentaires de<block ref="5053a9940effa118d38161a53f3b80f8" prefix=" " category="inline-code"></block> fournir un rapport pour chaque intervalle de 15 minutes.</block>
  <block id="97eb6d04cc93934c1be4ab95054cd0b0" category="list-text">Si le problème est une requête en cours très courte, fournissez un rapport AWR basé sur un instantané AWR créé au début de l'opération et un second instantané AWR créé à la fin de l'opération. Le serveur de base de données doit être silencieux pour minimiser l'activité en arrière-plan qui pourrait masquer l'activité de l'opération en cours d'analyse.</block>
  <block id="5186f459ce7d75e587a083bcb7c5927a" category="list-text">Si un problème de performance est signalé à certains moments mais pas à d'autres, fournissez des données AWR supplémentaires qui démontrent de bonnes performances pour la comparaison.</block>
  <block id="108a72dad388aa310cc52ee3bac7d1cc" category="section-title">etalonnez_io</block>
  <block id="f1c07dfccef6a6c47a5ccef938e10e3d" category="paragraph">Le<block ref="108a72dad388aa310cc52ee3bac7d1cc" prefix=" " category="inline-code"></block> command ne doit jamais être utilisé pour tester, comparer ou tester les systèmes de stockage. Comme indiqué dans la documentation Oracle, cette procédure permet d'étalonner les capacités d'E/S du stockage.</block>
  <block id="872892cce56a2665ad7ceecc44b38166" category="paragraph">L'étalonnage n'est pas le même que l'étalonnage. L'objectif de cette commande est d'émettre des E/S pour aider à étalonner les opérations de la base de données et améliorer leur efficacité en optimisant le niveau d'E/S émis pour l'hôte. Car le type d'E/S effectué par le<block ref="108a72dad388aa310cc52ee3bac7d1cc" prefix=" " category="inline-code"></block> Le fonctionnement ne représente pas les E/S réelles de l'utilisateur de la base de données, les résultats ne sont pas prévisibles et ne sont souvent même pas reproductibles.</block>
  <block id="e66807fad19acd41db50eedff918a4dd" category="section-title">SLOB2</block>
  <block id="0a6192ff5412539c31db2c7a98f408b3" category="inline-link-macro"><block ref="0a6192ff5412539c31db2c7a98f408b3" category="inline-link-rx"></block></block>
  <block id="d1f6fb23f52090ffd944dc54549735b8" category="paragraph">SLOB2, le très petit banc d'essai Oracle, est devenu l'outil privilégié pour évaluer les performances des bases de données. Il a été développé par Kevin Closson et est disponible à l'adresse <block ref="3ccce0719b1965cd915da75778e4e706" category="inline-link-macro-rx"></block>. L'installation et la configuration ne prennent que quelques minutes et une base de données Oracle génère des modèles d'E/S sur un espace de table définissable par l'utilisateur. Il s'agit de l'une des rares options de test disponibles permettant de saturer une baie 100 % Flash par E/S. Il est également utile de générer des niveaux d'E/S beaucoup plus bas pour simuler des charges de travail de stockage qui font partie des IOPS faibles, mais qui sont sensibles à la latence.</block>
  <block id="baffd8ac40ca7b966340e7b257b4c7b4" category="section-title">Swingbench</block>
  <block id="905a59d6f73f4e2aea1dc232a3bcd195" category="paragraph">Swingbench peut être utile pour tester les performances des bases de données, mais il est extrêmement difficile d'utiliser Swingbench sous un contrainte de stockage. NetApp n'a constaté aucun test de Swingbench ayant produit suffisamment d'E/S pour être une charge significative sur n'importe quelle baie AFF. Dans certains cas limités, le test OET (Order Entry Test) peut être utilisé pour évaluer le stockage du point de vue de la latence. Cela peut s'avérer utile lorsqu'une base de données a une dépendance connue en termes de latence pour des requêtes particulières. Assurez-vous que l'hôte et le réseau sont correctement configurés pour atteindre les potentiels de latence d'une baie 100 % Flash.</block>
  <block id="e3cf940afa524b20b15c43b20405be77" category="section-title">HammerDB</block>
  <block id="5c9408da71d2ff7554b9fd11add795cf" category="paragraph">HammerDB est un outil de test de base de données qui simule les bancs d'essai TPC-C et TPC-H, entre autres. La construction d'un jeu de données suffisamment volumineux pour exécuter correctement un test peut prendre beaucoup de temps, mais elle peut constituer un outil efficace pour évaluer les performances des applications OLTP et d'entrepôt de données.</block>
  <block id="7e1ad070b7fff621d9d64a71cec87684" category="section-title">Orion</block>
  <block id="56fedcbec2842fb62a743c5f84311597" category="paragraph">L'outil Oracle Orion a été couramment utilisé avec Oracle 9, mais il n'a pas été maintenu pour assurer la compatibilité avec les modifications apportées aux différents systèmes d'exploitation hôtes. Il est rarement utilisé avec Oracle 10 ou Oracle 11 en raison d'incompatibilités avec le système d'exploitation et la configuration du stockage.</block>
  <block id="38622bf572fa7bec2dc7f3915ebd345f" category="paragraph">Oracle a réécrit l'outil, qui est installé par défaut dans Oracle 12c. Bien que ce produit ait été amélioré et utilise la plupart des appels qu'une véritable base de données Oracle utilise, il n'utilise pas exactement le même chemin de code ou le même comportement d'E/S que celui utilisé par Oracle. Par exemple, la plupart des E/S Oracle sont exécutées de manière synchrone, ce qui signifie que la base de données s'arrête jusqu'à ce que les E/S soient terminées lorsque l'opération d'E/S se termine au premier plan. Le simple fait d'inonder un système de stockage d'E/S aléatoires n'est pas une reproduction de véritables E/S Oracle et n'offre pas de méthode directe pour comparer les baies de stockage ou mesurer l'impact des modifications de configuration.</block>
  <block id="bb68dfada5ca20e256bbd3ffbbfab9e6" category="paragraph">Cela étant, Orion est souvent associé à des cas d'usage, comme l'évaluation générale des performances maximales d'une configuration de stockage hôte-réseau ou encore l'évaluation de l'état d'un système de stockage. Grâce à des tests rigoureux, nous pouvons concevoir des tests Orion exploitables afin de comparer les baies de stockage ou d'évaluer l'effet d'une modification de la configuration, dans la mesure où les paramètres tiennent compte des IOPS, du débit et de la latence, et tenter de répliquer fidèlement une charge de travail réaliste.</block>
  <block id="6b64090d226d30776368e89b08c7c71b" category="summary">Alignement WAFL pour bases de données Oracle</block>
  <block id="03a35ba2b6191f8cfbd1cca378eefc91" category="doc">Vérification de l'alignement WAFL pour les bases de données Oracle</block>
  <block id="219900dcd21cee2f958254a708ad36f6" category="paragraph">Un alignement WAFL correct est essentiel pour de bonnes performances. Même si ONTAP gère des blocs dans des unités de 4 Ko, ONTAP ne réalise pas forcément toutes les opérations dans des unités de 4 Ko. ONTAP prend en charge les opérations en mode bloc de différentes tailles, mais la comptabilité sous-jacente est gérée par WAFL en unités de 4 Ko.</block>
  <block id="5d3a5c290e14d74acf49b20d15120886" category="paragraph">Le terme « alignement » fait référence à la manière dont les E/S Oracle correspondent à ces unités de 4 Ko. Pour optimiser les performances, un bloc Oracle de 8 Ko doit résider sur deux blocs physiques WAFL de 4 Ko sur un disque. Si un bloc est décalé de 2 Ko, ce bloc réside dans la moitié d'un bloc de 4 Ko, dans un bloc séparé complet de 4 Ko, puis dans la moitié d'un troisième bloc de 4 Ko. Cette configuration entraîne une dégradation des performances.</block>
  <block id="0073ce99d632b066d5ac09a4ad0cf7fc" category="paragraph">L'alignement n'est pas un problème avec les systèmes de fichiers NAS. Les fichiers de données Oracle sont alignés sur le début du fichier en fonction de la taille du bloc Oracle. Par conséquent, les tailles de bloc de 8 Ko, 16 Ko et 32 Ko sont toujours alignées. Toutes les opérations de bloc sont décalées par rapport au début du fichier en unités de 4 kilo-octets.</block>
  <block id="d7f7edd61ab216efc34578584a7d0e7c" category="paragraph">Les LUN, en revanche, contiennent généralement au départ un type d'en-tête de pilote ou de métadonnées de système de fichiers qui crée un décalage. L'alignement est rarement un problème dans les systèmes d'exploitation modernes, car ces systèmes d'exploitation sont conçus pour des disques physiques pouvant utiliser un secteur natif de 4 Ko. De plus, ils requièrent l'alignement des E/S sur les limites de 4 Ko pour des performances optimales.</block>
  <block id="38b3d1cd67903560954ad297a92e3de1" category="paragraph">Il y a toutefois quelques exceptions. Une base de données a peut-être été migrée à partir d'un système d'exploitation plus ancien qui n'a pas été optimisé pour les E/S de 4 Ko, ou une erreur de l'utilisateur lors de la création de la partition a pu entraîner un décalage qui ne se situe pas dans des unités de 4 Ko.</block>
  <block id="612eeadd26ceeace7b043d37f8e24b1f" category="paragraph">Les exemples suivants sont spécifiques à Linux, mais la procédure peut être adaptée à n'importe quel système d'exploitation.</block>
  <block id="1d5b772bea21e5e949413e09eedf17de" category="section-title">Aligné</block>
  <block id="594b0fc1af44897ff4b26f2e6b866685" category="paragraph">L'exemple suivant montre une vérification d'alignement sur une seule LUN avec une seule partition.</block>
  <block id="dc2c18402c86861702fc1d94a6495ac3" category="paragraph">Tout d'abord, créez la partition qui utilise toutes les partitions disponibles sur le lecteur.</block>
  <block id="adff8cc6319e96d2685fd082a5aa043c" category="paragraph">L'alignement peut être vérifié mathématiquement à l'aide de la commande suivante :</block>
  <block id="4bc7aba328a710bb7d0935cf830634aa" category="paragraph">Le résultat indique que les unités sont de 512 octets et que le début de la partition est de 32 unités. Il s'agit d'un total de 32 x 512 = 16,834 octets, soit un ensemble de blocs WAFL de 4 Ko. Cette partition est correctement alignée.</block>
  <block id="dd343941469b5360af52eb1b94fe5de6" category="paragraph">Pour vérifier que l'alignement est correct, procédez comme suit :</block>
  <block id="7d84e72acd05d0c93d99e414f5b092b5" category="list-text">Identifier l'UUID (identifiant universel unique) de la LUN</block>
  <block id="92af2a93f00a6297c490ba0be5fd7a8a" category="list-text">Entrez le shell du nœud sur le contrôleur ONTAP.</block>
  <block id="5274579d5eff6fe6d1e8ecbf54e84993" category="list-text">Démarrer les collections statistiques sur l'UUID cible identifié dans la première étape.</block>
  <block id="52df0a2ea976123bf02330300b2392e3" category="list-text">Certaines E/S. Il est important d'utiliser le<block ref="3c908d68ba53922b92c5595b72fa011c" prefix=" " category="inline-code"></block> Argument permettant de s'assurer que les E/S sont synchrones et non mises en tampon.</block>
  <block id="fac8a5b490ea29eca93ec213d79e6ff2" category="admonition">Faites très attention avec cette commande. Inversion du<block ref="39c8942e1038872a822c0dc75eedbde3" prefix=" " category="inline-code"></block> et<block ref="8bf8854bebe108183caeb845c7676ae4" prefix=" " category="inline-code"></block> les arguments détruisent les données.</block>
  <block id="4f7dce34a21e3de727f3e3ad05e6e7d8" category="list-text">Arrêtez les statistiques et affichez l'histogramme d'alignement. Toutes les E/S doivent se trouver dans le<block ref="c6bd178b372b0ddd17fff48819badc6a" prefix=" " category="inline-code"></block> Bucket, qui indique les E/S alignées sur les limites d'un bloc de 4 Ko.</block>
  <block id="5df81374c01d1b7c20fe8cb3883117eb" category="section-title">Mauvais alignement</block>
  <block id="5ff266dadf965b3c304513f516a13c12" category="paragraph">L'exemple suivant illustre un mauvais alignement des E/S :</block>
  <block id="25be03b87e6a5d8170ce85b16ea506ab" category="list-text">Créez une partition qui ne s'aligne pas sur une limite de 4 Ko. Il ne s'agit pas d'un comportement par défaut sur les systèmes d'exploitation modernes.</block>
  <block id="4adda0e871000c2b13a4faef6ce4e21b" category="paragraph">Le mauvais alignement est clair. Les E/S tombent principalement dans le* <block ref="66c8d76cad709856ccec680cab8ab35a" prefix="*" category="inline-code"></block> godet, qui correspond au décalage attendu. Lorsque la partition a été créée, elle a été déplacée de 512 octets plus loin dans le périphérique que la valeur par défaut optimisée, ce qui signifie que l'histogramme est décalé de 512 octets.</block>
  <block id="b53cb977228ac351c16dfacc3c427a99" category="paragraph">De plus, le<block ref="20e637b3ddd562732de038fba736c7ee" prefix=" " category="inline-code"></block> Ces statistiques ne sont pas égales à zéro, ce qui signifie que des E/S n'ont pas rempli un bloc de 4 Ko entier.</block>
  <block id="d3d92f87c5235ad11c8bc69e85fb2fd0" category="section-title">Fichiers de reprise</block>
  <block id="162b54d51a30629d78e153f8da201780" category="paragraph">Les procédures décrites ici s'appliquent aux fichiers de données. Les journaux de reprise et d'archivage Oracle ont différents modèles d'E/S. Par exemple, la journalisation de reprise est un remplacement circulaire d'un seul fichier. Si la taille de bloc par défaut de 512 octets est utilisée, les statistiques d'écriture se ressemblent à ceci :</block>
  <block id="d36dbaa617441d3308f5a9b50cb6f5ca" category="paragraph">Les E/S sont réparties dans tous les compartiments de l'histogramme, mais cela n'est pas un problème de performances. Toutefois, des taux de journalisation de reprise extrêmement élevés peuvent bénéficier d'une taille de bloc de 4 Ko. Dans ce cas, il est conseillé de vérifier que les LUN de journalisation de reprise sont correctement alignées. Cependant, cette condition n'est pas aussi importante pour de bonnes performances que l'alignement des fichiers de données.</block>
  <block id="f64f1c647516f5a47c00be152fdbf488" category="summary">Les verrous Oracle et NFSv3 obsolètes</block>
  <block id="91d9710c9fee248ae3e9c4b810ae704f" category="doc">Les verrous NFSv3 et les bases de données Oracle obsolètes</block>
  <block id="3f9e1e3abd12ad7445baea4b681b9ceb" category="paragraph">Si un serveur de base de données Oracle tombe en panne, des verrous NFS obsolètes peuvent se présenter au redémarrage. Ce problème peut être évité en portant une attention particulière à la configuration de la résolution de nom sur le serveur.</block>
  <block id="288ebefc25180862eb0448b786b1b9fc" category="paragraph">Ce problème survient parce que la création d'un verrou et l'effacement d'un verrou utilisent deux méthodes légèrement différentes de résolution de nom. Deux processus sont impliqués, Network Lock Manager (NLM) et le client NFS. Le NLM utilise<block ref="e5caaf154dfeed411b9eec65b903a22a" prefix=" " category="inline-code"></block> pour déterminer le nom d'hôte, pendant que le système<block ref="d49331f31f40041ebcee19fca74fd9d4" prefix=" " category="inline-code"></block> utilisations des processus<block ref="330c4316ae6124616389eb1ca9912f7a" prefix=" " category="inline-code"></block>. Ces noms d'hôte doivent correspondre pour que le système d'exploitation efface correctement les verrous obsolètes. Par exemple, l'hôte peut rechercher des verrous appartenant à<block ref="c7169a6dd344d0f0a38071a1262e4973" prefix=" " category="inline-code"></block>, mais les verrous ont été enregistrés par l'hôte comme<block ref="0c32c65f5ac66d0bdb4e63bd5fde7f75" prefix=" " category="inline-code"></block>. Si<block ref="330c4316ae6124616389eb1ca9912f7a" prefix=" " category="inline-code"></block> ne renvoie pas la même valeur que<block ref="5c020b5bb8d1ce1ace51c2a2f4c06fc2" prefix=" " category="inline-code"></block>, le processus de déverrouillage n'a pas réussi.</block>
  <block id="19b9a1f540971d74c69042125bab2abc" category="paragraph">L'exemple de script suivant vérifie si la résolution des noms est parfaitement cohérente :</block>
  <block id="ee04b3fa3b28391874763596275e09c9" category="paragraph">Si<block ref="b64c6f211add16fd66ac17ef14c2a2b4" prefix=" " category="inline-code"></block> ne correspond pas<block ref="4040592cec1880aa70936989f05e7c31" prefix=" " category="inline-code"></block>, des verrous obsolètes sont probables. Par exemple, ce résultat indique un problème potentiel :</block>
  <block id="2b500e5914ea5a219ade17dea0808f51" category="paragraph">La solution est généralement trouvée en modifiant l'ordre dans lequel les hôtes apparaissent dans<block ref="ad942c725cd0cae65ca4c63717ec464c" prefix=" " category="inline-code"></block>. Par exemple, supposons que le fichier hosts inclut l'entrée suivante :</block>
  <block id="22b58ec1cec48707dfc018e6e216e966" category="paragraph">Pour résoudre ce problème, modifiez l'ordre dans lequel le nom de domaine complet et le nom d'hôte court apparaissent :</block>
  <block id="e357ccd0745db58f22ea5c0947b613ee" category="paragraph"><block ref="330c4316ae6124616389eb1ca9912f7a" prefix="" category="inline-code"></block> renvoie maintenant le court<block ref="c7169a6dd344d0f0a38071a1262e4973" prefix=" " category="inline-code"></block> nom d'hôte, qui correspond à la sortie de<block ref="4040592cec1880aa70936989f05e7c31" prefix=" " category="inline-code"></block>. Les verrous sont donc effacés automatiquement après une panne de serveur.</block>
  <block id="547b870352d8464aadbe7bee63d6f3d1" category="summary">Introduction à la virtualisation de la base de données</block>
  <block id="ea4c55be196897a16d86999f5c16d582" category="doc">Virtualisation</block>
  <block id="4a478889a2e46bee771126a78eda2911" category="paragraph">La virtualisation des bases de données avec VMware ESX, Oracle OVM ou KVM est un choix de plus en plus courant pour les clients NetApp qui ont choisi la virtualisation, même pour leurs bases de données les plus stratégiques.</block>
  <block id="0f976e587b1e7af0949904e76d91384b" category="paragraph">Il existe de nombreuses idées fausses sur les politiques de prise en charge de la virtualisation, en particulier pour les produits VMware. En effet, il n'est pas rare d'entendre qu'Oracle ne prend en charge la virtualisation d'aucune façon. Cette notion est incorrecte et ne permet pas de bénéficier d'opportunités de virtualisation. Oracle Doc ID 249212.1 traite des problèmes connus dans un environnement Oracle et indique également la prise en charge de RAC.</block>
  <block id="02ea3d7754e6bc1c99ff77393e49e373" category="paragraph">Il peut être demandé à un client dont le problème n'est pas connu d'Oracle de reproduire le problème sur du matériel physique. Un client Oracle exécutant une version de pointe d'un produit peut ne pas vouloir utiliser la virtualisation en raison du risque de nouvelle détection de bogues. Cependant, cette situation n'a pas été un problème dans la pratique pour les clients utilisant des versions de produit généralement disponibles.</block>
  <block id="9e28dbd7a4f5940eeaf6d3893c5c4b1f" category="section-title">Présentation du stockage</block>
  <block id="8fdbc6d55014a06c15b9f130e5bedd12" category="paragraph">Les clients qui envisagent de virtualiser leurs bases de données doivent baser leurs décisions de stockage sur leurs besoins métier. Bien qu'il s'agisse généralement d'une véritable déclaration pour toutes les décisions INFORMATIQUES, elle est particulièrement importante pour la virtualisation, car la taille et l'étendue des projets varient considérablement.</block>
  <block id="6cf53ad2948792abdf4a8668365b8396" category="paragraph">Il existe quatre options de base pour la présentation du stockage :</block>
  <block id="151ae53a4100e0a6e83bde4d78083f81" category="list-text">LUN iSCSI gérées par l'initiateur iSCSI sur la machine virtuelle, pas par l'hyperviseur</block>
  <block id="73014dc1e7381cfd107ba79742a873e3" category="list-text">Systèmes de fichiers NFS montés par la machine virtuelle, pas un disque de machine virtuelle (VMDK)</block>
  <block id="810f0004f0e8e215c676ac0621d5836b" category="list-text">Datastores d'hyperviseur</block>
  <block id="8e2a0eba3eaebd64066d020ab225dd78" category="paragraph">En règle générale, évitez d'utiliser des datastores pour les fichiers Oracle. Il y a plusieurs raisons à cette recommandation :</block>
  <block id="98b171e836c6656f9cf88835666c6345" category="list-text">*Transparence.* lorsqu'une machine virtuelle possède ses systèmes de fichiers, il est plus facile pour un administrateur de base de données ou un administrateur système d'identifier la source des systèmes de fichiers pour leurs données.</block>
  <block id="ec6a3b593d5584a2e15651852e384082" category="list-text">*Performance.* les tests ont montré qu'il existe un effet sur les performances en canalisant toutes les E/S via un datastore d'hyperviseur.</block>
  <block id="47464ddf615c138c6c06d3bfea555b2d" category="list-text">*Gérabilité.* lorsqu'une machine virtuelle possède ses systèmes de fichiers, l'utilisation ou la non-utilisation d'une couche hyperviseur affecte la gestion. Les mêmes procédures de provisionnement, de surveillance, de protection des données, etc. Peuvent être utilisées dans l'ensemble du parc, y compris dans les environnements virtualisés et non virtualisés.</block>
  <block id="3d04d7019fbc0d27880dcc5c0881f87b" category="list-text">*Stabilité et dépannage.* lorsqu'une machine virtuelle possède ses systèmes de fichiers, les performances sont stables et les problèmes de dépannage sont beaucoup plus simples car la pile de stockage est entièrement présente sur la machine virtuelle. Le seul rôle de l'hyperviseur est de transporter des trames FC ou IP. Lorsqu'un datastore est inclus dans une configuration, il complique la configuration en introduisant un autre ensemble d'expirations de délai, de paramètres, de fichiers journaux et de bogues potentiels.</block>
  <block id="36f9cea3dc0f65698a9fbe15460591c1" category="list-text">*Portabilité.* lorsqu'une machine virtuelle possède ses systèmes de fichiers, le processus de déplacement d'un environnement Oracle devient beaucoup plus simple. Les systèmes de fichiers peuvent facilement être déplacés entre des invités virtualisés et non virtualisés.</block>
  <block id="cb90f9e52412940f028394174f31ec2f" category="list-text">*Dépendance vis-à-vis d'un fournisseur.* une fois les données placées dans un datastore, il devient très difficile d'utiliser un hyperviseur différent ou de retirer les données de l'environnement virtualisé.</block>
  <block id="4308dde96d1bdae6ac436a611c834331" category="list-text">*Activation Snapshot.* dans certains cas, les sauvegardes dans un environnement virtualisé peuvent devenir problématiques en raison de la bande passante relativement limitée. Par exemple, un agrégat 10 GbE à quatre ports peut suffire pour répondre aux besoins quotidiens en performances de nombreuses bases de données virtualisées. Cependant, un tel agrégat ne suffit pas pour effectuer des sauvegardes à l'aide de RMAN ou d'autres produits de sauvegarde nécessitant le streaming d'une copie complète des données.</block>
  <block id="872c95c8713fd14a0bef21fe92a55ab7" category="paragraph">L'utilisation de systèmes de fichiers appartenant à des machines virtuelles facilite l'exploitation des sauvegardes et des restaurations basées sur des copies Snapshot. Un système de fichiers appartenant à une VM délègue la tâche d'exécution des sauvegardes sur le système de stockage. Il n'est pas nécessaire de surconstruire la configuration de l'hyperviseur uniquement pour prendre en charge les besoins en bande passante et en CPU dans la fenêtre de sauvegarde.</block>
  <block id="3522f960cdbaf08c375bd70214f8db2f" category="admonition">*NetApp recommande* d'éviter de placer les données Oracle sur un datastore afin d'optimiser les performances et la facilité de gestion. Utilisez des systèmes de fichiers invités, tels que des systèmes de fichiers NFS ou iSCSI gérés par l'invité ou avec des RDM.</block>
  <block id="f114856edc6cd8d6a9add5ec3f67656f" category="section-title">Pilotes paravirtualisés</block>
  <block id="beeb10ceee6c9aabe178fb51edea7d22" category="paragraph">Pour des performances optimales, l'utilisation de pilotes de réseau paravirtualisés est essentielle. Lorsqu'un datastore est utilisé, un pilote SCSI paravirtualisé est requis. Un pilote de périphérique paravirtualisé permet à un invité de s'intégrer plus profondément dans l'hyperviseur, au lieu d'un pilote émulé dans lequel l'hyperviseur passe plus de temps CPU à imiter le comportement du matériel physique.</block>
  <block id="59b3d62404749c3e899b7e4c9ee10146" category="paragraph">Les performances de la plupart des bases de données sont limitées par le stockage. Par conséquent, la latence supplémentaire introduite par un pilote réseau ou SCSI est particulièrement notable. Le support client NetApp a rencontré de nombreuses plaintes de performances qui ont été résolues par l'installation de pilotes paravirtualisés. Au cours d'une démonstration de faisabilité effectuée par un client, les bases de données ont affiché des performances supérieures sous ESX par rapport au même matériel fonctionnant sous bare Metal. Les tests ont été très exigeants en E/S et la différence de performances a été attribuée à l'utilisation de pilotes réseau paravirtualisés ESX.</block>
  <block id="4e27b04a271416c5701a99234f8a23e6" category="admonition">*NetApp recommande* d'utiliser toujours des pilotes réseau paravirtualisés et des pilotes SCSI.</block>
  <block id="7c5996fc15a24ce96b30160b60ac2b96" category="section-title">Saturation de la mémoire RAM</block>
  <block id="5bccdd812c4af1cb5b9e36ddce656b60" category="paragraph">La saturation de la mémoire RAM implique la configuration d'une quantité de mémoire RAM virtualisée supérieure à celle qui existe sur le matériel physique sur différents hôtes. Cela peut entraîner des problèmes de performances inattendus. Lors de la virtualisation d'une base de données, les blocs sous-jacents de la SGA d'Oracle ne doivent pas être remplacés par l'hyperviseur vers le stockage. Cela entraîne des résultats de performances très instables.</block>
  <block id="31db92967e891f0a122e0329d819842e" category="admonition">*NetApp recommande* de ne pas configurer un hyperviseur de manière à ce que les blocs SGA Oracle puissent être échangés.</block>
  <block id="be493f1fc0b02ae45602c7c13f7b5dc7" category="summary">Le rapport technique TR-4792 fournit des recommandations sur l'utilisation du NetApp HCI 615C pour les workloads de graphiques 3D dans un environnement VMware Horizon optimisé par les processeurs graphiques (GPU) et le logiciel de virtualisation NVIDIA.</block>
  <block id="ff1d278a485c443dc5d8fc9f10f1a702" category="doc">NetApp HCI pour l'infrastructure de postes de travail virtuels avec VMware Horizon 7 : offrez aux utilisateurs intensifs des graphiques 3D</block>
  <block id="e3162938e0d7b1bbc74111cc5b5871c5" category="paragraph">Le rapport technique TR-4792 fournit des conseils sur l'utilisation du nœud de calcul NetApp H615C pour les workloads de graphiques 3D dans un environnement VMware Horizon optimisé par les processeurs graphiques (GPU) et le logiciel de virtualisation NVIDIA. Il fournit également les résultats des tests préliminaires de SPECviewperf 13 pour le H615C.</block>
  <block id="1de37c09602b46db5de57a946efe2768" category="paragraph"><block ref="1de37c09602b46db5de57a946efe2768" category="inline-link-macro-rx"></block></block>
  <block id="93b94e62ad8cb02a1d1a7b0944a5445d" category="summary">Ce document présente les fonctions de sécurité des produits des outils ONTAP pour VMware vSphere.</block>
  <block id="57a033c33a8be6110be46b2914cc4989" category="doc">Utilisation de vVols avec ONTAP</block>
  <block id="69556d50c944e0a07ade0bea62f078a3" category="paragraph">La clé de l'utilisation des vVols avec ONTAP est le logiciel VASA Provider inclus dans les outils ONTAP pour l'appliance virtuelle VMware vSphere.</block>
  <block id="5e484430124a3d64541b75bbf3c8f529" category="paragraph">Les outils ONTAP incluent également les extensions de l'interface utilisateur vCenter, le serveur d'API REST, Storage Replication adapter pour VMware site Recovery Manager, les outils de surveillance et de configuration de l'hôte, ainsi qu'un ensemble de rapports qui vous aident à mieux gérer votre environnement VMware.</block>
  <block id="21247c4392dc3c243f693dbf5b762553" category="section-title">Produits et documentation</block>
  <block id="4fc5e15c4dc0d227bc5f8f26e4337083" category="paragraph">La licence ONTAP FlexClone (incluse avec ONTAP ONE) et l'appliance ONTAP Tools sont les seuls produits supplémentaires requis pour utiliser les vVols avec NetApp ONTAP. Les dernières versions des outils ONTAP sont fournies sous la forme d'une appliance unifiée unique qui s'exécute sur ESXi, et qui offre les fonctionnalités de trois dispositifs et serveurs auparavant différents. Pour les vVols, il est important d'utiliser les extensions de l'interface utilisateur vCenter de l'outil ONTAP ou les API REST en tant qu'outils de gestion généraux et interfaces utilisateur pour les fonctions ONTAP avec vSphere, ainsi que le fournisseur VASA qui offre des fonctionnalités vVols spécifiques. Le composant SRA est inclus pour les datastores classiques, mais VMware site Recovery Manager n'utilise pas SRA pour les vVols pour la mise en œuvre de nouveaux services dans SRM 8.3 et versions ultérieures, qui utilisent VASA Provider pour la réplication des vVols.</block>
  <block id="bf03408d75f93f6e28c07c3c2300b98a" category="section-title">Architecture VASA Provider des outils ONTAP lors de l'utilisation d'iSCSI ou FCP</block>
  <block id="94ef809dc16e728151bda996f8b4f8aa" category="inline-image-macro">Architecture VASA Provider des outils ONTAP,240</block>
  <block id="d78de3410d86d345a548abdf67aff375" category="paragraph"><block ref="d78de3410d86d345a548abdf67aff375" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5e5421e75636200787a4449a2cdaa1f1" category="section-title">Installation du produit</block>
  <block id="3ef3033a2b9a744a1e4e7e93fa01f909" category="paragraph">Pour les nouvelles installations, déployez l'appliance virtuelle dans votre environnement vSphere. Les versions actuelles des outils ONTAP s'inscrivent automatiquement dans votre vCenter et activent le fournisseur VASA par défaut. Outre les informations sur l'hôte ESXi et vCenter Server, vous devez également disposer des détails de configuration de l'adresse IP de l'appliance. Comme indiqué précédemment, le fournisseur VASA nécessite que la licence ONTAP FlexClone soit déjà installée sur les clusters ONTAP que vous prévoyez d'utiliser pour les vVols. Le dispositif est doté d'un dispositif de surveillance intégré pour garantir la disponibilité et, dans le cadre des meilleures pratiques, doit être configuré avec les fonctions VMware High Availability et éventuellement Fault Tolerance. Voir la section 4.1 pour plus de détails. N'installez pas et ne déplacez pas l'appliance ONTAP Tools ou l'appliance vCenter Server (VCSA) vers le stockage vVols, car cela peut empêcher le redémarrage des appliances.</block>
  <block id="6a5c862f634c8967f7246f42eb9de6e1" category="paragraph">Les mises à niveau des outils ONTAP sur place sont prises en charge grâce au fichier ISO de mise à niveau disponible en téléchargement sur le site du support NetApp (NSS). Suivez les instructions du Guide de déploiement et de configuration pour mettre à niveau l'appliance.</block>
  <block id="3c07c9b4b562a16890d9fee571f0441e" category="inline-link">Guide de dimensionnement des outils ONTAP pour VMware vSphere</block>
  <block id="e4e51979718d88ce483f9477be981a76" category="paragraph">Pour le dimensionnement de votre appliance virtuelle et la compréhension des limites de configuration, reportez-vous à l'article suivant de la base de connaissances :<block ref="a75738ed95b0811ed0edd1b8ef0d9568" category="inline-link-rx"></block></block>
  <block id="72333dadacbc964761fb14f718f6d411" category="section-title">Documentation produit</block>
  <block id="e0644c46fdc2ced2c094f7db15e15a8a" category="paragraph">La documentation suivante est disponible pour vous aider à déployer les outils ONTAP.</block>
  <block id="09e308ed60d47b80b6cd16eb233f1bb9" category="inline-link">Pour consulter le référentiel de documentation complet et accéder à la page 44, cliquez sur ce lien : docs.netapp.com</block>
  <block id="7f21741a70426baea3ee41488da86af4" category="paragraph"><block ref="56b49132b20e341764c8aa067751e8a5" category="inline-link-rx"></block></block>
  <block id="be11c74c1dd7f307bb80183a90dc2067" category="section-title">Commencez</block>
  <block id="7d0ee6fed10d3d4e5c9ee496729ab519" category="inline-link">Notes de mise à jour</block>
  <block id="2645deadffb8af180b8a35da3d034ad8" category="list-text"><block ref="2645deadffb8af180b8a35da3d034ad8" category="inline-link-rx"></block></block>
  <block id="b1555cd6358e57b76c72e343dbe31846" category="inline-link">En savoir plus sur les outils ONTAP pour VMware vSphere</block>
  <block id="a0aaeda90fe2ef02fba791bc7c35645c" category="list-text"><block ref="a0aaeda90fe2ef02fba791bc7c35645c" category="inline-link-rx"></block></block>
  <block id="e695b432b77d6bddfcb785c76f5e5442" category="inline-link">Outils ONTAP démarrage rapide</block>
  <block id="324b0410f22fb210bbf88e1ee7e97428" category="list-text"><block ref="324b0410f22fb210bbf88e1ee7e97428" category="inline-link-rx"></block></block>
  <block id="3d7fe3e43f9f24fffe5ed0d546d12f13" category="inline-link">Déployez les outils ONTAP</block>
  <block id="354336d78d1f0a156dcd5221d341dfd0" category="list-text"><block ref="354336d78d1f0a156dcd5221d341dfd0" category="inline-link-rx"></block></block>
  <block id="a2fa58344be7fbd9a2be0320a8df0f77" category="inline-link">Mettez à niveau les outils ONTAP</block>
  <block id="33a77e1014f1325d6ba19639a6c95d48" category="list-text"><block ref="33a77e1014f1325d6ba19639a6c95d48" category="inline-link-rx"></block></block>
  <block id="21e2a89d708329706ec6ed3fc989a1f6" category="section-title">Utilisez les outils ONTAP</block>
  <block id="91a9cfdbaaa44e0a9ad72e92533f763f" category="inline-link">Provisionner les datastores classiques</block>
  <block id="f27fe8f858d8a91950e214753b95722c" category="list-text"><block ref="f27fe8f858d8a91950e214753b95722c" category="inline-link-rx"></block></block>
  <block id="fc7d7e475ac8c3868d7426bb41df9b09" category="inline-link">Provisionner des datastores vVols</block>
  <block id="0c2552c3930f472b2d120f30d7aa0415" category="list-text"><block ref="0c2552c3930f472b2d120f30d7aa0415" category="inline-link-rx"></block></block>
  <block id="317bbf73ff27c5f981628c8fb83ebf22" category="inline-link">Configurez le contrôle d'accès basé sur des rôles</block>
  <block id="644ae78061acbb2254be4de3ea454b06" category="list-text"><block ref="644ae78061acbb2254be4de3ea454b06" category="inline-link-rx"></block></block>
  <block id="48bc2d028cb2a507ef974230ca3ba793" category="inline-link">Configurer les diagnostics à distance</block>
  <block id="fc0330812838aba14025bd70d41b943d" category="list-text"><block ref="fc0330812838aba14025bd70d41b943d" category="inline-link-rx"></block></block>
  <block id="641e9457539249e880725760f91d5ee2" category="inline-link">Configurez la haute disponibilité</block>
  <block id="5027a18a60c68e05df84cd699af74497" category="list-text"><block ref="5027a18a60c68e05df84cd699af74497" category="inline-link-rx"></block></block>
  <block id="04edeb5424c826c14a69edb777edf395" category="section-title">Protéger et gérer les datastores</block>
  <block id="e17534281670c5ea4e8d55420a63c98f" category="inline-link">Protection des datastores classiques</block>
  <block id="c8ac931d575d89c007212a35c8dde74c" category="list-text"><block ref="8f91d2113ff32de18906bad1cd446b0d" category="inline-link-rx"></block> Avec SRM</block>
  <block id="bff05cbbc19cad2bd10b9fe25dc34a1b" category="inline-link">Protection des machines virtuelles basées sur vVols</block>
  <block id="710b15d782f0c2c0411066b86644a12d" category="list-text"><block ref="7741c74d7508dc983fa4af0dff0bdda1" category="inline-link-rx"></block> Avec SRM</block>
  <block id="5267febc97a2cc385cc5c73995dc64df" category="inline-link">Surveiller les datastores classiques et les machines virtuelles</block>
  <block id="bac3b262bb348a54f9986c2b5dbf6024" category="list-text"><block ref="bac3b262bb348a54f9986c2b5dbf6024" category="inline-link-rx"></block></block>
  <block id="3123ece3c3b36f605758cb0c9a28f904" category="inline-link">Surveillez les datastores vvols et les machines virtuelles</block>
  <block id="75c07b623699e1947d011983a7823584" category="list-text"><block ref="75c07b623699e1947d011983a7823584" category="inline-link-rx"></block></block>
  <block id="73751ced5959ea3089346b01d42dde76" category="paragraph">Outre la documentation produit, des articles de la base de connaissances de support peuvent être utiles.</block>
  <block id="dd5138e8a4207a5b2fde43b411a4b5e1" category="section-title">Tableau de bord VASA Provider</block>
  <block id="6da01a643ea28efe37fa2d6fd06a634b" category="paragraph">Le fournisseur VASA inclut un tableau de bord contenant des informations sur les performances et la capacité des VM vVols individuelles. Ces informations proviennent directement de ONTAP pour les fichiers et les LUN VVol, notamment la latence, les IOPS, le débit et la disponibilité pour les 5 principales VM, ainsi que la latence et les IOPS pour les 5 principaux datastores. Il est activé par défaut lors de l'utilisation de ONTAP 9.7 ou version ultérieure. L'extraction et l'affichage des données initiales dans le tableau de bord peuvent prendre jusqu'à 30 minutes.</block>
  <block id="9b78e1fecb2bcc40733f2180691c7507" category="section-title">Tableau de bord vVols des outils ONTAP</block>
  <block id="4adf016da96258b45a1cf762298729b5" category="inline-image-macro">Tableau de bord vVols des outils ONTAP,400</block>
  <block id="73c1e14ddf3f32984f869ac3f122b2ca" category="paragraph"><block ref="73c1e14ddf3f32984f869ac3f122b2ca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cd47dd01745339787e4c7300389401f2" category="section-title">Et des meilleures pratiques</block>
  <block id="9ae938622297e9d4b14dd0006a8f0bf4" category="paragraph">*Limites*</block>
  <block id="b4f52a4fd0b07c9d904b95fc98a1cd45" category="inline-link">Configuration maximale</block>
  <block id="bc8259e306c73b2969e7ac6297000e64" category="paragraph">En général, ONTAP supporte les limites vVols définies par VMware (voir publié<block ref="a6efdd9b1a19df6105024b4869e0582b" category="inline-link-rx"></block>). Le tableau suivant récapitule les limites de ONTAP spécifiques en taille et en nombre de vVols. Toujours vérifier le<block ref="bb9c67b5a4c15a85b5e6aa6c9afd0285" category="inline-link-rx"></block> Pour connaître les limites mises à jour concernant les nombres et la taille des LUN et des fichiers.</block>
  <block id="9b7ad553354519b31ec860eef39e5f6b" category="paragraph">*ONTAP vVols limites*</block>
  <block id="130b78bfd6c9b050a912fec77e285e3f" category="cell">Capacité/fonctionnalité</block>
  <block id="6231ad61105cd983d3f0042762d3233d" category="cell">SAN (SCSI ou NVMe-of)</block>
  <block id="75d4e7871261a858356a58d682ab71de" category="cell">Taille maximale des vVols</block>
  <block id="9cfd7100738cee4daf7acd5e01d31e14" category="cell">62 Tio*</block>
  <block id="9a728251ad1e90577975ae9395374772" category="cell">Nombre maximal de vVols par volume FlexVol</block>
  <block id="021bbc7ee20b71134d53e20206bd6feb" category="cell">1024</block>
  <block id="46ba990c143630f55072434a6ea958c0" category="cell">2 milliards</block>
  <block id="cdbcf58620f0b4b0bbf3291386a99407" category="cell">Nombre maximal de vVols par nœud ONTAP</block>
  <block id="342264031889898ec1a553b4dd58d98c" category="cell">Jusqu'à 12,288**</block>
  <block id="659e5faa0bdb08327ba0719230e95be2" category="cell">50 milliards</block>
  <block id="43b49f27d93c6f55f54a68e8983d5479" category="cell">Nombre maximal de vVols par paire ONTAP</block>
  <block id="3941694d19c2d1fc406f055ab62cb9eb" category="cell">Jusqu'à 24,576**</block>
  <block id="d6b3e65f296fd23975dd6f1a915c4b22" category="cell">Nombre maximal de vVols par cluster ONTAP</block>
  <block id="2702ff8627a3990fc940d6f53463925e" category="cell">Jusqu'à 98,304**</block>
  <block id="4f0c25d6c688cf50460d11fecaa97fa8" category="cell">Aucune limite spécifique de cluster</block>
  <block id="855ecc47bb0d239e1fdf6fee84e24c75" category="cell">Nombre maximal d'objets QoS (groupe de règles partagé et niveau de service vVols individuel)</block>
  <block id="26890bd9dcb27c05f1ab5bcc859501b8" category="cell">12,000 à ONTAP 9.3 ; 40,000 avec ONTAP 9.4 et versions ultérieures</block>
  <block id="0e38f856cb713ce9eea79fa1c6b7dc32" category="list-text">Taille limite basée sur les systèmes ASA ou AFF et FAS exécutant ONTAP 9.12.1P2 et versions ultérieures.</block>
  <block id="d27c43bb3cdcbfa3852bb91192ffb849" category="list-text">Le nombre de vVols SAN (espaces de noms NVMe ou LUN) varie en fonction de la plateforme. Toujours vérifier le<block ref="bb9c67b5a4c15a85b5e6aa6c9afd0285" category="inline-link-rx"></block> Pour connaître les limites mises à jour concernant les nombres et la taille des LUN et des fichiers.</block>
  <block id="72e0ee397942f7233122887584f94b8b" category="paragraph">L'utilisation des vVols de ONTAP avec vSphere est simple et suit les méthodes vSphere publiées (consultez la documentation utilisation des volumes virtuels sous vSphere Storage in VMware pour votre version d'ESXi). Voici quelques autres pratiques à prendre en compte avec ONTAP.</block>
  <block id="83583580d98b69cb8317f9b285f3c8df" category="cell">*Utilisez les outils ONTAP pour les extensions d'interface utilisateur ou les API REST de VMware vSphere pour provisionner les datastores vVols* *et les terminaux de protocole.*</block>
  <block id="9507d4f97aceb8d05fc962dd53f082af" category="cell">Bien qu'il soit possible de créer des datastores vVols avec l'interface vSphere générale, l'utilisation des outils ONTAP crée automatiquement des terminaux de protocole selon les besoins et des volumes FlexVol en utilisant les bonnes pratiques ONTAP et conformément aux profils de capacité de stockage que vous avez définis. Il vous suffit de cliquer avec le bouton droit sur l'hôte/le cluster/le data Center, puis de sélectionner _ONTAP Tools_ et _provisioning datastore_. Ensuite, il vous suffit de choisir les options vVols souhaitées dans l'assistant.</block>
  <block id="e8d5f9dc0bff953a9e59755813c7e8bf" category="cell">*Ne stockez jamais l'appliance ONTAP Tools ou l'appliance vCenter Server (VCSA) sur un datastore vVols qu'ils gèrent.*</block>
  <block id="c6ac0465bff03857ee851d98f6bd782b" category="cell">Cela peut entraîner une « situation de poulet et d'œuf » si vous devez redémarrer les appareils parce qu'ils ne pourront pas réassocier leurs propres vVols pendant qu'ils redémarrent. Vous pouvez les stocker sur un datastore vVols géré par un autre outil ONTAP et un déploiement vCenter.</block>
  <block id="ab8d352870fb5334773c7177d3d5dcd1" category="cell">*Évitez les opérations vVols sur différentes versions de ONTAP.*</block>
  <block id="8b2bcef781b7e1f6d64739147d50aae7" category="cell">Les fonctionnalités de stockage prises en charge telles que la QoS, le personnalité et bien d'autres encore ont changé dans plusieurs versions du fournisseur VASA, et certaines dépendent de la version de ONTAP. L'utilisation de différentes versions dans un cluster ONTAP ou le déplacement de vVols entre clusters avec différentes versions peut entraîner un comportement inattendu ou des alarmes de conformité.</block>
  <block id="b2da0eca57c759eff034e6fe26f153e6" category="cell">*Zone votre fabric Fibre Channel avant d'utiliser NVMe/FC ou FCP pour vVols.*</block>
  <block id="cd7bf0e1e61341c1aa3fa23401af8a27" category="inline-image-macro">Segmentation à un seul initiateur avec quatre nœuds,400</block>
  <block id="51591d05b7e084ba8e5ae7f63172177e" category="inline-link">_TR-4080 meilleures pratiques pour le SAN moderne ONTAP 9_</block>
  <block id="c1723e6a0e1d3dd28232b33e0cb6e61d" category="inline-link">_TR-4684 implémentation et configuration de SAN modernes avec NVMe-of_</block>
  <block id="9a36c8f0464a7ffce114044f1859c7ff" category="cell">*Planifier vos volumes FlexVol de soutien en fonction de vos besoins.*</block>
  <block id="03d2e894fa9a05efefa4e8d6b2008a19" category="cell">Il peut être souhaitable d'ajouter plusieurs volumes de sauvegarde à votre datastore vVols pour distribuer la charge de travail au sein du cluster ONTAP, pour prendre en charge différentes options de règles ou pour augmenter le nombre de LUN ou de fichiers autorisés. Toutefois, si vous avez besoin d'une efficacité de stockage maximale, placez l'ensemble de vos volumes en arrière-forme sur un seul agrégat. Si des performances de clonage maximales sont requises, envisagez d'utiliser un seul volume FlexVol et de conserver vos modèles ou votre bibliothèque de contenu dans le même volume. Le fournisseur VASA délègue de nombreuses opérations de stockage vVols à ONTAP, notamment la migration, le clonage et les copies Snapshot. Cette opération est réalisée au sein d'un seul volume FlexVol, ce qui permet d'utiliser des clones de fichiers peu encombrants et de les mettre presque instantanément à disposition. Sur des volumes FlexVol, les copies sont rapidement disponibles et utilisent la déduplication et la compression à la volée. Toutefois, l'efficacité du stockage maximale ne peut pas être restaurée tant que des tâches en arrière-plan ne sont pas exécutées sur des volumes utilisant la déduplication et la compression en arrière-plan. Selon la source et la destination, une certaine efficacité peut être dégradée.</block>
  <block id="80b15469535d95a1690f308427545c7e" category="cell">*Conserver les profils de capacité de stockage (SCP) simples.*</block>
  <block id="33e2905cb722c14575a9bff81ba78b39" category="cell">Évitez de spécifier des fonctionnalités qui ne sont pas requises en les configurant sur n'importe quelle option. Cela permet de réduire les problèmes lors de la sélection ou de la création de volumes FlexVol. Par exemple, avec VASA Provider 7.1 et les versions antérieures, si la compression est laissée au paramètre SCP par défaut de non, elle tente de désactiver la compression, même sur un système AFF.</block>
  <block id="5a6d5fdddf6fbd82f1952b532b03c9ef" category="cell">*Utilisez les SCP par défaut comme modèles d'exemple pour créer vos propres.*</block>
  <block id="ee3cbda1c3c4a14ae024478c7ada6d11" category="cell">*Suivre toutes les meilleures pratiques du protocole.*</block>
  <block id="6a2c1ac1da51eca0c1a65afffab8dfab" category="inline-image-macro">Configuration réseau utilisant vVols sur NFS v3.500</block>
  <block id="6cacb3f1edd09835a2ad07d72f488e2a" category="paragraph">Le logiciel NetApp ONTAP est une solution de stockage leader pour les environnements VMware vSphere depuis plus de vingt ans et continue d'ajouter des fonctionnalités innovantes pour simplifier la gestion tout en réduisant les coûts.</block>
  <block id="918febfed3d070cf1250909e5cdcf31d" category="paragraph">Ce document présente les fonctionnalités de ONTAP pour les volumes virtuels VMware vSphere (vVols), notamment les dernières informations sur les produits et les cas d'utilisation, ainsi que les bonnes pratiques et d'autres informations permettant de rationaliser le déploiement et de réduire les erreurs.</block>
  <block id="c7448b194ba68bddce48f1d11d5d7db7" category="admonition">Cette documentation remplace les rapports techniques _TR-4400 : VMware vSphere Virtual volumes (vVols) par NetApp ONTAP_</block>
  <block id="d30f04665be7a6d9663004b1b5e61a9a" category="paragraph">Les meilleures pratiques complètent d'autres documents, tels que des guides et des listes de compatibilité. Ils sont développés en fonction de tests effectués en laboratoire et d'une vaste expérience sur le terrain par les ingénieurs et les clients NetApp. Ce ne sont peut-être pas les seules pratiques qui fonctionnent ou sont prises en charge, mais sont généralement les solutions les plus simples qui répondent aux besoins de la plupart des clients.</block>
  <block id="b010d2e253827dbb44b7ba4e1332e24e" category="admonition">Ce document a été mis à jour pour inclure les nouvelles fonctionnalités vVols de vSphere 8.0 mise à jour 1 prises en charge par la version 9.12 des outils ONTAP.</block>
  <block id="cc713c330b9c4e00d3ed7233bc54a889" category="section-title">Présentation des volumes virtuels (vVols)</block>
  <block id="64f0863a7fb5f52a7ac6a911e1ad6862" category="paragraph">En 2012, NetApp a commencé à travailler avec VMware pour prendre en charge les API vSphere pour Storage Awareness (VASA) pour vSphere 5. Ce premier VASA Provider a autorisé la définition des fonctionnalités de stockage dans un profil qui pouvait être utilisé pour filtrer les datastores lors du provisionnement et pour vérifier par la suite la conformité avec la règle. Cette évolution a vu le jour, de nouvelles fonctionnalités permettant d'automatiser davantage le provisionnement, ainsi que l'ajout de volumes virtuels ou de vVols où des objets de stockage individuels sont utilisés pour les fichiers de machines virtuelles et les disques virtuels. Il peut s'agir de LUN, de fichiers et désormais de vSphere 8. NVMe namespaces.NetApp a étroitement collaboré avec VMware en tant que partenaire de référence pour les vVols publiés avec vSphere 6 en 2015, puis en tant que partenaire de conception pour les vVols utilisant NVMe over Fabrics dans vSphere 8. NetApp continue d'améliorer les vVols pour tirer parti des dernières fonctionnalités d'ONTAP.</block>
  <block id="cbf0aa9daeb855e4eace1a3bdc474ce2" category="paragraph">Plusieurs composants doivent être pris en compte :</block>
  <block id="e2f6b83160ea0712fbc59dd84410c4b2" category="cell">*VASA Provider*</block>
  <block id="919601826e1d58bccaaab76d787871d2" category="cell">Il s'agit du composant logiciel qui gère la communication entre VMware vSphere et le système de stockage. Pour ONTAP, le fournisseur VASA s'exécute dans une appliance connue sous le nom d'outils ONTAP pour VMware vSphere (outils ONTAP pour, par exemple). Les outils ONTAP incluent également un plug-in vCenter, un adaptateur de réplication du stockage (SRA) pour VMware site Recovery Manager et un serveur d'API REST pour vous permettre de créer votre propre automatisation. Une fois les outils ONTAP configurés et enregistrés dans vCenter, il est désormais peu nécessaire d'interagir directement avec le système ONTAP, puisque la quasi-totalité de vos besoins en stockage peut être gérée directement depuis l'interface utilisateur vCenter ou via l'automatisation de l'API REST.</block>
  <block id="05ad8543ff165c6b8cd0cc5e976d3245" category="cell">*Point de terminaison de protocole (PE)*</block>
  <block id="3b2cd9018385f55c53c9a8b756df8bb5" category="cell">Le terminal de protocole est un proxy pour les E/S entre les hôtes ESXi et le datastore vVols. Le fournisseur ONTAP VASA les crée automatiquement, soit une LUN de terminal de protocole (4 Mo) par volume FlexVol du datastore vVols, soit un point de montage NFS par interface NFS (LIF) sur le nœud de stockage hébergeant un volume FlexVol dans le datastore. L'hôte ESXi monte ces terminaux de protocole directement plutôt que des LUN vVol individuelles et des fichiers de disque virtuel. Il n'est pas nécessaire de gérer les terminaux PE lorsqu'ils sont créés, montés, démontés et supprimés automatiquement par le fournisseur VASA, avec les groupes d'interfaces ou les règles d'exportation nécessaires.</block>
  <block id="d3f051e8316cfd36651af1e65be24a75" category="cell">*Point de terminaison de protocole virtuel (VPE)*</block>
  <block id="71afca0aa1a505ea2ac3ce5a1a681549" category="paragraph">Nouveauté de vSphere 8, lorsque NVMe over Fabrics (NVMe-of) avec vVols, le concept de terminal de protocole n'est plus pertinent dans ONTAP. Au lieu de cela, un PE virtuel est instancié automatiquement par l'hôte ESXi pour chaque groupe ANA dès que la première machine virtuelle est sous tension. ONTAP crée automatiquement des groupes ANA pour chaque volume FlexVol utilisé par le datastore.</block>
  <block id="8202498953d2ebcf9968c37a7e47f4f6" category="paragraph">Autre avantage de NVMe-of pour les vVols : aucune demande de liaison n'est requise du fournisseur VASA. À la place, l'hôte ESXi gère en interne la fonctionnalité de liaison vVol basée sur le VPE. Cela réduit les risques d'impact d'une tempête de liaison vVol sur le service.</block>
  <block id="70532c0374111d897ef1176b34b6396c" category="inline-link">NVMe et les volumes virtuels</block>
  <block id="50ec55042a7f4e8c2c66219ac096cfb3" category="inline-link">vmware.com</block>
  <block id="113c9d4e642d1ba4cc469267fb7fd0de" category="paragraph">Pour plus d'informations, voir<block ref="f8d477cd77073d731aafe4f52026608a" category="inline-link-rx"></block> marche<block ref="1f1565cca975c4a703345d21e7f273b8" category="inline-link-rx"></block></block>
  <block id="61def0b14af00df4eb90bcd79d858a8b" category="cell">*Datastore de volume virtuel*</block>
  <block id="b945cda41d7a84e7152e09343a17cbe6" category="cell">Le datastore de volume virtuel est une représentation de datastore logique d'un conteneur vVols créée et gérée par un fournisseur VASA. Le conteneur représente un pool de capacité de stockage provisionné à partir des systèmes de stockage gérés par le fournisseur VASA. Les outils ONTAP prennent en charge l'allocation de plusieurs volumes FlexVol (appelés « volumes de sauvegarde ») à un datastore vVols unique. Ces datastores vVols peuvent couvrir plusieurs nœuds dans un cluster ONTAP, combinant des systèmes Flash et hybrides ayant des fonctionnalités différentes. L'administrateur peut créer de nouveaux volumes FlexVol à l'aide de l'assistant de provisionnement ou de l'API REST, ou sélectionner des volumes FlexVol précréés pour la sauvegarde du stockage, le cas échéant.</block>
  <block id="c25d2cc7c6540f6ac98af67455eecc39" category="cell">*Volumes virtuels (vVols)*</block>
  <block id="9664cdf7951789389813facac649fec1" category="cell">VVols sont les fichiers et disques de machines virtuelles réellement stockés dans le datastore vVols. L'utilisation du terme vVol (singulier) fait référence à un fichier, une LUN ou un espace de nom spécifique unique. ONTAP crée des namespaces NVMe, des LUN ou des fichiers en fonction du protocole utilisé par le datastore. Il existe plusieurs types distincts de vVols : les plus courants sont Config (fichiers de métadonnées), Data (disque virtuel ou VMDK) et Swap (créé lorsque la machine virtuelle est sous tension). Les vVols protégées par le chiffrement de machines virtuelles VMware seront de type autre. Le chiffrement des machines virtuelles VMware ne doit pas être confondu avec le chiffrement du volume ou de l'agrégat ONTAP.</block>
  <block id="937251054fa0c1a7b946f8928cc857b9" category="section-title">Gestion stratégique</block>
  <block id="34d2b7d8b570ede7a638d070656b7b81" category="paragraph">Avec VMware vSphere APIs for Storage Awareness (VASA), un administrateur de serveurs virtuels peut facilement utiliser les fonctionnalités de stockage nécessaires pour provisionner des serveurs virtuels sans avoir à interagir avec son équipe de stockage. Avant VASA, les administrateurs de VM pouvaient définir des règles de stockage de VM, mais devaient travailler avec leurs administrateurs de stockage pour identifier les datastores appropriés, souvent à l'aide de la documentation ou des conventions de nommage. Dans VASA, les administrateurs de vCenter disposant des autorisations appropriées peuvent définir une gamme de fonctionnalités de stockage que les utilisateurs de vCenter peuvent ensuite utiliser pour provisionner des VM. Le mappage entre la règle de stockage de machine virtuelle et le profil de capacité de stockage de datastore permet à vCenter d'afficher une liste de datastores compatibles à sélectionner, ainsi que d'activer d'autres technologies telles que Aria (anciennement vRealize) Automation ou Tanzu Kubernetes Grid pour sélectionner automatiquement le stockage dans une règle attribuée. Cette approche est appelée gestion basée sur des règles de stockage. Si les profils et les politiques de capacité de stockage peuvent également être utilisés avec les datastores classiques, nous nous concentrons ici sur les datastores vVols.</block>
  <block id="631bdc7de6608fd57c3fa0b397c3c26f" category="paragraph">Il existe deux éléments :</block>
  <block id="a156a7f38a3727ce705b5466eb11e0bf" category="cell">*Profil de capacité de stockage (SCP)*</block>
  <block id="43a258e66ca875fa9c5d3e35e06ba2b7" category="cell">Un profil de capacité de stockage (SCP) est un modèle de stockage qui permet à l'administrateur vCenter de définir les fonctionnalités de stockage dont ils ont besoin sans avoir à comprendre comment gérer ces fonctionnalités dans ONTAP. En adoptant une approche de type modèle, il permet à l'administrateur de fournir facilement des services de stockage de manière cohérente et prévisible. Les fonctionnalités décrites dans un SCP incluent les performances, le protocole, l'efficacité du stockage et d'autres fonctionnalités. Les fonctionnalités spécifiques varient selon la version. Leur création s'est effectuée à l'aide du menu ONTAP Tools for VMware vSphere de l'interface utilisateur vCenter. Vous pouvez également utiliser des API REST pour créer des SCP. Elles peuvent être créées manuellement en sélectionnant des fonctionnalités individuelles ou générées automatiquement à partir de datastores existants (traditionnels).</block>
  <block id="8f50a0757d99fe5dd0df8d19478d4921" category="cell">*Stratégie de stockage VM*</block>
  <block id="f99c5cf9298b040025bd3dfe966cb86e" category="cell">Les règles de stockage de serveur virtuel sont créées dans vCenter sous stratégies et profils. Pour les vVols, créez un jeu de règles à l'aide de règles provenant du fournisseur de type de stockage NetApp vVols. Les outils ONTAP offrent une approche simplifiée en vous permettant de sélectionner simplement un SCP plutôt que de vous obliger à spécifier des règles individuelles.</block>
  <block id="5dda8b04866334dc92ee08001b15701a" category="paragraph">Comme mentionné ci-dessus, l'utilisation des règles peut aider à rationaliser le provisionnement d'un volume. Il suffit de sélectionner une règle appropriée, et le fournisseur VASA affiche les datastores vVols qui prennent en charge cette règle et place le vVol dans un volume FlexVol individuel conforme (Figure 1).</block>
  <block id="2ce0d6ec59cca7e0b6e0bdc389301e63" category="section-title">Déployer une machine virtuelle à l'aide de la stratégie de stockage</block>
  <block id="e0795f8b847058e171dec5a519757ece" category="image-alt">Déploiement d'une machine virtuelle à l'aide d'une stratégie de stockage</block>
  <block id="f0d0f0a6174a5a9dde27782042e22ccf" category="paragraph">Une fois qu'une machine virtuelle est provisionnée, le fournisseur VASA continue à vérifier la conformité et alerte l'administrateur de la machine virtuelle en cas d'alarme dans vCenter lorsque le volume de sauvegarde n'est plus conforme à la règle (Figure 2).</block>
  <block id="941431bc1cecb0ec5e89e78e9a5a96fc" category="section-title">Conformité à la règle de stockage VM</block>
  <block id="bfd6dec22a6a1724ff1b67f1f289cdfc" category="image-alt">Conformité aux règles de stockage des machines virtuelles</block>
  <block id="e08bc5b354c3e8058003a662e0f7cade" category="section-title">Prise en charge des vVols de NetApp</block>
  <block id="234ad0324c313ec05d0fa6fe8d430967" category="paragraph">NetApp ONTAP prend en charge la spécification VASA depuis sa sortie initiale en 2012. Si d'autres systèmes de stockage NetApp peuvent prendre en charge VASA, ce document est axé sur les versions actuellement prises en charge de ONTAP 9.</block>
  <block id="7b02ea300aef2e0bff0d7f6111053284" category="section-title">NetApp ONTAP</block>
  <block id="4d53a8e49ac64213ffccdd970a35171e" category="paragraph">Outre ONTAP 9 sur les systèmes AFF, ASA et FAS, NetApp prend en charge les workloads VMware sur ONTAP Select, Amazon FSX pour NetApp ONTAP avec VMware Cloud sur AWS, Azure NetApp Files avec la solution Azure VMware, Cloud Volumes Service avec Google Cloud VMware Engine et le stockage privé NetApp dans Equinix, mais certaines fonctionnalités peuvent varier en fonction du fournisseur de services et de la connectivité réseau disponible. L'accès, depuis les invités vSphere, aux données stockées dans ces configurations ainsi qu'à Cloud Volumes ONTAP est également disponible.</block>
  <block id="9fe1fd556b933358881222d5c3da127c" category="paragraph">Au moment de la publication, les environnements hyperscale sont limités aux datastores NFS v3 classiques. Par conséquent, les vVols ne sont disponibles que pour les systèmes ONTAP sur site ou les systèmes connectés au cloud qui offrent l'ensemble des fonctionnalités d'un système sur site, tels que ceux hébergés par les partenaires et fournisseurs de services NetApp à travers le monde.</block>
  <block id="274bc582ca884fc158ea9ac9f79f9067" category="inline-link">Documentation des produits ONTAP</block>
  <block id="5ca60fe92dec435059ba5acefa4ce2c9" category="paragraph">_Pour plus d'informations sur ONTAP, voir<block ref="8a9b15dc18a16e0b1acfa438e27f6aa6" category="inline-link-rx"></block>_</block>
  <block id="3dffa984dadf9ff0006ee9cebd3b04b9" category="inline-link">TR-4597</block>
  <block id="9a03bb7ec5329e35d98c7b12b63c4df0" category="paragraph">_Pour plus d'informations sur les meilleures pratiques ONTAP et VMware vSphere, voir<block ref="fc9815e7b1405959c49ad47e9a23e3a5" category="inline-link-rx"></block>_</block>
  <block id="d3fb76da5fbbcd6fa32e40910b5b9a47" category="section-title">Avantages de l'utilisation de vVols avec ONTAP</block>
  <block id="d0f004282063136e91d76d1d43d7c95f" category="paragraph">Lorsque VMware a introduit la prise en charge de vVols avec VASA 2.0 en 2015, ils l'ont décrite comme « une structure d'intégration et de gestion fournissant un nouveau modèle opérationnel pour le stockage externe (SAN/NAS) ». Ce modèle opérationnel présente plusieurs avantages avec le stockage ONTAP.</block>
  <block id="6a74f7c0a9021e009a9c030e54084978" category="paragraph">Comme décrit à la section 1.2, la gestion basée sur des règles permet de provisionner les machines virtuelles et de les gérer par la suite à l'aide de règles prédéfinies. Les opérations INFORMATIQUES peuvent ainsi être réalisées de plusieurs manières :</block>
  <block id="e0eb51b6d319e14c2fbfc1f628021a26" category="list-text">*Augmentez la vitesse.* les outils ONTAP éliminent la nécessité pour l'administrateur vCenter d'ouvrir des tickets avec l'équipe chargée du stockage pour les activités de provisionnement du stockage. Cependant, les rôles RBAC des outils ONTAP dans vCenter et sur le système ONTAP permettent toujours l'accès à des équipes indépendantes (telles que les équipes chargées du stockage) ou à des activités indépendantes par la même équipe en limitant l'accès à des fonctions spécifiques si nécessaire.</block>
  <block id="3f4dbd6687bd0d55bf69fe5fdd0137c4" category="list-text">*Provisionnement plus intelligent.* les fonctionnalités du système de stockage peuvent être exposées via les API VASA, ce qui permet aux flux de travail de provisionnement de tirer parti de fonctionnalités avancées sans que l'administrateur des machines virtuelles ait besoin de comprendre comment gérer le système de stockage.</block>
  <block id="a13fcc9220d042cae454e9ac073636ca" category="list-text">*Provisionnement plus rapide.* différentes capacités de stockage peuvent être prises en charge dans un seul datastore et sélectionnées automatiquement comme approprié pour une machine virtuelle en fonction de la stratégie de la machine virtuelle.</block>
  <block id="eb4c052226108afebf26e670208b9a55" category="list-text">*Évitez les erreurs.* les stratégies de stockage et de machines virtuelles sont développées à l'avance et appliquées selon les besoins sans avoir à personnaliser le stockage à chaque fois qu'une machine virtuelle est provisionnée. Les alarmes de conformité sont déclenchées lorsque les fonctionnalités de stockage sont différentes des règles définies. Comme mentionné précédemment, les plateformes SCP rendent le provisionnement initial prévisible et reproductible, tandis que la base des règles de stockage des serveurs virtuels sur les plateformes SCP garantit un placement précis.</block>
  <block id="9c520768a1d84268417335cf19a423b9" category="list-text">*Meilleure gestion de la capacité.* les outils VASA et ONTAP permettent de visualiser la capacité de stockage jusqu'au niveau de l'agrégat industriel si nécessaire et de fournir plusieurs couches d'alertes en cas de début d'exécution de la capacité.</block>
  <block id="f9878e32fdf258284c007eaae38773cd" category="section-title">Gestion granulaire des machines virtuelles dans le SAN moderne</block>
  <block id="7e673a7c12cc256f29bcd7b2028d9d5a" category="paragraph">Les systèmes DE stockage SAN utilisant Fibre Channel et iSCSI ont été les premiers à être pris en charge par VMware pour ESX, mais ils n'ont pas été en mesure de gérer les disques et les fichiers individuels des machines virtuelles à partir du système de stockage. Au lieu de cela, les LUN sont provisionnées et VMFS gère les fichiers individuels. Il est donc difficile pour le système de stockage de gérer directement les performances, le clonage et la protection du stockage des machines virtuelles individuelles. Les vVols apportent la granularité du stockage dont les clients utilisent déjà le stockage NFS, et les fonctionnalités SAN robustes et hautes performances de ONTAP.</block>
  <block id="25a46370807e0eab0dfe3853abfb9b6e" category="paragraph">Désormais, avec vSphere 8 et les outils ONTAP pour VMware vSphere 9.12 et versions ultérieures, les mêmes contrôles granulaires utilisés par les vVols pour les anciens protocoles SCSI sont désormais disponibles dans le SAN Fibre Channel moderne utilisant NVMe over Fabrics pour des performances encore plus élevées à grande échelle. Avec vSphere 8.0 mise à jour 1, il est désormais possible de déployer une solution NVMe de bout en bout complète à l'aide de vVols sans déplacement d'E/S dans la pile de stockage de l'hyperviseur.</block>
  <block id="f61f57f748f5f0b52c7f11f1f1bd43f0" category="section-title">Meilleures fonctionnalités de déchargement du stockage</block>
  <block id="911fa02c34dda38cd69be06e524ed9d0" category="inline-link">Garantie d'efficacité</block>
  <block id="3170031d77f241bc872afcb490c0a806" category="paragraph">Tandis que VAAI offre de nombreuses opérations qui sont déchargées vers le stockage, certaines lacunes sont traitées par le fournisseur VASA. SAN VAAI ne peut pas décharger les snapshots gérés par VMware vers le système de stockage. NFS VAAI peut décharger les snapshots gérés par les machines virtuelles, mais il existe des limites placées pour les machines virtuelles avec des snapshots natifs de stockage. Étant donné que les vVols utilisent des LUN, des espaces de noms ou des fichiers individuels pour des disques de machines virtuelles, ONTAP peut rapidement et efficacement cloner les fichiers ou les LUN pour créer des snapshots granulaires de machines virtuelles qui ne nécessitent plus de fichiers delta. NFS VAAI ne prend pas non plus en charge les opérations de déchargement des clones pour les migrations Storage vMotion à chaud (basées sur). La machine virtuelle doit être mise hors tension pour permettre la décharge de la migration lors de l'utilisation de VAAI avec des datastores NFS classiques. Le fournisseur VASA des outils ONTAP permet des clones quasi instantanés et efficaces du stockage pour les migrations à chaud et à froid, et prend également en charge les copies quasi instantanées pour les migrations de volumes croisés de vVols. En raison de ces avantages considérables en matière d'efficacité du stockage, vous pouvez tirer pleinement parti des workloads vVols sous le<block ref="9d1af7a9d4f98887e53c1a9bedbce044" category="inline-link-rx"></block> programme. De même, si les clones multi-volumes à l'aide de VAAI ne répondent pas à vos besoins, vous serez probablement en mesure de relever vos défis business grâce aux améliorations apportées à l'expérience de copie des vVols.</block>
  <block id="a8567b4dc683947384ef2e1dd0fc6ac1" category="section-title">Cas d'utilisation courants des vVols</block>
  <block id="48e535b80538b088fd868fde9372715c" category="paragraph">Outre ces avantages, plusieurs cas d'utilisation courants sont également mentionnés ci-dessous pour le stockage vVol :</block>
  <block id="441f01ec38e91fad1b235a0e7422a178" category="list-text">*Provisionnement à la demande des machines virtuelles*</block>
  <block id="bd652a918164d8fa5176b5f9b92c2e61" category="list-text">Cloud privé ou IaaS d'un Service Provider.</block>
  <block id="fddccd9595370687015a5ab02bcff60f" category="list-text">Exploitez l'automatisation et l'orchestration via la suite Aria (anciennement vRealize), OpenStack, etc</block>
  <block id="4fbc1141a40f5259e3ab1545de52b1ea" category="list-text">*Disques de première classe (FCDS)*</block>
  <block id="e83f2e4e8676ee8faac4d6af599fd7e7" category="list-text">Volumes persistants VMware Tanzu Kubernetes Grid [TKG].</block>
  <block id="b2b81490f2245d3d566e0ccc6a29cfc2" category="list-text">Proposez des services Amazon EBS avec une gestion indépendante du cycle de vie VMDK.</block>
  <block id="2511e4e8cbb72027ae20f24008d4b939" category="list-text">*Approvisionnement à la demande des machines virtuelles temporaires*</block>
  <block id="eeb1044cc319a5d53503e45dbf762291" category="list-text">Laboratoires de test et de développement</block>
  <block id="858d314810762abccaa7baf230e3dc18" category="list-text">Environnements de formation</block>
  <block id="ab7bbc294bf0f0354980a3014e8f4219" category="section-title">Bénéfices communs avec les vVols</block>
  <block id="ccd6ea8c57e93a5401d07aab9c60f371" category="paragraph">Lorsqu'ils sont utilisés à leur plein avantage, comme dans les cas d'utilisation ci-dessus, les vVols apportent les améliorations spécifiques suivantes :</block>
  <block id="13491b3af50183642ea0035b2d1f95f9" category="list-text">La création de clones est rapide au sein d'un seul volume ou sur plusieurs volumes d'un cluster ONTAP. C'est un avantage par rapport aux clones classiques compatibles VAAI. Ils sont également efficaces en termes de stockage. Les clones d'un volume utilisent un clone de fichier ONTAP, qui ressemble aux volumes FlexClone et ne stockent que les modifications du fichier vVol source, de la LUN ou de l'espace de noms. Ainsi, les machines virtuelles à long terme pour la production ou d'autres applications sont créées rapidement, prennent un minimum d'espace et peuvent bénéficier de la protection au niveau des machines virtuelles (à l'aide du plug-in NetApp SnapCenter pour VMware vSphere, des snapshots gérés par VMware ou de la sauvegarde VADP) et de la gestion des performances (avec ONTAP QoS).</block>
  <block id="1c21847cdc5616af138ba0c03aad7adb" category="list-text">Les vVols sont la technologie de stockage idéale lors de l'utilisation de TKG avec vSphere CSI, fournissant des classes et des capacités de stockage distinctes gérées par l'administrateur vCenter.</block>
  <block id="d5f068caef73978a5483badd927a7e98" category="list-text">Les services de type Amazon EBS peuvent être fournis via les disques FCD, car un VMDK FCD, comme son nom l'indique, est citoyen de premier ordre dans vSphere et possède un cycle de vie qui peut être géré de manière indépendante, indépendamment des machines virtuelles auxquelles il peut être rattaché.</block>
  <block id="7e7040600922b2a78715f856613a3c08" category="doc">Protection des vVols</block>
  <block id="de92c927f248723e4668aec459709995" category="section-title">Haute disponibilité VASA Provider</block>
  <block id="f4d4cb8868f07cad16bd7de7e36c5201" category="paragraph">Le fournisseur NetApp VASA s'exécute en tant que composant de l'appliance virtuelle, avec le plug-in vCenter et le serveur d'API REST (anciennement Virtual Storage Console [VSC]) et Storage Replication adapter. Si le fournisseur VASA n'est pas disponible, les machines virtuelles utilisant des vVols continueront à s'exécuter. Toutefois, il n'est pas possible de créer de nouveaux datastores vVols et ne peut pas être créé ni lié par vSphere. Cela signifie que les machines virtuelles utilisant des vVols ne peuvent pas être activées car vCenter ne pourra pas demander la création du vVol de swap. De plus, les machines virtuelles en cours d'exécution ne peuvent pas utiliser vMotion pour la migration vers un autre hôte, car les vVols ne peuvent pas être liés au nouvel hôte.</block>
  <block id="3958bf41787d7fcc6a9f8dd9348c947f" category="paragraph">Vasa Provider 7.1 et les versions ultérieures prennent en charge de nouvelles fonctionnalités pour s'assurer que les services sont disponibles dès que nécessaire. Elle comprend de nouveaux processus de surveillance qui surveillent VASA Provider et des services de base de données intégrés. S'il détecte une défaillance, il met à jour les fichiers journaux, puis redémarre automatiquement les services.</block>
  <block id="1acc458c695b0d3dfbf588309801fda2" category="paragraph">L'administrateur vSphere doit configurer une protection supplémentaire en utilisant les mêmes fonctionnalités de disponibilité que celles utilisées pour protéger les autres ordinateurs virtuels stratégiques contre les défaillances logicielles, matérielles hôtes et réseau. Aucune configuration supplémentaire n'est requise sur l'appliance virtuelle pour utiliser ces fonctionnalités ; il vous suffit de les configurer à l'aide des approches vSphere standard. Ils ont été testés et sont pris en charge par NetApp.</block>
  <block id="ff43afff832597ff45e5abeab2826ccf" category="inline-link">Documentation relative aux outils ONTAP pour VMware vSphere (configuration de la haute disponibilité des outils ONTAP)</block>
  <block id="d516ca4c9c18446a82d9fc9ee85bd955" category="paragraph">VSphere High Availability est facilement configuré pour redémarrer une machine virtuelle sur un autre hôte du cluster hôte en cas de panne. VSphere Fault Tolerance offre une plus grande disponibilité en créant une machine virtuelle secondaire répliquée en continu et capable de prendre le relais à tout moment. Des informations supplémentaires sur ces fonctions sont disponibles dans le<block ref="b6d78cbf1d5afb52929c529b32a350ad" category="inline-link-rx"></block>, Ainsi que la documentation VMware vSphere (recherchez vSphere Availability sous ESXi et vCenter Server).</block>
  <block id="97ba24d475ff6fdc7743099992cc301f" category="paragraph">Le fournisseur VASA des outils ONTAP sauvegarde automatiquement la configuration vVols en temps réel vers des systèmes ONTAP gérés où les informations vVols sont stockées dans les métadonnées de volume FlexVol. Si l'appliance ONTAP Tools devient indisponible, quelle qu'en soit la raison, vous pouvez facilement et rapidement en déployer une nouvelle et importer la configuration. Pour plus d'informations sur les étapes de restauration d'un fournisseur VASA, consultez cet article de la base de connaissances :</block>
  <block id="6799b6ec743f9159edf3b43790210a11" category="inline-link">Guide de résolution des incidents VASA Provider</block>
  <block id="9462790a7557a7eb2fe9daad4b875817" category="paragraph"><block ref="9462790a7557a7eb2fe9daad4b875817" category="inline-link-rx"></block></block>
  <block id="029a7740ecd792264454f9dbe194e980" category="section-title">Réplication vVols</block>
  <block id="c7b26217fd0c9041b6f779a0f669de5c" category="paragraph">De nombreux clients ONTAP répliquent leurs datastores classiques sur des systèmes de stockage secondaires à l'aide de NetApp SnapMirror, puis utilisent le système secondaire pour restaurer des machines virtuelles individuelles ou la totalité d'un site en cas d'incident. Dans la plupart des cas, les clients utilisent un outil logiciel pour gérer ceci, tel qu'un logiciel de sauvegarde tel que le plug-in NetApp SnapCenter pour VMware vSphere ou une solution de reprise après incident telle que site Recovery Manager de VMware (avec l'adaptateur de réplication du stockage dans les outils ONTAP).</block>
  <block id="bc6303e4538280b1b01d45a5f7d20039" category="paragraph">Cette exigence relative à un outil logiciel est encore plus importante pour la gestion de la réplication des vVols. Les fonctionnalités natives permettent de gérer certains aspects (par exemple, les copies Snapshot des vVols gérées par VMware sont déchargées vers ONTAP, qui utilise des clones de fichiers ou de LUN rapides et efficaces). Toutefois, l'orchestration générale est nécessaire pour gérer la réplication et la restauration. Les métadonnées concernant les vVols sont protégées par ONTAP et par le fournisseur VASA, mais des traitements supplémentaires sont nécessaires pour les utiliser sur un site secondaire.</block>
  <block id="c6a26835eb364bad22b16cb127b74135" category="paragraph">Les outils ONTAP 9.7.1 associés à VMware site Recovery Manager (SRM) 8.3 ont également pris en charge la reprise après incident et l'orchestration des flux de travail de migration en tirant parti de la technologie NetApp SnapMirror.</block>
  <block id="2803a799fd66056eff404a17ba640c2b" category="paragraph">Dans la version initiale de la prise en charge de SRM avec les outils ONTAP 9.7.1, il était nécessaire de pré-créer les volumes FlexVol et d'activer la protection SnapMirror avant de les utiliser comme volumes de sauvegarde pour un datastore vVols. À partir des outils ONTAP 9.10, ce processus n'est plus nécessaire. Vous pouvez désormais ajouter la protection SnapMirror aux volumes de sauvegarde existants et mettre à jour les règles de stockage de vos machines virtuelles afin de bénéficier d'une gestion basée sur des règles avec reprise après incident, orchestration de la migration et automatisation intégrées à SRM.</block>
  <block id="8142fcf496d02a58ce02a17558db863e" category="paragraph">Actuellement, VMware SRM est la seule solution d'automatisation de la migration et de la reprise après incident pour les vVols pris en charge par NetApp. Les outils ONTAP vérifient l'existence d'un serveur SRM 8.3 ou version ultérieure enregistré dans votre vCenter avant de vous permettre d'activer la réplication vVols, Vous pouvez exploiter les API REST d'outils ONTAP pour créer vos propres services.</block>
  <block id="7d8e8eced8d8b1a50f20640ffb5d363a" category="section-title">Réplication de vVols avec SRM</block>
  <block id="4d30574e6d5bc9a71718858eeb30774c" category="inline-image-macro">Réplication des vVols avec SRM,300</block>
  <block id="5844b0ec1ad8db5185ec67effeb9a7b7" category="paragraph"><block ref="5844b0ec1ad8db5185ec67effeb9a7b7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c95aede1de7a41511c9d962deba49054" category="section-title">Support MetroCluster</block>
  <block id="3f15bb720adb42bd521a2ce1cb3a2974" category="paragraph">Bien que les outils ONTAP ne soient pas capables de déclencher un basculement MetroCluster, ils prennent en charge les systèmes NetApp MetroCluster pour les vVols soutenant les volumes dans une configuration vMSC (vSphere Metro Storage Cluster) uniforme. Le basculement d'un système MetroCluster est géré de la manière habituelle.</block>
  <block id="cde16c5ee89c209c821e120caf65bb81" category="paragraph">Même si NetApp SnapMirror Business Continuity (SM-BC) peut également servir de base pour une configuration vMSC, il n'est pas pris en charge avec les vVols.</block>
  <block id="c859f5cd725cb2d1b163e4b066bede9a" category="paragraph">Pour plus d'informations sur NetApp MetroCluster, consultez ces guides :</block>
  <block id="e5e0fb3ae5564674a6548ade7c601578" category="inline-link">_TR-4689 Architecture et conception de la solution MetroCluster IP_</block>
  <block id="e64de4e49a37e62ff7f8c37e859bbeb9" category="paragraph"><block ref="e64de4e49a37e62ff7f8c37e859bbeb9" category="inline-link-rx"></block></block>
  <block id="0229efec9dc9b9a7fdf144b025157176" category="inline-link">_TR-4705 Architecture et conception de la solution NetApp MetroCluster_</block>
  <block id="6aee4b78ffdfaf193918978472d660a7" category="paragraph"><block ref="6aee4b78ffdfaf193918978472d660a7" category="inline-link-rx"></block></block>
  <block id="876341bac548f230eb390348e8b075ad" category="inline-link">_VMware KB 2031038 prise en charge de VMware vSphere avec NetApp MetroCluster_</block>
  <block id="5e68486fffeebad2ed145408dc250367" category="paragraph"><block ref="5e68486fffeebad2ed145408dc250367" category="inline-link-rx"></block></block>
  <block id="50c323f7050912164118ba47eab75888" category="section-title">Présentation de la sauvegarde vVols</block>
  <block id="6751e706567f4773c4f3138b4de51a0f" category="paragraph">Il existe plusieurs approches pour protéger les machines virtuelles, telles que l'utilisation d'agents de sauvegarde invités, la connexion de fichiers de données VM à un proxy de sauvegarde ou l'utilisation d'API définies telles que VMware VADP. Les vVols peuvent être protégées à l'aide des mêmes mécanismes et de nombreux partenaires NetApp prennent en charge les sauvegardes de machines virtuelles, y compris les vVols.</block>
  <block id="416d27c872769e934ac8a49ec98ccb53" category="paragraph">Comme mentionné précédemment, les snapshots gérés par VMware vCenter sont déchargés dans des clones de fichiers/LUN ONTAP rapides et compacts. Elles peuvent être utilisées pour des sauvegardes rapides et manuelles, mais vCenter limite le nombre de snapshots à 32. Vous pouvez utiliser vCenter pour créer des snapshots et restaurer les données selon vos besoins.</block>
  <block id="8f3d5ae5bd7d8922841975ccd84b8526" category="paragraph">À partir du plug-in SnapCenter pour VMware vSphere (SCV) 4.6 utilisé conjointement avec les outils ONTAP 9.10 et versions ultérieures, ajoute la prise en charge de la sauvegarde et de la restauration cohérentes après panne des machines virtuelles basées sur vVols exploitant les snapshots de volume ONTAP FlexVol avec prise en charge de la réplication SnapMirror et SnapVault. Jusqu'à 1023 copies Snapshot sont prises en charge par volume. SCV peut également stocker davantage de copies Snapshot avec une conservation plus longue sur des volumes secondaires à l'aide de SnapMirror avec une règle de copie miroir.</block>
  <block id="1429a9379faa8e82f8b198e93eebdf61" category="paragraph">La prise en charge de vSphere 8.0 a été introduite avec SCV 4.7, qui utilisait une architecture de plug-ins locaux isolée. La prise en charge de vSphere 8.0U1 a été ajoutée à SCV 4.8, qui a entièrement migré vers la nouvelle architecture de plug-ins distants.</block>
  <block id="de1d77d00dae616276b6ceb6296a18f2" category="section-title">VVols Backup avec le plug-in SnapCenter pour VMware vSphere</block>
  <block id="02f41838319aab980999b60967d7fd53" category="paragraph">Avec NetApp SnapCenter, vous pouvez désormais créer des groupes de ressources pour les vVols à partir de balises et/ou de dossiers afin de tirer automatiquement parti des snapshots FlexVol d'ONTAP pour les machines virtuelles basées sur vVols. Cela vous permet de définir des services de sauvegarde et de restauration qui protègent automatiquement les machines virtuelles lorsqu'elles sont provisionnées dynamiquement au sein de votre environnement.</block>
  <block id="4549a2943666c4815098331d30a872da" category="paragraph">Le plug-in SnapCenter pour VMware vSphere est déployé en tant qu'appliance autonome enregistrée en tant qu'extension vCenter, gérée via l'interface utilisateur vCenter ou via les API REST pour l'automatisation des services de sauvegarde et de restauration.</block>
  <block id="26e2418d177df1dddb008e455ce28752" category="section-title">Architecture SnapCenter</block>
  <block id="3b345c0fb5d2f0451ef84d991b21dcac" category="inline-image-macro">Architecture SnapCenter,300</block>
  <block id="af9bca7d8452705ba7f607cd036dba01" category="paragraph"><block ref="af9bca7d8452705ba7f607cd036dba01" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c32197281aa44f57ae568a9a42c7b3b6" category="paragraph">Comme les autres plug-ins SnapCenter ne prennent pas encore en charge les vVols au moment de la rédaction de ce document, nous nous concentrerons sur le modèle de déploiement autonome présenté dans ce document.</block>
  <block id="6750052f2c0fb06d80a8efd7cb871190" category="paragraph">Étant donné que SnapCenter utilise les copies Snapshot ONTAP FlexVol, il n'y a pas de surcharge placée sur vSphere, ni de réduction des performances comme on peut le voir avec les machines virtuelles traditionnelles utilisant les snapshots gérés par vCenter. De plus, comme la fonctionnalité de SCV est exposée via les API REST, il est facile de créer des workflows automatisés à l'aide d'outils tels que VMware Aria Automation, Ansible, Terraform et pratiquement tous les autres outils d'automatisation capables d'utiliser des API REST standard.</block>
  <block id="0c889d77d71512ceb7241bd0f6d6ca23" category="inline-link">Présentation des API REST</block>
  <block id="35eab4195b135718da016e20979f9031" category="paragraph">Pour plus d'informations sur les API REST de SnapCenter, reportez-vous à la section<block ref="33852d6f529e96c0b816da3945bcb1e5" category="inline-link-rx"></block></block>
  <block id="4ee2d383554981f4ea8eff4f35db6832" category="inline-link">Plug-in SnapCenter pour les API REST VMware vSphere</block>
  <block id="63ae61e98eec102c39264a819a3c522e" category="paragraph">Pour plus d'informations sur le plug-in SnapCenter pour les API REST VMware vSphere, consultez la section<block ref="40a6c7462de67e21480b7a31e406f8f9" category="inline-link-rx"></block></block>
  <block id="bdf03d5c2a7086b6c916dc96d06a0a6c" category="paragraph">Les bonnes pratiques suivantes peuvent vous aider à tirer le meilleur parti de votre déploiement SnapCenter.</block>
  <block id="60af6a4208b610da54a63a7e3658d5a5" category="list-text">SCV prend en charge les rôles RBAC vCenter Server et ONTAP RBAC et inclut des rôles vCenter prédéfinis qui sont automatiquement créés pour vous lorsque le plug-in est enregistré. Vous pouvez en savoir plus sur les types de RBAC pris en charge<block ref="a8ef9d6a500bd8288101245a3828ddb1" category="inline-link-rx"></block></block>
  <block id="0ed0835259b5b8c4b0f0910e7bfe2b17" category="list-text">Utilisez l'interface utilisateur de vCenter pour attribuer l'accès au compte le moins privilégié à l'aide des rôles prédéfinis décrits<block ref="17b3487f3493b9c198e03f92348bfca0" category="inline-link-rx"></block>.</block>
  <block id="d53326766687d6bc7fa2e28ee177e809" category="list-text">Si vous utilisez SCV avec le serveur SnapCenter, vous devez attribuer le rôle _SnapCenter_Admin_.</block>
  <block id="61ba6cb0b6021c205d41ed7f6fc1eb71" category="list-text">ONTAP RBAC fait référence au compte utilisateur utilisé pour ajouter et gérer les systèmes de stockage utilisés par SCV. ONTAP RBAC ne s'applique pas aux sauvegardes basées sur vVols. En savoir plus sur ONTAP RBAC et SCV<block ref="e4e865178d3962f87ac5cef3d6d68942" category="inline-link-rx"></block>.</block>
  <block id="1c89ba258526186ea0ec98325b61371b" category="list-text">Répliquez vos jeux de données de sauvegarde sur un second système à l'aide de SnapMirror pour créer des répliques complètes des volumes source. Comme mentionné précédemment, vous pouvez également utiliser des règles de copie miroir pour la conservation à long terme des données de sauvegarde, indépendamment des paramètres de conservation des snapshots du volume source. Les deux mécanismes sont pris en charge avec vVols.</block>
  <block id="9792eeb3b91469abf77746b005d82d77" category="list-text">Étant donné que SCV requiert également les outils ONTAP pour la fonctionnalité VMware vSphere for vVols, vérifiez toujours la compatibilité des versions avec l'outil IMT (Interoperability Matrix Tool) de NetApp</block>
  <block id="71c989bd68059e2ddfa4200c60b736c7" category="list-text">Si vous utilisez la réplication vVols avec VMware SRM, tenez compte de vos objectifs RPO et de votre planification de sauvegarde</block>
  <block id="604eb779cbb9af378f7bda71633b5b31" category="list-text">Concevez vos règles de sauvegarde avec des paramètres de conservation qui répondent aux objectifs de point de restauration (RPO) définis par votre entreprise.</block>
  <block id="067ff91a08d3ff453b59d81993b96182" category="list-text">Configurez les paramètres de notification de vos groupes de ressources pour qu'ils soient informés de l'état lors de l'exécution des sauvegardes (voir la figure 10 ci-dessous).</block>
  <block id="c3add00693172bbbb4dd864bf0ad9116" category="section-title">Options de notification de groupe de ressources</block>
  <block id="c728df76dc3609672a7969e320e39e32" category="inline-image-macro">Options de notification des groupes de ressources,300</block>
  <block id="45281309785094533b5880fe6d0fd1ea" category="paragraph"><block ref="45281309785094533b5880fe6d0fd1ea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6eae9510711f8df8f55a15e1761875d9" category="section-title">Commencer à utiliser SCV à l'aide de ces documents</block>
  <block id="235a656535515ab3518937c09836e60d" category="inline-link">En savoir plus sur le plug-in SnapCenter pour VMware vSphere</block>
  <block id="79eb02d2a96cc634df87bec5bd511bbe" category="paragraph"><block ref="79eb02d2a96cc634df87bec5bd511bbe" category="inline-link-rx"></block></block>
  <block id="04e7bb0411c1c8f56ca4fc8000c62ad8" category="inline-link">Déployez le plug-in SnapCenter pour VMware vSphere</block>
  <block id="d4ba0aa084ae1145248006481c881d29" category="paragraph"><block ref="d4ba0aa084ae1145248006481c881d29" category="inline-link-rx"></block></block>
  <block id="231cf4c70d866b616c21baddaeed0696" category="doc">Dépannage</block>
  <block id="9d2169c1c2855b78a7aeaa4f42d27dc7" category="section-title">Site de support NetApp</block>
  <block id="ed9018b2e8611a3d2c03bb6a205b9715" category="inline-link">Les outils ONTAP pour VMware vSphere</block>
  <block id="890eb741924c425abbb11e4618560181" category="paragraph">Outre plusieurs articles de la base de connaissances sur les produits de virtualisation NetApp, le site de support NetApp offre également une page d'accueil pratique pour le<block ref="6e90053136fd326e5d581844ca21966d" category="inline-link-rx"></block> produit. Ce portail propose des liens vers des articles, des téléchargements, des rapports techniques et des discussions sur les solutions VMware sur la communauté NetApp. Il est disponible à l'adresse suivante :</block>
  <block id="fff460b039580a1bd42725a397b4c8be" category="inline-link">_Site de support NetApp_</block>
  <block id="897515b5a8a03f8d5cbed44fd47ef9f3" category="paragraph"><block ref="897515b5a8a03f8d5cbed44fd47ef9f3" category="inline-link-rx"></block></block>
  <block id="4020fd07f5ee2361dd23956e6a334ffd" category="paragraph">Vous trouverez une documentation supplémentaire sur les solutions ici :</block>
  <block id="503a41e1e31e362793f7e86af9102c41" category="inline-link">_Solutions NetApp pour la virtualisation_</block>
  <block id="33d455bce1363bad4500664eb6208860" category="paragraph"><block ref="33d455bce1363bad4500664eb6208860" category="inline-link-rx"></block></block>
  <block id="baf17f6d2396be5fd3676baf863a331f" category="section-title">Dépannage du produit</block>
  <block id="9d6d7fa1a5253698556ac2b0cda2207d" category="paragraph">Les différents composants des outils ONTAP, tels que le plug-in vCenter, VASA Provider et Storage Replication adapter sont tous documentés dans le référentiel de documents NetApp. Cependant, chacun d'entre eux dispose d'une sous-section distincte de la base de connaissances et peut avoir des procédures de dépannage spécifiques. Ils répondent aux problèmes les plus courants rencontrés avec le fournisseur VASA.</block>
  <block id="ae2a93a809929192ecc7b468f234af84" category="section-title">Problèmes liés à l'interface utilisateur de VASA Provider</block>
  <block id="92a2b5cb9c6906035c2864fa225e1940" category="inline-link">article</block>
  <block id="69aecee18a55993c779487758eb051cc" category="paragraph">Il arrive que le client Web vCenter vSphere rencontre des problèmes avec les composants Serenity, ce qui empêche l'affichage des éléments de menu VASA Provider for ONTAP. Consultez la section résolution des problèmes d'enregistrement de VASA Provider dans le Guide de déploiement ou cette base de connaissances<block ref="c8979f1604396ce5570d07774ba255f0" category="inline-link-rx"></block>.</block>
  <block id="03cc611b90575ea37b55959adaa1c754" category="section-title">Échec du provisionnement du datastore vVols</block>
  <block id="281b890be0e8280eea1aebb82de90961" category="paragraph">Il arrive parfois que les services vCenter prennent du temps lors de la création du datastore vVols. Pour le corriger, redémarrez le service vmware-sps et remontez le datastore vVols à l'aide des menus vCenter (stockage &gt; Nouveau datastore). Ceci est couvert par les échecs de provisionnement du datastore vVols avec vCenter Server 6.5 dans le Guide d'administration.</block>
  <block id="3152add163cd8aaf116a259d85ebf8fb" category="section-title">La mise à niveau d'Unified Appliance ne parvient pas à monter l'ISO</block>
  <block id="ffaa56a3f5a1157f2eb3955773bb41da" category="paragraph">En raison d'un bogue dans vCenter, le montage de l'ISO utilisé pour mettre à niveau l'appliance unifiée d'une version à l'autre peut échouer. Si l'ISO peut être attaché à l'appliance dans vCenter, suivez la procédure de cette base de connaissances<block ref="9839383ed04f777c0132b57ad0cb14ac" category="inline-link-rx"></block> à résoudre.</block>
  <block id="cacba1b456347ce8f32c7f5ed0d81e64" category="doc">Déploiement du stockage vVols</block>
  <block id="2a5f3dc8d46246216b293c9e41979269" category="paragraph">Les deux premières étapes peuvent ne pas être nécessaires dans un environnement vSphere existant qui utilise ONTAP pour les datastores traditionnels. Vous utilisez peut-être déjà des outils ONTAP pour la gestion, l'automatisation et la création de rapports avec votre stockage VMFS ou NFS classique. Ces étapes sont décrites plus en détail dans la section suivante.</block>
  <block id="841db3655338a0c3dc36cf2761bfdafd" category="list-text">Créer la machine virtuelle de stockage (SVM) et sa configuration de protocole. Vous sélectionnerez NVMe/FC, NFSv3, NFSv4.1, iSCSI, FCP, ou un mélange de ces options. Vous pouvez utiliser les assistants ONTAP System Manager ou la ligne de commande du cluster shell.</block>
  <block id="10818a8ad4f650a48d78d728278d4cb3" category="list-text">Au moins une LIF par nœud pour chaque connexion switch/fabric. Il est recommandé de créer au moins deux par nœud pour les protocoles FCP, iSCSI ou NVMe.</block>
  <block id="612705dd95888cdc6345d01c93c84c39" category="list-text">Les volumes peuvent être créés à ce stade, mais il est plus simple de laisser l'assistant _provisioning datastore_ les créer. La seule exception à cette règle est que vous prévoyez d'utiliser la réplication vVols avec VMware site Recovery Manager. Cette configuration est plus simple avec des volumes FlexVol préexistants avec des relations SnapMirror existantes. N'oubliez pas d'activer la QoS sur les volumes à utiliser pour les vVols, car ceux-ci doivent être gérés par les outils SPBM et ONTAP.</block>
  <block id="16421df834af873175559b678c2b3cd9" category="list-text">Déployez les outils ONTAP pour VMware vSphere à l'aide de la version OVA téléchargée sur le site de support NetApp.</block>
  <block id="8bdb69b5934ff84bbaafd84585965a90" category="list-text">Configurez les outils ONTAP pour votre environnement.</block>
  <block id="dd07accb290c9c1e3900692630a70767" category="list-text">Ajoutez le cluster ONTAP aux outils ONTAP sous _systèmes de stockage_</block>
  <block id="731ce7392ae254e2050191ae92cafb14" category="list-text">Tandis que les outils ONTAP et SRA prennent en charge les informations d'identification au niveau du cluster et du SVM, le fournisseur VASA prend uniquement en charge les informations d'identification au niveau du cluster pour les systèmes de stockage. Cela est becuase que de nombreuses API utilisées pour les vVols ne sont disponibles qu'au niveau du cluster. Par conséquent, si vous prévoyez d'utiliser vVols, vous devez ajouter vos clusters ONTAP à l'aide d'identifiants cluster-scoped.</block>
  <block id="869ce78032d85111f09ceb58bdb59a36" category="list-text">Si vos LIFs de données ONTAP se trouvent sur des sous-réseaux différents de vos adaptateurs VMkernel, vous devez ajouter les sous-réseaux de l'adaptateur VMkernel à la liste Selected Subnets (sous-réseaux sélectionnés) dans le menu settings (paramètres) des outils ONTAP. Par défaut, les outils ONTAP sécurisent votre trafic de stockage en autorisant uniquement l'accès au sous-réseau local.</block>
  <block id="5a6d084090f063797fc6b863d2817d98" category="list-text">Les outils ONTAP sont fournis avec plusieurs règles prédéfinies qui peuvent être utilisées ou non <block ref="434866eb159632a70c4db034544336ef" category="inline-xref-macro-rx"></block> Pour obtenir des conseils sur la création de SCP.</block>
  <block id="ef51190e4c839596248fc4173ed12a3c" category="list-text">Utilisez le menu _ONTAP Tools_ de vCenter pour démarrer l'assistant _provisioning datastore_.</block>
  <block id="66edaf6f622057aeadab950977c1f3e8" category="list-text">Indiquez un nom significatif et sélectionnez le protocole souhaité. Vous pouvez également fournir une description du datastore.</block>
  <block id="d22d6de0c8f11375907a1c10d8d0f251" category="list-text">Sélectionnez un ou plusieurs SCP à prendre en charge par le datastore vVols. Ceci permet de filtrer tous les systèmes ONTAP qui ne peuvent pas correspondre au profil. Dans la liste résultat, sélectionner le cluster et le SVM souhaités.</block>
  <block id="6a016a18a0c20e3b805cd9b8e713fb3e" category="list-text">Utilisez l'assistant pour créer de nouveaux volumes FlexVol pour chacun des SCP spécifiés ou pour utiliser des volumes existants en sélectionnant le bouton radio approprié.</block>
  <block id="2527effe721902a77755b8d628fdad93" category="list-text">Créez des stratégies VM pour chaque SCP qui sera utilisé dans le datastore à partir du menu _Policies and Profiles_ de l'interface utilisateur vCenter.</block>
  <block id="642dadaf5095b4c11730dca0ffcb0d27" category="list-text">Choisissez le jeu de règles de stockage NetApp.clustered.Data.ONTAP.VP.vvol. Le jeu de règles de stockage NetApp.clustered.Data.ONTAP.VP.VASA10 prend en charge SPBM pour les datastores non-vVols</block>
  <block id="c9565e0957e6e02cf12aef618bd30c3f" category="list-text">Vous devez spécifier le profil de capacité de stockage par nom lors de la création d'une stratégie de stockage de machine virtuelle. À cette étape, vous pouvez également configurer la mise en correspondance des règles SnapMirror à l'aide de l'onglet réplication et la mise en correspondance basée sur les balises à l'aide de l'onglet balises. Notez que les étiquettes doivent déjà être créées pour pouvoir être sélectionnées.</block>
  <block id="af70f7acdeed8e2a702372f9bc85d960" category="list-text">Créez vos machines virtuelles, en sélectionnant la stratégie de stockage VM et le datastore compatible sous Sélectionner le stockage.</block>
  <block id="3db9849d9f30bfc6e05c4e0b36d28848" category="section-title">Migration des machines virtuelles des datastores classiques vers des vVols</block>
  <block id="7be42b7840cc093ce6d05a247df8e63d" category="paragraph">La migration des machines virtuelles des datastores traditionnels vers un datastore vVols est aussi simple que le déplacement de machines virtuelles entre des datastores traditionnels. Il vous suffit de sélectionner la ou les machines virtuelles, puis de sélectionner migrer dans la liste actions et de sélectionner un type de migration de _modifier le stockage uniquement_. Les opérations de copie de migration seront déchargées avec vSphere 6.0 et versions ultérieures pour les migrations de SAN VMFS vers des vVols, mais pas des VMDK NAS vers des vVols.</block>
  <block id="58f2a764a13ec89d3c5ead5343e75637" category="section-title">Gestion des machines virtuelles avec des règles</block>
  <block id="4b746813f1085683be4f71c8affea233" category="paragraph">Pour automatiser le provisionnement du stockage avec la gestion basée sur des règles, nous devons :</block>
  <block id="10b68fb9cbee818a044f91644423640c" category="list-text">Définissez les fonctionnalités du stockage (nœud ONTAP et volume FlexVol) avec les profils de capacité de stockage (SSP).</block>
  <block id="2e415dc7a6f21b4fd03f963858c9f680" category="list-text">Créez des règles de stockage de machine virtuelle qui correspondent aux SCP définis.</block>
  <block id="67c819108c4ef294ac28a51197046dfc" category="paragraph">NetApp a simplifié les fonctionnalités et le mappage à partir de VASA Provider 7.2 avec des améliorations continues dans les versions ultérieures. Cette section porte sur cette nouvelle approche. Les versions précédentes prenaient en charge un plus grand nombre de fonctionnalités et permettaient de les mapper individuellement aux stratégies de stockage. Cette approche n'est cependant plus prise en charge.</block>
  <block id="0bd86c4955ab0bdce52b49644ce9396d" category="section-title">Fonctionnalités de stockage par version des outils ONTAP</block>
  <block id="4a6af8a6e216dcc53a63f04143c13222" category="cell">*Capacité SCP*</block>
  <block id="048424cc97a54b673c837ee7d4c19de0" category="cell">*Valeurs de capacité*</block>
  <block id="098e77f7c5d9e0c2ad5454817edf0767" category="cell">*Version prise en charge*</block>
  <block id="28f44037af103f0c930309365629f8ef" category="cell">*Notes*</block>
  <block id="d031377688b064b729a0cc60fb7fbbff" category="cell">*Compression*</block>
  <block id="cc6aee5037bdc5b051433a266ec7d4a3" category="cell">Oui, non, non</block>
  <block id="7778bddb1c205e9f74d08bd30be0aca3" category="cell">Obligatoire pour AFF en 7.2 et versions ultérieures.</block>
  <block id="221baf8ad30299306e725e4fb395bf34" category="cell">*Déduplication*</block>
  <block id="6868f879256c802b106616a006671848" category="cell">M andatrice pour AFF en 7.2 et plus tard.</block>
  <block id="504897d4a6b59afadffd3cf9e5d3ea85" category="cell">*Cryptage*</block>
  <block id="95fddd53c531d6efe15e3ac7ace1d9eb" category="cell">7.2 et versions ultérieures</block>
  <block id="b3870ec121aeafa2e7ca8cb3894c0e3a" category="cell">Sélectionne/crée un volume FlexVol chiffré. Licence ONTAP requise.</block>
  <block id="e2dcc78cf70dac34550234c95443ac37" category="cell">*IOPS max*</block>
  <block id="b78a981cc40fc4e66208bf5ee6d1a1eb" category="cell">&lt;number&gt;</block>
  <block id="130b32bc15d3fbe6d2e80ecda94135cc" category="cell">7.1 et plus tard, mais différences</block>
  <block id="c0f84018aff4ff4a1cf4012a8b82e509" category="cell">Répertorié sous QoS Policy Group pour 7.2 et les versions ultérieures. Voir <block ref="8fdd8868d80d04eecf1b4189862f536c" category="inline-xref-macro-rx"></block> pour en savoir plus.</block>
  <block id="993c56850c1da5de36e798b0c5a72513" category="cell">*Personnalité*</block>
  <block id="8485fa08bf8c556b7b2275349d11eb05" category="cell">A FF, FAS</block>
  <block id="c0acd03e8ba6b951b8c6dff3e95b9560" category="cell">FAS inclut également d'autres systèmes non AFF, tels que ONTAP Select. AFF inclut ASA.</block>
  <block id="dce365633ffb688b7532470dfaf4e118" category="cell">*Protocole*</block>
  <block id="7cff0b96b4a6467ea880f49dd365a81f" category="cell">NFS, NFS 4.1, iSCSI, FCP, NVMe/FC, Tous</block>
  <block id="be18de5e88c84ba55eeb5bc42cca4c0d" category="cell">7.1 et versions antérieures, 9.10 et ultérieures</block>
  <block id="cfca0bc0c0b481555ba52be1f4e21da6" category="cell">7.2-9.8 est effectivement « tout ». Depuis 9.10, où NFS 4.1 et NVMe/FC ont été ajoutés à la liste d'origine.</block>
  <block id="3dd301ae5682df79e8687ead5b6a3ddf" category="cell">*Réserve d'espace (provisionnement fin)*</block>
  <block id="03868a080fbf4cdbc006da45e13cfad7" category="cell">Fin, épais, (tous)</block>
  <block id="0a74dc1caf6ce891d5cbd3878cae2221" category="cell">Toutes, sauf les différences</block>
  <block id="4b370bcc260aa96e343bbb24d3af2cc5" category="cell">Appelé provisionnement fin en 7.1 et versions antérieures, qui permettait également de valoriser n'importe quel système. Appelé Réserve d'espace en 7.2. Toutes les versions prennent par défaut la valeur Thin.</block>
  <block id="40e2e283d064264dd51846580adb367d" category="cell">*Politique de hiérarchisation*</block>
  <block id="06b815f81a7e7aceb1489e3888fb9534" category="cell">Tous, aucun, instantané, Auto</block>
  <block id="00917abc35f0d57db6562a886997c4e8" category="cell">Utilisé pour FabricPool - requiert AFF ou ASA avec ONTAP 9.4 ou version ultérieure. Seul Snapshot est recommandé, à moins d'utiliser une solution S3 sur site telle que NetApp StorageGRID.</block>
  <block id="ffb0d092d584c15937dfacd5be3c684a" category="section-title">Création des profils de capacité de stockage</block>
  <block id="ad0b6bb809400347fc4806f18385015c" category="paragraph">NetApp VASA Provider est fourni avec plusieurs SCP prédéfinis. Les nouveaux SCP peuvent être créés manuellement, à l'aide de l'interface utilisateur vCenter ou via l'automatisation via les API REST. En spécifiant des fonctionnalités dans un nouveau profil, en clonant un profil existant ou en générant automatiquement un ou plusieurs profils à partir de datastores traditionnels existants. Pour ce faire, utilisez les menus sous Outils ONTAP. Utilisez _profils de capacité de stockage_ pour créer ou cloner un profil et _mappage de stockage_ pour générer automatiquement un profil.</block>
  <block id="62351556db3b0f6f13da226ca3e2df24" category="section-title">Fonctionnalités de stockage pour les outils ONTAP 9.10 et versions ultérieures</block>
  <block id="14b49e2a6b56b1177a77be03a29dfc83" category="inline-image-macro">« Storage Capabilities for ONTAP Tools 9.10 et versions ultérieures », 300</block>
  <block id="2a53cbcd07a15d9f13f0cc630c7cc44d" category="paragraph"><block ref="2a53cbcd07a15d9f13f0cc630c7cc44d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12bb128f53dfaac0a251798e4b4e6954" category="paragraph"><block ref="12bb128f53dfaac0a251798e4b4e6954" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4e6d46028a015a7f3860fc8fdf214b3c" category="paragraph"><block ref="4e6d46028a015a7f3860fc8fdf214b3c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="64ca5ade59a3a7351134cf0db3a8e06a" category="paragraph"><block ref="64ca5ade59a3a7351134cf0db3a8e06a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2c8f597441425c22b4ae09f872f8bcc4" category="paragraph"><block ref="2c8f597441425c22b4ae09f872f8bcc4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fd59d4e26c472ef1e14cadb688283604" category="paragraph"><block ref="fd59d4e26c472ef1e14cadb688283604" category="inline-image-macro-rx" type="image"></block></block>
  <block id="049b6d7b78dd8ffebadb5a0be2261637" category="paragraph">*Création des datastores vVols*
Une fois les SCP nécessaires créés, ils peuvent être utilisés pour créer le datastore vVols (et éventuellement, les volumes FlexVol pour le datastore). Cliquez avec le bouton droit de la souris sur l'hôte, le cluster ou le data Center sur lequel vous souhaitez créer le datastore vVols, puis sélectionnez _ONTAP Tools_ &gt; _Provision datastore_. Sélectionnez un ou plusieurs SCP à prendre en charge par le datastore, puis faites votre choix parmi les volumes FlexVol existants et/ou provisionnez de nouveaux volumes FlexVol pour le datastore. Enfin, spécifiez le SCP par défaut pour le datastore, qui sera utilisé pour les machines virtuelles sur lesquelles aucun SCP n'a été spécifié par la règle, ainsi que pour les vVols de swap (ceux-ci ne nécessitent pas de stockage haute performance).</block>
  <block id="a4332a81dbc3a9888be608dea640cd3d" category="section-title">Création de stratégies de stockage de machine virtuelle</block>
  <block id="b4f6f65777757af7630fae901718e51e" category="paragraph">Les versions précédentes sont similaires, mais comme indiqué dans <block ref="68072d20e775e4558feadbec7ba8f768" category="inline-xref-macro-rx"></block>, vos options varient.</block>
  <block id="52896487a6472798e1d6cbc9a95ec51e" category="section-title">Création de règles de stockage de VM avec les outils ONTAP VASA Provider 9.10</block>
  <block id="c0c5e719ad5439106e5a00588402f206" category="inline-image-macro">« VM Storage Policy Creation with ONTAP Tools VASA Provider 9.10 », 300</block>
  <block id="378e30f2a60dc28c4afc9ae4f11a39e1" category="paragraph"><block ref="378e30f2a60dc28c4afc9ae4f11a39e1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="95ac22478e141fde0d2878c71530a13a" category="section-title">Gestion de la performance avec les outils ONTAP 9.10 et versions ultérieures</block>
  <block id="c153012a9aa13e8ed8ce3f3e471a70b4" category="list-text">ONTAP Tools 9.10 utilise son propre algorithme de placement équilibré pour placer un nouveau VVol dans le meilleur volume FlexVol d'un datastore vVols. Le placement est basé sur le SCP spécifié et les volumes FlexVol correspondants. Cela permet de s'assurer que le datastore et le stockage de sauvegarde peuvent répondre aux exigences de performances spécifiées.</block>
  <block id="e65bde48b0a84fcc60d957de90c3a128" category="list-text">La modification des capacités de performance telles que les IOPS min et max requiert une certaine attention particulière à la configuration spécifique.</block>
  <block id="c43f1c590aab42b849ee038e863a567d" category="list-text">*Les valeurs min et Max IOPS* peuvent être spécifiées dans un SCP et utilisées dans une stratégie VM.</block>
  <block id="404e0fefd61512a9f144586382a62641" category="list-text">La modification des IOPS dans le SCP ne modifie pas la QoS sur les vVols tant que la règle de VM n'est pas modifiée, puis réappliquée aux VM qui l'utilisent (voir <block ref="2358041c73953300d39d98366deee80d" category="inline-xref-macro-rx"></block>). Vous pouvez également créer un nouveau SCP avec le nombre d'IOPS souhaité et modifier la règle pour l'utiliser (et appliquer de nouveau aux serveurs virtuels). Il est généralement recommandé de définir simplement des SCP et des règles de stockage VM distincts pour les différents niveaux de service, puis de simplement modifier la stratégie de stockage VM sur la VM.</block>
  <block id="0e05d638b7a9c7a5c32e6c22679eeb82" category="list-text">Les personnalités AFF et FAS ont des paramètres d'IOPS différents. Les valeurs min et Max sont disponibles sur AFF. Cependant, les systèmes non-AFF peuvent uniquement utiliser les paramètres Max IOPS.</block>
  <block id="97659fa3c3a5aaf088f6020a38faf086" category="list-text">Dans certains cas, il peut être nécessaire de migrer un VVol après une modification de règle (manuellement ou automatiquement par VASA Provider et ONTAP) :</block>
  <block id="81c975fc79a19102fa04ad9c49f7538b" category="list-text">Certains changements ne nécessitent pas de migration (par exemple, la modification des IOPS maximales qui peuvent être appliquées immédiatement à la machine virtuelle comme indiqué ci-dessus).</block>
  <block id="a426b56f86a12c200f3484efb990e81f" category="list-text">Si la modification de règle ne peut pas être prise en charge par le volume FlexVol actuel qui stocke le volume vVol (par exemple, la plateforme ne prend pas en charge la règle de chiffrement ou de hiérarchisation demandée), vous devez migrer manuellement la machine virtuelle dans vCenter.</block>
  <block id="7de504873f20af5c8ce6dadd2f79b29a" category="list-text">Les outils ONTAP créent des règles de QoS individuelles non partagées avec les versions de ONTAP actuellement prises en charge. Par conséquent, chaque VMDK individuel recevra sa propre allocation d'IOPS.</block>
  <block id="63a33ddbd2c3ccd2daac06020248049f" category="section-title">Réapplication de la stratégie de stockage VM</block>
  <block id="d0f5986c3378364e5cb0eda0e98fd0fd" category="inline-image-macro">« Reapplication de la règle de stockage VM », 300</block>
  <block id="2a8c2026166e178134c7e19c2f4a2c15" category="paragraph"><block ref="2a8c2026166e178134c7e19c2f4a2c15" category="inline-image-macro-rx" type="image"></block></block>
  <block id="50b6e1c7f2e81842d993d8ce88acc979" category="summary">ONTAP prend en charge tous les principaux protocoles de stockage utilisés pour la virtualisation, comme iSCSI, Fibre Channel (FC), Fibre Channel over Ethernet (FCoE) ou NVMe/FC (non-volatile Memory Express over Fibre Channel) pour les environnements SAN, ainsi que NFS (v3 et v4.1) et SMB ou S3 pour les connexions invités. Les clients sont libres de choisir ce qui fonctionne le mieux pour leur environnement et de combiner des protocoles en fonction des besoins sur un système unique.</block>
  <block id="ee8cc65cae83009c275cd4748f4c58ae" category="doc">Outils de virtualisation pour ONTAP</block>
  <block id="0894f8dfb7dd501a78dc2416b7b90c2a" category="paragraph">NetApp propose plusieurs outils logiciels autonomes pouvant être utilisés avec ONTAP et vSphere pour gérer votre environnement virtualisé.</block>
  <block id="236e1a1bf6abf86968baf738af47b78c" category="paragraph">Les outils suivants sont inclus avec la licence ONTAP sans frais supplémentaires. Voir la Figure 1 pour une description du fonctionnement de ces outils dans votre environnement vSphere.</block>
  <block id="f364e3337f5237c93d7b5439c82d444b" category="paragraph">Les outils ONTAP pour VMware vSphere sont un ensemble d'outils permettant d'utiliser le stockage ONTAP avec vSphere. Le plug-in vCenter, précédemment appelé Virtual Storage Console (VSC), simplifie les fonctionnalités de gestion et d'efficacité du stockage, améliore la disponibilité et réduit les coûts de stockage ainsi que les charges opérationnelles, que vous utilisiez SAN ou NAS. Il s'appuie sur les bonnes pratiques pour le provisionnement des datastores et optimise les paramètres d'hôte ESXi pour les environnements de stockage NFS et bloc. Pour tous ces avantages, NetApp recommande d'utiliser ces outils ONTAP comme meilleure pratique lorsque vous utilisez vSphere avec les systèmes exécutant le logiciel ONTAP. Elle comprend une appliance serveur, des extensions d'interface utilisateur pour vCenter, VASA Provider et Storage Replication adapter. La quasi-totalité des outils ONTAP peuvent être automatisés à l'aide d'API REST simples et consommables par la plupart des outils d'automatisation modernes.</block>
  <block id="0b266371a133b176a2ee883ccf72b46c" category="list-text">*Extensions de l'interface utilisateur vCenter.* les extensions de l'interface utilisateur des outils ONTAP simplifient le travail des équipes opérationnelles et des administrateurs vCenter en intégrant des menus contextuels faciles à utiliser pour gérer les hôtes et le stockage, les portlets d'information et les fonctionnalités d'alerte natives directement dans l'interface utilisateur vCenter pour optimiser les flux de travail.</block>
  <block id="e08c666b5127e745f8aacbacfce37dcf" category="list-text">*VASA Provider pour ONTAP.* le fournisseur VASA pour ONTAP prend en charge l'infrastructure VMware vStorage APIs for Storage Awareness (VASA). Il est fourni en tant qu'appliance virtuelle unique, avec les outils ONTAP pour VMware vSphere pour une facilité de déploiement. Vasa Provider connecte vCenter Server avec ONTAP pour faciliter le provisionnement et la surveillance du stockage des machines virtuelles. Il assure la prise en charge de VMware Virtual volumes (vvols), la gestion des profils de capacité de stockage et les performances individuelles de VM vvols, ainsi que des alarmes pour le contrôle de la capacité et de la conformité avec les profils.</block>
  <block id="1c7bb8764fc089dda8481678ad1ea0b5" category="list-text">*Storage Replication adapter.* l'adaptateur SRA est utilisé avec VMware site Recovery Manager (SRM) pour gérer la réplication des données entre les sites de production et de reprise après incident et tester les répliques de reprise après incident sans interruption. Il permet d'automatiser les tâches de détection, de restauration et de reprotection. Elle inclut une appliance serveur SRA et des adaptateurs SRA pour le serveur Windows SRM et l'appliance SRM.</block>
  <block id="a1c13ec555198266776a3a7b904810dd" category="paragraph">La figure suivante représente les outils ONTAP pour vSphere.</block>
  <block id="f7e876d450acee7c9ed7b18438440fb2" category="paragraph"><block ref="f7e876d450acee7c9ed7b18438440fb2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dd55e255500b9ec15305dc69dfa0e15b" category="section-title">Plug-in NFS pour VMware VAAI</block>
  <block id="4fbfd4c228f22ff3f2841908e853d895" category="paragraph">Le plug-in NetApp NFS pour VMware VAAI est un plug-in pour les hôtes ESXi qui leur permet d'utiliser des fonctionnalités VAAI avec les datastores NFS sur ONTAP. Il prend en charge le déchargement des copies pour les opérations de clonage, la réservation d'espace pour les fichiers de disque virtuel épais et le déchargement des snapshots. Le transfert des opérations de copie vers le stockage n'est pas forcément plus rapide. Toutefois, il réduit les besoins en bande passante réseau et réduit la charge des ressources hôte telles que les cycles de CPU, les tampons et les files d'attente. Vous pouvez utiliser les outils ONTAP pour VMware vSphere pour installer le plug-in sur des hôtes ESXi ou, le cas échéant, vSphere Lifecycle Manager (vLCM).</block>
  <block id="00cdd3f66e02711548cf72d579ec0df8" category="summary">SnapCenter vous permet de créer des règles de sauvegarde qui peuvent être appliquées à plusieurs tâches. Ces règles peuvent définir des fonctionnalités de planification, de conservation, de réplication et autres. Ils continuent d'autoriser la sélection facultative de snapshots cohérents avec les machines virtuelles, ce qui exploite la capacité de l'hyperviseur à suspendre les E/S avant de prendre un snapshot VMware.</block>
  <block id="f1d1eddd608fe98b6fa2bc3436ce81d0" category="doc">Gestion basée sur des règles de stockage et vVols</block>
  <block id="2bdce8d6813e7a3d93783119529cf146" category="paragraph">Les API VMware vSphere pour Storage Awareness (VASA) permettent à un administrateur du stockage de configurer des datastores avec des fonctionnalités bien définies et de permettre à l'administrateur des VM de les utiliser chaque fois que nécessaire pour provisionner des machines virtuelles sans avoir à interagir les unes avec les autres.</block>
  <block id="871db14a81b3510676400538c6f07073" category="paragraph">Il est intéressant d'étudier cette approche pour savoir comment rationaliser vos opérations de stockage de virtualisation et éviter un travail insignifiant.</block>
  <block id="ad0bd815b4fb6f01acc94f160af3dca7" category="paragraph">Avant de procéder à VASA, les administrateurs des VM pouvaient définir des règles de stockage des VM, mais ils devaient travailler avec l'administrateur du stockage pour identifier les datastores appropriés, souvent à l'aide de la documentation ou des conventions de nom. Grâce à VASA, l'administrateur du stockage peut définir un éventail de fonctionnalités de stockage, notamment la performance, le Tiering, le chiffrement et la réplication. Un ensemble de capacités pour un volume ou un ensemble de volumes est appelé « profil de capacité de stockage » (SCP).</block>
  <block id="44d75bdf4feecabe2de10427870ae623" category="paragraph">Le SCP prend en charge la QoS minimale et/ou maximale pour les vVols de données d'une machine virtuelle. La QoS minimale est prise en charge uniquement sur les systèmes AFF. Les outils ONTAP pour VMware vSphere comprennent un tableau de bord affichant des performances granulaires de machine virtuelle et une capacité logique pour vVvols sur les systèmes ONTAP.</block>
  <block id="4240fa68f6d9919e6d039c4038175025" category="paragraph">La figure suivante représente le tableau de bord des outils ONTAP pour VMware vSphere 9.8 vvols.</block>
  <block id="d3fcb217aa8b45eb8a95f8958c1f7746" category="paragraph"><block ref="d3fcb217aa8b45eb8a95f8958c1f7746" category="inline-image-macro-rx" type="image"></block></block>
  <block id="50e0e66922b3b12510a128829d1fdc70" category="paragraph">Une fois le profil de capacité de stockage défini, il peut être utilisé pour provisionner les machines virtuelles à l'aide de la règle de stockage qui identifie ses exigences. Le mappage entre la stratégie de stockage de la machine virtuelle et le profil de capacité de stockage du datastore permet à vCenter d'afficher la liste des datastores compatibles à sélectionner. Cette approche est appelée gestion basée sur des règles de stockage.</block>
  <block id="794b6e2fc393d40a552fc58975920cb0" category="paragraph">Vasa fournit la technologie permettant d'interroger le stockage et de renvoyer un ensemble de fonctionnalités de stockage vers vCenter. Les fournisseurs de VASA fournissent la traduction entre les API et les constructions du système de stockage et les API VMware que vCenter comprend. Le fournisseur VASA de NetApp pour ONTAP est proposé dans le cadre des outils ONTAP pour la machine virtuelle de l'appliance VMware vSphere. Le plug-in vCenter fournit l'interface de provisionnement et de gestion des datastores vVol, ainsi que la possibilité de définir des profils SCP (Storage Capability Profiles).</block>
  <block id="dad160104969c39365dd2cd4c98dd300" category="inline-link">TR-4400</block>
  <block id="79f0d5feb7ec25a16c407f3f585eabb2" category="paragraph">ONTAP prend en charge les datastores VMFS et NFS vvol. L'utilisation de vvols avec des datastores SAN apporte certains des avantages de NFS tels que la granularité au niveau des VM. Voici quelques meilleures pratiques à prendre en compte, et vous trouverez des informations supplémentaires dans le<block ref="4f23d4db151ca74200684ac8aef53fed" category="inline-link-rx"></block>:</block>
  <block id="bd490c925219bcb312338a370589bf70" category="list-text">Un datastore vvol peut être constitué de plusieurs volumes FlexVol sur plusieurs nœuds de cluster. L'approche la plus simple est un datastore unique, même si les volumes ont des capacités différentes. Grâce à la gestion du stockage basée sur des règles, un volume compatible est utilisé pour la machine virtuelle. Cependant, ces volumes doivent tous faire partie d'un seul SVM ONTAP et être accessibles via un seul protocole. Une LIF par nœud suffit pour chaque protocole. Évitez d'utiliser plusieurs versions de ONTAP dans un datastore vvol unique car les capacités de stockage peuvent varier d'une version à l'autre.</block>
  <block id="0cc956d6da91fefae9dad9b2c8c9519b" category="list-text">Utilisez les outils ONTAP pour le plug-in VMware vSphere pour créer et gérer des datastores vvol. En plus de gérer le datastore et son profil, il crée automatiquement un terminal de protocole permettant d'accéder aux vvols si nécessaire. Si les LUN sont utilisées, notez que les terminaux PE sont mappés à l'aide des ID de LUN 300 et supérieurs. Vérifiez que le paramètre système avancé de l'hôte ESXi est défini<block ref="ce913b4e625461a33f54f9e4ac38c2d7" prefix=" " category="inline-code"></block> Autorise un ID de LUN supérieur à 300 (la valeur par défaut est 1,024). Pour ce faire, sélectionnez l'hôte ESXi dans vCenter, puis l'onglet configurer et Rechercher<block ref="ce913b4e625461a33f54f9e4ac38c2d7" prefix=" " category="inline-code"></block> Dans la liste des paramètres système avancés.</block>
  <block id="fac85f355a1eb47127ef1b94e7603924" category="list-text">N'installez pas ni ne migrez de VASA Provider, vCenter Server (appliance ou base Windows), ou les outils ONTAP pour VMware vSphere lui-même vers un datastore vvols, car ils sont ensuite interdépendants et limitent votre capacité à les gérer en cas de panne de courant ou d'autre perturbation du data Center.</block>
  <block id="dd76252ea7a50def2a98f218cb1505b4" category="inline-link">Article de la base de connaissances</block>
  <block id="15ef75dd3d20b8278c16cd01a708e13e" category="list-text">Sauvegarder régulièrement la machine virtuelle de VASA Provider. Créez au moins des copies Snapshot toutes les heures du datastore classique contenant VASA Provider. Pour en savoir plus sur la protection et la restauration de VASA Provider, consultez cette section<block ref="9d642870dca1748c69f7aa0b6fb95a89" category="inline-link-rx"></block>.</block>
  <block id="2d2d2e356f9ab117b7d2a58d42cc5988" category="paragraph">La figure suivante montre les composants de vvols.</block>
  <block id="6aadcb77504dae1dbfed2e4d1c969158" category="paragraph"><block ref="6aadcb77504dae1dbfed2e4d1c969158" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7be2e69e5d19c282db8d81c60a51c862" category="summary">Cette page décrit les meilleures pratiques relatives à l'implémentation d'une solution de stockage NetApp ONTAP dans un environnement VMware vSphere.</block>
  <block id="d3ba101543fc97ba1dd9272c87bf65da" category="doc">Volumes virtuels (vvols) et gestion basée sur des règles de stockage (SPBM)</block>
  <block id="25e09c324ad3c89ee3aa01454fce14cd" category="section-title">À propos de vVvols et SPBM</block>
  <block id="a42f13867ea459821488608dc4d1b7c4" category="paragraph">NetApp a été un partenaire de conception précoce avec VMware dans le développement de vSphere Virtual volumes (vvols), en fournissant des informations architecturales et une prise en charge précoce pour vvols et VMware vSphere API for Storage Awareness (VASA). Non seulement cette approche intègre la gestion du stockage granulaire des machines virtuelles à VMFS, mais elle prend également en charge l'automatisation du provisionnement du stockage via la gestion basée sur des règles de stockage (SPBM).</block>
  <block id="ce09fc365ce48a9d89c0fdb5222c3909" category="paragraph">Grâce à la gestion du stockage basée sur des règles, une structure sert de couche d'abstraction entre les services de stockage disponibles pour votre environnement de virtualisation et les éléments de stockage provisionnés via des règles. Cette approche permet aux architectes du stockage de concevoir des pools de stockage dont les capacités sont facilement utilisable par les administrateurs de machines virtuelles. Les administrateurs peuvent ensuite répondre aux exigences des charges de travail des machines virtuelles par rapport aux pools de stockage provisionnés, ce qui permet un contrôle granulaire des divers paramètres au niveau de chaque machine virtuelle ou disque virtuel.</block>
  <block id="2902acda09b9786460c2dd928a2d8f1a" category="paragraph">ONTAP est leader du secteur du stockage dans l'évolutivité de vvols, en gérant des centaines de milliers de vvols dans un seul cluster, alors que les fournisseurs de baies d'entreprise et de baies Flash plus petites prennent en charge aussi peu que plusieurs milliers de vvols par baie. NetApp pilotant également l'évolution de la gestion granulaire des machines virtuelles avec des fonctionnalités à venir en matière de prise en charge de vvols 3.0.</block>
  <block id="fda9c21a4aefd4a1f42ad0b195e6ef0a" category="inline-link">Tr-4400 : volumes virtuels VMware vSphere avec ONTAP</block>
  <block id="69173613658292fc2adeb513b12f29ca" category="admonition">Pour plus d'informations sur les volumes virtuels VMware vSphere, SPBM et ONTAP, voir<block ref="354226c2546b1aed39f1c0c484e6a98a" category="inline-link-rx"></block>.</block>
  <block id="61823c0f572643e0ce2e4edcb74cae51" category="paragraph">Utilisez les snapshots pour créer des copies rapides de votre machine virtuelle ou de votre datastore sans affecter les performances, puis envoyez-les à un système secondaire à l'aide de SnapMirror pour une protection des données hors site à plus long terme. Cette approche réduit l'espace de stockage et la bande passante réseau en stockant uniquement les informations modifiées.</block>
  <block id="0aef2da721f0ab14676f8d6ffb9e7e8c" category="inline-link">recommandé</block>
  <block id="022e604112aa3d1870f0da5e7806f48b" category="paragraph">SnapCenter vous permet de créer des règles de sauvegarde qui peuvent être appliquées à plusieurs tâches. Ces règles peuvent définir des fonctionnalités de planification, de conservation, de réplication et autres. Ils continuent d'autoriser la sélection facultative de snapshots cohérents avec les machines virtuelles, ce qui exploite la capacité de l'hyperviseur à suspendre les E/S avant de prendre un snapshot VMware. Cependant, en raison de l'impact des snapshots VMware sur les performances, ils ne sont généralement pas recommandés sauf si vous devez suspendre le système de fichiers invité. Utilisez plutôt les snapshots pour une protection générale et des outils applicatifs tels que les plug-ins SnapCenter pour protéger les données transactionnelles comme SQL Server ou Oracle. Ces snapshots sont différents des snapshots VMware (cohérence) et sont adaptés à une protection à plus long terme.  Les snapshots VMware ne sont que de<block ref="75f5ad475d959e2ecb55267e1a9a54f1" category="inline-link-rx"></block> pour une utilisation à court terme en raison de performances et d'autres effets.</block>
  <block id="26aae91a7d92b32a60b1fbc86c29ee81" category="paragraph">Ces plug-ins offrent des fonctionnalités étendues pour protéger les bases de données dans les environnements physiques et virtuels. VSphere permet de protéger les bases de données SQL Server ou Oracle dans lesquelles les données sont stockées sur des LUN RDM, des LUN iSCSI directement connectées au système d'exploitation invité ou des fichiers VMDK dans des datastores VMFS ou NFS. Les plug-ins permettent de spécifier différents types de sauvegardes de bases de données, de prendre en charge les sauvegardes en ligne ou hors ligne, et de protéger les fichiers de bases de données avec les fichiers journaux. Outre la sauvegarde et la restauration, ces plug-ins prennent également en charge le clonage des bases de données à des fins de développement ou de test.</block>
  <block id="1556ba0bf6ea4783cda0ff40e96f0265" category="paragraph">La figure suivante représente un exemple de déploiement SnapCenter.</block>
  <block id="54ee9d8cd5db70a761321f3e7d168445" category="paragraph"><block ref="54ee9d8cd5db70a761321f3e7d168445" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6c1bef29e8dc34a00e17b06c221d5efe" category="paragraph">Pour des fonctionnalités améliorées de reprise sur incident, utilisez l'outil NetApp SRA pour ONTAP avec VMware site Recovery Manager. Outre la prise en charge de la réplication de datastores sur un site de reprise après incident, il permet également d'effectuer des tests sans interruption dans l'environnement de reprise après incident en clonant les datastores répliqués. L'automatisation intégrée à SRA simplifie également la reprise après incident et la reprotection de la production après panne.</block>
  <block id="650062685b0df8284f1b87f62fa3f9f3" category="inline-link">TR-4128</block>
  <block id="886a3fd32ec402d87ea2b090f8f701b2" category="paragraph">Enfin, pour obtenir le plus haut niveau de protection des données, pensez à une configuration VMware vSphere Metro Storage Cluster (vMSC) utilisant NetApp MetroCluster. VMSC est une solution certifiée VMware qui combine la réplication synchrone à la mise en cluster basée sur baie, offrant les mêmes avantages qu'un cluster haute disponibilité, mais distribuée sur des sites distincts pour une protection contre les incidents sur site. NetApp MetroCluster permet de réaliser des configurations économiques pour la réplication synchrone avec restauration transparente depuis n'importe quel composant de stockage défaillant, et récupération par commande unique en cas d'incident sur le site. VMSC est décrit plus en détail dans<block ref="737e6eedc4568d5bb72c6a6cf1fe681a" category="inline-link-rx"></block>.</block>
  <block id="d336a329d910c32fb90337a372f596fc" category="summary">Depuis près de vingt ans, le logiciel NetApp ONTAP est une solution de stockage leader pour les environnements VMware vSphere. Il continue d'ajouter des fonctionnalités innovantes pour simplifier la gestion, tout en réduisant les coûts. Ce document présente la solution ONTAP pour vSphere, comprenant les dernières informations sur les produits et les meilleures pratiques, afin de rationaliser le déploiement, de réduire les risques et de simplifier la gestion.</block>
  <block id="92515b597b8c0784d6000b89ee47c5fd" category="doc">Stockage unifié</block>
  <block id="8b02311a9d2f587eb4c447455c3df68f" category="paragraph">Les systèmes qui exécutent le logiciel ONTAP sont unifiés de plusieurs façons.</block>
  <block id="7242358e2514a48e7044717140cacb4b" category="paragraph">Cette approche, auparavant appelée à prendre en charge les protocoles NAS et SAN sur un seul système de stockage, et ONTAP continue d'être une plateforme SAN leader en plus de sa puissance initiale dans le stockage NAS.</block>
  <block id="4947dc197f31edea82b3fdab9dc68fdc" category="paragraph">Une machine virtuelle de stockage (SVM) est une structure logique qui permet aux clients d'accéder aux systèmes exécutant le logiciel ONTAP. Les SVM peuvent transmettre simultanément les données par le biais de plusieurs protocoles d'accès aux données via des interfaces logiques (LIF). Les SVM fournissent un accès aux données de niveau fichier via les protocoles NAS, tels que CIFS et NFS, et un accès aux données de niveau bloc via les protocoles SAN, tels que iSCSI, FC/FCoE et NVMe. Les SVM peuvent fournir des données aux clients SAN et NAS de façon indépendante et simultanément.</block>
  <block id="d6154a0901f9ca6bb5d8fb15c113581e" category="paragraph"><block ref="d6154a0901f9ca6bb5d8fb15c113581e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3c46d272642e0999c025f67e9de315c9" category="paragraph">Dans le monde de vSphere, cette approche peut également se traduire par un système unifié d'infrastructure de postes de travail virtuels (VDI) avec une infrastructure de serveurs virtuels (VSI). Les systèmes qui exécutent le logiciel ONTAP sont généralement moins coûteux pour VSI que les baies d'entreprise classiques et offrent cependant des fonctionnalités avancées d'efficacité du stockage permettant de gérer l'infrastructure VDI au sein du même système. ONTAP unifie également une grande variété de supports de stockage, des SSD aux SATA, et peut s'étendre facilement au cloud. Il n'est pas nécessaire d'acheter une baie Flash pour les performances, une baie SATA pour l'archivage ou des systèmes distincts pour le cloud. ONTAP les lie tous ensemble.</block>
  <block id="e9e0f5f2c513c7138ea70b4c929d6fef" category="inline-link">Virtualisation du stockage</block>
  <block id="54c9439ad8fb4842a5a86c34d2401e36" category="admonition">Pour plus d'informations sur les SVM, le stockage unifié et l'accès aux clients, voir<block ref="2843f934dec816d79f9c394ad0533c28" category="inline-link-rx"></block> Dans le centre de documentation ONTAP 9.</block>
  <block id="400cc516a4a40acd605aef2cfd4ba4c0" category="doc">Planificateur de ressources distribué de stockage VMware</block>
  <block id="6e210af5c49ef2b81c06b57f989ed5c6" category="paragraph">VMware Storage Distributed Resource Scheduler (SDRS) est une fonctionnalité vSphere qui place les machines virtuelles sur un stockage en fonction de la latence d'E/S actuelle et de l'utilisation de l'espace.</block>
  <block id="e7649bfbacc438bf8e20ba3564db4bdd" category="paragraph">Il déplace ensuite la machine virtuelle ou les VMDK sans interruption entre les datastores d'un cluster de datastores (également appelé pod), en sélectionnant le meilleur datastore pour placer la machine virtuelle ou les VMDK dans le cluster de datastore. Un cluster de data stores est un ensemble de datastores similaires agrégés dans une unité de consommation unique du point de vue de l'administrateur vSphere.</block>
  <block id="5735cfd4d72f50fd28717ac30361b503" category="paragraph">Avec LES SDRS associés aux outils NetApp ONTAP pour VMware vSphere, vous devez d'abord créer un datastore avec le plug-in, utiliser vCenter pour créer le cluster de datastore, puis y ajouter le datastore. Une fois le cluster datastore créé, des datastores supplémentaires peuvent être ajoutés au cluster datastore directement à partir de l'assistant de provisionnement sur la page Détails.</block>
  <block id="b028cce2007c32457c41f20d2954c0c2" category="paragraph">Les autres meilleures pratiques ONTAP en matière DE SDRS sont les suivantes :</block>
  <block id="d11eff5be5178b7ba95b06270611ffc8" category="list-text">Tous les datastores du cluster doivent utiliser le même type de stockage (SAS, SATA ou SSD, par exemple), être tous des datastores VMFS ou NFS et disposer des mêmes paramètres de réplication et de protection.</block>
  <block id="76db7ce67615bbc16da685df79ed0aa9" category="list-text">Envisagez d'utiliser DES DTS en mode par défaut (manuel). Cette approche vous permet d'examiner les recommandations et de décider s'il faut les appliquer ou non. Notez les effets suivants des migrations VMDK :</block>
  <block id="97f4ed95cb52bb29629002a25cb5039f" category="list-text">Lorsque DES DTS déplacent des VMDK entre les datastores, les économies d'espace éventuelles obtenues grâce au clonage ou à la déduplication ONTAP sont perdues. Vous pouvez réexécuter la déduplication pour récupérer ces économies.</block>
  <block id="38f492286c3edf236c76e993ce0f0bf2" category="list-text">Une fois que les DTS ont déplacé les VMDK, NetApp recommande de recréer les snapshots au niveau du datastore source car l'espace est autrement verrouillé par la machine virtuelle déplacée.</block>
  <block id="09a99cbc4fb85d10c7af970e79032a05" category="list-text">Le déplacement des VMDK entre les datastores du même agrégat n'a que peu d'avantages et LES DTS n'ont pas de visibilité sur d'autres charges de travail qui pourraient partager l'agrégat.</block>
  <block id="09b616c445ab7efa8240062532e526e4" category="doc">VMware vSphere avec ONTAP</block>
  <block id="48e29772cebbf1133d022577e278d5c1" category="admonition">Cette documentation remplace les rapports techniques _TR-4597 : VMware vSphere pour ONTAP_</block>
  <block id="bfa7e7fc7c6bf4cc4e4c5c74b09763eb" category="paragraph">Les meilleures pratiques complètent d'autres documents, tels que des guides et des listes de compatibilité. Ils sont développés en fonction de tests effectués en laboratoire et d'une vaste expérience sur le terrain par les ingénieurs et les clients NetApp. Non seulement elles sont les seules pratiques prises en charge dans chaque environnement, mais elles constituent généralement les solutions les plus simples qui répondent aux besoins de la plupart des clients.</block>
  <block id="9ed4a475dd3705157a9fed8811f63ce2" category="inline-link">Matrice d'interopérabilité NetApp</block>
  <block id="e08175c6fa64cba68719dea85ebd9d34" category="inline-link">Guide de compatibilité VMware</block>
  <block id="c7e9d53e7f1a53451fa25cb6340fbf6f" category="paragraph">Ce document est axé sur les fonctionnalités des dernières versions d'ONTAP (9.x) exécutées sur vSphere 7.0 ou version ultérieure. Voir la<block ref="37aa2814221d042697a27bc81e148f64" category="inline-link-rx"></block> et<block ref="e1593898142109fc8cd8025356d3f312" category="inline-link-rx"></block> pour obtenir des détails sur des versions spécifiques.</block>
  <block id="74587fa4ad90f8713c0446529a3670e0" category="section-title">Pourquoi choisir ONTAP pour vSphere ?</block>
  <block id="a110ecc6d4ce7014019c560e5fedf572" category="paragraph">De nombreuses raisons ont poussé des dizaines de milliers de clients à choisir ONTAP comme solution de stockage pour vSphere, par exemple un système de stockage unifié prenant en charge les protocoles SAN et NAS, des fonctionnalités robustes de protection des données à l'aide de copies Snapshot compactes et une multitude d'outils pour vous aider à gérer les données applicatives. En utilisant un système de stockage distinct de l'hyperviseur, vous pouvez décharger de nombreuses fonctions et optimiser votre investissement dans les systèmes hôtes vSphere. En plus de s'assurer que les ressources de vos hôtes sont concentrées sur les charges de travail applicatives, vous évitez également l'impact aléatoire sur les performances des applications en provenance des opérations de stockage.</block>
  <block id="0f50acddbdbb9aa9712a471f2276e655" category="paragraph">L'association de ONTAP et de vSphere permet de réduire les dépenses liées au matériel hôte et aux logiciels VMware. Vous pouvez également protéger vos données à moindre coût grâce à des performances élevées et prévisibles. Les charges de travail virtualisées étant mobiles, vous pouvez explorer différentes approches à l'aide de Storage vMotion afin de déplacer des ordinateurs virtuels entre des datastores VMFS, NFS ou vvols, le tout sur un même système de stockage.</block>
  <block id="90977175b761542615a11f2b96cc4cbd" category="paragraph">Voici les principaux facteurs dont la valeur aujourd'hui est :</block>
  <block id="442c1f0ac31c3d71b638125e0a8b51da" category="list-text">*Stockage unifié.* les systèmes qui exécutent le logiciel ONTAP sont unifiés de plusieurs façons significatives. À l'origine, cette approche était appelée protocoles NAS et SAN, et ONTAP continue d'être une plateforme SAN de premier plan en plus de ses capacités d'origine dans le stockage NAS. Dans le monde de vSphere, cette approche peut également se traduire par un système unifié d'infrastructure de postes de travail virtuels (VDI) avec une infrastructure de serveurs virtuels (VSI). Les systèmes qui exécutent le logiciel ONTAP sont généralement moins coûteux pour VSI que les baies d'entreprise classiques et offrent cependant des fonctionnalités avancées d'efficacité du stockage permettant de gérer l'infrastructure VDI au sein du même système. ONTAP unifie également une grande variété de supports de stockage, des SSD aux SATA, et peut s'étendre facilement au cloud. Il n'est pas nécessaire d'acheter une baie Flash pour les performances, une baie SATA pour l'archivage ou des systèmes distincts pour le cloud. ONTAP les lie tous ensemble.</block>
  <block id="0ce37df1cd9b66a2abde8244f17fc051" category="list-text">*Volumes virtuels et gestion basée sur des règles de stockage.* NetApp a été l'un des premiers partenaires de conception avec VMware dans le développement des volumes virtuels vSphere (vVols). Il a fourni des données architecturales et une prise en charge précoce des vVols et des API VMware vSphere pour la sensibilisation au stockage (VASA). Non seulement cette approche intègre la gestion granulaire du stockage des machines virtuelles à VMFS, mais elle a également pris en charge l'automatisation du provisionnement du stockage via la gestion basée sur des règles de stockage. Cette approche permet aux architectes du stockage de concevoir des pools de stockage dont les capacités sont facilement utilisable par les administrateurs de machines virtuelles. ONTAP est leader du secteur du stockage en matière d'évolutivité vvol, en gérant des centaines de milliers de vvols dans un seul cluster, alors que les fournisseurs de baies d'entreprise et de baies Flash de plus petite taille prennent en charge à peine plusieurs milliers de vvols par baie. NetApp pilotant également l'évolution de la gestion granulaire des ordinateurs virtuels avec des fonctionnalités à venir en matière de prise en charge de vvols 3.0.</block>
  <block id="9eeea06a6a7f860f801343c04af5d7d2" category="list-text">*Efficacité du stockage.* bien que NetApp ait été le premier à fournir la déduplication pour les charges de travail de production, cette innovation n'a pas été la première ou la dernière dans ce domaine. Il a commencé par les copies Snapshot, un mécanisme de protection des données peu encombrant et sans impact sur les performances, ainsi que la technologie FlexClone, qui permet de réaliser instantanément des copies en lecture/écriture des machines virtuelles pour la production et la sauvegarde. NetApp a continué à proposer des fonctionnalités en ligne, notamment la déduplication, la compression et la déduplication des blocs « zéro », afin d'exploiter tout le stockage provenant de disques SSD très coûteux. Plus récemment, ONTAP a ajouté la possibilité de stocker des opérations d'E/S et des fichiers de petite taille dans un bloc de disque à l'aide de la compaction. L'association de ces fonctionnalités a permis à des clients d'obtenir des économies allant jusqu'à 5:1 pour VSI et jusqu'à 30:1 pour VDI.</block>
  <block id="bb73602f3344c326a7b63c94db24362a" category="list-text">*Cloud hybride.* qu'il soit utilisé pour le cloud privé sur site, une infrastructure de cloud public ou un cloud hybride qui associe le meilleur des deux types de clouds, les solutions ONTAP vous aident à créer votre Data Fabric pour rationaliser et optimiser la gestion des données. Commencez par des systèmes 100 % Flash haute performance, puis coupler les avec des systèmes de stockage sur disque ou cloud pour la protection des données et le cloud computing. Vous pouvez choisir entre des clouds Azure, AWS, IBM ou Google pour optimiser les coûts et éviter l'enfermement propriétaire. Bénéficiez de la prise en charge avancée des technologies OpenStack et de conteneur, selon vos besoins. NetApp propose également des solutions de sauvegarde cloud (SnapMirror Cloud, Cloud Backup Service et Cloud Sync), ainsi que des outils de Tiering du stockage et d'archivage (FabricPool) pour ONTAP afin de réduire les dépenses d'exploitation et d'exploiter la portée du cloud.</block>
  <block id="7a61ec7965eebc0b5486cb78f096c770" category="list-text">*Et plus.* tirez parti des performances extrêmes des baies NetApp AFF A-Series pour accélérer votre infrastructure virtualisée tout en gérant les coûts. Assurez la continuité totale de l'activité, qu'il s'agisse de la maintenance ou des mises à niveau, ou du remplacement complet de votre système de stockage à l'aide de clusters ONTAP scale-out. Protégez vos données au repos avec les fonctionnalités de chiffrement NetApp, sans frais supplémentaires. Assurez-vous que les performances respectent les niveaux de service grâce à des fonctionnalités de qualité de service très avancées. Elles font toutes partie du vaste éventail de fonctionnalités fournies par ONTAP, le logiciel de gestion des données d'entreprise leader du secteur.</block>
  <block id="6104c8ef7be4222a76596ab6a22bb422" category="doc">Hôte ESXi recommandé et autres paramètres ONTAP recommandés</block>
  <block id="0416d04b345b434b120840c30ddaf0a1" category="paragraph">NetApp a développé un ensemble de paramètres de chemins d'accès multiples de l'hôte ESXi et de délai d'expiration de la carte HBA afin que son comportement soit correct avec ONTAP suite à des tests effectués par NetApp. Ils sont facilement configurés à l'aide des outils ONTAP pour VMware vSphere. Dans le tableau de bord Résumé, cliquez sur Modifier les paramètres dans le portlet systèmes hôtes ou cliquez avec le bouton droit de la souris sur l'hôte dans vCenter, puis accédez aux outils ONTAP &gt; définir les valeurs recommandées. Voici les paramètres d'hôte actuellement recommandés avec la version 9.8.</block>
  <block id="678582eb0cbbe0e063e618d230b63223" category="cell">*Paramètres hôte*</block>
  <block id="dfe49b73bd7e747701b49f9ed21ea2d6" category="cell">*Valeur recommandée par NetApp*</block>
  <block id="edceae57d92287f4f6200f94d3259cd0" category="cell">*Redémarrer requis*</block>
  <block id="dc3a6955a23583876d020db0f6b80d4d" category="cell">*Configuration avancée ESXi*</block>
  <block id="73663d0d00956f0632e4ae75d811d53f" category="cell">VMFS3.HardwareAccélérationde la localisation</block>
  <block id="59b1aceaef0203fdc32e11df232b16e6" category="cell">Conserver la valeur par défaut (1)</block>
  <block id="bafd7322c6e97d25b6299b5d6fe8920b" category="cell">Non</block>
  <block id="1b50110aedae4d8d2043a4eb9beb20af" category="cell">VMFS3.EnableBlockDelete</block>
  <block id="5d1b81f1885499e392018ebd7124ad37" category="inline-link-macro">VMware KB 2007427</block>
  <block id="3aca64366573d9850e0148ce2a38164c" category="cell">Conservez la valeur par défaut (0), mais vous pouvez la modifier si nécessaire.
Pour plus d'informations, voir <block ref="68c2cf0ecb6a1c6abaf6e56c035d5866" category="inline-link-macro-rx"></block></block>
  <block id="316084648bbafe451240702bd19c6ee9" category="cell">VMFS3.EnableVMFS6Unmap</block>
  <block id="befd90cd01403237f6fdf296822efbee" category="inline-link-macro">API VMware vSphere : intégration des baies (VAAI)</block>
  <block id="e385d2442208cc1e23ca841b1f217380" category="cell">Conserver la valeur par défaut (1)
Pour plus d'informations, voir <block ref="d124e203790e5f214a195f69cd068c6d" category="inline-link-macro-rx"></block></block>
  <block id="571cc1d48c6d1ff3cf7e3a54cb035753" category="cell">*Paramètres NFS*</block>
  <block id="c3b49a515dd0046685e06092642aa139" category="cell">Net.TcpipeHeapSize</block>
  <block id="875f6b98e20edfecb56f9013d00987f6" category="cell">VSphere 6.0 ou version ultérieure, défini sur 32.
Toutes les autres configurations NFS, définies sur 30</block>
  <block id="93cba07454f06a4a960172bbd6e2a435" category="cell">Oui.</block>
  <block id="504e96cc79e7efe30a8271cea152d9d1" category="cell">Net.TcpipeHeapMax</block>
  <block id="a8af33a99dd728969fd947da27a2f69f" category="cell">Défini sur 512 Mo pour la plupart des versions vSphere 6.X.
Défini sur 1024 Mo pour 6.5U3, 6.7U3 et 7.0 ou version ultérieure.</block>
  <block id="5f1e7b6431061565550e292d05c73588" category="cell">NFS.MaxVolumes</block>
  <block id="e787d5b0d643685421632a1af3914963" category="cell">VSphere 6.0 ou version ultérieure, défini sur 256
Toutes les autres configurations NFS, définies sur 64.</block>
  <block id="3058676a1cf088aa4a73312ac36f2a58" category="cell">NFS41.Maxvolumes</block>
  <block id="62c07f94c64184ee5d530e4c0917093f" category="cell">VSphere 6.0 ou version ultérieure, défini sur 256.</block>
  <block id="e18600af98c17fae10fdba0dc89979ed" category="cell">NFS.MaxQueueDepth^1^</block>
  <block id="be7707fa525d0124489c9fe3072f78de" category="cell">VSphere 6.0 ou version ultérieure, défini sur 128</block>
  <block id="18e1fb6924459470760771b20ab0c379" category="cell">NFS.HeartbeatMaxFailures</block>
  <block id="138989cbe5dd3a4997662e0f65c17878" category="cell">Définissez sur 10 pour l'ensemble des configurations NFS</block>
  <block id="1aa26eb281359ba3b9a9a4b83a09ed46" category="cell">NFS.HeartbeatFrequency</block>
  <block id="7ea6e8664542e3beb1aea10425efb4db" category="cell">Définissez la valeur 12 pour toutes les configurations NFS</block>
  <block id="eb4182715f8cde98563dc59ea36461d3" category="cell">NFS.HeartbeatTimeout</block>
  <block id="45aa5481fa55802a29a96aefd2f5dab1" category="cell">Définissez sur 5 pour l'ensemble des configurations NFS.</block>
  <block id="54a08b15243d9078d3b5a47f8242da6f" category="cell">Sunrpc.MaxConnPerIP</block>
  <block id="9a9ccbecb3f315797ff8e709d85a0e18" category="cell">VSphere 7.0 ou version ultérieure, défini sur 128.</block>
  <block id="c0b3fd5512c2093847f753f398290f30" category="cell">*Paramètres FC/FCoE*</block>
  <block id="2e556ad678160413b32dcca55c7d1f5f" category="cell">Stratégie de sélection de chemin</block>
  <block id="fb62337a3ef32f4701b639339a4ceb33" category="cell">Définissez-le sur RR (Round Robin) lorsque des chemins FC avec ALUA sont utilisés. Défini sur FIXE pour toutes les autres configurations.
La définition de cette valeur sur RR permet d'équilibrer la charge sur l'ensemble des chemins actifs/optimisés.
La valeur FIXÉE est pour les anciennes configurations non ALUA et contribue à empêcher les E/S proxy En d'autres termes, il contribue à empêcher les E/S de se diriger vers l'autre nœud d'une paire haute disponibilité dans un environnement doté de Data ONTAP 7-mode</block>
  <block id="117704664d6cada78ac3107380f63d23" category="cell">Disk.QFullSampleSize</block>
  <block id="0e82e1f81de2159b0e9bee0b7be00dc9" category="cell">Définissez sur 32 pour toutes les configurations.
La définition de cette valeur permet d'éviter les erreurs d'E/S.</block>
  <block id="f66a3c183f0e736240b77f8b755c880e" category="cell">Disk.QFullThreshold</block>
  <block id="bdd8c1d08eabb5e1923ed8f0c4b10ba4" category="cell">Réglez à 8 pour toutes les configurations.
La définition de cette valeur permet d'éviter les erreurs d'E/S.</block>
  <block id="19c08de7404551288e1274186e039ef4" category="cell">Délais d'expiration de la carte HBA FC Emulex</block>
  <block id="b4dbfc2d52627e923cbb563a31ff756d" category="cell">Utilisez la valeur par défaut.</block>
  <block id="d46cddda4da7ec11f17472d11df95b68" category="cell">Délais de connexion HBA FC QLogic</block>
  <block id="19b5aaf3e2cb86809996ca63a2a416b0" category="cell">*Paramètres iSCSI*</block>
  <block id="2aa077454308383f1e82025427cd7362" category="cell">Définissez à RR (Round Robin) pour tous les chemins iSCSI.
La définition de cette valeur sur RR permet d'équilibrer la charge sur l'ensemble des chemins actifs/optimisés.</block>
  <block id="0340eb1bcbfc6cd3c62b8a878d8d643b" category="cell">Définissez sur 32 pour toutes les configurations.
La définition de cette valeur permet d'éviter les erreurs d'E/S.</block>
  <block id="891c10448731ad57490b9a932dabfff8" category="inline-link-macro">VMware KB 86331</block>
  <block id="2c572e3c397fe100b075a09359c9cc23" category="admonition">1 : l'option de configuration avancée NFS MaxQueueDepth peut ne pas fonctionner comme prévu avec VMware vSphere ESXi 7.0.1 et VMware vSphere ESXi 7.0.2. Veuillez vous reporter à <block ref="861055760f3cd527823fd34a49459992" category="inline-link-macro-rx"></block> pour en savoir plus.</block>
  <block id="fb55ee99c04280ac638757869929785d" category="paragraph">Lors de la création de volumes et de LUN ONTAP FlexVol, les outils ONTAP permettent également de spécifier certains paramètres par défaut :</block>
  <block id="3f7502a5f109d7a73706aba1c0741a4b" category="cell">*Outil ONTAP*</block>
  <block id="485577e97e8efcd504fc8e8b13e613f1" category="cell">*Paramètre par défaut*</block>
  <block id="5938fe448c8661febcef3f4e779e3adb" category="cell">Réserve Snapshot (-percent-snapshot-space)</block>
  <block id="cfcd208495d565ef66e7dff9f98764da" category="cell">0</block>
  <block id="7218aec62575561a6de1cae8d5658390" category="cell">Réserve fractionnaire (-réserve fractionnaire)</block>
  <block id="3a7e09ff0fa38663ffe6d91324ea75d9" category="cell">Mise à jour de l'heure d'accès (-atime-update)</block>
  <block id="f8320b26d30ab433c5a54546d21f414c" category="cell">Faux</block>
  <block id="e93200d5b0d16915bf04236790544b2f" category="cell">Lecture minimum (-min-lecture anticipée)</block>
  <block id="c877d89702fdd14e51b02028a20c7d07" category="cell">Snapshots planifiés</block>
  <block id="fd18465573ec21a6218982055981f6b1" category="cell">Efficacité du stockage</block>
  <block id="00d23a76e43b46dae9ec7aa9dcbebb32" category="cell">Activé</block>
  <block id="f65fd63b63c9e9f25bf6bc141e83de34" category="cell">Garantie de volume</block>
  <block id="c2410aebdf425dabcc65e546e506b03e" category="cell">Aucune (provisionnement fin)</block>
  <block id="f97c03bf3e9580446d70d479f5aad1e0" category="cell">Taille automatique du volume</block>
  <block id="d89f4f8b1d7c18847b88b46142f61535" category="cell">augmenter_réduire</block>
  <block id="ace72ec54e17777d27eb8bdb9d57e782" category="cell">Réservation d'espace par LUN</block>
  <block id="b9f5c797ebbf55adccdd8539a65a0241" category="cell">Désactivé</block>
  <block id="514aa7792a71ab4ab677eb2385131aae" category="cell">Allocation d'espace de la LUN</block>
  <block id="dbe1e98b00264bd496095ed5c95f9350" category="section-title">Paramètres de chemins d'accès multiples pour les performances</block>
  <block id="de9f44b08eec22d6b405acff2c925d56" category="paragraph">Bien qu'il ne soit pas actuellement configuré par les outils ONTAP disponibles, NetApp suggère les options de configuration suivantes :</block>
  <block id="840731ae1cb9e4b23e19f645ab018b6f" category="inline-link">2069356</block>
  <block id="5073fc9da327263a7db04fd449991e6a" category="list-text">Dans les environnements hautes performances ou lors des tests de performances avec un seul datastore LUN, envisagez de modifier le paramètre d'équilibrage de charge de la règle de sélection de chemin Round-Robin (VMW_PSP_RR) entre la valeur de 1000 IOPS par défaut et la valeur de 1. Voir VMware KB<block ref="f3f4762788a6845119bdb5b9c9179bda" category="inline-link-rx"></block> pour en savoir plus.</block>
  <block id="1ea3eb55b985cf75e100607ee8bd935d" category="inline-link">Plug-ins et règles de sélection de chemin</block>
  <block id="249afbf456bd04d574e8d362d5bf133c" category="list-text">Dans vSphere 6.7 mise à jour 1, VMware a introduit un nouveau mécanisme d'équilibrage de la charge de latence pour la PSP Round Robin. La nouvelle option prend en compte la bande passante d'E/S et la latence de chemin lors de la sélection du chemin optimal pour les E/S. Il peut être bénéfique de l'utiliser dans des environnements dotés d'une connectivité de chemin non équivalente, comme les cas où il y a plus de sauts réseau sur un chemin que l'autre ou lors de l'utilisation d'un système de baie SAN de NetApp. Voir<block ref="f5ecc69f2970e2e9c8638ad278ec38f7" category="inline-link-rx"></block> pour en savoir plus.</block>
  <block id="01d954fb2edbf283d121f0651b04de83" category="section-title">Documentation complémentaire</block>
  <block id="40db5019ed68654f4eb2cf21ec5021db" category="inline-link">Utilisez VMware vSphere 7.x avec ONTAP</block>
  <block id="30d85838b9488ee908d075559c8978cd" category="inline-link">Utilisez VMware vSphere 8.x avec ONTAP</block>
  <block id="000c9205416c1ea85f6841a7ca379c17" category="inline-link">Pour plus de détails sur NVMe-of, consultez la page Configuration d'hôte NVMe-of pour ESXi 7.x avec ONTAP</block>
  <block id="5a27e6dbe6279e323aec51d205b2b455" category="inline-link">Pour plus de détails sur NVMe-of, consultez la page Configuration d'hôte NVMe-of pour ESXi 8.x avec ONTAP</block>
  <block id="842acd8b4932f6c9329df8e0fefe8b9b" category="paragraph">Pour plus d'informations sur FCP et iSCSI avec vSphere 7, consultez la page<block ref="f3eae508de4d3c1748a9c65337197b21" category="inline-link-rx"></block>
Pour plus d'informations sur FCP et iSCSI avec vSphere 8, consultez la page<block ref="3f8db75ee0177b85df9cdf31ddb51abe" category="inline-link-rx"></block>
Pour plus d'informations sur la spécification NVMe-of avec vSphere 7, rendez-vous sur la page<block ref="6c040a6e611e78bb9d0ad92946e613ea" category="inline-link-rx"></block>
Pour plus d'informations sur la spécification NVMe-of avec vSphere 8, rendez-vous sur la page<block ref="030788e4c7bbe3137759b534ea62d7d9" category="inline-link-rx"></block></block>
  <block id="99a66df20e19a8e18fae37a7f714750a" category="doc">Clonage des VM et des datastores</block>
  <block id="fe12a277656562082ad50b980c227a84" category="paragraph">Dans vSphere, vous pouvez cloner une machine virtuelle, un disque virtuel, un volume virtuel ou un datastore. Une fois cloné, l'objet peut être davantage personnalisé, souvent par le biais d'un processus automatisé. VSphere prend en charge les clones de copie complète ainsi que les clones liés, pour assurer le suivi séparé des modifications apportées à l'objet d'origine.</block>
  <block id="883a97a36ab0c59ec785b03161a1cc32" category="paragraph">Les clones liés permettent un gain d'espace considérable, mais ils augmentent la quantité d'E/S que vSphere gère pour la machine virtuelle, ce qui affecte les performances de cette machine virtuelle, et peut-être de l'hôte dans son ensemble. C'est pourquoi les clients NetApp utilisent souvent des clones basés sur des systèmes de stockage pour profiter d'un double avantage : une utilisation efficace du stockage et des performances supérieures.</block>
  <block id="17e1a153b5d05c5a642c93ba9ce3c6de" category="paragraph">La figure suivante représente le clonage ONTAP.</block>
  <block id="8ee3cd3dba25fb32f1bc38cb528ac998" category="paragraph"><block ref="8ee3cd3dba25fb32f1bc38cb528ac998" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76ee7355875ad5e9f56186ff7da961f6" category="paragraph">Le clonage peut être déchargé sur les systèmes qui exécutent le logiciel ONTAP via plusieurs mécanismes, en général au niveau de la machine virtuelle, du volume ou du datastore. Ces champs d'application incluent :</block>
  <block id="d957242cd67db8ffccec78d93c14449d" category="list-text">Vvols avec le fournisseur NetApp vSphere APIs for Storage Awareness (VASA).  Les clones ONTAP sont utilisés pour prendre en charge les snapshots vVol gérés par vCenter. Ces snapshots sont peu encombrants avec un impact E/S minimal en termes de création et de suppression.  Les machines virtuelles peuvent également être clonées via vCenter, qui sont également déchargées vers ONTAP, que ce soit dans un datastore/volume unique ou entre les datastores/volumes.</block>
  <block id="059e5a6b7f963e9876ba0129dc1b667d" category="list-text">Clonage et migration de vSphere à l'aide des API vSphere – intégration de baies (VAAI). Les opérations de clonage de VM peuvent être déchargées sur ONTAP dans les environnements SAN et NAS (NetApp fournit un plug-in ESXi pour que VAAI for NFS).  VSphere ne décharge les opérations sur les machines virtuelles inactives (désactivées) dans un datastore NAS, tandis que les opérations sur les machines virtuelles fortement sollicitées (clonage et stockage vMotion) sont également déchargées pour le système SAN. ONTAP utilise l'approche la plus efficace selon la source, la destination et les licences des produits installés. Cette fonctionnalité est également utilisée par VMware Horizon View.</block>
  <block id="a603c207c7b5801942ff108502676c12" category="list-text">SRA (utilisé avec VMware site Recovery Manager). Ici, des clones sont utilisés pour tester la restauration de la réplique de reprise après incident sans interruption.</block>
  <block id="bb300d356d258c084dbe5da2ca367e08" category="list-text">Sauvegarde et restauration à l'aide d'outils NetApp tels que SnapCenter. Les clones de machine virtuelle sont utilisés pour vérifier les opérations de sauvegarde ainsi que pour monter une sauvegarde de machine virtuelle, de sorte que les fichiers individuels puissent être copiés.</block>
  <block id="524b5b8bc03312baeafbea86df667c4b" category="paragraph">Le clonage ONTAP Offloaded peut être appelé par les outils VMware, NetApp et tiers. Les clones déchargés sur ONTAP présentent plusieurs avantages. Elles sont peu gourmandes en espace dans la plupart des cas, et n'ont besoin que de systèmes de stockage pour modifier les objets. Cela n'a aucun impact supplémentaire sur les performances en lecture et en écriture. Dans certains cas, le partage des blocs dans des caches haute vitesse améliore les performances. Ils délester également le serveur ESXi de la charge des cycles CPU et des E/S réseau. Il est possible de décharger des copies dans un data store traditionnel grâce à un volume FlexVol, de manière rapide et efficace avec une licence FlexClone, mais les copies entre volumes FlexVol peuvent être plus lentes. Si vous maintenez les modèles de machine virtuelle comme source de clones, envisagez de les placer dans le volume du datastore (utilisez les dossiers ou les bibliothèques de contenu pour les organiser) afin de créer des clones rapides et compacts.</block>
  <block id="f3968368501d882b3969da59138db6e2" category="paragraph">Vous pouvez également cloner un volume ou une LUN directement au sein de ONTAP afin de cloner un datastore. Grâce aux datastores NFS, la technologie FlexClone peut cloner un volume entier. Le clone peut être exporté depuis ONTAP et monté par ESXi en tant qu'autre datastore. Pour les datastores VMFS, ONTAP peut cloner une LUN au sein d'un volume ou d'un volume complet, y compris une ou plusieurs LUN au sein de celle-ci. Une LUN contenant un VMFS doit être mappée sur un groupe d'initiateurs ESXi, puis une nouvelle signature définie par ESXi doit être montée et utilisée comme datastore standard. Pour certains cas d'utilisation temporaire, un VMFS cloné peut être monté sans nouvelle signature. Une fois le datastore cloné, les ordinateurs virtuels internes peuvent être enregistrés, reconfigurés et personnalisés comme s'ils étaient individuellement clonés.</block>
  <block id="2d506b6088a383ccf08479b0f80c0ff4" category="paragraph">Dans certains cas, des fonctionnalités supplémentaires sous licence peuvent être utilisées pour améliorer le clonage, telles que SnapRestore pour la sauvegarde ou FlexClone. Ces licences sont souvent incluses dans les packs de licence sans frais supplémentaires. Une licence FlexClone est requise pour les opérations de clonage vVol, ainsi que pour la prise en charge des snapshots gérés d'un VVol (qui sont déchargés de l'hyperviseur vers ONTAP). Une licence FlexClone peut également améliorer certains clones VAAI lorsqu'ils sont utilisés dans un datastore/volume (création de copies instantanées et compactes à la place de copies de bloc).  Elle est également utilisée par SRA pour tester la restauration d'une réplique de reprise après incident et SnapCenter pour les opérations de clonage, et pour parcourir les copies de sauvegarde afin de restaurer des fichiers individuels.</block>
  <block id="5dd57c2a315d3af44c2eb40eefc47111" category="doc">Configuration du réseau</block>
  <block id="66507f357c74ee12194270cfe053b98d" category="paragraph">Voici quelques points à prendre en compte :</block>
  <block id="b3752ab8dec37db2e30f4bf37fbdc112" category="list-text">Trafic du réseau de stockage séparé des autres réseaux Un réseau distinct peut être obtenu à l'aide d'un VLAN dédié ou de commutateurs distincts pour le stockage. Si le réseau de stockage partage des chemins physiques, tels que des liaisons ascendantes, vous pouvez avoir besoin de la qualité de service ou de ports supplémentaires pour garantir une bande passante suffisante. Ne connectez pas les hôtes directement au stockage ; utilisez les commutateurs pour disposer de chemins redondants et permettez à VMware HA de fonctionner sans intervention.</block>
  <block id="7c4904daaa282388097ad83bf382e1a5" category="list-text">Les trames Jumbo peuvent être utilisées si vous le souhaitez et prises en charge par votre réseau, en particulier lors de l'utilisation d'iSCSI. Si elles sont utilisées, assurez-vous qu'elles sont configurées de manière identique sur tous les périphériques réseau, VLAN, etc. Dans le chemin entre le stockage et l'hôte ESXi. Vous pourriez voir des problèmes de performances ou de connexion. La MTU doit également être définie de manière identique sur le switch virtuel ESXi, le port VMkernel et également sur les ports physiques ou les groupes d'interface de chaque nœud ONTAP.</block>
  <block id="8b6e7f43d1d697e8f99164f0aa2ab1b6" category="inline-link">TR-4182</block>
  <block id="3745abd352adaa2cdec42c798060eef6" category="list-text">NetApp recommande uniquement la désactivation du contrôle de flux réseau sur les ports réseau du cluster dans un cluster ONTAP. NetApp ne recommande pas d'autres recommandations sur les meilleures pratiques pour les ports réseau restants utilisés pour le trafic de données. Vous devez activer ou désactiver si nécessaire. Voir<block ref="bdfb81665a0ef86d871a52c0e6ebc591" category="inline-link-rx"></block> pour plus d'informations sur le contrôle de flux.</block>
  <block id="730a8287f758961d602b1b050bbe2751" category="list-text">Lorsque les baies de stockage ESXi et ONTAP sont connectées aux réseaux de stockage Ethernet, NetApp recommande de configurer les ports Ethernet auxquels ces systèmes se connectent en tant que ports de périphérie RSTP (Rapid Spanning Tree Protocol) ou en utilisant la fonctionnalité Cisco PortFast. NetApp recommande d'activer la fonction de jonction Spanning-Tree PortFast dans les environnements qui utilisent la fonction Cisco PortFast et dont le agrégation VLAN 802.1Q est activée soit au serveur ESXi, soit aux baies de stockage ONTAP.</block>
  <block id="ac4976538e1fc8726f77afc202561afc" category="list-text">NetApp recommande les meilleures pratiques suivantes pour l'agrégation de liens :</block>
  <block id="301c77ecc6cdfa6ebde6c8164cffae0c" category="list-text">Utilisez des commutateurs qui prennent en charge l'agrégation de liens des ports sur deux châssis de commutateurs distincts grâce à une approche de groupe d'agrégation de liens multichâssis, telle que Virtual PortChannel (VPC) de Cisco.</block>
  <block id="19d137845c7f6687c99b386dfad0aa97" category="list-text">Désactiver LACP pour les ports de switch connectés à ESXi, sauf si vous utilisez dvswitches 5.1 ou version ultérieure avec LACP configuré.</block>
  <block id="30254a2bb3e4b3b958b06d08c724e7db" category="list-text">Utilisez LACP pour créer des agrégats de liens pour les systèmes de stockage ONTAP avec des groupes d'interface multimode dynamiques avec un hachage IP.</block>
  <block id="d608421cceb8e4c584a2a32d9127879e" category="list-text">Utilisez une stratégie de regroupement de hachage IP sur ESXi.</block>
  <block id="2432030fc6183a1a6c52cf5e93f3e9ae" category="paragraph">Le tableau suivant fournit un récapitulatif des éléments de configuration réseau et indique l'emplacement d'application des paramètres.</block>
  <block id="7d74f3b92b19da5e606d737d339a9679" category="cell">Élément</block>
  <block id="1aa66ef3a8e34a7a538960a80d2e1e31" category="cell">VMware ESXi</block>
  <block id="bbc155fb2b111bf61c4f5ff892915e6b" category="cell">Commutateur</block>
  <block id="6c3a6944a808a7c0bbb6788dbec54a9f" category="cell">Nœud</block>
  <block id="0b7e67b6cdcf0432b624d53588d520fb" category="cell">SVM</block>
  <block id="75ba8d70e3692ba200f0e0df37b4d2ae" category="cell">Adresse IP</block>
  <block id="ee6c0f25c2881cc69947a2ef23be5b8c" category="cell">VMkernel</block>
  <block id="e11f298a5bd5344d2d975b5157c27b69" category="cell">Non**</block>
  <block id="d6f0876f76c273b8962b749c36153157" category="cell">Agrégation de liens</block>
  <block id="fabd320b3b2249377e53e93099e27657" category="cell">Commutateur virtuel</block>
  <block id="b1b40427c8eb8d0a083ddb16e250325b" category="cell">Non*</block>
  <block id="9881f82f0dd89588831f9d1682bd5492" category="cell">VLAN</block>
  <block id="5fc0d231160fa9650ea5c877f146bbe6" category="cell">Groupes de ports VMKernel et VM</block>
  <block id="39a3e05f380e583ae2887c79c7443f11" category="cell">Contrôle de flux</block>
  <block id="220071ab44b426f80ef21f1c552c363c" category="cell">NIC</block>
  <block id="6f2c08412f489e52a17a30217f50b3c1" category="cell">Spanning Tree</block>
  <block id="4b1c0df98ba3f3d1681c3c3dbdc97746" category="cell">MTU (pour les trames jumbo)</block>
  <block id="7d6feaf896df4a937157d4ee5b91f4e1" category="cell">Commutateur virtuel et port VMkernel (9000)</block>
  <block id="0110e50bd8629573701e73a4ba8b056f" category="cell">Oui (défini sur max)</block>
  <block id="061ff5255adf00e4ae68469f43a7bf55" category="cell">Oui (9000)</block>
  <block id="bcc0e5a3e08cd34e80692195d056b06d" category="cell">Groupes de basculement</block>
  <block id="a4d1a66a448e327c12d3e287098a31d5" category="cell">Oui (créer)</block>
  <block id="465d5674eb6808b997037470f4dace73" category="cell">Oui (sélectionner)</block>
  <block id="ba78d695573c8d4f1205452c675fa539" category="paragraph">*Les LIF SVM se connectent aux ports, aux groupes d'interface ou aux interfaces VLAN dotés de VLAN, MTU et d'autres paramètres. Cependant, les paramètres ne sont pas gérés au niveau de la SVM.</block>
  <block id="50ecdab93bf5a2f1bfb4cd8f81b9bd3d" category="paragraph">**Ces périphériques ont leur propre adresse IP pour la gestion, mais ces adresses ne sont pas utilisées dans le contexte du réseau de stockage VMware ESXi.</block>
  <block id="efd0bde36323238fec688b9cdf0c75a3" category="section-title">SAN (FC, FCoE, NVMe/FC, iSCSI), RDM</block>
  <block id="29cdd488736a6111699f7348320bbed7" category="paragraph">Dans vSphere, il existe trois façons d'utiliser les LUN de stockage bloc :</block>
  <block id="8982d243303f9d1a8c2470b7d55278e6" category="list-text">Avec les datastores VMFS</block>
  <block id="9a0098c8c1be287e8d1da1aaf3bd2e59" category="list-text">Avec mappage de périphériques bruts (RDM)</block>
  <block id="93e209176746ac6f25c618631a02643b" category="list-text">En tant que LUN accessible et contrôlée par un initiateur logiciel à partir d'un système d'exploitation invité de machine virtuelle</block>
  <block id="c25dc676ca39a05ee6067ac9a50dbce0" category="paragraph">VMFS est un système de fichiers en cluster hautes performances qui fournit des datastores sous forme de pools de stockage partagés. Les datastores VMFS peuvent être configurés avec des LUN accessibles via des espaces de noms FC, iSCSI, FCoE ou NVMe accessibles via le protocole NVMe/FC. VMFS permet d'accéder simultanément aux LUN classiques par chaque serveur ESX d'un cluster. La taille de LUN maximale du ONTAP est généralement de 16 To. Par conséquent, un datastore VMFS 5 de 64 To (voir le premier tableau de cette section) est créé avec quatre LUN de 16 To (tous les systèmes SAN prennent en charge la taille de LUN VMFS de 64 To maximum). Dans la mesure où l'architecture LUN ONTAP ne dispose pas de petites profondeurs de files d'attente individuelles, les datastores VMFS en ONTAP peuvent évoluer plus largement qu'avec les architectures de baies traditionnelles de manière relativement simple.</block>
  <block id="43f67f108e50dab0978a343603cbfec9" category="paragraph">VSphere inclut la prise en charge intégrée de plusieurs chemins d'accès aux périphériques de stockage, appelés chemins d'accès multiples natifs (NMP). NMP peut détecter le type de stockage pour les systèmes de stockage pris en charge et configure automatiquement la pile NMP afin de prendre en charge les capacités du système de stockage utilisé.</block>
  <block id="6bf646772584de04f877d166e564b5ff" category="paragraph">Les protocoles NMP et ONTAP prennent en charge le protocole ALUA (Asymmetric Logical Unit Access) pour négocier des chemins optimisés et non optimisés. Dans ONTAP, un chemin optimisé pour le protocole ALUA suit un chemin d'accès direct aux données, utilisant un port cible sur le nœud qui héberge la LUN accédée. ALUA est activé par défaut dans vSphere et ONTAP. Le NMP reconnaît le cluster ONTAP en tant que ALUA, et il utilise le plug-in ALUA de type baie de stockage <block ref="d4f7bd3bf4872a2f8cd0cbe400fb23d0" prefix="(" category="inline-code"></block>) et sélectionne le plug-in de sélection de chemin de tourniquet <block ref="4646bb781f9a95f64c182af129e43c7c" prefix="(" category="inline-code"></block>).</block>
  <block id="b284ee628d89c3e804c4def2a90f0520" category="paragraph">ESXi 6 prend en charge jusqu'à 256 LUN et jusqu'à 1,024 chemins d'accès aux LUN au total. Les LUN et les chemins au-delà de ces limites ne sont pas visibles par ESXi. En supposant un nombre maximum de LUN, la limite de chemin autorise quatre chemins par LUN. Dans un cluster ONTAP plus grand, il est possible d'atteindre la limite de chemin avant la limite de LUN. Pour résoudre cette limitation, ONTAP prend en charge le mappage de LUN sélectif (SLM) dans la version 8.3 et les versions ultérieures.</block>
  <block id="8466b1e5abb4751e931c5feb1af4e469" category="inline-link">TR-4080</block>
  <block id="e9e7de5d01d51034d9114fd8f16c9144" category="paragraph">SLM limite les nœuds qui annoncent les chemins vers une LUN donnée. Il est recommandé à NetApp d'utiliser au moins une LIF par nœud par SVM et SLM pour limiter les chemins annoncés vers le nœud hébergeant la LUN et son partenaire de haute disponibilité. Bien que d'autres chemins existent, ils ne sont pas annoncés par défaut. Il est possible de modifier les chemins annoncés avec les arguments de noeud de rapport ajouter et supprimer dans SLM. Notez que les LUN créées dans les versions antérieures à 8.3 annoncent tous les chemins et doivent être modifiés uniquement pour annoncer les chemins vers la paire HA d'hébergement. Pour plus d'informations sur SLM, consultez la section 5.9 de<block ref="c6b12416d518b4689065ffe16afe88db" category="inline-link-rx"></block>. La méthode précédente de ensembles de ports peut également être utilisée pour réduire davantage les chemins disponibles pour une LUN. Les jeux de ports permettent de réduire le nombre de chemins visibles via lesquels les initiateurs d'un groupe initiateur peuvent voir les LUN.</block>
  <block id="4157f0c23fc104508f492dc846f187f3" category="list-text">SLM est activé par défaut. Sauf si vous utilisez des ensembles de ports, aucune configuration supplémentaire n'est requise.</block>
  <block id="597f1433ad810b3b86c7ae0f8f95afa8" category="list-text">Pour les LUN créées avant Data ONTAP 8.3, appliquez manuellement SLM en exécutant le<block ref="886fd385b633a0746a8a08f8f00c67cd" prefix=" " category="inline-code"></block> Commande permettant de supprimer les nœuds présentant les rapports LUN et de limiter l'accès des LUN au nœud propriétaire de la LUN et à son partenaire haute disponibilité.</block>
  <block id="43919b4d4d6d446ed498e26bff62db84" category="paragraph">Des protocoles de bloc (iSCSI, FC et FCoE) accèdent aux LUN à l'aide d'identifiants de LUN, de numéros de série et de noms uniques. Les protocoles FC et FCoE utilisent des noms mondiaux (WWN et WWPN) et iSCSI utilise les noms qualifiés iSCSI (IQN). Le chemin vers les LUN à l'intérieur du stockage n'a aucun sens avec les protocoles de bloc et n'est pas présenté au niveau du protocole. Par conséquent, un volume contenant uniquement des LUN n'a pas besoin d'être monté en interne et un chemin de jonction n'est pas nécessaire pour les volumes contenant les LUN utilisées dans les datastores. Le sous-système NVMe dans ONTAP fonctionne de la même manière.</block>
  <block id="ed0e76ed86e852bd7317a09d856ec4e8" category="paragraph">D'autres meilleures pratiques à prendre en compte :</block>
  <block id="93586ad57931e0f16fff61cdba9d77df" category="list-text">Vérifier qu'une interface logique (LIF) est créée pour chaque SVM sur chaque nœud du cluster ONTAP pour optimiser la disponibilité et la mobilité. La meilleure pratique du SAN de ONTAP est d'utiliser deux ports physiques et LIF par nœud, un pour chaque structure. ALUA sert à analyser les chemins et à identifier les chemins (directs) optimisés actifs/actifs au lieu de chemins non optimisés actifs. ALUA est utilisé pour FC, FCoE et iSCSI.</block>
  <block id="b3cebb7381bddbabb1e950a46d264190" category="list-text">Pour les réseaux iSCSI, utilisez plusieurs interfaces réseau VMkernel sur différents sous-réseaux du réseau avec le regroupement de cartes réseau lorsque plusieurs commutateurs virtuels sont présents. Vous pouvez également utiliser plusieurs cartes réseau physiques connectées à plusieurs commutateurs physiques pour fournir la haute disponibilité et un débit accru. La figure suivante fournit un exemple de connectivité multivoie. Dans ONTAP, configurez soit un groupe d'interface en mode unique pour basculement avec deux liaisons ou plus connectées à deux ou plusieurs switchs, soit au moyen de LACP ou d'une autre technologie d'agrégation de liens avec des groupes d'interfaces multimode afin d'assurer la haute disponibilité et les avantages de l'agrégation de liens.</block>
  <block id="2968b9f3c141bf23bc73d0e6e15a174a" category="list-text">Si le protocole CHAP (Challenge-Handshake Authentication Protocol) est utilisé dans ESXi pour l'authentification de la cible, il doit également être configuré dans ONTAP à l'aide de l'interface de ligne de commande <block ref="199c9b970eacf1c35d84a383b7ceb210" prefix="(" category="inline-code"></block>) Ou avec System Manager (modifier la sécurité de l'initiateur sous Storage &gt; SVM &gt; SVM Settings &gt; protocoles &gt; iSCSI).</block>
  <block id="d31f2e075df4ca75ca0874fa08f74b12" category="list-text">Utilisez les outils ONTAP pour VMware vSphere pour créer et gérer des LUN et des igroups. Le plug-in détermine automatiquement les WWPN des serveurs et crée les igroups appropriés. Il configure également les LUN en fonction des meilleures pratiques et les mappe avec les groupes initiateurs appropriés.</block>
  <block id="de78559e8aed2cd62fbf852f73dc58c2" category="inline-link">mode de compatibilité physique et virtuelle</block>
  <block id="905221150fdd103b5241870a0a1f2c42" category="list-text">Utilisez les RDM avec soin car ils peuvent être plus difficiles à gérer et ils utilisent également des chemins, qui sont limités comme décrit précédemment. Les LUN ONTAP prennent en charge les deux<block ref="27e1f8e5a88cfbb2836b083145b004c9" category="inline-link-rx"></block> RDM.</block>
  <block id="636da39a2033c6179a718983c5ce1222" category="inline-link">Guide de configuration d'hôte NVMe/FC de ONTAP</block>
  <block id="81ef6507a13da5635951bc5b533deb59" category="inline-link">TR-4684</block>
  <block id="15483b0826bb9a4b11d1c89af2029c5c" category="list-text">Pour en savoir plus sur l'utilisation de NVMe/FC avec vSphere 7.0, consultez cette<block ref="6b4ed262d14e47ef641cd57b65c32c38" category="inline-link-rx"></block> et<block ref="7a29b2f31035a451d5b068728d2b79a7" category="inline-link-rx"></block>La figure suivante décrit la connectivité multivoie d'un hôte vSphere vers un LUN ONTAP.</block>
  <block id="f9fd9ea22ea7a2e8ec9e95254a449831" category="paragraph"><block ref="f9fd9ea22ea7a2e8ec9e95254a449831" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f2a693e1f056b96566c4551fcab418f2" category="paragraph">VSphere permet aux clients d'utiliser des baies NFS de classe entreprise pour fournir un accès simultané aux datastores à tous les nœuds d'un cluster ESXi. Comme mentionné dans la section datastore, la facilité d'utilisation et la visibilité sur l'efficacité du stockage présentent des avantages avec NFS avec vSphere.</block>
  <block id="743fa5a7bc7d4ba215b096e34779d298" category="paragraph">Nous vous recommandons les meilleures pratiques suivantes lorsque vous utilisez ONTAP NFS avec vSphere :</block>
  <block id="c05061b6d3055b83136fa96cb38f0f9a" category="list-text">Utiliser une interface logique (LIF) unique pour chaque SVM sur chaque nœud du cluster ONTAP. Les recommandations précédentes d'une LIF par datastore ne sont plus nécessaires. L'accès direct (LIF et datastore sur le même nœud) est idéal, mais ne vous inquiétez pas pour l'accès indirect, car l'effet de performance est généralement minimal (microsecondes).</block>
  <block id="7b997b3be9c993d49799dd9d71d8c3f6" category="list-text">VMware prend en charge NFSv3 depuis VMware Infrastructure 3. VSphere 6.0 a ajouté la prise en charge de NFSv4.1, offrant des fonctionnalités avancées telles que la sécurité Kerberos. Dans le cas où NFSv3 utilise un verrouillage côté client, NFSv4.1 utilise un verrouillage côté serveur. Bien qu'un volume ONTAP puisse être exporté via les deux protocoles, ESXi ne peut être monté que via un seul protocole. Ce montage de protocole unique n'empêche pas les autres hôtes ESXi de monter le même datastore dans une version différente. Veillez à spécifier la version du protocole à utiliser lors du montage de sorte que tous les hôtes utilisent la même version et, par conséquent, le même style de verrouillage. Ne pas mélanger les versions NFS sur les hôtes. Si possible, utilisez des profils hôtes pour vérifier la conformité.</block>
  <block id="ae4c5baa79e370d8f601cc7082f8123e" category="list-text">Étant donné qu'il n'existe pas de conversion automatique de datastore entre NFS v3 et NFS v4.1, créez un nouveau datastore NFSv4.1 et utilisez Storage vMotion pour migrer les machines virtuelles vers le nouveau datastore.</block>
  <block id="8065bff4940ae8d7161f926b0df47ac4" category="inline-link">Matrice d'interopérabilité NetApp</block>
  <block id="1479ddf58c038ab7d220ff734c74deaf" category="list-text">Reportez-vous aux notes du tableau interopérabilité NFS v4.1 dans le<block ref="8813559f5b95abb5411182be29200aff" category="inline-link-rx"></block> Pour les niveaux de correctifs VMware ESXi spécifiques requis pour la prise en charge.</block>
  <block id="24aaa4a688e881fa13d31656a85d40a9" category="list-text">Les export policy NFS permettent de contrôler l'accès des hôtes vSphere. Vous pouvez utiliser une seule règle avec plusieurs volumes (datastores). Avec NFSv3, ESXi utilise le style de sécurité sys (UNIX) et requiert l'option de montage root pour exécuter les VM. Dans ONTAP, cette option est appelée superutilisateur et, lorsque l'option superutilisateur est utilisée, il n'est pas nécessaire de spécifier l'ID utilisateur anonyme. Notez que l'export-policy rules avec des valeurs différentes de<block ref="ea72d12ecaa06afdb0c8a3b15e485e95" prefix=" " category="inline-code"></block> et<block ref="df809a941c1287d18c08bb5927b639dc" prefix=" " category="inline-code"></block> Peut entraîner des problèmes de découverte des SVM à l'aide des outils ONTAP. Voici un exemple de politique :</block>
  <block id="822366735aef72f1a9429ac86dda7338" category="list-text">Protocole d'accès : nfs3</block>
  <block id="69abbd5c7cd9c1b3828b9aa5a894ff47" category="list-text">Spéc. Correspondance client : 192.168.42.21</block>
  <block id="bd6cc42f9cd65cca72cbd56d2f4bf43d" category="list-text">Règle d'accès RO : sys</block>
  <block id="581c470a5099548fc9865a4bab8761f8" category="list-text">Règle d'accès RW : sys</block>
  <block id="0bbc71e6a4ea49af70dd616d3807e524" category="list-text">UID anonyme</block>
  <block id="59d5d8c898df18115bd4ced36c6bc0de" category="list-text">Superutilisateur : sys</block>
  <block id="c184ce6b86d2e6fbf8681d61637c101b" category="list-text">Si vous utilisez le plug-in NetApp NFS pour VMware VAAI, le protocole doit être défini en tant que<block ref="2521ef5d58fc027d3121662b7d8f9ac2" prefix=" " category="inline-code"></block> lorsque la règle export-policy est créée ou modifiée. Le protocole NFSv4 est requis pour que le déchargement des copies VAAI fonctionne et que vous spécifiez le protocole comme<block ref="2521ef5d58fc027d3121662b7d8f9ac2" prefix=" " category="inline-code"></block> Inclut automatiquement les versions NFSv3 et NFSv4.</block>
  <block id="6670a317619282ec228a9ef492af0a76" category="list-text">Les volumes des datastores NFS sont rassemblés dans le volume racine du SVM. Par conséquent, ESXi doit également avoir accès au volume racine pour naviguer et monter des volumes de datastores. La export policy pour le volume root, et pour tout autre volume dans lequel la jonction du volume de datastore est imbriquée, doit inclure une règle ou des règles pour les serveurs ESXi leur accordant un accès en lecture seule. Voici un exemple de règle pour le volume racine, également à l'aide du plug-in VAAI :</block>
  <block id="8c93fb3ff528165613797962f5a0ed9c" category="list-text">Protocole d'accès : nfs (qui inclut nfs3 et nfs4)</block>
  <block id="80e6a4f964e826c69c1c62bd5ea67590" category="list-text">Règle d'accès RW : jamais (meilleure sécurité pour le volume racine)</block>
  <block id="f96625174b4a06d13267f9b0a5a96d59" category="list-text">Superutilisateur : sys (également requis pour le volume racine avec VAAI)</block>
  <block id="4c571520a8128d1692fc709ffbfb2b1e" category="list-text">Utilisez les outils ONTAP pour VMware vSphere (meilleure pratique la plus importante) :</block>
  <block id="b8d278c6184cb65727ca5ae729db92d7" category="list-text">Utilisez les outils ONTAP pour VMware vSphere pour provisionner les datastores, car cela simplifie automatiquement la gestion des règles d'exportation.</block>
  <block id="23aa7b9aeed3fba2a1ec43e630313af7" category="list-text">Lors de la création de datastores pour clusters VMware avec le plug-in, sélectionnez le cluster plutôt qu'un seul serveur ESX. Ce choix permet de monter automatiquement le datastore sur tous les hôtes du cluster.</block>
  <block id="e4e62770daaf9887c7868fbc8e248a4b" category="list-text">Utilisez la fonction de montage du plug-in pour appliquer les datastores existants aux nouveaux serveurs.</block>
  <block id="928562eb576ed6ae31cb1a149d3e751a" category="list-text">Lorsque vous n'utilisez pas les outils ONTAP pour VMware vSphere, utilisez une export policy unique pour tous les serveurs ou pour chaque cluster de serveurs où un contrôle d'accès supplémentaire est nécessaire.</block>
  <block id="7bccab0fa4c0864835c645c9fde7ebf6" category="list-text">Bien que ONTAP offre une structure d'espace de noms de volume flexible permettant d'organiser les volumes dans une arborescence à l'aide de jonctions, cette approche n'a aucune valeur pour vSphere. Il crée un répertoire pour chaque machine virtuelle à la racine du datastore, quelle que soit la hiérarchie de l'espace de noms du stockage. Il est donc recommandé de simplement monter le Junction path pour les volumes pour vSphere au volume root du SVM, c'est-à-dire comment les outils ONTAP pour VMware vSphere provisionne les datastores. Sans chemins de jonction imbriqués, aucun volume ne dépend d'aucun volume autre que le volume root et que mettre un volume hors ligne ou le détruire, même intentionnellement, n'affecte pas le chemin d'accès aux autres volumes.</block>
  <block id="ea6fc1288f1d3b21238d29ff28cb867a" category="list-text">Une taille de bloc de 4 Ko convient parfaitement aux partitions NTFS sur les datastores NFS. La figure suivante décrit la connectivité d'un hôte vSphere vers un datastore NFS ONTAP.</block>
  <block id="16c864cb4f3b00c59e1124932e49f342" category="paragraph"><block ref="16c864cb4f3b00c59e1124932e49f342" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e54433644e830ed1503561b778e9ded4" category="paragraph">Le tableau suivant répertorie les versions NFS et les fonctionnalités prises en charge.</block>
  <block id="9fb9dac7513c7ef8452aade8a52ad40d" category="cell">Fonctionnalités de vSphere</block>
  <block id="5b12ee0369243579651edca43ff65c85" category="cell">NFSv3</block>
  <block id="de841868c2911da76b8ae2da9fa3166d" category="cell">NFSv4.1</block>
  <block id="64e3cc476958b05086721cd6070004cf" category="cell">VMotion et Storage vMotion</block>
  <block id="05807e454c19f244770adae059b3c330" category="cell">Haute disponibilité</block>
  <block id="45a75e44a713fdf94dbf1dbaa0749188" category="cell">Tolérance aux pannes</block>
  <block id="f1e3446c69e4d87279ff7863482f9dcb" category="cell">DRS</block>
  <block id="6ca09f98e8925b2cb78bbf24eccc0186" category="cell">Profils hôtes</block>
  <block id="ec8420797e3b089812499cce4047ded8" category="cell">DRS de stockage</block>
  <block id="7c19bf1cbe62a87a42857ef0b4fe22ae" category="cell">Contrôle des E/S du stockage</block>
  <block id="56d43ad1a280ada5e16fd2960ae44b32" category="cell">SRM</block>
  <block id="d595c8f30866b71ea121ced5cde66b1d" category="cell">Volumes virtuels</block>
  <block id="6ad5114acf73f68a85c72f11646920cb" category="cell">Accélération matérielle (VAAI)</block>
  <block id="ad37ded9046268d8e5ea7cb253bb5dda" category="cell">Authentification Kerberos</block>
  <block id="45701e6ef9bc09dca07f8f4abe661dc6" category="cell">Oui (optimisé avec vSphere 6.5 et versions ultérieures pour prendre en charge AES et krb5i)</block>
  <block id="76969a36155d2f41fc6cc3bd3faff244" category="cell">Prise en charge des chemins d'accès</block>
  <block id="8a18e0a50dc5755c294477cb16507a6c" category="doc">Groupes flexibles</block>
  <block id="f9ac230f370c7937167d25093c4ce9b9" category="paragraph">FlexGroup simplifie la création de datastores volumineux et crée automatiquement un certain nombre de volumes constitutifs afin d'optimiser les performances d'un système ONTAP. Utilisez FlexGroup avec vSphere pour créer un datastore vSphere unique et évolutif tout en bénéficiant de la puissance d'un cluster ONTAP complet.</block>
  <block id="6829bc8d3038be0130fd2b409ad5e560" category="paragraph">En plus des tests exhaustifs sur les charges de travail vSphere, ONTAP 9.8 propose également un nouveau mécanisme d'allègement de la charge de données pour les datastores FlexGroup. Un moteur de copie amélioré permet de copier des fichiers entre les composants en arrière-plan tout en permettant l'accès à la source et à la destination. Plusieurs copies utilisent les clones de fichiers instantanément disponibles dans un composant, si nécessaire, en fonction des évolutions.</block>
  <block id="760383437e8e5cbe4a2560753da783fb" category="paragraph">ONTAP 9.8 propose également de nouvelles mesures de performance basées sur les fichiers (IOPS, débit et latence) pour les fichiers FlexGroup. Ces metrics sont également consultables dans le tableau de bord et les rapports des machines virtuelles de ONTAP pour VMware vSphere. Les outils ONTAP pour le plug-in VMware vSphere vous permettent également de définir des règles de qualité de service (QoS) en combinant des IOPS minimales et/ou maximales. Ils peuvent être définis au sein de toutes les machines virtuelles d'un datastore ou individuellement pour des machines virtuelles spécifiques.</block>
  <block id="50783a97403d748762dff691da2d3723" category="paragraph">Voici quelques meilleures pratiques supplémentaires que NetApp a développées :</block>
  <block id="d190c5fcdf8146c1dd7aad1140be4e64" category="list-text">Utilisez les valeurs par défaut de provisionnement FlexGroup. Les outils ONTAP pour VMware vSphere sont recommandés, car ils créent et montés FlexGroup dans vSphere, mais ONTAP System Manager ou la ligne de commandes peuvent être utilisés pour des besoins particuliers. Ensuite, utilisez les valeurs par défaut, telles que le nombre de membres constitutifs par nœud, car c'est ce qui a été testé avec vSphere.</block>
  <block id="9f3fa65c2cc36eabd2228b984c30c5e1" category="list-text">Lors du dimensionnement d'un datastore FlexGroup, n'oubliez pas que le FlexGroup est constitué de plusieurs petits volumes FlexVol qui créent un espace de noms plus important. Par conséquent, dimensionnez le datastore pour qu'il soit au moins 8x de la taille de votre plus grande machine virtuelle. Par exemple, si votre environnement contient une machine virtuelle de 6 To, sa taille FlexGroup n'est pas inférieure à 48 To.</block>
  <block id="5fbee6b763967c822bb1e4a31665b11d" category="list-text">Autoriser FlexGroup à gérer l'espace du datastore. La taille automatique et le dimensionnement souple ont été testés avec les datastores vSphere. Si la capacité totale du datastore est proche de celle maximale, utilisez les outils ONTAP pour VMware vSphere ou un autre outil pour redimensionner le volume FlexGroup. FlexGroup permet d'équilibrer la capacité et les inodes entre les composants, en hiérarchisant les fichiers d'un dossier (VM) vers le même composant si la capacité le permet.</block>
  <block id="b48b55db402c8085e1d333cad214232b" category="list-text">Actuellement, VMware et NetApp ne prennent pas en charge une approche commune de mise en réseau multivoie. Pour NFSv4.1, NetApp prend en charge pNFS, tandis que VMware prend en charge l'agrégation de sessions. NFSv3 ne prend pas en charge plusieurs chemins physiques vers un volume. Pour les environnements FlexGroup avec ONTAP 9.8, nous vous recommandons de laisser les outils ONTAP pour VMware vSphere effectuer le montage unique, car les effets de l'accès indirect sont généralement minimes (microsecondes). Il est possible d'utiliser un DNS round-Robin pour distribuer les hôtes ESXi sur les LIF de différents nœuds de la FlexGroup, mais cela nécessiterait la création et le montage de la FlexGroup sans les outils ONTAP pour VMware vSphere. Dans ce cas, les fonctionnalités de gestion des performances ne sont pas disponibles.</block>
  <block id="f5f11bb6aa98d02453eca36d5d1d2e19" category="list-text">La prise en charge du datastore FlexGroup vSphere a été testée jusqu'à 1500 machines virtuelles dans la version 9.8.</block>
  <block id="f48591b3ae898f29a551a2995a7dcfe8" category="list-text">Utilisez le plug-in NFS pour VMware VAAI pour la copie auxiliaire. Notez que même si le clonage est amélioré dans un datastore FlexGroup, ONTAP ne fournit pas d'avantages significatifs en termes de performances par rapport à la copie d'hôte ESXi lors de la copie de machines virtuelles entre des volumes FlexVol et/ou FlexGroup.</block>
  <block id="57a0d1deb8da99d321814990d26d21ed" category="list-text">Utilisez les outils ONTAP pour VMware vSphere 9.8 pour surveiller les performances des machines virtuelles FlexGroup à l'aide de metrics de ONTAP (tableau de bord et rapports sur les machines virtuelles), et pour gérer la qualité de service sur des machines virtuelles individuelles. Ces metrics ne sont pas encore disponibles via les commandes ou les API ONTAP.</block>
  <block id="ad971da24ec0a38449ebf31e4e2c9332" category="list-text">À ce moment-là, la qualité de service (IOPS max/min) peut être définie sur des machines virtuelles individuelles ou sur toutes les machines virtuelles d'un datastore. La définition de la qualité de service sur toutes les VM remplace tous les paramètres distincts par VM. Les paramètres ne s'étendent pas ultérieurement aux nouvelles machines virtuelles ou aux machines virtuelles migrées ; définissez la qualité de service sur les nouvelles machines virtuelles ou appliquez à nouveau la qualité de service à toutes les machines virtuelles du datastore.</block>
  <block id="3c9d41390700cbdfb2c273f00df0d6fd" category="list-text">Le plug-in SnapCenter pour VMware vSphere version 4.4 prend en charge la sauvegarde et la restauration des machines virtuelles dans un datastore FlexGroup sur le système de stockage primaire. Même si SnapMirror peut être utilisé manuellement pour répliquer un FlexGroup sur un système secondaire, le distributeur sélectif n° 4.4 ne gère pas les copies secondaires.</block>
  <block id="be0ec3d9251292dd856ea0924ecc6873" category="doc">La qualité de service (QoS)</block>
  <block id="8fdd6138f63aa45f1c51b48d9a01b19d" category="paragraph">Les limites de débit sont utiles pour contrôler les charges de travail inconnues ou de test avant le déploiement afin de s'assurer qu'elles n'affectent pas les autres charges de travail. Elles peuvent également être utilisées pour contraindre une charge de travail dominante après son identification. Des niveaux minimaux de service basés sur des IOPS sont également pris en charge pour assurer des performances prévisibles pour les objets SAN d'ONTAP 9.2 et pour les objets NAS d'ONTAP 9.3.</block>
  <block id="3e4a2dc31acddb628ba286d25b1bd36e" category="paragraph">Avec un datastore NFS, une politique de qualité de services peut s'appliquer à tout le volume FlexVol ou à tous les fichiers VMDK de l'environnement IT. Avec les datastores VMFS utilisant des LUN ONTAP, les règles de QoS peuvent être appliquées au volume FlexVol contenant les LUN ou les LUN individuels, mais pas aux fichiers VMDK individuels, car ONTAP ne connaît pas le système de fichiers VMFS. Lors de l'utilisation de vvols, il est possible de définir une qualité de service minimale et/ou maximale sur des machines virtuelles individuelles en utilisant le profil de capacité de stockage et la règle de stockage des machines virtuelles.</block>
  <block id="534ecd446aac2f9c809eef9064f44aab" category="paragraph">Le débit maximal de QoS sur un objet peut être défini en Mbit/s et/ou IOPS. Si les deux sont utilisés, la première limite atteinte est appliquée par ONTAP. Une charge de travail peut contenir plusieurs objets et une règle de QoS peut être appliquée à un ou plusieurs workloads. Lorsqu'une règle est appliquée à plusieurs workloads, celle-ci partage la limite totale de la règle. Les objets imbriqués ne sont pas pris en charge (par exemple, les fichiers d'un volume ne peuvent pas chacun avoir leur propre stratégie). La valeur minimale de qualité de service ne peut être définie que dans les IOPS.</block>
  <block id="040f184b126879657b253b6d258661d9" category="paragraph">Les outils suivants sont actuellement disponibles pour la gestion des règles de QoS de ONTAP et leur application aux objets :</block>
  <block id="de134183bea5df515a6756a539ce6f18" category="list-text">INTERFACE DE LIGNE DE COMMANDES DE ONTAP</block>
  <block id="6ad5e0a20f49ad6a370454bb3afc9a9e" category="list-text">ONTAP System Manager</block>
  <block id="8e23e05fc0865e950d6a3581e0dd8ce9" category="list-text">OnCommand Workflow Automation</block>
  <block id="5ecb6b24c169667ff1a176768115659e" category="list-text">Active IQ Unified Manager</block>
  <block id="8cc4e713850f67a131e9dbf8b997f61e" category="list-text">Kit d'outils NetApp PowerShell pour ONTAP</block>
  <block id="fcdb48d0d22627e4910a8352c80bd87a" category="list-text">Outils ONTAP pour VMware vSphere VASA Provider</block>
  <block id="e6defd03e0f49585b6d47614713e97f7" category="paragraph">Pour affecter une politique de QoS à un VMDK sur NFS, suivez les consignes suivantes :</block>
  <block id="10509998e8d4c4d7be30fc1d0b6b2a1e" category="list-text">La politique doit être appliquée au<block ref="a1bb63c284b58c32f1afb554a12e3e9a" prefix=" " category="inline-code"></block> qui contient l'image réelle du disque virtuel, pas le<block ref="aa26c73336ecfd98ed727b3e249c7f90" prefix=" " category="inline-code"></block> (fichier de descripteur de disque virtuel) ou<block ref="092eb4dd2ca488962f4c22b3e8cc4ca0" prefix=" " category="inline-code"></block> (Fichier de descripteur de machine virtuelle).</block>
  <block id="2175e0e29bc4b213fa8b9c7afd591b6b" category="list-text">N'appliquez pas de règles aux autres fichiers VM tels que les fichiers d'échange virtuels <block ref="aa33c3c1850a3f99cec7426e2c411d08" prefix="(" category="inline-code"></block>).</block>
  <block id="8230e9b5c1e9862fedb2c69f7cc5d3d1" category="list-text">Lors de l'utilisation du client Web vSphere pour trouver des chemins de fichiers (datastore &gt; fichiers), notez qu'il combine les informations de l'<block ref="f149d7424e10a266ec998ca5b32b81bb" prefix=" " category="inline-code"></block> et<block ref="4a78be158c13cd6b2dc2100a80bb7070" prefix=" " category="inline-code"></block> et montre simplement un fichier avec le nom du<block ref="4a78be158c13cd6b2dc2100a80bb7070" prefix=" " category="inline-code"></block> mais la taille du<block ref="f149d7424e10a266ec998ca5b32b81bb" prefix=" " category="inline-code"></block>. Autres<block ref="4fc4e556dbb9dcede037ccd80fabd784" prefix=" " category="inline-code"></block> dans le nom du fichier pour obtenir le chemin correct.</block>
  <block id="1d4614aca13104c98d5d8cc2d415b941" category="paragraph">Pour affecter une QoS à une LUN, y compris VMFS et RDM, le SVM ONTAP (affiché comme vServer), le chemin LUN et le numéro de série peuvent être obtenus du menu systèmes de stockage de la page d'accueil des outils ONTAP pour VMware vSphere. Sélectionner le système de stockage (SVM), puis objets associés &gt; SAN.  Utilisez cette approche lors de la spécification de QoS à l'aide de l'un des outils ONTAP.</block>
  <block id="cc97a1a52adc0bd6f188de1545eea887" category="paragraph">Il est possible de définir une qualité de service minimale et maximale facilement sur une machine virtuelle basée sur des volumes grâce aux outils ONTAP pour VMware vSphere ou Virtual Storage Console 7.1 et versions ultérieures. Lors de la création du profil de capacité de stockage pour le conteneur vVol, spécifiez une valeur IOPS max et/ou min sous la fonctionnalité de performance, puis indiquez ce SCP avec la stratégie de stockage de la VM. Utilisez cette règle lors de la création de la machine virtuelle ou appliquez-la à une machine virtuelle existante.</block>
  <block id="421c9efa4ff1b039a5378be7bc1e2e49" category="paragraph">Les datastores FlexGroup offrent des fonctionnalités QoS améliorées lors de l'utilisation des outils ONTAP pour VMware vSphere 9.8 et versions ultérieures. Vous pouvez facilement définir la qualité de service sur toutes les machines virtuelles d'un datastore ou sur des machines virtuelles spécifiques. Consultez la section FlexGroup de ce rapport pour plus d'informations.</block>
  <block id="77bb2ba950959bd3f1c55da523ace0be" category="section-title">QoS ONTAP et SIOC VMware</block>
  <block id="b2e21dac6070ea83831ff6521a66a447" category="paragraph">La QoS ONTAP et la fonctionnalité VMware vSphere Storage I/O Control (SIOC) sont des technologies complémentaires que les administrateurs vSphere et du stockage peuvent utiliser ensemble pour gérer les performances des VM vSphere hébergées sur des systèmes exécutant le logiciel ONTAP. Chaque outil a ses propres forces, comme le montre le tableau suivant. En raison des différents champs d'application de VMware vCenter et de ONTAP, certains objets peuvent être vus et gérés par un système et non par l'autre.</block>
  <block id="5ad234cb2cde4266195252a23ca7d84e" category="cell">Propriété</block>
  <block id="b8b8d1ba8fa345f03438a90f29af5784" category="cell">QoS de ONTAP</block>
  <block id="c2a4cb962db2a4a6782b69864f0e411c" category="cell">SIOC VMware</block>
  <block id="aa628d5a66888444926b4dc042458200" category="cell">Lorsqu'il est actif</block>
  <block id="688b10fcfff927dee65634e3b3636064" category="cell">La règle est toujours active</block>
  <block id="a981c4aa67c29ff2d36fc614d8b28808" category="cell">Actif en cas de conflit (latence du datastore supérieure au seuil)</block>
  <block id="f46e64a82c96db56f3d6657d4fb53f00" category="cell">Type d'unités</block>
  <block id="878b4223bb85b95d8caf0429d9406cd5" category="cell">IOPS, Mo/sec</block>
  <block id="3e189a34f422a141311dad231f9ad5b5" category="cell">IOPS, partages</block>
  <block id="7367a0ec46339213625cbc77d56a9572" category="cell">Étendue vCenter ou des applications</block>
  <block id="1faff19290bb64ce8ff6bc1220496881" category="cell">Plusieurs environnements vCenter, d'autres hyperviseurs et applications</block>
  <block id="1e664a3cc0ab109fcabcc81b488cebb1" category="cell">Un seul serveur vCenter</block>
  <block id="ebccc9f5c939841d86e5382988dfcc47" category="cell">Définir la qualité de service sur la machine virtuelle ?</block>
  <block id="cddd0980ce99890d2ea90288f6b03117" category="cell">VMDK sur NFS uniquement</block>
  <block id="928629d8a2a889f5274cad9940a06da0" category="cell">VMDK sur NFS ou VMFS</block>
  <block id="305e85b992089534091855224f60cf75" category="cell">Définir la qualité de service sur la LUN (RDM) ?</block>
  <block id="e798014243cf5682e7fb3aaf4ee7cecf" category="cell">Définir la QoS sur LUN (VMFS) ?</block>
  <block id="9cd021ea9d3c88de723fe9a2e50a2380" category="cell">Définir la qualité de service sur le volume (datastore NFS) ?</block>
  <block id="c352b53c32380efcf4436926da6d0414" category="cell">Qualité de service définie sur un SVM (locataire) ?</block>
  <block id="5dad340ee8f9e8fa9b65bf86a9fd5341" category="cell">Approche basée sur des règles ?</block>
  <block id="b31c76176f26196c6379a9bcce212d99" category="cell">Oui. Elles peuvent être partagées par toutes les charges de travail dans la règle ou appliquées en totalité à chaque charge de travail dans la règle.</block>
  <block id="1ff33557bad923d68973872cacf2e43a" category="cell">Oui, avec vSphere 6.5 et versions ultérieures.</block>
  <block id="d5f1465492190ee9d30a09b36f64f4b7" category="cell">Licence requise</block>
  <block id="4cec76d82991abd453484c23f7e3788a" category="cell">Inclus avec ONTAP</block>
  <block id="6bb36803f4670824ff9ebdf665654829" category="cell">Enterprise plus</block>
  <block id="d4d4b5b65bebf236590d70c702a6ba6b" category="paragraph">VMware Storage Distributed Resource Scheduler (SDRS) est une fonctionnalité vSphere qui place les machines virtuelles sur un stockage en fonction de la latence d'E/S actuelle et de l'utilisation de l'espace. Il déplace ensuite la machine virtuelle ou les VMDK sans interruption entre les datastores d'un cluster de datastores (également appelé pod), en sélectionnant le meilleur datastore pour placer la machine virtuelle ou les VMDK dans le cluster de datastore. Un cluster de data stores est un ensemble de datastores similaires agrégés dans une unité de consommation unique du point de vue de l'administrateur vSphere.</block>
  <block id="01e838e1c124042f75adb374a81f72a6" category="paragraph">Les API VMware vSphere pour Storage Awareness (VASA) permettent à un administrateur du stockage de configurer des datastores avec des fonctionnalités bien définies et de permettre à l'administrateur des VM de les utiliser chaque fois que nécessaire pour provisionner des machines virtuelles sans avoir à interagir les unes avec les autres. Il est intéressant d'étudier cette approche pour savoir comment rationaliser vos opérations de stockage de virtualisation et éviter un travail insignifiant.</block>
  <block id="0ce8b0e3e0d7dc7f39c62fb74a28b3bf" category="section-title">Migration et sauvegarde dans le cloud</block>
  <block id="4fe11b4a91ff38ec9933009a15dd5b0b" category="paragraph">ONTAP permet également la prise en charge étendue du cloud hybride en fusionnant les systèmes de votre cloud privé sur site avec des capacités de cloud public. Voici quelques solutions clouds NetApp qui peuvent être utilisées en association avec vSphere :</block>
  <block id="e18ab5f123ad4ce169202479f07f3f0f" category="list-text">*Cloud volumes.* NetApp Cloud Volumes Service pour Amazon Web Services ou Google Cloud Platform et Azure NetApp Files pour ANF offrent des services de stockage gérés multiprotocole haute performance dans les principaux environnements de cloud public. Ils peuvent être utilisés directement par les invités de machine virtuelle VMware Cloud.</block>
  <block id="9625e7e8b7b951b4ac75beee0139b407" category="list-text">*Cloud Volumes ONTAP.* le logiciel de gestion des données NetApp Cloud Volumes ONTAP permet de contrôler et de protéger les données et d'optimiser l'efficacité du stockage, tout en bénéficiant de la flexibilité du cloud de votre choix. Cloud Volumes ONTAP est un logiciel de gestion des données cloud basé sur le logiciel de stockage NetApp ONTAP. Utilisez-les conjointement avec Cloud Manager pour déployer et gérer des instances Cloud Volumes ONTAP avec vos systèmes ONTAP sur site. Profitez des fonctionnalités NAS avancées et SAN iSCSI combinées à la gestion unifiée des données, notamment les copies Snapshot et la réplication SnapMirror.</block>
  <block id="2a11701c0c01affc0ce96eb0d0c16ed9" category="list-text">*Services cloud.* utilisez Cloud Backup Service ou SnapMirror Cloud pour protéger les données des systèmes sur site qui utilisent un stockage de cloud public. Cloud Sync vous aide à migrer et à synchroniser vos données sur les systèmes NAS, les magasins d'objets et le stockage Cloud Volumes Service.</block>
  <block id="99c6c4d349151c1f4a6694e424aef741" category="inline-link">Stockez davantage de snapshots de vos machines virtuelles</block>
  <block id="01fa297dbdab5aceb83a45a98161efe0" category="list-text">*FabricPool.* FabricPool offre un Tiering simple et rapide pour les données ONTAP. Les blocs inactifs peuvent être migrés vers un magasin d'objets dans des clouds publics ou un magasin d'objets StorageGRID privé. Ils sont automatiquement rappelés lorsque vous accédez de nouveau aux données ONTAP. Vous pouvez également utiliser le Tier objet comme troisième niveau de protection pour les données déjà gérées par SnapVault. Cette approche peut vous permettre de<block ref="60d027dbb3c3f076cbb70c6b246eb433" category="inline-link-rx"></block> Sur les systèmes de stockage ONTAP primaires et/ou secondaires.</block>
  <block id="1a7072854c9dd945a98f4314b3f77408" category="list-text">*ONTAP Select.* utilisez le stockage Software-defined NetApp pour étendre votre cloud privé sur Internet aux sites et bureaux distants, où vous pouvez utiliser ONTAP Select pour prendre en charge les services de blocs et de fichiers ainsi que les mêmes fonctionnalités de gestion de données vSphere que votre data Center d'entreprise.</block>
  <block id="79aec220098057ef8c0e46281a45d6c2" category="paragraph">Lors de la conception de vos applications basées sur une VM, pensez à la mobilité future du cloud. Par exemple, plutôt que de placer les fichiers d'application et de données en même temps que les fichiers de données, utilisez une exportation LUN ou NFS distincte. Cela vous permet de migrer la machine virtuelle et les données séparément vers des services cloud.</block>
  <block id="af63597853dc0983258c8f86a12aae0b" category="section-title">Chiffrement pour les données vSphere</block>
  <block id="63a07ab9352c9297cea3894d6cd41c3f" category="paragraph">Aujourd'hui, les exigences croissantes en matière de protection des données au repos sont liées au chiffrement. Bien que la priorité initiale ait été donnée aux informations financières et de santé, il est de plus en plus intéressant de protéger toutes les informations, qu'elles soient stockées dans des fichiers, des bases de données ou tout autre type de données.</block>
  <block id="f131c8f285a9ebc44140235877aecbe5" category="paragraph">Les systèmes qui exécutent le logiciel ONTAP simplifient la protection de toutes les données au repos. NetApp Storage Encryption (NSE) utilise des lecteurs de disque à chiffrement automatique avec ONTAP pour protéger les données SAN et NAS. NetApp propose également NetApp Volume Encryption et NetApp Aggregate Encryption comme une approche logicielle simple pour le chiffrement des volumes sur tous les disques. Ce chiffrement logiciel ne nécessite pas de disques spéciaux ni de gestionnaires de clés externes. Il est disponible gratuitement pour les clients ONTAP. Vous pouvez procéder à une mise à niveau et commencer à l'utiliser sans perturber vos clients ou applications. Elles sont validées par la norme FIPS 140-2 de niveau 1, y compris le gestionnaire de clés intégré.</block>
  <block id="937a352e0f824ff55e4cd50c8e3b051e" category="paragraph">Il existe plusieurs approches de protection des données des applications virtualisées qui s'exécutent sur VMware vSphere. L'une d'elles consiste à protéger les données avec les logiciels internes à la machine virtuelle au niveau du système d'exploitation invité. Les nouveaux hyperviseurs, tels que vSphere 6.5, prennent désormais en charge le cryptage au niveau des machines virtuelles. Cependant, le chiffrement logiciel NetApp est simple et facile :</block>
  <block id="6eda79cc710edc32583cf567b00e7672" category="list-text">*Aucun effet sur la CPU du serveur virtuel.* certains environnements de serveurs virtuels nécessitent chaque cycle CPU disponible pour leurs applications, mais les tests ont montré que jusqu'à 5x ressources CPU sont nécessaires avec le cryptage au niveau de l'hyperviseur. Même si le logiciel de chiffrement prend en charge l'ensemble d'instructions AES-ni d'Intel pour décharger la charge de travail de chiffrement (comme le fait le chiffrement du logiciel NetApp), cette approche peut ne pas être possible en raison de l'exigence de nouveaux processeurs non compatibles avec les anciens serveurs.</block>
  <block id="6abee98aea26f85e6f0fe8d4db70f998" category="list-text">*Gestionnaire de clés intégré inclus.* le chiffrement logiciel NetApp inclut un gestionnaire de clés intégré sans frais supplémentaires, ce qui simplifie les prises en main sans serveurs de gestion des clés haute disponibilité complexes à acheter et à utiliser.</block>
  <block id="c216121021de8554d33503ef6616b256" category="list-text">*Aucun effet sur l'efficacité du stockage.* les techniques d'efficacité du stockage comme la déduplication et la compression sont largement utilisées aujourd'hui et sont essentielles pour exploiter les supports disque Flash de façon rentable. Toutefois, les données cryptées ne sont en général pas dédupliquées ou compressées. Le cryptage du stockage et du matériel NetApp fonctionne à un niveau inférieur et permet l'utilisation totale des fonctionnalités d'efficacité du stockage NetApp, contrairement aux autres approches.</block>
  <block id="5f9aa8333f218d1c21e67c8608a48672" category="list-text">*Chiffrement granulaire simple des datastores.* avec NetApp Volume Encryption, chaque volume bénéficie de sa propre clé AES 256 bits. Si vous devez le modifier, utilisez une seule commande. Cette approche est idéale si vous disposez de plusieurs locataires ou si vous devez prouver votre chiffrement indépendant pour différents services ou applications. Ce chiffrement est géré au niveau du datastore, ce qui est bien plus simple que de gérer des machines virtuelles individuelles.</block>
  <block id="de2b3baa1cd4980c36e8bbf7c827ae0c" category="paragraph">La prise en main du chiffrement logiciel est très simple. Une fois la licence installée, il vous suffit de configurer le gestionnaire de clés intégré en spécifiant une phrase secrète, puis de créer un volume ou de déplacer un volume côté stockage pour activer le chiffrement. NetApp travaille à ajouter une prise en charge plus intégrée des fonctionnalités de cryptage dans les prochaines versions de ses outils VMware.</block>
  <block id="c95fa5b56a01e5c1a80c540c1ab1a750" category="paragraph">Active IQ Unified Manager permet d'avoir une grande visibilité sur les machines virtuelles de votre infrastructure virtuelle et assure la surveillance et le dépannage des problèmes de stockage et de performances dans votre environnement virtuel.</block>
  <block id="be75250c2f30870dc1e359b4ade2a767" category="paragraph">Un déploiement d'infrastructure virtuelle standard sur ONTAP comporte divers composants répartis sur les couches de calcul, de réseau et de stockage. Tout ralentissement des performances dans une application VM peut survenir en raison de la combinaison de latences rencontrées par les différents composants au niveau des couches respectives.</block>
  <block id="d1734f6f2e65a1488896f74695db5254" category="paragraph">La capture d'écran suivante présente la vue des machines virtuelles Active IQ Unified Manager.</block>
  <block id="8aa017c9f67ad32dd7301ecf52b61d72" category="paragraph"><block ref="8aa017c9f67ad32dd7301ecf52b61d72" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2118336fa447fcc0f213cb8c40c516af" category="paragraph">Unified Manager présente le sous-système sous-jacent d'un environnement virtuel dans une vue topologique afin de déterminer si un problème de latence a eu lieu dans le nœud de calcul, le réseau ou le stockage. La vue indique également l'objet spécifique qui provoque le décalage des performances lors de la réalisation des étapes correctives et de la résolution du problème sous-jacent.</block>
  <block id="d8a78b994fcd4e04901203a2e7bc6414" category="paragraph">La capture d'écran suivante montre la topologie étendue AIQUM.</block>
  <block id="e9659be2b7d3d69eccdb443ed2acec75" category="paragraph"><block ref="e9659be2b7d3d69eccdb443ed2acec75" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f02207fb26160d7e47cf5ea35d07df03" category="doc">Datastores et protocoles</block>
  <block id="af8dcb8c7a1e8b7e614e570806d8dcee" category="paragraph">Sept protocoles sont utilisés pour connecter VMware vSphere aux datastores sur un système exécutant le logiciel ONTAP :</block>
  <block id="a7c815fafe60ae637d38216fa6300395" category="list-text">FCP</block>
  <block id="14eae6ee278098bfad4f8a10fd6c1195" category="list-text">FCoE</block>
  <block id="26bcb9f1cb6f391f4b2c18e676bb458d" category="list-text">NVMe/FC</block>
  <block id="8b7c42123642e2e4ea7dd426aeb2de58" category="list-text">NVMe/TCP</block>
  <block id="e4e1c13bb0b14f6cb7608cbecea948ef" category="list-text">ISCSI</block>
  <block id="f7d773fd2896401c143676940bc001fc" category="list-text">NFS v3</block>
  <block id="0b99b245267ef194ca3b9f6e694b0983" category="list-text">NFS v4.1</block>
  <block id="cfa070ed8af17c3125cfd1530fbd387a" category="paragraph">FCP, FCoE, NVMe/FC, NVMe/TCP et iSCSI sont des protocoles de bloc qui utilisent vSphere Virtual machine File System (VMFS) pour stocker des VM au sein de LUN ONTAP ou des espaces de noms NVMe contenus dans un volume ONTAP FlexVol. Notez que depuis vSphere 7.0, VMware ne prend plus en charge la technologie FCoE dans les environnements de production. NFS est un protocole de fichier qui place les machines virtuelles dans des datastores (qui sont simplement des volumes ONTAP) sans avoir besoin de VMFS. SMB (CIFS), iSCSI, NVMe/TCP ou NFS peuvent également être utilisés directement d'un système d'exploitation invité à ONTAP.</block>
  <block id="2b19cb432f68f1ba3dc7b0f175a14778" category="inline-link">Valeurs maximales de la configuration VMware</block>
  <block id="f8ca1b19553d4c965e40e9eeb1eb5aca" category="paragraph">Les tableaux suivants présentent les fonctionnalités de datastore traditionnel prises en charge par vSphere avec ONTAP. Ces informations ne s'appliquent pas aux datastores vvols, mais elles s'appliquent généralement aux versions vSphere 6.x et ultérieures utilisant des versions ONTAP prises en charge. Vous pouvez également consulter<block ref="61b579b455015dfa2bbf16bf62f07f93" category="inline-link-rx"></block> Pour les versions de vSphere spécifiques afin de confirmer les limites spécifiques.</block>
  <block id="9da73946f1bc3be4a41898d06c9d2e8b" category="cell">Capacités/fonctionnalités</block>
  <block id="c982f804d02e2d7e937f125d2cac1024" category="cell">FC/FCoE</block>
  <block id="6151632541dcd80356c6c76b34d69d0c" category="cell">NVMe-of</block>
  <block id="520d0db389f362bf79ef56ca0af3dcab" category="cell">Format</block>
  <block id="99a3142584ca8ad0a3afadeaa6f2ef69" category="cell">Mappage de périphériques VMFS ou bruts (RDM)</block>
  <block id="26aae26f61844ac20ab7b04ba6f5c515" category="cell">VMFS ou RDM</block>
  <block id="18263a30df8afc60a733e59c60676ac0" category="cell">VMFS</block>
  <block id="382b0f5185773fa0f67a8ed8056c7759" category="cell">S/O</block>
  <block id="8dc6d0c66219ddb809322c0d248e55e6" category="cell">Nombre maximal de datastores ou de LUN</block>
  <block id="aa23f9914ce1939ea7a4d479edfdc915" category="cell">1024 LUN par hôte</block>
  <block id="1af3b27207afc48a363629a315d76b59" category="cell">1024 LUN par serveur</block>
  <block id="0705fd627c25b5fba17cd9a022ed7d72" category="cell">256 Namespeces par serveur</block>
  <block id="2774ddb6f193789c5d9a480b9e53a38d" category="cell">256 supports
NFS par défaut. MaxVolumes est 8. Utilisez les outils ONTAP pour VMware vSphere et augmentez jusqu'à 256.</block>
  <block id="51c0dc217976e27de06e262947947a62" category="cell">Taille maximale des datastores</block>
  <block id="856c997f909830b8249756c07dc9452b" category="cell">64 TO</block>
  <block id="8e5d3a4b085389c59a1a7af7c4067a9b" category="cell">Volume FlexVol de 100 To ou supérieur avec FlexGroup volume</block>
  <block id="b4fb1d41fedaec79072964cbb4d16e3d" category="cell">Taille maximale des fichiers du datastore</block>
  <block id="d10549beb2f7bd1e91e5ef8965edd84a" category="cell">62TO</block>
  <block id="18301e675ce7d51c23071d7b135edbdc" category="cell">62 To avec ONTAP 9.12.1P2 et versions ultérieures</block>
  <block id="9aa56a79640231adaec83bc53e59c929" category="cell">Profondeur de file d'attente optimale par LUN ou par système de fichiers</block>
  <block id="c7dfde106afbb4e1d55096403af252e0" category="cell">64-256</block>
  <block id="ca6e77250a239af7b4aed9a1ac058825" category="cell">Négociation automatique</block>
  <block id="bad19bc2587cd465cab5cec5a13aa306" category="cell">Se reporter à NFS.MaxQueueDepth dans<block ref="0391a4aaf03ed2bf80fb4efb215797d0" category="inline-link-rx"></block>.</block>
  <block id="edc5121cb9b42a76b718b8ece9d67437" category="paragraph">Le tableau suivant répertorie les fonctionnalités de stockage VMware prises en charge.</block>
  <block id="6c1a84b789b54fd42511ce582be94d21" category="cell">VMotion</block>
  <block id="e95b58d02782c970bb339c6cc587ff39" category="cell">Stockage vMotion</block>
  <block id="0486e0e3dc3e86859f43b6d8e32b8071" category="cell">Haute disponibilité VMware</block>
  <block id="8be6bd7f20474cbefdd496cb9fd495ca" category="cell">Storage Distributed Resource Scheduler (SDRS)</block>
  <block id="4244919a64848265426dfd82a14f8248" category="cell">Logiciel de sauvegarde VMware vStorage APIs for Data protection (VADP)</block>
  <block id="28c2f8ab9cdbf296aa4261bc3c58ba0d" category="cell">Microsoft Cluster Service (MSCS) ou mise en cluster de basculement au sein d'une machine virtuelle</block>
  <block id="01a9a3b8d0fcae3055dc91935e8ec6c6" category="cell">Oui*</block>
  <block id="aa7f77e663b832d5b0e544c5511e680c" category="cell">Non pris en charge</block>
  <block id="aa18abedec09bd4f85e612c307e2eaa6" category="cell">Tolérance aux pannes</block>
  <block id="bfd52522de4ac6efd6f680e0e754eeb5" category="cell">Gestionnaire de reprise de site</block>
  <block id="d6407966cf588d8d78d4f7e65f1ea6fd" category="cell">V3 uniquement**</block>
  <block id="17d495427086fa21259b9df40b27e00a" category="cell">Machines virtuelles à provisionnement fin (disques virtuels)</block>
  <block id="4ee7af004efef335d6a14c60ee758f5e" category="cell">Oui.
Ce paramètre est le paramètre par défaut pour toutes les machines virtuelles sur NFS lorsqu'elles n'utilisent pas VAAI.</block>
  <block id="13bc264ff420559de4156ec40980a4b9" category="cell">Chemins d'accès multiples natifs VMware</block>
  <block id="50ed43e1a7a22335069a344bc706b600" category="cell">Oui, en utilisant le nouveau plug-in haute performance (HPP)</block>
  <block id="a06819d91a165d0491c5816c54b41234" category="paragraph">Le tableau suivant répertorie les fonctionnalités de gestion du stockage ONTAP prises en charge.</block>
  <block id="f8d61013f1a3bbf1342f4ced3279c7cf" category="cell">Déduplication des données</block>
  <block id="72167540968147afed9deb59f0e9fe00" category="cell">D'économies sur la baie</block>
  <block id="9a5473a6abaea16b736f096913a749be" category="cell">Économies au niveau du datastore</block>
  <block id="6cd880eabbec3488232c6cba3fbcf998" category="cell">Provisionnement fin</block>
  <block id="5caeb11c4ed379b808d7f7cdca7cfbf0" category="cell">Datastore ou RDM</block>
  <block id="8a5227cc82d14862956938caffc1acf2" category="cell">Datastore</block>
  <block id="b71ba22dcd42deceac87150206f7bd12" category="cell">Redimensionnement datastore</block>
  <block id="c6b792bfd7aac8067d36337e67d11545" category="cell">Évoluer uniquement</block>
  <block id="29e23534878bb63341e0b689426b7fb0" category="cell">Croissance, croissance automatique et réduction des volumes</block>
  <block id="76021405cc62a4b8c542e7f65e3d24ed" category="cell">Plug-ins SnapCenter pour applications Windows, Linux (invités)</block>
  <block id="c0b3c629432c82a9e8500242abb35eaf" category="cell">Contrôle et configuration de l'hôte à l'aide des outils ONTAP pour VMware vSphere</block>
  <block id="5a915a8215e9a66bcff0f034e8adff18" category="cell">Provisionnement avec les outils ONTAP pour VMware vSphere</block>
  <block id="6495c7cda42bf1b80bc1c2af6166ef58" category="paragraph">Le tableau suivant répertorie les fonctionnalités de sauvegarde prises en charge.</block>
  <block id="ad336d1fccea3e918d07055edac855a3" category="cell">Snapshots ONTAP</block>
  <block id="bf22a1b5bc2b72a75825094826a942de" category="cell">SRM pris en charge par les sauvegardes répliquées</block>
  <block id="60d3f7d9f265eb34e826da352cb545be" category="cell">SnapMirror volume</block>
  <block id="fabf31a57c142c986c5d88cb089b3d7b" category="cell">Accès image VMDK</block>
  <block id="40b655e79545b3922b8095be28d59428" category="cell">Logiciel de sauvegarde VADP</block>
  <block id="8215e73d220182794dfbd75ad494c727" category="cell">Logiciel de sauvegarde VADP, vSphere client et le navigateur du datastore du client Web vSphere</block>
  <block id="d7605580ecad0fcb4528789d74cdcad5" category="cell">Accès niveau fichier VMDK</block>
  <block id="906ece32da286d6c4b323bc0d6443b7c" category="cell">Logiciel de sauvegarde VADP, Windows uniquement</block>
  <block id="d17e2fa63a62622f88bf170612132383" category="cell">Logiciels de sauvegarde VADP et applications tierces</block>
  <block id="4e3d259d82a536e12c5c9c948b62e26a" category="cell">Granularité NDMP</block>
  <block id="90d45e02e50c81603c36a4e4ad3649d9" category="cell">Datastore ou VM</block>
  <block id="8339c514e73f5cced3b83d504d60441b" category="inline-link">Configuration de Windows Server Failover Clustering</block>
  <block id="45f7e6f7f6f0f4093754d7d48810e17f" category="paragraph">*NetApp recommande l'utilisation d'iSCSI « in-guest » pour les clusters Microsoft, plutôt que de VMDK « multiwriter » dans un datastore VMFS. Cette approche est entièrement prise en charge par Microsoft et VMware, et offre une grande flexibilité avec ONTAP (SnapMirror vers des systèmes ONTAP sur site ou dans le cloud), est facile à configurer et à automatiser et peut être protégée avec SnapCenter. VSphere 7 intègre une nouvelle option clustered VMDK. Cette approche est différente des VMDK compatibles avec plusieurs enregistreurs, qui requièrent un datastore présenté via le protocole FC pour lequel la prise en charge de VMDK en cluster est activée. D'autres restrictions s'appliquent. Voir VMware<block ref="b158594c147457b5b6417413cb30f800" category="inline-link-rx"></block> documentation pour les instructions de configuration.</block>
  <block id="e2bd40041a6472b580305ce9017b0b2e" category="paragraph">**Les datastores utilisant NVMe-of et NFS v4.1 nécessitent une réplication vSphere. SRM ne prend pas en charge la réplication basée sur les baies.</block>
  <block id="54b3e11ce37eaaa9884f4086e72dd2be" category="section-title">Sélection d'un protocole de stockage</block>
  <block id="4bbd62e7748dbf2416c644698342b5f9" category="paragraph">Les systèmes exécutant le logiciel ONTAP prennent en charge les principaux protocoles de stockage. Les clients peuvent ainsi choisir ce qui convient le mieux à leur environnement, en fonction de l'infrastructure réseau planifiée et du personnel. Les tests effectués par NetApp n'ont généralement pas permis de faire la différence entre les protocoles s'exécutant à des vitesses de ligne similaires. Il est donc préférable de se concentrer sur votre infrastructure réseau et sur les capacités des équipes par rapport aux performances des protocoles bruts.</block>
  <block id="0212b4e8bc965dcd8a7ff771dd96bf21" category="paragraph">Les facteurs suivants peuvent être utiles lors de l'examen d'un choix de protocole :</block>
  <block id="0425ddb6dbbe7f13280e19e1f925b0a8" category="list-text">*Environnement client actuel.* même si les équipes INFORMATIQUES sont généralement compétentes en matière de gestion de l'infrastructure IP Ethernet, elles ne sont pas toutes qualifiées pour la gestion d'une structure SAN FC. Cependant, l'utilisation d'un réseau IP générique non conçu pour le trafic de stockage risque de ne pas fonctionner correctement. Considérez l'infrastructure de réseau que vous avez en place, toutes les améliorations planifiées, ainsi que les compétences et la disponibilité du personnel pour les gérer.</block>
  <block id="774f1348caf3e145710073eb634c4fa1" category="list-text">*Simplicité d'installation.* au-delà de la configuration initiale de la structure FC (commutateurs et câblage supplémentaires, segmentation et vérification de l'interopérabilité des HBA et des micrologiciels), les protocoles de bloc exigent également la création et le mappage de LUN, ainsi que la découverte et le formatage par le système d'exploitation invité. Une fois les volumes NFS créés et exportés, ils sont montés par l'hôte ESXi et prêts à être utilisés. Avec NFS, il n'a pas de qualification de matériel ni de firmware à gérer.</block>
  <block id="bf5169ce5bb544313eaf17435f756da2" category="list-text">* Facilité de gestion.* avec les protocoles SAN, si plus d'espace est nécessaire, plusieurs étapes sont nécessaires, y compris l'expansion d'un LUN, de recanning pour découvrir la nouvelle taille, puis de développer le système de fichiers). Bien que la croissance d'une LUN soit possible, la réduction de la taille d'une LUN n'est pas possible et la restauration de l'espace inutilisé peut nécessiter un effort supplémentaire. NFS facilite le dimensionnement et le redimensionnement peut être automatisé par le système de stockage. LE SYSTÈME SAN permet de réclamer de l'espace via les commandes TRIM/UNMAP du système d'exploitation invité. L'espace des fichiers supprimés est ainsi renvoyé à la baie. Ce type de récupération d'espace est plus difficile avec les datastores NFS.</block>
  <block id="530c759326761c6ac026b313985b255f" category="list-text">*Transparence de l'espace de stockage.* l'utilisation du stockage est généralement plus facile à voir dans les environnements NFS parce que le provisionnement fin renvoie immédiatement des économies. De même, les économies de déduplication et de clonage sont immédiatement disponibles pour les autres VM dans le même datastore ou pour les autres volumes du système de stockage. La densité des machines virtuelles est également meilleure généralement dans un datastore NFS, ce qui permet d'améliorer les économies de déduplication et de réduire les coûts de gestion en utilisant moins de datastores à gérer.</block>
  <block id="16ee928b12bc598bf52b0f312879ec95" category="section-title">Disposition des datastores</block>
  <block id="b8c499c7b537f5bd4e51b0a6d6a1e9d0" category="list-text">Le déploiement de vSphere avec des datastores NFS ONTAP offre une implémentation très performante et facile à gérer qui fournit des ratios VM/datastore qui ne peuvent pas être obtenus avec des protocoles de stockage de niveau bloc. Cette architecture peut entraîner une multiplication par dix de la densité des datastores avec une corrélation réduction du nombre de datastores. Bien qu'un datastore plus volumineux puisse améliorer l'efficacité du stockage et offrir des avantages opérationnels, envisagez d'utiliser au moins quatre datastores (volumes FlexVol) pour stocker vos machines virtuelles sur un seul contrôleur ONTAP afin d'optimiser les performances des ressources matérielles. Cette approche vous permet également de créer des datastores avec différentes règles de restauration. Certaines peuvent être sauvegardées ou répliquées plus fréquemment que d'autres, en fonction des besoins de l'entreprise. Les volumes FlexGroup n'ont pas besoin de plusieurs datastores pour améliorer les performances, car ils évoluent indépendamment de la conception.</block>
  <block id="e15ed0ec7af4278259b7618024b3e7ce" category="list-text">NetApp recommande l'utilisation de volumes FlexVol pour la plupart des datastores NFS. À partir de ONTAP 9.8, les volumes FlexGroup sont également pris en charge en tant que datastores et sont généralement recommandés pour certaines utilisations. Les autres conteneurs de stockage ONTAP, tels que les qtrees, ne sont généralement pas recommandés, car ils ne sont actuellement pas pris en charge par les outils ONTAP pour VMware vSphere ou par le plug-in NetApp SnapCenter pour VMware vSphere. Cela étant, le déploiement de datastores sous forme de plusieurs qtrees dans un seul volume peut s'avérer utile dans les environnements hautement automatisés qui peuvent bénéficier de quotas au niveau du datastore ou de clones de fichiers de machine virtuelle.</block>
  <block id="dc4d78be836807b32c7ef7f42028b1ef" category="list-text">La taille correcte des datastores de volumes FlexVol est d'environ 4 To à 8 To. Cette taille constitue un bon équilibre pour les performances, la facilité de gestion et la protection des données. Démarrer petit (4 To, par exemple) et étendre le datastore en fonction des besoins (jusqu'à 100 To maximum). Les datastores plus petits peuvent être plus rapides à restaurer depuis la sauvegarde ou après un incident, et déplacés rapidement dans l'ensemble du cluster. Envisagez d'utiliser la fonction de dimensionnement automatique de ONTAP pour augmenter et réduire automatiquement le volume en fonction des modifications de l'espace utilisé. Les outils ONTAP de l'assistant de provisionnement des datastores VMware vSphere utilisent la taille automatique par défaut pour les nouveaux datastores. Vous pouvez également personnaliser davantage les seuils d'extension et de réduction ainsi que la taille maximale et minimale, avec System Manager ou la ligne de commandes.</block>
  <block id="964a81e46088ae1cc6306072464a9d73" category="list-text">Les datastores VMFS peuvent également être configurés avec des LUN accessibles via FC, iSCSI ou FCoE. VMFS permet d'accéder simultanément aux LUN classiques par chaque serveur ESX d'un cluster. Les datastores VMFS peuvent être jusqu'à 64 To et comprennent jusqu'à 32 LUN de 2 To (VMFS 3) ou un seul LUN de 64 To (VMFS 5). La taille de LUN maximale de ONTAP est de 16 To sur la plupart des systèmes et de 128 To sur les baies SAN. Il est donc possible de créer un datastore VMFS 5 de taille maximale sur la plupart des systèmes ONTAP en utilisant quatre LUN de 16 To. Bien que les charges de travail E/S élevées puissent bénéficier de la performance de plusieurs LUN (avec les systèmes FAS ou AFF haut de gamme), cet avantage peut être compensé par la complexité de gestion supplémentaire qui permet de créer, de gérer et de protéger les LUN des datastores et un risque de disponibilité accru. NetApp recommande généralement d'utiliser un volume LUN unique et important pour chaque datastore et ne peut être étendu que si le besoin de dépasser 16 To de data store. Comme pour NFS, envisagez l'utilisation de plusieurs datastores (volumes) pour optimiser les performances d'un seul contrôleur ONTAP.</block>
  <block id="c74cab014e402128efd8102b941c0b0c" category="list-text">Les anciens systèmes d'exploitation invités (OS) devaient s'aligner sur le système de stockage pour obtenir des performances et une efficacité du stockage optimales. Cependant, les systèmes d'exploitation actuels pris en charge par les fournisseurs de Microsoft et de distributeurs Linux tels que Red Hat ne nécessitent plus d'ajustements pour aligner la partition du système de fichiers sur les blocs du système de stockage sous-jacent dans un environnement virtuel. Si vous utilisez un ancien système d'exploitation pouvant nécessiter un alignement, recherchez dans la base de connaissances de support NetApp des articles utilisant « alignement de machines virtuelles » ou demandez une copie du rapport TR-3747 à un contact partenaire ou commercial NetApp.</block>
  <block id="8c761039ef4dd69451490b849ace1f82" category="list-text">Évitez d'utiliser des utilitaires de défragmentation au sein du système d'exploitation invité, car cela n'améliore pas les performances et affecte l'efficacité du stockage et l'utilisation de l'espace Snapshot. Envisagez également de désactiver l'indexation des recherches sur le système d'exploitation invité pour les postes de travail virtuels.</block>
  <block id="14abb814748566a24367c4459a54840b" category="list-text">ONTAP s'est leader du marché en proposant des fonctionnalités innovantes d'efficacité du stockage qui vous permettent d'exploiter au maximum votre espace disque utilisable. Les systèmes AFF renforcent cette efficacité avec la compression et la déduplication à la volée par défaut. Les données sont dédupliquées sur tous les volumes d'un agrégat. Ainsi, vous n'avez plus besoin de regrouper des systèmes d'exploitation similaires et des applications similaires au sein d'un même datastore pour optimiser les économies.</block>
  <block id="446548f2b1301893641e29657fc7fe53" category="inline-link-macro">Les bases de données Oracle sur ONTAP</block>
  <block id="6cda576d2fd323c1a728b7ac67d6034f" category="list-text">Les disques de première classe (ou des disques virtuels améliorés) permettent de gérer des disques gérés par vCenter indépendamment d'une machine virtuelle dotée de vSphere 6.5 et versions ultérieures. Lorsqu'elles sont principalement gérées par API, elles peuvent être utiles avec vvols, en particulier lorsqu'elles sont gérées par les outils OpenStack ou Kubernetes. Ils sont pris en charge par ONTAP ainsi que par les outils ONTAP pour VMware vSphere.</block>
  <block id="71318121439b39fdf872bb0bd57494f2" category="section-title">Migration des datastores et des machines virtuelles</block>
  <block id="e8824ce2062c6d1fc536163f7b8940bd" category="paragraph">Lorsque vous migrez des machines virtuelles depuis un datastore existant sur un autre système de stockage vers ONTAP, voici quelques principes à prendre en compte :</block>
  <block id="73b729fbc964c7d78dd90b64aaaeb785" category="list-text">Utilisez Storage vMotion pour déplacer la masse de vos machines virtuelles vers ONTAP. Cette approche n'assure pas seulement une exécution sans interruption des machines virtuelles. Elle permet également d'exploiter des fonctionnalités d'efficacité du stockage de ONTAP, comme la déduplication et la compression à la volée, pour traiter les données lors de leur migration. Envisagez d'utiliser les fonctionnalités de vCenter pour sélectionner plusieurs machines virtuelles dans la liste d'inventaire, puis planifiez la migration (utilisez la touche Ctrl tout en cliquant sur actions) à un moment opportun.</block>
  <block id="e512c890754c686d8deccac97d84a290" category="list-text">Bien que vous puissiez planifier avec soin une migration vers des datastores de destination appropriés, il est souvent plus simple de les migrer en bloc, puis de les organiser ultérieurement, si nécessaire. Utilisez cette approche pour orienter la migration vers différents datastores si vous avez besoin de protection des données spécifique, par exemple des calendriers Snapshot différents.</block>
  <block id="616b2180a0659911fed5aa758dba722c" category="list-text">La plupart des machines virtuelles et leur stockage peuvent être migrées lors de l'exécution (à chaud), mais pour migrer le stockage attaché (hors datastore) tel qu'un ISO (ISO), une LUN ou des volumes NFS à partir d'un autre système de stockage, il peut exiger une migration à froid.</block>
  <block id="fbb88da5639930a05f510729e473a216" category="inline-link">TR-4534</block>
  <block id="096f2185af16e07c387a7fbe50df957a" category="list-text">Les machines virtuelles qui nécessitent une migration plus minutieuse incluent les bases de données et les applications qui utilisent le stockage associé. De manière générale, envisagez l'utilisation des outils de l'application pour gérer la migration. Pour Oracle, envisagez d'utiliser des outils Oracle tels que RMAN ou ASM pour migrer les fichiers de base de données. Voir<block ref="6b3f565e7a7ce633fa62f4114c295216" category="inline-link-rx"></block> pour en savoir plus. De même, pour SQL Server, envisagez d'utiliser soit SQL Server Management Studio, soit des outils NetApp tels qu'SnapManager pour SQL Server, soit SnapCenter.</block>
  <block id="09485b54473eee31422696bf0217d714" category="paragraph">Lors de l'utilisation de vSphere avec des systèmes exécutant le logiciel ONTAP, la meilleure pratique la plus importante consiste à installer et à utiliser les outils ONTAP pour le plug-in VMware vSphere (anciennement Virtual Storage Console). Ce plug-in vCenter simplifie la gestion du stockage, améliore la disponibilité et réduit les coûts de stockage ainsi que les charges opérationnelles, que ce soit via SAN ou NAS. Il tire parti des bonnes pratiques pour le provisionnement des datastores et optimise les paramètres des hôtes ESXi pour les délais entre les chemins d'accès multiples et les HBA (ces paramètres sont décrits dans l'annexe B). Comme il s'agit d'un plug-in vCenter, il est disponible pour tous les clients Web vSphere qui se connectent au serveur vCenter.</block>
  <block id="9fb2cc2ced88ce872ef16c37d8284360" category="paragraph">Le plug-in permet également d'utiliser d'autres outils ONTAP dans les environnements vSphere. Il vous permet d'installer le plug-in NFS pour VMware VAAI, ce qui permet d'alléger la copie vers ONTAP pour les opérations de clonage de machines virtuelles, de réserver de l'espace pour les fichiers de disques virtuels lourds et de décharger les snapshots ONTAP.</block>
  <block id="2e0fa230911ceec131e12fe7c87fc01e" category="paragraph">Le plug-in est également l'interface de gestion de nombreuses fonctions du VASA Provider pour ONTAP, prenant en charge la gestion basée sur des règles de stockage avec vVols. Une fois les outils ONTAP pour VMware vSphere enregistrés, utilisez-le pour créer des profils de capacité de stockage, les mapper au stockage, et assurez-vous que le datastore est conforme aux profils au fil du temps. Vasa Provider fournit également une interface pour créer et gérer les datastores vvol.</block>
  <block id="9baea886f208a41896164d4ade5b3fde" category="paragraph">En règle générale, NetApp recommande d'utiliser les outils ONTAP pour l'interface VMware vSphere dans vCenter afin de provisionner les datastores classiques et vvols pour garantir le respect de bonnes pratiques.</block>
  <block id="6161d374e9022f89382fd63b4be15aa1" category="section-title">Réseau général</block>
  <block id="f0cd6847f2a7a0773ad0b58d0f9dc67d" category="paragraph">La configuration des paramètres réseau lors de l'utilisation de vSphere avec des systèmes exécutant le logiciel ONTAP est simple et similaire à celle d'autres configurations réseau. Voici quelques points à prendre en compte :</block>
  <block id="c7949782ad094d3ffc126bee722642a3" category="list-text">Utilisez des commutateurs qui prennent en charge l'agrégation de liens des ports sur deux châssis de commutateurs distincts grâce à une approche de groupe d'agrégation de liens multichâssis, telle que Virtual PortChannel (VPC) de Cisco.</block>
  <block id="9dc1904e0c3ace141704b477cd9b345d" category="inline-link">Gestion de réseau</block>
  <block id="68ecdb0d7a96e68318a53d12e9fab5b5" category="list-text">Utilisez LACP pour créer des agrégats de liens pour les systèmes de stockage ONTAP avec des groupes d'interfaces multimode dynamiques avec un hachage de port ou d'IP. Reportez-vous à la section<block ref="b87480ad0ff34784c4be1445a72a3aaf" category="inline-link-rx"></block> pour obtenir des conseils supplémentaires.</block>
  <block id="3b407fe7c9654197902b1dd26af6dc81" category="list-text">Utilisez une stratégie de regroupement de hachage IP sur ESXi lors de l'agrégation de liens statiques (EtherChannel, par exemple) et des vSwitch standard ou de l'agrégation de liens basée sur LACP avec des commutateurs distribués vSphere. Si l'agrégation de liens n'est pas utilisée, utilisez plutôt « route basée sur l'ID de port virtuel d'origine ».</block>
  <block id="ee1ef6cf0f3971b44eb2abcac958fb8d" category="section-title">Volumes FlexGroup</block>
  <block id="bf985cdd1506d49ea0773c8997e0b723" category="paragraph">ONTAP 9.8 ajoute la prise en charge des datastores de volumes FlexGroup dans vSphere, ainsi que les outils ONTAP pour VMware vSphere et le plug-in SnapCenter pour VMware vSphere. FlexGroup simplifie la création de datastores volumineux et crée automatiquement un certain nombre de volumes constitutifs afin d'optimiser les performances d'un système ONTAP. Utilisez FlexGroup avec vSphere si vous avez besoin d'un datastore vSphere unique et évolutif doté de la puissance d'un cluster ONTAP complet ou si vous disposez de charges de travail de clonage très volumineuses qui peuvent bénéficier du nouveau mécanisme de clonage FlexGroup.</block>
  <block id="83bcea036e70c0f011b083b2325b7a4b" category="paragraph">En plus des tests exhaustifs sur les charges de travail vSphere, ONTAP 9.8 propose également un nouveau mécanisme d'allègement de la charge de données pour les datastores FlexGroup. Il utilise un moteur de copie mis à jour qui utilise les premiers clones pour remplir un cache local dans chaque volume constitutif. Ce cache local est ensuite utilisé pour instancier rapidement des clones de machine virtuelle à la demande.</block>
  <block id="dd9bd4a686bdeb1c7f11dc3cd0cda75f" category="paragraph">Prenons le scénario suivant :</block>
  <block id="6b277580cb59b13790b36344e827e22f" category="list-text">Vous avez créé un nouveau FlexGroup avec 8 composants</block>
  <block id="32efd8b10cc3b73c344f4c7e6c4b741e" category="list-text">Le délai d'expiration du cache pour le nouveau FlexGroup est défini sur 160 minutes</block>
  <block id="879f959734466d50681eae9b95e7e591" category="paragraph">Dans ce scénario, les 8 premiers clones à terminer seront des copies complètes, et non des clones de fichiers locaux. Tout clonage supplémentaire de cette machine virtuelle avant l'expiration du délai de 160 secondes utilisera le moteur de clonage de fichiers à l'intérieur de chaque composant de manière circulaire pour créer des copies quasi immédiates réparties uniformément sur les volumes constitutifs.</block>
  <block id="b368b4dbd46dd778776d405dc46d2033" category="paragraph">Chaque nouvelle tâche de clonage reçue par un volume réinitialise le délai d'expiration. Si un volume composant de l'exemple FlexGroup ne reçoit pas de requête de clone avant le délai d'expiration, le cache de cette machine virtuelle sera effacé et le volume devra être à nouveau rempli. De même, si la source du clone d'origine change (par exemple, si vous avez mis à jour le modèle), le cache local de chaque composant sera invalidé pour éviter tout conflit. Le cache est réglable et peut être configuré pour répondre aux besoins de votre environnement.</block>
  <block id="0f98175ace2dd0d56e47961b22b2544b" category="paragraph">Dans les environnements où vous ne pouvez pas tirer pleinement parti du cache FlexGroup, mais où vous avez toujours besoin d'un clonage rapide entre plusieurs volumes, envisagez d'utiliser les vVols. Le clonage entre volumes avec vVols est beaucoup plus rapide qu'avec les datastores traditionnels et ne repose pas sur un cache.</block>
  <block id="189aae773e13462525f07e99fcd9e90f" category="inline-link">VAAI : comment la mise en cache fonctionne-t-elle avec les volumes FlexGroup ?</block>
  <block id="718103d957da7fb9e8210a49a85aedab" category="paragraph">Pour plus d'informations sur l'utilisation de FlexGroups avec VAAI, consultez l'article de la base de connaissances suivant :<block ref="23db52497ce446299e31ecc0b7572649" category="inline-link-rx"></block></block>
  <block id="eafcbe529f542610c50d02e4a2fffcd6" category="paragraph">ONTAP 9.8 ajoute également de nouveaux metrics de performance basés sur des fichiers (IOPS, débit et latence) pour les fichiers de volume FlexGroup. Ces metrics peuvent être consultées dans les outils ONTAP pour les rapports sur les machines virtuelles et le tableau de bord VMware vSphere. Les outils ONTAP pour le plug-in VMware vSphere vous permettent également de définir des règles de qualité de service (QoS) en combinant des IOPS minimales et/ou maximales. Ils peuvent être définis au sein de toutes les machines virtuelles d'un datastore ou individuellement pour des machines virtuelles spécifiques.</block>
  <block id="b8c631b88d7be5f1105be2f8c7ff3213" category="list-text">Utilisez les valeurs par défaut de provisionnement du volume FlexGroup. Les outils ONTAP pour VMware vSphere sont recommandés, car ils créent et montés FlexGroup dans vSphere, mais ONTAP System Manager ou la ligne de commandes peuvent être utilisés pour des besoins particuliers. Même ensuite, utilisez les valeurs par défaut, telles que le nombre de membres constituants par nœud, car c'est ce qui a été le plus testé avec vSphere. Cela dit, les paramètres non par défaut, tels que la modification du nombre ou le placement des composants, sont toujours pris en charge.</block>
  <block id="301593c45668093a7eb242d138c597a3" category="list-text">Lors du dimensionnement d'un datastore basé sur FlexGroup, gardez à l'esprit que le système FlexGroup se compose de plusieurs volumes FlexVol de plus petite taille qui créent un espace de noms plus grand. Par conséquent, lorsque vous utilisez un FlexGroup avec huit composants, assurez-vous que le datastore est au moins 8 fois plus volumineux que votre machine virtuelle la plus importante. Par exemple, si votre environnement contient une machine virtuelle de 6 To, sa taille FlexGroup n'est pas inférieure à 48 To.</block>
  <block id="6d9993f47e7802210a05453f494513bf" category="list-text">Actuellement, VMware et NetApp ne prennent pas en charge une approche commune de mise en réseau multivoie. Pour NFSv4.1, NetApp prend en charge pNFS, tandis que VMware prend en charge l'agrégation de sessions. NFSv3 ne prend pas en charge plusieurs chemins physiques vers un volume. Pour FlexGroup avec ONTAP 9.8, il est recommandé de laisser les outils ONTAP pour VMware vSphere créer le FlexGroup, puis de le démonter et de le remonter à l'aide d'un DNS circulaire afin de répartir la charge sur le cluster. Les outils ONTAP n'utilisent qu'une seule LIF lors du montage des datastores. Après avoir remoné le datastore, vous pouvez utiliser les outils ONTAP pour le surveiller et le gérer.</block>
  <block id="04cc9e0b9478cc704d42735886027630" category="list-text">Utilisez le plug-in NFS pour VMware VAAI pour la copie auxiliaire. Notez que même si le clonage est amélioré dans un datastore FlexGroup, comme mentionné précédemment, ONTAP n'offre pas d'avantages significatifs en termes de performances par rapport à la copie hôte ESXi lors de la copie de machines virtuelles entre des volumes FlexVol et/ou FlexGroup. Prenez donc en compte vos charges de travail de clonage lorsque vous décidez d'utiliser VAAI ou FlexGroups. L'une des façons d'optimiser le clonage basé sur FlexGroup consiste à modifier le nombre de volumes constitutifs. Tout comme le réglage du délai d'expiration du cache.</block>
  <block id="b9e0a0134c0815e50bb71d8dd7e367b6" category="list-text">À ce moment-là, la qualité de service (IOPS max/min) peut être définie sur des machines virtuelles individuelles ou sur toutes les machines virtuelles d'un datastore. La définition de la qualité de service sur toutes les VM remplace tous les paramètres distincts par VM. Les paramètres ne s'étendent pas ultérieurement aux nouvelles machines virtuelles ou aux machines virtuelles migrées ; définissez la qualité de service sur les nouvelles machines virtuelles ou appliquez à nouveau la qualité de service à toutes les machines virtuelles du datastore. Les stratégies QoS de FlexGroup ne suivent pas non plus la machine virtuelle si elle est migrée vers un autre datastore. Cela contraste avec les vVols qui peuvent conserver leurs paramètres de politique de QoS s'ils migrent vers un autre datastore.</block>
  <block id="1133ff8355478000111c8b1969e32770" category="list-text">Le plug-in SnapCenter pour VMware vSphere version 4.4 et ultérieure prend en charge la sauvegarde et la restauration des machines virtuelles dans un datastore FlexGroup sur le système de stockage principal. Le distributeur sélectif 4.6 ajoute la prise en charge de SnapMirror pour les datastores basés sur FlexGroup.</block>
  <block id="ce4df831657d2621e80bbef9271c33cd" category="summary">Avec la transition de l'appliance virtuelle existante, les outils ONTAP apportent une richesse de nouvelles fonctionnalités, de limites plus élevées, et de la prise en charge de nouveaux vvols.</block>
  <block id="45b1565c472fff4046d0f7ddbe1342f2" category="doc">Nouvelles fonctionnalités de SRM et des outils ONTAP</block>
  <block id="116d20fc387d73c8e4a86e7998913947" category="section-title">Dernières versions de vSphere et de site Recovery Manager</block>
  <block id="57359b8d2b77ce83f2e854fdd323377f" category="paragraph">Avec la version 8.7 et ultérieure de SRM et les versions 9.12 et ultérieures des outils ONTAP, vous pouvez désormais protéger les machines virtuelles qui s'exécutent sur VMware vSphere 8 mise à jour 1.</block>
  <block id="96ca6fcc2ffdab3c06d0875be8d4fe29" category="paragraph">NetApp a partagé un partenariat étroit avec VMware depuis près de deux décennies, et s'efforce de fournir une assistance pour les dernières versions dès que possible. Consultez toujours la matrice d'interopérabilité NetApp (IMT) pour connaître les dernières combinaisons logicielles qualifiées.</block>
  <block id="4ada3eb5b908caaedb757052562dfcf5" category="inline-link-macro"><block ref="4ada3eb5b908caaedb757052562dfcf5" category="inline-link-rx"></block></block>
  <block id="0a0a2a299629bed81a283fcd3b7833e9" category="paragraph">Le NetApp IMT est disponible à l'adresse <block ref="83e08b5e992bc41d59feec38bb24f26d" category="inline-link-macro-rx"></block>.</block>
  <block id="9d6e1631f68d52fd0f82222bf276cdc4" category="section-title">La prise en charge des vVols (et la raison pour laquelle la gestion basée sur des règles de stockage (SPBM) compte, même avec SRM)</block>
  <block id="b0b7bc3c901f340c708b7560d1f2b7e1" category="paragraph">À partir de la version 8.3, SRM prend désormais en charge la gestion basée sur les règles de stockage (SPBM) de la réplication exploitant les vVols et la réplication basée sur les baies pour les datastores utilisant iSCSI, FCP et NFS v3. Pour ce faire, le serveur SRM a été mis à jour pour inclure un nouveau service de fournisseur SRM vVols, qui communique avec le service SMS du serveur vCenter pour les tâches liées à VASA.</block>
  <block id="4567f5576b4577c63b126cac3f6aa5fa" category="paragraph">L'un des avantages de cette architecture est que SRA n'est plus nécessaire, car tout est géré à l'aide de VASA.</block>
  <block id="e04031e1cecdb6732f91d44b204dbcf3" category="paragraph">SPBM est un outil puissant dans la boîte à outils vSphere. Il permet de proposer des services de stockage cohérents, prévisibles et cohérents en fonction de la consommation dans les frameworks d'automatisation dans les environnements de cloud privé et hybride. Fondamentalement, grâce à la gestion des règles, vous pouvez définir des classes de service qui répondent aux besoins de votre base client diversifiée. SRM vous permet maintenant d'exposer des fonctionnalités de réplication à vos clients pour des charges de travail stratégiques qui nécessitent une orchestration et une automatisation fiables et standard de la reprise après incident.</block>
  <block id="1b6204fa76bd422416757c4e2d6187bd" category="paragraph">Exemple d'architecture vVols avec FCP ou iSCSI :</block>
  <block id="6f1ad7cac2af0e3b92a3936efc393a0e" category="paragraph"><block ref="6f1ad7cac2af0e3b92a3936efc393a0e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9abbd7aed7e9791d9c52e8e17f34a756" category="section-title">Prise en charge des serveurs SRM basés sur les dispositifs</block>
  <block id="925c477f139cce0692e13946a7f75eac" category="paragraph">Les serveurs SRM basés sur le système d'exploitation de photons sont désormais pris en charge, en plus des plates-formes Windows existantes.</block>
  <block id="62c2c4203aebe081ddbc6cdd489f8ad7" category="paragraph">Vous pouvez maintenant installer des cartes SRA quel que soit votre type de serveur SRM préféré.</block>
  <block id="7cb1700928c008eb817bc79250cc9002" category="section-title">Prise en charge d'IPv6</block>
  <block id="ea9aacd1495949730de8eeab11e66459" category="paragraph">IPv6 est désormais pris en charge avec les limites suivantes :</block>
  <block id="d6d7f3d43de975c07655ebba1936867a" category="list-text">VCenter 6.7 ou version ultérieure</block>
  <block id="eb26ee1a20fe3dbde98204ec8b3ab838" category="list-text">Non pris en charge avec SRM 8.2 (8.1, 8.3 et 8). 4 sont pris en charge)</block>
  <block id="918d32b75f0ab883abba3a8dc0c3ae8d" category="inline-link">Matrice d'interopérabilité</block>
  <block id="02e7e71042609d3158020ab7befe45c6" category="list-text">Vérifier le<block ref="218f4ad7153f69cdc5467065434cd2f0" category="inline-link-rx"></block> pour les dernières versions qualifiées.</block>
  <block id="e887aed8f9c3dbecd37e8896d96b6637" category="section-title">Meilleures performances</block>
  <block id="2a71574e89a69c8218fbac3f604b5728" category="paragraph">La performance opérationnelle est une exigence clé pour l'exécution des tâches SRM. Afin de respecter les exigences de RTO et RPO modernes, la SRA, associée aux outils ONTAP, a été améliorée.</block>
  <block id="bd403c539a0c414afacd7477bf3d311f" category="list-text">*Prise en charge des opérations de reprotection simultanées.* première introduction dans SRA 9.7.1, cette fonctionnalité vous permet d'exécuter la reprotection sur deux plans de reprise ou plus simultanément, ce qui réduit le temps nécessaire pour reprotéger les datastores après un basculement ou une migration et reste dans vos paramètres RTO et RPO.</block>
  <block id="f63b947f655a5aee2cf69d4f30d7f96b" category="list-text">*ONTAP Tools 9.8 ajoute un nouveau mode optimisé pour le NAS uniquement.* lorsque vous utilisez des comptes SVM et des connexions aux clusters ONTAP avec uniquement des datastores basés sur NFS, vous pouvez activer le mode optimisé pour NAS uniquement pour des performances optimales dans les environnements pris en charge.</block>
  <block id="c82379d922d9cdc55fa21affe9f9b8bf" category="list-text">*ONTAP Tools 9.12 a ajouté la prise en charge de la fonctionnalité de resynchronisation rapide SnapMirror d'ONTAP.* cette fonctionnalité permet la resynchronisation rapide des miroirs en vue de recalculer les économies réalisées après le processus. Cette fonctionnalité n'est pas utilisée par défaut, mais elle peut être activée dans les environnements à grande échelle où la resynchronisation classique prend trop de temps ou s'arrête.</block>
  <block id="4a4842d7448ef71eb69b013e560b18bb" category="section-title">Évolutivité accrue</block>
  <block id="26738e8d40ae8035805f13bdbf185c30" category="paragraph">L'outil ONTAP SRA peut désormais prendre en charge jusqu'à 500 groupes de protection (PPG) lorsqu'il est utilisé avec SRM 8.3 et versions ultérieures.</block>
  <block id="96cb4d41ca97bd9d3d446984d3170a57" category="paragraph">Une nouvelle fonctionnalité très attendue et très attendue est la version SnapMirror synchrone (SM-S) avec ONTAP 9.5 et versions ultérieures, qui offre une solution de réplication des données avec un RPO nul et granulaire pour vos applications stratégiques. SM-S requiert ONTAP Tools 9.8 ou version ultérieure.</block>
  <block id="b9832b10a87d0c3793ed3b413ee1d839" category="section-title">Prise en charge des API REST</block>
  <block id="0065ce57adc813187a8e9c640ba6223a" category="paragraph">La configuration du serveur SRA peut désormais être gérée par les API REST. Une interface utilisateur swagger a été ajoutée pour vous aider à créer vos flux de travail d'automatisation. Elle est disponible sur votre appliance ONTAP Tools à l'adresse<block ref="579ce3ee0a7c1521f3dce6a507ea64a0" prefix=" " category="inline-code"></block>.</block>
  <block id="dcaf091737df278b1b4bdd2e37c10a75" category="summary">NetApp ONTAP est une solution de stockage leader pour les environnements VMware vSphere depuis son introduction au data Center moderne en 2002. Elle continue également d'ajouter des fonctionnalités innovantes pour simplifier la gestion tout en réduisant les coûts.</block>
  <block id="0a0e655ee9ba6467857ebf014a268f29" category="doc">VMware site Recovery Manager et NetApp ONTAP</block>
  <block id="5bdb12cbb14efa98a61e7c5e3b4de108" category="admonition">Cette documentation remplace le rapport technique _TR-4900 : VMware site Recovery Manager with ONTAP_</block>
  <block id="7659430738ccf1c5b8c8084a4003c709" category="paragraph">NetApp ONTAP est une solution de stockage leader pour les environnements VMware vSphere depuis son introduction au data Center moderne en 2002. Elle continue également d'ajouter des fonctionnalités innovantes pour simplifier la gestion tout en réduisant les coûts. Ce document présente la solution ONTAP pour VMware site Recovery Manager (SRM), le logiciel de reprise après incident de pointe de VMware, qui inclut les dernières informations produit et les meilleures pratiques permettant de rationaliser le déploiement, de réduire les risques et de simplifier la gestion au quotidien.</block>
  <block id="e3445c3aa798f5ad98665e33d34dd952" category="paragraph">Les meilleures pratiques complètent d'autres documents, tels que des guides et des outils de compatibilité. Ils sont développés en fonction de tests effectués en laboratoire et d'une vaste expérience sur le terrain par les ingénieurs et les clients NetApp. Dans certains cas, les meilleures pratiques recommandées peuvent ne pas être adaptées à votre environnement. Cependant, ce sont généralement les solutions les plus simples qui répondent aux besoins des plus clients.</block>
  <block id="10b8f80c23f8a44dfa6b10ae56d7dbe9" category="paragraph">Ce document est axé sur les fonctionnalités des dernières versions de ONTAP 9 utilisées conjointement avec les outils ONTAP pour VMware vSphere 9.12 (notamment NetApp Storage Replication adapter [SRA] et VASA Provider [VP]), ainsi que VMware site Recovery Manager 8.7.</block>
  <block id="c40f8c2af56356193284f6b46865d954" category="section-title">Pourquoi utiliser ONTAP avec SRM ?</block>
  <block id="36c28121fc6c9b02a38c0b6c92654e9a" category="paragraph">Les plateformes de gestion des données NetApp optimisées par le logiciel ONTAP constituent certaines des solutions de stockage les plus utilisées pour SRM. Les raisons en sont nombreuses : une plateforme de gestion des données sécurisée, haute performance et multiprotocole unifié (NAS et SAN ensemble) qui fournit l'efficacité du stockage, la colocation, le contrôle de la qualité de service, la protection des données avec des copies Snapshot compactes et la réplication avec SnapMirror. Exploitez l'intégration native du multicloud hybride pour protéger vos charges de travail VMware et bénéficier de nombreux outils d'automatisation et d'orchestration à portée de main.</block>
  <block id="2242b80f4627736a48c4c9a36b7428f6" category="paragraph">Lorsque vous utilisez SnapMirror pour la réplication basée sur les baies, vous tirez parti de l'une des technologies ONTAP les plus éprouvées et les plus matures. SnapMirror vous permet de transférer les données de manière sécurisée et efficace en copiant uniquement les blocs du système de fichiers modifiés, et non les machines virtuelles entières ou les datastores. Même ces blocs tirent parti des économies d'espace, telles que la déduplication, la compression et la compaction. Les systèmes ONTAP modernes utilisent désormais SnapMirror, indépendant de la version, pour vous permettre de sélectionner plus de flexibilité vos clusters source et cible. SnapMirror est véritablement devenu l'un des outils les plus puissants disponibles pour la reprise après incident.</block>
  <block id="36b04390d6103d8075862e4b825a485e" category="paragraph">Que vous utilisiez des datastores NFS, iSCSI ou Fibre Channel classiques (désormais avec prise en charge des datastores vvols), SRM constitue une offre commerciale performante qui tire parti des fonctionnalités ONTAP pour la reprise après incident ou la planification et l'orchestration de la migration de data Center.</block>
  <block id="5d111e8a6885460b43ecf1f7abb6377e" category="section-title">Comment SRM exploite ONTAP 9</block>
  <block id="16d4ec242c9f020f3a1fade311c776ed" category="paragraph">SRM exploite les technologies avancées de gestion des données des systèmes ONTAP en l'intégrant aux outils ONTAP pour VMware vSphere, une appliance virtuelle qui englobe trois composants principaux :</block>
  <block id="d54038ba1f2a04a5b5f26c96627ae3e7" category="list-text">Le plug-in vCenter, précédemment appelé Virtual Storage Console (VSC), simplifie les fonctionnalités de gestion et d'efficacité du stockage, améliore la disponibilité et réduit les coûts de stockage ainsi que les charges opérationnelles, que vous utilisiez SAN ou NAS. Il s'appuie sur les bonnes pratiques pour le provisionnement des datastores et optimise les paramètres d'hôte ESXi pour les environnements de stockage NFS et bloc. Pour tous ces avantages, NetApp recommande ce plug-in lorsque vous utilisez vSphere avec les systèmes exécutant le logiciel ONTAP.</block>
  <block id="a106bb15d6dc2b11535ed4fefc81fbf4" category="list-text">Le fournisseur VASA pour ONTAP prend en charge la structure VMware vStorage APIs for Storage Awareness (VASA). Vasa Provider connecte vCenter Server avec ONTAP pour faciliter le provisionnement et la surveillance du stockage des machines virtuelles. Il assure la prise en charge de VMware Virtual volumes (vvols) et la gestion des profils de capacité de stockage (y compris les fonctionnalités de réplication vvols) ainsi que les performances individuelles de VM vvols. Il fournit également des alarmes pour la surveillance de la capacité et la conformité avec les profils. Utilisé conjointement avec SRM, le fournisseur VASA pour ONTAP permet la prise en charge des machines virtuelles basées sur vvols sans avoir à installer un adaptateur SRA sur le serveur SRM.</block>
  <block id="f2007951062862f5f0d593acbb23bcb4" category="list-text">SRA est utilisée en association avec SRM pour gérer la réplication des données des machines virtuelles entre les sites de production et de reprise après incident pour les datastores VMFS et NFS traditionnels, et pour les tests non disruptives des répliques de DR. Il permet d'automatiser les tâches de détection, de restauration et de reprotection. Elle inclut une appliance serveur SRA et des adaptateurs SRA pour le serveur Windows SRM et l'appliance SRM.</block>
  <block id="8ccaa60ee78ecc93c4870b3b2ad15284" category="paragraph">Après avoir installé et configuré les adaptateurs SRA sur le serveur SRM pour la protection des datastores non-vvols et/ou la réplication vvols activée dans les paramètres de VASA Provider, vous pouvez commencer la tâche de configuration de votre environnement vSphere pour la reprise après incident.</block>
  <block id="0a1e25166326359cd5f50d0ab83e6a37" category="paragraph">Les fournisseurs SRA et VASA proposent une interface de commande et de contrôle pour le serveur SRM afin de gérer les volumes FlexVol ONTAP contenant vos machines virtuelles VMware, ainsi que la réplication SnapMirror les protégeant.</block>
  <block id="38db855935949f86c5db7bfe7d49873e" category="paragraph">À partir de SRM 8.3, un nouveau chemin de contrôle SRM vvols Provider a été introduit dans le serveur SRM, ce qui lui a permis de communiquer avec le serveur vCenter et, par le biais de celui-ci, au VASA Provider sans avoir besoin d'une SRA. Ainsi, le serveur SRM a pu mieux contrôler le cluster ONTAP qu'auparavant. En effet, VASA fournit une API complète pour une intégration étroitement couplée.</block>
  <block id="1c27364cc3705aff403c6ef131c347ff" category="paragraph">SRM peut tester votre plan de reprise après incident sans interruption grâce à la technologie FlexClone propriétaire de NetApp pour créer des clones quasi instantanés de vos datastores protégés sur votre site de reprise après incident. SRM crée un sandbox afin de tester en toute sécurité afin que votre entreprise et vos clients soient protégés en cas d'incident, vous assurant ainsi la confiance de votre entreprise dans la capacité à exécuter un basculement lors d'un incident.</block>
  <block id="04a8f82007ed4bec45053912a49b6f85" category="paragraph">En cas d'incident véritable ou même de migration planifiée, SRM vous permet d'envoyer les modifications de dernière minute au jeu de données via une mise à jour SnapMirror finale (si vous le souhaitez). Il interrompt ensuite le miroir et monte le datastore sur vos hôtes de reprise après incident. À ce stade, vos machines virtuelles peuvent être automatiquement alimentées dans l'ordre de votre stratégie prédéfinie.</block>
  <block id="b2560426a08ae6ceb167dad2bfb5e8ae" category="section-title">SRM avec ONTAP et autres cas d'utilisation : cloud hybride et migration</block>
  <block id="ed4c730bd8636c27d3eaa876c63b3d45" category="inline-link">NetApp Private Storage dans Equinix</block>
  <block id="b422e05bc5c6f52208b66ff51d718b9d" category="paragraph">En intégrant votre déploiement de SRM aux fonctionnalités avancées de gestion des données de ONTAP, vous pouvez améliorer l'évolutivité et les performances par rapport aux options de stockage local. Elle apporte cependant la flexibilité du cloud hybride. Grâce au cloud hybride, vous pouvez réaliser des économies en transférant les blocs de données non utilisés de votre baie haute performance vers votre hyperscaler préférée, via FabricPool, qui peut être un magasin S3 sur site tel que NetApp StorageGRID. Vous pouvez également utiliser SnapMirror pour les systèmes basés en périphérie avec ONTAP Select l'infrastructure de reprise après incident Software-defined ou basée dans le cloud à l'aide de Cloud Volumes ONTAP (CVO) ou<block ref="37a666d3a37f1c4a8c4c8dba379664a4" category="inline-link-rx"></block> Pour créer une pile de services de stockage, de réseau et de calcul entièrement intégrée dans le cloud, Amazon Web Services (AWS), Microsoft Azure et Google Cloud Platform (GCP)</block>
  <block id="87a7b114355b836acefe833c497611bb" category="paragraph">Vous pouvez ensuite effectuer un basculement de test dans le data Center d'un fournisseur de services clouds avec une empreinte de stockage proche de zéro grâce à FlexClone. La protection de votre entreprise peut à présent être plus économique que jamais.</block>
  <block id="12d0cbcf61df7df30bf9b020f6fbb051" category="paragraph">SRM peut également être utilisé pour exécuter des migrations planifiées en utilisant SnapMirror pour transférer efficacement vos machines virtuelles d'un data Center à un autre ou même au sein d'un même data Center, que vous le soyez propriétaire ou via plusieurs fournisseurs de services partenaires NetApp.</block>
  <block id="160f88ca0bed5b24e94c809f4e22f1e7" category="summary">Dans ONTAP 9, les composants physiques d'un cluster sont visibles pour les administrateurs du cluster, mais ils ne sont pas directement visibles pour les applications et les hôtes qui utilisent le cluster.</block>
  <block id="89fafdb11a7e8cd8abebb1d4df053dad" category="doc">Topologies de réplication</block>
  <block id="be01acd2f018d38f9446f06b99ee4a2a" category="paragraph">Dans ONTAP 9, les composants physiques d'un cluster sont visibles pour les administrateurs du cluster, mais ils ne sont pas directement visibles pour les applications et les hôtes qui utilisent le cluster. Les composants physiques offrent un pool de ressources partagées à partir duquel les ressources logiques du cluster sont créées. Les applications et les hôtes accèdent aux données uniquement au moyen de SVM qui contiennent des volumes et des LIF.</block>
  <block id="7758fc02779ee5917b0a09ee22b52221" category="paragraph">Chaque SVM NetApp est traité comme une baie dans VMware vCenter site Recovery Manager. SRM prend en charge certaines dispositions de réplication baie à baie (ou SVM à SVM).</block>
  <block id="58c0b55a67f4331cc49b073a7183e06c" category="paragraph">Une seule machine virtuelle ne peut pas héberger de données (Virtual machine Disk (VMDK) ou RDM) sur plusieurs baies SRM pour les raisons suivantes :</block>
  <block id="880aeda0b58c0b30120b6319ae5f3beb" category="list-text">SRM ne voit que la SVM, pas un contrôleur physique individuel.</block>
  <block id="6f55124e085dbeb640e4cb8ad2c97905" category="list-text">Un SVM peut contrôler les LUN et les volumes répartis sur plusieurs nœuds dans un cluster.</block>
  <block id="39d9903201320a83d45d3b36d512f051" category="cell">Meilleure pratique</block>
  <block id="d86019fe4ba86b184ac71cf24a22f0c6" category="cell">Pour déterminer la prise en charge, conservez cette règle à l'esprit : pour protéger une machine virtuelle via SRM et NetApp SRA, tous les composants de la machine virtuelle doivent exister sur un seul SVM. Cette règle s'applique aussi bien au site protégé que au site de reprise.</block>
  <block id="2e4472d35f80aa8b7eca52ae3dd43dc6" category="section-title">Dispositions SnapMirror prises en charge</block>
  <block id="d070ad9d8397892aa7f317cbb9046661" category="paragraph">Les figures suivantes présentent les scénarios de disposition des relations SnapMirror pris en charge par SRM et SRA. Chaque machine virtuelle des volumes répliqués est propriétaire de données sur une seule baie SRM (SVM) sur chaque site.</block>
  <block id="39d3085abe6ccb914d8535de8a5f3e37" category="paragraph"><block ref="39d3085abe6ccb914d8535de8a5f3e37" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ae7670cf947a397bdf6a882fbcc912a" category="paragraph"><block ref="1ae7670cf947a397bdf6a882fbcc912a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="111d3212464dba203cbd675a0338dcbc" category="paragraph"><block ref="111d3212464dba203cbd675a0338dcbc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c5dc3a606b05b41db22793ed3c1a72db" category="paragraph"><block ref="c5dc3a606b05b41db22793ed3c1a72db" category="inline-image-macro-rx" type="image"></block></block>
  <block id="86cf5bd2bdb1b1d67f8f907f41099509" category="section-title">Mises en page de Array Manager prises en charge</block>
  <block id="aacc8f18d659f75715d91a983e872233" category="paragraph">Lorsque vous utilisez la réplication basée sur la baie (ABR) dans SRM, les groupes de protection sont isolés vers une seule paire de baies, comme l'illustre la capture d'écran suivante. Dans ce scénario,<block ref="129864522ed0e4ac80f306ecfa130ef7" prefix=" " category="inline-code"></block> et<block ref="ec87aa7f4c8e70a139fd988f87b6549f" prefix=" " category="inline-code"></block> sont associés à<block ref="387d04b65848414d4697f145a3782f90" prefix=" " category="inline-code"></block> et<block ref="58bdbfcb72c2dd3d883a7ca754443a4c" prefix=" " category="inline-code"></block> sur le site de reprise. Cependant, vous ne pouvez sélectionner qu'une des deux paires de matrices lorsque vous créez un groupe de protection.</block>
  <block id="68a1b289711a591ed50627014cd01ce9" category="paragraph"><block ref="68a1b289711a591ed50627014cd01ce9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ceb46f3e1c6c7995de4ec5f05601227" category="section-title">Présentations non prises en charge</block>
  <block id="611b9b35ac984f20e6594baec9181dbf" category="paragraph">Les configurations non prises en charge possèdent des données (VMDK ou RDM) sur plusieurs SVM appartenant à une machine virtuelle individuelle. Dans les exemples présentés dans les figures suivantes,<block ref="df777c4d2477e55571925353ce589f7e" prefix=" " category="inline-code"></block> Ne peut pas être configuré pour la protection avec SRM car<block ref="df777c4d2477e55571925353ce589f7e" prefix=" " category="inline-code"></block> Possède des données sur deux SVM.</block>
  <block id="5c251a65e8394fbeaf104ba1a1cad2e1" category="paragraph"><block ref="5c251a65e8394fbeaf104ba1a1cad2e1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f5f5fe64e0e9d0ae7ce2a0777d0ccf62" category="paragraph"><block ref="f5f5fe64e0e9d0ae7ce2a0777d0ccf62" category="inline-image-macro-rx" type="image"></block></block>
  <block id="69851ac8c2fa81b32799efc8522798d5" category="paragraph">Toute relation de réplication dans laquelle un volume NetApp individuel est répliqué depuis un SVM source vers plusieurs destinations dans un même SVM ou dans différents SVM, est appelée « Fan-Out » de SnapMirror. La réplication « Fan-Out » n'est pas prise en charge par SRM. Dans l'exemple illustré dans la figure suivante,<block ref="df777c4d2477e55571925353ce589f7e" prefix=" " category="inline-code"></block> Ne peut pas être configuré pour la protection dans SRM car elle est répliquée avec SnapMirror dans deux emplacements différents.</block>
  <block id="688890bdbdfd2d73a05a09883f3c4b40" category="paragraph"><block ref="688890bdbdfd2d73a05a09883f3c4b40" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3f88384b0d5cdcdc25895c644126c1b0" category="section-title">SnapMirror en cascade</block>
  <block id="7ebde774ad43c45667d5544308a6d688" category="paragraph">SRM ne prend pas en charge le cascade des relations SnapMirror, dans lesquelles un volume source est répliqué sur un volume de destination, et ce volume de destination est également répliqué avec SnapMirror vers un autre volume de destination. Dans le scénario illustré dans la figure suivante, SRM ne peut pas être utilisé pour le basculement entre des sites.</block>
  <block id="2990fc44e9ba827a397e96e1c278a02a" category="paragraph"><block ref="2990fc44e9ba827a397e96e1c278a02a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8bd15e818d377a0a5cf6ebc429555f79" category="section-title">SnapMirror et SnapVault</block>
  <block id="d440734d1f5d9c6e59aa97f7cbbcd525" category="paragraph">Le logiciel NetApp SnapVault permet de sauvegarder les données d'entreprise sur disque entre les systèmes de stockage NetApp. SnapVault et SnapMirror peuvent coexister dans un même environnement, mais SRM prend en charge le basculement de uniquement les relations SnapMirror.</block>
  <block id="7878dfbf4b6ad3bc60d095cf89d79202" category="admonition">L'adaptateur NetApp SRA prend en charge le<block ref="e7d3e049f94ce3ff8a47f209f012173d" prefix=" " category="inline-code"></block> type de règle.</block>
  <block id="883e69a285ae2d5fd23c80cd29285804" category="paragraph">SnapVault a été entièrement reconstruit pour ONTAP 8.2. Bien que les anciens utilisateurs de Data ONTAP 7-mode trouvent des similarités, des améliorations majeures ont été apportées dans cette version d'SnapVault. Une avancée majeure est la capacité à préserver l'efficacité du stockage sur les données primaires au cours des transferts SnapVault.</block>
  <block id="9bc21373e0e299579a7ac86dcd4f513d" category="paragraph">L'architecture SnapVault de ONTAP 9 réplique au niveau du volume et non au niveau du qtree, comme c'est le cas avec 7-mode SnapVault. Dans ce cas, la source d'une relation SnapVault doit être un volume, et ce volume doit être répliqué sur son propre volume sur le système secondaire SnapVault.</block>
  <block id="d447048519c85a2fb3bea0790cd109fb" category="paragraph">Dans un environnement dans lequel SnapVault est utilisé, des snapshots nommés spécifiques sont créés sur le système de stockage principal. Selon la configuration implémentée, les snapshots nommés peuvent être créés sur le système principal par une planification SnapVault ou par une application telle que NetApp Active IQ Unified Manager. Les snapshots nommés créés sur le système primaire sont ensuite répliqués sur la destination SnapMirror, puis stockés sur la destination SnapVault.</block>
  <block id="5dd37b7cd36f7d38ba2e6a63c603be4c" category="paragraph">Un volume source peut être créé dans une configuration en cascade, dans laquelle un volume est répliqué vers une destination SnapMirror dans le site de reprise après incident, et depuis ce volume est copié vers une destination SnapVault. Un volume source peut également être créé au sein d'une relation « fan-out » où une destination est une destination SnapMirror et l'autre destination est une destination SnapVault. Toutefois, SRA ne reconfigurez pas automatiquement la relation SnapVault pour utiliser le volume de destination SnapMirror comme source du coffre-fort en cas de basculement ou d'inversion de réplication SRM.</block>
  <block id="5bc66b9c84b3f7cc0b375e729376b68d" category="inline-link">Tr-4015 Guide des meilleures pratiques en matière de configuration de SnapMirror pour ONTAP 9.</block>
  <block id="0d510e96259254d285c6aaeb8458f45d" category="paragraph">Pour connaître les dernières informations concernant SnapMirror et SnapVault pour ONTAP 9, consultez<block ref="32e7c991f675bf983c547a2a174c2caf" category="inline-link-rx"></block></block>
  <block id="75f8a2d99eea9f336120aec69d8c1010" category="cell">Si SnapVault et SRM sont utilisés dans le même environnement, NetApp recommande d'utiliser une configuration SnapMirror vers SnapVault en cascade dans laquelle les sauvegardes SnapVault sont normalement exécutées à partir de la destination SnapMirror sur le site de reprise après incident. En cas d'incident, cette configuration rend le site principal inaccessible. Le fait de conserver la destination SnapVault sur le site de reprise permet de reconfigurer les sauvegardes SnapVault après le basculement, de sorte que les sauvegardes SnapVault puissent continuer sur le site de reprise.</block>
  <block id="e082a67e3ddd7f4f92096536440cbb34" category="paragraph">Dans un environnement VMware, chaque datastore dispose d'un identifiant unique universel (UUID) et chaque machine virtuelle possède un ID d'objet géré unique (MOID). Ces identifiants ne sont pas gérés par SRM lors du basculement ou de la restauration. Étant donné que les UID et les MOID de machine virtuelle ne sont pas maintenus lors du basculement par SRM, toutes les applications qui dépendent de ces ID doivent être reconfigurées après le basculement SRM. NetApp Active IQ Unified Manager, qui coordonne la réplication SnapVault avec l'environnement vSphere, est un exemple d'application.</block>
  <block id="657a41cce55646ab17754ac1427970af" category="paragraph">La figure suivante décrit une configuration SnapMirror vers SnapVault en cascade. Si la destination SnapVault se trouve sur le site de reprise après incident ou sur un site tertiaire non affecté par une panne sur le site primaire, l'environnement peut être reconfiguré afin de permettre la continuité des sauvegardes après le basculement.</block>
  <block id="b56afb9a43332c671116b9fa3d597867" category="paragraph"><block ref="b56afb9a43332c671116b9fa3d597867" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e068178460f103498576eac8ddb7fb82" category="paragraph">La figure suivante décrit la configuration après l'utilisation de SRM pour renvoyer la réplication SnapMirror vers le site primaire. L'environnement a également été reconfiguré de façon à ce que les sauvegardes SnapVault s'effectuent à partir d'une source SnapMirror. Cette configuration est « Fan-Out » de SnapMirror SnapVault.</block>
  <block id="0ffa07ffd89b136d0ed8f2ac5ebcabb8" category="paragraph"><block ref="0ffa07ffd89b136d0ed8f2ac5ebcabb8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b4607a4ee7e1830ab6ba0007df206956" category="paragraph">Une fois que SRM a effectué une restauration et une seconde inversion des relations SnapMirror, les données de production sont de nouveau sur le site principal. Ces données sont désormais protégées de la même manière qu'avant le basculement vers le site de reprise après incident, via les sauvegardes SnapMirror et SnapVault.</block>
  <block id="63fd1f18d5d53fa97fd05a7fd96090b4" category="section-title">Utilisation de qtrees dans les environnements site Recovery Manager</block>
  <block id="2d88570ceb2de0d8699a068b0140454b" category="paragraph">Les qtrees sont des répertoires spéciaux qui permettent l'application de quotas de système de fichiers pour NAS. ONTAP 9 permet la création de qtrees et peut exister dans les volumes répliqués avec SnapMirror. Toutefois, SnapMirror ne permet pas la réplication de qtrees individuels ni de réplication au niveau qtree. Toute la réplication SnapMirror se fait au niveau du volume uniquement. C'est pour cette raison que NetApp ne recommande pas l'utilisation de qtrees avec SRM.</block>
  <block id="345cb3f040f9f7f3f1a4261ed260aa79" category="section-title">Environnements FC et iSCSI mixtes</block>
  <block id="a60b166c2b69b4fdfbb733dc2193668a" category="paragraph">Grâce à la prise en charge des protocoles SAN (FC, FCoE et iSCSI), ONTAP 9 propose des services LUN, à savoir la création de LUN et leur mappage vers les hôtes associés. Dans la mesure où le cluster compte plusieurs contrôleurs, il existe plusieurs chemins logiques gérés par les E/S multivoies vers une LUN individuelle. L'accès ALUA (Asymmetric Logical Unit Access) est utilisé sur les hôtes pour que le chemin optimisé vers un LUN soit sélectionné et activé pour le transfert de données. Si ce chemin change (par exemple, en raison du déplacement du volume qui y est associé), ONTAP 9 reconnaît automatiquement cette modification et s'ajuste de façon non disruptive. S'il devient indisponible, ONTAP peut également basculer sans interruption sur un autre chemin.</block>
  <block id="b9921ac732e72656bc2836f83bb09522" category="paragraph">VMware SRM et NetApp SRA prennent en charge l'utilisation du protocole FC sur un site et le protocole iSCSI sur l'autre site. Il ne prend pas en charge la combinaison de datastores FC et de datastores iSCSI dans le même hôte ESXi ou d'hôtes différents dans le même cluster. Cette configuration n'est pas prise en charge avec SRM car, pendant le basculement SRM ou le basculement de test, SRM inclut tous les initiateurs FC et iSCSI des hôtes ESXi dans la demande.</block>
  <block id="fccd44a96243e459128798803dca70aa" category="cell">SRM et SRA prennent en charge les protocoles FC et iSCSI mixtes entre les sites protégés et de reprise. Cependant, chaque site ne doit pas être configuré avec un seul protocole, FC ou iSCSI, et non avec les deux protocoles sur le même site. Si il est nécessaire de configurer les protocoles FC et iSCSI sur le même site, NetApp recommande que certains hôtes utilisent iSCSI et d'autres hôtes utilisent FC. Dans ce cas, NetApp recommande également de configurer les mappages de ressources SRM de sorte que les VM soient configurés pour basculer vers un groupe d'hôtes ou un autre.</block>
  <block id="963739e9818c0bf4d8959b5cdf6a7956" category="summary">Le flux de travail de SRM est significativement différent lors de l'utilisation de la réplication vvols à partir de ce qui est utilisé avec SRA et les datastores traditionnels.</block>
  <block id="56687c1a324f03f5d1429500efea710e" category="doc">Dépannage de SRM lors de l'utilisation de la réplication de vvols</block>
  <block id="14acf40cbe69d8682b4c844ac7fbf7f6" category="paragraph">Le flux de travail de SRM est significativement différent lors de l'utilisation de la réplication vvols à partir de ce qui est utilisé avec SRA et les datastores traditionnels. Par exemple, il n'existe pas de concept de gestionnaire de baie. Comme c'est le cas,<block ref="0ec64480a9620a1430c0ae1b6603ea01" prefix=" " category="inline-code"></block> et<block ref="ba6c59072f543cb828e47d5bac560371" prefix=" " category="inline-code"></block> les commandes ne sont jamais vues.</block>
  <block id="ef74d715544e3b067a6bec3218ac5044" category="paragraph">Lors du dépannage, il est utile de comprendre les nouveaux flux de travail répertoriés ci-dessous :</block>
  <block id="47f0942d341ee10381b2eff35089d75d" category="list-text">QueryReplicationPeer : détecte les accords de réplication entre deux domaines de défaillance.</block>
  <block id="136a299aae29998a147852cb0cba5b4a" category="list-text">QueryFaultDomain : détecte la hiérarchie du domaine de pannes.</block>
  <block id="c071098c5df923c31f6245e4db2f3861" category="list-text">QueryReplicationGroup : détecte les groupes de réplication présents dans les domaines source ou cible.</block>
  <block id="792cfe9ad3a3dc8528080a262e92989a" category="list-text">SyncReplicationGroup : synchronise les données entre la source et la cible.</block>
  <block id="39afb1e1e3b180a6230e07bb8571667e" category="list-text">QueryPointInTimeReplica : détecte le point dans le temps des répliques sur une cible.</block>
  <block id="9fb25fe2ff084dc9ccfb99eaccba7212" category="list-text">TestFailoverReplicationGroupStart : démarre le basculement de test.</block>
  <block id="bd4e1dacaca4c37a53b5286b6ae0239d" category="list-text">TestFailoverReplicationGroupStop : met fin au basculement de test.</block>
  <block id="887f376a43cf9de1d6e14a8d69e588f6" category="list-text">PromoteReplicationGroup : promeut un groupe actuellement en cours de test à la production.</block>
  <block id="17ab16c5c0786ff381e6a085318bad9b" category="list-text">PreparFailoverReplicationTM : prépare une reprise après sinistre.</block>
  <block id="665dd64ebcc4016bda94e0e8020d8c8e" category="list-text">FailoverReplicationGroup : exécute la reprise après incident.</block>
  <block id="6936cf00e30b7cd4421225113a023c3e" category="list-text">ReverseReplicateGroup : lance la réplication inverse.</block>
  <block id="61ac8950a043e6998b458d4f8171154c" category="list-text">QueryMatchingContainer : recherche les conteneurs (ainsi que les hôtes ou les groupes de réplication) susceptibles de satisfaire une demande de provisionnement avec une règle donnée.</block>
  <block id="05c9efdc056d2af4640bc441ab61b53a" category="list-text">QueryResourceMetadata : recherche les métadonnées de toutes les ressources du fournisseur VASA, l'utilisation des ressources peut être renvoyée comme réponse à la fonction queryMatchingContainer.</block>
  <block id="01fa56986f885c588b1be8c206623de8" category="paragraph">L'erreur la plus courante lors de la configuration de la réplication vvols est une incapacité à découvrir les relations SnapMirror. En effet, les volumes et les relations SnapMirror sont créés en dehors de la purView des outils ONTAP. Il est donc recommandé de toujours s'assurer que votre relation SnapMirror est totalement initialisée et que vous avez exécuté une redécouverte dans les outils ONTAP sur les deux sites avant de tenter de créer un datastore vvols répliqué.</block>
  <block id="3e4627f6667f830baceaaf35890b575a" category="summary">Pour en savoir plus sur les informations données dans ce livre blanc, consultez ces documents et/ou sites web.</block>
  <block id="092bf78f9c97ba171b8232ddff585392" category="doc">Informations supplémentaires</block>
  <block id="7d5b957cd473f6eaf5ad335a9c63c4ff" category="paragraph">Pour en savoir plus sur les informations données dans ce livre blanc, consultez ces documents et/ou sites web :</block>
  <block id="ccc4b678df8ad6453b7f71661f118ae1" category="inline-link"><block ref="ccc4b678df8ad6453b7f71661f118ae1" category="inline-link-rx"></block></block>
  <block id="b17e2a7e5f42c90b40de5971850339ae" category="list-text">Tr-4597 : VMware vSphere pour ONTAP
<block ref="5938ff9651f6c5e53544676ba8504afc" category="inline-link-rx"></block></block>
  <block id="7d9ee37e3155d571b441d63bcbc54709" category="inline-link"><block ref="7d9ee37e3155d571b441d63bcbc54709" category="inline-link-rx"></block></block>
  <block id="52c629361849219069b336f56f1556d0" category="list-text">Tr-4400 : volumes virtuels VMware vSphere avec ONTAP
<block ref="b7bf139d6051615d8c8e01b6b63dacc3" category="inline-link-rx"></block></block>
  <block id="18df8e05a5400abd9d0980b1c5bc9ef3" category="list-text">Tr-4015 Guide des meilleures pratiques en matière de configuration de SnapMirror pour ONTAP 9
<block ref="e361bd9d6f7b20da762bc23fcb3d09c2" category="inline-link-rx"></block></block>
  <block id="cbe2f6eb2a73f4a2c871a06264f10dc7" category="inline-link"><block ref="cbe2f6eb2a73f4a2c871a06264f10dc7" category="inline-link-rx"></block></block>
  <block id="249b98331fa56dc46bf6ba51dc6c39d5" category="list-text">Créateur d'utilisateurs RBAC pour ONTAP
<block ref="6b15b91279acfce2bbee060bdb17db43" category="inline-link-rx"></block></block>
  <block id="c88037eb28ae3cceb0e32c2cd3c322d7" category="inline-link"><block ref="c88037eb28ae3cceb0e32c2cd3c322d7" category="inline-link-rx"></block></block>
  <block id="1a57e0f74e725c1a5e2d53b4d4b4460d" category="list-text">Outils ONTAP pour les ressources VMware vSphere
<block ref="80c496cd9ab75e5683007d8f66ca6fbf" category="inline-link-rx"></block></block>
  <block id="9aa6e8f8fac5c131e5924ee033660d29" category="inline-link"><block ref="9aa6e8f8fac5c131e5924ee033660d29" category="inline-link-rx"></block></block>
  <block id="91a48e1708df22b7464bced79c745ad2" category="list-text">Documentation VMware site Recovery Manager
<block ref="92ad802ced4838839b492be6d0bf427d" category="inline-link-rx"></block></block>
  <block id="c9dd6bad4c7d561872f2e2d498a990bf" category="inline-link">Matrice d'interopérabilité (IMT)</block>
  <block id="97cd1357ea4a16b44bd9e360127a1a9d" category="paragraph">Reportez-vous à la<block ref="99cfde592e1d7fa7832b186d73ee4002" category="inline-link-rx"></block> Le site de support NetApp vous assure que les versions de produits et de fonctionnalités mentionnées dans le présent document sont prises en charge par votre environnement. NetApp IMT définit les composants et versions de produits qu'il est possible d'utiliser pour créer des configurations prises en charge par NetApp. Les résultats dépendent des installations de chaque client et de leur conformité aux spécifications publiées.</block>
  <block id="1f82b18dcba5f32a085bc502cdd0c6b7" category="summary">Avec ONTAP, le concept de machine virtuelle de stockage (SVM) offre une segmentation stricte dans les environnements mutualisés sécurisés.</block>
  <block id="7520e12a140ccf3de279fe2fd48889e4" category="doc">Bonnes pratiques de déploiement</block>
  <block id="1b4574c516231b685bb37b013b789b06" category="section-title">Disposition des SVM et segmentation pour la colocation sécurisée</block>
  <block id="446e04546ec0567eeeeef8e07368ab40" category="paragraph">Avec ONTAP, le concept de machine virtuelle de stockage (SVM) offre une segmentation stricte dans les environnements mutualisés sécurisés. Les utilisateurs des SVM situés sur un SVM ne peuvent ni accéder aux ressources d'un autre ni les gérer. De cette façon, vous pouvez exploiter la technologie ONTAP en créant des SVM distincts pour différentes unités commerciales qui gèrent leurs propres flux de travail SRM sur le même cluster, pour une efficacité globale supérieure du stockage.</block>
  <block id="f98c1d223f34b2fdaf90eab1a3bc6a25" category="paragraph">Envisagez de gérer ONTAP avec des comptes SVM-scoped et des LIF de management SVM pour non seulement améliorer les contrôles de sécurité, mais aussi améliorer les performances. Les performances sont supérieures par nature lorsque des connexions SVM-scoped sont utilisées, car SRA n'est pas nécessaire pour traiter toutes les ressources d'un cluster entier, y compris les ressources physiques. Il ne doit plutôt comprendre que les ressources logiques qui sont extraites vers la SVM particulière.</block>
  <block id="849d4d5e8a5d5b2747d8375d2ec03b29" category="paragraph">Si vous utilisez uniquement des protocoles NAS (pas d'accès SAN), vous pouvez même exploiter le nouveau mode optimisé NAS en définissant le paramètre suivant (notez que le nom est tel, car SRA et VASA utilisent les mêmes services back-end de l'appliance) :</block>
  <block id="05f551a655f40911851a53ba0c721997" category="list-text">Connectez-vous au panneau de commande à<block ref="501a3478972ee5e3d6f109bdc0514bdc" prefix=" " category="inline-code"></block> Et cliquez sur interface de ligne de commande Web.</block>
  <block id="b0cc185c73ca964d1429a601551c68f5" category="list-text">Lancer la commande<block ref="4f35e9b3adeccfaf0287d002b134221c" prefix=" " category="inline-code"></block>.</block>
  <block id="5f7e35f90689bef91afe9f01257c61ac" category="list-text">Lancer la commande<block ref="aa610e3ab4e5162f432950793f30a387" prefix=" " category="inline-code"></block>.</block>
  <block id="ba2a1e4d95dc56709260e82cca20a789" category="list-text">Lancer la commande<block ref="6d83e9fce5e947159c3c34b9f499e80e" prefix=" " category="inline-code"></block>.</block>
  <block id="2d14ca751c8ce5a724606e4f75f02c50" category="section-title">Déployez des outils ONTAP et des considérations pour vvols</block>
  <block id="fa3a193f1892cf0f45f4a95a35aa3c4b" category="paragraph">Si vous prévoyez d'utiliser SRM avec vvols, vous devez gérer le stockage à l'aide d'identifiants cluster-scoped et d'une LIF de cluster management. En effet, le fournisseur VASA doit comprendre l'architecture physique sous-jacente pour satisfaire aux exigences des règles de stockage des VM. Par exemple, si vous disposez d'une règle exigeant un stockage 100 % Flash, le fournisseur VASA doit pouvoir identifier les systèmes 100 % Flash.</block>
  <block id="31d279d1cc3bc5a4281567ba697f678d" category="paragraph">Une autre meilleure pratique de déploiement est de ne jamais stocker votre appliance ONTAP Tools sur un datastore vvols qu'il gère. Cela peut entraîner une situation dans laquelle vous ne pouvez pas mettre le fournisseur VASA sous tension, car vous ne pouvez pas créer le vVol swap pour l'appliance, car l'appliance est hors ligne.</block>
  <block id="97399fb37deca0d463aa5c7dc8d064a6" category="section-title">Meilleures pratiques pour la gestion des systèmes ONTAP 9</block>
  <block id="18f8b81b7fb7ea92f333e127583df17c" category="paragraph">Comme mentionné précédemment, il est possible de gérer des clusters ONTAP avec des identifiants cluster ou SVM évalués et des LIF de gestion. Pour des performances optimales, il peut être intéressant d'utiliser des identifiants SVM- scoped lorsque vous n'utilisez pas les vVols. Cependant, ce faisant, vous devriez être conscient de certaines exigences, et que vous perdez certaines fonctionnalités.</block>
  <block id="fec05e53ca7d96aaf3e4c1a1b2502bea" category="list-text">Le compte SVM vsadmin par défaut ne dispose pas du niveau d'accès requis pour effectuer les tâches des outils ONTAP Il faut donc créer un nouveau compte SVM.</block>
  <block id="d508cbe8ee8a3aa0f975b96403baf33c" category="list-text">Si vous utilisez ONTAP 9.8 ou une version ultérieure, NetApp recommande de créer un compte utilisateur RBAC avec le moins de privilèges à l'aide du menu utilisateurs de ONTAP System Manager ainsi que le fichier JSON disponible sur votre appliance ONTAP Tools à l'adresse<block ref="137f8d4bb89dcc34c3bfe48f2a61c95e" prefix=" " category="inline-code"></block>. Utilisez votre mot de passe d'administrateur pour télécharger le fichier JSON. Il peut être utilisé pour les comptes évalués au niveau du SVM ou du cluster.</block>
  <block id="a7a83b5e4f375c0585588b9c7ff92219" category="inline-link">Outils du site de support NetApp</block>
  <block id="fdfe9ba9104df6a32fff0f859291ea3c" category="paragraph">Si vous utilisez ONTAP 9.6 ou une version antérieure, vous devez utiliser l'outil Créateur d'utilisateurs RBAC (RUC) disponible dans le<block ref="bdbf96c18cf8ac76d01fba7057b81b87" category="inline-link-rx"></block>.</block>
  <block id="ea7a3d08d55dc3e8ecf89d2a5d5e302d" category="list-text">Le plug-in de l'interface utilisateur vCenter, VASA Provider et SRA Server étant tous des services entièrement intégrés, vous devez ajouter du stockage à l'adaptateur SRA dans SRM de la même manière que vous ajoutez du stockage dans l'interface utilisateur vCenter pour les outils ONTAP. Sinon, le serveur SRA pourrait ne pas reconnaître les requêtes envoyées depuis SRM via l'adaptateur SRA.</block>
  <block id="b473de4177eeaa79a66448798a446db3" category="list-text">La vérification du chemin NFS n'est pas effectuée avec les identifiants évalués par SVM. Car l'emplacement physique est logiquement extrait du SVM. Cela ne pose pas de problème, car les systèmes ONTAP modernes ne subissent plus de déclin perceptible des performances lors de l'utilisation de chemins indirects.</block>
  <block id="6e62430b92a7c5a0b8512436b163a10d" category="list-text">Il est possible que les économies d'espace réalisées grâce à l'efficacité du stockage ne soient pas signalées.</block>
  <block id="93d86aa51e0909549d1b1210f887aef3" category="list-text">Lorsqu'ils sont pris en charge, les miroirs de partage de charge ne peuvent pas être mis à jour.</block>
  <block id="647d380b52e259fe7ed2e2582bc54b27" category="list-text">Il est possible que la connexion EMS ne soit pas effectuée sur des systèmes ONTAP gérés avec des identifiants évalués par SVM.</block>
  <block id="c5cd657df037c277c37216b73efb0b08" category="summary">Si possible, utilisez toujours les outils ONTAP pour provisionner les datastores et les volumes. Cela vérifie que les volumes, les chemins de jonction, les LUN, les igroups, les règles d'exportation, et d'autres paramètres sont configurés de manière compatible.</block>
  <block id="d3b26e9021e83573a3d2a9050400a33a" category="doc">Meilleures pratiques opérationnelles</block>
  <block id="4d15db58f26b374b36c283df6b5a5fc1" category="paragraph">SRM prend en charge iSCSI, Fibre Channel et NFS version 3 avec ONTAP 9 lors de l'utilisation d'une réplication basée sur les baies via SRA. SRM ne prend pas en charge la réplication basée sur la baie pour NFS version 4.1 avec des datastores traditionnels ou vvols.</block>
  <block id="61f54ceeb0338787a2ee2d801cbc62cd" category="paragraph">Pour confirmer la connectivité, vérifiez toujours que vous pouvez monter et démonter un nouveau datastore test sur le site de reprise sur incident à partir du cluster ONTAP de destination. Testez chaque protocole que vous envisagez d'utiliser pour la connectivité du datastore. L'une des meilleures pratiques est d'utiliser les outils ONTAP pour créer votre datastore de test, car elle effectue toutes les automatisations du datastore telles que dirigées par SRM.</block>
  <block id="0ac3e8abbf45a28af68d22b0f59a973e" category="paragraph">Les protocoles SAN doivent être homogènes pour chaque site. Vous pouvez combiner les protocoles NFS et SAN, mais les protocoles SAN ne doivent pas être combinés dans un même site. Par exemple, vous pouvez utiliser FCP sur le site A et iSCSI sur le site B. Vous ne devez pas utiliser FCP et iSCSI sur le site A. La raison en est que SRA ne crée pas de groupes initiateurs mixtes sur le site de reprise et SRM ne filtre pas la liste des initiateurs donnée à SRA.</block>
  <block id="62a631034cae40cfcee909c69c12c5b3" category="paragraph">NetApp ONTAP 9 peut être configuré pour supprimer automatiquement les snapshots afin de préserver la disponibilité en cas de manque d'espace lorsque la taille automatique ne peut pas fournir une capacité d'urgence suffisante. Le paramètre par défaut de cette fonctionnalité ne supprime pas automatiquement les snapshots créés par SnapMirror. Si des snapshots SnapMirror sont supprimés, NetApp SRA ne peut pas inverser et resynchroniser la réplication pour le volume affecté. Pour empêcher ONTAP de supprimer des snapshots SnapMirror, configurez la fonctionnalité de suppression automatique de snapshots.</block>
  <block id="63b6c8d5e17ef7185a34c4ddd86f9d19" category="inline-link-macro">configuration des volumes pour l'extension ou la réduction automatique</block>
  <block id="a1874a28c8389c5c687d10167e80dc1f" category="paragraph">La taille automatique du volume doit être définie sur<block ref="4d200fce73a8e1cc965cfc2c43343824" prefix=" " category="inline-code"></block> Pour les volumes contenant les datastores SAN et<block ref="d89f4f8b1d7c18847b88b46142f61535" prefix=" " category="inline-code"></block> Pour les datastores NFS. En savoir plus sur <block ref="ebd664f1c7cf128a3758282775d35e72" category="inline-link-macro-rx"></block>.</block>
  <block id="e401bd7c98141814eaf5528ddb318da6" category="section-title">Gestion basée sur des règles de stockage (SPBM) et vVols</block>
  <block id="b180e7f35111dca8acd6c56cdbcabb3e" category="paragraph"><block ref="b180e7f35111dca8acd6c56cdbcabb3e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="be41c3baf700984021c43e2e6b661b0a" category="paragraph">La capture d'écran suivante fournit un exemple de planifications SnapMirror affichées dans l'assistant de création de règles de stockage de machine virtuelle.</block>
  <block id="43c130b36e9e2b3d61409aa974f89fc7" category="paragraph"><block ref="43c130b36e9e2b3d61409aa974f89fc7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f6292d9eb6ea467a3c3560a65b7f63b5" category="paragraph">Le fournisseur ONTAP VASA prend en charge le basculement vers des systèmes de stockage différents. Par exemple, le système peut basculer d'un système ONTAP Select à un emplacement de périphérie vers un système AFF dans le data Center central. Indépendamment de la similarité de stockage, vous devez toujours configurer les mappages des règles de stockage et les mappages inversés des règles de stockage de machines virtuelles grâce à la réplication, afin de garantir que les services fournis sur le site de reprise répondent aux attentes et aux exigences de votre entreprise. La capture d'écran suivante met en évidence un exemple de mappage de règles.</block>
  <block id="783a951245ce43eb84161804072a38c6" category="paragraph"><block ref="783a951245ce43eb84161804072a38c6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1eb90dc8f7adfd00c74af3b815e2ac15" category="section-title">Créez des volumes répliqués pour les datastores vvols</block>
  <block id="dd5e006520a09e3975e52f6fb8991fd2" category="paragraph"><block ref="dd5e006520a09e3975e52f6fb8991fd2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="550d51e15336d4a33bcbb0f26a6810f7" category="paragraph">Il faut faire preuve de prudence lorsqu'il s'agit de vVvols et SRM. Ne mélangez jamais des machines virtuelles protégées et non protégées dans le même datastore vVvols. Cela s'explique par le fait que, lorsque vous utilisez SRM pour basculer vers votre site de reprise sur incident, seules les machines virtuelles qui font partie du groupe de protection sont mises en ligne sur le site de reprise sur incident. Par conséquent, lorsque vous reprotégez (repassez de SnapMirror de la reprise sur incident à la production), vous pouvez remplacer les machines virtuelles qui n'étaient pas basculées et qui pouvaient contenir des données précieuses.</block>
  <block id="6d717f70d89096b731dfc63d7a1379e1" category="section-title">À propos des paires de baies</block>
  <block id="2219228418c053eb593ce0a1f318da47" category="paragraph">Lors de la configuration des paires de baies dans SRM, vous devez toujours les ajouter à SRM de la même manière que vous les avez ajoutés à ONTAP Tools : autrement dit, ils doivent utiliser le même nom d'utilisateur, mot de passe et LIF de gestion. Cette exigence garantit que SRA communique correctement avec la baie. La copie d'écran suivante montre comment un cluster peut s'afficher dans les outils ONTAP et comment il peut être ajouté à un gestionnaire de baies.</block>
  <block id="7ec48584a43ed8a9b1dda55398d97cf4" category="paragraph"><block ref="7ec48584a43ed8a9b1dda55398d97cf4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3b34135c8c4d2b14ceb7ebf595f00193" category="section-title">À propos des groupes de réplication</block>
  <block id="6be59afd3c8bb91501f55a7e77ebe794" category="paragraph">Les groupes de réplication contiennent des ensembles logiques de machines virtuelles qui sont restaurées ensemble. Le fournisseur VASA, un outil de ONTAP, crée automatiquement des groupes de réplication pour vous. Étant donné que la réplication SnapMirror de ONTAP se produit au niveau du volume, toutes les machines virtuelles d'un volume se trouvent dans le même groupe de réplication.</block>
  <block id="c727c1020d3128dd7495a6e3e6f23736" category="paragraph">Dernier point à prendre en compte pour les groupes de réplication : chacun d'entre eux est, par nature, un groupe de cohérence logique (à ne pas confondre avec les groupes de cohérence SRM). En effet, toutes les machines virtuelles du volume sont transférées ensemble à l'aide du même snapshot. Ainsi, si vous disposez de machines virtuelles qui doivent être cohérentes les unes avec les autres, envisagez de les stocker dans le même FlexVol.</block>
  <block id="9f8a350a2113ea4be6b4e5e5112514a3" category="section-title">À propos des groupes de protection</block>
  <block id="df77671ab2743af7f1d1457c200eb12c" category="paragraph">Les groupes de protection définissent les VM et les datastores dans des groupes restaurés à partir du site protégé. Le site protégé est là où existent les VM configurées dans un groupe de protection pendant les opérations stables. Il est important de noter que même si SRM peut afficher plusieurs gestionnaires de baies pour un groupe de protection, un groupe de protection ne peut pas s'étendre sur plusieurs gestionnaires de baies. Pour cette raison, vous ne devez pas couvrir les fichiers de machine virtuelle sur plusieurs datastores sur différents SVM.</block>
  <block id="b148467d645c3613c1c7a2607764c515" category="section-title">À propos des plans de reprise</block>
  <block id="fd28cd9834ad3aa213c4fec2881064b5" category="paragraph">Les plans de reprise définissent les groupes de protection qui sont restaurés au cours du même processus. Plusieurs groupes de protection peuvent être configurés dans le même plan de reprise. Par ailleurs, pour activer davantage d'options pour l'exécution des plans de reprise, un seul groupe de protection peut être inclus dans plusieurs plans de restauration.</block>
  <block id="77aa84394124509e5e4006dcfd18789f" category="paragraph">Les plans de restauration permettent aux administrateurs SRM de définir les flux de travail de restauration en affectant des VM à un groupe de priorité compris entre 1 (le plus élevé) et 5 (le plus faible), dont la valeur par défaut est 3 (moyen). Au sein d'un groupe de priorités, les VM peuvent être configurés pour les dépendances.</block>
  <block id="030d749269f8866de516a551b0286001" category="paragraph">NetApp recommande fortement de travailler avec vos équipes en charge des applications pour comprendre l'ordre des opérations requises dans un scénario de basculement et pour élaborer vos plans de reprise en conséquence.</block>
  <block id="cebb1167d3e78885137c837f0abf8026" category="section-title">Tester le basculement</block>
  <block id="6ae8acfc86f5df3426d525fb95767506" category="paragraph">NetApp recommande également de confirmer occasionnellement les fonctionnalités des applications chez l'invité, en particulier après la reconfiguration du stockage des machines virtuelles.</block>
  <block id="bd47371bcd8b3d08d6b4b15481b08d93" category="paragraph">Lors de l'exécution d'une opération de restauration test, un réseau de bulles de test privé est créé sur l'hôte ESXi pour les machines virtuelles. Cependant, ce réseau n'est pas automatiquement connecté à aucune carte réseau physique et ne fournit donc pas de connectivité entre les hôtes ESXi. Pour permettre la communication entre les machines virtuelles s'exécutant sur différents hôtes ESXi lors du test de reprise après incident, un réseau privé physique est créé entre les hôtes ESXi du site de reprise après incident. Pour vérifier que le réseau de test est privé, le réseau de bulles de test peut être séparé physiquement ou à l'aide de VLAN ou de balisage VLAN. Ce réseau doit être isolé du réseau de production car les machines virtuelles sont restaurées. En effet, ils ne peuvent pas être placés sur le réseau de production avec des adresses IP qui pourraient entrer en conflit avec les systèmes de production réels. Lors de la création d'un plan de reprise d'activité dans SRM, le réseau test créé peut être sélectionné comme réseau privé afin de connecter les VM à pendant le test.</block>
  <block id="2be58fc410ddf2ba9c350135a617944a" category="paragraph">Une fois le test validé et n'est plus nécessaire, effectuez une opération de nettoyage. Le nettoyage en cours d'exécution renvoie l'état initial des machines virtuelles protégées à leur état initial et réinitialise le plan de restauration en mode prêt.</block>
  <block id="6f07b53963ee80903f0f13654de2cc3a" category="section-title">Considérations relatives au basculement</block>
  <block id="9d33d94019b4a595a1ea232926a4da1b" category="paragraph">Il y a plusieurs autres considérations lorsqu'il s'agit de basculer sur un site en plus de l'ordre des opérations mentionné dans ce guide.</block>
  <block id="74abdd5cb502cd65bcf1d7ca484ab0c2" category="paragraph">Vous devrez peut-être résoudre ce problème en tenant compte des différences de réseau entre les sites. Certains environnements peuvent utiliser les mêmes adresses IP réseau à la fois sur le site primaire et sur le site de reprise après incident. Cette fonctionnalité est appelée VLAN (Virtual LAN) étendu ou configuration réseau étendu. Dans d'autres environnements, il est parfois nécessaire d'utiliser différentes adresses IP réseau (par exemple, sur différents VLAN) sur le site primaire par rapport au site de reprise.</block>
  <block id="9b8890fe5b1ab29543118b12a7bd0a07" category="inline-link-macro">Options NSX-T avec SRM</block>
  <block id="25154023650451d6cc971fc54bff8898" category="paragraph">VMware offre plusieurs moyens de résoudre ce problème. Pour la première, des technologies de virtualisation de réseau comme VMware NSX-T Data Center extraient la pile réseau des couches 2 à 7 de l'environnement d'exploitation, afin d'offrir des solutions plus portables. En savoir plus sur <block ref="3e6a2bd8e1acf69d423b7944c6543271" category="inline-link-macro-rx"></block>.</block>
  <block id="b56336aa967325217297d8725b64eb0b" category="inline-link-macro">Documentation de VMware</block>
  <block id="d32598436410006707b2ad1d79395f02" category="paragraph">Pour configurer SRM de façon à appliquer différents paramètres réseau à plusieurs machines virtuelles sans devoir modifier les propriétés de chacune d'entre elles dans le plan de reprise, VMware fournit un outil appelé dr-ip-customizer. Pour savoir comment utiliser cet utilitaire, reportez-vous à la section <block ref="837c7339284b78d4fd5550c5d0fb1a68" category="inline-link-macro-rx"></block>.</block>
  <block id="3c8c527afa8ce5009c8f707f7fd4fabf" category="section-title">Reprotéger</block>
  <block id="3b496038cb575fc404f8b0783e570f7a" category="paragraph">Après une restauration, le site de reprise devient le nouveau site de production. Comme l'opération de reprise a rompue la réplication SnapMirror, le nouveau site de production n'est pas protégé contre un futur incident. Il est recommandé de protéger le nouveau site de production sur un autre site immédiatement après une restauration. Si le site de production d'origine est opérationnel, l'administrateur VMware peut utiliser le site de production d'origine comme nouveau site de reprise pour protéger le nouveau site de production, ce qui inversera efficacement la direction de la protection. La reprotection est disponible uniquement en cas de défaillance majeure. Par conséquent, les serveurs vCenter d'origine, les serveurs ESXi, les serveurs SRM et les bases de données correspondantes doivent être récupérables. S'ils ne sont pas disponibles, un nouveau groupe de protection et un nouveau plan de récupération doivent être créés.</block>
  <block id="2bf236f8aceaaff2b305848df524c42e" category="paragraph">Une opération de retour arrière est fondamentalement un basculement dans une direction différente de celle précédente. Il est recommandé de vérifier que le site d'origine fonctionne à un niveau de fonctionnalité acceptable avant de tenter un retour arrière ou, en d'autres termes, un basculement vers le site d'origine. Si le site d'origine est toujours compromis, vous devez reporter la restauration jusqu'à ce que la défaillance soit suffisamment remédiée.</block>
  <block id="cb03753531bad31391d7156433b98ae6" category="paragraph">Une autre meilleure pratique de restauration consiste à toujours effectuer un basculement de test après avoir terminé la reprotection et avant de procéder à la restauration finale. Cela vérifie que les systèmes en place sur le site initial peuvent mener à bien l'opération.</block>
  <block id="900a3b65ea54b6dcff72ed0d6ac66fdf" category="section-title">Reprotéger le site d'origine</block>
  <block id="12d059a2c7519f2e3497b30a71121503" category="paragraph">La reprotection après le retour arrière reprend l'état où il était au début, avec la réplication SnapMirror à nouveau en cours d'exécution depuis le site de production vers le site de reprise.</block>
  <block id="7ab9df3e4e38ca227c1b48b0f6740675" category="section-title">Activités de développement sécurisées</block>
  <block id="1a79eb278bc02ebdbd2ab32925e316f6" category="paragraph">L'ingénierie logicielle associée aux outils NetApp ONTAP pour VMware vSphere exploite les activités de développement sécurisées suivantes :</block>
  <block id="39e5fc9eb192f011ab14dae6c2974c4e" category="list-text">*Modélisation des menaces.* le but de la modélisation des menaces est de découvrir des défauts de sécurité dans une fonction, un composant ou un produit au début du cycle de vie du développement logiciel. Un modèle de menace est une représentation structurée de toutes les informations qui affectent la sécurité d'une application. En substance, c'est une vision de l'application et de son environnement par le biais du principe de sécurité.</block>
  <block id="9f16ab3a50bca32d19c4729319035c8d" category="list-text">*Dynamic application Security Testing (DAST).* cette technologie est conçue pour détecter les conditions vulnérables sur les applications dans leur état d'exécution. DAST teste les interfaces HTTP et HTML exposées des applications Web-enable.</block>
  <block id="267bed0525e4dab477e4c24ca5a1794e" category="list-text">*Devise de code tierce.* dans le cadre du développement de logiciels avec des logiciels open-source (OSS), vous devez corriger les vulnérabilités de sécurité qui pourraient être associées à tout OSS intégré à votre produit. Il s'agit d'un effort continu car une nouvelle version OSS peut avoir une nouvelle vulnérabilité découverte signalée à tout moment.</block>
  <block id="db7bc87c89c1ee76d313865a32fc0e06" category="list-text">*Analyse des vulnérabilités* l'analyse des vulnérabilités a pour but de détecter les vulnérabilités de sécurité courantes et connues dans les produits NetApp avant leur publication auprès des clients.</block>
  <block id="1a4c104571630526efc77b84e82380fe" category="list-text">* Tests de pénétration.* le test de pénétration est le processus d'évaluation d'un système, d'une application Web ou d'un réseau pour trouver des vulnérabilités de sécurité qui pourraient être exploitées par un attaquant. Les tests d'intrusion chez NetApp sont réalisés par un groupe d'entreprises tierces de confiance et approuvées. Leur domaine de test comprend le lancement d'attaques contre une application ou un logiciel similaire à des intrus hostiles ou des pirates informatiques à l'aide de méthodes ou d'outils d'exploitation sophistiqués.</block>
  <block id="7e98fc3ea1ec077cfd1727a58e9c9020" category="section-title">Fonctionnalités de sécurité du produit</block>
  <block id="85d61648687f15050da0b86741b90358" category="paragraph">Les outils NetApp ONTAP pour VMware vSphere comprennent les fonctions de sécurité suivantes dans chaque version.</block>
  <block id="dff88c2ef0b49b09246ffd6f9ec55195" category="list-text">*Bannière de connexion.* SSH est désactivé par défaut et n'autorise que les connexions à une seule fois si elles sont activées à partir de la console VM. La bannière de connexion suivante s'affiche une fois que l'utilisateur a saisi un nom d'utilisateur dans l'invite de connexion :</block>
  <block id="399875025e8e96cc13102a4dd72f2434" category="paragraph">*AVERTISSEMENT:* l'accès non autorisé à ce système est interdit et sera poursuivi par la loi. En accédant à ce système, vous convenez que vos actions peuvent être surveillées si vous soupçonnez une utilisation non autorisée.</block>
  <block id="2d8330ed99c80a842ffbd1362e038e5e" category="paragraph">Une fois la connexion établie par l'utilisateur via le canal SSH, le texte suivant s'affiche :</block>
  <block id="677528ad13d460c058ac50e8a62092cf" category="list-text">*Contrôle d'accès basé sur les rôles (RBAC).* deux types de contrôles RBAC sont associés aux outils ONTAP :</block>
  <block id="ac38773d017495a97d5b88f242578cb8" category="list-text">Privilèges de serveur vCenter natif</block>
  <block id="c2e2fce3a995f59900d7afbbe58683f5" category="inline-link">ce lien</block>
  <block id="31cedac82fef311cb790a12f96897223" category="list-text">Privilèges spécifiques au plug-in vCenter. Pour plus de détails, voir<block ref="e5f6920797dbff91ef59367270a82669" category="inline-link-rx"></block>.</block>
  <block id="5d32469f8a65b884a8f70abf95fe485a" category="list-text">*Canaux de communication cryptés.* toutes les communications externes se produisent sur HTTPS en utilisant la version 1.2 de TLS.</block>
  <block id="600d4f98483fae8e58054f976d7e0c0e" category="list-text">*Exposition minimale au port.* seuls les ports nécessaires sont ouverts sur le pare-feu.</block>
  <block id="0406f8902379502d1eba01f043c232b7" category="paragraph">Le tableau suivant décrit les détails du port ouvert.</block>
  <block id="69fc9fe9cbb7709e97a433352aecf77d" category="cell">N° de port TCP v4/v6</block>
  <block id="02674a4ef33e11c879283629996c8ff8" category="cell">Direction</block>
  <block id="86408593c34af77fdd90df932f8b5261" category="cell">Fonction</block>
  <block id="0c95054981de037de06e544a52eb3613" category="cell">8143</block>
  <block id="a8e6fe5b9e68f30a146cefebaa7edcc3" category="cell">entrant</block>
  <block id="d16c4afdc5f340936b747baf91efc843" category="cell">Connexions HTTPS pour l'API REST</block>
  <block id="5bd529d5b07b647a8863cf71e98d651a" category="cell">8043</block>
  <block id="1f4deeb2f64336d4ff65ea3d2b4ffe2f" category="cell">Connexions HTTPS</block>
  <block id="cb4b69eb9bd10da82c15dca2f86a1385" category="cell">9060</block>
  <block id="5852f8019b572f4cdef5bab783fa799f" category="cell">Connexions HTTPS
Utilisé pour les connexions SOAP sur https
Ce port doit être ouvert pour permettre à un client de se connecter au serveur d'API des outils ONTAP.</block>
  <block id="b6d767d2f8ed5d21a44b0e5886680cb9" category="cell">22</block>
  <block id="f4e339608b243f9b57b78ffaf061b498" category="cell">SSH (désactivé par défaut)</block>
  <block id="d82d678e9583c1f5f283ec56fbf1abb7" category="cell">9080</block>
  <block id="ef34781e03f49b5db5dd8fa267c4c41b" category="cell">Connexions HTTPS - VP et SRA - connexions internes à partir du bouclage uniquement</block>
  <block id="a44ba9086b2b83ccf2baf7c678723449" category="cell">9083</block>
  <block id="fe01ac95967cd8cb5f5b5669b685277a" category="cell">Connexions HTTPS - VP et SRA
Utilisé pour les connexions SOAP sur https</block>
  <block id="abea47ba24142ed16b7d8fbf2c740e0d" category="cell">1162</block>
  <block id="4a0724da5c6f4e4817663ae822550800" category="cell">Paquets de déroutement SNMP VP</block>
  <block id="5cce8dede893813f879b873962fb669f" category="cell">1527</block>
  <block id="91c15b8eb529bf2100c10383d1010a1e" category="cell">diffusion interne uniquement</block>
  <block id="60135f95267c6e0711bf5a2858dfff2f" category="cell">Port de base de données Derby, uniquement entre cet ordinateur et lui-même, connexions externes non acceptées -- connexions internes uniquement</block>
  <block id="13f3cf8c531952d72e5847c4183e6910" category="cell">443</block>
  <block id="1ef2b5426b0824e93e33753fa87ddbf5" category="cell">bidirectionnel</block>
  <block id="e4b8a8d8761aab7733e317b585d5d606" category="cell">Utilisé pour les connexions aux clusters ONTAP</block>
  <block id="bf6184406d1e18fffc86ecf770fbb391" category="inline-link">article de la base de connaissances</block>
  <block id="fedac49792829de4ff38fcf7a3846faa" category="list-text">*Prise en charge des certificats signés de l'autorité de certification (CA).* les outils ONTAP pour VMware vSphere prennent en charge les certificats signés de l'autorité de certification. Voir ceci<block ref="0903a062b2072644a9b744a7fece4216" category="inline-link-rx"></block> pour en savoir plus.</block>
  <block id="9fca19988370da2a459b24505e9d23d5" category="list-text">*Audit Logging.* les offres de support peuvent être téléchargées et sont extrêmement détaillées. Les outils ONTAP consigne toutes les activités de connexion et de déconnexion de l'utilisateur dans un fichier journal distinct. Les appels d'API VASA sont connectés à un journal d'audit VASA dédié (local cxf.log).</block>
  <block id="7d60a2806aedd934b75cce55d6693689" category="list-text">*Stratégies de mot de passe.* les stratégies de mot de passe suivantes sont respectées :</block>
  <block id="f82f7513742f08b9d2784923213bdc75" category="list-text">Les mots de passe ne sont pas enregistrés dans des fichiers journaux.</block>
  <block id="83040c348e071499488a8128db207545" category="list-text">Les mots de passe ne sont pas communiqués en texte brut.</block>
  <block id="bc319862df3312f423a50fece7730db9" category="list-text">Les mots de passe sont configurés lors du processus d'installation lui-même.</block>
  <block id="853c2ea85b86882d0ea73b606a9800a4" category="list-text">L'historique des mots de passe est un paramètre configurable.</block>
  <block id="b3d3877bc96752ae50a409c72597d47a" category="list-text">L'âge minimum du mot de passe est défini sur 24 heures.</block>
  <block id="fb0bdec50022a37424a405b53da7c9c8" category="list-text">La saisie automatique des champs de mot de passe est désactivée.</block>
  <block id="3a04f054be8ad983ea82fd5079519810" category="list-text">Les outils ONTAP crypte toutes les informations d'identification stockées à l'aide de la fonction de hachage SHA256.</block>
  <block id="46e61d6e7c848d43ddcede8efd36c3d8" category="doc">Plug-in SnapCenter VMware vSphere</block>
  <block id="ae9e79ac4b60eba67cf1c7508417b42c" category="paragraph">Le plug-in NetApp SnapCenter pour l'ingénierie logicielle VMware vSphere exploite les activités de développement sécurisées suivantes :</block>
  <block id="b25a1098aff7d0c5ee590f1e1a114bb9" category="list-text">*Test dynamique de sécurité des applications (DAST).* technologies conçues pour détecter les conditions vulnérables des applications dans leur état d'exécution. DAST teste les interfaces HTTP et HTML exposées des applications Web-enable.</block>
  <block id="6cc1fee6b4fc48755d78e93170bbed93" category="list-text">*Devise de code tierce.* dans le cadre du développement de logiciels et de l'utilisation de logiciels open-source (OSS), il est important de traiter les vulnérabilités de sécurité qui pourraient être associées à OSS qui a été intégré à votre produit. Il s'agit d'un effort continu car la version du composant OSS peut avoir une vulnérabilité nouvellement découverte signalée à tout moment.</block>
  <block id="87bd0fb9b4198f33535e0e1888a809f5" category="list-text">* Tests de pénétration.* le test de pénétration est le processus d'évaluation d'un système, d'une application Web ou d'un réseau pour trouver des vulnérabilités de sécurité qui pourraient être exploitées par un attaquant. Les tests d'intrusion chez NetApp sont réalisés par un groupe d'entreprises tierces de confiance et approuvées. Leur domaine de test comprend le lancement d'attaques contre une application ou un logiciel comme des intrus hostiles ou des pirates informatiques à l'aide de méthodes ou d'outils d'exploitation sophistiqués.</block>
  <block id="e3a3be4b4b04c5e0b6a5f1b5ea388380" category="list-text">*Activité réponse aux incidents de sécurité des produits.* les vulnérabilités de sécurité sont découvertes à la fois en interne et en externe pour l'entreprise et peuvent poser un risque grave à la réputation de NetApps'ils ne sont pas traités en temps opportun. Pour faciliter ce processus, l'équipe d'intervention en cas d'incident de sécurité des produits (PSIRT) signale et effectue le suivi des vulnérabilités.</block>
  <block id="e91db3b3278f7bd95cc704d74c5c9597" category="paragraph">Le plug-in NetApp SnapCenter pour VMware vSphere inclut les fonctionnalités de sécurité suivantes dans chaque version :</block>
  <block id="4abd7d1d5d223683d3346671efb7e89c" category="list-text">*Accès limité au shell.* SSH est désactivé par défaut, et les connexions à une seule fois ne sont autorisées que si elles sont activées à partir de la console VM.</block>
  <block id="8c264fa5ca2c588d960d98bd30cbc897" category="list-text">*Avertissement d'accès dans la bannière de connexion.* la bannière de connexion suivante s'affiche après que l'utilisateur ait entré un nom d'utilisateur dans l'invite de connexion :</block>
  <block id="0d6633ada3a9803e206b2359d859e892" category="paragraph">Une fois que l'utilisateur a terminé sa connexion via le canal SSH, les valeurs de sortie suivantes s'affichent :</block>
  <block id="83e463bb73b12d9ca6e419327073c8a4" category="list-text">*Contrôle d'accès basé sur des rôles (RBAC).* deux types de contrôles RBAC sont associés aux outils NetApp ONTAP :</block>
  <block id="b883bf79639dfce77e395b8458ee69e4" category="list-text">Privilèges de serveur vCenter natif.</block>
  <block id="721796b1cb3468f0daf819180184d460" category="inline-link">Contrôle d'accès basé sur des rôles (RBAC)</block>
  <block id="1d08c46b7567a29be0690a92b9722a58" category="list-text">Privilèges spécifiques au plug-in VMware vCenter. Pour plus d'informations, voir<block ref="f351263ad3706bd0a472039400dece78" category="inline-link-rx"></block>.</block>
  <block id="acab4c655c4a7b4db67fc07e22b86222" category="list-text">*Canaux de communication cryptés.* toutes les communications externes sont effectuées via HTTPS en utilisant TLS.</block>
  <block id="47a37e2d5fc8b7c936ad9b2b7a569a08" category="paragraph">Le tableau suivant fournit les détails du port ouvert.</block>
  <block id="10bd16a816f831080065e807daa36a9a" category="cell">Numéro de port TCP v4/v6</block>
  <block id="edf0320adc8658b25ca26be5351b6c4a" category="cell">8144</block>
  <block id="d4a973e303ec37692cc8923e3148eef7" category="cell">8080</block>
  <block id="2c25c3d66f80eeaa8d6e5a144c6f942e" category="cell">Connexions HTTPS pour interface graphique OVA</block>
  <block id="14b3e670eec63cc0cc456fd904bbfbd9" category="cell">SSH (désactivé par défaut)</block>
  <block id="16fc18d787294ad5171100e33d05d4e2" category="cell">3306</block>
  <block id="4cbf9c234f6b34c242a110cb993252bd" category="cell">MySQL (connexions internes uniquement, connexions externes désactivées par défaut)</block>
  <block id="29ab4efbdb7c727c81ee1382593bc5e2" category="cell">Nginx (services de protection des données)</block>
  <block id="89f152cad33314315b4995ed1ca71535" category="inline-link">Comment créer et/ou importer un certificat SSL dans le plug-in SnapCenter pour VMware vSphere (SCV)</block>
  <block id="450adc59e39f23172756ac9369494a2d" category="list-text">*Prise en charge des certificats signés par l'autorité de certification (CA).* le plug-in SnapCenter pour VMware vSphere prend en charge la fonctionnalité des certificats signés par l'autorité de certification. Voir<block ref="9f83d87d5d9f604d96288df21d450fac" category="inline-link-rx"></block>.</block>
  <block id="05a1aa8021df4579874c4eeb8788e5c9" category="list-text">*Stratégies de mot de passe.* les stratégies de mot de passe suivantes sont en vigueur :</block>
  <block id="2c87609dbbc3630573c64e271de8207d" category="list-text">Toutes les informations d'identification sont stockées à l'aide d'un hachage SHA256.</block>
  <block id="0f1a6fa0a65f9d5c3c4a16b070104d7a" category="list-text">*Image du système d'exploitation de base.* le produit est fourni avec le système d'exploitation de base Debian pour OVA avec accès restreint et accès au shell désactivé. Cela réduit l'empreinte d'attaque. Chaque système d'exploitation de base SnapCenter est mis à jour avec les derniers correctifs de sécurité disponibles pour une protection maximale.</block>
  <block id="83cd5867ba912e517fa1100299fd1cf3" category="paragraph">NetApp développe des fonctionnalités logicielles et des correctifs de sécurité en ce qui concerne le plug-in SnapCenter pour l'appliance VMware vSphere, puis les publie auprès de ses clients sous la forme d'un pack logiciel. Étant donné que ces dispositifs intègrent des dépendances spécifiques au système d'exploitation Linux et à notre logiciel propriétaire, NetApp vous recommande de ne pas modifier le système sous-exploitation, car il présente un potentiel important d'affecter l'appliance NetApp. Cela pourrait affecter la capacité de NetApp à prendre en charge l'appliance. NetApp recommande de tester et de déployer la dernière version de code pour les appliances, car elles sont publiées pour corriger les problèmes de sécurité.</block>
  <block id="c7eca250a9863785d63364853c46c00d" category="doc">Tiering MySQL avec FabricPool</block>
  <block id="1bc6cee680286aae1b12889369b7f18a" category="summary">MySQL sur ONTAP</block>
  <block id="dac8ea4fbfd87a535663c227b91f50e3" category="doc">Planificateurs d'E/S.</block>
  <block id="215dca219378b291ae287eb076489fdd" category="paragraph">Le noyau Linux permet un contrôle de bas niveau sur la façon dont les E/S sont planifiées pour bloquer les périphériques.</block>
  <block id="dc36d23ef487690f1698c69d9e49cee2" category="paragraph">Les valeurs par défaut sur les différentes distributions de Linux varient considérablement. MySQL vous recommande d'utiliser<block ref="722d122e81cbbe543bd5520bb8678c0e" prefix=" " category="inline-code"></block> ou un<block ref="30e482a8ab57cfc19075dece53b0a56b" prefix=" " category="inline-code"></block> Planificateur d'E/S avec E/S asynchrones natives (AIO) sous Linux. De manière générale, les clients NetApp et les tests internes montrent de meilleurs résultats avec NoOps.</block>
  <block id="6def78482bd1915cb81f0f5c19ee8fe6" category="paragraph">Le moteur de stockage InnoDB de MySQL utilise le sous-système d'E/S asynchrone (AIO natif) sur Linux pour effectuer des demandes de lecture et d'écriture pour les pages de fichiers de données. Ce comportement est contrôlé par le<block ref="2c03186a22d036ce7dad84be5de2f2ce" prefix=" " category="inline-code"></block> option de configuration, activée par défaut. Avec le tout-en-un natif, le type de planificateur d'E/S a une plus grande influence sur les performances E/S. Menez des bancs d'essai pour déterminer quel planificateur d'E/S offre les meilleurs résultats pour votre charge de travail et votre environnement.</block>
  <block id="e7b09beaf26efc7d8bee91786cf794b5" category="paragraph">Consultez la documentation Linux et MySQL appropriée pour obtenir des instructions sur la configuration du planificateur d'E/S.</block>
  <block id="6e8775bd755a8835ce86806d669677ea" category="doc">Configuration de stockage sous-jacente</block>
  <block id="2f09ac000b4a1808cb795b7bdbb20ecc" category="doc">taille_fichier_log_innodb</block>
  <block id="b8674b2897b288ca55b74328df4780b3" category="paragraph">Il est important de sélectionner la bonne taille pour le fichier journal InnoDB pour les opérations d'écriture et pour avoir un temps de récupération décent après une panne du serveur.</block>
  <block id="b61bad6f7bf48bf9abda0c86c9beed79" category="paragraph">Étant donné que tant de transactions sont connectées au fichier, la taille du fichier journal est importante pour les opérations d'écriture. Lorsque les enregistrements sont modifiés, la modification n'est pas immédiatement réécrite dans l'espace de table. Au lieu de cela, la modification est enregistrée à la fin du fichier journal et la page est marquée comme sale. InnoDB utilise son journal pour convertir les E/S aléatoires en E/S séquentielles</block>
  <block id="e87d83a3c0af4df83efb4784b5182f8f" category="paragraph">Lorsque le journal est plein, la page sale est écrite dans l'espace table en séquence pour libérer de l'espace dans le fichier journal. Par exemple, supposons qu'un serveur se bloque au milieu d'une transaction et que les opérations d'écriture ne sont enregistrées que dans le fichier journal. Avant que le serveur puisse de nouveau être mis en service, il doit passer par une phase de récupération dans laquelle les modifications enregistrées dans le fichier journal sont relus. Plus le nombre d'entrées dans le fichier journal est important, plus la restauration du serveur prend de temps.</block>
  <block id="8321756b7fedf72543a1b0917bf92613" category="paragraph">Dans cet exemple, la taille du fichier journal affecte à la fois le temps de restauration et les performances d'écriture. Lorsque vous choisissez le bon nombre pour la taille du fichier journal, équilibrez le délai de restauration par rapport aux performances d'écriture. En général, tout ce qui se trouve entre 128M et 512M est d'une bonne valeur.</block>
  <block id="d4ae77cd65c244ceb4277b27553d6931" category="doc">Bases de données MySQL sur ONTAP</block>
  <block id="598132a821e8cc696fbbae934047d991" category="paragraph">MySQL et ses variantes, y compris MariaDB et Percona MySQL, est la base de données la plus populaire au monde.</block>
  <block id="478f00c3805e92ad9e8a7cd4f335a020" category="admonition">Cette documentation sur ONTAP et la base de données MySQL remplace la base de données _TR-4722: Base de données MySQL sur les meilleures pratiques NetApp ONTAP._</block>
  <block id="9793e07572d1520fdffd0e4db62df588" category="paragraph">Les fonctionnalités de MySQL incluent :</block>
  <block id="04b90043b7bbdc843dd2b77f2014f14f" category="list-text">*TCO réduit.* MySQL est un système de gestion de base de données puissant, gratuit et open source, disponible depuis des années. Il est très stable. Il dispose d'un support communautaire qui permet de gérer, de déboguer et d'ajouter de nouvelles fonctionnalités. Si une application Web requiert plus qu'une base de données, ou exige un équilibrage de charge ou une gestion des données, vous pouvez facilement configurer des instances de base de données avec des coûts matériels uniquement, plutôt que des bases de données commerciales qui requièrent une seule licence pour chaque instance.</block>
  <block id="ae129f31dc6bc29ee6e28e9dbd8bd904" category="list-text">*Fiabilité, performances et facilité d'utilisation.* l'un des atouts de MySQL est une performance et une évolutivité exceptionnelles, ce qui explique pourquoi tant d'entreprises basées sur le Web l'utilisent. MySQL utilise plusieurs points forts pour fournir des performances rapides. La concurrence étant toujours accessible par un clic de souris (ou un toucher à l'écran), il est primordial de répondre rapidement aux demandes et aux activités des clients. La base de données qui prend en charge les applications web doit fournir des performances extrêmes pour les opérations de lecture (requêtes simples et complexes) et d'écriture.</block>
  <block id="ce921a1775ad78848c0ef06b4c2aaff3" category="list-text">*Développement, conception et administration de la base de données.* MySQL Workbench fournit un environnement intégré de développement, de conception et d'administration pour rendre les développeurs et les administrateurs de bases de données plus productifs. Différents développeurs recherchent différentes fonctionnalités dans une base de données, et MySQL offre une gamme de fonctionnalités. Il peut fonctionner correctement sur un ordinateur portable comme sur un ordinateur de bureau. Il peut s'adapter facilement à l'environnement, en s'assurant qu'il n'entre pas en collision avec les serveurs Web ou les applications existants.</block>
  <block id="26ab39333494c60fdfe1fbf67fcb9c4a" category="list-text">*Support transactionnel complet.* MySQL est l'un des moteurs de bases de données transactionnelles les plus robustes disponibles. Il s'agit d'une solution garantissant l'intégrité complète des données, offrant des fonctionnalités telles que la prise en charge complète des transactions atomiques, cohérentes, isolées et durables ; la prise en charge des transactions multiversions ; et verrouillage illimité au niveau des rangées. Il permet une identification instantanée des blocages grâce à l'intégrité référentielle appliquée par le serveur.</block>
  <block id="f9ab99873ba8416ec0975ef4f4fb655a" category="list-text">*Sécurité des données.* MySQL est mondialement reconnu pour être le système de gestion de base de données le plus sûr et le plus fiable utilisé dans les applications web populaires telles que WordPress, Drupal, Joomla, Facebook, Google, et Twitter. La sécurité des données et le support pour le traitement transactionnel qui accompagne la version récente de MySQL peut bénéficier à n'importe quelle entreprise, en particulier les entreprises de commerce électronique qui impliquent des transferts d'argent fréquents.</block>
  <block id="2cb5bda4a8945e058ff550f4991ba8b6" category="list-text">*Architecture enfichable.* l'architecture du moteur de stockage enfichable MySQL permet à un professionnel de base de données de sélectionner un moteur de stockage spécialisé pour un besoin d'application particulier sans avoir à gérer les exigences de codage d'application. L'architecture du serveur MySQL isole le programmeur d'application et l'administrateur de bases de données de tous les détails d'implémentation de bas niveau au niveau du stockage, fournissant ainsi un modèle d'application et une API cohérents et faciles. Bien que les différents moteurs de stockage offrent différentes capacités, l'application est protégée de ces différences.</block>
  <block id="e0780e103bd4ebcb0ee7f25b644eca40" category="paragraph">L'architecture efficace et modulaire de MySQL offre des avantages considérables si vous souhaitez cibler des besoins spécifiques en matière d'applications, tels que l'entreposage de données, le traitement de transactions ou la haute disponibilité, tout en utilisant des interfaces et des services indépendants de n'importe quel moteur de stockage.</block>
  <block id="35701e1bcd40c8e1a520fc33d0e14842" category="doc">innodb_flush_method</block>
  <block id="138738e11d5fda5c496edaa92e32e158" category="paragraph">Le paramètre innodb_flush_method indique comment InnoDB ouvre et vide les fichiers journaux et de données.</block>
  <block id="c262c8cd82b96f69fbbc058d7a35683b" category="section-title">Optimisations</block>
  <block id="d1e67ebe6122765789852eb430c42c75" category="paragraph">Dans l'optimisation InnoDB, la définition de ce paramètre permet de régler les performances de la base de données, le cas échéant.</block>
  <block id="51ca63a7fb332d4d18e7139ea5787c50" category="paragraph">Les options suivantes permettent de vider les fichiers via InnoDB :</block>
  <block id="a9b8d4c72b58a9554274cba7904d47e2" category="list-text"><block ref="e590322920bebc1156ab585bd6597d76" prefix="" category="inline-code"></block>. InnoDB utilise le<block ref="4d0b2ade287f8f35e993511729bc75a1" prefix=" " category="inline-code"></block> appel système pour vider les fichiers de données et les fichiers journaux. Cette option est le paramètre par défaut.</block>
  <block id="8198b1fd4bf2fafa4f4e8ffb4a8ac900" category="list-text"><block ref="a48be70a21bca2cf4b3e481efed66ae4" prefix="" category="inline-code"></block>. InnoDB utilise le<block ref="a48be70a21bca2cf4b3e481efed66ae4" prefix=" " category="inline-code"></block> option permettant d'ouvrir et de vider les fichiers journaux et fsync() pour vider les fichiers de données. InnoDB n'utilise pas<block ref="a48be70a21bca2cf4b3e481efed66ae4" prefix=" " category="inline-code"></block> Directement, parce qu'il y a eu des problèmes avec elle sur de nombreuses variétés d'UNIX.</block>
  <block id="f89f9147df5dde99a7944d2028b59e7e" category="list-text"><block ref="6a334fd488ef92b18584207148410cc4" prefix="" category="inline-code"></block>. InnoDB utilise le<block ref="6a334fd488ef92b18584207148410cc4" prefix=" " category="inline-code"></block> option (ou<block ref="42d27f470f62deaad644fef8618b59bb" prefix=" " category="inline-code"></block> Sous Solaris) pour ouvrir les fichiers de données et les utilise<block ref="4d0b2ade287f8f35e993511729bc75a1" prefix=" " category="inline-code"></block> pour vider les fichiers de données et les fichiers journaux. Cette option est disponible sur certaines versions de GNU/Linux, FreeBSD et Solaris.</block>
  <block id="5e90100e134d805a66f8cda2e73f5298" category="list-text"><block ref="d66655d6d13113f23421f282ed1eaeb7" prefix="" category="inline-code"></block>. InnoDB utilise le<block ref="6a334fd488ef92b18584207148410cc4" prefix=" " category="inline-code"></block> Option pendant le vidage des E/S ; cependant, il ignore le<block ref="4d0b2ade287f8f35e993511729bc75a1" prefix=" " category="inline-code"></block> appel système par la suite. Cette option n'est pas adaptée à certains types de systèmes de fichiers (par exemple, XFS). Si vous n'êtes pas sûr que votre système de fichiers nécessite un<block ref="4d0b2ade287f8f35e993511729bc75a1" prefix=" " category="inline-code"></block> l'appel système, par exemple pour conserver toutes les métadonnées de fichier, utilise le<block ref="6a334fd488ef92b18584207148410cc4" prefix=" " category="inline-code"></block> à la place.</block>
  <block id="c680d437163cc6bab4f9bdb35c3073d0" category="section-title">Observation</block>
  <block id="907dee0040812e8e7d1fd00b870b5063" category="paragraph">Dans les tests de laboratoire NetApp, le<block ref="e590322920bebc1156ab585bd6597d76" prefix=" " category="inline-code"></block> L'option par défaut a été utilisée sur NFS et SAN, et il s'agissait d'un outil d'amélioration des performances par rapport à<block ref="6a334fd488ef92b18584207148410cc4" prefix=" " category="inline-code"></block>. Lors de l'utilisation de la méthode de rinçage comme<block ref="6a334fd488ef92b18584207148410cc4" prefix=" " category="inline-code"></block> Avec ONTAP, nous avons observé que le client écrit beaucoup d'écritures sur un seul octet à la frontière du bloc 4096 en série. Ces écritures ont augmenté la latence sur le réseau et dégradé les performances.</block>
  <block id="2f0b9319cf6d59e07ea4b1ef65a12be1" category="doc">open_file_limits</block>
  <block id="11e52b21a9795b7dcf947027b0ec5d01" category="paragraph">Le<block ref="2f0b9319cf6d59e07ea4b1ef65a12be1" prefix=" " category="inline-code"></block> paramètre détermine le nombre de fichiers que le système d'exploitation autorise à ouvrir mysqld.</block>
  <block id="e0732f22b2900006e8fcb6367fd162f7" category="paragraph">La valeur de ce paramètre au moment de l'exécution est la valeur réelle autorisée par le système et peut être différente de la valeur spécifiée au démarrage du serveur. La valeur est 0 sur les systèmes où MySQL ne peut pas modifier le nombre de fichiers ouverts. L'efficace<block ref="3d39e9c5aa2f78830dd6993cec18e93e" prefix=" " category="inline-code"></block> la valeur est basée sur la valeur spécifiée au démarrage du système (le cas échéant) et sur les valeurs de<block ref="0bc91339c0d774f560a9a38fc9dfac30" prefix=" " category="inline-code"></block> et<block ref="023a3b50ddf424c9a1d51984190a0c92" prefix=" " category="inline-code"></block> en utilisant ces formules :</block>
  <block id="6b840ff0a7667f4642a0844269657fc4" category="list-text">10 +<block ref="0bc91339c0d774f560a9a38fc9dfac30" prefix=" " category="inline-code"></block> + <block ref="023a3b50ddf424c9a1d51984190a0c92" prefix="(" category="inline-code"></block> x 2)</block>
  <block id="d3de183489c20b8efa2947eeff3028d7" category="list-text"><block ref="0bc91339c0d774f560a9a38fc9dfac30" prefix="" category="inline-code"></block> x 5</block>
  <block id="2c08922fbaba089e7c2982df43fd352a" category="list-text">Limite du système d'exploitation si positif</block>
  <block id="8ca153937fcbdf56497ad779a91f31d1" category="list-text">Si la limite du système d'exploitation est infinie :<block ref="3d39e9c5aa2f78830dd6993cec18e93e" prefix=" " category="inline-code"></block> la valeur est spécifiée au démarrage ; 5,000 si aucune</block>
  <block id="98038bb4026a70f5ee4041522c6eebe4" category="paragraph">Le serveur tente d'obtenir le nombre de descripteurs de fichier en utilisant le maximum de ces quatre valeurs. Si ce nombre de descripteurs ne peut pas être obtenu, le serveur tente d'obtenir autant que le système le permet.</block>
  <block id="3ee58d04a0dc9b2551698643e0421005" category="doc">innodb_lru_scan_depth</block>
  <block id="29d0f4f8b383d39e73abd11ac73ca28a" category="paragraph">Le<block ref="3ee58d04a0dc9b2551698643e0421005" prefix=" " category="inline-code"></block> Le paramètre influence les algorithmes et les heuristiques de l'opération de vidage pour le pool de mémoire tampon InnoDB.</block>
  <block id="eeb16232629bd788f0d29c104105bba2" category="paragraph">Ce paramètre intéresse principalement les experts en performances qui s'intéressent au réglage des charges de travail exigeantes en E/S. Pour chaque instance de pool de mémoire tampon, ce paramètre indique la distance vers le bas dans la liste de pages LRU (least recently used) que le thread de nettoyage de page doit poursuivre la numérisation, en recherchant les pages sales à vider. Cette opération d'arrière-plan est effectuée une fois par seconde.</block>
  <block id="39359bf2914e4e1cf84a9dea580fd20a" category="paragraph">Vous pouvez régler la valeur vers le haut ou vers le bas pour réduire le nombre de pages libres. Ne définissez pas la valeur beaucoup plus haut que nécessaire, car les analyses peuvent avoir un coût de performance important. Pensez également à ajuster ce paramètre lors de la modification du nombre d'instances de pool de mémoire tampon, car<block ref="f2c8312d381c16c6c95a727c3f61a4c7" prefix=" " category="inline-code"></block> définit la quantité de travail effectuée par le thread de nettoyage de page chaque seconde.</block>
  <block id="513a275422fae2456617321a2f3fc0af" category="paragraph">Un paramètre inférieur à celui par défaut convient à la plupart des workloads. Envisagez d'augmenter la valeur uniquement si vous disposez d'une capacité d'E/S disponible pour une charge de travail classique. Inversement, si une charge de travail exigeante en écriture sature votre capacité d'E/S, diminuez la valeur, en particulier si vous disposez d'un pool de mémoire tampon important.</block>
  <block id="62812b938ba1113b81bd7f612ad0e6f8" category="doc">innodb_buffer_pool_size</block>
  <block id="d7a8b502d05f5e477158eb80c1fb8dae" category="paragraph">Le pool de mémoire tampon InnoDB est la partie la plus importante de toute activité de réglage.</block>
  <block id="5cb6c45d18482180f34ae727b53379fb" category="paragraph">InnoDB s'appuie fortement sur le pool de mémoire tampon pour mettre en cache les index et ramer les données, l'index de hachage adaptatif, le tampon d'insertion et de nombreuses autres structures de données utilisées en interne. Le pool de mémoire tampon met également en mémoire tampon les modifications apportées aux données afin que les opérations d'écriture n'aient pas à être exécutées immédiatement sur le stockage, ce qui améliore les performances. Le pool de mémoire tampon fait partie intégrante d'InnoDB et sa taille doit être ajustée en conséquence. Tenez compte des facteurs suivants lors de la définition de la taille du pool de mémoire tampon :</block>
  <block id="03f07291794c3b9cb00d04cb9f30be81" category="list-text">Pour une machine dédiée uniquement InnoDB, définissez la taille du pool de mémoire tampon sur 80 % ou plus de la mémoire RAM disponible.</block>
  <block id="7b0119b7fa59f87d23d5c65da456b226" category="list-text">S'il ne s'agit pas d'un serveur dédié MySQL, définissez la taille sur 50 % de RAM.</block>
  <block id="a6a9695e1464f5554c0006c55facfadf" category="doc">Descripteurs de fichier</block>
  <block id="5ef6471f819ed2d47303473cc87d9305" category="paragraph">Pour s'exécuter, le serveur MySQL a besoin de descripteurs de fichier.</block>
  <block id="8e222c68dd214db9f8a1b5b572ee6267" category="paragraph">Il les utilise pour ouvrir de nouvelles connexions, stocker des tables dans le cache, créer des tables temporaires pour résoudre des requêtes complexes et accéder à des requêtes persistantes. Si mysqld n'est pas en mesure d'ouvrir de nouveaux fichiers lorsque cela est nécessaire, il peut arrêter de fonctionner correctement. Un symptôme courant de ce problème est l'erreur 24, "trop de fichiers ouverts". Le nombre de descripteurs de fichier que mysqld peut ouvrir simultanément est défini par le<block ref="3d39e9c5aa2f78830dd6993cec18e93e" prefix=" " category="inline-code"></block> option définie dans le fichier de configuration <block ref="86d0d007043d911697753b35e2c18f35" prefix="(" category="inline-code"></block>). Mais<block ref="3d39e9c5aa2f78830dd6993cec18e93e" prefix=" " category="inline-code"></block> dépend également des limites du système d'exploitation. Cette dépendance complique la définition de la variable.</block>
  <block id="07561a91f81dfe3c8e4364aac8bdbea4" category="paragraph">MySQL ne peut pas définir son<block ref="3d39e9c5aa2f78830dd6993cec18e93e" prefix=" " category="inline-code"></block> option supérieure à celle spécifiée sous<block ref="dd1c6d8164dfd1cee0afa39b177e843b" prefix=" " category="inline-code"></block>. Par conséquent, vous devez définir explicitement ces limites au niveau du système d'exploitation pour permettre à MySQL d'ouvrir des fichiers si nécessaire. Il existe deux façons de vérifier la limite de fichiers sous Linux :</block>
  <block id="84e705ac120a887df441f4161dc29409" category="list-text">Le<block ref="2eabb4efed7dffb32ea1170eab71b798" prefix=" " category="inline-code"></block> commande vous donne rapidement une description détaillée des paramètres autorisés ou verrouillés. Les modifications apportées par l'exécution de cette commande ne sont pas permanentes et seront effacées après un redémarrage du système.</block>
  <block id="a4c404dc92855948bc4c007a86091dbe" category="list-text">Modifications apportées au<block ref="b803f460349bd101b1de260021ef0e60" prefix=" " category="inline-code"></block> les fichiers sont permanents et ne sont pas affectés par un redémarrage du système.</block>
  <block id="cbcab8220d4ffddbdc44f9936125d83d" category="paragraph">Assurez-vous de modifier les limites matérielles et logicielles de l'utilisateur mysql. Les extraits suivants sont issus de la configuration :</block>
  <block id="97dc47f90c600a96fac6642560ffaceb" category="paragraph">En parallèle, mettez à jour la même configuration dans<block ref="90f16be5b82ca0aa94088c89fe00b3dd" prefix=" " category="inline-code"></block> pour utiliser pleinement les limites de fichiers ouverts.</block>
  <block id="395ec860c9530814e94538b7121a8319" category="doc">innodb_flush_log_at_trx_commit</block>
  <block id="2f2c7742844f13de59d435b9099c78cc" category="paragraph">En cas de modification des données, celles-ci ne sont pas immédiatement écrites sur le support de stockage.</block>
  <block id="0b36b8f791a48c7b4692e7df069dabc8" category="paragraph">À la place, les données sont enregistrées dans une mémoire tampon, qui est une partie de la mémoire allouée par InnoDB aux modifications de mémoire tampon enregistrées dans le fichier journal. InnoDB vide le tampon dans le fichier journal lorsqu'une transaction est validée, lorsque le tampon est plein ou une fois par seconde, quel que soit l'événement qui se produit en premier. La variable de configuration qui contrôle ce processus est innodb_flush_log_at_trx_commit. Les options de valeur comprennent :</block>
  <block id="280a38864b81c14ba3db52801e087ed0" category="list-text">Lorsque vous réglez<block ref="cab9a35054c49f0ba619a6e6943f461b" prefix=" " category="inline-code"></block>, InnoDB écrit les données modifiées (dans le pool de mémoire tampon InnoDB) dans le fichier journal (ib_logfile) et purge le fichier journal (écriture dans le stockage) toutes les secondes. Cependant, elle ne fait rien lorsque la transaction est validée. En cas de panne de courant ou de panne du système, aucune des données non rincées n'est récupérable car elles ne sont pas écrites sur le fichier journal ou les lecteurs.</block>
  <block id="5967bb5566cb7cd8bdb0b372ceb21565" category="list-text">Lorsque vous réglez<block ref="1ab7a7611b59147e84a38b6f3e7d9d09" prefix=" " category="inline-code"></block>, InnoDB écrit la mémoire tampon du journal dans le journal de transactions et vide jusqu'à un stockage durable pour chaque transaction. Par exemple, pour toutes les validations de transactions, InnoDB écrit dans le journal, puis écrit dans le stockage. Un stockage plus lent affecte négativement les performances. Par exemple, le nombre de transactions InnoDB par seconde est réduit.</block>
  <block id="9e9b3a43cb7a1b13c5ee3f6519d7f60e" category="list-text">Lorsque vous réglez<block ref="44d4dfee9b1c95f8768bec989cd3baf5" prefix=" " category="inline-code"></block>, InnoDB écrit la mémoire tampon du journal dans le fichier journal à chaque validation ; cependant, il n'écrit pas de données dans le stockage. InnoDB vide les données une fois par seconde. Même en cas de panne de courant ou de panne du système, les données de l'option 2 sont disponibles dans le fichier journal et peuvent être récupérées.</block>
  <block id="14f3e0328e25aa02b37bd6817a442a58" category="paragraph">Si la performance est l'objectif principal, définissez la valeur sur 2. Comme InnoDB écrit sur les disques une fois par seconde, pas pour chaque validation de transaction, les performances s'améliorent considérablement. En cas de panne de courant ou de panne de courant, les données peuvent être récupérées à partir du journal de transactions.</block>
  <block id="4a34cbb1957909093a2e216fc1cd0962" category="paragraph">Si la sécurité des données est l'objectif principal, définissez la valeur sur 1 afin que, pour chaque validation de transaction, InnoDB vide les lecteurs. Cependant, les performances peuvent être affectées.</block>
  <block id="53be3047aa6f8a62c640cc8b4d6089c6" category="admonition">*NetApp recommande* de définir la valeur innodb_flush_log_trx_commit sur 2 pour de meilleures performances.</block>
  <block id="2199371f8380c97ad11a03fba3b501c9" category="doc">innodb_io_capacity</block>
  <block id="ac165f23bb7435219b226ed6e76c5fa4" category="paragraph">Dans le plug-in InnoDB, un nouveau paramètre appelé innodb_io_Capacity a été ajouté à partir de MySQL 5.7.</block>
  <block id="b4f38c42ef968074288f239b42e92b7f" category="paragraph">Il contrôle le nombre maximal d'IOPS qu'InnoDB exécute (qui inclut la vitesse de vidage des pages sales ainsi que la taille de lot du tampon d'insertion [ibuf]). Le paramètre innodb_io_Capacity définit une limite supérieure sur les IOPS par les tâches d'arrière-plan InnoDB, telles que le vidage des pages du pool de mémoire tampon et la fusion des données à partir du tampon de changement.</block>
  <block id="9679a08c293f29d9546c42207b09d418" category="paragraph">Définissez le paramètre innodb_io_Capacity sur le nombre approximatif d'opérations d'E/S que le système peut effectuer par seconde. Idéalement, maintenez le paramètre aussi bas que possible, mais pas si bas que les activités en arrière-plan ralentissent. Si le paramètre est trop élevé, les données sont supprimées du pool de mémoire tampon et la mémoire tampon est insérée trop rapidement pour que la mise en cache offre un avantage significatif.</block>
  <block id="668b6acc98c3469094062ed50b43e43a" category="admonition">*NetApp recommande* que si vous utilisez ce paramètre sur NFS, analysez le résultat du test d'IOPS (SysBench/FiO) et définissez le paramètre en conséquence. Utilisez la plus petite valeur possible pour le vidage et la purge pour continuer à fonctionner, sauf si vous voyez plus de pages modifiées ou sales que vous le souhaitez dans le pool de mémoire tampon InnoDB.</block>
  <block id="038b11d42ee14bd77b6370c575c63b16" category="admonition">N'utilisez pas de valeurs extrêmes telles que 20,000 ou plus, sauf si vous avez prouvé que des valeurs inférieures ne suffisent pas à votre charge de travail.</block>
  <block id="62385f5ceb285bca676cb0561555d719" category="paragraph">Le paramètre InnoDB_IO_Capacity régule les débits de rinçage et les E/S associées</block>
  <block id="c957ef06af970a7526a73e741b47fef1" category="admonition">Vous pouvez sérieusement nuire aux performances en définissant ce paramètre ou le paramètre innodb_io_Capacity_max trop élevé et en gaspillant les opérations d'E/S avec un rinçage prématuré.</block>
  <block id="d32067c550345cae14e678b4def6aa22" category="doc">MySQL sur SAN</block>
  <block id="b238d5dd75fe5ed855c5b3047e074050" category="paragraph">Il existe deux options pour configurer MySQL avec SAN à l'aide du modèle à deux volumes habituel.</block>
  <block id="58d94bb6e53e154e2f4b16efa09f4c0d" category="paragraph">Les bases de données plus petites peuvent être placées sur une paire de LUN standard tant que les besoins en E/S et en capacité se situent dans les limites d'un seul système de fichiers LUN. Par exemple, une base de données qui nécessite environ 2 000 IOPS aléatoires peut être hébergée sur un système de fichiers unique sur une seule LUN. De même, une base de données de 100 Go seulement serait prise en charge sur une seule LUN sans problème de gestion.</block>
  <block id="c33bcb4f520265bb106616e844397ffb" category="paragraph">Les bases de données plus grandes nécessitent plusieurs LUN. Par exemple, une base de données qui nécessite 100 000 IOPS aurait probablement besoin d'au moins huit LUN. Un seul LUN deviendrait un goulot d'étranglement en raison du nombre insuffisant de canaux SCSI vers les disques. Une base de données de 10 To serait tout aussi difficile à gérer sur un seul LUN de 10 To. Les gestionnaires de volumes logiques sont conçus pour lier les performances et les capacités de plusieurs LUN afin d'améliorer les performances et la gestion.</block>
  <block id="428e88a1415b00f5eb396829b4bd9a2c" category="paragraph">Dans les deux cas, une paire de volumes ONTAP doit suffire. Dans une configuration simple, le LUN du fichier de données serait placé dans un volume dédié, tout comme le LUN du journal. Avec une configuration de gestionnaire de volumes logique, toutes les LUN du groupe de volumes de fichiers de données se trouvent dans un volume dédié, et les LUN du groupe de volumes de logs se trouvent dans un second volume dédié.</block>
  <block id="e8c31916b755be39cb0a66804a1d8f8b" category="paragraph">*NetApp recommande* l'utilisation de deux systèmes de fichiers pour les déploiements MySQL sur SAN :</block>
  <block id="fe9d8ca2c46747e16ed31f64638e66e6" category="list-text">Le premier système de fichiers stocke toutes les données MySQL, y compris l'espace table, les données et l'index.</block>
  <block id="04d82ed32fa1eeaa6df117c178062441" category="list-text">Le second système de fichiers stocke tous les journaux (journaux binaires, journaux lents et journaux des transactions).</block>
  <block id="15bcb76b7e8b441c0d2a6e723f70c20c" category="paragraph">Il existe plusieurs raisons de séparer les données de cette manière :</block>
  <block id="02774797d31a8f1c6d805860038c32a3" category="list-text">Les modèles d'E/S des fichiers de données et des fichiers journaux diffèrent. De les séparer, on disposerait d'un plus grand nombre d'options avec les contrôles de QoS.</block>
  <block id="6cab2c793e807e2d0c57f5b0d96505c1" category="list-text">Pour optimiser l'utilisation de la technologie Snapshot, vous devez pouvoir restaurer les fichiers de données de manière indépendante. La connexion de fichiers de données avec des fichiers journaux interfère avec la restauration des fichiers de données.</block>
  <block id="553ad1f7b6f5cfee021e5cf56e56a289" category="list-text">La technologie SnapMirror de NetApp peut être utilisée pour fournir une fonctionnalité de reprise d'activité simple à faible RPO pour une base de données. Toutefois, le planning de réplication des fichiers de données et des journaux doit être différent.</block>
  <block id="ff5f52a69a35dd41da3e3c4b810e4f94" category="admonition">Utilisez cette disposition de base à deux volumes pour pérenniser votre solution et utiliser toutes les fonctionnalités ONTAP si nécessaire.</block>
  <block id="7b755794e9de5716b2d6305bd10bee1b" category="paragraph">*NetApp recommande* de formater votre lecteur avec le système de fichiers ext4 en raison des fonctionnalités suivantes :</block>
  <block id="fa92f58d5035dec5e24a787f76504783" category="list-text">Approche étendue des fonctions de gestion des blocs utilisées dans le système de fichiers de journalisation (JFS) et fonctions d'allocation différée du système de fichiers étendu (XFS).</block>
  <block id="a72d73cde02c10703b72dcae6bc7c812" category="list-text">Ext4 autorise des systèmes de fichiers allant jusqu'à 1 exbioctet (2^60 octets) et des fichiers allant jusqu'à 16 tébioctets (16 * 2^40 octets). En revanche, le système de fichiers ext3 ne prend en charge qu'une taille de système de fichiers maximale de 16 To et une taille de fichier maximale de 2 To.</block>
  <block id="56b4168424fa999bc383d24daf2da4eb" category="list-text">Dans les systèmes de fichiers ext4, l'allocation multi-blocs (mballoc) alloue plusieurs blocs pour un fichier en une seule opération, au lieu de les allouer un par un, comme dans ext3. Cette configuration réduit la surcharge liée à l'appel de l'ALlocator de bloc plusieurs fois et optimise l'allocation de mémoire.</block>
  <block id="632635d22b347f0140fb15d0eb0ed09e" category="list-text">Bien que XFS soit la valeur par défaut pour de nombreuses distributions Linux, il gère les métadonnées différemment et ne convient pas à certaines configurations MySQL.</block>
  <block id="aff8b2ed0a4719f014e5baeb861ea7d4" category="paragraph">*NetApp recommande* d'utiliser les options de taille de bloc de 4 ko avec l'utilitaire mkfs pour l'aligner avec la taille de LUN de bloc existante.</block>
  <block id="0a24d0336b7b0b29a9daa97f88499884" category="paragraph"><block ref="018d13c1d8b9abcae080b8abbc7c2d8b" prefix="" category="inline-code"></block></block>
  <block id="86fc8cb3bf2cae621315896a94b35f67" category="paragraph">Les LUN NetApp stockent les données dans des blocs physiques de 4 Ko, ce qui produit huit blocs logiques de 512 octets.</block>
  <block id="5f441ceabc94de2a9cced94d9f53a2d0" category="paragraph">Si vous ne configurez pas la même taille de bloc, les E/S ne seront pas alignées avec les blocs physiques correctement et pourraient écrire sur deux disques différents dans un groupe RAID, ce qui entraîne une latence.</block>
  <block id="236ac851d05b8822524001920948f23d" category="admonition">Il est important d'aligner les E/S pour que les opérations de lecture/écriture soient fluides. Cependant, lorsque les E/S commencent au niveau d'un bloc logique qui n'est pas au début d'un bloc physique, les E/S sont mal alignées. Les opérations d'E/S ne sont alignées que lorsqu'elles commencent au niveau d'un bloc logique, le premier bloc logique d'un bloc physique.</block>
  <block id="e6cf2549be4da18bf404cacc6100516a" category="summary">Configuration MySQL</block>
  <block id="282155126a94a0702cfd80daf38d4362" category="doc">Présentation de la configuration</block>
  <block id="13b506e9cda8a01b4cd60e08f3f1faf6" category="paragraph">NetApp recommande quelques paramètres de configuration MySQL importants (répertoriés dans le Tableau 1) pour obtenir des performances optimales.</block>
  <block id="3225a10b07f1580f10dee4abc3779e6c" category="cell">Paramètres</block>
  <block id="c82a6100dace2b41087ba6cf99a5976a" category="cell">Valeurs</block>
  <block id="b10db909b8fda84e70bf9b308d0938d9" category="cell">256M</block>
  <block id="c81e728d9d4c2f636f067f89cc14862c" category="cell">2</block>
  <block id="7ccc31934ae8244d8263d3c09bcee186" category="cell">innodb_doublewrite</block>
  <block id="e590322920bebc1156ab585bd6597d76" category="cell">fsync</block>
  <block id="adb0c1ec32461889a5093441599260eb" category="cell">11G</block>
  <block id="774412967f19ea61d448977ad9749078" category="cell">8192</block>
  <block id="311887a53ec7390fc383fa2ad813f012" category="cell">innodb_buffer_pool_instances</block>
  <block id="c9f0f895fb98ab9159f51fd0297e236d" category="cell">8</block>
  <block id="1006f82d8df7d2325439b28ea691737c" category="cell">open_file_limit</block>
  <block id="3c9b5f1cd6a030bcb7bed9eac80589fb" category="cell">65535</block>
  <block id="c9f5a4d3ede4d084dda0a788ed06783c" category="paragraph">Pour définir les paramètres décrits dans cette section, vous devez les modifier dans le fichier de configuration MySQL (my.cnf). Les meilleures pratiques NetApp sont le résultat de tests réalisés en interne.</block>
  <block id="5382aaf8b3d2fdeb6717f9805b0dd511" category="doc">Conteneurs</block>
  <block id="6a554ff1dc93539a626e576bf0d28a02" category="paragraph">La conteneurisation des bases de données MySQL est de plus en plus répandue.</block>
  <block id="bcc002a9f2e2ade112438f50a6630498" category="paragraph">La gestion des conteneurs de faible niveau est presque toujours effectuée via Docker. Les plateformes de gestion de conteneurs comme OpenShift et Kubernetes simplifient encore la gestion des grands environnements de conteneurs. La conteneurisation présente des avantages à moindre coût, car il n'est pas nécessaire de posséder une licence pour un hyperviseur. De plus, les conteneurs permettent à plusieurs bases de données de s'exécuter isolées les unes des autres tout en partageant le même noyau et le même système d'exploitation sous-jacents. Les conteneurs sont provisionnés en quelques microsecondes.</block>
  <block id="14d9b10c6196045941347a9e85704b50" category="inline-link-macro">Documentation Astra Trident</block>
  <block id="d4f640fe6950a1baff001f5601c7fbd7" category="paragraph">NetApp propose Astra Trident pour fournir des fonctionnalités de gestion avancées du stockage. Par exemple, avec Astra Trident, un conteneur créé dans Kubernetes peut provisionner automatiquement son stockage sur le Tier approprié, appliquer des règles d'exportation, définir des règles de copie Snapshot NetApp et même cloner un conteneur vers un autre. Pour plus d'informations, reportez-vous au <block ref="2b8a155fc083396b96b18cee0ba5eab0" category="inline-link-macro-rx"></block>.</block>
  <block id="b8c3891a902a70c4f7f774363652f4b4" category="summary">Structure de fichier MySQL</block>
  <block id="5713a921d815fd7d19875846450f8ea8" category="doc">Structure de fichier</block>
  <block id="4955922857da5499a2f1be602a96b0ff" category="paragraph">InnoDB agit comme la couche intermédiaire entre le stockage et le serveur MySQL, il stocke les données sur les lecteurs.</block>
  <block id="8a6fab0b8bb36427eda4071adfd7780b" category="inline-image-macro">Erreur : image graphique introuvable</block>
  <block id="5d416cf65dd1e2c908bf430f957c89f8" category="paragraph">Les E/S MySQL sont classées en deux types :</block>
  <block id="e8a320970c929abda9ae744b0b9e8f5f" category="list-text">E/S de fichiers aléatoires</block>
  <block id="85430c0aa096ec282f2a14156baa312e" category="list-text">E/S séquentielles de fichiers</block>
  <block id="b7b9a4c6983139a2673988826094a3cf" category="paragraph">Les fichiers de données sont lus et écrasés de manière aléatoire, ce qui entraîne un nombre élevé d'IOPS. Un stockage SSD est donc recommandé.</block>
  <block id="322f79fd77365edecd173807cb429ca2" category="paragraph">Les fichiers redo log et les fichiers log binaires sont des journaux transactionnels. Ils sont écrits de manière séquentielle, ce qui vous permet d'obtenir de bonnes performances sur le disque dur avec le cache d'écriture. Une lecture séquentielle a lieu lors de la restauration, mais cela provoque rarement un problème de performance, car la taille du fichier journal est généralement inférieure à celle des fichiers de données et les lectures séquentielles sont plus rapides que les lectures aléatoires (se produisant sur les fichiers de données).</block>
  <block id="a898d206a27508975fea2e241af2f04e" category="paragraph">La mémoire tampon en double écriture est une fonction spéciale d'InnoDB. InnoDB écrit d'abord les pages vidées dans le tampon de double écriture, puis écrit les pages à leur position correcte sur les fichiers de données. Ce processus empêche la corruption de la page. Sans le tampon de double écriture, la page peut être corrompue si une panne de courant se produit pendant le processus d'écriture sur les lecteurs. L'écriture sur la mémoire tampon en double écriture étant séquentielle, elle est optimisée pour les disques durs. Les lectures séquentielles ont lieu lors de la restauration.</block>
  <block id="363512900e45bc17bdd6edfa50582862" category="paragraph">Comme la mémoire NVRAM ONTAP fournit déjà une protection en écriture, la mise en mémoire tampon en double écriture n'est pas nécessaire. MySQL a un paramètre,<block ref="02d3c518a4019ea00e34e16491d826b4" prefix=" " category="inline-code"></block>, pour désactiver le tampon de double écriture. Cette fonction peut améliorer considérablement les performances.</block>
  <block id="49a7df723922bddb4df4002b51087a1c" category="paragraph">Le tampon d'insertion est également une fonction spéciale d'InnoDB. Si des blocs d'index secondaires non uniques ne sont pas en mémoire, InnoDB insère des entrées dans le tampon d'insertion pour éviter les opérations d'E/S aléatoires. Périodiquement, le tampon d'insertion est fusionné dans les arborescences d'index secondaires de la base de données. La mémoire tampon d'insertion réduit le nombre d'opérations d'E/S en fusionnant les demandes d'E/S vers le même bloc ; les opérations d'E/S aléatoires peuvent être séquentielles. Le tampon d'insertion est également hautement optimisé pour les disques durs. Les écritures et les lectures séquentielles ont lieu pendant les opérations normales.</block>
  <block id="6a0190340f27f29279bbfd319800289d" category="paragraph">Les segments d'annulation sont orientés E/S aléatoires. Pour garantir la simultanéité multiversion (MVCC), InnoDB doit enregistrer les anciennes images dans les segments d'annulation. La lecture des images précédentes à partir des segments d'annulation nécessite des lectures aléatoires. Si vous exécutez une longue transaction avec des lectures reproductibles (comme mysqldump—single transaction) ou exécutez une longue requête, les lectures aléatoires peuvent se produire. Par conséquent, le stockage des segments d'annulation sur des disques SSD est préférable dans ce cas. Si vous exécutez uniquement des transactions ou des requêtes courtes, les lectures aléatoires ne sont pas un problème.</block>
  <block id="a27e0d4b650aa6db30fdd95b54c94b27" category="paragraph">*NetApp recommande* la disposition de conception de stockage suivante en raison des caractéristiques d'E/S InnoDB.</block>
  <block id="defc1bfda928f419df5e4af79c98343e" category="list-text">Un volume pour stocker des fichiers MySQL orientés E/S aléatoires et séquentielles</block>
  <block id="7fd750411093ebd1faa0d99dd2608514" category="list-text">Un autre volume pour stocker des fichiers MySQL orientés E/S purement séquentiels</block>
  <block id="0561a3b014eef0e5125fa63e1626cf57" category="paragraph">Cette disposition vous aide également à concevoir des stratégies et des règles de protection des données.</block>
  <block id="a53db665fd1a9734a7a0e119671a0cd0" category="paragraph">Les performances NFS sous Linux dépendent d'un paramètre appelé<block ref="453f2cc2326f82af1053f4aa4b75400b" prefix=" " category="inline-code"></block>.</block>
  <block id="9166d970028a28a614af39e6286371b7" category="paragraph">Vous pouvez désactiver ce paramètre avec<block ref="8cafbd8d9096941261e87f4f9152ab92" prefix=" " category="inline-code"></block> pour les bancs d'essai ou lorsque vous êtes davantage préoccupé par les performances que par l'intégrité des données ou par les défaillances possibles. InnoDB utilise une technique de vidage de fichier appelée double écriture. Avant d'écrire des pages dans les fichiers de données, InnoDB les écrit dans une zone contiguë appelée tampon de double écriture. Une fois l'écriture et le vidage de la mémoire tampon en double écriture terminés, InnoDB écrit les pages dans leur position correcte dans le fichier de données. Si le système d'exploitation ou un processus mysqld se bloque lors d'une écriture de page, InnoDB peut plus tard trouver une bonne copie de la page à partir du tampon de double écriture pendant la récupération après panne.</block>
  <block id="3dfd4b9a526f8a8cf17021e34638b375" category="admonition">*NetApp recommande* de désactiver le tampon en double écriture. La mémoire NVRAM de ONTAP remplit la même fonction. La double mise en mémoire tampon endommagera inutilement les performances.</block>
  <block id="dd5a2a602f713562e0f9f0fd8385660e" category="doc">MySQL sur NFS</block>
  <block id="0e5e83102103fcdd25af430bf7327034" category="paragraph">La documentation MySQL recommande d'utiliser NFSv4 pour les déploiements NAS.</block>
  <block id="ca0d9fdc80b88e73b548638af421788f" category="section-title">Tailles de transfert NFS ONTAP</block>
  <block id="efcd0ba3fcbee9896a25804677e70b4b" category="paragraph">Par défaut, ONTAP limite les tailles d'E/S NFS à 64 Ko. Les E/S aléatoires avec une base de données MySQL utilisent une taille de bloc bien inférieure à la taille maximale de 64 Ko. Les E/S de bloc volumineux sont généralement parallélisées de sorte que le maximum de 64 000 ne constitue pas non plus une limitation.</block>
  <block id="4655f686de75b23f16d530ed7351c447" category="paragraph">Dans certains cas, le maximum de 64 000 charges de travail entraîne une limitation. En particulier, les opérations à thread unique, telles que les opérations de sauvegarde d'analyse de table complète, s'exécuteront plus rapidement et plus efficacement si la base de données peut exécuter moins d'E/S, mais de plus grande taille. La taille optimale de gestion des E/S pour ONTAP avec charges de travail de base de données est de 256 Ko. Les options de montage NFS répertoriées pour les systèmes d'exploitation spécifiques ci-dessous ont été mises à jour de 64 Ko à 256 Ko en conséquence.</block>
  <block id="3ab93db30f3dded2c8d71859afbb53f6" category="admonition">Ne diminuez jamais la taille de transfert maximale autorisée sur ONTAP en dessous de la valeur de rsize/wsize des systèmes de fichiers NFS actuellement montés. Cela peut provoquer des blocages ou même une corruption des données avec certains systèmes d'exploitation. Par exemple, si les clients NFS sont actuellement définis sur une taille rsize/wsize de 65536, la taille maximale du transfert ONTAP peut être ajustée entre 65536 et 1048576 sans effet car les clients eux-mêmes sont limités. Réduire la taille de transfert maximale en dessous de 65536 peut endommager la disponibilité ou les données.</block>
  <block id="5ea0bb5d4dab46d7971fef94ccde9369" category="paragraph">*NetApp recommande*</block>
  <block id="09c6aa928c90ba68a4e03deadfeaa644" category="paragraph">Définition du paramètre NFSv4 fstab (/etc/fstab) suivant :</block>
  <block id="0ae3c9648bc2d8c33fa57415604da370" category="paragraph"><block ref="a63a3dc825ff52908de7c9dfcb29ffa5" prefix="" category="inline-code"></block></block>
  <block id="3e0b2c100b093560f63ad57c6849bc8a" category="admonition">NFSv3 présentait fréquemment un problème de verrouillage des fichiers journaux InnoDB après une panne de courant. L'utilisation du temps ou la commutation des fichiers journaux a résolu ce problème. Cependant, NFSv4 dispose d'opérations de verrouillage et assure le suivi des fichiers ouverts et des délégations.</block>
  <block id="62e4eb800d20b46085ccb975da78bafe" category="sidebar">ONTAP constitue le socle de la gestion et de la protection des données pour de nombreuses applications d'entreprise et technologies de base de données. Les pages suivantes fournissent des conseils sur les meilleures pratiques et les procédures d'implémentation pour l'infrastructure et les applications ONTAP et d'entreprise.</block>
  <block id="78898e52fcbdc5337204a384f2456d4f" category="sidebar">Microsoft SQL Server</block>
  <block id="4f60acc41a8bf3fa75e7f74768637787" category="sidebar">Protection des données Microsoft SQL Server</block>
  <block id="b8529ff730dcf8dd2178d72de271dc4d" category="sidebar">Bases de données open source</block>
  <block id="bb9a5a6fadabab849d2e87f0898d7601" category="sidebar">MariaDB et MySQL sur ONTAP</block>
  <block id="5ad2a11eceac3ebd7cbf3b534ebdb1db" category="sidebar">PostgreSQL sur ONTAP</block>
  <block id="c30dd1a85cf86d95b11c1a08f70130ce" category="sidebar">Base de données Oracle</block>
  <block id="4948dede9f4e7c3dfe48c38f7902f6e5" category="sidebar">Oracle sur ONTAP</block>
  <block id="d71074394b511143c8d1108e74a81abb" category="sidebar">Protection des données Oracle</block>
  <block id="f4d8825927d11df25770df5e00d6a52e" category="sidebar">Migration Oracle</block>
  <block id="86083f3ea21c2385b4f013aae3c57858" category="sidebar">SAP HANA</block>
  <block id="677f2e7e550075f7bbbdac91e0918f2f" category="sidebar">Solutions SAP</block>
  <block id="1b83f2b1c0b7fb3af048c2a59624fe3b" category="sidebar">SAP HANA avec AFF et FC</block>
  <block id="6ab3c3f05076d213f0b1feff267607c6" category="sidebar">SAP HANA avec AFF et NFS</block>
  <block id="56079badd056a19303cc26e6a4fcc7e0" category="sidebar">VMware</block>
  <block id="f07084a11252c9bca97503ea9a627c89" category="sidebar">Volumes virtuels (vVols) avec ONTAP</block>
  <block id="2d90ac09cbf108bddad31dd341f8614e" category="sidebar">VMware site Recovery Manager et ONTAP</block>
  <block id="b0dae11b82e63781abdc8f893c41b3c0" category="sidebar">Les applications d'entreprise</block>
  <block id="999bc6b18351bbe817d26f559ba408ae" category="sidebar">SAP</block>
  <block id="2d2eef88dbdd0c34bde24e2632d9944f" category="sidebar">SAP HANA et AnyDB</block>
  <block id="399bd1ee587245ecac6f39beaa99886f" category="sidebar">PostgreSQL</block>
  <block id="f4f70727dc34561dfde1a3c529b6205c" category="sidebar">Paramètres</block>
  <block id="c476a4701643b158f9f5d57bcc91951d" category="sidebar">Technologie Snapshot</block>
  <block id="35084d885dea7b061e6894c1cf3036d9" category="sidebar">Charges de travail</block>
  <block id="7d219314ccabde6609510141bb175a6c" category="sidebar">Instance partagée ou instance dédiée</block>
  <block id="d5363ae19ecaede49e2ced297df7737a" category="sidebar">Configuration de la mémoire</block>
  <block id="500c09aa1bb9af431f2c18348e69bfd0" category="sidebar">Fichiers tempdb</block>
  <block id="6fb6843bd9a214011969c02729c7d671" category="sidebar">Considérations relatives au stockage</block>
  <block id="4c5d94eb4dc4bff93f6a96a08ab7b244" category="sidebar">Sécurité des données</block>
  <block id="cf91513c6fc63cebe4b63a6647238d6d" category="sidebar">RAID</block>
  <block id="83db97189c47f7bb4edd879e8756f6e6" category="sidebar">Limites de capacité</block>
  <block id="4d2caccc34711835f6ff99da411ac04e" category="sidebar">Machines virtuelles de stockage</block>
  <block id="af81930661b267e8f1e68c4d66e9ee56" category="sidebar">Basculement et basculement</block>
  <block id="dfd1f50170457b961c15bb13ad7e3bed" category="sidebar">Tailles des fichiers de données et des blocs de reprise</block>
  <block id="49f83bf3a15b8626eb91fde93c6b1788" category="sidebar">RAC Oracle</block>
  <block id="13d80777c8fd43e555c1f5b1b72d7ef0" category="sidebar">Configuration de l'hôte</block>
  <block id="7e6bb0931a72759d39514aa924b420bc" category="sidebar">AIX</block>
  <block id="6bb83af717367dd4a47f75801ae7a2b0" category="sidebar">Linux avec ASMlib et AFD</block>
  <block id="619615da0f93507e22a6054ef2aea4f1" category="sidebar">Interfaces logiques</block>
  <block id="aca8e861c6f30fe2d42d0310a387312b" category="sidebar">Configuration Ethernet</block>
  <block id="63a5b8bd41978e8124f9ccdfa9063e9e" category="sidebar">Configuration FC SAN</block>
  <block id="c3f378ef942f6bf228a43aaacc628fea" category="sidebar">Marquage LVM</block>
  <block id="254f642527b45bc260048e30704edb39" category="sidebar">Configuration</block>
  <block id="f3a78e25ce9f95fc3c61ccc39f32fb4d" category="sidebar">Oracle Direct NFS (dNFS)</block>
  <block id="989cefa74de0e10a575103f446258d99" category="sidebar">Locations et verrouillages NFS</block>
  <block id="0d695ec265a3b0b5e7e32e33ffe4ed22" category="sidebar">Mise en cache NFS</block>
  <block id="eb4d10d6eda7c9266cd36c4eb0a223cf" category="sidebar">Utilitaire de récupération ASM</block>
  <block id="297e2ac2ec0bd88ad598062f4c07ee45" category="sidebar">Règles de hiérarchisation</block>
  <block id="9af6f452cd88c83f2bde555de8f93690" category="sidebar">Envoi de données à un magasin d'objets</block>
  <block id="08af6d4e6b562e2d0b418d7198f5a0f7" category="sidebar">Récupération des données dans le magasin d'objets</block>
  <block id="02d01636975b3ae0c0ab22368cea8d54" category="sidebar">Stratégies de Tiering</block>
  <block id="7fbd108e1fc6910c941094e95a677878" category="sidebar">Fichiers entiers</block>
  <block id="eb43c2427eb06b9f561363863b4a4f0b" category="sidebar">Fichiers partiels</block>
  <block id="1afe200fa26ba361f59b603b22ad6392" category="sidebar">Sélectionnez fichiers</block>
  <block id="448d15345bb99c834095da225c529b8a" category="sidebar">Disponibilité des données</block>
  <block id="5869e10a9dea6d88d61bb10040557f35" category="sidebar">Intégrité des données</block>
  <block id="7b68149402c05a52968bda6af0435c8a" category="sidebar">Sauvegardes en ligne basées sur des snapshots</block>
  <block id="49ba0ee205d016d8236db9c1e8c130e5" category="sidebar">Sauvegardes optimisées pour les snapshots de stockage</block>
  <block id="2c6d98297c340e390e0783220b038545" category="sidebar">Architecture physique</block>
  <block id="13a854bdd11f8f57a0b25c00631f1430" category="sidebar">Architecture logique</block>
  <block id="5e7988aeba0e1d3c15c5c78a0db738d1" category="sidebar">SyncMirror</block>
  <block id="3f23f85f537c810b6eca3c767c3ff00c" category="sidebar">Basculement Oracle</block>
  <block id="5783cab279142a801ff0fd0a03b607d5" category="sidebar">Instance unique sur MetroCluster</block>
  <block id="ea98d1b4d8c0f4b9e705df8dcdf77730" category="sidebar">Instance unique sur SM-BC</block>
  <block id="39520db4a78ddf352897eac9b11c5890" category="sidebar">Oracle RAC sur SM-BC</block>
  <block id="5ba8ee2f32815884475d1f2244ba16a6" category="sidebar">Scénarios d'échec</block>
  <block id="e31593850dc03f8f10d036df5dc8633b" category="sidebar">Migration de la base de données Oracle</block>
  <block id="5102abd5a9cc202678054b832caf678d" category="sidebar">Procédures</block>
  <block id="1495d3ed3ebff783c0f480b583372450" category="sidebar">Copie des données de l'hôte</block>
  <block id="d81ca5686c955ed50927409eb8c14bb0" category="sidebar">Importation de LUN étrangères</block>
  <block id="2fea59b7e470acac5ec1589d504da14e" category="sidebar">Achèvement</block>
  <block id="e9cc85ef98d982c3c3e53d6b82293126" category="sidebar">Conversion de protocoles</block>
  <block id="fbbd0e8905df3950eca4d1d8f55881ad" category="sidebar">Remarques supplémentaires</block>
  <block id="ac0465a970688dc3c326dcdd8fe2805e" category="sidebar">Optimisation des performances et analyse comparative</block>
  <block id="7cb9c3cd8b9873d39a1fe87c083cd55c" category="sidebar">Verrous NFS obsolètes</block>
  <block id="c0916addb4f26afa58c5a6df4f463fa5" category="sidebar">Le stockage unifié</block>
  <block id="c0032c6bab44eeeb6886c7a4aa67cf77" category="sidebar">Outils de virtualisation</block>
  <block id="1c77ac70000b6804e930748d5df7be5e" category="sidebar">Gestion basée sur des règles de stockage et des volumes virtuels</block>
  <block id="217601d383b816e6a2548e57b5006f92" category="sidebar">Clonage</block>
  <block id="8f2db90dd4a6fbd95ba8f0bc54fd6b27" category="sidebar">La QoS</block>
  <block id="09b4a81ec7b05cbacc7cbfa13e006254" category="sidebar">Gestion basée sur des règles de stockage</block>
  <block id="2e8526cbe762cb1b8393d935a3b0bf16" category="sidebar">Paramètres recommandés</block>
  <block id="10a764f91b59ce3c8931d55c2fd54222" category="sidebar">Déploiement du stockage vVols</block>
  <block id="30f6724a02fc69093960468c0a2fbcd4" category="sidebar">Sécurité des produits</block>
  <block id="3390e3575b3e341afa2b7172ff5b33a7" category="sidebar">Plug-in SnapCenter pour VMware vSphere</block>
  <block id="62a004b95946bb97541afa471dcca73a" category="sidebar">MySQL</block>
  <block id="7f1a6761f7160e33a32105202e47303b" category="sidebar">Conteneurisation</block>
  <block id="bd57f4f74ca087a92a48b23d45753729" category="paragraph">Le fournisseur VASA des outils ONTAP se charge de la gestion des igroups FCP et iSCSI ainsi que des sous-systèmes NVMe dans ONTAP en fonction des initiateurs détectés d'hôtes ESXi gérés. Toutefois, il ne s'intègre pas aux commutateurs Fibre Channel pour gérer la segmentation. La segmentation doit être effectuée conformément aux meilleures pratiques avant tout provisionnement. Voici un exemple de segmentation à un seul initiateur sur quatre systèmes ONTAP :</block>
  <block id="6b14e3f4a37881185acf7a766f8f6272" category="paragraph">Segmentation à un seul initiateur :</block>
  <block id="17ccf64e30cb518fd7ca87ce752ad738" category="paragraph"><block ref="17ccf64e30cb518fd7ca87ce752ad738" category="inline-image-macro-rx" type="image"></block></block>
  <block id="58b5cd2a94730c2e044c14891f1e0e87" category="paragraph">Pour plus d'informations sur les meilleures pratiques, reportez-vous aux documents suivants :</block>
  <block id="fc9e4d789d968936f8ff5ae5a99847e0" category="paragraph"><block ref="fc9e4d789d968936f8ff5ae5a99847e0" category="inline-link-rx"></block></block>
  <block id="d748a2834a7220eef4ec4775a51632f9" category="paragraph"><block ref="d748a2834a7220eef4ec4775a51632f9" category="inline-link-rx"></block></block>
  <block id="4047245d73abc6e3ae8bf58ec063e52e" category="paragraph">Les SCP inclus sont adaptés à la plupart des utilisations générales, mais vos besoins peuvent être différents.</block>
  <block id="80dad10df0d1a031764e7c648c46aa23" category="paragraph">*Pensez à utiliser Max IOPS pour contrôler des machines virtuelles inconnues ou tester des machines virtuelles.*</block>
  <block id="93e4f73afe8b787b33161ec273ca087f" category="paragraph">Disponible pour la première fois dans VASA Provider 7.1, Max IOPS peut être utilisé pour limiter les IOPS à un vVol spécifique pour une charge de travail inconnue afin d'éviter tout impact sur d'autres charges de travail plus stratégiques. Pour plus d'informations sur la gestion des performances, consultez le Tableau 4.</block>
  <block id="bdbd10905a1446f944699405bca52654" category="paragraph">*Assurez-vous d'avoir suffisamment de LIFs de données.*
Créez au moins deux LIF par nœud et par paire haute disponibilité. Vous devrez peut-être en faire davantage en fonction de votre charge de travail.</block>
  <block id="4e0d7e0587bf99c9b7a64a84fd42f6bd" category="paragraph">Reportez-vous aux autres guides des meilleures pratiques de NetApp et VMware spécifiques au protocole sélectionné. En général, il n'y a pas d'autres changements que ceux déjà mentionnés.</block>
  <block id="97f87e9ab1d660463c63beb8745fd9e5" category="paragraph">*Exemple de configuration réseau utilisant vVols sur NFS v3*</block>
  <block id="c80b3cc8b5013bd4039769fb0f783e60" category="paragraph"><block ref="c80b3cc8b5013bd4039769fb0f783e60" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dee28dd6d1a9ef7bf399f642fd9d588f" category="section-title">Tailles de transfert NFS</block>
  <block id="d8299d00f914e35b80644e5781e47a77" category="paragraph"><block ref="d8299d00f914e35b80644e5781e47a77" category="inline-image-macro-rx" type="image"></block></block>
  <block id="14ce62ac76fa34a51093e6bcf11a2fd1" category="paragraph">La principale considération pour la sauvegarde de base de données est d'exploiter la technologie NetApp Snapshot. La sauvegarde cohérente avec les applications et la disposition de la base de données sont d'autres éléments clés à prendre en compte pour atteindre les objectifs RTO et RPO, qui peuvent être orchestrés par NetApp SnapCenter.</block>
  <block id="2c024bdc7d0e87e8ba0f473024d45a4e" category="paragraph">La modification des paramètres du serveur et de la base de données peut améliorer et optimiser les performances de la base de données.</block>
  <block id="861f074a1ecd9d1cc088d2fe81903565" category="paragraph"><block ref="861f074a1ecd9d1cc088d2fe81903565" category="inline-image-macro-rx" type="image"></block></block>
  <block id="710e9cd79e3865d47122a799f425b31f" category="paragraph"><block ref="710e9cd79e3865d47122a799f425b31f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5a656ddcc72bacc3a5900c23edf7a08e" category="paragraph"><block ref="5a656ddcc72bacc3a5900c23edf7a08e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="073ce0a0568adc64d52dd9b1d8c02c54" category="paragraph"><block ref="073ce0a0568adc64d52dd9b1d8c02c54" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d5e31e9b7075c2926dba10053509346b" category="paragraph">L'efficacité du stockage combine RAID, le provisionnement (disposition et utilisation globales), la mise en miroir et d'autres technologies de protection des données. Les technologies NetApp telles que les copies Snapshot, le provisionnement fin et FlexClone permettent de réaliser des économies en optimisant le stockage existant de l'infrastructure et en différant, voire en évitant, les dépenses futures en stockage. Plus vous utilisez ces technologies ensemble, plus vous réalisez d'économies.</block>
  <block id="3401a9880dfc322da8a56c4d632361f6" category="paragraph"><block ref="3401a9880dfc322da8a56c4d632361f6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="87f823f4f3b4258445d5af029afe5ad9" category="paragraph"><block ref="87f823f4f3b4258445d5af029afe5ad9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9213fe9d391179276ff6c03552486255" category="paragraph"><block ref="9213fe9d391179276ff6c03552486255" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3105b4c0642b9710179c18edcf8e8718" category="paragraph"><block ref="3105b4c0642b9710179c18edcf8e8718" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1a43000eb9893bff7ab7b1ce1d3fd6a8" category="paragraph"><block ref="1a43000eb9893bff7ab7b1ce1d3fd6a8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4b7a8562c98b8c652bdfb6aa79788222" category="paragraph"><block ref="4b7a8562c98b8c652bdfb6aa79788222" category="inline-image-macro-rx" type="image"></block></block>
  <block id="25cec91f17a8619119f76c8adbace583" category="paragraph">Voir également la discussion sur l'alignement des blocs de compression dans la section <block ref="0faffd62be034c86d531acfee84d252e" category="inline-link-macro-rx"></block>. Toute disposition alignée avec les limites des blocs de compression de 8 Ko est également alignée avec les limites de 4 Ko.</block>
  <block id="38ac6f4e1538397bd4f659237ec03ebf" category="paragraph"><block ref="38ac6f4e1538397bd4f659237ec03ebf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f01518e5f3b18a9ea241bc63a3475dbd" category="paragraph"><block ref="f01518e5f3b18a9ea241bc63a3475dbd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="acce752526553bfa73c92799accd9cb8" category="summary">Présentation de la protection des données Oracle</block>
  <block id="deb8cb7644231cae002f5f37c725b86f" category="paragraph">La migration sur de longues distances nécessite généralement une approche plus créative, comme le processus d'expédition des journaux expliqué dans <block ref="86efe12ea0d3a769a4b7cfc2b6362f49" category="inline-link-macro-rx"></block>. Les réseaux IP longue distance disposent rarement d'une bande passante proche des vitesses LAN ou SAN. Dans un cas, NetApp a participé à la migration à distance d'une base de données de 220 To avec des taux de génération de journaux d'archivage très élevés. L'approche choisie pour le transfert de données a été l'expédition quotidienne de bandes, parce que cette méthode offrait la bande passante maximale possible.</block>
  <block id="055362c7082175c34483772a43b776cf" category="paragraph">Par exemple, la copie d'une base de données de 10 To prend généralement environ sept heures. Si l'entreprise a besoin d'une interruption de service de sept heures, la copie de fichiers est une option simple et sûre pour la migration. Si cinq heures sont inacceptables, un simple processus d'envoi de journaux (voir <block ref="eee8a7589b6555fc3411165c58a62ca5" category="inline-link-macro-rx"></block>) peut être configuré en déployant un minimum d'efforts afin de réduire le délai de mise en service à environ 15 minutes. Pendant ce temps, un administrateur de base de données peut terminer le processus. Si 15 ce n'est pas le cas, le processus de mise en service final peut être automatisé par script afin de réduire le délai de mise en service à quelques minutes seulement. Vous pouvez toujours accélérer une migration, mais cette opération a un coût en temps et en efforts. Les délais de mise en service doivent être déterminés en fonction des objectifs acceptables pour l'entreprise.</block>
  <block id="911e63244fc82405263306a64e535c69" category="paragraph">Un zpool ne doit être créé qu'après les étapes de la <block ref="e8673fdb712a2edcdf56742c7eec0045" category="inline-link-macro-rx"></block> sont effectuées. Si la procédure n'est pas effectuée correctement, les performances risquent d'être sérieusement dégradées en raison de l'alignement des E/S. Pour des performances optimales sur ONTAP, les E/S doivent être alignées sur une limite de 4 Ko sur un disque. Les systèmes de fichiers créés sur un zpool utilisent une taille de bloc effective qui est contrôlée par un paramètre appelé<block ref="81df978a8e3da4bee74b135548f390f3" prefix=" " category="inline-code"></block>, qui peut être affiché en exécutant la commande<block ref="1615297782a0dff59b20451e2ca97ea7" prefix=" " category="inline-code"></block>.</block>
  <block id="b2ca9da17ac7a0807fb313343c1ba9cb" category="list-text">La partition a été créée avec un décalage de 33 secteurs au lieu du décalage de 32 par défaut. Répétez la procédure décrite à la section <block ref="6ba0f94fdd8f9504e3fef5712023fb85" category="inline-link-macro-rx"></block>. L'histogramme s'affiche comme suit :</block>
  <block id="eb7f9a88026c895932f70c650c364132" category="list-text">Augmentez la taille des LUN</block>
  <block id="0f11c45e6e7377b9d10a93534d0fa2f3" category="list-text">Ajoutez une LUN à un groupe de volumes existant et développez le volume logique contenu</block>
  <block id="e4da750cce448393b2597f8f66086894" category="paragraph">Un groupe initiateur (igroup) fait partie de l'architecture de masquage des LUN ONTAP. L'accès à une LUN nouvellement créée n'est pas accessible à moins qu'un hôte ne bénéficie au préalable d'un accès. Pour ce faire, vous devez créer un groupe initiateur qui répertorie les WWN FC ou les noms d'initiateurs iSCSI auxquels l'accès doit être accordé. Au moment de la rédaction de ce rapport, FLI était pris en charge uniquement pour les LUN FC. Cependant, la conversion en iSCSI après migration est une tâche simple, comme illustré dans la <block ref="43085dc2a05784d4912331d1ed1db91d" category="inline-link-macro-rx"></block>.</block>
  <block id="525e71fb331412cd820122c3d51d453c" category="paragraph">Cela permet aux administrateurs de bases de données de récupérer de l'espace sur la baie de stockage après la suppression des données. ONTAP intercepte les zéros et désalloue l'espace de la LUN. Le processus de récupération est extrêmement rapide, car aucune donnée n'est écrite dans le système de stockage.</block>
  <block id="be17af715060572d2df93d7ffe4ce6dd" category="paragraph">Les systèmes de stockage ONTAP offrent une grande flexibilité de création de datastores pour les machines virtuelles et les disques virtuels. Bien que la plupart des meilleures pratiques relatives à ONTAP soient appliquées lors du provisionnement de datastores pour vSphere (voir la section dans cette section) <block ref="2e24324ebf41be836715e1e0dd648f4f" category="inline-link-macro-rx"></block>), voici quelques lignes directrices supplémentaires à prendre en compte :</block>
  <block id="141c3dc68be34b8f11c2a120b36a1eb8" category="list-text">Dans certains cas, vous n'aurez même pas besoin d'un datastore. Pour obtenir des performances et une gestion optimales, évitez d'utiliser un datastore pour des applications d'E/S élevées telles que les bases de données et certaines applications. Prenez plutôt en compte les systèmes de fichiers invités, tels que les systèmes de fichiers NFS ou iSCSI, gérés par l'invité ou par RDM. Pour une assistance spécifique aux applications, consultez les rapports techniques de NetApp pour votre application. Par exemple : <block ref="cfa0393f870bc70fd8973ae18376facc" category="inline-link-macro-rx"></block> dispose d'une section sur la virtualisation avec des détails utiles.</block>
  <block id="3cd9527ff0ddb17e00c08bdb4cd1a776" category="paragraph">Les règles de stockage des machines virtuelles sont utilisées dans vSphere pour gérer les fonctionnalités facultatives telles que le contrôle des E/S du stockage ou le chiffrement vSphere. Ils sont également utilisés avec les vVols pour appliquer des fonctionnalités de stockage spécifiques à la machine virtuelle. Utilisez le type de stockage NetApp.clustered.Data.ONTAP.VP.vvol et la règle ProfileName pour appliquer un SCP spécifique aux machines virtuelles à l'aide de la politique. Voir le lien:vmware-vvols-ontap.html#Best Practices[exemple de configuration réseau avec vVols sur NFS v3] pour un exemple de ceci avec les outils ONTAP VASA Provider. Les règles pour le stockage « NetApp.clustered.Data.ONTAP.VP.VASA10 » doivent être utilisées avec les datastores non basés sur vVols.</block>
  <block id="36ad91be49fdde7d3fadeba0fb782510" category="paragraph">Une fois la règle de stockage créée, elle peut être utilisée lors du provisionnement de nouvelles machines virtuelles, comme illustré à la <block ref="d202b3fe265f968d81802fcec9f3c381" category="inline-link-macro-rx"></block>. Les instructions relatives à l'utilisation des fonctionnalités de gestion des performances avec VASA Provider 7.2 sont traitées dans le <block ref="8fdd8868d80d04eecf1b4189862f536c" category="inline-xref-macro-rx"></block>.</block>
  <block id="14bdf3569ec0024259b2b02c5a668eae" category="paragraph">Quand<block ref="7ccc31934ae8244d8263d3c09bcee186" prefix=" " category="inline-code"></block> Est activé (valeur par défaut), InnoDB stocke toutes les données deux fois : d'abord dans le tampon de double écriture, puis dans les fichiers de données réels.</block>
  <block id="394ad91b4701dbd32675896bed204755" category="sidebar">Configuration de l'hôte pour PostgreSQL</block>
  <block id="9852487272d9b2aa9026d0fddc0616fc" category="sidebar">Configuration du stockage pour PostgreSQL</block>
  <block id="bc237072428e0e4c415160b898946d4c" category="sidebar">Protection des données pour PostgreSQL</block>
  <block id="3423582eed75b4bd6632c18238fd78e4" category="sidebar">Configuration de la base de données pour Microsoft SQL Server</block>
  <block id="6e97cf67ec5979ab5828852639efa208" category="sidebar">Configuration du stockage pour Microsoft SQL Server</block>
  <block id="5a4517368fb2ab5498fc2108c2ea64c5" category="sidebar">Configuration de la base de données pour Oracle Database</block>
  <block id="e483c0ecf3a2b1a60f886d4a5ac553ff" category="sidebar">Configuration de l'hôte pour Oracle Database</block>
  <block id="06b078afa802a679ad4694d13a8a2495" category="sidebar">Configuration réseau pour Oracle Database</block>
  <block id="f1991b28c5d48cb53798755acf9dfe62" category="sidebar">Configuration du stockage pour Oracle Database</block>
  <block id="ea9cdfcbfcf1906c15b6779f0f327028" category="sidebar">Configuration de base de données pour MySQL</block>
  <block id="308f8f580d0248ac023557cfd4b10d83" category="sidebar">Configuration de l'hôte pour MySQL</block>
  <block id="830f353b3e6055499fac447b16b0c935" category="sidebar">Configuration du stockage pour MySQL</block>
  <block id="3106f8f17f2974fe05da16fb0cc50505" category="summary">Bases de données PostgreSQL avec SAN sur ONTAP</block>
  <block id="74cacb0c34a37e2859e3b054938a344d" category="doc">PostgreSQL avec systèmes de fichiers SAN</block>
  <block id="1758f5c81d60f1a0ac8600fddc99a919" category="paragraph">Les bases de données PostgreSQL avec SAN sont généralement hébergées sur des systèmes de fichiers xfs, mais d'autres peuvent être utilisées si elles sont prises en charge par le fournisseur du système d'exploitation</block>
  <block id="d73e7b56b7baa813a32c521ca074e7c4" category="paragraph">Même si un seul LUN peut généralement prendre en charge jusqu'à 100 000 IOPS, les bases de données exigeantes en E/S nécessitent généralement l'utilisation de LVM avec répartition.</block>
  <block id="5c24f0d1d447c2dfc01f2f2641e1d56c" category="summary">PostgreSQL bases de données NFS avec ONTAP</block>
  <block id="3532099588a13fbccb2af22a75936454" category="doc">PostgreSQL avec systèmes de fichiers NFS</block>
  <block id="f7cc8c4234952826818ad4d0c2050ac9" category="paragraph">Les bases de données PostgreSQL peuvent être hébergées sur les systèmes de fichiers NFSv3 ou NFSv4. La meilleure option dépend de facteurs extérieurs à la base de données.</block>
  <block id="1482c42acc1dd31ee8496c71a805e73c" category="paragraph">Par exemple, le comportement de verrouillage NFSv4 peut être préférable dans certains environnements en cluster. (Voir <block ref="bc3a7e667477b8b3590fa1451dcb924c" category="inline-link-macro-rx"></block> pour plus d'informations)</block>
  <block id="9674525687765646f35916d0e569eda9" category="paragraph">Dans le cas contraire, les fonctionnalités de la base de données doivent être proches des mêmes, y compris les performances. La seule exigence est l'utilisation du<block ref="d64a84456adc959f56de6af685d0dadd" prefix=" " category="inline-code"></block> option de montage. Ceci est nécessaire pour garantir que les délais d'expiration ne produisent pas d'erreurs d'E/S irrécupérables.</block>
  <block id="0c6430fad6c643c444b5d6d52b18edb4" category="paragraph">Si NFSv4 est choisi en tant que protocole, NetApp recommande d'utiliser NFSv4.1. Certaines améliorations fonctionnelles du protocole NFSv4 dans NFSv4.1 améliorent la résilience sur NFSv4.0.</block>
  <block id="248212b04c23627e2719e106224d2eb3" category="paragraph">Utilisez les options de montage suivantes pour les charges de travail de base de données générales :</block>
  <block id="9efbdff43e91279291e95690414bec95" category="paragraph">Une fois la taille de transfert augmentée au niveau ONTAP, les options de montage suivantes sont utilisées :</block>
  <block id="395201f6a339cc4cf6b345e0c259f383" category="section-title">Tables d'emplacements TCP NFSv3</block>
  <block id="1f8260aa2c5a5b35bf771c26828d2096" category="paragraph">Si NFSv3 est utilisé avec Linux, il est essentiel de définir correctement les tables d'emplacements TCP.</block>
  <block id="92d0a1aef2134a70d5c0f0279dc22ec6" category="doc">Copies Snapshot</block>
  <block id="0c47b4eb567b018e3d2e5882b88eaca9" category="paragraph">Les snapshots de stockage sont des répliques instantanées des données cible. La mise en œuvre d'ONTAP permet de définir diverses règles et de stocker jusqu'à 1024 copies Snapshot par volume. Les copies Snapshot dans ONTAP sont compactes. L'espace est uniquement utilisé lorsque le dataset d'origine change. Ils sont également en lecture seule. Un snapshot peut être supprimé, mais il ne peut pas être modifié.</block>
  <block id="7986a4827296ca9cd0b991ded9f8a10d" category="paragraph">Dans certains cas, les snapshots peuvent être programmés directement sur ONTAP. Dans d'autres cas, des logiciels tels que SnapCenter peuvent être requis pour orchestrer les opérations d'application ou de système d'exploitation avant de créer des snapshots. Quelle que soit l'approche la plus adaptée à votre charge de travail, une stratégie Snapshot agressive peut assurer la sécurité des données grâce à un accès facile et fréquent aux sauvegardes de tous les éléments, des LUN de démarrage aux bases de données stratégiques.</block>
  <block id="210c45246ad11e0b53bdb20b64266780" category="paragraph">*Remarque* : un volume flexible ONTAP, ou plus simplement, un volume n'est pas synonyme d'un LUN. Les volumes sont des conteneurs de gestion pour des données telles que des fichiers ou des LUN. Par exemple, une base de données peut être placée sur un jeu de bandes de 8 LUN, toutes les LUN étant contenues dans un seul volume.</block>
  <block id="ad590deba1cd4423ee565e822c3a91d1" category="paragraph">Pour plus d'informations sur les instantanés, cliquez sur <block ref="211d7effcac0cb0488144c6fc8b3cb7c" category="inline-link-macro-rx"></block></block>
  <block id="c4bf0f56feeec9a45e973768fbc4f47e" category="section-title">Des snapshots inviolables</block>
  <block id="d2e783db61d20da61c761d4d473bed14" category="paragraph">Depuis ONTAP 9.12.1, les snapshots ne sont pas seulement en lecture seule, ils peuvent également être protégés contre la suppression accidentelle ou intentionnelle. Cette fonction s'appelle instantanés inviolables. Une période de conservation peut être définie et appliquée via une règle Snapshot. Les snapshots obtenus ne peuvent pas être supprimés tant qu'ils n'ont pas atteint leur date d'expiration. Il n'y a pas de substitution administrative ou de centre de support.</block>
  <block id="38fef959179f8d3eb79a68a5ce747bdc" category="paragraph">Cela permet de s'assurer qu'un intrus, un collaborateur malveillant ou même une attaque par ransomware ne peut pas compromettre les sauvegardes, même s'il a pu accéder au système ONTAP lui-même. Associée à une planification Snapshot fréquente, cette solution offre une protection des données extrêmement puissante avec un RPO très faible.</block>
  <block id="c64db0c79e66c1c0e5b932c5d2dedfea" category="paragraph">Pour plus d'informations sur les instantanés inviolables, cliquez sur <block ref="134603be635c039f9224bff191c6103c" category="inline-link-macro-rx"></block></block>
  <block id="a1f41e52e9ddbd9f87ecd032c237b1c0" category="section-title">Réplication SnapMirror</block>
  <block id="1bb837ddfb635c39a6c6e23d847823f9" category="paragraph">Les snapshots peuvent également être répliqués sur un système distant. Cela inclut les instantanés inviolables, où la période de conservation est appliquée et appliquée sur le système distant. Il en résulte les mêmes avantages en matière de protection des données que les snapshots locaux, mais les données se trouvent sur une seconde baie de stockage. Cela permet de s'assurer que la destruction de la baie d'origine ne compromet pas les sauvegardes.</block>
  <block id="18d315ae923785b3f9c5234724b0ab42" category="paragraph">Un deuxième système ouvre également de nouvelles options pour la sécurité administrative. Par exemple, certains clients NetApp isolent les informations d'authentification pour les systèmes de stockage primaire et secondaire. Aucun utilisateur administratif n'a accès aux deux systèmes, ce qui signifie qu'un administrateur malveillant ne peut pas supprimer toutes les copies des données.</block>
  <block id="e805272dcce51c35975e830e5ee9ecaf" category="paragraph">Pour en savoir plus sur SnapMirror, cliquez sur <block ref="9abdfd5d94773cf0a996248d1d722cac" category="inline-link-macro-rx"></block></block>
  <block id="500569e3cc0764260a592cb176921ca3" category="section-title">Ordinateurs virtuels de stockage</block>
  <block id="d5174dd4c760ef1a826b3e5bc22215e5" category="paragraph">Un système de stockage ONTAP nouvellement configuré est similaire à un serveur VMware ESX nouvellement provisionné, car aucun utilisateur ne peut prendre en charge avant la création d'une machine virtuelle. Avec ONTAP, vous créez une machine virtuelle de stockage (SVM) qui devient l'unité de gestion du stockage la plus élémentaire. Chaque SVM dispose de ses propres ressources de stockage, configurations de protocoles, adresses IP et WWN FCP.  C'est la base de ONTAP mult-locaancy.</block>
  <block id="597cb258dd509add7cd999794c60d430" category="paragraph">Par exemple, vous pouvez configurer un SVM pour les charges de travail de production stratégiques et un second SVM sur un autre segment réseau pour les activités de développement. Vous pouvez alors restreindre l'accès au SVM de production à certains administrateurs, tout en accordant aux développeurs un contrôle plus étendu sur les ressources de stockage du SVM de développement. Vous devrez peut-être également proposer un troisième SVM à vos équipes financières et RH afin de stocker des données sensibles uniquement.</block>
  <block id="18519d16720b1e13890c2639657b5bf8" category="paragraph">Pour plus d'informations sur les SVM, cliquez sur <block ref="a06a0fd566387240178b1c926e07cb7b" category="inline-link-macro-rx"></block></block>
  <block id="7d0fc71fe28e011ca49b06214469d484" category="section-title">RBAC d'administration</block>
  <block id="4f0dae2ba2fd11c533349d6ade4f81de" category="paragraph">ONTAP offre un puissant contrôle d'accès basé sur des rôles (RBAC) pour les connexions d'administration. Certains administrateurs peuvent avoir besoin d'un accès complet au cluster, tandis que d'autres n'ont besoin que de l'accès à certains SVM. Le personnel du service d'assistance avancé peut avoir besoin d'augmenter la taille des volumes. Vous pouvez ainsi accorder aux utilisateurs administratifs l'accès requis pour s'acquitter de leurs responsabilités professionnelles, et rien de plus. De plus, vous pouvez sécuriser ces connexions à l'aide de PKI provenant de différents fournisseurs, restreindre l'accès aux clés ssh uniquement et appliquer les verrouillages de tentatives de connexion échouées.</block>
  <block id="6ae13b0198daa7d13d79a8631297e64d" category="paragraph">Pour plus d'informations sur le contrôle d'accès administratif, cliquez sur <block ref="db5be08b697b5ef26e0e94da1d5f4970" category="inline-link-macro-rx"></block></block>
  <block id="671a94a08dff3cf44fad087e2346c8b0" category="section-title">Authentification Multfactor</block>
  <block id="c6595c32ea3c4aa315aa5c66b88b0a54" category="paragraph">ONTAP et certains autres produits NetApp prennent désormais en charge l'authentification multifacteur par le biais de diverses méthodes. Le résultat est un nom d'utilisateur/mot de passe compromis seul n'est pas un thread de sécurité sans les données du deuxième facteur, tel qu'un FOB ou une application de smartphone.</block>
  <block id="945c88a63c229c39ee73ab5592b3ef63" category="paragraph">Pour plus d'informations, cliquez sur <block ref="03628d0cd13b6640ef56c399aa1c2070" category="inline-link-macro-rx"></block></block>
  <block id="852741d2a7fb0a8a1a5dd748dbbd6734" category="section-title">RBAC D'API</block>
  <block id="bbbea5fec67f15424fa77aa563754c49" category="paragraph">L'automatisation nécessite des appels d'API, mais tous les outils ne nécessitent pas un accès administratif complet. Pour sécuriser les systèmes d'automatisation, le RBAC est également disponible au niveau des API. Vous pouvez limiter les comptes d'utilisateur d'automatisation aux appels d'API requis. Par exemple, le logiciel de surveillance n'a pas besoin d'un accès de modification, il ne nécessite qu'un accès en lecture. Les flux de travail qui provisionnent le stockage n'ont pas besoin d'être supprimés.</block>
  <block id="97ad75902b447ba6b23cabdb10252ce8" category="paragraph">Pour en savoir plus, commencez <block ref="d3dd665f13f927a9546f36768f8407dd" category="inline-link-macro-rx"></block></block>
  <block id="cb93ad4589e6e6834d2627d2ef8c8456" category="section-title">Vérification multi-administrateurs</block>
  <block id="7604bad489eaec7e27d112c63d3e2936" category="paragraph">L'authentification multifacteur peut être encore plus poussée en exigeant que deux administrateurs différents, chacun disposant de leurs propres informations d'identification, approuvent certaines activités. Cela inclut la modification des autorisations de connexion, l'exécution des commandes de diagnostic et la suppression des données.</block>
  <block id="e890d04cd745ac382688bbb307655e81" category="paragraph">Pour plus d'informations sur la vérification multiadministrateur (MAV), cliquez sur <block ref="88f84d4fec0424d978600980bf11baf0" category="inline-link-macro-rx"></block></block>
  <block id="b39c0496b44447232912303246b46aaa" category="paragraph">Si des E/S séquentielles lourdes sont attendues, la taille du transfert NFS peut être augmentée comme décrit dans la section suivante.</block>
  <block id="f8fd5d7386ed935c8520d4e04b029e93" category="paragraph">Les sections suivantes expliquent certains des paramètres de configuration de mémoire critiques.</block>
  <block id="959e8f746f4ff03f6225b95cf646e65f" category="admonition">Cette documentation remplace le rapport technique _TR-4590 : guide des meilleures pratiques pour Microsoft SQL Server avec ONTAP_</block>
  <block id="1f6b7ed754cfe3488cf91c21c13ec49a" category="paragraph">La sécurisation d'un environnement de base de données représente un effort multidimensionnel qui va au-delà de la gestion de la base de données elle-même. NetApp propose plusieurs fonctionnalités uniques conçues pour sécuriser l'aspect stockage de votre infrastructure de base de données.</block>
  <block id="15d2f797f7375b32cb5e92538291f2af" category="list-text"><block ref="15d2f797f7375b32cb5e92538291f2af" category="inline-link-rx"></block></block>
  <block id="36d72286c0ef70108b2f7791b73fdc6d" category="list-text">Les guides précédents ont recommandé de créer la LIF pour la localisation des données. C'est-à-dire toujours monter un datastore à l'aide d'une LIF située sur le nœud qui détient physiquement le volume. Ce n'est plus une exigence dans les versions modernes de ONTAP 9. Dans la mesure du possible, et si des informations d'identification avec périmètre du cluster sont fournies, les outils ONTAP choisissent toujours d'équilibrer la charge entre les LIF locales aux données, mais il ne s'agit pas d'une exigence de haute disponibilité ou de performance.</block>
  <block id="aa131b86ebd9f719bab1aba612ae3c3f" category="list-text">SRM fonctionne mieux lorsque le nombre de datastores et donc les groupes de protection sont limités dans vos plans de reprise d'activité. Par conséquent, vous devez envisager d'optimiser la densité des machines virtuelles dans les environnements protégés par SRM où le RTO est essentiel.</block>
  <block id="afab42482b97a8b43c62320c373ded74" category="list-text">Utilisez Distributed Resource Scheduler (DRS) pour équilibrer la charge sur vos clusters ESXi protégés et de récupération. N'oubliez pas que si vous prévoyez de revenir en arrière, lorsque vous exécutez une reprotection, les clusters précédemment protégés deviennent les nouveaux clusters de récupération. Le DRS contribue à équilibrer le placement dans les deux sens.</block>
  <block id="8ed6c5d9143eeb92cf75bb8a08bb7819" category="list-text">Dans la mesure du possible, évitez d'utiliser la personnalisation IP avec SRM car cela peut augmenter votre RTO.</block>
  <block id="8baa3b91d59f004ee489f4f3fd3dd4e4" category="paragraph">À partir de SRM 8.3, la protection des machines virtuelles à l'aide des datastores vVols est prise en charge. Les planifications SnapMirror sont exposées aux règles de stockage de VM par le VASA Provider lorsque la réplication de vvols est activée dans le menu des paramètres des outils ONTAP, comme indiqué dans les captures d'écran suivantes.</block>
  <block id="3c1a2fd7a7a41ca20efeae84dc73ba0a" category="paragraph">L'exemple suivant montre l'activation de la réplication vVols.</block>
  <block id="fc7cd76ae57374916b5edd5a2dd19fee" category="paragraph">À la différence des précédents datastores vvols, les datastores vvols répliqués doivent être créés dès le début avec une réplication activée, et ils doivent utiliser des volumes pré-créés sur les systèmes ONTAP avec des relations SnapMirror. Cela nécessite de pré-configurer des éléments tels que le peering de cluster et de SVM. Ces activités doivent être réalisées par votre administrateur ONTAP, car elles permettent une séparation stricte des responsabilités entre ceux qui gèrent les systèmes ONTAP sur plusieurs sites et ceux qui sont principalement responsables des opérations vSphere.</block>
  <block id="e4ad04c89e34f6ca94c87cd68315b108" category="paragraph">Cette exigence est nouvelle pour le compte de l'administrateur vSphere. Les volumes étant créés hors du cadre des outils ONTAP, il n'est pas tenu de suivre les modifications apportées par votre administrateur ONTAP tant que la période de redécouverte planifiée n'est pas au moment de la prochaine découverte. C'est pourquoi il est recommandé de toujours exécuter la redécouverte chaque fois que vous créez un volume ou une relation SnapMirror à utiliser avec vvols. Il vous suffit de cliquer avec le bouton droit de la souris sur l'hôte ou le cluster et de sélectionner Outils NetApp ONTAP &gt; mettre à jour les données d'hôte et de stockage, comme illustré dans la capture d'écran suivante.</block>
  <block id="e2e7245b1b3cf4a13a6b703ead49ebee" category="paragraph">Un gestionnaire de matrices est créé pour chaque paire de matrices. Avec les outils SRM et ONTAP, chaque association de baie s'effectue au sein d'un SVM, même si vous utilisez les identifiants du cluster. Vous pouvez ainsi segmenter les flux de travail de reprise après incident entre des locataires, en fonction des SVM qu'ils ont affectés à la gestion. Vous pouvez créer plusieurs gestionnaires de baies pour un cluster donné, qui peuvent être asymétriques. Vous pouvez « Fan-Out » ou « Fan-In » sur différents clusters ONTAP 9. Par exemple, il peut y avoir des SVM-A et SVM-B dans le Cluster-1 en cours de réplication vers SVM-C dans le Cluster-2, SVM-D dans le Cluster-3 ou vice-versa.</block>
  <block id="3233e61306af256f9de7fd3086bc08bf" category="paragraph">Il existe plusieurs facteurs à prendre en compte dans les groupes de réplication et dans la manière dont vous distribuez les machines virtuelles sur les volumes FlexVol. Le regroupement de machines virtuelles similaires dans un même volume peut améliorer l'efficacité du stockage avec les systèmes ONTAP plus anciens qui n'offrent pas de déduplication au niveau de l'agrégat. Cependant, ce regroupement augmente la taille du volume et réduit la simultanéité E/S du volume. Les systèmes ONTAP modernes offrent un équilibre parfait entre performance et efficacité du stockage en distribuant les machines virtuelles entre les volumes FlexVol au sein d'un même agrégat. La déduplication au niveau de l'agrégat améliore la parallélisation des E/S sur plusieurs volumes. Vous pouvez restaurer des VM dans les volumes simultanément, car un groupe de protection (voir ci-dessous) peut contenir plusieurs groupes de réplication. L'inconvénient de cette disposition est que les blocs peuvent être transmis plusieurs fois sur le réseau, car SnapMirror volume ne prend pas en compte la déduplication dans l'agrégat.</block>
  <block id="670ea4d89ef5c48c4f2d840baf48688c" category="paragraph">Par exemple, votre entreprise peut disposer d'une application stratégique de niveau 1 qui repose sur un serveur Microsoft SQL pour sa base de données. Vous décidez donc de placer vos machines virtuelles dans le groupe de priorité 1. Au sein du groupe de priorité 1, vous commencez à planifier la commande afin d'obtenir des services. Vous devez probablement démarrer votre contrôleur de domaine Microsoft Windows avant votre serveur Microsoft SQL, qui devra être en ligne avant votre serveur d'applications, etc. Vous devez ajouter toutes ces machines virtuelles au groupe de priorité, puis définir les dépendances, car elles ne s'appliquent qu'à un groupe de priorité donné.</block>
  <block id="512ee19e5020f3ee80a9e25f3f5a6468" category="paragraph">Il est recommandé de toujours effectuer un basculement de test dès que la configuration d'un stockage protégé d'ordinateurs virtuels modifie. Ainsi, en cas d'incident, vous avez l'assurance que site Recovery Manager peut restaurer les services au sein de la cible de délai de restauration prévue.</block>
  <block id="4da3f855cd505741909cfd49d743e68e" category="paragraph">SRM vous permet également de modifier la configuration réseau d'une machine virtuelle lors de sa restauration. Cette reconfiguration inclut des paramètres tels que les adresses IP, les adresses de passerelle et les paramètres du serveur DNS. Différents paramètres réseau, qui sont appliqués aux machines virtuelles individuelles au fur et à mesure qu'elles sont restaurées, peuvent être spécifiés dans les paramètres de propriété d'une machine virtuelle dans le plan de reprise.</block>
  <block id="e409450ce49f3558b068c69a77a9623a" category="paragraph">Après la restauration, vous devez confirmer auprès de toutes les parties prenantes que leurs services ont été renvoyés à la normale avant d'exécuter à nouveau reprotéger.</block>
  <block id="a42cf9beb4788dddb7d317e05cc08e23" category="sidebar">Fichiers de base de données et groupes de fichiers</block>
  <block id="8858bb6564a2efc189c9183c495ce545" category="sidebar">Alignement LUN</block>
  <block id="02bc4ad8a694d41c8b598dfbcb12f069" category="sidebar">Nombre de LUN et taille de LUN</block>
  <block id="066f208a93617bd82090d42624ce63cc" category="sidebar">Redimensionnement de la LUN</block>
  <block id="9eeba6fd02cf3b6d8aee35e0ce9bf8fe" category="sidebar">Répartition LVM</block>
  <block id="183bdb28f19bee640319f68825827aea" category="sidebar">RPO, RTO et SLA</block>
  <block id="2172b5d51273924b537842b0db78bfd4" category="sidebar">Notions de base sur la sauvegarde et la restauration</block>
</blocks>